nohup: ignoring input
2024-10-30 14:57:06: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
2024-10-30 14:57:07: 
================== Exp 0 ==================
 
2024-10-30 14:57:07: Hyper-parameters: 
{'dataset': 'OrganCMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f9aa0d64b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganCMNIST (INFO)>}
2024-10-30 14:57:07: Evaluation model pool: ['ConvNet']
2024-10-30 14:57:13: class c = 0: 1148 real images
2024-10-30 14:57:13: class c = 1: 619 real images
2024-10-30 14:57:13: class c = 2: 595 real images
2024-10-30 14:57:13: class c = 3: 600 real images
2024-10-30 14:57:13: class c = 4: 1088 real images
2024-10-30 14:57:13: class c = 5: 1170 real images
2024-10-30 14:57:13: class c = 6: 2986 real images
2024-10-30 14:57:13: class c = 7: 1002 real images
2024-10-30 14:57:13: class c = 8: 1022 real images
2024-10-30 14:57:13: class c = 9: 1173 real images
2024-10-30 14:57:13: class c = 10: 1572 real images
2024-10-30 14:57:13: real images channel 0, mean = 0.4942, std = 0.2834
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 14:57:13: initialize synthetic data from random real images
2024-10-30 14:57:13: [2024-10-30 14:57:13] training begins
2024-10-30 14:57:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 14:57:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:57:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:00:22: Evaluate 5 random ConvNet, ACCmean = 0.6925 ACCstd = 0.0061
-------------------------
2024-10-30 15:00:22: Evaluate 5 random ConvNet, SENmean = 0.6944 SENstd = 0.0058
-------------------------
2024-10-30 15:00:22: Evaluate 5 random ConvNet, SPEmean = 0.9692 SPEstd = 0.0006
-------------------------
2024-10-30 15:00:22: Evaluate 5 random ConvNet, F!mean = 0.6772 F!std = 0.0060
-------------------------
2024-10-30 15:00:22: Evaluate 5 random ConvNet, mean = 0.6925 std = 0.0061
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:00:23: [2024-10-30 15:00:23] iter = 00000, loss = 12.1310
2024-10-30 15:00:27: [2024-10-30 15:00:27] iter = 00010, loss = 4.5818
2024-10-30 15:00:31: [2024-10-30 15:00:31] iter = 00020, loss = 3.8390
2024-10-30 15:00:36: [2024-10-30 15:00:36] iter = 00030, loss = 3.2599
2024-10-30 15:00:40: [2024-10-30 15:00:40] iter = 00040, loss = 3.2282
2024-10-30 15:00:44: [2024-10-30 15:00:44] iter = 00050, loss = 2.6718
2024-10-30 15:00:48: [2024-10-30 15:00:48] iter = 00060, loss = 2.9035
2024-10-30 15:00:53: [2024-10-30 15:00:53] iter = 00070, loss = 3.1800
2024-10-30 15:00:57: [2024-10-30 15:00:57] iter = 00080, loss = 2.2298
2024-10-30 15:01:01: [2024-10-30 15:01:01] iter = 00090, loss = 2.4073
2024-10-30 15:01:04: [2024-10-30 15:01:04] iter = 00100, loss = 3.2378
2024-10-30 15:01:07: [2024-10-30 15:01:07] iter = 00110, loss = 2.5806
2024-10-30 15:01:12: [2024-10-30 15:01:12] iter = 00120, loss = 3.3000
2024-10-30 15:01:16: [2024-10-30 15:01:16] iter = 00130, loss = 3.3019
2024-10-30 15:01:20: [2024-10-30 15:01:20] iter = 00140, loss = 3.0429
2024-10-30 15:01:25: [2024-10-30 15:01:25] iter = 00150, loss = 2.4933
2024-10-30 15:01:29: [2024-10-30 15:01:29] iter = 00160, loss = 3.1469
2024-10-30 15:01:33: [2024-10-30 15:01:33] iter = 00170, loss = 2.6611
2024-10-30 15:01:37: [2024-10-30 15:01:37] iter = 00180, loss = 2.0877
2024-10-30 15:01:41: [2024-10-30 15:01:41] iter = 00190, loss = 2.0735
2024-10-30 15:01:46: [2024-10-30 15:01:46] iter = 00200, loss = 3.0297
2024-10-30 15:01:50: [2024-10-30 15:01:50] iter = 00210, loss = 2.2855
2024-10-30 15:01:54: [2024-10-30 15:01:54] iter = 00220, loss = 2.7298
2024-10-30 15:01:58: [2024-10-30 15:01:58] iter = 00230, loss = 3.0970
2024-10-30 15:02:02: [2024-10-30 15:02:02] iter = 00240, loss = 2.7145
2024-10-30 15:02:06: [2024-10-30 15:02:06] iter = 00250, loss = 2.0921
2024-10-30 15:02:10: [2024-10-30 15:02:10] iter = 00260, loss = 2.2270
2024-10-30 15:02:15: [2024-10-30 15:02:15] iter = 00270, loss = 2.2252
2024-10-30 15:02:20: [2024-10-30 15:02:20] iter = 00280, loss = 2.4056
2024-10-30 15:02:25: [2024-10-30 15:02:25] iter = 00290, loss = 2.2496
2024-10-30 15:02:29: [2024-10-30 15:02:29] iter = 00300, loss = 2.2100
2024-10-30 15:02:33: [2024-10-30 15:02:33] iter = 00310, loss = 1.9191
2024-10-30 15:02:37: [2024-10-30 15:02:37] iter = 00320, loss = 2.2132
2024-10-30 15:02:42: [2024-10-30 15:02:42] iter = 00330, loss = 2.2635
2024-10-30 15:02:46: [2024-10-30 15:02:46] iter = 00340, loss = 3.0608
2024-10-30 15:02:49: [2024-10-30 15:02:49] iter = 00350, loss = 2.1200
2024-10-30 15:02:53: [2024-10-30 15:02:53] iter = 00360, loss = 2.5009
2024-10-30 15:02:57: [2024-10-30 15:02:57] iter = 00370, loss = 2.0352
2024-10-30 15:02:59: [2024-10-30 15:02:59] iter = 00380, loss = 2.5364
2024-10-30 15:03:03: [2024-10-30 15:03:03] iter = 00390, loss = 2.1512
2024-10-30 15:03:07: [2024-10-30 15:03:07] iter = 00400, loss = 2.2453
2024-10-30 15:03:10: [2024-10-30 15:03:10] iter = 00410, loss = 2.1151
2024-10-30 15:03:14: [2024-10-30 15:03:14] iter = 00420, loss = 2.9864
2024-10-30 15:03:17: [2024-10-30 15:03:17] iter = 00430, loss = 2.6371
2024-10-30 15:03:21: [2024-10-30 15:03:21] iter = 00440, loss = 2.4630
2024-10-30 15:03:25: [2024-10-30 15:03:25] iter = 00450, loss = 1.9851
2024-10-30 15:03:28: [2024-10-30 15:03:28] iter = 00460, loss = 2.1811
2024-10-30 15:03:32: [2024-10-30 15:03:32] iter = 00470, loss = 1.9245
2024-10-30 15:03:35: [2024-10-30 15:03:35] iter = 00480, loss = 2.3501
2024-10-30 15:03:38: [2024-10-30 15:03:38] iter = 00490, loss = 2.1058
2024-10-30 15:03:42: [2024-10-30 15:03:42] iter = 00500, loss = 2.9259
2024-10-30 15:03:46: [2024-10-30 15:03:46] iter = 00510, loss = 2.1583
2024-10-30 15:03:49: [2024-10-30 15:03:49] iter = 00520, loss = 3.1047
2024-10-30 15:03:54: [2024-10-30 15:03:54] iter = 00530, loss = 2.3231
2024-10-30 15:03:58: [2024-10-30 15:03:58] iter = 00540, loss = 2.0347
2024-10-30 15:04:02: [2024-10-30 15:04:02] iter = 00550, loss = 2.0050
2024-10-30 15:04:06: [2024-10-30 15:04:06] iter = 00560, loss = 2.0023
2024-10-30 15:04:10: [2024-10-30 15:04:10] iter = 00570, loss = 2.0314
2024-10-30 15:04:14: [2024-10-30 15:04:14] iter = 00580, loss = 1.8671
2024-10-30 15:04:17: [2024-10-30 15:04:17] iter = 00590, loss = 2.1781
2024-10-30 15:04:21: [2024-10-30 15:04:21] iter = 00600, loss = 2.2964
2024-10-30 15:04:25: [2024-10-30 15:04:25] iter = 00610, loss = 3.0415
2024-10-30 15:04:29: [2024-10-30 15:04:29] iter = 00620, loss = 2.5966
2024-10-30 15:04:33: [2024-10-30 15:04:33] iter = 00630, loss = 2.1012
2024-10-30 15:04:37: [2024-10-30 15:04:37] iter = 00640, loss = 1.8226
2024-10-30 15:04:41: [2024-10-30 15:04:41] iter = 00650, loss = 2.1669
2024-10-30 15:04:45: [2024-10-30 15:04:45] iter = 00660, loss = 2.4686
2024-10-30 15:04:49: [2024-10-30 15:04:49] iter = 00670, loss = 2.7372
2024-10-30 15:04:53: [2024-10-30 15:04:53] iter = 00680, loss = 2.9730
2024-10-30 15:04:58: [2024-10-30 15:04:58] iter = 00690, loss = 2.1835
2024-10-30 15:05:01: [2024-10-30 15:05:01] iter = 00700, loss = 1.7796
2024-10-30 15:05:06: [2024-10-30 15:05:06] iter = 00710, loss = 2.8607
2024-10-30 15:05:09: [2024-10-30 15:05:09] iter = 00720, loss = 3.7373
2024-10-30 15:05:13: [2024-10-30 15:05:13] iter = 00730, loss = 2.0374
2024-10-30 15:05:16: [2024-10-30 15:05:16] iter = 00740, loss = 1.8919
2024-10-30 15:05:21: [2024-10-30 15:05:21] iter = 00750, loss = 1.7637
2024-10-30 15:05:24: [2024-10-30 15:05:24] iter = 00760, loss = 1.8263
2024-10-30 15:05:28: [2024-10-30 15:05:28] iter = 00770, loss = 2.4447
2024-10-30 15:05:32: [2024-10-30 15:05:32] iter = 00780, loss = 2.5871
2024-10-30 15:05:36: [2024-10-30 15:05:36] iter = 00790, loss = 2.0512
2024-10-30 15:05:39: [2024-10-30 15:05:39] iter = 00800, loss = 2.1885
2024-10-30 15:05:42: [2024-10-30 15:05:42] iter = 00810, loss = 2.8964
2024-10-30 15:05:47: [2024-10-30 15:05:47] iter = 00820, loss = 1.9303
2024-10-30 15:05:51: [2024-10-30 15:05:51] iter = 00830, loss = 2.4280
2024-10-30 15:05:55: [2024-10-30 15:05:55] iter = 00840, loss = 4.3509
2024-10-30 15:05:59: [2024-10-30 15:05:59] iter = 00850, loss = 3.0021
2024-10-30 15:06:04: [2024-10-30 15:06:04] iter = 00860, loss = 2.1172
2024-10-30 15:06:08: [2024-10-30 15:06:08] iter = 00870, loss = 2.7136
2024-10-30 15:06:14: [2024-10-30 15:06:14] iter = 00880, loss = 2.8124
2024-10-30 15:06:19: [2024-10-30 15:06:19] iter = 00890, loss = 2.9599
2024-10-30 15:06:23: [2024-10-30 15:06:23] iter = 00900, loss = 2.3246
2024-10-30 15:06:28: [2024-10-30 15:06:28] iter = 00910, loss = 2.3356
2024-10-30 15:06:32: [2024-10-30 15:06:32] iter = 00920, loss = 1.6335
2024-10-30 15:06:36: [2024-10-30 15:06:36] iter = 00930, loss = 2.6629
2024-10-30 15:06:40: [2024-10-30 15:06:40] iter = 00940, loss = 3.5868
2024-10-30 15:06:45: [2024-10-30 15:06:45] iter = 00950, loss = 3.1555
2024-10-30 15:06:49: [2024-10-30 15:06:49] iter = 00960, loss = 1.9742
2024-10-30 15:06:55: [2024-10-30 15:06:55] iter = 00970, loss = 2.0644
2024-10-30 15:06:58: [2024-10-30 15:06:58] iter = 00980, loss = 2.6394
2024-10-30 15:07:00: [2024-10-30 15:07:00] iter = 00990, loss = 2.2043
2024-10-30 15:07:03: [2024-10-30 15:07:03] iter = 01000, loss = 2.0731
2024-10-30 15:07:09: [2024-10-30 15:07:09] iter = 01010, loss = 1.4245
2024-10-30 15:07:14: [2024-10-30 15:07:14] iter = 01020, loss = 2.1512
2024-10-30 15:07:18: [2024-10-30 15:07:18] iter = 01030, loss = 2.8213
2024-10-30 15:07:22: [2024-10-30 15:07:22] iter = 01040, loss = 1.6393
2024-10-30 15:07:26: [2024-10-30 15:07:26] iter = 01050, loss = 2.0617
2024-10-30 15:07:30: [2024-10-30 15:07:30] iter = 01060, loss = 2.3363
2024-10-30 15:07:35: [2024-10-30 15:07:35] iter = 01070, loss = 2.1866
2024-10-30 15:07:40: [2024-10-30 15:07:40] iter = 01080, loss = 1.9556
2024-10-30 15:07:45: [2024-10-30 15:07:45] iter = 01090, loss = 1.9869
2024-10-30 15:07:49: [2024-10-30 15:07:49] iter = 01100, loss = 2.8820
2024-10-30 15:07:52: [2024-10-30 15:07:52] iter = 01110, loss = 1.9853
2024-10-30 15:07:57: [2024-10-30 15:07:57] iter = 01120, loss = 1.8392
2024-10-30 15:08:01: [2024-10-30 15:08:01] iter = 01130, loss = 4.3898
2024-10-30 15:08:05: [2024-10-30 15:08:05] iter = 01140, loss = 1.9636
2024-10-30 15:08:10: [2024-10-30 15:08:10] iter = 01150, loss = 2.1106
2024-10-30 15:08:14: [2024-10-30 15:08:14] iter = 01160, loss = 2.0740
2024-10-30 15:08:19: [2024-10-30 15:08:19] iter = 01170, loss = 1.6667
2024-10-30 15:08:24: [2024-10-30 15:08:24] iter = 01180, loss = 1.9731
2024-10-30 15:08:27: [2024-10-30 15:08:27] iter = 01190, loss = 2.9378
2024-10-30 15:08:31: [2024-10-30 15:08:31] iter = 01200, loss = 1.9427
2024-10-30 15:08:35: [2024-10-30 15:08:35] iter = 01210, loss = 2.2945
2024-10-30 15:08:40: [2024-10-30 15:08:40] iter = 01220, loss = 1.7996
2024-10-30 15:08:44: [2024-10-30 15:08:44] iter = 01230, loss = 7.3647
2024-10-30 15:08:48: [2024-10-30 15:08:48] iter = 01240, loss = 1.7595
2024-10-30 15:08:53: [2024-10-30 15:08:53] iter = 01250, loss = 8.7126
2024-10-30 15:08:56: [2024-10-30 15:08:56] iter = 01260, loss = 2.3521
2024-10-30 15:09:00: [2024-10-30 15:09:00] iter = 01270, loss = 2.0823
2024-10-30 15:09:04: [2024-10-30 15:09:04] iter = 01280, loss = 1.9150
2024-10-30 15:09:08: [2024-10-30 15:09:08] iter = 01290, loss = 5.7502
2024-10-30 15:09:10: [2024-10-30 15:09:10] iter = 01300, loss = 1.6835
2024-10-30 15:09:13: [2024-10-30 15:09:13] iter = 01310, loss = 1.7960
2024-10-30 15:09:18: [2024-10-30 15:09:18] iter = 01320, loss = 2.1322
2024-10-30 15:09:22: [2024-10-30 15:09:22] iter = 01330, loss = 2.3841
2024-10-30 15:09:27: [2024-10-30 15:09:27] iter = 01340, loss = 1.6852
2024-10-30 15:09:31: [2024-10-30 15:09:31] iter = 01350, loss = 1.7772
2024-10-30 15:09:35: [2024-10-30 15:09:35] iter = 01360, loss = 2.1668
2024-10-30 15:09:40: [2024-10-30 15:09:40] iter = 01370, loss = 2.4040
2024-10-30 15:09:44: [2024-10-30 15:09:44] iter = 01380, loss = 2.2815
2024-10-30 15:09:48: [2024-10-30 15:09:48] iter = 01390, loss = 2.2082
2024-10-30 15:09:53: [2024-10-30 15:09:53] iter = 01400, loss = 1.8633
2024-10-30 15:09:58: [2024-10-30 15:09:58] iter = 01410, loss = 2.0933
2024-10-30 15:10:02: [2024-10-30 15:10:02] iter = 01420, loss = 1.9980
2024-10-30 15:10:06: [2024-10-30 15:10:06] iter = 01430, loss = 2.0781
2024-10-30 15:10:10: [2024-10-30 15:10:10] iter = 01440, loss = 1.9432
2024-10-30 15:10:14: [2024-10-30 15:10:14] iter = 01450, loss = 2.0459
2024-10-30 15:10:18: [2024-10-30 15:10:18] iter = 01460, loss = 2.3724
2024-10-30 15:10:22: [2024-10-30 15:10:22] iter = 01470, loss = 2.5233
2024-10-30 15:10:24: [2024-10-30 15:10:24] iter = 01480, loss = 1.7918
2024-10-30 15:10:28: [2024-10-30 15:10:28] iter = 01490, loss = 2.1822
2024-10-30 15:10:32: [2024-10-30 15:10:32] iter = 01500, loss = 2.0678
2024-10-30 15:10:37: [2024-10-30 15:10:37] iter = 01510, loss = 2.9378
2024-10-30 15:10:41: [2024-10-30 15:10:41] iter = 01520, loss = 2.4136
2024-10-30 15:10:45: [2024-10-30 15:10:45] iter = 01530, loss = 2.3592
2024-10-30 15:10:49: [2024-10-30 15:10:49] iter = 01540, loss = 2.1782
2024-10-30 15:10:53: [2024-10-30 15:10:53] iter = 01550, loss = 1.7013
2024-10-30 15:10:57: [2024-10-30 15:10:57] iter = 01560, loss = 2.0346
2024-10-30 15:11:01: [2024-10-30 15:11:01] iter = 01570, loss = 2.9197
2024-10-30 15:11:05: [2024-10-30 15:11:05] iter = 01580, loss = 2.1685
2024-10-30 15:11:09: [2024-10-30 15:11:09] iter = 01590, loss = 1.7910
2024-10-30 15:11:13: [2024-10-30 15:11:13] iter = 01600, loss = 2.3093
2024-10-30 15:11:17: [2024-10-30 15:11:17] iter = 01610, loss = 2.2378
2024-10-30 15:11:22: [2024-10-30 15:11:22] iter = 01620, loss = 2.8443
2024-10-30 15:11:26: [2024-10-30 15:11:26] iter = 01630, loss = 2.1069
2024-10-30 15:11:30: [2024-10-30 15:11:30] iter = 01640, loss = 2.7344
2024-10-30 15:11:35: [2024-10-30 15:11:35] iter = 01650, loss = 3.1047
2024-10-30 15:11:39: [2024-10-30 15:11:39] iter = 01660, loss = 2.2609
2024-10-30 15:11:43: [2024-10-30 15:11:43] iter = 01670, loss = 1.8564
2024-10-30 15:11:48: [2024-10-30 15:11:48] iter = 01680, loss = 1.8296
2024-10-30 15:11:50: [2024-10-30 15:11:50] iter = 01690, loss = 2.2382
2024-10-30 15:11:53: [2024-10-30 15:11:53] iter = 01700, loss = 1.8003
2024-10-30 15:11:57: [2024-10-30 15:11:57] iter = 01710, loss = 2.7197
2024-10-30 15:12:00: [2024-10-30 15:12:00] iter = 01720, loss = 1.8772
2024-10-30 15:12:04: [2024-10-30 15:12:04] iter = 01730, loss = 1.8770
2024-10-30 15:12:07: [2024-10-30 15:12:07] iter = 01740, loss = 1.9823
2024-10-30 15:12:11: [2024-10-30 15:12:11] iter = 01750, loss = 1.8346
2024-10-30 15:12:15: [2024-10-30 15:12:15] iter = 01760, loss = 1.8110
2024-10-30 15:12:19: [2024-10-30 15:12:19] iter = 01770, loss = 2.1912
2024-10-30 15:12:23: [2024-10-30 15:12:23] iter = 01780, loss = 2.0423
2024-10-30 15:12:27: [2024-10-30 15:12:27] iter = 01790, loss = 1.8717
2024-10-30 15:12:31: [2024-10-30 15:12:31] iter = 01800, loss = 1.9914
2024-10-30 15:12:35: [2024-10-30 15:12:35] iter = 01810, loss = 2.3434
2024-10-30 15:12:39: [2024-10-30 15:12:39] iter = 01820, loss = 2.5373
2024-10-30 15:12:42: [2024-10-30 15:12:42] iter = 01830, loss = 2.2504
2024-10-30 15:12:45: [2024-10-30 15:12:45] iter = 01840, loss = 2.0694
2024-10-30 15:12:49: [2024-10-30 15:12:49] iter = 01850, loss = 2.1566
2024-10-30 15:12:53: [2024-10-30 15:12:53] iter = 01860, loss = 2.3361
2024-10-30 15:12:56: [2024-10-30 15:12:56] iter = 01870, loss = 3.3551
2024-10-30 15:13:00: [2024-10-30 15:13:00] iter = 01880, loss = 2.5558
2024-10-30 15:13:04: [2024-10-30 15:13:04] iter = 01890, loss = 3.5755
2024-10-30 15:13:07: [2024-10-30 15:13:07] iter = 01900, loss = 2.4618
2024-10-30 15:13:10: [2024-10-30 15:13:10] iter = 01910, loss = 2.2159
2024-10-30 15:13:15: [2024-10-30 15:13:15] iter = 01920, loss = 1.9961
2024-10-30 15:13:19: [2024-10-30 15:13:19] iter = 01930, loss = 1.9701
2024-10-30 15:13:23: [2024-10-30 15:13:23] iter = 01940, loss = 2.1204
2024-10-30 15:13:26: [2024-10-30 15:13:26] iter = 01950, loss = 2.1188
2024-10-30 15:13:29: [2024-10-30 15:13:29] iter = 01960, loss = 2.1781
2024-10-30 15:13:33: [2024-10-30 15:13:33] iter = 01970, loss = 2.4742
2024-10-30 15:13:37: [2024-10-30 15:13:37] iter = 01980, loss = 1.7692
2024-10-30 15:13:40: [2024-10-30 15:13:40] iter = 01990, loss = 1.8339
2024-10-30 15:13:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 15:13:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:13:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 23963}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:16:13: Evaluate 5 random ConvNet, ACCmean = 0.7913 ACCstd = 0.0027
-------------------------
2024-10-30 15:16:13: Evaluate 5 random ConvNet, SENmean = 0.7855 SENstd = 0.0032
-------------------------
2024-10-30 15:16:13: Evaluate 5 random ConvNet, SPEmean = 0.9789 SPEstd = 0.0003
-------------------------
2024-10-30 15:16:13: Evaluate 5 random ConvNet, F!mean = 0.7769 F!std = 0.0032
-------------------------
2024-10-30 15:16:13: Evaluate 5 random ConvNet, mean = 0.7913 std = 0.0027
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:16:13: [2024-10-30 15:16:13] iter = 02000, loss = 3.6343
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:16:18: [2024-10-30 15:16:18] iter = 02010, loss = 1.7389
2024-10-30 15:16:22: [2024-10-30 15:16:22] iter = 02020, loss = 1.8898
2024-10-30 15:16:27: [2024-10-30 15:16:27] iter = 02030, loss = 2.5372
2024-10-30 15:16:31: [2024-10-30 15:16:31] iter = 02040, loss = 2.7220
2024-10-30 15:16:34: [2024-10-30 15:16:34] iter = 02050, loss = 2.4047
2024-10-30 15:16:38: [2024-10-30 15:16:38] iter = 02060, loss = 2.4784
2024-10-30 15:16:41: [2024-10-30 15:16:41] iter = 02070, loss = 1.9472
2024-10-30 15:16:45: [2024-10-30 15:16:45] iter = 02080, loss = 2.8651
2024-10-30 15:16:47: [2024-10-30 15:16:47] iter = 02090, loss = 2.3167
2024-10-30 15:16:51: [2024-10-30 15:16:51] iter = 02100, loss = 2.0237
2024-10-30 15:16:55: [2024-10-30 15:16:55] iter = 02110, loss = 2.1608
2024-10-30 15:16:59: [2024-10-30 15:16:59] iter = 02120, loss = 1.6753
2024-10-30 15:17:03: [2024-10-30 15:17:03] iter = 02130, loss = 1.8008
2024-10-30 15:17:07: [2024-10-30 15:17:07] iter = 02140, loss = 2.9427
2024-10-30 15:17:10: [2024-10-30 15:17:10] iter = 02150, loss = 2.1760
2024-10-30 15:17:14: [2024-10-30 15:17:14] iter = 02160, loss = 1.7154
2024-10-30 15:17:19: [2024-10-30 15:17:19] iter = 02170, loss = 2.8198
2024-10-30 15:17:22: [2024-10-30 15:17:22] iter = 02180, loss = 1.7264
2024-10-30 15:17:26: [2024-10-30 15:17:26] iter = 02190, loss = 1.7067
2024-10-30 15:17:29: [2024-10-30 15:17:29] iter = 02200, loss = 3.1034
2024-10-30 15:17:34: [2024-10-30 15:17:34] iter = 02210, loss = 2.3932
2024-10-30 15:17:38: [2024-10-30 15:17:38] iter = 02220, loss = 1.8895
2024-10-30 15:17:41: [2024-10-30 15:17:41] iter = 02230, loss = 2.9660
2024-10-30 15:17:44: [2024-10-30 15:17:44] iter = 02240, loss = 2.2243
2024-10-30 15:17:47: [2024-10-30 15:17:47] iter = 02250, loss = 1.8964
2024-10-30 15:17:50: [2024-10-30 15:17:50] iter = 02260, loss = 1.8237
2024-10-30 15:17:54: [2024-10-30 15:17:54] iter = 02270, loss = 2.0775
2024-10-30 15:17:58: [2024-10-30 15:17:58] iter = 02280, loss = 2.2360
2024-10-30 15:18:00: [2024-10-30 15:18:00] iter = 02290, loss = 2.3434
2024-10-30 15:18:03: [2024-10-30 15:18:03] iter = 02300, loss = 5.2628
2024-10-30 15:18:06: [2024-10-30 15:18:06] iter = 02310, loss = 2.8090
2024-10-30 15:18:10: [2024-10-30 15:18:10] iter = 02320, loss = 2.0673
2024-10-30 15:18:13: [2024-10-30 15:18:13] iter = 02330, loss = 2.7262
2024-10-30 15:18:16: [2024-10-30 15:18:16] iter = 02340, loss = 2.0031
2024-10-30 15:18:19: [2024-10-30 15:18:19] iter = 02350, loss = 2.2988
2024-10-30 15:18:23: [2024-10-30 15:18:23] iter = 02360, loss = 1.7385
2024-10-30 15:18:27: [2024-10-30 15:18:27] iter = 02370, loss = 2.7986
2024-10-30 15:18:30: [2024-10-30 15:18:30] iter = 02380, loss = 2.0012
2024-10-30 15:18:34: [2024-10-30 15:18:34] iter = 02390, loss = 2.1065
2024-10-30 15:18:37: [2024-10-30 15:18:37] iter = 02400, loss = 3.3022
2024-10-30 15:18:40: [2024-10-30 15:18:40] iter = 02410, loss = 1.8306
2024-10-30 15:18:44: [2024-10-30 15:18:44] iter = 02420, loss = 2.0980
2024-10-30 15:18:48: [2024-10-30 15:18:48] iter = 02430, loss = 2.1296
2024-10-30 15:18:51: [2024-10-30 15:18:51] iter = 02440, loss = 2.3453
2024-10-30 15:18:54: [2024-10-30 15:18:54] iter = 02450, loss = 2.0354
2024-10-30 15:18:57: [2024-10-30 15:18:57] iter = 02460, loss = 2.0143
2024-10-30 15:19:02: [2024-10-30 15:19:02] iter = 02470, loss = 2.5628
2024-10-30 15:19:04: [2024-10-30 15:19:04] iter = 02480, loss = 2.0519
2024-10-30 15:19:07: [2024-10-30 15:19:07] iter = 02490, loss = 1.8513
2024-10-30 15:19:10: [2024-10-30 15:19:10] iter = 02500, loss = 1.8299
2024-10-30 15:19:13: [2024-10-30 15:19:13] iter = 02510, loss = 5.0800
2024-10-30 15:19:17: [2024-10-30 15:19:17] iter = 02520, loss = 2.1406
2024-10-30 15:19:20: [2024-10-30 15:19:20] iter = 02530, loss = 2.6161
2024-10-30 15:19:24: [2024-10-30 15:19:24] iter = 02540, loss = 3.7637
2024-10-30 15:19:28: [2024-10-30 15:19:28] iter = 02550, loss = 3.9628
2024-10-30 15:19:31: [2024-10-30 15:19:31] iter = 02560, loss = 2.4037
2024-10-30 15:19:35: [2024-10-30 15:19:35] iter = 02570, loss = 2.2299
2024-10-30 15:19:38: [2024-10-30 15:19:38] iter = 02580, loss = 2.3750
2024-10-30 15:19:42: [2024-10-30 15:19:42] iter = 02590, loss = 1.8872
2024-10-30 15:19:46: [2024-10-30 15:19:45] iter = 02600, loss = 2.6601
2024-10-30 15:19:49: [2024-10-30 15:19:49] iter = 02610, loss = 2.0067
2024-10-30 15:19:53: [2024-10-30 15:19:53] iter = 02620, loss = 2.1502
2024-10-30 15:19:56: [2024-10-30 15:19:56] iter = 02630, loss = 2.2942
2024-10-30 15:20:01: [2024-10-30 15:20:01] iter = 02640, loss = 2.5432
2024-10-30 15:20:04: [2024-10-30 15:20:04] iter = 02650, loss = 1.6915
2024-10-30 15:20:07: [2024-10-30 15:20:07] iter = 02660, loss = 2.1985
2024-10-30 15:20:11: [2024-10-30 15:20:11] iter = 02670, loss = 2.8325
2024-10-30 15:20:14: [2024-10-30 15:20:14] iter = 02680, loss = 3.4316
2024-10-30 15:20:19: [2024-10-30 15:20:19] iter = 02690, loss = 1.9752
2024-10-30 15:20:22: [2024-10-30 15:20:22] iter = 02700, loss = 1.7985
2024-10-30 15:20:25: [2024-10-30 15:20:25] iter = 02710, loss = 2.1683
2024-10-30 15:20:29: [2024-10-30 15:20:29] iter = 02720, loss = 3.0011
2024-10-30 15:20:34: [2024-10-30 15:20:34] iter = 02730, loss = 2.0353
2024-10-30 15:20:37: [2024-10-30 15:20:37] iter = 02740, loss = 2.0164
2024-10-30 15:20:41: [2024-10-30 15:20:41] iter = 02750, loss = 2.3319
2024-10-30 15:20:44: [2024-10-30 15:20:44] iter = 02760, loss = 2.9104
2024-10-30 15:20:48: [2024-10-30 15:20:48] iter = 02770, loss = 2.1936
2024-10-30 15:20:51: [2024-10-30 15:20:51] iter = 02780, loss = 2.1388
2024-10-30 15:20:54: [2024-10-30 15:20:54] iter = 02790, loss = 3.1880
2024-10-30 15:20:58: [2024-10-30 15:20:58] iter = 02800, loss = 2.3522
2024-10-30 15:21:02: [2024-10-30 15:21:02] iter = 02810, loss = 2.4174
2024-10-30 15:21:05: [2024-10-30 15:21:05] iter = 02820, loss = 3.5284
2024-10-30 15:21:09: [2024-10-30 15:21:09] iter = 02830, loss = 2.5847
2024-10-30 15:21:12: [2024-10-30 15:21:12] iter = 02840, loss = 2.7097
2024-10-30 15:21:16: [2024-10-30 15:21:16] iter = 02850, loss = 2.0519
2024-10-30 15:21:19: [2024-10-30 15:21:19] iter = 02860, loss = 1.9703
2024-10-30 15:21:23: [2024-10-30 15:21:23] iter = 02870, loss = 2.2760
2024-10-30 15:21:27: [2024-10-30 15:21:27] iter = 02880, loss = 1.9257
2024-10-30 15:21:30: [2024-10-30 15:21:30] iter = 02890, loss = 3.9098
2024-10-30 15:21:34: [2024-10-30 15:21:34] iter = 02900, loss = 5.0784
2024-10-30 15:21:38: [2024-10-30 15:21:38] iter = 02910, loss = 1.7888
2024-10-30 15:21:41: [2024-10-30 15:21:41] iter = 02920, loss = 7.8844
2024-10-30 15:21:44: [2024-10-30 15:21:44] iter = 02930, loss = 2.4500
2024-10-30 15:21:47: [2024-10-30 15:21:47] iter = 02940, loss = 1.7227
2024-10-30 15:21:51: [2024-10-30 15:21:51] iter = 02950, loss = 2.0099
2024-10-30 15:21:54: [2024-10-30 15:21:54] iter = 02960, loss = 1.7054
2024-10-30 15:21:58: [2024-10-30 15:21:58] iter = 02970, loss = 2.1900
2024-10-30 15:22:03: [2024-10-30 15:22:03] iter = 02980, loss = 2.0549
2024-10-30 15:22:06: [2024-10-30 15:22:06] iter = 02990, loss = 1.7908
2024-10-30 15:22:10: [2024-10-30 15:22:09] iter = 03000, loss = 2.3569
2024-10-30 15:22:13: [2024-10-30 15:22:13] iter = 03010, loss = 2.3010
2024-10-30 15:22:17: [2024-10-30 15:22:17] iter = 03020, loss = 1.9827
2024-10-30 15:22:21: [2024-10-30 15:22:21] iter = 03030, loss = 2.6120
2024-10-30 15:22:24: [2024-10-30 15:22:24] iter = 03040, loss = 1.9527
2024-10-30 15:22:29: [2024-10-30 15:22:28] iter = 03050, loss = 1.9697
2024-10-30 15:22:33: [2024-10-30 15:22:33] iter = 03060, loss = 2.4932
2024-10-30 15:22:38: [2024-10-30 15:22:38] iter = 03070, loss = 1.8538
2024-10-30 15:22:43: [2024-10-30 15:22:43] iter = 03080, loss = 2.9452
2024-10-30 15:22:47: [2024-10-30 15:22:47] iter = 03090, loss = 1.9412
2024-10-30 15:22:51: [2024-10-30 15:22:51] iter = 03100, loss = 2.3618
2024-10-30 15:22:55: [2024-10-30 15:22:55] iter = 03110, loss = 1.8244
2024-10-30 15:22:59: [2024-10-30 15:22:59] iter = 03120, loss = 1.9874
2024-10-30 15:23:02: [2024-10-30 15:23:02] iter = 03130, loss = 2.0627
2024-10-30 15:23:06: [2024-10-30 15:23:06] iter = 03140, loss = 2.1121
2024-10-30 15:23:10: [2024-10-30 15:23:10] iter = 03150, loss = 1.8274
2024-10-30 15:23:15: [2024-10-30 15:23:15] iter = 03160, loss = 3.2864
2024-10-30 15:23:20: [2024-10-30 15:23:20] iter = 03170, loss = 2.5823
2024-10-30 15:23:24: [2024-10-30 15:23:24] iter = 03180, loss = 1.8878
2024-10-30 15:23:28: [2024-10-30 15:23:28] iter = 03190, loss = 2.7905
2024-10-30 15:23:31: [2024-10-30 15:23:31] iter = 03200, loss = 1.8814
2024-10-30 15:23:35: [2024-10-30 15:23:35] iter = 03210, loss = 3.1934
2024-10-30 15:23:39: [2024-10-30 15:23:39] iter = 03220, loss = 2.0900
2024-10-30 15:23:43: [2024-10-30 15:23:43] iter = 03230, loss = 2.0208
2024-10-30 15:23:48: [2024-10-30 15:23:48] iter = 03240, loss = 1.7323
2024-10-30 15:23:52: [2024-10-30 15:23:52] iter = 03250, loss = 1.6480
2024-10-30 15:23:56: [2024-10-30 15:23:56] iter = 03260, loss = 3.0321
2024-10-30 15:24:00: [2024-10-30 15:24:00] iter = 03270, loss = 2.0402
2024-10-30 15:24:03: [2024-10-30 15:24:03] iter = 03280, loss = 2.3508
2024-10-30 15:24:06: [2024-10-30 15:24:06] iter = 03290, loss = 1.9932
2024-10-30 15:24:10: [2024-10-30 15:24:10] iter = 03300, loss = 1.6111
2024-10-30 15:24:15: [2024-10-30 15:24:15] iter = 03310, loss = 2.2667
2024-10-30 15:24:17: [2024-10-30 15:24:17] iter = 03320, loss = 2.3475
2024-10-30 15:24:21: [2024-10-30 15:24:21] iter = 03330, loss = 2.1935
2024-10-30 15:24:24: [2024-10-30 15:24:24] iter = 03340, loss = 2.6363
2024-10-30 15:24:27: [2024-10-30 15:24:27] iter = 03350, loss = 2.1509
2024-10-30 15:24:30: [2024-10-30 15:24:30] iter = 03360, loss = 2.0254
2024-10-30 15:24:33: [2024-10-30 15:24:33] iter = 03370, loss = 3.7215
2024-10-30 15:24:37: [2024-10-30 15:24:37] iter = 03380, loss = 2.5488
2024-10-30 15:24:40: [2024-10-30 15:24:40] iter = 03390, loss = 1.7828
2024-10-30 15:24:44: [2024-10-30 15:24:44] iter = 03400, loss = 2.2134
2024-10-30 15:24:47: [2024-10-30 15:24:47] iter = 03410, loss = 2.0688
2024-10-30 15:24:50: [2024-10-30 15:24:50] iter = 03420, loss = 1.8109
2024-10-30 15:24:53: [2024-10-30 15:24:53] iter = 03430, loss = 1.9036
2024-10-30 15:24:56: [2024-10-30 15:24:56] iter = 03440, loss = 1.7892
2024-10-30 15:24:59: [2024-10-30 15:24:59] iter = 03450, loss = 1.8749
2024-10-30 15:25:03: [2024-10-30 15:25:03] iter = 03460, loss = 1.9209
2024-10-30 15:25:07: [2024-10-30 15:25:07] iter = 03470, loss = 2.3496
2024-10-30 15:25:10: [2024-10-30 15:25:10] iter = 03480, loss = 1.9125
2024-10-30 15:25:14: [2024-10-30 15:25:14] iter = 03490, loss = 1.9874
2024-10-30 15:25:18: [2024-10-30 15:25:18] iter = 03500, loss = 3.0423
2024-10-30 15:25:22: [2024-10-30 15:25:22] iter = 03510, loss = 2.8636
2024-10-30 15:25:26: [2024-10-30 15:25:26] iter = 03520, loss = 1.8392
2024-10-30 15:25:30: [2024-10-30 15:25:30] iter = 03530, loss = 1.9256
2024-10-30 15:25:34: [2024-10-30 15:25:34] iter = 03540, loss = 2.0495
2024-10-30 15:25:38: [2024-10-30 15:25:38] iter = 03550, loss = 2.5118
2024-10-30 15:25:42: [2024-10-30 15:25:42] iter = 03560, loss = 1.8877
2024-10-30 15:25:46: [2024-10-30 15:25:46] iter = 03570, loss = 2.0775
2024-10-30 15:25:49: [2024-10-30 15:25:49] iter = 03580, loss = 2.0507
2024-10-30 15:25:53: [2024-10-30 15:25:53] iter = 03590, loss = 2.2342
2024-10-30 15:25:57: [2024-10-30 15:25:57] iter = 03600, loss = 2.0468
2024-10-30 15:26:01: [2024-10-30 15:26:01] iter = 03610, loss = 2.0460
2024-10-30 15:26:05: [2024-10-30 15:26:05] iter = 03620, loss = 1.8709
2024-10-30 15:26:08: [2024-10-30 15:26:08] iter = 03630, loss = 2.1683
2024-10-30 15:26:13: [2024-10-30 15:26:13] iter = 03640, loss = 2.1512
2024-10-30 15:26:17: [2024-10-30 15:26:17] iter = 03650, loss = 1.9349
2024-10-30 15:26:20: [2024-10-30 15:26:20] iter = 03660, loss = 2.2538
2024-10-30 15:26:24: [2024-10-30 15:26:24] iter = 03670, loss = 2.0518
2024-10-30 15:26:28: [2024-10-30 15:26:28] iter = 03680, loss = 3.1689
2024-10-30 15:26:32: [2024-10-30 15:26:32] iter = 03690, loss = 2.4192
2024-10-30 15:26:36: [2024-10-30 15:26:36] iter = 03700, loss = 1.7914
2024-10-30 15:26:40: [2024-10-30 15:26:40] iter = 03710, loss = 1.6803
2024-10-30 15:26:45: [2024-10-30 15:26:45] iter = 03720, loss = 7.3817
2024-10-30 15:26:49: [2024-10-30 15:26:49] iter = 03730, loss = 1.8134
2024-10-30 15:26:52: [2024-10-30 15:26:52] iter = 03740, loss = 4.8776
2024-10-30 15:26:56: [2024-10-30 15:26:56] iter = 03750, loss = 2.3625
2024-10-30 15:27:00: [2024-10-30 15:27:00] iter = 03760, loss = 3.3596
2024-10-30 15:27:04: [2024-10-30 15:27:04] iter = 03770, loss = 2.0408
2024-10-30 15:27:09: [2024-10-30 15:27:09] iter = 03780, loss = 2.2594
2024-10-30 15:27:13: [2024-10-30 15:27:13] iter = 03790, loss = 1.6913
2024-10-30 15:27:18: [2024-10-30 15:27:18] iter = 03800, loss = 4.0073
2024-10-30 15:27:22: [2024-10-30 15:27:22] iter = 03810, loss = 2.1582
2024-10-30 15:27:25: [2024-10-30 15:27:25] iter = 03820, loss = 2.7211
2024-10-30 15:27:29: [2024-10-30 15:27:29] iter = 03830, loss = 2.2750
2024-10-30 15:27:33: [2024-10-30 15:27:33] iter = 03840, loss = 2.2154
2024-10-30 15:27:37: [2024-10-30 15:27:37] iter = 03850, loss = 1.6886
2024-10-30 15:27:41: [2024-10-30 15:27:41] iter = 03860, loss = 3.0670
2024-10-30 15:27:43: [2024-10-30 15:27:43] iter = 03870, loss = 2.5336
2024-10-30 15:27:47: [2024-10-30 15:27:47] iter = 03880, loss = 1.7976
2024-10-30 15:27:52: [2024-10-30 15:27:52] iter = 03890, loss = 2.7920
2024-10-30 15:27:56: [2024-10-30 15:27:56] iter = 03900, loss = 2.2620
2024-10-30 15:27:59: [2024-10-30 15:27:59] iter = 03910, loss = 5.4514
2024-10-30 15:28:03: [2024-10-30 15:28:03] iter = 03920, loss = 2.1619
2024-10-30 15:28:07: [2024-10-30 15:28:07] iter = 03930, loss = 3.1741
2024-10-30 15:28:10: [2024-10-30 15:28:10] iter = 03940, loss = 1.9758
2024-10-30 15:28:14: [2024-10-30 15:28:14] iter = 03950, loss = 1.8126
2024-10-30 15:28:18: [2024-10-30 15:28:18] iter = 03960, loss = 2.0077
2024-10-30 15:28:22: [2024-10-30 15:28:22] iter = 03970, loss = 3.1888
2024-10-30 15:28:24: [2024-10-30 15:28:24] iter = 03980, loss = 1.8089
2024-10-30 15:28:28: [2024-10-30 15:28:28] iter = 03990, loss = 2.2520
2024-10-30 15:28:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 15:28:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:28:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 12388}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:31:00: Evaluate 5 random ConvNet, ACCmean = 0.7807 ACCstd = 0.0045
-------------------------
2024-10-30 15:31:00: Evaluate 5 random ConvNet, SENmean = 0.7757 SENstd = 0.0043
-------------------------
2024-10-30 15:31:00: Evaluate 5 random ConvNet, SPEmean = 0.9779 SPEstd = 0.0004
-------------------------
2024-10-30 15:31:00: Evaluate 5 random ConvNet, F!mean = 0.7673 F!std = 0.0045
-------------------------
2024-10-30 15:31:00: Evaluate 5 random ConvNet, mean = 0.7807 std = 0.0045
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:31:00: [2024-10-30 15:31:00] iter = 04000, loss = 2.0860
2024-10-30 15:31:03: [2024-10-30 15:31:03] iter = 04010, loss = 2.0219
2024-10-30 15:31:06: [2024-10-30 15:31:06] iter = 04020, loss = 2.0930
2024-10-30 15:31:09: [2024-10-30 15:31:09] iter = 04030, loss = 1.8164
2024-10-30 15:31:14: [2024-10-30 15:31:14] iter = 04040, loss = 1.9851
2024-10-30 15:31:18: [2024-10-30 15:31:18] iter = 04050, loss = 2.3119
2024-10-30 15:31:22: [2024-10-30 15:31:22] iter = 04060, loss = 2.4847
2024-10-30 15:31:25: [2024-10-30 15:31:25] iter = 04070, loss = 3.8066
2024-10-30 15:31:28: [2024-10-30 15:31:28] iter = 04080, loss = 1.6743
2024-10-30 15:31:31: [2024-10-30 15:31:31] iter = 04090, loss = 2.2359
2024-10-30 15:31:34: [2024-10-30 15:31:34] iter = 04100, loss = 2.0617
2024-10-30 15:31:38: [2024-10-30 15:31:38] iter = 04110, loss = 3.0400
2024-10-30 15:31:42: [2024-10-30 15:31:42] iter = 04120, loss = 2.4015
2024-10-30 15:31:45: [2024-10-30 15:31:45] iter = 04130, loss = 2.1645
2024-10-30 15:31:49: [2024-10-30 15:31:49] iter = 04140, loss = 2.0456
2024-10-30 15:31:53: [2024-10-30 15:31:53] iter = 04150, loss = 1.8540
2024-10-30 15:31:57: [2024-10-30 15:31:57] iter = 04160, loss = 1.9277
2024-10-30 15:32:00: [2024-10-30 15:32:00] iter = 04170, loss = 2.4486
2024-10-30 15:32:03: [2024-10-30 15:32:03] iter = 04180, loss = 1.7033
2024-10-30 15:32:07: [2024-10-30 15:32:07] iter = 04190, loss = 1.8444
2024-10-30 15:32:10: [2024-10-30 15:32:10] iter = 04200, loss = 2.6099
2024-10-30 15:32:14: [2024-10-30 15:32:14] iter = 04210, loss = 2.5833
2024-10-30 15:32:19: [2024-10-30 15:32:19] iter = 04220, loss = 2.0357
2024-10-30 15:32:23: [2024-10-30 15:32:23] iter = 04230, loss = 1.9724
2024-10-30 15:32:27: [2024-10-30 15:32:27] iter = 04240, loss = 2.1410
2024-10-30 15:32:30: [2024-10-30 15:32:30] iter = 04250, loss = 1.9347
2024-10-30 15:32:33: [2024-10-30 15:32:33] iter = 04260, loss = 3.8967
2024-10-30 15:32:37: [2024-10-30 15:32:37] iter = 04270, loss = 2.4714
2024-10-30 15:32:42: [2024-10-30 15:32:42] iter = 04280, loss = 1.9622
2024-10-30 15:32:45: [2024-10-30 15:32:45] iter = 04290, loss = 1.8584
2024-10-30 15:32:47: [2024-10-30 15:32:47] iter = 04300, loss = 2.7565
2024-10-30 15:32:51: [2024-10-30 15:32:51] iter = 04310, loss = 2.1518
2024-10-30 15:32:55: [2024-10-30 15:32:55] iter = 04320, loss = 2.2112
2024-10-30 15:32:57: [2024-10-30 15:32:57] iter = 04330, loss = 2.8016
2024-10-30 15:33:01: [2024-10-30 15:33:01] iter = 04340, loss = 2.3393
2024-10-30 15:33:04: [2024-10-30 15:33:04] iter = 04350, loss = 1.8345
2024-10-30 15:33:07: [2024-10-30 15:33:07] iter = 04360, loss = 2.0820
2024-10-30 15:33:11: [2024-10-30 15:33:11] iter = 04370, loss = 3.2536
2024-10-30 15:33:14: [2024-10-30 15:33:14] iter = 04380, loss = 2.4456
2024-10-30 15:33:17: [2024-10-30 15:33:17] iter = 04390, loss = 4.3361
2024-10-30 15:33:21: [2024-10-30 15:33:21] iter = 04400, loss = 1.8770
2024-10-30 15:33:24: [2024-10-30 15:33:24] iter = 04410, loss = 2.2242
2024-10-30 15:33:28: [2024-10-30 15:33:28] iter = 04420, loss = 1.8467
2024-10-30 15:33:32: [2024-10-30 15:33:32] iter = 04430, loss = 1.8296
2024-10-30 15:33:35: [2024-10-30 15:33:35] iter = 04440, loss = 2.9725
2024-10-30 15:33:38: [2024-10-30 15:33:38] iter = 04450, loss = 2.1970
2024-10-30 15:33:42: [2024-10-30 15:33:42] iter = 04460, loss = 2.1899
2024-10-30 15:33:45: [2024-10-30 15:33:45] iter = 04470, loss = 2.0359
2024-10-30 15:33:49: [2024-10-30 15:33:49] iter = 04480, loss = 2.5081
2024-10-30 15:33:52: [2024-10-30 15:33:52] iter = 04490, loss = 2.0011
2024-10-30 15:33:56: [2024-10-30 15:33:56] iter = 04500, loss = 1.9436
2024-10-30 15:34:00: [2024-10-30 15:34:00] iter = 04510, loss = 4.5061
2024-10-30 15:34:04: [2024-10-30 15:34:04] iter = 04520, loss = 2.6508
2024-10-30 15:34:08: [2024-10-30 15:34:08] iter = 04530, loss = 1.7877
2024-10-30 15:34:11: [2024-10-30 15:34:11] iter = 04540, loss = 2.1447
2024-10-30 15:34:15: [2024-10-30 15:34:15] iter = 04550, loss = 2.1020
2024-10-30 15:34:18: [2024-10-30 15:34:18] iter = 04560, loss = 3.7618
2024-10-30 15:34:22: [2024-10-30 15:34:22] iter = 04570, loss = 2.2533
2024-10-30 15:34:26: [2024-10-30 15:34:26] iter = 04580, loss = 2.0493
2024-10-30 15:34:29: [2024-10-30 15:34:29] iter = 04590, loss = 1.9688
2024-10-30 15:34:31: [2024-10-30 15:34:31] iter = 04600, loss = 1.6775
2024-10-30 15:34:34: [2024-10-30 15:34:34] iter = 04610, loss = 2.3419
2024-10-30 15:34:37: [2024-10-30 15:34:37] iter = 04620, loss = 2.1793
2024-10-30 15:34:41: [2024-10-30 15:34:41] iter = 04630, loss = 1.7888
2024-10-30 15:34:45: [2024-10-30 15:34:45] iter = 04640, loss = 2.9244
2024-10-30 15:34:49: [2024-10-30 15:34:49] iter = 04650, loss = 1.8373
2024-10-30 15:34:53: [2024-10-30 15:34:53] iter = 04660, loss = 2.4837
2024-10-30 15:34:57: [2024-10-30 15:34:57] iter = 04670, loss = 1.8703
2024-10-30 15:35:00: [2024-10-30 15:35:00] iter = 04680, loss = 5.5057
2024-10-30 15:35:02: [2024-10-30 15:35:02] iter = 04690, loss = 2.3705
2024-10-30 15:35:05: [2024-10-30 15:35:05] iter = 04700, loss = 2.1535
2024-10-30 15:35:08: [2024-10-30 15:35:08] iter = 04710, loss = 1.9184
2024-10-30 15:35:11: [2024-10-30 15:35:11] iter = 04720, loss = 1.9750
2024-10-30 15:35:15: [2024-10-30 15:35:15] iter = 04730, loss = 2.2265
2024-10-30 15:35:19: [2024-10-30 15:35:19] iter = 04740, loss = 1.9477
2024-10-30 15:35:22: [2024-10-30 15:35:22] iter = 04750, loss = 3.1566
2024-10-30 15:35:25: [2024-10-30 15:35:25] iter = 04760, loss = 3.0390
2024-10-30 15:35:28: [2024-10-30 15:35:28] iter = 04770, loss = 2.0328
2024-10-30 15:35:32: [2024-10-30 15:35:32] iter = 04780, loss = 2.0338
2024-10-30 15:35:35: [2024-10-30 15:35:35] iter = 04790, loss = 2.0082
2024-10-30 15:35:38: [2024-10-30 15:35:38] iter = 04800, loss = 2.0159
2024-10-30 15:35:42: [2024-10-30 15:35:42] iter = 04810, loss = 3.4630
2024-10-30 15:35:45: [2024-10-30 15:35:45] iter = 04820, loss = 2.0687
2024-10-30 15:35:49: [2024-10-30 15:35:49] iter = 04830, loss = 4.1191
2024-10-30 15:35:53: [2024-10-30 15:35:53] iter = 04840, loss = 2.1640
2024-10-30 15:35:56: [2024-10-30 15:35:56] iter = 04850, loss = 3.0421
2024-10-30 15:36:00: [2024-10-30 15:36:00] iter = 04860, loss = 2.1444
2024-10-30 15:36:03: [2024-10-30 15:36:03] iter = 04870, loss = 2.0081
2024-10-30 15:36:07: [2024-10-30 15:36:07] iter = 04880, loss = 2.3440
2024-10-30 15:36:10: [2024-10-30 15:36:10] iter = 04890, loss = 3.1321
2024-10-30 15:36:13: [2024-10-30 15:36:13] iter = 04900, loss = 1.7019
2024-10-30 15:36:16: [2024-10-30 15:36:16] iter = 04910, loss = 2.2694
2024-10-30 15:36:18: [2024-10-30 15:36:18] iter = 04920, loss = 1.7662
2024-10-30 15:36:21: [2024-10-30 15:36:21] iter = 04930, loss = 1.9816
2024-10-30 15:36:24: [2024-10-30 15:36:24] iter = 04940, loss = 2.1034
2024-10-30 15:36:29: [2024-10-30 15:36:29] iter = 04950, loss = 2.4149
2024-10-30 15:36:33: [2024-10-30 15:36:33] iter = 04960, loss = 1.8671
2024-10-30 15:36:37: [2024-10-30 15:36:37] iter = 04970, loss = 1.8393
2024-10-30 15:36:41: [2024-10-30 15:36:41] iter = 04980, loss = 2.1137
2024-10-30 15:36:45: [2024-10-30 15:36:45] iter = 04990, loss = 2.7140
2024-10-30 15:36:49: [2024-10-30 15:36:49] iter = 05000, loss = 1.8417
2024-10-30 15:36:52: [2024-10-30 15:36:52] iter = 05010, loss = 2.0312
2024-10-30 15:36:55: [2024-10-30 15:36:55] iter = 05020, loss = 1.9318
2024-10-30 15:36:59: [2024-10-30 15:36:59] iter = 05030, loss = 2.4264
2024-10-30 15:37:02: [2024-10-30 15:37:02] iter = 05040, loss = 1.9098
2024-10-30 15:37:06: [2024-10-30 15:37:06] iter = 05050, loss = 1.7831
2024-10-30 15:37:09: [2024-10-30 15:37:09] iter = 05060, loss = 2.0193
2024-10-30 15:37:13: [2024-10-30 15:37:13] iter = 05070, loss = 1.8181
2024-10-30 15:37:17: [2024-10-30 15:37:17] iter = 05080, loss = 1.7195
2024-10-30 15:37:22: [2024-10-30 15:37:22] iter = 05090, loss = 1.7053
2024-10-30 15:37:26: [2024-10-30 15:37:26] iter = 05100, loss = 1.7242
2024-10-30 15:37:30: [2024-10-30 15:37:30] iter = 05110, loss = 2.0133
2024-10-30 15:37:33: [2024-10-30 15:37:33] iter = 05120, loss = 6.4549
2024-10-30 15:37:37: [2024-10-30 15:37:37] iter = 05130, loss = 2.3438
2024-10-30 15:37:40: [2024-10-30 15:37:40] iter = 05140, loss = 1.9561
2024-10-30 15:37:43: [2024-10-30 15:37:43] iter = 05150, loss = 1.6505
2024-10-30 15:37:47: [2024-10-30 15:37:47] iter = 05160, loss = 4.7140
2024-10-30 15:37:51: [2024-10-30 15:37:51] iter = 05170, loss = 1.9197
2024-10-30 15:37:53: [2024-10-30 15:37:53] iter = 05180, loss = 1.8604
2024-10-30 15:37:56: [2024-10-30 15:37:56] iter = 05190, loss = 2.2232
2024-10-30 15:37:59: [2024-10-30 15:37:59] iter = 05200, loss = 1.9578
2024-10-30 15:38:03: [2024-10-30 15:38:03] iter = 05210, loss = 2.1339
2024-10-30 15:38:06: [2024-10-30 15:38:06] iter = 05220, loss = 2.1061
2024-10-30 15:38:10: [2024-10-30 15:38:10] iter = 05230, loss = 3.0686
2024-10-30 15:38:13: [2024-10-30 15:38:13] iter = 05240, loss = 2.1054
2024-10-30 15:38:17: [2024-10-30 15:38:17] iter = 05250, loss = 1.8560
2024-10-30 15:38:21: [2024-10-30 15:38:21] iter = 05260, loss = 2.1979
2024-10-30 15:38:25: [2024-10-30 15:38:25] iter = 05270, loss = 2.4971
2024-10-30 15:38:29: [2024-10-30 15:38:29] iter = 05280, loss = 2.4096
2024-10-30 15:38:33: [2024-10-30 15:38:33] iter = 05290, loss = 1.8251
2024-10-30 15:38:36: [2024-10-30 15:38:36] iter = 05300, loss = 2.0979
2024-10-30 15:38:40: [2024-10-30 15:38:40] iter = 05310, loss = 2.0449
2024-10-30 15:38:44: [2024-10-30 15:38:44] iter = 05320, loss = 3.3250
2024-10-30 15:38:47: [2024-10-30 15:38:47] iter = 05330, loss = 1.8813
2024-10-30 15:38:51: [2024-10-30 15:38:51] iter = 05340, loss = 2.3728
2024-10-30 15:38:54: [2024-10-30 15:38:54] iter = 05350, loss = 3.3826
2024-10-30 15:38:57: [2024-10-30 15:38:57] iter = 05360, loss = 2.3978
2024-10-30 15:39:01: [2024-10-30 15:39:01] iter = 05370, loss = 1.8809
2024-10-30 15:39:04: [2024-10-30 15:39:04] iter = 05380, loss = 2.0393
2024-10-30 15:39:07: [2024-10-30 15:39:07] iter = 05390, loss = 2.3522
2024-10-30 15:39:10: [2024-10-30 15:39:10] iter = 05400, loss = 2.8108
2024-10-30 15:39:13: [2024-10-30 15:39:13] iter = 05410, loss = 1.8820
2024-10-30 15:39:16: [2024-10-30 15:39:16] iter = 05420, loss = 2.7232
2024-10-30 15:39:20: [2024-10-30 15:39:20] iter = 05430, loss = 1.8469
2024-10-30 15:39:24: [2024-10-30 15:39:24] iter = 05440, loss = 2.0885
2024-10-30 15:39:28: [2024-10-30 15:39:28] iter = 05450, loss = 2.7547
2024-10-30 15:39:32: [2024-10-30 15:39:32] iter = 05460, loss = 1.8144
2024-10-30 15:39:36: [2024-10-30 15:39:36] iter = 05470, loss = 1.9477
2024-10-30 15:39:40: [2024-10-30 15:39:40] iter = 05480, loss = 2.0869
2024-10-30 15:39:43: [2024-10-30 15:39:43] iter = 05490, loss = 2.1296
2024-10-30 15:39:47: [2024-10-30 15:39:47] iter = 05500, loss = 2.6566
2024-10-30 15:39:51: [2024-10-30 15:39:51] iter = 05510, loss = 4.6868
2024-10-30 15:39:54: [2024-10-30 15:39:54] iter = 05520, loss = 1.6322
2024-10-30 15:39:57: [2024-10-30 15:39:57] iter = 05530, loss = 1.9341
2024-10-30 15:40:01: [2024-10-30 15:40:01] iter = 05540, loss = 3.4051
2024-10-30 15:40:04: [2024-10-30 15:40:04] iter = 05550, loss = 1.6182
2024-10-30 15:40:08: [2024-10-30 15:40:08] iter = 05560, loss = 2.5141
2024-10-30 15:40:12: [2024-10-30 15:40:12] iter = 05570, loss = 2.5361
2024-10-30 15:40:16: [2024-10-30 15:40:16] iter = 05580, loss = 2.7322
2024-10-30 15:40:19: [2024-10-30 15:40:19] iter = 05590, loss = 1.7172
2024-10-30 15:40:23: [2024-10-30 15:40:22] iter = 05600, loss = 3.4811
2024-10-30 15:40:25: [2024-10-30 15:40:25] iter = 05610, loss = 2.7726
2024-10-30 15:40:28: [2024-10-30 15:40:28] iter = 05620, loss = 1.9536
2024-10-30 15:40:31: [2024-10-30 15:40:31] iter = 05630, loss = 2.1520
2024-10-30 15:40:34: [2024-10-30 15:40:34] iter = 05640, loss = 2.0840
2024-10-30 15:40:38: [2024-10-30 15:40:38] iter = 05650, loss = 1.7387
2024-10-30 15:40:41: [2024-10-30 15:40:41] iter = 05660, loss = 2.1692
2024-10-30 15:40:45: [2024-10-30 15:40:45] iter = 05670, loss = 2.3297
2024-10-30 15:40:48: [2024-10-30 15:40:48] iter = 05680, loss = 3.5885
2024-10-30 15:40:51: [2024-10-30 15:40:51] iter = 05690, loss = 2.3772
2024-10-30 15:40:54: [2024-10-30 15:40:54] iter = 05700, loss = 2.1737
2024-10-30 15:40:57: [2024-10-30 15:40:57] iter = 05710, loss = 1.9100
2024-10-30 15:41:01: [2024-10-30 15:41:01] iter = 05720, loss = 1.8682
2024-10-30 15:41:05: [2024-10-30 15:41:05] iter = 05730, loss = 1.8056
2024-10-30 15:41:09: [2024-10-30 15:41:09] iter = 05740, loss = 2.5527
2024-10-30 15:41:13: [2024-10-30 15:41:13] iter = 05750, loss = 1.9120
2024-10-30 15:41:17: [2024-10-30 15:41:17] iter = 05760, loss = 2.2018
2024-10-30 15:41:20: [2024-10-30 15:41:20] iter = 05770, loss = 2.3324
2024-10-30 15:41:24: [2024-10-30 15:41:24] iter = 05780, loss = 2.1254
2024-10-30 15:41:28: [2024-10-30 15:41:28] iter = 05790, loss = 1.9563
2024-10-30 15:41:32: [2024-10-30 15:41:32] iter = 05800, loss = 2.3165
2024-10-30 15:41:36: [2024-10-30 15:41:36] iter = 05810, loss = 1.9983
2024-10-30 15:41:39: [2024-10-30 15:41:39] iter = 05820, loss = 2.1318
2024-10-30 15:41:43: [2024-10-30 15:41:43] iter = 05830, loss = 2.0795
2024-10-30 15:41:47: [2024-10-30 15:41:47] iter = 05840, loss = 2.0981
2024-10-30 15:41:50: [2024-10-30 15:41:50] iter = 05850, loss = 2.5962
2024-10-30 15:41:53: [2024-10-30 15:41:53] iter = 05860, loss = 2.0275
2024-10-30 15:41:57: [2024-10-30 15:41:57] iter = 05870, loss = 1.8832
2024-10-30 15:42:00: [2024-10-30 15:42:00] iter = 05880, loss = 1.8910
2024-10-30 15:42:04: [2024-10-30 15:42:04] iter = 05890, loss = 2.5071
2024-10-30 15:42:08: [2024-10-30 15:42:08] iter = 05900, loss = 2.0830
2024-10-30 15:42:12: [2024-10-30 15:42:12] iter = 05910, loss = 1.7619
2024-10-30 15:42:16: [2024-10-30 15:42:16] iter = 05920, loss = 2.6513
2024-10-30 15:42:20: [2024-10-30 15:42:20] iter = 05930, loss = 2.3195
2024-10-30 15:42:24: [2024-10-30 15:42:24] iter = 05940, loss = 1.8399
2024-10-30 15:42:27: [2024-10-30 15:42:27] iter = 05950, loss = 3.4414
2024-10-30 15:42:30: [2024-10-30 15:42:30] iter = 05960, loss = 1.7949
2024-10-30 15:42:34: [2024-10-30 15:42:34] iter = 05970, loss = 1.8243
2024-10-30 15:42:38: [2024-10-30 15:42:38] iter = 05980, loss = 1.8630
2024-10-30 15:42:42: [2024-10-30 15:42:42] iter = 05990, loss = 3.3645
2024-10-30 15:42:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 15:42:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:42:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 65495}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:01: Evaluate 5 random ConvNet, ACCmean = 0.7816 ACCstd = 0.0026
-------------------------
2024-10-30 15:45:01: Evaluate 5 random ConvNet, SENmean = 0.7778 SENstd = 0.0019
-------------------------
2024-10-30 15:45:01: Evaluate 5 random ConvNet, SPEmean = 0.9780 SPEstd = 0.0002
-------------------------
2024-10-30 15:45:01: Evaluate 5 random ConvNet, F!mean = 0.7690 F!std = 0.0030
-------------------------
2024-10-30 15:45:01: Evaluate 5 random ConvNet, mean = 0.7816 std = 0.0026
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:01: [2024-10-30 15:45:01] iter = 06000, loss = 2.0852
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:05: [2024-10-30 15:45:05] iter = 06010, loss = 1.8560
2024-10-30 15:45:08: [2024-10-30 15:45:08] iter = 06020, loss = 1.8785
2024-10-30 15:45:11: [2024-10-30 15:45:11] iter = 06030, loss = 2.3139
2024-10-30 15:45:15: [2024-10-30 15:45:15] iter = 06040, loss = 1.9419
2024-10-30 15:45:19: [2024-10-30 15:45:19] iter = 06050, loss = 1.9235
2024-10-30 15:45:22: [2024-10-30 15:45:22] iter = 06060, loss = 1.7331
2024-10-30 15:45:25: [2024-10-30 15:45:25] iter = 06070, loss = 1.5373
2024-10-30 15:45:28: [2024-10-30 15:45:28] iter = 06080, loss = 2.3584
2024-10-30 15:45:31: [2024-10-30 15:45:31] iter = 06090, loss = 1.6028
2024-10-30 15:45:35: [2024-10-30 15:45:35] iter = 06100, loss = 2.4350
2024-10-30 15:45:39: [2024-10-30 15:45:39] iter = 06110, loss = 1.8104
2024-10-30 15:45:43: [2024-10-30 15:45:43] iter = 06120, loss = 1.9033
2024-10-30 15:45:46: [2024-10-30 15:45:46] iter = 06130, loss = 1.9374
2024-10-30 15:45:50: [2024-10-30 15:45:50] iter = 06140, loss = 2.4118
2024-10-30 15:45:55: [2024-10-30 15:45:55] iter = 06150, loss = 2.6811
2024-10-30 15:45:58: [2024-10-30 15:45:58] iter = 06160, loss = 2.5922
2024-10-30 15:46:02: [2024-10-30 15:46:02] iter = 06170, loss = 3.4011
2024-10-30 15:46:04: [2024-10-30 15:46:04] iter = 06180, loss = 2.1545
2024-10-30 15:46:08: [2024-10-30 15:46:08] iter = 06190, loss = 1.7943
2024-10-30 15:46:11: [2024-10-30 15:46:11] iter = 06200, loss = 1.8926
2024-10-30 15:46:13: [2024-10-30 15:46:13] iter = 06210, loss = 3.0989
2024-10-30 15:46:16: [2024-10-30 15:46:16] iter = 06220, loss = 2.0056
2024-10-30 15:46:20: [2024-10-30 15:46:20] iter = 06230, loss = 1.5838
2024-10-30 15:46:24: [2024-10-30 15:46:24] iter = 06240, loss = 4.6710
2024-10-30 15:46:27: [2024-10-30 15:46:27] iter = 06250, loss = 2.5097
2024-10-30 15:46:32: [2024-10-30 15:46:32] iter = 06260, loss = 2.2590
2024-10-30 15:46:35: [2024-10-30 15:46:35] iter = 06270, loss = 2.1682
2024-10-30 15:46:39: [2024-10-30 15:46:39] iter = 06280, loss = 2.1114
2024-10-30 15:46:42: [2024-10-30 15:46:42] iter = 06290, loss = 2.1519
2024-10-30 15:46:45: [2024-10-30 15:46:45] iter = 06300, loss = 2.0571
2024-10-30 15:46:49: [2024-10-30 15:46:49] iter = 06310, loss = 2.8964
2024-10-30 15:46:53: [2024-10-30 15:46:53] iter = 06320, loss = 2.4527
2024-10-30 15:46:57: [2024-10-30 15:46:57] iter = 06330, loss = 1.8687
2024-10-30 15:47:00: [2024-10-30 15:47:00] iter = 06340, loss = 2.3270
2024-10-30 15:47:04: [2024-10-30 15:47:04] iter = 06350, loss = 1.8781
2024-10-30 15:47:07: [2024-10-30 15:47:07] iter = 06360, loss = 1.9311
2024-10-30 15:47:11: [2024-10-30 15:47:11] iter = 06370, loss = 1.6717
2024-10-30 15:47:14: [2024-10-30 15:47:14] iter = 06380, loss = 1.7770
2024-10-30 15:47:18: [2024-10-30 15:47:18] iter = 06390, loss = 2.1500
2024-10-30 15:47:22: [2024-10-30 15:47:22] iter = 06400, loss = 1.9129
2024-10-30 15:47:27: [2024-10-30 15:47:27] iter = 06410, loss = 2.7847
2024-10-30 15:47:31: [2024-10-30 15:47:31] iter = 06420, loss = 1.7860
2024-10-30 15:47:35: [2024-10-30 15:47:35] iter = 06430, loss = 1.7349
2024-10-30 15:47:40: [2024-10-30 15:47:40] iter = 06440, loss = 1.5915
2024-10-30 15:47:44: [2024-10-30 15:47:44] iter = 06450, loss = 2.2716
2024-10-30 15:47:49: [2024-10-30 15:47:49] iter = 06460, loss = 1.9042
2024-10-30 15:47:53: [2024-10-30 15:47:53] iter = 06470, loss = 1.9719
2024-10-30 15:47:58: [2024-10-30 15:47:58] iter = 06480, loss = 2.7184
2024-10-30 15:48:02: [2024-10-30 15:48:02] iter = 06490, loss = 2.0159
2024-10-30 15:48:06: [2024-10-30 15:48:06] iter = 06500, loss = 2.2926
2024-10-30 15:48:11: [2024-10-30 15:48:11] iter = 06510, loss = 2.9294
2024-10-30 15:48:14: [2024-10-30 15:48:14] iter = 06520, loss = 2.2237
2024-10-30 15:48:18: [2024-10-30 15:48:18] iter = 06530, loss = 2.4850
2024-10-30 15:48:21: [2024-10-30 15:48:21] iter = 06540, loss = 2.4883
2024-10-30 15:48:25: [2024-10-30 15:48:25] iter = 06550, loss = 3.3438
2024-10-30 15:48:31: [2024-10-30 15:48:31] iter = 06560, loss = 1.8509
2024-10-30 15:48:35: [2024-10-30 15:48:35] iter = 06570, loss = 2.0810
2024-10-30 15:48:39: [2024-10-30 15:48:39] iter = 06580, loss = 2.0433
2024-10-30 15:48:44: [2024-10-30 15:48:44] iter = 06590, loss = 2.8827
2024-10-30 15:48:49: [2024-10-30 15:48:49] iter = 06600, loss = 2.6302
2024-10-30 15:48:53: [2024-10-30 15:48:53] iter = 06610, loss = 2.2941
2024-10-30 15:48:57: [2024-10-30 15:48:57] iter = 06620, loss = 2.1509
2024-10-30 15:49:01: [2024-10-30 15:49:01] iter = 06630, loss = 1.8360
2024-10-30 15:49:04: [2024-10-30 15:49:04] iter = 06640, loss = 1.8802
2024-10-30 15:49:07: [2024-10-30 15:49:07] iter = 06650, loss = 1.9812
2024-10-30 15:49:12: [2024-10-30 15:49:12] iter = 06660, loss = 2.1602
2024-10-30 15:49:16: [2024-10-30 15:49:16] iter = 06670, loss = 2.2094
2024-10-30 15:49:20: [2024-10-30 15:49:20] iter = 06680, loss = 1.9139
2024-10-30 15:49:24: [2024-10-30 15:49:24] iter = 06690, loss = 1.8565
2024-10-30 15:49:28: [2024-10-30 15:49:28] iter = 06700, loss = 2.2542
2024-10-30 15:49:31: [2024-10-30 15:49:31] iter = 06710, loss = 2.0355
2024-10-30 15:49:36: [2024-10-30 15:49:36] iter = 06720, loss = 2.1331
2024-10-30 15:49:40: [2024-10-30 15:49:40] iter = 06730, loss = 2.8125
2024-10-30 15:49:43: [2024-10-30 15:49:43] iter = 06740, loss = 2.1159
2024-10-30 15:49:48: [2024-10-30 15:49:48] iter = 06750, loss = 3.0433
2024-10-30 15:49:51: [2024-10-30 15:49:51] iter = 06760, loss = 3.2592
2024-10-30 15:49:56: [2024-10-30 15:49:56] iter = 06770, loss = 2.0022
2024-10-30 15:50:01: [2024-10-30 15:50:01] iter = 06780, loss = 1.7824
2024-10-30 15:50:06: [2024-10-30 15:50:06] iter = 06790, loss = 2.2976
2024-10-30 15:50:10: [2024-10-30 15:50:10] iter = 06800, loss = 1.9621
2024-10-30 15:50:13: [2024-10-30 15:50:13] iter = 06810, loss = 2.9318
2024-10-30 15:50:18: [2024-10-30 15:50:18] iter = 06820, loss = 1.8582
2024-10-30 15:50:21: [2024-10-30 15:50:21] iter = 06830, loss = 2.0167
2024-10-30 15:50:25: [2024-10-30 15:50:25] iter = 06840, loss = 1.6918
2024-10-30 15:50:29: [2024-10-30 15:50:29] iter = 06850, loss = 2.1090
2024-10-30 15:50:33: [2024-10-30 15:50:33] iter = 06860, loss = 3.9992
2024-10-30 15:50:38: [2024-10-30 15:50:38] iter = 06870, loss = 1.9168
2024-10-30 15:50:41: [2024-10-30 15:50:41] iter = 06880, loss = 2.2076
2024-10-30 15:50:45: [2024-10-30 15:50:45] iter = 06890, loss = 1.8853
2024-10-30 15:50:50: [2024-10-30 15:50:50] iter = 06900, loss = 1.7887
2024-10-30 15:50:53: [2024-10-30 15:50:53] iter = 06910, loss = 1.7749
2024-10-30 15:50:57: [2024-10-30 15:50:57] iter = 06920, loss = 1.7747
2024-10-30 15:51:00: [2024-10-30 15:51:00] iter = 06930, loss = 1.7544
2024-10-30 15:51:04: [2024-10-30 15:51:04] iter = 06940, loss = 2.6299
2024-10-30 15:51:07: [2024-10-30 15:51:07] iter = 06950, loss = 2.0293
2024-10-30 15:51:11: [2024-10-30 15:51:11] iter = 06960, loss = 2.3674
2024-10-30 15:51:14: [2024-10-30 15:51:14] iter = 06970, loss = 2.3984
2024-10-30 15:51:18: [2024-10-30 15:51:18] iter = 06980, loss = 2.5532
2024-10-30 15:51:22: [2024-10-30 15:51:22] iter = 06990, loss = 1.9397
2024-10-30 15:51:24: [2024-10-30 15:51:24] iter = 07000, loss = 1.7983
2024-10-30 15:51:27: [2024-10-30 15:51:27] iter = 07010, loss = 2.1810
2024-10-30 15:51:30: [2024-10-30 15:51:30] iter = 07020, loss = 2.1748
2024-10-30 15:51:33: [2024-10-30 15:51:33] iter = 07030, loss = 1.8431
2024-10-30 15:51:36: [2024-10-30 15:51:36] iter = 07040, loss = 2.0017
2024-10-30 15:51:39: [2024-10-30 15:51:39] iter = 07050, loss = 1.8895
2024-10-30 15:51:43: [2024-10-30 15:51:43] iter = 07060, loss = 2.1065
2024-10-30 15:51:47: [2024-10-30 15:51:47] iter = 07070, loss = 2.2924
2024-10-30 15:51:50: [2024-10-30 15:51:50] iter = 07080, loss = 2.3813
2024-10-30 15:51:53: [2024-10-30 15:51:53] iter = 07090, loss = 2.6670
2024-10-30 15:51:56: [2024-10-30 15:51:56] iter = 07100, loss = 2.5541
2024-10-30 15:52:00: [2024-10-30 15:52:00] iter = 07110, loss = 1.9363
2024-10-30 15:52:04: [2024-10-30 15:52:04] iter = 07120, loss = 2.9576
2024-10-30 15:52:07: [2024-10-30 15:52:07] iter = 07130, loss = 1.9575
2024-10-30 15:52:10: [2024-10-30 15:52:10] iter = 07140, loss = 2.6752
2024-10-30 15:52:14: [2024-10-30 15:52:14] iter = 07150, loss = 2.0329
2024-10-30 15:52:16: [2024-10-30 15:52:16] iter = 07160, loss = 2.6579
2024-10-30 15:52:20: [2024-10-30 15:52:19] iter = 07170, loss = 3.3268
2024-10-30 15:52:23: [2024-10-30 15:52:23] iter = 07180, loss = 2.2585
2024-10-30 15:52:26: [2024-10-30 15:52:26] iter = 07190, loss = 2.8799
2024-10-30 15:52:29: [2024-10-30 15:52:29] iter = 07200, loss = 1.5405
2024-10-30 15:52:32: [2024-10-30 15:52:32] iter = 07210, loss = 1.8682
2024-10-30 15:52:36: [2024-10-30 15:52:36] iter = 07220, loss = 1.8155
2024-10-30 15:52:40: [2024-10-30 15:52:40] iter = 07230, loss = 1.9169
2024-10-30 15:52:43: [2024-10-30 15:52:43] iter = 07240, loss = 1.9754
2024-10-30 15:52:47: [2024-10-30 15:52:47] iter = 07250, loss = 2.8392
2024-10-30 15:52:50: [2024-10-30 15:52:50] iter = 07260, loss = 2.2547
2024-10-30 15:52:54: [2024-10-30 15:52:54] iter = 07270, loss = 1.8153
2024-10-30 15:52:58: [2024-10-30 15:52:58] iter = 07280, loss = 1.5352
2024-10-30 15:53:01: [2024-10-30 15:53:01] iter = 07290, loss = 2.0159
2024-10-30 15:53:05: [2024-10-30 15:53:05] iter = 07300, loss = 2.1933
2024-10-30 15:53:09: [2024-10-30 15:53:09] iter = 07310, loss = 2.7163
2024-10-30 15:53:12: [2024-10-30 15:53:12] iter = 07320, loss = 4.6514
2024-10-30 15:53:16: [2024-10-30 15:53:16] iter = 07330, loss = 3.4295
2024-10-30 15:53:20: [2024-10-30 15:53:20] iter = 07340, loss = 1.7575
2024-10-30 15:53:24: [2024-10-30 15:53:24] iter = 07350, loss = 1.8158
2024-10-30 15:53:27: [2024-10-30 15:53:27] iter = 07360, loss = 3.0725
2024-10-30 15:53:31: [2024-10-30 15:53:31] iter = 07370, loss = 2.2325
2024-10-30 15:53:35: [2024-10-30 15:53:35] iter = 07380, loss = 2.7287
2024-10-30 15:53:39: [2024-10-30 15:53:39] iter = 07390, loss = 2.5037
2024-10-30 15:53:44: [2024-10-30 15:53:44] iter = 07400, loss = 1.5881
2024-10-30 15:53:47: [2024-10-30 15:53:47] iter = 07410, loss = 1.8168
2024-10-30 15:53:51: [2024-10-30 15:53:51] iter = 07420, loss = 5.1734
2024-10-30 15:53:55: [2024-10-30 15:53:55] iter = 07430, loss = 1.8863
2024-10-30 15:53:59: [2024-10-30 15:53:59] iter = 07440, loss = 1.9858
2024-10-30 15:54:03: [2024-10-30 15:54:03] iter = 07450, loss = 2.2361
2024-10-30 15:54:07: [2024-10-30 15:54:07] iter = 07460, loss = 2.3414
2024-10-30 15:54:11: [2024-10-30 15:54:11] iter = 07470, loss = 3.4108
2024-10-30 15:54:14: [2024-10-30 15:54:14] iter = 07480, loss = 1.9923
2024-10-30 15:54:17: [2024-10-30 15:54:17] iter = 07490, loss = 1.9615
2024-10-30 15:54:21: [2024-10-30 15:54:21] iter = 07500, loss = 2.1190
2024-10-30 15:54:26: [2024-10-30 15:54:26] iter = 07510, loss = 1.9121
2024-10-30 15:54:29: [2024-10-30 15:54:29] iter = 07520, loss = 2.3455
2024-10-30 15:54:33: [2024-10-30 15:54:33] iter = 07530, loss = 1.8881
2024-10-30 15:54:36: [2024-10-30 15:54:36] iter = 07540, loss = 2.0548
2024-10-30 15:54:40: [2024-10-30 15:54:40] iter = 07550, loss = 1.7455
2024-10-30 15:54:44: [2024-10-30 15:54:44] iter = 07560, loss = 2.6807
2024-10-30 15:54:48: [2024-10-30 15:54:48] iter = 07570, loss = 2.7420
2024-10-30 15:54:52: [2024-10-30 15:54:52] iter = 07580, loss = 2.5103
2024-10-30 15:54:57: [2024-10-30 15:54:57] iter = 07590, loss = 2.1322
2024-10-30 15:55:00: [2024-10-30 15:55:00] iter = 07600, loss = 2.2862
2024-10-30 15:55:04: [2024-10-30 15:55:04] iter = 07610, loss = 1.7956
2024-10-30 15:55:07: [2024-10-30 15:55:07] iter = 07620, loss = 1.9149
2024-10-30 15:55:11: [2024-10-30 15:55:11] iter = 07630, loss = 2.1807
2024-10-30 15:55:14: [2024-10-30 15:55:14] iter = 07640, loss = 2.0851
2024-10-30 15:55:19: [2024-10-30 15:55:19] iter = 07650, loss = 1.8342
2024-10-30 15:55:23: [2024-10-30 15:55:23] iter = 07660, loss = 1.7390
2024-10-30 15:55:27: [2024-10-30 15:55:27] iter = 07670, loss = 1.7139
2024-10-30 15:55:31: [2024-10-30 15:55:31] iter = 07680, loss = 3.9815
2024-10-30 15:55:35: [2024-10-30 15:55:35] iter = 07690, loss = 1.6632
2024-10-30 15:55:38: [2024-10-30 15:55:38] iter = 07700, loss = 1.7729
2024-10-30 15:55:42: [2024-10-30 15:55:42] iter = 07710, loss = 1.6752
2024-10-30 15:55:45: [2024-10-30 15:55:45] iter = 07720, loss = 1.9117
2024-10-30 15:55:49: [2024-10-30 15:55:49] iter = 07730, loss = 1.8800
2024-10-30 15:55:53: [2024-10-30 15:55:53] iter = 07740, loss = 1.5796
2024-10-30 15:55:56: [2024-10-30 15:55:56] iter = 07750, loss = 2.2849
2024-10-30 15:56:00: [2024-10-30 15:56:00] iter = 07760, loss = 2.2330
2024-10-30 15:56:05: [2024-10-30 15:56:05] iter = 07770, loss = 2.2909
2024-10-30 15:56:09: [2024-10-30 15:56:09] iter = 07780, loss = 1.6598
2024-10-30 15:56:13: [2024-10-30 15:56:13] iter = 07790, loss = 2.5539
2024-10-30 15:56:17: [2024-10-30 15:56:17] iter = 07800, loss = 2.4971
2024-10-30 15:56:21: [2024-10-30 15:56:21] iter = 07810, loss = 1.6707
2024-10-30 15:56:25: [2024-10-30 15:56:25] iter = 07820, loss = 2.1312
2024-10-30 15:56:29: [2024-10-30 15:56:29] iter = 07830, loss = 1.7889
2024-10-30 15:56:33: [2024-10-30 15:56:33] iter = 07840, loss = 1.6222
2024-10-30 15:56:38: [2024-10-30 15:56:38] iter = 07850, loss = 1.8217
2024-10-30 15:56:41: [2024-10-30 15:56:41] iter = 07860, loss = 2.6340
2024-10-30 15:56:45: [2024-10-30 15:56:45] iter = 07870, loss = 1.7254
2024-10-30 15:56:49: [2024-10-30 15:56:49] iter = 07880, loss = 3.0674
2024-10-30 15:56:52: [2024-10-30 15:56:52] iter = 07890, loss = 1.7833
2024-10-30 15:56:56: [2024-10-30 15:56:56] iter = 07900, loss = 2.0627
2024-10-30 15:57:00: [2024-10-30 15:57:00] iter = 07910, loss = 1.8968
2024-10-30 15:57:04: [2024-10-30 15:57:04] iter = 07920, loss = 1.8035
2024-10-30 15:57:08: [2024-10-30 15:57:08] iter = 07930, loss = 2.9502
2024-10-30 15:57:12: [2024-10-30 15:57:12] iter = 07940, loss = 2.0734
2024-10-30 15:57:15: [2024-10-30 15:57:15] iter = 07950, loss = 1.7744
2024-10-30 15:57:18: [2024-10-30 15:57:18] iter = 07960, loss = 2.1264
2024-10-30 15:57:22: [2024-10-30 15:57:22] iter = 07970, loss = 2.2804
2024-10-30 15:57:26: [2024-10-30 15:57:26] iter = 07980, loss = 1.9528
2024-10-30 15:57:29: [2024-10-30 15:57:29] iter = 07990, loss = 3.5610
2024-10-30 15:57:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 15:57:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:57:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53004}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:59:59: Evaluate 5 random ConvNet, ACCmean = 0.7883 ACCstd = 0.0046
-------------------------
2024-10-30 15:59:59: Evaluate 5 random ConvNet, SENmean = 0.7802 SENstd = 0.0037
-------------------------
2024-10-30 15:59:59: Evaluate 5 random ConvNet, SPEmean = 0.9786 SPEstd = 0.0004
-------------------------
2024-10-30 15:59:59: Evaluate 5 random ConvNet, F!mean = 0.7728 F!std = 0.0044
-------------------------
2024-10-30 15:59:59: Evaluate 5 random ConvNet, mean = 0.7883 std = 0.0046
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:59:59: [2024-10-30 15:59:59] iter = 08000, loss = 2.0408
2024-10-30 16:00:02: [2024-10-30 16:00:02] iter = 08010, loss = 1.7904
2024-10-30 16:00:04: [2024-10-30 16:00:04] iter = 08020, loss = 2.6406
2024-10-30 16:00:07: [2024-10-30 16:00:07] iter = 08030, loss = 2.0699
2024-10-30 16:00:10: [2024-10-30 16:00:10] iter = 08040, loss = 2.6434
2024-10-30 16:00:14: [2024-10-30 16:00:14] iter = 08050, loss = 2.0316
2024-10-30 16:00:17: [2024-10-30 16:00:17] iter = 08060, loss = 1.9294
2024-10-30 16:00:20: [2024-10-30 16:00:20] iter = 08070, loss = 2.0192
2024-10-30 16:00:23: [2024-10-30 16:00:23] iter = 08080, loss = 2.5592
2024-10-30 16:00:27: [2024-10-30 16:00:27] iter = 08090, loss = 2.6409
2024-10-30 16:00:30: [2024-10-30 16:00:30] iter = 08100, loss = 2.0591
2024-10-30 16:00:34: [2024-10-30 16:00:34] iter = 08110, loss = 1.9597
2024-10-30 16:00:38: [2024-10-30 16:00:38] iter = 08120, loss = 2.4215
2024-10-30 16:00:42: [2024-10-30 16:00:42] iter = 08130, loss = 2.2053
2024-10-30 16:00:46: [2024-10-30 16:00:46] iter = 08140, loss = 1.9563
2024-10-30 16:00:49: [2024-10-30 16:00:49] iter = 08150, loss = 2.2004
2024-10-30 16:00:53: [2024-10-30 16:00:53] iter = 08160, loss = 3.9315
2024-10-30 16:00:57: [2024-10-30 16:00:57] iter = 08170, loss = 2.2959
2024-10-30 16:01:01: [2024-10-30 16:01:01] iter = 08180, loss = 3.9442
2024-10-30 16:01:06: [2024-10-30 16:01:06] iter = 08190, loss = 4.4790
2024-10-30 16:01:10: [2024-10-30 16:01:10] iter = 08200, loss = 2.3780
2024-10-30 16:01:14: [2024-10-30 16:01:14] iter = 08210, loss = 2.6644
2024-10-30 16:01:17: [2024-10-30 16:01:17] iter = 08220, loss = 1.9447
2024-10-30 16:01:20: [2024-10-30 16:01:20] iter = 08230, loss = 2.7396
2024-10-30 16:01:23: [2024-10-30 16:01:23] iter = 08240, loss = 1.7899
2024-10-30 16:01:26: [2024-10-30 16:01:26] iter = 08250, loss = 2.0330
2024-10-30 16:01:30: [2024-10-30 16:01:30] iter = 08260, loss = 1.7399
2024-10-30 16:01:33: [2024-10-30 16:01:33] iter = 08270, loss = 2.1970
2024-10-30 16:01:36: [2024-10-30 16:01:36] iter = 08280, loss = 1.9948
2024-10-30 16:01:40: [2024-10-30 16:01:40] iter = 08290, loss = 1.7002
2024-10-30 16:01:43: [2024-10-30 16:01:43] iter = 08300, loss = 2.2782
2024-10-30 16:01:47: [2024-10-30 16:01:47] iter = 08310, loss = 1.7522
2024-10-30 16:01:51: [2024-10-30 16:01:51] iter = 08320, loss = 1.9939
2024-10-30 16:01:55: [2024-10-30 16:01:55] iter = 08330, loss = 2.3828
2024-10-30 16:01:58: [2024-10-30 16:01:58] iter = 08340, loss = 2.8948
2024-10-30 16:02:02: [2024-10-30 16:02:02] iter = 08350, loss = 2.1762
2024-10-30 16:02:06: [2024-10-30 16:02:06] iter = 08360, loss = 2.6096
2024-10-30 16:02:10: [2024-10-30 16:02:10] iter = 08370, loss = 2.4682
2024-10-30 16:02:13: [2024-10-30 16:02:13] iter = 08380, loss = 2.1701
2024-10-30 16:02:17: [2024-10-30 16:02:17] iter = 08390, loss = 2.0440
2024-10-30 16:02:21: [2024-10-30 16:02:20] iter = 08400, loss = 2.5759
2024-10-30 16:02:24: [2024-10-30 16:02:24] iter = 08410, loss = 1.8508
2024-10-30 16:02:28: [2024-10-30 16:02:28] iter = 08420, loss = 3.1326
2024-10-30 16:02:32: [2024-10-30 16:02:32] iter = 08430, loss = 1.9447
2024-10-30 16:02:36: [2024-10-30 16:02:36] iter = 08440, loss = 1.8916
2024-10-30 16:02:39: [2024-10-30 16:02:39] iter = 08450, loss = 2.4959
2024-10-30 16:02:42: [2024-10-30 16:02:42] iter = 08460, loss = 1.8114
2024-10-30 16:02:45: [2024-10-30 16:02:45] iter = 08470, loss = 1.8319
2024-10-30 16:02:50: [2024-10-30 16:02:49] iter = 08480, loss = 2.1331
2024-10-30 16:02:54: [2024-10-30 16:02:54] iter = 08490, loss = 2.8763
2024-10-30 16:02:58: [2024-10-30 16:02:58] iter = 08500, loss = 2.9575
2024-10-30 16:03:02: [2024-10-30 16:03:02] iter = 08510, loss = 2.4295
2024-10-30 16:03:06: [2024-10-30 16:03:06] iter = 08520, loss = 2.0489
2024-10-30 16:03:10: [2024-10-30 16:03:10] iter = 08530, loss = 2.7167
2024-10-30 16:03:13: [2024-10-30 16:03:13] iter = 08540, loss = 3.9318
2024-10-30 16:03:17: [2024-10-30 16:03:17] iter = 08550, loss = 1.8888
2024-10-30 16:03:21: [2024-10-30 16:03:21] iter = 08560, loss = 1.7915
2024-10-30 16:03:26: [2024-10-30 16:03:26] iter = 08570, loss = 2.6945
2024-10-30 16:03:30: [2024-10-30 16:03:30] iter = 08580, loss = 2.2751
2024-10-30 16:03:33: [2024-10-30 16:03:33] iter = 08590, loss = 2.3585
2024-10-30 16:03:37: [2024-10-30 16:03:37] iter = 08600, loss = 2.6007
2024-10-30 16:03:41: [2024-10-30 16:03:41] iter = 08610, loss = 1.8207
2024-10-30 16:03:45: [2024-10-30 16:03:45] iter = 08620, loss = 1.8495
2024-10-30 16:03:49: [2024-10-30 16:03:49] iter = 08630, loss = 1.9753
2024-10-30 16:03:54: [2024-10-30 16:03:54] iter = 08640, loss = 2.0482
2024-10-30 16:03:59: [2024-10-30 16:03:59] iter = 08650, loss = 3.2051
2024-10-30 16:04:02: [2024-10-30 16:04:02] iter = 08660, loss = 2.4480
2024-10-30 16:04:06: [2024-10-30 16:04:06] iter = 08670, loss = 2.8681
2024-10-30 16:04:10: [2024-10-30 16:04:10] iter = 08680, loss = 2.0553
2024-10-30 16:04:13: [2024-10-30 16:04:13] iter = 08690, loss = 1.8147
2024-10-30 16:04:16: [2024-10-30 16:04:16] iter = 08700, loss = 2.1767
2024-10-30 16:04:19: [2024-10-30 16:04:19] iter = 08710, loss = 2.2681
2024-10-30 16:04:22: [2024-10-30 16:04:22] iter = 08720, loss = 1.9758
2024-10-30 16:04:26: [2024-10-30 16:04:26] iter = 08730, loss = 1.7522
2024-10-30 16:04:31: [2024-10-30 16:04:31] iter = 08740, loss = 1.6060
2024-10-30 16:04:35: [2024-10-30 16:04:35] iter = 08750, loss = 1.9721
2024-10-30 16:04:40: [2024-10-30 16:04:40] iter = 08760, loss = 1.8145
2024-10-30 16:04:44: [2024-10-30 16:04:44] iter = 08770, loss = 2.0270
2024-10-30 16:04:46: [2024-10-30 16:04:46] iter = 08780, loss = 2.0320
2024-10-30 16:04:49: [2024-10-30 16:04:49] iter = 08790, loss = 2.0266
2024-10-30 16:04:53: [2024-10-30 16:04:53] iter = 08800, loss = 1.8663
2024-10-30 16:04:57: [2024-10-30 16:04:57] iter = 08810, loss = 1.9263
2024-10-30 16:05:02: [2024-10-30 16:05:02] iter = 08820, loss = 1.9262
2024-10-30 16:05:05: [2024-10-30 16:05:05] iter = 08830, loss = 2.2809
2024-10-30 16:05:08: [2024-10-30 16:05:08] iter = 08840, loss = 1.7544
2024-10-30 16:05:11: [2024-10-30 16:05:11] iter = 08850, loss = 1.4444
2024-10-30 16:05:14: [2024-10-30 16:05:14] iter = 08860, loss = 4.7904
2024-10-30 16:05:18: [2024-10-30 16:05:18] iter = 08870, loss = 3.6243
2024-10-30 16:05:21: [2024-10-30 16:05:21] iter = 08880, loss = 2.2288
2024-10-30 16:05:25: [2024-10-30 16:05:25] iter = 08890, loss = 2.4909
2024-10-30 16:05:28: [2024-10-30 16:05:28] iter = 08900, loss = 3.2198
2024-10-30 16:05:31: [2024-10-30 16:05:31] iter = 08910, loss = 2.0592
2024-10-30 16:05:34: [2024-10-30 16:05:34] iter = 08920, loss = 2.4686
2024-10-30 16:05:37: [2024-10-30 16:05:37] iter = 08930, loss = 2.7715
2024-10-30 16:05:40: [2024-10-30 16:05:40] iter = 08940, loss = 2.0591
2024-10-30 16:05:44: [2024-10-30 16:05:44] iter = 08950, loss = 2.5394
2024-10-30 16:05:48: [2024-10-30 16:05:48] iter = 08960, loss = 2.1731
2024-10-30 16:05:52: [2024-10-30 16:05:52] iter = 08970, loss = 2.5327
2024-10-30 16:05:55: [2024-10-30 16:05:55] iter = 08980, loss = 1.9166
2024-10-30 16:05:59: [2024-10-30 16:05:59] iter = 08990, loss = 2.2418
2024-10-30 16:06:02: [2024-10-30 16:06:02] iter = 09000, loss = 3.2151
2024-10-30 16:06:05: [2024-10-30 16:06:05] iter = 09010, loss = 1.8484
2024-10-30 16:06:08: [2024-10-30 16:06:08] iter = 09020, loss = 2.6763
2024-10-30 16:06:12: [2024-10-30 16:06:12] iter = 09030, loss = 2.0421
2024-10-30 16:06:15: [2024-10-30 16:06:15] iter = 09040, loss = 1.6556
2024-10-30 16:06:17: [2024-10-30 16:06:17] iter = 09050, loss = 1.8743
2024-10-30 16:06:20: [2024-10-30 16:06:20] iter = 09060, loss = 1.7716
2024-10-30 16:06:24: [2024-10-30 16:06:24] iter = 09070, loss = 2.3183
2024-10-30 16:06:28: [2024-10-30 16:06:28] iter = 09080, loss = 2.0901
2024-10-30 16:06:32: [2024-10-30 16:06:32] iter = 09090, loss = 2.0211
2024-10-30 16:06:35: [2024-10-30 16:06:35] iter = 09100, loss = 2.1155
2024-10-30 16:06:38: [2024-10-30 16:06:38] iter = 09110, loss = 1.7509
2024-10-30 16:06:42: [2024-10-30 16:06:42] iter = 09120, loss = 2.3598
2024-10-30 16:06:45: [2024-10-30 16:06:45] iter = 09130, loss = 2.0076
2024-10-30 16:06:49: [2024-10-30 16:06:49] iter = 09140, loss = 2.2520
2024-10-30 16:06:53: [2024-10-30 16:06:53] iter = 09150, loss = 2.0531
2024-10-30 16:06:56: [2024-10-30 16:06:56] iter = 09160, loss = 2.0890
2024-10-30 16:06:59: [2024-10-30 16:06:59] iter = 09170, loss = 1.7788
2024-10-30 16:07:04: [2024-10-30 16:07:04] iter = 09180, loss = 1.8142
2024-10-30 16:07:07: [2024-10-30 16:07:07] iter = 09190, loss = 2.0716
2024-10-30 16:07:11: [2024-10-30 16:07:11] iter = 09200, loss = 1.8834
2024-10-30 16:07:15: [2024-10-30 16:07:15] iter = 09210, loss = 2.0052
2024-10-30 16:07:18: [2024-10-30 16:07:18] iter = 09220, loss = 1.7863
2024-10-30 16:07:22: [2024-10-30 16:07:22] iter = 09230, loss = 2.1126
2024-10-30 16:07:25: [2024-10-30 16:07:25] iter = 09240, loss = 2.0535
2024-10-30 16:07:28: [2024-10-30 16:07:28] iter = 09250, loss = 1.8106
2024-10-30 16:07:32: [2024-10-30 16:07:32] iter = 09260, loss = 1.9070
2024-10-30 16:07:36: [2024-10-30 16:07:36] iter = 09270, loss = 2.1259
2024-10-30 16:07:39: [2024-10-30 16:07:39] iter = 09280, loss = 2.1242
2024-10-30 16:07:42: [2024-10-30 16:07:42] iter = 09290, loss = 1.8055
2024-10-30 16:07:45: [2024-10-30 16:07:45] iter = 09300, loss = 3.3960
2024-10-30 16:07:48: [2024-10-30 16:07:48] iter = 09310, loss = 2.3001
2024-10-30 16:07:53: [2024-10-30 16:07:53] iter = 09320, loss = 1.7316
2024-10-30 16:07:56: [2024-10-30 16:07:56] iter = 09330, loss = 1.8406
2024-10-30 16:08:00: [2024-10-30 16:08:00] iter = 09340, loss = 1.9953
2024-10-30 16:08:03: [2024-10-30 16:08:03] iter = 09350, loss = 2.1354
2024-10-30 16:08:07: [2024-10-30 16:08:07] iter = 09360, loss = 2.0543
2024-10-30 16:08:11: [2024-10-30 16:08:11] iter = 09370, loss = 1.8163
2024-10-30 16:08:14: [2024-10-30 16:08:14] iter = 09380, loss = 1.9364
2024-10-30 16:08:18: [2024-10-30 16:08:18] iter = 09390, loss = 1.9525
2024-10-30 16:08:21: [2024-10-30 16:08:21] iter = 09400, loss = 2.1518
2024-10-30 16:08:24: [2024-10-30 16:08:24] iter = 09410, loss = 2.0540
2024-10-30 16:08:28: [2024-10-30 16:08:28] iter = 09420, loss = 3.1832
2024-10-30 16:08:31: [2024-10-30 16:08:31] iter = 09430, loss = 3.5249
2024-10-30 16:08:34: [2024-10-30 16:08:34] iter = 09440, loss = 2.6191
2024-10-30 16:08:37: [2024-10-30 16:08:37] iter = 09450, loss = 2.5554
2024-10-30 16:08:42: [2024-10-30 16:08:42] iter = 09460, loss = 1.8987
2024-10-30 16:08:45: [2024-10-30 16:08:45] iter = 09470, loss = 2.0899
2024-10-30 16:08:49: [2024-10-30 16:08:49] iter = 09480, loss = 1.5724
2024-10-30 16:08:52: [2024-10-30 16:08:52] iter = 09490, loss = 1.7777
2024-10-30 16:08:55: [2024-10-30 16:08:55] iter = 09500, loss = 3.4571
2024-10-30 16:08:59: [2024-10-30 16:08:59] iter = 09510, loss = 2.0151
2024-10-30 16:09:02: [2024-10-30 16:09:02] iter = 09520, loss = 2.0503
2024-10-30 16:09:05: [2024-10-30 16:09:05] iter = 09530, loss = 2.2444
2024-10-30 16:09:08: [2024-10-30 16:09:08] iter = 09540, loss = 2.0024
2024-10-30 16:09:12: [2024-10-30 16:09:12] iter = 09550, loss = 3.5127
2024-10-30 16:09:15: [2024-10-30 16:09:15] iter = 09560, loss = 2.1150
2024-10-30 16:09:19: [2024-10-30 16:09:19] iter = 09570, loss = 2.0802
2024-10-30 16:09:23: [2024-10-30 16:09:23] iter = 09580, loss = 1.6107
2024-10-30 16:09:26: [2024-10-30 16:09:26] iter = 09590, loss = 2.6497
2024-10-30 16:09:31: [2024-10-30 16:09:31] iter = 09600, loss = 2.3444
2024-10-30 16:09:36: [2024-10-30 16:09:36] iter = 09610, loss = 4.0068
2024-10-30 16:09:39: [2024-10-30 16:09:39] iter = 09620, loss = 2.0969
2024-10-30 16:09:42: [2024-10-30 16:09:42] iter = 09630, loss = 1.5158
2024-10-30 16:09:46: [2024-10-30 16:09:46] iter = 09640, loss = 1.5976
2024-10-30 16:09:50: [2024-10-30 16:09:50] iter = 09650, loss = 2.4902
2024-10-30 16:09:53: [2024-10-30 16:09:53] iter = 09660, loss = 1.8344
2024-10-30 16:09:56: [2024-10-30 16:09:56] iter = 09670, loss = 5.5741
2024-10-30 16:10:00: [2024-10-30 16:10:00] iter = 09680, loss = 2.2806
2024-10-30 16:10:03: [2024-10-30 16:10:03] iter = 09690, loss = 2.3426
2024-10-30 16:10:06: [2024-10-30 16:10:06] iter = 09700, loss = 2.3395
2024-10-30 16:10:10: [2024-10-30 16:10:10] iter = 09710, loss = 2.1011
2024-10-30 16:10:14: [2024-10-30 16:10:14] iter = 09720, loss = 2.2979
2024-10-30 16:10:17: [2024-10-30 16:10:17] iter = 09730, loss = 2.1169
2024-10-30 16:10:21: [2024-10-30 16:10:21] iter = 09740, loss = 1.7694
2024-10-30 16:10:24: [2024-10-30 16:10:24] iter = 09750, loss = 2.2259
2024-10-30 16:10:28: [2024-10-30 16:10:28] iter = 09760, loss = 2.6545
2024-10-30 16:10:33: [2024-10-30 16:10:33] iter = 09770, loss = 2.2513
2024-10-30 16:10:36: [2024-10-30 16:10:36] iter = 09780, loss = 2.1923
2024-10-30 16:10:38: [2024-10-30 16:10:38] iter = 09790, loss = 2.0099
2024-10-30 16:10:42: [2024-10-30 16:10:41] iter = 09800, loss = 1.9208
2024-10-30 16:10:44: [2024-10-30 16:10:44] iter = 09810, loss = 1.7869
2024-10-30 16:10:48: [2024-10-30 16:10:48] iter = 09820, loss = 2.2403
2024-10-30 16:10:51: [2024-10-30 16:10:51] iter = 09830, loss = 1.9995
2024-10-30 16:10:55: [2024-10-30 16:10:55] iter = 09840, loss = 2.0537
2024-10-30 16:10:58: [2024-10-30 16:10:58] iter = 09850, loss = 1.7338
2024-10-30 16:11:01: [2024-10-30 16:11:01] iter = 09860, loss = 2.4315
2024-10-30 16:11:04: [2024-10-30 16:11:04] iter = 09870, loss = 2.7167
2024-10-30 16:11:08: [2024-10-30 16:11:08] iter = 09880, loss = 2.6419
2024-10-30 16:11:12: [2024-10-30 16:11:12] iter = 09890, loss = 1.9577
2024-10-30 16:11:16: [2024-10-30 16:11:16] iter = 09900, loss = 2.0726
2024-10-30 16:11:20: [2024-10-30 16:11:20] iter = 09910, loss = 2.1853
2024-10-30 16:11:24: [2024-10-30 16:11:24] iter = 09920, loss = 1.7948
2024-10-30 16:11:29: [2024-10-30 16:11:29] iter = 09930, loss = 1.9812
2024-10-30 16:11:33: [2024-10-30 16:11:33] iter = 09940, loss = 2.5020
2024-10-30 16:11:36: [2024-10-30 16:11:36] iter = 09950, loss = 2.2980
2024-10-30 16:11:40: [2024-10-30 16:11:40] iter = 09960, loss = 1.7939
2024-10-30 16:11:42: [2024-10-30 16:11:42] iter = 09970, loss = 2.0780
2024-10-30 16:11:46: [2024-10-30 16:11:46] iter = 09980, loss = 1.8517
2024-10-30 16:11:49: [2024-10-30 16:11:49] iter = 09990, loss = 1.6518
2024-10-30 16:11:52: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 16:11:52: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:11:52: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 12603}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:14:19: Evaluate 5 random ConvNet, ACCmean = 0.7945 ACCstd = 0.0029
-------------------------
2024-10-30 16:14:19: Evaluate 5 random ConvNet, SENmean = 0.7856 SENstd = 0.0027
-------------------------
2024-10-30 16:14:19: Evaluate 5 random ConvNet, SPEmean = 0.9791 SPEstd = 0.0003
-------------------------
2024-10-30 16:14:19: Evaluate 5 random ConvNet, F!mean = 0.7798 F!std = 0.0029
-------------------------
2024-10-30 16:14:19: Evaluate 5 random ConvNet, mean = 0.7945 std = 0.0029
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:14:20: [2024-10-30 16:14:20] iter = 10000, loss = 1.7271
2024-10-30 16:14:24: [2024-10-30 16:14:24] iter = 10010, loss = 2.5779
2024-10-30 16:14:28: [2024-10-30 16:14:28] iter = 10020, loss = 1.9599
2024-10-30 16:14:31: [2024-10-30 16:14:31] iter = 10030, loss = 1.7945
2024-10-30 16:14:35: [2024-10-30 16:14:35] iter = 10040, loss = 2.0080
2024-10-30 16:14:40: [2024-10-30 16:14:40] iter = 10050, loss = 2.0452
2024-10-30 16:14:44: [2024-10-30 16:14:44] iter = 10060, loss = 2.4443
2024-10-30 16:14:47: [2024-10-30 16:14:47] iter = 10070, loss = 3.1882
2024-10-30 16:14:51: [2024-10-30 16:14:51] iter = 10080, loss = 2.9451
2024-10-30 16:14:53: [2024-10-30 16:14:53] iter = 10090, loss = 1.6356
2024-10-30 16:14:56: [2024-10-30 16:14:56] iter = 10100, loss = 2.0243
2024-10-30 16:15:00: [2024-10-30 16:15:00] iter = 10110, loss = 2.0344
2024-10-30 16:15:04: [2024-10-30 16:15:04] iter = 10120, loss = 2.1330
2024-10-30 16:15:07: [2024-10-30 16:15:07] iter = 10130, loss = 1.8798
2024-10-30 16:15:11: [2024-10-30 16:15:11] iter = 10140, loss = 2.3820
2024-10-30 16:15:14: [2024-10-30 16:15:14] iter = 10150, loss = 1.8416
2024-10-30 16:15:18: [2024-10-30 16:15:18] iter = 10160, loss = 1.7904
2024-10-30 16:15:22: [2024-10-30 16:15:22] iter = 10170, loss = 2.0432
2024-10-30 16:15:26: [2024-10-30 16:15:26] iter = 10180, loss = 1.9098
2024-10-30 16:15:30: [2024-10-30 16:15:30] iter = 10190, loss = 3.3961
2024-10-30 16:15:35: [2024-10-30 16:15:35] iter = 10200, loss = 2.1512
2024-10-30 16:15:39: [2024-10-30 16:15:39] iter = 10210, loss = 1.9983
2024-10-30 16:15:42: [2024-10-30 16:15:42] iter = 10220, loss = 3.1809
2024-10-30 16:15:47: [2024-10-30 16:15:47] iter = 10230, loss = 1.9746
2024-10-30 16:15:50: [2024-10-30 16:15:50] iter = 10240, loss = 1.9146
2024-10-30 16:15:54: [2024-10-30 16:15:54] iter = 10250, loss = 1.8899
2024-10-30 16:15:57: [2024-10-30 16:15:57] iter = 10260, loss = 2.0405
2024-10-30 16:16:00: [2024-10-30 16:16:00] iter = 10270, loss = 2.0998
2024-10-30 16:16:03: [2024-10-30 16:16:03] iter = 10280, loss = 2.5318
2024-10-30 16:16:06: [2024-10-30 16:16:06] iter = 10290, loss = 1.7482
2024-10-30 16:16:10: [2024-10-30 16:16:10] iter = 10300, loss = 1.8016
2024-10-30 16:16:13: [2024-10-30 16:16:13] iter = 10310, loss = 2.2058
2024-10-30 16:16:16: [2024-10-30 16:16:16] iter = 10320, loss = 1.9009
2024-10-30 16:16:19: [2024-10-30 16:16:19] iter = 10330, loss = 1.8442
2024-10-30 16:16:23: [2024-10-30 16:16:23] iter = 10340, loss = 2.0566
2024-10-30 16:16:28: [2024-10-30 16:16:28] iter = 10350, loss = 1.9474
2024-10-30 16:16:31: [2024-10-30 16:16:31] iter = 10360, loss = 2.0111
2024-10-30 16:16:35: [2024-10-30 16:16:35] iter = 10370, loss = 2.4689
2024-10-30 16:16:39: [2024-10-30 16:16:39] iter = 10380, loss = 2.3426
2024-10-30 16:16:43: [2024-10-30 16:16:43] iter = 10390, loss = 2.4388
2024-10-30 16:16:47: [2024-10-30 16:16:47] iter = 10400, loss = 1.7666
2024-10-30 16:16:50: [2024-10-30 16:16:50] iter = 10410, loss = 2.4687
2024-10-30 16:16:54: [2024-10-30 16:16:54] iter = 10420, loss = 4.2544
2024-10-30 16:16:59: [2024-10-30 16:16:59] iter = 10430, loss = 2.9526
2024-10-30 16:17:02: [2024-10-30 16:17:02] iter = 10440, loss = 2.0978
2024-10-30 16:17:06: [2024-10-30 16:17:06] iter = 10450, loss = 1.9694
2024-10-30 16:17:10: [2024-10-30 16:17:10] iter = 10460, loss = 2.1722
2024-10-30 16:17:13: [2024-10-30 16:17:13] iter = 10470, loss = 2.9155
2024-10-30 16:17:17: [2024-10-30 16:17:17] iter = 10480, loss = 2.7022
2024-10-30 16:17:20: [2024-10-30 16:17:20] iter = 10490, loss = 2.0673
2024-10-30 16:17:23: [2024-10-30 16:17:23] iter = 10500, loss = 1.5250
2024-10-30 16:17:26: [2024-10-30 16:17:26] iter = 10510, loss = 8.7320
2024-10-30 16:17:29: [2024-10-30 16:17:29] iter = 10520, loss = 2.2813
2024-10-30 16:17:32: [2024-10-30 16:17:32] iter = 10530, loss = 2.3517
2024-10-30 16:17:35: [2024-10-30 16:17:35] iter = 10540, loss = 1.5180
2024-10-30 16:17:39: [2024-10-30 16:17:39] iter = 10550, loss = 1.7731
2024-10-30 16:17:43: [2024-10-30 16:17:43] iter = 10560, loss = 2.1990
2024-10-30 16:17:46: [2024-10-30 16:17:46] iter = 10570, loss = 2.0363
2024-10-30 16:17:49: [2024-10-30 16:17:49] iter = 10580, loss = 2.7909
2024-10-30 16:17:53: [2024-10-30 16:17:53] iter = 10590, loss = 2.9153
2024-10-30 16:17:56: [2024-10-30 16:17:56] iter = 10600, loss = 2.8248
2024-10-30 16:18:00: [2024-10-30 16:18:00] iter = 10610, loss = 1.8002
2024-10-30 16:18:03: [2024-10-30 16:18:03] iter = 10620, loss = 1.8931
2024-10-30 16:18:07: [2024-10-30 16:18:07] iter = 10630, loss = 1.8285
2024-10-30 16:18:11: [2024-10-30 16:18:11] iter = 10640, loss = 2.4407
2024-10-30 16:18:15: [2024-10-30 16:18:15] iter = 10650, loss = 1.8919
2024-10-30 16:18:18: [2024-10-30 16:18:18] iter = 10660, loss = 1.5813
2024-10-30 16:18:22: [2024-10-30 16:18:22] iter = 10670, loss = 2.0155
2024-10-30 16:18:25: [2024-10-30 16:18:25] iter = 10680, loss = 3.3146
2024-10-30 16:18:29: [2024-10-30 16:18:29] iter = 10690, loss = 2.0434
2024-10-30 16:18:33: [2024-10-30 16:18:33] iter = 10700, loss = 1.7686
2024-10-30 16:18:37: [2024-10-30 16:18:37] iter = 10710, loss = 1.6528
2024-10-30 16:18:40: [2024-10-30 16:18:40] iter = 10720, loss = 2.1171
2024-10-30 16:18:44: [2024-10-30 16:18:44] iter = 10730, loss = 2.2353
2024-10-30 16:18:49: [2024-10-30 16:18:49] iter = 10740, loss = 1.9299
2024-10-30 16:18:53: [2024-10-30 16:18:53] iter = 10750, loss = 1.9084
2024-10-30 16:18:57: [2024-10-30 16:18:57] iter = 10760, loss = 2.9422
2024-10-30 16:19:01: [2024-10-30 16:19:01] iter = 10770, loss = 1.9348
2024-10-30 16:19:04: [2024-10-30 16:19:04] iter = 10780, loss = 2.1649
2024-10-30 16:19:09: [2024-10-30 16:19:09] iter = 10790, loss = 1.7598
2024-10-30 16:19:13: [2024-10-30 16:19:13] iter = 10800, loss = 3.8467
2024-10-30 16:19:17: [2024-10-30 16:19:17] iter = 10810, loss = 2.5057
2024-10-30 16:19:20: [2024-10-30 16:19:20] iter = 10820, loss = 2.0213
2024-10-30 16:19:24: [2024-10-30 16:19:24] iter = 10830, loss = 2.4337
2024-10-30 16:19:27: [2024-10-30 16:19:27] iter = 10840, loss = 2.5379
2024-10-30 16:19:31: [2024-10-30 16:19:31] iter = 10850, loss = 1.9316
2024-10-30 16:19:34: [2024-10-30 16:19:34] iter = 10860, loss = 2.8830
2024-10-30 16:19:38: [2024-10-30 16:19:38] iter = 10870, loss = 1.8818
2024-10-30 16:19:42: [2024-10-30 16:19:42] iter = 10880, loss = 2.0048
2024-10-30 16:19:45: [2024-10-30 16:19:45] iter = 10890, loss = 2.2605
2024-10-30 16:19:49: [2024-10-30 16:19:49] iter = 10900, loss = 2.1041
2024-10-30 16:19:53: [2024-10-30 16:19:53] iter = 10910, loss = 1.7932
2024-10-30 16:19:57: [2024-10-30 16:19:57] iter = 10920, loss = 2.5600
2024-10-30 16:20:01: [2024-10-30 16:20:01] iter = 10930, loss = 1.9568
2024-10-30 16:20:05: [2024-10-30 16:20:05] iter = 10940, loss = 1.8718
2024-10-30 16:20:08: [2024-10-30 16:20:08] iter = 10950, loss = 2.0986
2024-10-30 16:20:12: [2024-10-30 16:20:12] iter = 10960, loss = 2.2716
2024-10-30 16:20:16: [2024-10-30 16:20:16] iter = 10970, loss = 1.7715
2024-10-30 16:20:20: [2024-10-30 16:20:20] iter = 10980, loss = 2.6563
2024-10-30 16:20:23: [2024-10-30 16:20:23] iter = 10990, loss = 2.2635
2024-10-30 16:20:26: [2024-10-30 16:20:26] iter = 11000, loss = 1.9190
2024-10-30 16:20:31: [2024-10-30 16:20:31] iter = 11010, loss = 1.7374
2024-10-30 16:20:35: [2024-10-30 16:20:35] iter = 11020, loss = 1.9504
2024-10-30 16:20:39: [2024-10-30 16:20:39] iter = 11030, loss = 2.7259
2024-10-30 16:20:43: [2024-10-30 16:20:43] iter = 11040, loss = 2.0076
2024-10-30 16:20:46: [2024-10-30 16:20:46] iter = 11050, loss = 2.6791
2024-10-30 16:20:49: [2024-10-30 16:20:49] iter = 11060, loss = 2.2010
2024-10-30 16:20:53: [2024-10-30 16:20:53] iter = 11070, loss = 1.9161
2024-10-30 16:20:56: [2024-10-30 16:20:56] iter = 11080, loss = 2.8407
2024-10-30 16:21:01: [2024-10-30 16:21:01] iter = 11090, loss = 2.0640
2024-10-30 16:21:05: [2024-10-30 16:21:05] iter = 11100, loss = 2.8908
2024-10-30 16:21:10: [2024-10-30 16:21:10] iter = 11110, loss = 2.0886
2024-10-30 16:21:14: [2024-10-30 16:21:14] iter = 11120, loss = 1.7021
2024-10-30 16:21:18: [2024-10-30 16:21:18] iter = 11130, loss = 1.7506
2024-10-30 16:21:22: [2024-10-30 16:21:22] iter = 11140, loss = 1.5793
2024-10-30 16:21:26: [2024-10-30 16:21:26] iter = 11150, loss = 2.1701
2024-10-30 16:21:29: [2024-10-30 16:21:29] iter = 11160, loss = 2.2156
2024-10-30 16:21:33: [2024-10-30 16:21:33] iter = 11170, loss = 2.1986
2024-10-30 16:21:37: [2024-10-30 16:21:37] iter = 11180, loss = 2.5485
2024-10-30 16:21:41: [2024-10-30 16:21:41] iter = 11190, loss = 2.0236
2024-10-30 16:21:44: [2024-10-30 16:21:44] iter = 11200, loss = 1.8021
2024-10-30 16:21:47: [2024-10-30 16:21:47] iter = 11210, loss = 4.6203
2024-10-30 16:21:51: [2024-10-30 16:21:51] iter = 11220, loss = 2.4119
2024-10-30 16:21:54: [2024-10-30 16:21:54] iter = 11230, loss = 2.2151
2024-10-30 16:21:57: [2024-10-30 16:21:57] iter = 11240, loss = 2.8767
2024-10-30 16:22:01: [2024-10-30 16:22:01] iter = 11250, loss = 1.7118
2024-10-30 16:22:05: [2024-10-30 16:22:05] iter = 11260, loss = 2.2895
2024-10-30 16:22:09: [2024-10-30 16:22:09] iter = 11270, loss = 1.8707
2024-10-30 16:22:12: [2024-10-30 16:22:12] iter = 11280, loss = 2.1893
2024-10-30 16:22:17: [2024-10-30 16:22:17] iter = 11290, loss = 1.6282
2024-10-30 16:22:21: [2024-10-30 16:22:21] iter = 11300, loss = 2.0788
2024-10-30 16:22:24: [2024-10-30 16:22:24] iter = 11310, loss = 1.9569
2024-10-30 16:22:28: [2024-10-30 16:22:28] iter = 11320, loss = 1.8415
2024-10-30 16:22:32: [2024-10-30 16:22:32] iter = 11330, loss = 3.0376
2024-10-30 16:22:37: [2024-10-30 16:22:37] iter = 11340, loss = 1.8153
2024-10-30 16:22:41: [2024-10-30 16:22:41] iter = 11350, loss = 1.7224
2024-10-30 16:22:45: [2024-10-30 16:22:45] iter = 11360, loss = 1.7643
2024-10-30 16:22:48: [2024-10-30 16:22:48] iter = 11370, loss = 1.6719
2024-10-30 16:22:53: [2024-10-30 16:22:53] iter = 11380, loss = 2.3097
2024-10-30 16:22:56: [2024-10-30 16:22:56] iter = 11390, loss = 1.8227
2024-10-30 16:23:00: [2024-10-30 16:23:00] iter = 11400, loss = 2.0722
2024-10-30 16:23:03: [2024-10-30 16:23:03] iter = 11410, loss = 1.6969
2024-10-30 16:23:08: [2024-10-30 16:23:08] iter = 11420, loss = 1.9162
2024-10-30 16:23:10: [2024-10-30 16:23:10] iter = 11430, loss = 1.8563
2024-10-30 16:23:13: [2024-10-30 16:23:13] iter = 11440, loss = 1.9171
2024-10-30 16:23:17: [2024-10-30 16:23:17] iter = 11450, loss = 1.6631
2024-10-30 16:23:20: [2024-10-30 16:23:20] iter = 11460, loss = 1.9337
2024-10-30 16:23:24: [2024-10-30 16:23:24] iter = 11470, loss = 3.4323
2024-10-30 16:23:27: [2024-10-30 16:23:27] iter = 11480, loss = 1.5205
2024-10-30 16:23:29: [2024-10-30 16:23:29] iter = 11490, loss = 2.7009
2024-10-30 16:23:33: [2024-10-30 16:23:33] iter = 11500, loss = 3.5742
2024-10-30 16:23:38: [2024-10-30 16:23:38] iter = 11510, loss = 3.7960
2024-10-30 16:23:42: [2024-10-30 16:23:42] iter = 11520, loss = 2.7476
2024-10-30 16:23:46: [2024-10-30 16:23:46] iter = 11530, loss = 2.6301
2024-10-30 16:23:49: [2024-10-30 16:23:49] iter = 11540, loss = 2.0019
2024-10-30 16:23:54: [2024-10-30 16:23:54] iter = 11550, loss = 3.2146
2024-10-30 16:23:58: [2024-10-30 16:23:58] iter = 11560, loss = 1.8651
2024-10-30 16:24:01: [2024-10-30 16:24:01] iter = 11570, loss = 1.8968
2024-10-30 16:24:04: [2024-10-30 16:24:04] iter = 11580, loss = 1.8801
2024-10-30 16:24:08: [2024-10-30 16:24:08] iter = 11590, loss = 2.5423
2024-10-30 16:24:13: [2024-10-30 16:24:13] iter = 11600, loss = 1.8989
2024-10-30 16:24:17: [2024-10-30 16:24:17] iter = 11610, loss = 1.7948
2024-10-30 16:24:20: [2024-10-30 16:24:20] iter = 11620, loss = 2.6869
2024-10-30 16:24:24: [2024-10-30 16:24:24] iter = 11630, loss = 2.0693
2024-10-30 16:24:28: [2024-10-30 16:24:28] iter = 11640, loss = 1.9842
2024-10-30 16:24:32: [2024-10-30 16:24:32] iter = 11650, loss = 1.9217
2024-10-30 16:24:36: [2024-10-30 16:24:36] iter = 11660, loss = 2.0699
2024-10-30 16:24:40: [2024-10-30 16:24:40] iter = 11670, loss = 1.9648
2024-10-30 16:24:45: [2024-10-30 16:24:45] iter = 11680, loss = 3.0442
2024-10-30 16:24:49: [2024-10-30 16:24:49] iter = 11690, loss = 1.9502
2024-10-30 16:24:53: [2024-10-30 16:24:53] iter = 11700, loss = 2.5390
2024-10-30 16:24:57: [2024-10-30 16:24:57] iter = 11710, loss = 2.0525
2024-10-30 16:25:01: [2024-10-30 16:25:01] iter = 11720, loss = 2.5208
2024-10-30 16:25:04: [2024-10-30 16:25:04] iter = 11730, loss = 1.8881
2024-10-30 16:25:08: [2024-10-30 16:25:08] iter = 11740, loss = 2.1985
2024-10-30 16:25:11: [2024-10-30 16:25:11] iter = 11750, loss = 2.4774
2024-10-30 16:25:16: [2024-10-30 16:25:16] iter = 11760, loss = 1.5631
2024-10-30 16:25:20: [2024-10-30 16:25:20] iter = 11770, loss = 2.5402
2024-10-30 16:25:24: [2024-10-30 16:25:24] iter = 11780, loss = 1.9911
2024-10-30 16:25:28: [2024-10-30 16:25:28] iter = 11790, loss = 2.1384
2024-10-30 16:25:32: [2024-10-30 16:25:32] iter = 11800, loss = 2.0179
2024-10-30 16:25:35: [2024-10-30 16:25:35] iter = 11810, loss = 2.1210
2024-10-30 16:25:39: [2024-10-30 16:25:39] iter = 11820, loss = 2.7105
2024-10-30 16:25:43: [2024-10-30 16:25:43] iter = 11830, loss = 2.0621
2024-10-30 16:25:47: [2024-10-30 16:25:47] iter = 11840, loss = 1.9661
2024-10-30 16:25:52: [2024-10-30 16:25:52] iter = 11850, loss = 1.6328
2024-10-30 16:25:56: [2024-10-30 16:25:56] iter = 11860, loss = 3.5608
2024-10-30 16:26:00: [2024-10-30 16:26:00] iter = 11870, loss = 2.7841
2024-10-30 16:26:04: [2024-10-30 16:26:04] iter = 11880, loss = 2.0593
2024-10-30 16:26:08: [2024-10-30 16:26:08] iter = 11890, loss = 2.2185
2024-10-30 16:26:13: [2024-10-30 16:26:13] iter = 11900, loss = 2.7241
2024-10-30 16:26:17: [2024-10-30 16:26:17] iter = 11910, loss = 5.4845
2024-10-30 16:26:21: [2024-10-30 16:26:21] iter = 11920, loss = 2.1909
2024-10-30 16:26:24: [2024-10-30 16:26:24] iter = 11930, loss = 2.4445
2024-10-30 16:26:28: [2024-10-30 16:26:28] iter = 11940, loss = 2.2208
2024-10-30 16:26:32: [2024-10-30 16:26:32] iter = 11950, loss = 1.8073
2024-10-30 16:26:36: [2024-10-30 16:26:36] iter = 11960, loss = 2.6320
2024-10-30 16:26:39: [2024-10-30 16:26:39] iter = 11970, loss = 1.9365
2024-10-30 16:26:43: [2024-10-30 16:26:43] iter = 11980, loss = 2.5199
2024-10-30 16:26:47: [2024-10-30 16:26:47] iter = 11990, loss = 2.0009
2024-10-30 16:26:51: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 16:26:51: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:26:51: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 11899}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:29:25: Evaluate 5 random ConvNet, ACCmean = 0.7858 ACCstd = 0.0049
-------------------------
2024-10-30 16:29:25: Evaluate 5 random ConvNet, SENmean = 0.7793 SENstd = 0.0036
-------------------------
2024-10-30 16:29:25: Evaluate 5 random ConvNet, SPEmean = 0.9783 SPEstd = 0.0005
-------------------------
2024-10-30 16:29:25: Evaluate 5 random ConvNet, F!mean = 0.7722 F!std = 0.0055
-------------------------
2024-10-30 16:29:25: Evaluate 5 random ConvNet, mean = 0.7858 std = 0.0049
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:29:26: [2024-10-30 16:29:26] iter = 12000, loss = 2.3334
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:29:29: [2024-10-30 16:29:29] iter = 12010, loss = 1.8547
2024-10-30 16:29:34: [2024-10-30 16:29:34] iter = 12020, loss = 1.8489
2024-10-30 16:29:37: [2024-10-30 16:29:37] iter = 12030, loss = 1.9290
2024-10-30 16:29:41: [2024-10-30 16:29:41] iter = 12040, loss = 1.9169
2024-10-30 16:29:45: [2024-10-30 16:29:45] iter = 12050, loss = 2.9845
2024-10-30 16:29:50: [2024-10-30 16:29:50] iter = 12060, loss = 2.2237
2024-10-30 16:29:54: [2024-10-30 16:29:54] iter = 12070, loss = 2.3540
2024-10-30 16:29:58: [2024-10-30 16:29:58] iter = 12080, loss = 2.7688
2024-10-30 16:30:03: [2024-10-30 16:30:03] iter = 12090, loss = 2.7451
2024-10-30 16:30:07: [2024-10-30 16:30:07] iter = 12100, loss = 1.8852
2024-10-30 16:30:12: [2024-10-30 16:30:12] iter = 12110, loss = 1.9846
2024-10-30 16:30:16: [2024-10-30 16:30:16] iter = 12120, loss = 1.9694
2024-10-30 16:30:20: [2024-10-30 16:30:20] iter = 12130, loss = 1.7275
2024-10-30 16:30:25: [2024-10-30 16:30:25] iter = 12140, loss = 3.6176
2024-10-30 16:30:29: [2024-10-30 16:30:29] iter = 12150, loss = 1.8816
2024-10-30 16:30:34: [2024-10-30 16:30:34] iter = 12160, loss = 1.8057
2024-10-30 16:30:37: [2024-10-30 16:30:37] iter = 12170, loss = 1.9761
2024-10-30 16:30:40: [2024-10-30 16:30:40] iter = 12180, loss = 2.9476
2024-10-30 16:30:44: [2024-10-30 16:30:44] iter = 12190, loss = 1.8788
2024-10-30 16:30:48: [2024-10-30 16:30:48] iter = 12200, loss = 1.9507
2024-10-30 16:30:53: [2024-10-30 16:30:52] iter = 12210, loss = 2.1159
2024-10-30 16:30:57: [2024-10-30 16:30:57] iter = 12220, loss = 2.0833
2024-10-30 16:31:01: [2024-10-30 16:31:01] iter = 12230, loss = 3.1299
2024-10-30 16:31:05: [2024-10-30 16:31:05] iter = 12240, loss = 3.2573
2024-10-30 16:31:10: [2024-10-30 16:31:10] iter = 12250, loss = 1.8045
2024-10-30 16:31:13: [2024-10-30 16:31:13] iter = 12260, loss = 1.9664
2024-10-30 16:31:17: [2024-10-30 16:31:17] iter = 12270, loss = 4.1587
2024-10-30 16:31:20: [2024-10-30 16:31:20] iter = 12280, loss = 1.8350
2024-10-30 16:31:24: [2024-10-30 16:31:24] iter = 12290, loss = 2.1996
2024-10-30 16:31:28: [2024-10-30 16:31:28] iter = 12300, loss = 1.9899
2024-10-30 16:31:31: [2024-10-30 16:31:31] iter = 12310, loss = 1.9412
2024-10-30 16:31:36: [2024-10-30 16:31:36] iter = 12320, loss = 2.1695
2024-10-30 16:31:40: [2024-10-30 16:31:40] iter = 12330, loss = 1.7093
2024-10-30 16:31:44: [2024-10-30 16:31:44] iter = 12340, loss = 1.8630
2024-10-30 16:31:47: [2024-10-30 16:31:47] iter = 12350, loss = 3.1166
2024-10-30 16:31:51: [2024-10-30 16:31:51] iter = 12360, loss = 2.1649
2024-10-30 16:31:55: [2024-10-30 16:31:55] iter = 12370, loss = 2.0325
2024-10-30 16:31:59: [2024-10-30 16:31:59] iter = 12380, loss = 1.9344
2024-10-30 16:32:03: [2024-10-30 16:32:03] iter = 12390, loss = 1.9111
2024-10-30 16:32:07: [2024-10-30 16:32:07] iter = 12400, loss = 1.9785
2024-10-30 16:32:11: [2024-10-30 16:32:11] iter = 12410, loss = 1.8439
2024-10-30 16:32:15: [2024-10-30 16:32:15] iter = 12420, loss = 2.9318
2024-10-30 16:32:20: [2024-10-30 16:32:20] iter = 12430, loss = 2.5988
2024-10-30 16:32:24: [2024-10-30 16:32:24] iter = 12440, loss = 2.2782
2024-10-30 16:32:28: [2024-10-30 16:32:28] iter = 12450, loss = 1.7846
2024-10-30 16:32:32: [2024-10-30 16:32:32] iter = 12460, loss = 2.1769
2024-10-30 16:32:37: [2024-10-30 16:32:37] iter = 12470, loss = 2.3344
2024-10-30 16:32:41: [2024-10-30 16:32:41] iter = 12480, loss = 2.0183
2024-10-30 16:32:44: [2024-10-30 16:32:44] iter = 12490, loss = 2.0876
2024-10-30 16:32:47: [2024-10-30 16:32:47] iter = 12500, loss = 2.7413
2024-10-30 16:32:51: [2024-10-30 16:32:51] iter = 12510, loss = 2.1287
2024-10-30 16:32:54: [2024-10-30 16:32:54] iter = 12520, loss = 2.9603
2024-10-30 16:32:58: [2024-10-30 16:32:58] iter = 12530, loss = 2.5451
2024-10-30 16:33:02: [2024-10-30 16:33:02] iter = 12540, loss = 1.6051
2024-10-30 16:33:06: [2024-10-30 16:33:06] iter = 12550, loss = 1.7758
2024-10-30 16:33:09: [2024-10-30 16:33:09] iter = 12560, loss = 2.6284
2024-10-30 16:33:13: [2024-10-30 16:33:13] iter = 12570, loss = 2.4721
2024-10-30 16:33:17: [2024-10-30 16:33:17] iter = 12580, loss = 1.8343
2024-10-30 16:33:20: [2024-10-30 16:33:20] iter = 12590, loss = 1.7194
2024-10-30 16:33:25: [2024-10-30 16:33:25] iter = 12600, loss = 2.0985
2024-10-30 16:33:28: [2024-10-30 16:33:28] iter = 12610, loss = 3.0011
2024-10-30 16:33:32: [2024-10-30 16:33:31] iter = 12620, loss = 2.1212
2024-10-30 16:33:35: [2024-10-30 16:33:35] iter = 12630, loss = 1.7442
2024-10-30 16:33:39: [2024-10-30 16:33:39] iter = 12640, loss = 3.5842
2024-10-30 16:33:44: [2024-10-30 16:33:44] iter = 12650, loss = 3.0348
2024-10-30 16:33:48: [2024-10-30 16:33:48] iter = 12660, loss = 1.9893
2024-10-30 16:33:53: [2024-10-30 16:33:53] iter = 12670, loss = 1.8154
2024-10-30 16:33:57: [2024-10-30 16:33:57] iter = 12680, loss = 2.1252
2024-10-30 16:34:01: [2024-10-30 16:34:01] iter = 12690, loss = 2.4928
2024-10-30 16:34:05: [2024-10-30 16:34:05] iter = 12700, loss = 1.8699
2024-10-30 16:34:10: [2024-10-30 16:34:10] iter = 12710, loss = 1.8981
2024-10-30 16:34:14: [2024-10-30 16:34:14] iter = 12720, loss = 1.7826
2024-10-30 16:34:19: [2024-10-30 16:34:19] iter = 12730, loss = 1.7624
2024-10-30 16:34:23: [2024-10-30 16:34:23] iter = 12740, loss = 2.6419
2024-10-30 16:34:26: [2024-10-30 16:34:26] iter = 12750, loss = 2.6076
2024-10-30 16:34:30: [2024-10-30 16:34:30] iter = 12760, loss = 3.0149
2024-10-30 16:34:35: [2024-10-30 16:34:35] iter = 12770, loss = 2.3177
2024-10-30 16:34:40: [2024-10-30 16:34:40] iter = 12780, loss = 2.6137
2024-10-30 16:34:44: [2024-10-30 16:34:44] iter = 12790, loss = 1.9235
2024-10-30 16:34:47: [2024-10-30 16:34:47] iter = 12800, loss = 2.0401
2024-10-30 16:34:51: [2024-10-30 16:34:51] iter = 12810, loss = 2.1815
2024-10-30 16:34:54: [2024-10-30 16:34:54] iter = 12820, loss = 1.9446
2024-10-30 16:34:58: [2024-10-30 16:34:58] iter = 12830, loss = 2.2445
2024-10-30 16:35:03: [2024-10-30 16:35:03] iter = 12840, loss = 2.5003
2024-10-30 16:35:07: [2024-10-30 16:35:07] iter = 12850, loss = 2.2203
2024-10-30 16:35:12: [2024-10-30 16:35:12] iter = 12860, loss = 8.0355
2024-10-30 16:35:16: [2024-10-30 16:35:16] iter = 12870, loss = 2.0317
2024-10-30 16:35:20: [2024-10-30 16:35:20] iter = 12880, loss = 2.9997
2024-10-30 16:35:24: [2024-10-30 16:35:24] iter = 12890, loss = 1.8876
2024-10-30 16:35:28: [2024-10-30 16:35:28] iter = 12900, loss = 2.1477
2024-10-30 16:35:31: [2024-10-30 16:35:31] iter = 12910, loss = 2.1379
2024-10-30 16:35:35: [2024-10-30 16:35:35] iter = 12920, loss = 2.1648
2024-10-30 16:35:40: [2024-10-30 16:35:40] iter = 12930, loss = 1.7479
2024-10-30 16:35:44: [2024-10-30 16:35:44] iter = 12940, loss = 2.3987
2024-10-30 16:35:48: [2024-10-30 16:35:48] iter = 12950, loss = 2.5048
2024-10-30 16:35:52: [2024-10-30 16:35:52] iter = 12960, loss = 1.7599
2024-10-30 16:35:56: [2024-10-30 16:35:56] iter = 12970, loss = 2.6015
2024-10-30 16:36:00: [2024-10-30 16:36:00] iter = 12980, loss = 1.9103
2024-10-30 16:36:04: [2024-10-30 16:36:04] iter = 12990, loss = 2.0507
2024-10-30 16:36:08: [2024-10-30 16:36:08] iter = 13000, loss = 1.9711
2024-10-30 16:36:13: [2024-10-30 16:36:13] iter = 13010, loss = 2.2525
2024-10-30 16:36:18: [2024-10-30 16:36:17] iter = 13020, loss = 2.6708
2024-10-30 16:36:21: [2024-10-30 16:36:21] iter = 13030, loss = 2.3627
2024-10-30 16:36:26: [2024-10-30 16:36:26] iter = 13040, loss = 5.9719
2024-10-30 16:36:30: [2024-10-30 16:36:30] iter = 13050, loss = 2.1500
2024-10-30 16:36:34: [2024-10-30 16:36:34] iter = 13060, loss = 2.0887
2024-10-30 16:36:38: [2024-10-30 16:36:38] iter = 13070, loss = 2.1631
2024-10-30 16:36:42: [2024-10-30 16:36:42] iter = 13080, loss = 1.7575
2024-10-30 16:36:46: [2024-10-30 16:36:46] iter = 13090, loss = 2.5690
2024-10-30 16:36:49: [2024-10-30 16:36:49] iter = 13100, loss = 2.0588
2024-10-30 16:36:51: [2024-10-30 16:36:51] iter = 13110, loss = 2.5984
2024-10-30 16:36:55: [2024-10-30 16:36:55] iter = 13120, loss = 1.9827
2024-10-30 16:36:59: [2024-10-30 16:36:59] iter = 13130, loss = 2.4104
2024-10-30 16:37:04: [2024-10-30 16:37:04] iter = 13140, loss = 1.7053
2024-10-30 16:37:09: [2024-10-30 16:37:09] iter = 13150, loss = 2.1210
2024-10-30 16:37:14: [2024-10-30 16:37:14] iter = 13160, loss = 1.8375
2024-10-30 16:37:19: [2024-10-30 16:37:19] iter = 13170, loss = 1.9339
2024-10-30 16:37:24: [2024-10-30 16:37:24] iter = 13180, loss = 2.0539
2024-10-30 16:37:28: [2024-10-30 16:37:28] iter = 13190, loss = 3.1315
2024-10-30 16:37:32: [2024-10-30 16:37:32] iter = 13200, loss = 1.7966
2024-10-30 16:37:36: [2024-10-30 16:37:36] iter = 13210, loss = 1.9975
2024-10-30 16:37:41: [2024-10-30 16:37:41] iter = 13220, loss = 1.8470
2024-10-30 16:37:45: [2024-10-30 16:37:45] iter = 13230, loss = 2.4966
2024-10-30 16:37:50: [2024-10-30 16:37:50] iter = 13240, loss = 1.8698
2024-10-30 16:37:54: [2024-10-30 16:37:54] iter = 13250, loss = 2.1893
2024-10-30 16:37:57: [2024-10-30 16:37:57] iter = 13260, loss = 2.0771
2024-10-30 16:38:00: [2024-10-30 16:38:00] iter = 13270, loss = 2.5943
2024-10-30 16:38:04: [2024-10-30 16:38:04] iter = 13280, loss = 1.7232
2024-10-30 16:38:08: [2024-10-30 16:38:08] iter = 13290, loss = 2.4124
2024-10-30 16:38:12: [2024-10-30 16:38:12] iter = 13300, loss = 3.3318
2024-10-30 16:38:15: [2024-10-30 16:38:15] iter = 13310, loss = 1.7006
2024-10-30 16:38:19: [2024-10-30 16:38:19] iter = 13320, loss = 1.8875
2024-10-30 16:38:25: [2024-10-30 16:38:25] iter = 13330, loss = 4.4836
2024-10-30 16:38:29: [2024-10-30 16:38:29] iter = 13340, loss = 2.1959
2024-10-30 16:38:33: [2024-10-30 16:38:33] iter = 13350, loss = 1.8685
2024-10-30 16:38:36: [2024-10-30 16:38:36] iter = 13360, loss = 3.5451
2024-10-30 16:38:40: [2024-10-30 16:38:40] iter = 13370, loss = 1.7565
2024-10-30 16:38:43: [2024-10-30 16:38:43] iter = 13380, loss = 2.8959
2024-10-30 16:38:46: [2024-10-30 16:38:46] iter = 13390, loss = 2.0712
2024-10-30 16:38:50: [2024-10-30 16:38:50] iter = 13400, loss = 2.1414
2024-10-30 16:38:54: [2024-10-30 16:38:54] iter = 13410, loss = 1.9022
2024-10-30 16:38:58: [2024-10-30 16:38:58] iter = 13420, loss = 1.6935
2024-10-30 16:39:02: [2024-10-30 16:39:02] iter = 13430, loss = 2.0355
2024-10-30 16:39:06: [2024-10-30 16:39:06] iter = 13440, loss = 1.8942
2024-10-30 16:39:11: [2024-10-30 16:39:11] iter = 13450, loss = 1.7202
2024-10-30 16:39:16: [2024-10-30 16:39:16] iter = 13460, loss = 1.7956
2024-10-30 16:39:20: [2024-10-30 16:39:20] iter = 13470, loss = 3.2561
2024-10-30 16:39:24: [2024-10-30 16:39:24] iter = 13480, loss = 2.1958
2024-10-30 16:39:28: [2024-10-30 16:39:28] iter = 13490, loss = 1.9440
2024-10-30 16:39:33: [2024-10-30 16:39:33] iter = 13500, loss = 1.8765
2024-10-30 16:39:38: [2024-10-30 16:39:38] iter = 13510, loss = 2.0011
2024-10-30 16:39:42: [2024-10-30 16:39:42] iter = 13520, loss = 2.4210
2024-10-30 16:39:45: [2024-10-30 16:39:45] iter = 13530, loss = 1.7863
2024-10-30 16:39:50: [2024-10-30 16:39:50] iter = 13540, loss = 2.0981
2024-10-30 16:39:54: [2024-10-30 16:39:54] iter = 13550, loss = 2.0285
2024-10-30 16:39:59: [2024-10-30 16:39:59] iter = 13560, loss = 2.0364
2024-10-30 16:40:02: [2024-10-30 16:40:02] iter = 13570, loss = 2.3226
2024-10-30 16:40:07: [2024-10-30 16:40:07] iter = 13580, loss = 1.6444
2024-10-30 16:40:10: [2024-10-30 16:40:10] iter = 13590, loss = 2.5088
2024-10-30 16:40:14: [2024-10-30 16:40:14] iter = 13600, loss = 1.8189
2024-10-30 16:40:19: [2024-10-30 16:40:19] iter = 13610, loss = 1.7316
2024-10-30 16:40:24: [2024-10-30 16:40:24] iter = 13620, loss = 6.9674
2024-10-30 16:40:28: [2024-10-30 16:40:28] iter = 13630, loss = 1.8854
2024-10-30 16:40:33: [2024-10-30 16:40:33] iter = 13640, loss = 1.7094
2024-10-30 16:40:37: [2024-10-30 16:40:37] iter = 13650, loss = 3.1292
2024-10-30 16:40:41: [2024-10-30 16:40:41] iter = 13660, loss = 1.7839
2024-10-30 16:40:46: [2024-10-30 16:40:46] iter = 13670, loss = 2.0733
2024-10-30 16:40:51: [2024-10-30 16:40:51] iter = 13680, loss = 2.1471
2024-10-30 16:40:55: [2024-10-30 16:40:55] iter = 13690, loss = 2.9998
2024-10-30 16:40:59: [2024-10-30 16:40:59] iter = 13700, loss = 9.1187
2024-10-30 16:41:03: [2024-10-30 16:41:03] iter = 13710, loss = 1.7925
2024-10-30 16:41:07: [2024-10-30 16:41:07] iter = 13720, loss = 2.3100
2024-10-30 16:41:11: [2024-10-30 16:41:11] iter = 13730, loss = 1.9097
2024-10-30 16:41:16: [2024-10-30 16:41:16] iter = 13740, loss = 1.9534
2024-10-30 16:41:20: [2024-10-30 16:41:20] iter = 13750, loss = 2.8223
2024-10-30 16:41:23: [2024-10-30 16:41:23] iter = 13760, loss = 2.0280
2024-10-30 16:41:26: [2024-10-30 16:41:26] iter = 13770, loss = 2.1135
2024-10-30 16:41:29: [2024-10-30 16:41:29] iter = 13780, loss = 1.9245
2024-10-30 16:41:33: [2024-10-30 16:41:33] iter = 13790, loss = 2.2888
2024-10-30 16:41:37: [2024-10-30 16:41:37] iter = 13800, loss = 2.2956
2024-10-30 16:41:41: [2024-10-30 16:41:41] iter = 13810, loss = 1.8797
2024-10-30 16:41:46: [2024-10-30 16:41:46] iter = 13820, loss = 2.1839
2024-10-30 16:41:51: [2024-10-30 16:41:51] iter = 13830, loss = 2.6722
2024-10-30 16:41:56: [2024-10-30 16:41:56] iter = 13840, loss = 4.4152
2024-10-30 16:42:01: [2024-10-30 16:42:01] iter = 13850, loss = 2.3616
2024-10-30 16:42:04: [2024-10-30 16:42:04] iter = 13860, loss = 2.2735
2024-10-30 16:42:08: [2024-10-30 16:42:08] iter = 13870, loss = 2.5872
2024-10-30 16:42:11: [2024-10-30 16:42:11] iter = 13880, loss = 2.3653
2024-10-30 16:42:15: [2024-10-30 16:42:15] iter = 13890, loss = 2.2517
2024-10-30 16:42:19: [2024-10-30 16:42:19] iter = 13900, loss = 3.2863
2024-10-30 16:42:24: [2024-10-30 16:42:24] iter = 13910, loss = 1.5674
2024-10-30 16:42:28: [2024-10-30 16:42:28] iter = 13920, loss = 1.9223
2024-10-30 16:42:33: [2024-10-30 16:42:33] iter = 13930, loss = 1.9091
2024-10-30 16:42:36: [2024-10-30 16:42:36] iter = 13940, loss = 2.0357
2024-10-30 16:42:40: [2024-10-30 16:42:40] iter = 13950, loss = 2.1383
2024-10-30 16:42:44: [2024-10-30 16:42:44] iter = 13960, loss = 1.6638
2024-10-30 16:42:48: [2024-10-30 16:42:48] iter = 13970, loss = 1.9564
2024-10-30 16:42:53: [2024-10-30 16:42:53] iter = 13980, loss = 1.8592
2024-10-30 16:42:57: [2024-10-30 16:42:57] iter = 13990, loss = 1.9376
2024-10-30 16:43:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 16:43:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:43:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 80957}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:32: Evaluate 5 random ConvNet, ACCmean = 0.7764 ACCstd = 0.0025
-------------------------
2024-10-30 16:45:32: Evaluate 5 random ConvNet, SENmean = 0.7688 SENstd = 0.0018
-------------------------
2024-10-30 16:45:32: Evaluate 5 random ConvNet, SPEmean = 0.9773 SPEstd = 0.0003
-------------------------
2024-10-30 16:45:32: Evaluate 5 random ConvNet, F!mean = 0.7628 F!std = 0.0023
-------------------------
2024-10-30 16:45:32: Evaluate 5 random ConvNet, mean = 0.7764 std = 0.0025
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:32: [2024-10-30 16:45:32] iter = 14000, loss = 2.2192
2024-10-30 16:45:37: [2024-10-30 16:45:37] iter = 14010, loss = 2.9351
2024-10-30 16:45:44: [2024-10-30 16:45:44] iter = 14020, loss = 1.8567
2024-10-30 16:45:48: [2024-10-30 16:45:48] iter = 14030, loss = 2.6219
2024-10-30 16:45:52: [2024-10-30 16:45:52] iter = 14040, loss = 2.1748
2024-10-30 16:45:57: [2024-10-30 16:45:57] iter = 14050, loss = 2.7466
2024-10-30 16:46:01: [2024-10-30 16:46:01] iter = 14060, loss = 1.9657
2024-10-30 16:46:06: [2024-10-30 16:46:06] iter = 14070, loss = 2.2749
2024-10-30 16:46:11: [2024-10-30 16:46:11] iter = 14080, loss = 1.7188
2024-10-30 16:46:15: [2024-10-30 16:46:15] iter = 14090, loss = 1.8128
2024-10-30 16:46:18: [2024-10-30 16:46:18] iter = 14100, loss = 1.6387
2024-10-30 16:46:22: [2024-10-30 16:46:22] iter = 14110, loss = 1.9620
2024-10-30 16:46:26: [2024-10-30 16:46:26] iter = 14120, loss = 2.2650
2024-10-30 16:46:31: [2024-10-30 16:46:31] iter = 14130, loss = 3.3602
2024-10-30 16:46:34: [2024-10-30 16:46:34] iter = 14140, loss = 1.8947
2024-10-30 16:46:39: [2024-10-30 16:46:39] iter = 14150, loss = 1.8832
2024-10-30 16:46:43: [2024-10-30 16:46:43] iter = 14160, loss = 2.7448
2024-10-30 16:46:46: [2024-10-30 16:46:46] iter = 14170, loss = 2.5321
2024-10-30 16:46:50: [2024-10-30 16:46:50] iter = 14180, loss = 1.8710
2024-10-30 16:46:54: [2024-10-30 16:46:54] iter = 14190, loss = 1.9502
2024-10-30 16:46:59: [2024-10-30 16:46:59] iter = 14200, loss = 1.8938
2024-10-30 16:47:02: [2024-10-30 16:47:02] iter = 14210, loss = 1.8721
2024-10-30 16:47:06: [2024-10-30 16:47:06] iter = 14220, loss = 1.7027
2024-10-30 16:47:12: [2024-10-30 16:47:12] iter = 14230, loss = 2.0517
2024-10-30 16:47:16: [2024-10-30 16:47:16] iter = 14240, loss = 2.3480
2024-10-30 16:47:20: [2024-10-30 16:47:20] iter = 14250, loss = 3.1971
2024-10-30 16:47:24: [2024-10-30 16:47:23] iter = 14260, loss = 1.8182
2024-10-30 16:47:26: [2024-10-30 16:47:26] iter = 14270, loss = 2.3429
2024-10-30 16:47:31: [2024-10-30 16:47:31] iter = 14280, loss = 1.7420
2024-10-30 16:47:35: [2024-10-30 16:47:35] iter = 14290, loss = 2.2337
2024-10-30 16:47:38: [2024-10-30 16:47:38] iter = 14300, loss = 2.0152
2024-10-30 16:47:42: [2024-10-30 16:47:42] iter = 14310, loss = 1.7809
2024-10-30 16:47:46: [2024-10-30 16:47:46] iter = 14320, loss = 1.9345
2024-10-30 16:47:50: [2024-10-30 16:47:50] iter = 14330, loss = 2.1094
2024-10-30 16:47:54: [2024-10-30 16:47:54] iter = 14340, loss = 1.9073
2024-10-30 16:47:58: [2024-10-30 16:47:58] iter = 14350, loss = 1.7222
2024-10-30 16:48:02: [2024-10-30 16:48:02] iter = 14360, loss = 1.6907
2024-10-30 16:48:07: [2024-10-30 16:48:07] iter = 14370, loss = 2.3312
2024-10-30 16:48:10: [2024-10-30 16:48:10] iter = 14380, loss = 2.6975
2024-10-30 16:48:14: [2024-10-30 16:48:14] iter = 14390, loss = 2.3730
2024-10-30 16:48:18: [2024-10-30 16:48:18] iter = 14400, loss = 2.5770
2024-10-30 16:48:23: [2024-10-30 16:48:23] iter = 14410, loss = 2.0563
2024-10-30 16:48:27: [2024-10-30 16:48:27] iter = 14420, loss = 2.0506
2024-10-30 16:48:31: [2024-10-30 16:48:31] iter = 14430, loss = 1.5936
2024-10-30 16:48:36: [2024-10-30 16:48:36] iter = 14440, loss = 2.0010
2024-10-30 16:48:40: [2024-10-30 16:48:40] iter = 14450, loss = 1.5570
2024-10-30 16:48:45: [2024-10-30 16:48:45] iter = 14460, loss = 1.8745
2024-10-30 16:48:48: [2024-10-30 16:48:48] iter = 14470, loss = 2.1005
2024-10-30 16:48:51: [2024-10-30 16:48:51] iter = 14480, loss = 1.3829
2024-10-30 16:48:55: [2024-10-30 16:48:55] iter = 14490, loss = 2.1715
2024-10-30 16:48:59: [2024-10-30 16:48:59] iter = 14500, loss = 1.8180
2024-10-30 16:49:02: [2024-10-30 16:49:02] iter = 14510, loss = 1.7865
2024-10-30 16:49:07: [2024-10-30 16:49:07] iter = 14520, loss = 1.8122
2024-10-30 16:49:11: [2024-10-30 16:49:11] iter = 14530, loss = 1.9007
2024-10-30 16:49:14: [2024-10-30 16:49:14] iter = 14540, loss = 1.9034
2024-10-30 16:49:19: [2024-10-30 16:49:19] iter = 14550, loss = 1.8252
2024-10-30 16:49:23: [2024-10-30 16:49:23] iter = 14560, loss = 2.2439
2024-10-30 16:49:27: [2024-10-30 16:49:27] iter = 14570, loss = 2.2379
2024-10-30 16:49:31: [2024-10-30 16:49:31] iter = 14580, loss = 3.1582
2024-10-30 16:49:35: [2024-10-30 16:49:35] iter = 14590, loss = 1.8440
2024-10-30 16:49:38: [2024-10-30 16:49:38] iter = 14600, loss = 1.9925
2024-10-30 16:49:42: [2024-10-30 16:49:42] iter = 14610, loss = 2.0907
2024-10-30 16:49:46: [2024-10-30 16:49:46] iter = 14620, loss = 2.5454
2024-10-30 16:49:50: [2024-10-30 16:49:50] iter = 14630, loss = 1.8503
2024-10-30 16:49:54: [2024-10-30 16:49:54] iter = 14640, loss = 2.0147
2024-10-30 16:49:57: [2024-10-30 16:49:57] iter = 14650, loss = 1.9037
2024-10-30 16:50:01: [2024-10-30 16:50:01] iter = 14660, loss = 2.8806
2024-10-30 16:50:05: [2024-10-30 16:50:05] iter = 14670, loss = 2.5143
2024-10-30 16:50:09: [2024-10-30 16:50:09] iter = 14680, loss = 1.8659
2024-10-30 16:50:12: [2024-10-30 16:50:12] iter = 14690, loss = 2.1884
2024-10-30 16:50:17: [2024-10-30 16:50:17] iter = 14700, loss = 1.7759
2024-10-30 16:50:20: [2024-10-30 16:50:20] iter = 14710, loss = 2.9018
2024-10-30 16:50:24: [2024-10-30 16:50:24] iter = 14720, loss = 2.3944
2024-10-30 16:50:27: [2024-10-30 16:50:27] iter = 14730, loss = 2.3669
2024-10-30 16:50:31: [2024-10-30 16:50:31] iter = 14740, loss = 2.4657
2024-10-30 16:50:36: [2024-10-30 16:50:36] iter = 14750, loss = 2.3132
2024-10-30 16:50:40: [2024-10-30 16:50:40] iter = 14760, loss = 2.4028
2024-10-30 16:50:44: [2024-10-30 16:50:44] iter = 14770, loss = 1.9050
2024-10-30 16:50:48: [2024-10-30 16:50:48] iter = 14780, loss = 2.9444
2024-10-30 16:50:53: [2024-10-30 16:50:53] iter = 14790, loss = 2.2195
2024-10-30 16:50:57: [2024-10-30 16:50:57] iter = 14800, loss = 1.8195
2024-10-30 16:51:01: [2024-10-30 16:51:01] iter = 14810, loss = 2.8716
2024-10-30 16:51:05: [2024-10-30 16:51:05] iter = 14820, loss = 1.9226
2024-10-30 16:51:09: [2024-10-30 16:51:09] iter = 14830, loss = 1.9767
2024-10-30 16:51:13: [2024-10-30 16:51:13] iter = 14840, loss = 2.3874
2024-10-30 16:51:17: [2024-10-30 16:51:17] iter = 14850, loss = 2.5565
2024-10-30 16:51:21: [2024-10-30 16:51:21] iter = 14860, loss = 1.8271
2024-10-30 16:51:24: [2024-10-30 16:51:24] iter = 14870, loss = 1.8847
2024-10-30 16:51:29: [2024-10-30 16:51:29] iter = 14880, loss = 2.8022
2024-10-30 16:51:33: [2024-10-30 16:51:33] iter = 14890, loss = 1.9992
2024-10-30 16:51:36: [2024-10-30 16:51:36] iter = 14900, loss = 1.9866
2024-10-30 16:51:40: [2024-10-30 16:51:40] iter = 14910, loss = 2.5621
2024-10-30 16:51:44: [2024-10-30 16:51:44] iter = 14920, loss = 1.8298
2024-10-30 16:51:47: [2024-10-30 16:51:47] iter = 14930, loss = 1.9204
2024-10-30 16:51:51: [2024-10-30 16:51:51] iter = 14940, loss = 2.3524
2024-10-30 16:51:55: [2024-10-30 16:51:55] iter = 14950, loss = 1.6486
2024-10-30 16:51:58: [2024-10-30 16:51:58] iter = 14960, loss = 2.2789
2024-10-30 16:52:02: [2024-10-30 16:52:02] iter = 14970, loss = 1.8744
2024-10-30 16:52:06: [2024-10-30 16:52:06] iter = 14980, loss = 2.1605
2024-10-30 16:52:09: [2024-10-30 16:52:09] iter = 14990, loss = 1.8622
2024-10-30 16:52:13: [2024-10-30 16:52:13] iter = 15000, loss = 2.1541
2024-10-30 16:52:17: [2024-10-30 16:52:17] iter = 15010, loss = 3.0862
2024-10-30 16:52:21: [2024-10-30 16:52:21] iter = 15020, loss = 2.6544
2024-10-30 16:52:25: [2024-10-30 16:52:25] iter = 15030, loss = 1.7731
2024-10-30 16:52:28: [2024-10-30 16:52:28] iter = 15040, loss = 2.4007
2024-10-30 16:52:31: [2024-10-30 16:52:31] iter = 15050, loss = 2.4262
2024-10-30 16:52:35: [2024-10-30 16:52:35] iter = 15060, loss = 2.0389
2024-10-30 16:52:39: [2024-10-30 16:52:39] iter = 15070, loss = 1.5936
2024-10-30 16:52:43: [2024-10-30 16:52:43] iter = 15080, loss = 2.2137
2024-10-30 16:52:49: [2024-10-30 16:52:49] iter = 15090, loss = 2.1517
2024-10-30 16:52:52: [2024-10-30 16:52:52] iter = 15100, loss = 2.1468
2024-10-30 16:52:55: [2024-10-30 16:52:55] iter = 15110, loss = 1.8509
2024-10-30 16:52:58: [2024-10-30 16:52:58] iter = 15120, loss = 2.4221
2024-10-30 16:53:02: [2024-10-30 16:53:02] iter = 15130, loss = 2.2082
2024-10-30 16:53:06: [2024-10-30 16:53:06] iter = 15140, loss = 2.9314
2024-10-30 16:53:09: [2024-10-30 16:53:09] iter = 15150, loss = 1.7945
2024-10-30 16:53:13: [2024-10-30 16:53:13] iter = 15160, loss = 1.8299
2024-10-30 16:53:17: [2024-10-30 16:53:17] iter = 15170, loss = 2.1687
2024-10-30 16:53:21: [2024-10-30 16:53:21] iter = 15180, loss = 1.8474
2024-10-30 16:53:24: [2024-10-30 16:53:24] iter = 15190, loss = 2.7625
2024-10-30 16:53:29: [2024-10-30 16:53:29] iter = 15200, loss = 3.4081
2024-10-30 16:53:32: [2024-10-30 16:53:32] iter = 15210, loss = 1.5984
2024-10-30 16:53:36: [2024-10-30 16:53:36] iter = 15220, loss = 2.9220
2024-10-30 16:53:40: [2024-10-30 16:53:40] iter = 15230, loss = 1.7147
2024-10-30 16:53:43: [2024-10-30 16:53:43] iter = 15240, loss = 1.7606
2024-10-30 16:53:48: [2024-10-30 16:53:48] iter = 15250, loss = 2.6154
2024-10-30 16:53:53: [2024-10-30 16:53:53] iter = 15260, loss = 1.9198
2024-10-30 16:53:57: [2024-10-30 16:53:57] iter = 15270, loss = 2.9656
2024-10-30 16:54:01: [2024-10-30 16:54:01] iter = 15280, loss = 2.0768
2024-10-30 16:54:05: [2024-10-30 16:54:05] iter = 15290, loss = 1.8148
2024-10-30 16:54:09: [2024-10-30 16:54:09] iter = 15300, loss = 1.5670
2024-10-30 16:54:14: [2024-10-30 16:54:14] iter = 15310, loss = 1.6215
2024-10-30 16:54:19: [2024-10-30 16:54:19] iter = 15320, loss = 1.9065
2024-10-30 16:54:22: [2024-10-30 16:54:22] iter = 15330, loss = 2.5750
2024-10-30 16:54:26: [2024-10-30 16:54:26] iter = 15340, loss = 2.1185
2024-10-30 16:54:30: [2024-10-30 16:54:30] iter = 15350, loss = 2.0299
2024-10-30 16:54:34: [2024-10-30 16:54:34] iter = 15360, loss = 1.8651
2024-10-30 16:54:39: [2024-10-30 16:54:39] iter = 15370, loss = 1.6223
2024-10-30 16:54:43: [2024-10-30 16:54:43] iter = 15380, loss = 2.0846
2024-10-30 16:54:47: [2024-10-30 16:54:47] iter = 15390, loss = 1.9553
2024-10-30 16:54:51: [2024-10-30 16:54:51] iter = 15400, loss = 2.0843
2024-10-30 16:54:55: [2024-10-30 16:54:55] iter = 15410, loss = 2.1565
2024-10-30 16:54:59: [2024-10-30 16:54:59] iter = 15420, loss = 3.1653
2024-10-30 16:55:03: [2024-10-30 16:55:03] iter = 15430, loss = 4.0605
2024-10-30 16:55:06: [2024-10-30 16:55:06] iter = 15440, loss = 2.2851
2024-10-30 16:55:10: [2024-10-30 16:55:10] iter = 15450, loss = 1.7016
2024-10-30 16:55:14: [2024-10-30 16:55:14] iter = 15460, loss = 1.7357
2024-10-30 16:55:18: [2024-10-30 16:55:18] iter = 15470, loss = 2.0690
2024-10-30 16:55:22: [2024-10-30 16:55:22] iter = 15480, loss = 1.8653
2024-10-30 16:55:25: [2024-10-30 16:55:25] iter = 15490, loss = 2.0056
2024-10-30 16:55:29: [2024-10-30 16:55:29] iter = 15500, loss = 2.9393
2024-10-30 16:55:34: [2024-10-30 16:55:34] iter = 15510, loss = 2.4910
2024-10-30 16:55:37: [2024-10-30 16:55:37] iter = 15520, loss = 1.9375
2024-10-30 16:55:41: [2024-10-30 16:55:41] iter = 15530, loss = 1.9646
2024-10-30 16:55:45: [2024-10-30 16:55:45] iter = 15540, loss = 2.4890
2024-10-30 16:55:49: [2024-10-30 16:55:49] iter = 15550, loss = 2.2184
2024-10-30 16:55:53: [2024-10-30 16:55:53] iter = 15560, loss = 2.2664
2024-10-30 16:55:55: [2024-10-30 16:55:55] iter = 15570, loss = 1.7102
2024-10-30 16:55:58: [2024-10-30 16:55:58] iter = 15580, loss = 2.0645
2024-10-30 16:56:03: [2024-10-30 16:56:03] iter = 15590, loss = 2.4999
2024-10-30 16:56:06: [2024-10-30 16:56:06] iter = 15600, loss = 3.3243
2024-10-30 16:56:10: [2024-10-30 16:56:10] iter = 15610, loss = 2.0658
2024-10-30 16:56:14: [2024-10-30 16:56:14] iter = 15620, loss = 2.4472
2024-10-30 16:56:18: [2024-10-30 16:56:18] iter = 15630, loss = 1.8218
2024-10-30 16:56:22: [2024-10-30 16:56:22] iter = 15640, loss = 1.8441
2024-10-30 16:56:25: [2024-10-30 16:56:25] iter = 15650, loss = 5.3666
2024-10-30 16:56:29: [2024-10-30 16:56:29] iter = 15660, loss = 1.8186
2024-10-30 16:56:32: [2024-10-30 16:56:32] iter = 15670, loss = 1.6677
2024-10-30 16:56:37: [2024-10-30 16:56:37] iter = 15680, loss = 2.1744
2024-10-30 16:56:42: [2024-10-30 16:56:42] iter = 15690, loss = 2.7364
2024-10-30 16:56:45: [2024-10-30 16:56:45] iter = 15700, loss = 1.8467
2024-10-30 16:56:48: [2024-10-30 16:56:48] iter = 15710, loss = 2.1407
2024-10-30 16:56:52: [2024-10-30 16:56:52] iter = 15720, loss = 1.5445
2024-10-30 16:56:55: [2024-10-30 16:56:55] iter = 15730, loss = 2.6172
2024-10-30 16:56:59: [2024-10-30 16:56:59] iter = 15740, loss = 2.4036
2024-10-30 16:57:03: [2024-10-30 16:57:03] iter = 15750, loss = 2.6884
2024-10-30 16:57:07: [2024-10-30 16:57:07] iter = 15760, loss = 2.0163
2024-10-30 16:57:12: [2024-10-30 16:57:12] iter = 15770, loss = 1.9549
2024-10-30 16:57:15: [2024-10-30 16:57:15] iter = 15780, loss = 2.2420
2024-10-30 16:57:19: [2024-10-30 16:57:19] iter = 15790, loss = 1.8018
2024-10-30 16:57:22: [2024-10-30 16:57:22] iter = 15800, loss = 2.1810
2024-10-30 16:57:26: [2024-10-30 16:57:26] iter = 15810, loss = 1.9940
2024-10-30 16:57:30: [2024-10-30 16:57:30] iter = 15820, loss = 1.7954
2024-10-30 16:57:34: [2024-10-30 16:57:34] iter = 15830, loss = 2.3059
2024-10-30 16:57:38: [2024-10-30 16:57:38] iter = 15840, loss = 2.0486
2024-10-30 16:57:42: [2024-10-30 16:57:42] iter = 15850, loss = 1.8574
2024-10-30 16:57:46: [2024-10-30 16:57:46] iter = 15860, loss = 3.9170
2024-10-30 16:57:49: [2024-10-30 16:57:49] iter = 15870, loss = 1.8295
2024-10-30 16:57:54: [2024-10-30 16:57:54] iter = 15880, loss = 3.2541
2024-10-30 16:57:57: [2024-10-30 16:57:57] iter = 15890, loss = 3.1694
2024-10-30 16:58:01: [2024-10-30 16:58:01] iter = 15900, loss = 1.5646
2024-10-30 16:58:04: [2024-10-30 16:58:04] iter = 15910, loss = 2.0385
2024-10-30 16:58:08: [2024-10-30 16:58:08] iter = 15920, loss = 3.0146
2024-10-30 16:58:12: [2024-10-30 16:58:12] iter = 15930, loss = 1.9224
2024-10-30 16:58:15: [2024-10-30 16:58:15] iter = 15940, loss = 1.9909
2024-10-30 16:58:19: [2024-10-30 16:58:19] iter = 15950, loss = 1.9716
2024-10-30 16:58:24: [2024-10-30 16:58:24] iter = 15960, loss = 1.9507
2024-10-30 16:58:28: [2024-10-30 16:58:28] iter = 15970, loss = 1.7895
2024-10-30 16:58:32: [2024-10-30 16:58:32] iter = 15980, loss = 2.5722
2024-10-30 16:58:38: [2024-10-30 16:58:38] iter = 15990, loss = 1.9279
2024-10-30 16:58:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 16:58:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:58:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 22862}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/organcmnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/organcmnist.npz
Loaded the dataset:OrganCMNIST
[2024-10-30 14:57:59] Evaluate_00: epoch = 1000 train time = 43 s train loss = 0.003691 train acc = 1.0000, test acc = 0.6888, test_sen =0.6883, test_spe =0.9688, test_f1 =0.6715
[2024-10-30 14:58:39] Evaluate_01: epoch = 1000 train time = 38 s train loss = 0.004000 train acc = 1.0000, test acc = 0.6904, test_sen =0.6916, test_spe =0.9689, test_f1 =0.6760
[2024-10-30 14:59:17] Evaluate_02: epoch = 1000 train time = 36 s train loss = 0.034266 train acc = 0.9909, test acc = 0.7018, test_sen =0.7035, test_spe =0.9702, test_f1 =0.6871
[2024-10-30 14:59:51] Evaluate_03: epoch = 1000 train time = 33 s train loss = 0.002180 train acc = 1.0000, test acc = 0.6968, test_sen =0.6988, test_spe =0.9696, test_f1 =0.6802
[2024-10-30 15:00:22] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.002506 train acc = 1.0000, test acc = 0.6846, test_sen =0.6897, test_spe =0.9685, test_f1 =0.6711
[2024-10-30 15:14:12] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.009814 train acc = 1.0000, test acc = 0.7942, test_sen =0.7888, test_spe =0.9793, test_f1 =0.7794
[2024-10-30 15:14:42] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.009529 train acc = 1.0000, test acc = 0.7874, test_sen =0.7843, test_spe =0.9785, test_f1 =0.7744
[2024-10-30 15:15:13] Evaluate_02: epoch = 1000 train time = 29 s train loss = 0.002646 train acc = 1.0000, test acc = 0.7898, test_sen =0.7815, test_spe =0.9787, test_f1 =0.7740
[2024-10-30 15:15:42] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.003786 train acc = 1.0000, test acc = 0.7943, test_sen =0.7896, test_spe =0.9792, test_f1 =0.7820
[2024-10-30 15:16:13] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.006812 train acc = 1.0000, test acc = 0.7910, test_sen =0.7832, test_spe =0.9789, test_f1 =0.7746
[2024-10-30 15:29:01] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.003961 train acc = 1.0000, test acc = 0.7853, test_sen =0.7804, test_spe =0.9783, test_f1 =0.7713
[2024-10-30 15:29:32] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.031412 train acc = 1.0000, test acc = 0.7756, test_sen =0.7730, test_spe =0.9774, test_f1 =0.7627
[2024-10-30 15:30:02] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.003606 train acc = 1.0000, test acc = 0.7799, test_sen =0.7742, test_spe =0.9778, test_f1 =0.7662
[2024-10-30 15:30:32] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.008991 train acc = 1.0000, test acc = 0.7764, test_sen =0.7698, test_spe =0.9774, test_f1 =0.7626
[2024-10-30 15:31:00] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.002903 train acc = 1.0000, test acc = 0.7865, test_sen =0.7810, test_spe =0.9784, test_f1 =0.7738
[2024-10-30 15:43:11] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.003479 train acc = 1.0000, test acc = 0.7835, test_sen =0.7792, test_spe =0.9782, test_f1 =0.7719
[2024-10-30 15:43:39] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.005075 train acc = 1.0000, test acc = 0.7848, test_sen =0.7803, test_spe =0.9783, test_f1 =0.7727
[2024-10-30 15:44:07] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.014829 train acc = 1.0000, test acc = 0.7784, test_sen =0.7751, test_spe =0.9777, test_f1 =0.7653
[2024-10-30 15:44:37] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.003518 train acc = 1.0000, test acc = 0.7825, test_sen =0.7781, test_spe =0.9780, test_f1 =0.7695
[2024-10-30 15:45:01] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.018146 train acc = 1.0000, test acc = 0.7787, test_sen =0.7762, test_spe =0.9777, test_f1 =0.7658
[2024-10-30 15:58:06] Evaluate_00: epoch = 1000 train time = 32 s train loss = 0.004919 train acc = 1.0000, test acc = 0.7888, test_sen =0.7824, test_spe =0.9786, test_f1 =0.7754
[2024-10-30 15:58:33] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.007237 train acc = 1.0000, test acc = 0.7819, test_sen =0.7753, test_spe =0.9780, test_f1 =0.7670
[2024-10-30 15:59:03] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.010558 train acc = 1.0000, test acc = 0.7952, test_sen =0.7859, test_spe =0.9793, test_f1 =0.7791
[2024-10-30 15:59:33] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.006512 train acc = 1.0000, test acc = 0.7851, test_sen =0.7773, test_spe =0.9783, test_f1 =0.7690
[2024-10-30 15:59:59] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.003710 train acc = 1.0000, test acc = 0.7908, test_sen =0.7802, test_spe =0.9789, test_f1 =0.7733
[2024-10-30 16:12:20] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.003631 train acc = 1.0000, test acc = 0.7941, test_sen =0.7848, test_spe =0.9790, test_f1 =0.7808
[2024-10-30 16:12:50] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.005303 train acc = 1.0000, test acc = 0.7969, test_sen =0.7889, test_spe =0.9794, test_f1 =0.7823
[2024-10-30 16:13:19] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.004815 train acc = 1.0000, test acc = 0.7903, test_sen =0.7820, test_spe =0.9787, test_f1 =0.7751
[2024-10-30 16:13:50] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.003895 train acc = 1.0000, test acc = 0.7984, test_sen =0.7885, test_spe =0.9796, test_f1 =0.7829
[2024-10-30 16:14:19] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.004662 train acc = 1.0000, test acc = 0.7931, test_sen =0.7840, test_spe =0.9790, test_f1 =0.7778
[2024-10-30 16:27:21] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.015001 train acc = 1.0000, test acc = 0.7948, test_sen =0.7860, test_spe =0.9792, test_f1 =0.7823
[2024-10-30 16:27:50] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.005591 train acc = 1.0000, test acc = 0.7808, test_sen =0.7771, test_spe =0.9779, test_f1 =0.7675
[2024-10-30 16:28:23] Evaluate_02: epoch = 1000 train time = 32 s train loss = 0.006488 train acc = 1.0000, test acc = 0.7865, test_sen =0.7797, test_spe =0.9784, test_f1 =0.7727
[2024-10-30 16:28:54] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.013991 train acc = 1.0000, test acc = 0.7842, test_sen =0.7785, test_spe =0.9781, test_f1 =0.7717
[2024-10-30 16:29:25] Evaluate_04: epoch = 1000 train time = 30 s train loss = 0.002699 train acc = 1.0000, test acc = 0.7826, test_sen =0.7754, test_spe =0.9780, test_f1 =0.7669
[2024-10-30 16:43:30] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.030115 train acc = 1.0000, test acc = 0.7741, test_sen =0.7671, test_spe =0.9771, test_f1 =0.7602
[2024-10-30 16:44:04] Evaluate_01: epoch = 1000 train time = 32 s train loss = 0.011059 train acc = 1.0000, test acc = 0.7729, test_sen =0.7667, test_spe =0.9770, test_f1 =0.7600
[2024-10-30 16:44:35] Evaluate_02: epoch = 1000 train time = 30 s train loss = 0.010972 train acc = 0.9909, test acc = 0.7785, test_sen =0.7707, test_spe =0.9775, test_f1 =0.7647
[2024-10-30 16:45:02] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.003845 train acc = 1.0000, test acc = 0.7796, test_sen =0.7710, test_spe =0.9776, test_f1 =0.7658
[2024-10-30 16:45:32] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.005184 train acc = 1.0000, test acc = 0.7768, test_sen =0.7685, test_spe =0.9774, test_f1 =0.7632
[2024-10-30 16:59:20] Evaluate_00: epoch = 1000 train time = 36 s train loss = 0.003730 train acc = 1.0000, test acc = 0.7887, test_sen =0.7839, test_spe =0.9786, test_f1 =0.7756
[2024-10-30 16:59:54] Evaluate_01: epoch = 1000 train time = 32 s train loss = 0.010738 train acc = 1.0000, test acc = 0.7808, test_sen =0.7752, test_spe =0.9778, test_f1 =0.7665
[2024-10-30 17:00:24] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.004126 train acc = 1.0000, test acc = 0.7848, test_sen =0.7820, test_spe =0.9782, test_f1 =0.7734
[2024-10-30 17:00:54] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.009788 train acc = 1.0000, test acc = 0.7830, test_sen =0.7780, test_spe =0.9780, test_f1 =0.7708
[2024-10-30 17:01:25] Evaluate_04: epoch = 1000 train time = 30 s train loss = 0.022235 train acc = 0.9909, test acc = 0.7888, test_sen =0.7797, test_spe =0.9785, test_f1 =0.7755/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:01:25: Evaluate 5 random ConvNet, ACCmean = 0.7852 ACCstd = 0.0032
-------------------------
2024-10-30 17:01:25: Evaluate 5 random ConvNet, SENmean = 0.7798 SENstd = 0.0031
-------------------------
2024-10-30 17:01:25: Evaluate 5 random ConvNet, SPEmean = 0.9782 SPEstd = 0.0003
-------------------------
2024-10-30 17:01:25: Evaluate 5 random ConvNet, F!mean = 0.7724 F!std = 0.0034
-------------------------
2024-10-30 17:01:25: Evaluate 5 random ConvNet, mean = 0.7852 std = 0.0032
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:01:26: [2024-10-30 17:01:26] iter = 16000, loss = 2.0718
2024-10-30 17:01:30: [2024-10-30 17:01:30] iter = 16010, loss = 1.5876
2024-10-30 17:01:32: [2024-10-30 17:01:32] iter = 16020, loss = 2.2442
2024-10-30 17:01:37: [2024-10-30 17:01:37] iter = 16030, loss = 2.1196
2024-10-30 17:01:43: [2024-10-30 17:01:43] iter = 16040, loss = 1.9658
2024-10-30 17:01:47: [2024-10-30 17:01:47] iter = 16050, loss = 2.1580
2024-10-30 17:01:50: [2024-10-30 17:01:50] iter = 16060, loss = 2.6428
2024-10-30 17:01:55: [2024-10-30 17:01:55] iter = 16070, loss = 1.7174
2024-10-30 17:02:00: [2024-10-30 17:02:00] iter = 16080, loss = 1.9638
2024-10-30 17:02:03: [2024-10-30 17:02:03] iter = 16090, loss = 1.6534
2024-10-30 17:02:07: [2024-10-30 17:02:07] iter = 16100, loss = 1.6792
2024-10-30 17:02:12: [2024-10-30 17:02:12] iter = 16110, loss = 2.0566
2024-10-30 17:02:16: [2024-10-30 17:02:16] iter = 16120, loss = 1.8771
2024-10-30 17:02:19: [2024-10-30 17:02:19] iter = 16130, loss = 2.1677
2024-10-30 17:02:24: [2024-10-30 17:02:24] iter = 16140, loss = 2.2420
2024-10-30 17:02:29: [2024-10-30 17:02:29] iter = 16150, loss = 3.2946
2024-10-30 17:02:33: [2024-10-30 17:02:33] iter = 16160, loss = 1.6623
2024-10-30 17:02:38: [2024-10-30 17:02:37] iter = 16170, loss = 2.2615
2024-10-30 17:02:42: [2024-10-30 17:02:42] iter = 16180, loss = 2.1133
2024-10-30 17:02:45: [2024-10-30 17:02:45] iter = 16190, loss = 2.5925
2024-10-30 17:02:50: [2024-10-30 17:02:50] iter = 16200, loss = 1.9965
2024-10-30 17:02:54: [2024-10-30 17:02:54] iter = 16210, loss = 2.7979
2024-10-30 17:02:58: [2024-10-30 17:02:58] iter = 16220, loss = 2.4210
2024-10-30 17:03:03: [2024-10-30 17:03:03] iter = 16230, loss = 2.1579
2024-10-30 17:03:08: [2024-10-30 17:03:08] iter = 16240, loss = 1.9742
2024-10-30 17:03:13: [2024-10-30 17:03:13] iter = 16250, loss = 2.0075
2024-10-30 17:03:17: [2024-10-30 17:03:17] iter = 16260, loss = 1.8076
2024-10-30 17:03:21: [2024-10-30 17:03:21] iter = 16270, loss = 1.8139
2024-10-30 17:03:25: [2024-10-30 17:03:25] iter = 16280, loss = 2.4595
2024-10-30 17:03:30: [2024-10-30 17:03:30] iter = 16290, loss = 2.4792
2024-10-30 17:03:35: [2024-10-30 17:03:35] iter = 16300, loss = 2.0552
2024-10-30 17:03:39: [2024-10-30 17:03:39] iter = 16310, loss = 2.9655
2024-10-30 17:03:43: [2024-10-30 17:03:43] iter = 16320, loss = 1.5846
2024-10-30 17:03:47: [2024-10-30 17:03:47] iter = 16330, loss = 3.4059
2024-10-30 17:03:50: [2024-10-30 17:03:50] iter = 16340, loss = 1.9718
2024-10-30 17:03:53: [2024-10-30 17:03:53] iter = 16350, loss = 1.8297
2024-10-30 17:03:58: [2024-10-30 17:03:58] iter = 16360, loss = 2.4430
2024-10-30 17:04:03: [2024-10-30 17:04:03] iter = 16370, loss = 2.2297
2024-10-30 17:04:09: [2024-10-30 17:04:09] iter = 16380, loss = 2.5130
2024-10-30 17:04:14: [2024-10-30 17:04:14] iter = 16390, loss = 2.3661
2024-10-30 17:04:18: [2024-10-30 17:04:18] iter = 16400, loss = 2.4492
2024-10-30 17:04:22: [2024-10-30 17:04:22] iter = 16410, loss = 1.7999
2024-10-30 17:04:25: [2024-10-30 17:04:25] iter = 16420, loss = 2.6458
2024-10-30 17:04:30: [2024-10-30 17:04:30] iter = 16430, loss = 1.8398
2024-10-30 17:04:34: [2024-10-30 17:04:34] iter = 16440, loss = 1.9757
2024-10-30 17:04:37: [2024-10-30 17:04:37] iter = 16450, loss = 2.2652
2024-10-30 17:04:41: [2024-10-30 17:04:41] iter = 16460, loss = 2.4406
2024-10-30 17:04:46: [2024-10-30 17:04:46] iter = 16470, loss = 2.3394
2024-10-30 17:04:50: [2024-10-30 17:04:50] iter = 16480, loss = 1.7237
2024-10-30 17:04:54: [2024-10-30 17:04:54] iter = 16490, loss = 2.5806
2024-10-30 17:04:59: [2024-10-30 17:04:59] iter = 16500, loss = 3.7775
2024-10-30 17:05:04: [2024-10-30 17:05:04] iter = 16510, loss = 2.5495
2024-10-30 17:05:07: [2024-10-30 17:05:07] iter = 16520, loss = 3.3737
2024-10-30 17:05:12: [2024-10-30 17:05:12] iter = 16530, loss = 2.0904
2024-10-30 17:05:16: [2024-10-30 17:05:16] iter = 16540, loss = 2.4689
2024-10-30 17:05:21: [2024-10-30 17:05:21] iter = 16550, loss = 3.7147
2024-10-30 17:05:26: [2024-10-30 17:05:26] iter = 16560, loss = 2.2338
2024-10-30 17:05:31: [2024-10-30 17:05:31] iter = 16570, loss = 2.2052
2024-10-30 17:05:35: [2024-10-30 17:05:35] iter = 16580, loss = 1.9241
2024-10-30 17:05:39: [2024-10-30 17:05:39] iter = 16590, loss = 1.9635
2024-10-30 17:05:43: [2024-10-30 17:05:43] iter = 16600, loss = 1.8899
2024-10-30 17:05:47: [2024-10-30 17:05:47] iter = 16610, loss = 1.7724
2024-10-30 17:05:52: [2024-10-30 17:05:52] iter = 16620, loss = 2.5945
2024-10-30 17:05:57: [2024-10-30 17:05:57] iter = 16630, loss = 2.9645
2024-10-30 17:06:01: [2024-10-30 17:06:01] iter = 16640, loss = 1.4682
2024-10-30 17:06:04: [2024-10-30 17:06:04] iter = 16650, loss = 2.7562
2024-10-30 17:06:08: [2024-10-30 17:06:08] iter = 16660, loss = 1.6477
2024-10-30 17:06:12: [2024-10-30 17:06:12] iter = 16670, loss = 1.7824
2024-10-30 17:06:16: [2024-10-30 17:06:16] iter = 16680, loss = 1.8406
2024-10-30 17:06:20: [2024-10-30 17:06:20] iter = 16690, loss = 1.7469
2024-10-30 17:06:23: [2024-10-30 17:06:23] iter = 16700, loss = 2.3705
2024-10-30 17:06:27: [2024-10-30 17:06:27] iter = 16710, loss = 2.3155
2024-10-30 17:06:31: [2024-10-30 17:06:31] iter = 16720, loss = 3.4685
2024-10-30 17:06:34: [2024-10-30 17:06:34] iter = 16730, loss = 1.7836
2024-10-30 17:06:39: [2024-10-30 17:06:39] iter = 16740, loss = 1.8317
2024-10-30 17:06:43: [2024-10-30 17:06:43] iter = 16750, loss = 2.0604
2024-10-30 17:06:47: [2024-10-30 17:06:47] iter = 16760, loss = 2.2273
2024-10-30 17:06:52: [2024-10-30 17:06:52] iter = 16770, loss = 1.7762
2024-10-30 17:06:56: [2024-10-30 17:06:56] iter = 16780, loss = 2.1867
2024-10-30 17:07:00: [2024-10-30 17:07:00] iter = 16790, loss = 1.4939
2024-10-30 17:07:04: [2024-10-30 17:07:04] iter = 16800, loss = 1.9430
2024-10-30 17:07:08: [2024-10-30 17:07:08] iter = 16810, loss = 2.4262
2024-10-30 17:07:12: [2024-10-30 17:07:12] iter = 16820, loss = 2.6226
2024-10-30 17:07:16: [2024-10-30 17:07:16] iter = 16830, loss = 1.6860
2024-10-30 17:07:20: [2024-10-30 17:07:20] iter = 16840, loss = 1.8257
2024-10-30 17:07:25: [2024-10-30 17:07:25] iter = 16850, loss = 1.9627
2024-10-30 17:07:29: [2024-10-30 17:07:29] iter = 16860, loss = 2.4003
2024-10-30 17:07:33: [2024-10-30 17:07:33] iter = 16870, loss = 1.9267
2024-10-30 17:07:37: [2024-10-30 17:07:37] iter = 16880, loss = 1.7382
2024-10-30 17:07:40: [2024-10-30 17:07:40] iter = 16890, loss = 1.5839
2024-10-30 17:07:45: [2024-10-30 17:07:45] iter = 16900, loss = 1.5649
2024-10-30 17:07:49: [2024-10-30 17:07:49] iter = 16910, loss = 2.0907
2024-10-30 17:07:54: [2024-10-30 17:07:54] iter = 16920, loss = 1.7432
2024-10-30 17:07:58: [2024-10-30 17:07:58] iter = 16930, loss = 1.5662
2024-10-30 17:08:02: [2024-10-30 17:08:02] iter = 16940, loss = 2.2544
2024-10-30 17:08:07: [2024-10-30 17:08:07] iter = 16950, loss = 1.9568
2024-10-30 17:08:10: [2024-10-30 17:08:10] iter = 16960, loss = 1.7563
2024-10-30 17:08:14: [2024-10-30 17:08:14] iter = 16970, loss = 4.2540
2024-10-30 17:08:19: [2024-10-30 17:08:19] iter = 16980, loss = 1.9026
2024-10-30 17:08:22: [2024-10-30 17:08:22] iter = 16990, loss = 3.0755
2024-10-30 17:08:26: [2024-10-30 17:08:26] iter = 17000, loss = 1.9729
2024-10-30 17:08:30: [2024-10-30 17:08:30] iter = 17010, loss = 1.9483
2024-10-30 17:08:34: [2024-10-30 17:08:34] iter = 17020, loss = 1.9232
2024-10-30 17:08:39: [2024-10-30 17:08:39] iter = 17030, loss = 1.8572
2024-10-30 17:08:43: [2024-10-30 17:08:43] iter = 17040, loss = 2.2688
2024-10-30 17:08:47: [2024-10-30 17:08:47] iter = 17050, loss = 2.4122
2024-10-30 17:08:50: [2024-10-30 17:08:50] iter = 17060, loss = 1.7105
2024-10-30 17:08:55: [2024-10-30 17:08:55] iter = 17070, loss = 3.7234
2024-10-30 17:08:58: [2024-10-30 17:08:58] iter = 17080, loss = 2.0646
2024-10-30 17:09:03: [2024-10-30 17:09:03] iter = 17090, loss = 2.4071
2024-10-30 17:09:07: [2024-10-30 17:09:07] iter = 17100, loss = 3.0392
2024-10-30 17:09:11: [2024-10-30 17:09:11] iter = 17110, loss = 1.7234
2024-10-30 17:09:15: [2024-10-30 17:09:15] iter = 17120, loss = 2.0268
2024-10-30 17:09:19: [2024-10-30 17:09:19] iter = 17130, loss = 2.7142
2024-10-30 17:09:23: [2024-10-30 17:09:23] iter = 17140, loss = 1.9988
2024-10-30 17:09:26: [2024-10-30 17:09:26] iter = 17150, loss = 2.0308
2024-10-30 17:09:30: [2024-10-30 17:09:30] iter = 17160, loss = 2.3400
2024-10-30 17:09:34: [2024-10-30 17:09:34] iter = 17170, loss = 2.0552
2024-10-30 17:09:38: [2024-10-30 17:09:38] iter = 17180, loss = 1.9007
2024-10-30 17:09:42: [2024-10-30 17:09:42] iter = 17190, loss = 2.4272
2024-10-30 17:09:45: [2024-10-30 17:09:45] iter = 17200, loss = 2.1506
2024-10-30 17:09:49: [2024-10-30 17:09:49] iter = 17210, loss = 2.2446
2024-10-30 17:09:53: [2024-10-30 17:09:53] iter = 17220, loss = 1.9364
2024-10-30 17:09:56: [2024-10-30 17:09:56] iter = 17230, loss = 2.3127
2024-10-30 17:09:59: [2024-10-30 17:09:59] iter = 17240, loss = 4.2170
2024-10-30 17:10:02: [2024-10-30 17:10:02] iter = 17250, loss = 2.3449
2024-10-30 17:10:06: [2024-10-30 17:10:06] iter = 17260, loss = 1.9229
2024-10-30 17:10:10: [2024-10-30 17:10:10] iter = 17270, loss = 2.1532
2024-10-30 17:10:14: [2024-10-30 17:10:14] iter = 17280, loss = 3.5102
2024-10-30 17:10:19: [2024-10-30 17:10:19] iter = 17290, loss = 1.9199
2024-10-30 17:10:23: [2024-10-30 17:10:23] iter = 17300, loss = 2.3465
2024-10-30 17:10:28: [2024-10-30 17:10:28] iter = 17310, loss = 1.7259
2024-10-30 17:10:31: [2024-10-30 17:10:31] iter = 17320, loss = 1.6378
2024-10-30 17:10:35: [2024-10-30 17:10:35] iter = 17330, loss = 3.6800
2024-10-30 17:10:39: [2024-10-30 17:10:39] iter = 17340, loss = 1.9052
2024-10-30 17:10:44: [2024-10-30 17:10:44] iter = 17350, loss = 2.0934
2024-10-30 17:10:48: [2024-10-30 17:10:48] iter = 17360, loss = 1.7525
2024-10-30 17:10:53: [2024-10-30 17:10:53] iter = 17370, loss = 2.3293
2024-10-30 17:10:58: [2024-10-30 17:10:58] iter = 17380, loss = 2.2622
2024-10-30 17:11:02: [2024-10-30 17:11:02] iter = 17390, loss = 2.2661
2024-10-30 17:11:06: [2024-10-30 17:11:06] iter = 17400, loss = 2.8268
2024-10-30 17:11:09: [2024-10-30 17:11:09] iter = 17410, loss = 1.7633
2024-10-30 17:11:13: [2024-10-30 17:11:13] iter = 17420, loss = 2.2643
2024-10-30 17:11:17: [2024-10-30 17:11:17] iter = 17430, loss = 1.7124
2024-10-30 17:11:21: [2024-10-30 17:11:21] iter = 17440, loss = 2.0069
2024-10-30 17:11:26: [2024-10-30 17:11:26] iter = 17450, loss = 1.8990
2024-10-30 17:11:30: [2024-10-30 17:11:30] iter = 17460, loss = 1.8474
2024-10-30 17:11:34: [2024-10-30 17:11:34] iter = 17470, loss = 1.9024
2024-10-30 17:11:38: [2024-10-30 17:11:38] iter = 17480, loss = 2.0687
2024-10-30 17:11:41: [2024-10-30 17:11:41] iter = 17490, loss = 1.8713
2024-10-30 17:11:45: [2024-10-30 17:11:45] iter = 17500, loss = 2.9405
2024-10-30 17:11:49: [2024-10-30 17:11:49] iter = 17510, loss = 1.7356
2024-10-30 17:11:53: [2024-10-30 17:11:53] iter = 17520, loss = 1.7451
2024-10-30 17:11:57: [2024-10-30 17:11:57] iter = 17530, loss = 1.8644
2024-10-30 17:12:00: [2024-10-30 17:12:00] iter = 17540, loss = 1.7385
2024-10-30 17:12:03: [2024-10-30 17:12:03] iter = 17550, loss = 2.3077
2024-10-30 17:12:07: [2024-10-30 17:12:07] iter = 17560, loss = 1.9732
2024-10-30 17:12:09: [2024-10-30 17:12:09] iter = 17570, loss = 2.9520
2024-10-30 17:12:12: [2024-10-30 17:12:12] iter = 17580, loss = 3.9647
2024-10-30 17:12:17: [2024-10-30 17:12:17] iter = 17590, loss = 2.2091
2024-10-30 17:12:20: [2024-10-30 17:12:20] iter = 17600, loss = 6.5617
2024-10-30 17:12:24: [2024-10-30 17:12:24] iter = 17610, loss = 2.1407
2024-10-30 17:12:27: [2024-10-30 17:12:27] iter = 17620, loss = 2.2624
2024-10-30 17:12:30: [2024-10-30 17:12:30] iter = 17630, loss = 3.2957
2024-10-30 17:12:35: [2024-10-30 17:12:35] iter = 17640, loss = 2.4918
2024-10-30 17:12:39: [2024-10-30 17:12:39] iter = 17650, loss = 2.0756
2024-10-30 17:12:42: [2024-10-30 17:12:42] iter = 17660, loss = 4.5106
2024-10-30 17:12:46: [2024-10-30 17:12:46] iter = 17670, loss = 1.6361
2024-10-30 17:12:51: [2024-10-30 17:12:51] iter = 17680, loss = 2.1295
2024-10-30 17:12:55: [2024-10-30 17:12:55] iter = 17690, loss = 1.9162
2024-10-30 17:12:59: [2024-10-30 17:12:59] iter = 17700, loss = 1.8428
2024-10-30 17:13:02: [2024-10-30 17:13:02] iter = 17710, loss = 1.6164
2024-10-30 17:13:06: [2024-10-30 17:13:06] iter = 17720, loss = 2.4917
2024-10-30 17:13:09: [2024-10-30 17:13:09] iter = 17730, loss = 2.3187
2024-10-30 17:13:12: [2024-10-30 17:13:12] iter = 17740, loss = 3.3352
2024-10-30 17:13:17: [2024-10-30 17:13:17] iter = 17750, loss = 3.0170
2024-10-30 17:13:20: [2024-10-30 17:13:20] iter = 17760, loss = 3.5721
2024-10-30 17:13:24: [2024-10-30 17:13:24] iter = 17770, loss = 1.7923
2024-10-30 17:13:28: [2024-10-30 17:13:28] iter = 17780, loss = 2.3179
2024-10-30 17:13:32: [2024-10-30 17:13:32] iter = 17790, loss = 2.1801
2024-10-30 17:13:36: [2024-10-30 17:13:36] iter = 17800, loss = 1.6751
2024-10-30 17:13:40: [2024-10-30 17:13:40] iter = 17810, loss = 1.9062
2024-10-30 17:13:43: [2024-10-30 17:13:43] iter = 17820, loss = 1.9309
2024-10-30 17:13:46: [2024-10-30 17:13:46] iter = 17830, loss = 1.9208
2024-10-30 17:13:50: [2024-10-30 17:13:50] iter = 17840, loss = 1.8217
2024-10-30 17:13:53: [2024-10-30 17:13:53] iter = 17850, loss = 2.0351
2024-10-30 17:13:57: [2024-10-30 17:13:57] iter = 17860, loss = 3.1271
2024-10-30 17:14:00: [2024-10-30 17:14:00] iter = 17870, loss = 2.6609
2024-10-30 17:14:03: [2024-10-30 17:14:03] iter = 17880, loss = 2.2789
2024-10-30 17:14:06: [2024-10-30 17:14:06] iter = 17890, loss = 2.3370
2024-10-30 17:14:11: [2024-10-30 17:14:11] iter = 17900, loss = 2.1707
2024-10-30 17:14:15: [2024-10-30 17:14:15] iter = 17910, loss = 1.8914
2024-10-30 17:14:19: [2024-10-30 17:14:19] iter = 17920, loss = 1.9464
2024-10-30 17:14:23: [2024-10-30 17:14:23] iter = 17930, loss = 2.0031
2024-10-30 17:14:26: [2024-10-30 17:14:26] iter = 17940, loss = 2.0687
2024-10-30 17:14:30: [2024-10-30 17:14:30] iter = 17950, loss = 1.9932
2024-10-30 17:14:34: [2024-10-30 17:14:34] iter = 17960, loss = 1.9722
2024-10-30 17:14:39: [2024-10-30 17:14:39] iter = 17970, loss = 1.7988
2024-10-30 17:14:44: [2024-10-30 17:14:44] iter = 17980, loss = 2.4461
2024-10-30 17:14:48: [2024-10-30 17:14:48] iter = 17990, loss = 2.7018
2024-10-30 17:14:52: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 17:14:52: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:14:52: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 92342}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:31: Evaluate 5 random ConvNet, ACCmean = 0.7779 ACCstd = 0.0021
-------------------------
2024-10-30 17:17:31: Evaluate 5 random ConvNet, SENmean = 0.7745 SENstd = 0.0022
-------------------------
2024-10-30 17:17:31: Evaluate 5 random ConvNet, SPEmean = 0.9776 SPEstd = 0.0002
-------------------------
2024-10-30 17:17:31: Evaluate 5 random ConvNet, F!mean = 0.7651 F!std = 0.0023
-------------------------
2024-10-30 17:17:31: Evaluate 5 random ConvNet, mean = 0.7779 std = 0.0021
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:32: [2024-10-30 17:17:32] iter = 18000, loss = 1.9674
2024-10-30 17:17:35: [2024-10-30 17:17:35] iter = 18010, loss = 2.0555
2024-10-30 17:17:39: [2024-10-30 17:17:39] iter = 18020, loss = 1.7254
2024-10-30 17:17:43: [2024-10-30 17:17:43] iter = 18030, loss = 2.2667
2024-10-30 17:17:47: [2024-10-30 17:17:47] iter = 18040, loss = 2.6227
2024-10-30 17:17:51: [2024-10-30 17:17:51] iter = 18050, loss = 1.9173
2024-10-30 17:17:55: [2024-10-30 17:17:55] iter = 18060, loss = 1.7144
2024-10-30 17:17:59: [2024-10-30 17:17:59] iter = 18070, loss = 1.7582
2024-10-30 17:18:04: [2024-10-30 17:18:04] iter = 18080, loss = 2.6960
2024-10-30 17:18:07: [2024-10-30 17:18:07] iter = 18090, loss = 2.8759
2024-10-30 17:18:11: [2024-10-30 17:18:11] iter = 18100, loss = 2.3035
2024-10-30 17:18:15: [2024-10-30 17:18:15] iter = 18110, loss = 1.9984
2024-10-30 17:18:19: [2024-10-30 17:18:19] iter = 18120, loss = 1.9735
2024-10-30 17:18:22: [2024-10-30 17:18:22] iter = 18130, loss = 1.9772
2024-10-30 17:18:26: [2024-10-30 17:18:26] iter = 18140, loss = 2.6624
2024-10-30 17:18:31: [2024-10-30 17:18:31] iter = 18150, loss = 1.9346
2024-10-30 17:18:36: [2024-10-30 17:18:36] iter = 18160, loss = 2.5648
2024-10-30 17:18:40: [2024-10-30 17:18:40] iter = 18170, loss = 2.2074
2024-10-30 17:18:45: [2024-10-30 17:18:45] iter = 18180, loss = 2.1036
2024-10-30 17:18:51: [2024-10-30 17:18:51] iter = 18190, loss = 1.8670
2024-10-30 17:18:54: [2024-10-30 17:18:54] iter = 18200, loss = 1.7620
2024-10-30 17:18:58: [2024-10-30 17:18:58] iter = 18210, loss = 1.7232
2024-10-30 17:19:03: [2024-10-30 17:19:03] iter = 18220, loss = 1.7780
2024-10-30 17:19:07: [2024-10-30 17:19:07] iter = 18230, loss = 2.0821
2024-10-30 17:19:11: [2024-10-30 17:19:11] iter = 18240, loss = 1.7040
2024-10-30 17:19:15: [2024-10-30 17:19:15] iter = 18250, loss = 2.3040
2024-10-30 17:19:19: [2024-10-30 17:19:19] iter = 18260, loss = 2.0162
2024-10-30 17:19:23: [2024-10-30 17:19:23] iter = 18270, loss = 2.0633
2024-10-30 17:19:27: [2024-10-30 17:19:27] iter = 18280, loss = 2.3530
2024-10-30 17:19:30: [2024-10-30 17:19:30] iter = 18290, loss = 1.7376
2024-10-30 17:19:34: [2024-10-30 17:19:34] iter = 18300, loss = 1.7501
2024-10-30 17:19:39: [2024-10-30 17:19:39] iter = 18310, loss = 2.3289
2024-10-30 17:19:43: [2024-10-30 17:19:43] iter = 18320, loss = 1.6080
2024-10-30 17:19:47: [2024-10-30 17:19:47] iter = 18330, loss = 2.2858
2024-10-30 17:19:50: [2024-10-30 17:19:50] iter = 18340, loss = 1.6988
2024-10-30 17:19:55: [2024-10-30 17:19:55] iter = 18350, loss = 1.7257
2024-10-30 17:19:59: [2024-10-30 17:19:59] iter = 18360, loss = 2.5793
2024-10-30 17:20:03: [2024-10-30 17:20:03] iter = 18370, loss = 2.0352
2024-10-30 17:20:08: [2024-10-30 17:20:08] iter = 18380, loss = 2.1239
2024-10-30 17:20:12: [2024-10-30 17:20:12] iter = 18390, loss = 1.9576
2024-10-30 17:20:15: [2024-10-30 17:20:15] iter = 18400, loss = 2.2225
2024-10-30 17:20:20: [2024-10-30 17:20:20] iter = 18410, loss = 1.8519
2024-10-30 17:20:24: [2024-10-30 17:20:24] iter = 18420, loss = 1.8231
2024-10-30 17:20:27: [2024-10-30 17:20:27] iter = 18430, loss = 1.7892
2024-10-30 17:20:31: [2024-10-30 17:20:31] iter = 18440, loss = 1.9681
2024-10-30 17:20:35: [2024-10-30 17:20:35] iter = 18450, loss = 2.8244
2024-10-30 17:20:39: [2024-10-30 17:20:39] iter = 18460, loss = 1.6452
2024-10-30 17:20:43: [2024-10-30 17:20:43] iter = 18470, loss = 2.0976
2024-10-30 17:20:46: [2024-10-30 17:20:46] iter = 18480, loss = 3.8832
2024-10-30 17:20:51: [2024-10-30 17:20:51] iter = 18490, loss = 2.5490
2024-10-30 17:20:54: [2024-10-30 17:20:54] iter = 18500, loss = 2.1765
2024-10-30 17:20:58: [2024-10-30 17:20:58] iter = 18510, loss = 2.1060
2024-10-30 17:21:02: [2024-10-30 17:21:02] iter = 18520, loss = 1.8723
2024-10-30 17:21:06: [2024-10-30 17:21:06] iter = 18530, loss = 1.9769
2024-10-30 17:21:10: [2024-10-30 17:21:10] iter = 18540, loss = 1.8948
2024-10-30 17:21:14: [2024-10-30 17:21:14] iter = 18550, loss = 1.6021
2024-10-30 17:21:18: [2024-10-30 17:21:18] iter = 18560, loss = 1.8538
2024-10-30 17:21:21: [2024-10-30 17:21:21] iter = 18570, loss = 2.0770
2024-10-30 17:21:25: [2024-10-30 17:21:25] iter = 18580, loss = 2.2765
2024-10-30 17:21:29: [2024-10-30 17:21:29] iter = 18590, loss = 2.0068
2024-10-30 17:21:33: [2024-10-30 17:21:33] iter = 18600, loss = 2.2118
2024-10-30 17:21:36: [2024-10-30 17:21:36] iter = 18610, loss = 3.0123
2024-10-30 17:21:40: [2024-10-30 17:21:40] iter = 18620, loss = 2.6766
2024-10-30 17:21:43: [2024-10-30 17:21:43] iter = 18630, loss = 2.8114
2024-10-30 17:21:48: [2024-10-30 17:21:47] iter = 18640, loss = 1.9615
2024-10-30 17:21:51: [2024-10-30 17:21:51] iter = 18650, loss = 2.3632
2024-10-30 17:21:53: [2024-10-30 17:21:53] iter = 18660, loss = 2.0633
2024-10-30 17:21:55: [2024-10-30 17:21:55] iter = 18670, loss = 1.7489
2024-10-30 17:21:59: [2024-10-30 17:21:59] iter = 18680, loss = 1.7963
2024-10-30 17:22:03: [2024-10-30 17:22:03] iter = 18690, loss = 2.6219
2024-10-30 17:22:07: [2024-10-30 17:22:07] iter = 18700, loss = 1.8315
2024-10-30 17:22:11: [2024-10-30 17:22:11] iter = 18710, loss = 1.6958
2024-10-30 17:22:16: [2024-10-30 17:22:16] iter = 18720, loss = 2.4183
2024-10-30 17:22:19: [2024-10-30 17:22:19] iter = 18730, loss = 2.1519
2024-10-30 17:22:22: [2024-10-30 17:22:22] iter = 18740, loss = 1.8810
2024-10-30 17:22:27: [2024-10-30 17:22:27] iter = 18750, loss = 1.7449
2024-10-30 17:22:31: [2024-10-30 17:22:31] iter = 18760, loss = 2.0456
2024-10-30 17:22:35: [2024-10-30 17:22:35] iter = 18770, loss = 2.4561
2024-10-30 17:22:39: [2024-10-30 17:22:39] iter = 18780, loss = 1.6100
2024-10-30 17:22:42: [2024-10-30 17:22:42] iter = 18790, loss = 2.6503
2024-10-30 17:22:47: [2024-10-30 17:22:47] iter = 18800, loss = 1.8773
2024-10-30 17:22:51: [2024-10-30 17:22:51] iter = 18810, loss = 1.9244
2024-10-30 17:22:55: [2024-10-30 17:22:55] iter = 18820, loss = 2.7201
2024-10-30 17:22:59: [2024-10-30 17:22:59] iter = 18830, loss = 2.3174
2024-10-30 17:23:03: [2024-10-30 17:23:03] iter = 18840, loss = 2.4831
2024-10-30 17:23:06: [2024-10-30 17:23:06] iter = 18850, loss = 2.0818
2024-10-30 17:23:09: [2024-10-30 17:23:09] iter = 18860, loss = 2.0177
2024-10-30 17:23:14: [2024-10-30 17:23:14] iter = 18870, loss = 1.9618
2024-10-30 17:23:18: [2024-10-30 17:23:18] iter = 18880, loss = 1.9203
2024-10-30 17:23:22: [2024-10-30 17:23:22] iter = 18890, loss = 1.8275
2024-10-30 17:23:26: [2024-10-30 17:23:26] iter = 18900, loss = 2.5387
2024-10-30 17:23:30: [2024-10-30 17:23:30] iter = 18910, loss = 2.8495
2024-10-30 17:23:35: [2024-10-30 17:23:35] iter = 18920, loss = 1.7180
2024-10-30 17:23:39: [2024-10-30 17:23:39] iter = 18930, loss = 2.5265
2024-10-30 17:23:43: [2024-10-30 17:23:43] iter = 18940, loss = 1.8590
2024-10-30 17:23:48: [2024-10-30 17:23:48] iter = 18950, loss = 2.5201
2024-10-30 17:23:51: [2024-10-30 17:23:51] iter = 18960, loss = 2.1728
2024-10-30 17:23:54: [2024-10-30 17:23:54] iter = 18970, loss = 2.1678
2024-10-30 17:23:58: [2024-10-30 17:23:58] iter = 18980, loss = 2.1153
2024-10-30 17:24:04: [2024-10-30 17:24:04] iter = 18990, loss = 2.5862
2024-10-30 17:24:08: [2024-10-30 17:24:08] iter = 19000, loss = 2.5561
2024-10-30 17:24:12: [2024-10-30 17:24:12] iter = 19010, loss = 2.5154
2024-10-30 17:24:17: [2024-10-30 17:24:17] iter = 19020, loss = 1.8972
2024-10-30 17:24:21: [2024-10-30 17:24:21] iter = 19030, loss = 1.7993
2024-10-30 17:24:26: [2024-10-30 17:24:26] iter = 19040, loss = 1.6645
2024-10-30 17:24:30: [2024-10-30 17:24:30] iter = 19050, loss = 2.2688
2024-10-30 17:24:36: [2024-10-30 17:24:36] iter = 19060, loss = 1.6547
2024-10-30 17:24:40: [2024-10-30 17:24:40] iter = 19070, loss = 2.1222
2024-10-30 17:24:45: [2024-10-30 17:24:45] iter = 19080, loss = 1.8618
2024-10-30 17:24:50: [2024-10-30 17:24:50] iter = 19090, loss = 1.8392
2024-10-30 17:24:54: [2024-10-30 17:24:54] iter = 19100, loss = 1.8802
2024-10-30 17:24:59: [2024-10-30 17:24:59] iter = 19110, loss = 2.2808
2024-10-30 17:25:03: [2024-10-30 17:25:03] iter = 19120, loss = 2.0787
2024-10-30 17:25:07: [2024-10-30 17:25:07] iter = 19130, loss = 1.8145
2024-10-30 17:25:12: [2024-10-30 17:25:12] iter = 19140, loss = 2.2824
2024-10-30 17:25:17: [2024-10-30 17:25:17] iter = 19150, loss = 2.0753
2024-10-30 17:25:22: [2024-10-30 17:25:22] iter = 19160, loss = 1.6517
2024-10-30 17:25:27: [2024-10-30 17:25:27] iter = 19170, loss = 1.7973
2024-10-30 17:25:32: [2024-10-30 17:25:32] iter = 19180, loss = 1.8975
2024-10-30 17:25:36: [2024-10-30 17:25:36] iter = 19190, loss = 1.7986
2024-10-30 17:25:40: [2024-10-30 17:25:40] iter = 19200, loss = 1.7639
2024-10-30 17:25:44: [2024-10-30 17:25:44] iter = 19210, loss = 5.7070
2024-10-30 17:25:49: [2024-10-30 17:25:49] iter = 19220, loss = 1.7558
2024-10-30 17:25:52: [2024-10-30 17:25:52] iter = 19230, loss = 2.4487
2024-10-30 17:25:57: [2024-10-30 17:25:57] iter = 19240, loss = 1.7750
2024-10-30 17:26:02: [2024-10-30 17:26:02] iter = 19250, loss = 3.2226
2024-10-30 17:26:05: [2024-10-30 17:26:04] iter = 19260, loss = 1.7874
2024-10-30 17:26:08: [2024-10-30 17:26:08] iter = 19270, loss = 2.0882
2024-10-30 17:26:11: [2024-10-30 17:26:11] iter = 19280, loss = 2.7899
2024-10-30 17:26:14: [2024-10-30 17:26:14] iter = 19290, loss = 2.2586
2024-10-30 17:26:18: [2024-10-30 17:26:18] iter = 19300, loss = 2.0236
2024-10-30 17:26:22: [2024-10-30 17:26:22] iter = 19310, loss = 1.6446
2024-10-30 17:26:28: [2024-10-30 17:26:28] iter = 19320, loss = 2.5340
2024-10-30 17:26:32: [2024-10-30 17:26:32] iter = 19330, loss = 2.5847
2024-10-30 17:26:35: [2024-10-30 17:26:35] iter = 19340, loss = 1.8916
2024-10-30 17:26:39: [2024-10-30 17:26:39] iter = 19350, loss = 2.3247
2024-10-30 17:26:42: [2024-10-30 17:26:42] iter = 19360, loss = 1.9802
2024-10-30 17:26:46: [2024-10-30 17:26:46] iter = 19370, loss = 3.1326
2024-10-30 17:26:50: [2024-10-30 17:26:50] iter = 19380, loss = 2.1474
2024-10-30 17:26:54: [2024-10-30 17:26:54] iter = 19390, loss = 1.7931
2024-10-30 17:26:58: [2024-10-30 17:26:58] iter = 19400, loss = 2.6641
2024-10-30 17:27:03: [2024-10-30 17:27:03] iter = 19410, loss = 2.1686
2024-10-30 17:27:06: [2024-10-30 17:27:06] iter = 19420, loss = 1.9281
2024-10-30 17:27:10: [2024-10-30 17:27:10] iter = 19430, loss = 1.8874
2024-10-30 17:27:14: [2024-10-30 17:27:14] iter = 19440, loss = 2.5274
2024-10-30 17:27:19: [2024-10-30 17:27:19] iter = 19450, loss = 3.8525
2024-10-30 17:27:23: [2024-10-30 17:27:23] iter = 19460, loss = 2.0156
2024-10-30 17:27:28: [2024-10-30 17:27:28] iter = 19470, loss = 1.7863
2024-10-30 17:27:31: [2024-10-30 17:27:31] iter = 19480, loss = 1.8417
2024-10-30 17:27:36: [2024-10-30 17:27:36] iter = 19490, loss = 1.5926
2024-10-30 17:27:40: [2024-10-30 17:27:40] iter = 19500, loss = 2.0327
2024-10-30 17:27:44: [2024-10-30 17:27:44] iter = 19510, loss = 2.2185
2024-10-30 17:27:48: [2024-10-30 17:27:48] iter = 19520, loss = 2.0592
2024-10-30 17:27:51: [2024-10-30 17:27:51] iter = 19530, loss = 2.0553
2024-10-30 17:27:56: [2024-10-30 17:27:56] iter = 19540, loss = 1.8444
2024-10-30 17:28:00: [2024-10-30 17:28:00] iter = 19550, loss = 2.3613
2024-10-30 17:28:04: [2024-10-30 17:28:04] iter = 19560, loss = 1.6817
2024-10-30 17:28:08: [2024-10-30 17:28:08] iter = 19570, loss = 1.9319
2024-10-30 17:28:13: [2024-10-30 17:28:13] iter = 19580, loss = 3.1243
2024-10-30 17:28:17: [2024-10-30 17:28:17] iter = 19590, loss = 3.3472
2024-10-30 17:28:20: [2024-10-30 17:28:20] iter = 19600, loss = 1.7091
2024-10-30 17:28:23: [2024-10-30 17:28:23] iter = 19610, loss = 2.2213
2024-10-30 17:28:27: [2024-10-30 17:28:27] iter = 19620, loss = 2.5908
2024-10-30 17:28:30: [2024-10-30 17:28:30] iter = 19630, loss = 1.8247
2024-10-30 17:28:34: [2024-10-30 17:28:34] iter = 19640, loss = 1.9845
2024-10-30 17:28:39: [2024-10-30 17:28:39] iter = 19650, loss = 2.5951
2024-10-30 17:28:43: [2024-10-30 17:28:43] iter = 19660, loss = 1.9747
2024-10-30 17:28:47: [2024-10-30 17:28:47] iter = 19670, loss = 3.3317
2024-10-30 17:28:50: [2024-10-30 17:28:50] iter = 19680, loss = 1.9942
2024-10-30 17:28:54: [2024-10-30 17:28:54] iter = 19690, loss = 2.2842
2024-10-30 17:28:58: [2024-10-30 17:28:58] iter = 19700, loss = 2.1897
2024-10-30 17:29:02: [2024-10-30 17:29:02] iter = 19710, loss = 1.6713
2024-10-30 17:29:05: [2024-10-30 17:29:05] iter = 19720, loss = 3.3165
2024-10-30 17:29:09: [2024-10-30 17:29:09] iter = 19730, loss = 1.6772
2024-10-30 17:29:14: [2024-10-30 17:29:14] iter = 19740, loss = 2.1094
2024-10-30 17:29:19: [2024-10-30 17:29:19] iter = 19750, loss = 2.9836
2024-10-30 17:29:23: [2024-10-30 17:29:23] iter = 19760, loss = 2.1481
2024-10-30 17:29:27: [2024-10-30 17:29:27] iter = 19770, loss = 2.2440
2024-10-30 17:29:31: [2024-10-30 17:29:31] iter = 19780, loss = 2.0989
2024-10-30 17:29:36: [2024-10-30 17:29:36] iter = 19790, loss = 1.8970
2024-10-30 17:29:40: [2024-10-30 17:29:40] iter = 19800, loss = 2.2420
2024-10-30 17:29:43: [2024-10-30 17:29:43] iter = 19810, loss = 1.5207
2024-10-30 17:29:47: [2024-10-30 17:29:47] iter = 19820, loss = 2.4938
2024-10-30 17:29:51: [2024-10-30 17:29:51] iter = 19830, loss = 2.2484
2024-10-30 17:29:55: [2024-10-30 17:29:55] iter = 19840, loss = 2.7181
2024-10-30 17:29:59: [2024-10-30 17:29:59] iter = 19850, loss = 2.7463
2024-10-30 17:30:02: [2024-10-30 17:30:02] iter = 19860, loss = 2.1364
2024-10-30 17:30:04: [2024-10-30 17:30:04] iter = 19870, loss = 1.7065
2024-10-30 17:30:07: [2024-10-30 17:30:07] iter = 19880, loss = 1.9645
2024-10-30 17:30:10: [2024-10-30 17:30:10] iter = 19890, loss = 1.9513
2024-10-30 17:30:15: [2024-10-30 17:30:15] iter = 19900, loss = 1.5599
2024-10-30 17:30:20: [2024-10-30 17:30:20] iter = 19910, loss = 1.8908
2024-10-30 17:30:24: [2024-10-30 17:30:24] iter = 19920, loss = 1.7098
2024-10-30 17:30:27: [2024-10-30 17:30:27] iter = 19930, loss = 1.8884
2024-10-30 17:30:31: [2024-10-30 17:30:31] iter = 19940, loss = 1.5890
2024-10-30 17:30:35: [2024-10-30 17:30:35] iter = 19950, loss = 2.1725
2024-10-30 17:30:38: [2024-10-30 17:30:38] iter = 19960, loss = 1.8922
2024-10-30 17:30:42: [2024-10-30 17:30:42] iter = 19970, loss = 2.1450
2024-10-30 17:30:46: [2024-10-30 17:30:46] iter = 19980, loss = 1.8818
2024-10-30 17:30:51: [2024-10-30 17:30:51] iter = 19990, loss = 2.3811
2024-10-30 17:30:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 17:30:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:30:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 54768}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:12: Evaluate 5 random ConvNet, ACCmean = 0.7806 ACCstd = 0.0031
-------------------------
2024-10-30 17:33:12: Evaluate 5 random ConvNet, SENmean = 0.7741 SENstd = 0.0029
-------------------------
2024-10-30 17:33:12: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0003
-------------------------
2024-10-30 17:33:12: Evaluate 5 random ConvNet, F!mean = 0.7672 F!std = 0.0023
-------------------------
2024-10-30 17:33:12: Evaluate 5 random ConvNet, mean = 0.7806 std = 0.0031
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:13: [2024-10-30 17:33:13] iter = 20000, loss = 2.5907
2024-10-30 17:33:13: 
================== Exp 1 ==================
 
2024-10-30 17:33:13: Hyper-parameters: 
{'dataset': 'OrganCMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f9aa0d64b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganCMNIST (INFO)>}
2024-10-30 17:33:13: Evaluation model pool: ['ConvNet']
2024-10-30 17:33:14: class c = 0: 1148 real images
2024-10-30 17:33:14: class c = 1: 619 real images
2024-10-30 17:33:14: class c = 2: 595 real images
2024-10-30 17:33:14: class c = 3: 600 real images
2024-10-30 17:33:14: class c = 4: 1088 real images
2024-10-30 17:33:14: class c = 5: 1170 real images
2024-10-30 17:33:14: class c = 6: 2986 real images
2024-10-30 17:33:14: class c = 7: 1002 real images
2024-10-30 17:33:14: class c = 8: 1022 real images
2024-10-30 17:33:14: class c = 9: 1173 real images
2024-10-30 17:33:14: class c = 10: 1572 real images
2024-10-30 17:33:14: real images channel 0, mean = 0.4942, std = 0.2834
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 17:33:14: initialize synthetic data from random real images
2024-10-30 17:33:14: [2024-10-30 17:33:14] training begins
2024-10-30 17:33:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 17:33:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:33:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 93059}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:41: Evaluate 5 random ConvNet, ACCmean = 0.6992 ACCstd = 0.0019
-------------------------
2024-10-30 17:35:41: Evaluate 5 random ConvNet, SENmean = 0.6946 SENstd = 0.0019
-------------------------
2024-10-30 17:35:41: Evaluate 5 random ConvNet, SPEmean = 0.9696 SPEstd = 0.0002
-------------------------
2024-10-30 17:35:41: Evaluate 5 random ConvNet, F!mean = 0.6841 F!std = 0.0025
-------------------------
2024-10-30 17:35:41: Evaluate 5 random ConvNet, mean = 0.6992 std = 0.0019
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:42: [2024-10-30 17:35:42] iter = 00000, loss = 12.0661
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:46: [2024-10-30 17:35:46] iter = 00010, loss = 4.0718
2024-10-30 17:35:50: [2024-10-30 17:35:50] iter = 00020, loss = 3.7970
2024-10-30 17:35:54: [2024-10-30 17:35:54] iter = 00030, loss = 3.1263
2024-10-30 17:35:58: [2024-10-30 17:35:58] iter = 00040, loss = 4.0759
2024-10-30 17:36:02: [2024-10-30 17:36:02] iter = 00050, loss = 2.7753
2024-10-30 17:36:06: [2024-10-30 17:36:06] iter = 00060, loss = 3.5680
2024-10-30 17:36:09: [2024-10-30 17:36:09] iter = 00070, loss = 2.6255
2024-10-30 17:36:13: [2024-10-30 17:36:13] iter = 00080, loss = 3.1398
2024-10-30 17:36:16: [2024-10-30 17:36:16] iter = 00090, loss = 3.3047
2024-10-30 17:36:21: [2024-10-30 17:36:21] iter = 00100, loss = 2.9724
2024-10-30 17:36:25: [2024-10-30 17:36:25] iter = 00110, loss = 2.2135
2024-10-30 17:36:28: [2024-10-30 17:36:28] iter = 00120, loss = 2.7345
2024-10-30 17:36:32: [2024-10-30 17:36:32] iter = 00130, loss = 3.1250
2024-10-30 17:36:36: [2024-10-30 17:36:36] iter = 00140, loss = 2.6888
2024-10-30 17:36:40: [2024-10-30 17:36:40] iter = 00150, loss = 2.8793
2024-10-30 17:36:43: [2024-10-30 17:36:43] iter = 00160, loss = 2.6716
2024-10-30 17:36:47: [2024-10-30 17:36:47] iter = 00170, loss = 2.4377
2024-10-30 17:36:50: [2024-10-30 17:36:50] iter = 00180, loss = 2.6701
2024-10-30 17:36:54: [2024-10-30 17:36:54] iter = 00190, loss = 2.3901
2024-10-30 17:36:58: [2024-10-30 17:36:58] iter = 00200, loss = 2.4517
2024-10-30 17:37:01: [2024-10-30 17:37:01] iter = 00210, loss = 3.4415
2024-10-30 17:37:04: [2024-10-30 17:37:04] iter = 00220, loss = 2.5747
2024-10-30 17:37:08: [2024-10-30 17:37:08] iter = 00230, loss = 3.0040
2024-10-30 17:37:12: [2024-10-30 17:37:12] iter = 00240, loss = 2.6408
2024-10-30 17:37:16: [2024-10-30 17:37:16] iter = 00250, loss = 2.3000
2024-10-30 17:37:19: [2024-10-30 17:37:19] iter = 00260, loss = 3.5130
2024-10-30 17:37:21: [2024-10-30 17:37:21] iter = 00270, loss = 4.1715
2024-10-30 17:37:25: [2024-10-30 17:37:25] iter = 00280, loss = 2.1227
2024-10-30 17:37:28: [2024-10-30 17:37:28] iter = 00290, loss = 2.0992
2024-10-30 17:37:32: [2024-10-30 17:37:32] iter = 00300, loss = 2.3305
2024-10-30 17:37:36: [2024-10-30 17:37:36] iter = 00310, loss = 2.5943
2024-10-30 17:37:40: [2024-10-30 17:37:40] iter = 00320, loss = 2.3054
2024-10-30 17:37:45: [2024-10-30 17:37:45] iter = 00330, loss = 2.4043
2024-10-30 17:37:49: [2024-10-30 17:37:49] iter = 00340, loss = 2.6623
2024-10-30 17:37:53: [2024-10-30 17:37:53] iter = 00350, loss = 3.8136
2024-10-30 17:37:57: [2024-10-30 17:37:57] iter = 00360, loss = 3.7083
2024-10-30 17:38:01: [2024-10-30 17:38:01] iter = 00370, loss = 2.9562
2024-10-30 17:38:04: [2024-10-30 17:38:04] iter = 00380, loss = 2.2286
2024-10-30 17:38:07: [2024-10-30 17:38:07] iter = 00390, loss = 2.5181
2024-10-30 17:38:10: [2024-10-30 17:38:10] iter = 00400, loss = 2.4026
2024-10-30 17:38:14: [2024-10-30 17:38:14] iter = 00410, loss = 2.4504
2024-10-30 17:38:18: [2024-10-30 17:38:18] iter = 00420, loss = 2.7784
2024-10-30 17:38:21: [2024-10-30 17:38:21] iter = 00430, loss = 2.3935
2024-10-30 17:38:25: [2024-10-30 17:38:25] iter = 00440, loss = 2.6091
2024-10-30 17:38:29: [2024-10-30 17:38:29] iter = 00450, loss = 2.3220
2024-10-30 17:38:32: [2024-10-30 17:38:32] iter = 00460, loss = 3.1561
2024-10-30 17:38:36: [2024-10-30 17:38:36] iter = 00470, loss = 2.6353
2024-10-30 17:38:40: [2024-10-30 17:38:39] iter = 00480, loss = 1.9417
2024-10-30 17:38:43: [2024-10-30 17:38:43] iter = 00490, loss = 2.2486
2024-10-30 17:38:47: [2024-10-30 17:38:47] iter = 00500, loss = 2.0520
2024-10-30 17:38:49: [2024-10-30 17:38:49] iter = 00510, loss = 4.9726
2024-10-30 17:38:52: [2024-10-30 17:38:52] iter = 00520, loss = 2.4417
2024-10-30 17:38:56: [2024-10-30 17:38:56] iter = 00530, loss = 2.3506
2024-10-30 17:38:59: [2024-10-30 17:38:59] iter = 00540, loss = 2.0895
2024-10-30 17:39:03: [2024-10-30 17:39:03] iter = 00550, loss = 2.3498
2024-10-30 17:39:06: [2024-10-30 17:39:06] iter = 00560, loss = 2.2493
2024-10-30 17:39:09: [2024-10-30 17:39:09] iter = 00570, loss = 2.4213
2024-10-30 17:39:13: [2024-10-30 17:39:13] iter = 00580, loss = 2.3768
2024-10-30 17:39:16: [2024-10-30 17:39:16] iter = 00590, loss = 2.6453
2024-10-30 17:39:20: [2024-10-30 17:39:20] iter = 00600, loss = 2.5688
2024-10-30 17:39:24: [2024-10-30 17:39:24] iter = 00610, loss = 2.0333
2024-10-30 17:39:27: [2024-10-30 17:39:27] iter = 00620, loss = 2.4640
2024-10-30 17:39:32: [2024-10-30 17:39:32] iter = 00630, loss = 2.8041
2024-10-30 17:39:35: [2024-10-30 17:39:35] iter = 00640, loss = 2.3283
2024-10-30 17:39:38: [2024-10-30 17:39:38] iter = 00650, loss = 2.2886
2024-10-30 17:39:43: [2024-10-30 17:39:43] iter = 00660, loss = 2.0696
2024-10-30 17:39:47: [2024-10-30 17:39:47] iter = 00670, loss = 2.5372
2024-10-30 17:39:51: [2024-10-30 17:39:51] iter = 00680, loss = 2.0491
2024-10-30 17:39:54: [2024-10-30 17:39:54] iter = 00690, loss = 2.2319
2024-10-30 17:39:58: [2024-10-30 17:39:58] iter = 00700, loss = 2.2716
2024-10-30 17:40:02: [2024-10-30 17:40:02] iter = 00710, loss = 1.9913
2024-10-30 17:40:05: [2024-10-30 17:40:05] iter = 00720, loss = 1.7358
2024-10-30 17:40:09: [2024-10-30 17:40:09] iter = 00730, loss = 2.6322
2024-10-30 17:40:14: [2024-10-30 17:40:14] iter = 00740, loss = 2.3033
2024-10-30 17:40:18: [2024-10-30 17:40:18] iter = 00750, loss = 2.2504
2024-10-30 17:40:22: [2024-10-30 17:40:22] iter = 00760, loss = 2.9351
2024-10-30 17:40:26: [2024-10-30 17:40:26] iter = 00770, loss = 2.2321
2024-10-30 17:40:30: [2024-10-30 17:40:30] iter = 00780, loss = 2.1123
2024-10-30 17:40:33: [2024-10-30 17:40:33] iter = 00790, loss = 2.2033
2024-10-30 17:40:37: [2024-10-30 17:40:37] iter = 00800, loss = 2.0802
2024-10-30 17:40:41: [2024-10-30 17:40:41] iter = 00810, loss = 2.0478
2024-10-30 17:40:44: [2024-10-30 17:40:44] iter = 00820, loss = 2.3219
2024-10-30 17:40:47: [2024-10-30 17:40:47] iter = 00830, loss = 2.0981
2024-10-30 17:40:52: [2024-10-30 17:40:52] iter = 00840, loss = 2.3389
2024-10-30 17:40:55: [2024-10-30 17:40:55] iter = 00850, loss = 1.8932
2024-10-30 17:40:59: [2024-10-30 17:40:59] iter = 00860, loss = 2.0735
2024-10-30 17:41:02: [2024-10-30 17:41:02] iter = 00870, loss = 2.4135
2024-10-30 17:41:07: [2024-10-30 17:41:07] iter = 00880, loss = 2.4871
2024-10-30 17:41:11: [2024-10-30 17:41:11] iter = 00890, loss = 2.2127
2024-10-30 17:41:14: [2024-10-30 17:41:14] iter = 00900, loss = 2.9697
2024-10-30 17:41:18: [2024-10-30 17:41:18] iter = 00910, loss = 2.2609
2024-10-30 17:41:21: [2024-10-30 17:41:21] iter = 00920, loss = 2.0692
2024-10-30 17:41:25: [2024-10-30 17:41:25] iter = 00930, loss = 2.1741
2024-10-30 17:41:29: [2024-10-30 17:41:29] iter = 00940, loss = 2.1150
2024-10-30 17:41:32: [2024-10-30 17:41:32] iter = 00950, loss = 3.2195
2024-10-30 17:41:35: [2024-10-30 17:41:35] iter = 00960, loss = 2.1233
2024-10-30 17:41:38: [2024-10-30 17:41:38] iter = 00970, loss = 1.9448
2024-10-30 17:41:42: [2024-10-30 17:41:42] iter = 00980, loss = 2.8250
2024-10-30 17:41:44: [2024-10-30 17:41:44] iter = 00990, loss = 1.9242
2024-10-30 17:41:47: [2024-10-30 17:41:47] iter = 01000, loss = 2.7389
2024-10-30 17:41:51: [2024-10-30 17:41:51] iter = 01010, loss = 2.8019
2024-10-30 17:41:55: [2024-10-30 17:41:55] iter = 01020, loss = 2.0241
2024-10-30 17:41:59: [2024-10-30 17:41:59] iter = 01030, loss = 2.3648
2024-10-30 17:42:03: [2024-10-30 17:42:03] iter = 01040, loss = 1.9694
2024-10-30 17:42:07: [2024-10-30 17:42:07] iter = 01050, loss = 2.7757
2024-10-30 17:42:11: [2024-10-30 17:42:11] iter = 01060, loss = 1.9785
2024-10-30 17:42:14: [2024-10-30 17:42:14] iter = 01070, loss = 2.0924
2024-10-30 17:42:18: [2024-10-30 17:42:18] iter = 01080, loss = 2.1058
2024-10-30 17:42:22: [2024-10-30 17:42:22] iter = 01090, loss = 2.5351
2024-10-30 17:42:26: [2024-10-30 17:42:26] iter = 01100, loss = 2.4711
2024-10-30 17:42:30: [2024-10-30 17:42:30] iter = 01110, loss = 2.6160
2024-10-30 17:42:33: [2024-10-30 17:42:33] iter = 01120, loss = 2.3603
2024-10-30 17:42:36: [2024-10-30 17:42:36] iter = 01130, loss = 2.3403
2024-10-30 17:42:39: [2024-10-30 17:42:39] iter = 01140, loss = 2.5909
2024-10-30 17:42:42: [2024-10-30 17:42:42] iter = 01150, loss = 2.9056
2024-10-30 17:42:46: [2024-10-30 17:42:46] iter = 01160, loss = 2.7901
2024-10-30 17:42:50: [2024-10-30 17:42:50] iter = 01170, loss = 1.9742
2024-10-30 17:42:54: [2024-10-30 17:42:54] iter = 01180, loss = 2.1834
2024-10-30 17:42:57: [2024-10-30 17:42:57] iter = 01190, loss = 2.6046
2024-10-30 17:43:00: [2024-10-30 17:43:00] iter = 01200, loss = 4.6921
2024-10-30 17:43:03: [2024-10-30 17:43:03] iter = 01210, loss = 2.3243
2024-10-30 17:43:07: [2024-10-30 17:43:07] iter = 01220, loss = 4.5947
2024-10-30 17:43:11: [2024-10-30 17:43:11] iter = 01230, loss = 2.1332
2024-10-30 17:43:15: [2024-10-30 17:43:15] iter = 01240, loss = 1.7093
2024-10-30 17:43:19: [2024-10-30 17:43:19] iter = 01250, loss = 1.9678
2024-10-30 17:43:24: [2024-10-30 17:43:24] iter = 01260, loss = 5.3393
2024-10-30 17:43:27: [2024-10-30 17:43:27] iter = 01270, loss = 2.5397
2024-10-30 17:43:30: [2024-10-30 17:43:30] iter = 01280, loss = 3.3670
2024-10-30 17:43:34: [2024-10-30 17:43:34] iter = 01290, loss = 1.9764
2024-10-30 17:43:38: [2024-10-30 17:43:38] iter = 01300, loss = 2.1875
2024-10-30 17:43:42: [2024-10-30 17:43:42] iter = 01310, loss = 3.3830
2024-10-30 17:43:45: [2024-10-30 17:43:45] iter = 01320, loss = 2.4549
2024-10-30 17:43:49: [2024-10-30 17:43:49] iter = 01330, loss = 2.2437
2024-10-30 17:43:52: [2024-10-30 17:43:52] iter = 01340, loss = 3.7412
2024-10-30 17:43:57: [2024-10-30 17:43:57] iter = 01350, loss = 2.0673
2024-10-30 17:44:00: [2024-10-30 17:44:00] iter = 01360, loss = 3.1313
2024-10-30 17:44:04: [2024-10-30 17:44:04] iter = 01370, loss = 4.2204
2024-10-30 17:44:07: [2024-10-30 17:44:07] iter = 01380, loss = 2.2082
2024-10-30 17:44:10: [2024-10-30 17:44:10] iter = 01390, loss = 2.0609
2024-10-30 17:44:13: [2024-10-30 17:44:13] iter = 01400, loss = 2.1387
2024-10-30 17:44:17: [2024-10-30 17:44:17] iter = 01410, loss = 2.1654
2024-10-30 17:44:21: [2024-10-30 17:44:21] iter = 01420, loss = 1.9926
2024-10-30 17:44:25: [2024-10-30 17:44:25] iter = 01430, loss = 3.0726
2024-10-30 17:44:29: [2024-10-30 17:44:29] iter = 01440, loss = 1.9405
2024-10-30 17:44:32: [2024-10-30 17:44:32] iter = 01450, loss = 2.4014
2024-10-30 17:44:36: [2024-10-30 17:44:36] iter = 01460, loss = 3.0949
2024-10-30 17:44:39: [2024-10-30 17:44:39] iter = 01470, loss = 3.0738
2024-10-30 17:44:43: [2024-10-30 17:44:43] iter = 01480, loss = 2.2241
2024-10-30 17:44:48: [2024-10-30 17:44:48] iter = 01490, loss = 2.5396
2024-10-30 17:44:51: [2024-10-30 17:44:51] iter = 01500, loss = 2.1634
2024-10-30 17:44:54: [2024-10-30 17:44:54] iter = 01510, loss = 2.0977
2024-10-30 17:44:57: [2024-10-30 17:44:57] iter = 01520, loss = 1.9915
2024-10-30 17:45:01: [2024-10-30 17:45:01] iter = 01530, loss = 2.3062
2024-10-30 17:45:05: [2024-10-30 17:45:05] iter = 01540, loss = 1.8804
2024-10-30 17:45:08: [2024-10-30 17:45:08] iter = 01550, loss = 3.5130
2024-10-30 17:45:12: [2024-10-30 17:45:12] iter = 01560, loss = 1.7573
2024-10-30 17:45:13: [2024-10-30 17:45:13] iter = 01570, loss = 2.3574
2024-10-30 17:45:16: [2024-10-30 17:45:16] iter = 01580, loss = 2.9372
2024-10-30 17:45:19: [2024-10-30 17:45:19] iter = 01590, loss = 3.3085
2024-10-30 17:45:22: [2024-10-30 17:45:22] iter = 01600, loss = 1.9194
2024-10-30 17:45:25: [2024-10-30 17:45:25] iter = 01610, loss = 2.1256
2024-10-30 17:45:28: [2024-10-30 17:45:28] iter = 01620, loss = 2.1164
2024-10-30 17:45:31: [2024-10-30 17:45:31] iter = 01630, loss = 1.9773
2024-10-30 17:45:33: [2024-10-30 17:45:33] iter = 01640, loss = 2.1454
2024-10-30 17:45:36: [2024-10-30 17:45:36] iter = 01650, loss = 3.1638
2024-10-30 17:45:39: [2024-10-30 17:45:39] iter = 01660, loss = 2.5206
2024-10-30 17:45:42: [2024-10-30 17:45:42] iter = 01670, loss = 2.5751
2024-10-30 17:45:45: [2024-10-30 17:45:45] iter = 01680, loss = 2.1858
2024-10-30 17:45:49: [2024-10-30 17:45:49] iter = 01690, loss = 3.5698
2024-10-30 17:45:52: [2024-10-30 17:45:52] iter = 01700, loss = 3.5284
2024-10-30 17:45:55: [2024-10-30 17:45:55] iter = 01710, loss = 2.1058
2024-10-30 17:45:58: [2024-10-30 17:45:58] iter = 01720, loss = 2.6150
2024-10-30 17:46:01: [2024-10-30 17:46:01] iter = 01730, loss = 2.1922
2024-10-30 17:46:06: [2024-10-30 17:46:06] iter = 01740, loss = 1.6888
2024-10-30 17:46:09: [2024-10-30 17:46:09] iter = 01750, loss = 2.6497
2024-10-30 17:46:14: [2024-10-30 17:46:14] iter = 01760, loss = 6.2332
2024-10-30 17:46:17: [2024-10-30 17:46:17] iter = 01770, loss = 1.8484
2024-10-30 17:46:19: [2024-10-30 17:46:19] iter = 01780, loss = 2.3967
2024-10-30 17:46:23: [2024-10-30 17:46:23] iter = 01790, loss = 1.9926
2024-10-30 17:46:25: [2024-10-30 17:46:25] iter = 01800, loss = 1.8885
2024-10-30 17:46:27: [2024-10-30 17:46:27] iter = 01810, loss = 2.4298
2024-10-30 17:46:30: [2024-10-30 17:46:30] iter = 01820, loss = 2.9384
2024-10-30 17:46:32: [2024-10-30 17:46:32] iter = 01830, loss = 3.4925
2024-10-30 17:46:35: [2024-10-30 17:46:35] iter = 01840, loss = 2.2873
2024-10-30 17:46:39: [2024-10-30 17:46:39] iter = 01850, loss = 1.7479
2024-10-30 17:46:42: [2024-10-30 17:46:42] iter = 01860, loss = 3.3583
2024-10-30 17:46:45: [2024-10-30 17:46:45] iter = 01870, loss = 2.1625
2024-10-30 17:46:48: [2024-10-30 17:46:48] iter = 01880, loss = 2.6956
2024-10-30 17:46:52: [2024-10-30 17:46:52] iter = 01890, loss = 2.3054
2024-10-30 17:46:56: [2024-10-30 17:46:56] iter = 01900, loss = 2.0202
2024-10-30 17:47:00: [2024-10-30 17:47:00] iter = 01910, loss = 2.1359
2024-10-30 17:47:04: [2024-10-30 17:47:04] iter = 01920, loss = 2.0908
2024-10-30 17:47:06: [2024-10-30 17:47:06] iter = 01930, loss = 2.2833
2024-10-30 17:47:09: [2024-10-30 17:47:09] iter = 01940, loss = 2.5747
2024-10-30 17:47:12: [2024-10-30 17:47:12] iter = 01950, loss = 4.1941
2024-10-30 17:47:16: [2024-10-30 17:47:16] iter = 01960, loss = 1.9344
2024-10-30 17:47:19: [2024-10-30 17:47:19] iter = 01970, loss = 2.3593
2024-10-30 17:47:22: [2024-10-30 17:47:22] iter = 01980, loss = 2.8847
2024-10-30 17:47:26: [2024-10-30 17:47:26] iter = 01990, loss = 3.2836
2024-10-30 17:47:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 17:47:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:47:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50344}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:49: Evaluate 5 random ConvNet, ACCmean = 0.7829 ACCstd = 0.0024
-------------------------
2024-10-30 17:49:49: Evaluate 5 random ConvNet, SENmean = 0.7763 SENstd = 0.0031
-------------------------
2024-10-30 17:49:49: Evaluate 5 random ConvNet, SPEmean = 0.9781 SPEstd = 0.0003
-------------------------
2024-10-30 17:49:49: Evaluate 5 random ConvNet, F!mean = 0.7673 F!std = 0.0026
-------------------------
2024-10-30 17:49:49: Evaluate 5 random ConvNet, mean = 0.7829 std = 0.0024
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:49: [2024-10-30 17:49:49] iter = 02000, loss = 1.9105
2024-10-30 17:49:52: [2024-10-30 17:49:52] iter = 02010, loss = 2.5470
2024-10-30 17:49:56: [2024-10-30 17:49:56] iter = 02020, loss = 2.8959
2024-10-30 17:50:00: [2024-10-30 17:50:00] iter = 02030, loss = 1.7895
2024-10-30 17:50:03: [2024-10-30 17:50:03] iter = 02040, loss = 2.2154
2024-10-30 17:50:07: [2024-10-30 17:50:07] iter = 02050, loss = 2.6717
2024-10-30 17:50:10: [2024-10-30 17:50:10] iter = 02060, loss = 3.2432
2024-10-30 17:50:14: [2024-10-30 17:50:14] iter = 02070, loss = 2.1981
2024-10-30 17:50:17: [2024-10-30 17:50:17] iter = 02080, loss = 1.8777
2024-10-30 17:50:20: [2024-10-30 17:50:20] iter = 02090, loss = 1.8843
2024-10-30 17:50:23: [2024-10-30 17:50:23] iter = 02100, loss = 2.0588
2024-10-30 17:50:26: [2024-10-30 17:50:26] iter = 02110, loss = 2.8277
2024-10-30 17:50:30: [2024-10-30 17:50:30] iter = 02120, loss = 2.3150
2024-10-30 17:50:33: [2024-10-30 17:50:33] iter = 02130, loss = 2.4520
2024-10-30 17:50:36: [2024-10-30 17:50:36] iter = 02140, loss = 2.1800
2024-10-30 17:50:40: [2024-10-30 17:50:40] iter = 02150, loss = 2.8538
2024-10-30 17:50:45: [2024-10-30 17:50:45] iter = 02160, loss = 2.8938
2024-10-30 17:50:49: [2024-10-30 17:50:49] iter = 02170, loss = 2.4080
2024-10-30 17:50:53: [2024-10-30 17:50:53] iter = 02180, loss = 1.8955
2024-10-30 17:50:57: [2024-10-30 17:50:57] iter = 02190, loss = 2.5451
2024-10-30 17:51:00: [2024-10-30 17:51:00] iter = 02200, loss = 2.0471
2024-10-30 17:51:04: [2024-10-30 17:51:04] iter = 02210, loss = 2.7983
2024-10-30 17:51:07: [2024-10-30 17:51:07] iter = 02220, loss = 2.2816
2024-10-30 17:51:10: [2024-10-30 17:51:10] iter = 02230, loss = 1.8899
2024-10-30 17:51:13: [2024-10-30 17:51:13] iter = 02240, loss = 2.2775
2024-10-30 17:51:17: [2024-10-30 17:51:17] iter = 02250, loss = 2.1425
2024-10-30 17:51:19: [2024-10-30 17:51:19] iter = 02260, loss = 3.5696
2024-10-30 17:51:23: [2024-10-30 17:51:23] iter = 02270, loss = 2.1131
2024-10-30 17:51:26: [2024-10-30 17:51:26] iter = 02280, loss = 4.1101
2024-10-30 17:51:29: [2024-10-30 17:51:29] iter = 02290, loss = 2.2718
2024-10-30 17:51:33: [2024-10-30 17:51:33] iter = 02300, loss = 2.0977
2024-10-30 17:51:36: [2024-10-30 17:51:36] iter = 02310, loss = 1.9376
2024-10-30 17:51:40: [2024-10-30 17:51:40] iter = 02320, loss = 2.4128
2024-10-30 17:51:44: [2024-10-30 17:51:44] iter = 02330, loss = 3.2296
2024-10-30 17:51:48: [2024-10-30 17:51:48] iter = 02340, loss = 3.6261
2024-10-30 17:51:51: [2024-10-30 17:51:51] iter = 02350, loss = 2.5635
2024-10-30 17:51:55: [2024-10-30 17:51:55] iter = 02360, loss = 1.9013
2024-10-30 17:51:58: [2024-10-30 17:51:58] iter = 02370, loss = 2.2282
2024-10-30 17:52:01: [2024-10-30 17:52:01] iter = 02380, loss = 2.4741
2024-10-30 17:52:04: [2024-10-30 17:52:04] iter = 02390, loss = 2.2888
2024-10-30 17:52:08: [2024-10-30 17:52:08] iter = 02400, loss = 3.9822
2024-10-30 17:52:11: [2024-10-30 17:52:11] iter = 02410, loss = 1.9390
2024-10-30 17:52:14: [2024-10-30 17:52:14] iter = 02420, loss = 2.2409
2024-10-30 17:52:17: [2024-10-30 17:52:17] iter = 02430, loss = 2.3121
2024-10-30 17:52:22: [2024-10-30 17:52:22] iter = 02440, loss = 3.0400
2024-10-30 17:52:26: [2024-10-30 17:52:26] iter = 02450, loss = 7.5406
2024-10-30 17:52:30: [2024-10-30 17:52:30] iter = 02460, loss = 2.0454
2024-10-30 17:52:34: [2024-10-30 17:52:34] iter = 02470, loss = 1.9845
2024-10-30 17:52:38: [2024-10-30 17:52:38] iter = 02480, loss = 3.7325
2024-10-30 17:52:41: [2024-10-30 17:52:41] iter = 02490, loss = 2.0188
2024-10-30 17:52:45: [2024-10-30 17:52:45] iter = 02500, loss = 2.2455
2024-10-30 17:52:49: [2024-10-30 17:52:49] iter = 02510, loss = 2.8689
2024-10-30 17:52:52: [2024-10-30 17:52:52] iter = 02520, loss = 2.5679
2024-10-30 17:52:56: [2024-10-30 17:52:56] iter = 02530, loss = 2.1547
2024-10-30 17:53:00: [2024-10-30 17:53:00] iter = 02540, loss = 2.1008
2024-10-30 17:53:05: [2024-10-30 17:53:05] iter = 02550, loss = 2.2216
2024-10-30 17:53:08: [2024-10-30 17:53:08] iter = 02560, loss = 2.0520
2024-10-30 17:53:11: [2024-10-30 17:53:11] iter = 02570, loss = 4.5131
2024-10-30 17:53:14: [2024-10-30 17:53:14] iter = 02580, loss = 3.2443
2024-10-30 17:53:18: [2024-10-30 17:53:18] iter = 02590, loss = 1.8696
2024-10-30 17:53:22: [2024-10-30 17:53:22] iter = 02600, loss = 2.4887
2024-10-30 17:53:25: [2024-10-30 17:53:25] iter = 02610, loss = 2.3628
2024-10-30 17:53:28: [2024-10-30 17:53:28] iter = 02620, loss = 2.2658
2024-10-30 17:53:31: [2024-10-30 17:53:31] iter = 02630, loss = 2.3518
2024-10-30 17:53:35: [2024-10-30 17:53:35] iter = 02640, loss = 2.3581
2024-10-30 17:53:38: [2024-10-30 17:53:38] iter = 02650, loss = 2.0757
2024-10-30 17:53:41: [2024-10-30 17:53:41] iter = 02660, loss = 1.9299
2024-10-30 17:53:45: [2024-10-30 17:53:45] iter = 02670, loss = 2.0721
2024-10-30 17:53:49: [2024-10-30 17:53:49] iter = 02680, loss = 2.1311
2024-10-30 17:53:53: [2024-10-30 17:53:53] iter = 02690, loss = 2.8873
2024-10-30 17:53:56: [2024-10-30 17:53:56] iter = 02700, loss = 1.8424
2024-10-30 17:54:00: [2024-10-30 17:54:00] iter = 02710, loss = 3.1221
2024-10-30 17:54:03: [2024-10-30 17:54:03] iter = 02720, loss = 1.5328
2024-10-30 17:54:08: [2024-10-30 17:54:07] iter = 02730, loss = 2.4695
2024-10-30 17:54:11: [2024-10-30 17:54:11] iter = 02740, loss = 2.5988
2024-10-30 17:54:15: [2024-10-30 17:54:15] iter = 02750, loss = 2.5222
2024-10-30 17:54:20: [2024-10-30 17:54:20] iter = 02760, loss = 2.5463
2024-10-30 17:54:23: [2024-10-30 17:54:23] iter = 02770, loss = 2.3317
2024-10-30 17:54:27: [2024-10-30 17:54:27] iter = 02780, loss = 2.4292
2024-10-30 17:54:31: [2024-10-30 17:54:31] iter = 02790, loss = 2.9199
2024-10-30 17:54:35: [2024-10-30 17:54:35] iter = 02800, loss = 2.1646
2024-10-30 17:54:38: [2024-10-30 17:54:38] iter = 02810, loss = 1.9261
2024-10-30 17:54:42: [2024-10-30 17:54:42] iter = 02820, loss = 3.8122
2024-10-30 17:54:46: [2024-10-30 17:54:46] iter = 02830, loss = 2.5375
2024-10-30 17:54:49: [2024-10-30 17:54:49] iter = 02840, loss = 2.4992
2024-10-30 17:54:53: [2024-10-30 17:54:53] iter = 02850, loss = 2.1921
2024-10-30 17:54:56: [2024-10-30 17:54:56] iter = 02860, loss = 2.2248
2024-10-30 17:54:59: [2024-10-30 17:54:59] iter = 02870, loss = 2.4538
2024-10-30 17:55:02: [2024-10-30 17:55:02] iter = 02880, loss = 2.3141
2024-10-30 17:55:07: [2024-10-30 17:55:07] iter = 02890, loss = 2.0159
2024-10-30 17:55:10: [2024-10-30 17:55:10] iter = 02900, loss = 2.8284
2024-10-30 17:55:13: [2024-10-30 17:55:13] iter = 02910, loss = 2.1724
2024-10-30 17:55:16: [2024-10-30 17:55:16] iter = 02920, loss = 2.3831
2024-10-30 17:55:20: [2024-10-30 17:55:20] iter = 02930, loss = 1.9501
2024-10-30 17:55:23: [2024-10-30 17:55:23] iter = 02940, loss = 2.1224
2024-10-30 17:55:27: [2024-10-30 17:55:27] iter = 02950, loss = 1.9410
2024-10-30 17:55:30: [2024-10-30 17:55:30] iter = 02960, loss = 3.0972
2024-10-30 17:55:33: [2024-10-30 17:55:33] iter = 02970, loss = 2.4636
2024-10-30 17:55:36: [2024-10-30 17:55:36] iter = 02980, loss = 2.2150
2024-10-30 17:55:40: [2024-10-30 17:55:40] iter = 02990, loss = 2.2771
2024-10-30 17:55:43: [2024-10-30 17:55:43] iter = 03000, loss = 2.1062
2024-10-30 17:55:48: [2024-10-30 17:55:48] iter = 03010, loss = 1.9966
2024-10-30 17:55:51: [2024-10-30 17:55:51] iter = 03020, loss = 2.0565
2024-10-30 17:55:55: [2024-10-30 17:55:55] iter = 03030, loss = 2.9743
2024-10-30 17:55:58: [2024-10-30 17:55:58] iter = 03040, loss = 3.4982
2024-10-30 17:56:01: [2024-10-30 17:56:01] iter = 03050, loss = 2.7272
2024-10-30 17:56:05: [2024-10-30 17:56:05] iter = 03060, loss = 2.3457
2024-10-30 17:56:08: [2024-10-30 17:56:08] iter = 03070, loss = 2.2406
2024-10-30 17:56:12: [2024-10-30 17:56:12] iter = 03080, loss = 2.1365
2024-10-30 17:56:14: [2024-10-30 17:56:14] iter = 03090, loss = 2.1104
2024-10-30 17:56:18: [2024-10-30 17:56:18] iter = 03100, loss = 2.4840
2024-10-30 17:56:22: [2024-10-30 17:56:22] iter = 03110, loss = 2.6647
2024-10-30 17:56:26: [2024-10-30 17:56:26] iter = 03120, loss = 2.8140
2024-10-30 17:56:30: [2024-10-30 17:56:30] iter = 03130, loss = 2.0177
2024-10-30 17:56:33: [2024-10-30 17:56:33] iter = 03140, loss = 2.7254
2024-10-30 17:56:35: [2024-10-30 17:56:35] iter = 03150, loss = 2.4428
2024-10-30 17:56:39: [2024-10-30 17:56:39] iter = 03160, loss = 2.0484
2024-10-30 17:56:41: [2024-10-30 17:56:41] iter = 03170, loss = 2.1600
2024-10-30 17:56:45: [2024-10-30 17:56:45] iter = 03180, loss = 7.3953
2024-10-30 17:56:48: [2024-10-30 17:56:48] iter = 03190, loss = 2.1128
2024-10-30 17:56:51: [2024-10-30 17:56:51] iter = 03200, loss = 2.1448
2024-10-30 17:56:55: [2024-10-30 17:56:55] iter = 03210, loss = 2.0681
2024-10-30 17:56:59: [2024-10-30 17:56:59] iter = 03220, loss = 2.0736
2024-10-30 17:57:02: [2024-10-30 17:57:02] iter = 03230, loss = 2.0878
2024-10-30 17:57:05: [2024-10-30 17:57:05] iter = 03240, loss = 2.0781
2024-10-30 17:57:08: [2024-10-30 17:57:08] iter = 03250, loss = 1.8663
2024-10-30 17:57:12: [2024-10-30 17:57:12] iter = 03260, loss = 1.9702
2024-10-30 17:57:16: [2024-10-30 17:57:16] iter = 03270, loss = 2.2769
2024-10-30 17:57:19: [2024-10-30 17:57:19] iter = 03280, loss = 2.0694
2024-10-30 17:57:23: [2024-10-30 17:57:23] iter = 03290, loss = 2.2334
2024-10-30 17:57:27: [2024-10-30 17:57:27] iter = 03300, loss = 2.2711
2024-10-30 17:57:31: [2024-10-30 17:57:31] iter = 03310, loss = 2.9555
2024-10-30 17:57:35: [2024-10-30 17:57:35] iter = 03320, loss = 2.5187
2024-10-30 17:57:39: [2024-10-30 17:57:39] iter = 03330, loss = 1.9724
2024-10-30 17:57:42: [2024-10-30 17:57:42] iter = 03340, loss = 2.4685
2024-10-30 17:57:46: [2024-10-30 17:57:46] iter = 03350, loss = 1.8829
2024-10-30 17:57:49: [2024-10-30 17:57:49] iter = 03360, loss = 1.7788
2024-10-30 17:57:53: [2024-10-30 17:57:53] iter = 03370, loss = 2.1510
2024-10-30 17:57:57: [2024-10-30 17:57:57] iter = 03380, loss = 1.9815
2024-10-30 17:58:01: [2024-10-30 17:58:01] iter = 03390, loss = 2.3925
2024-10-30 17:58:04: [2024-10-30 17:58:04] iter = 03400, loss = 2.0382
2024-10-30 17:58:08: [2024-10-30 17:58:08] iter = 03410, loss = 4.2054
2024-10-30 17:58:12: [2024-10-30 17:58:12] iter = 03420, loss = 1.6734
2024-10-30 17:58:16: [2024-10-30 17:58:16] iter = 03430, loss = 3.3046
2024-10-30 17:58:19: [2024-10-30 17:58:19] iter = 03440, loss = 1.9758
2024-10-30 17:58:24: [2024-10-30 17:58:24] iter = 03450, loss = 2.2759
2024-10-30 17:58:27: [2024-10-30 17:58:27] iter = 03460, loss = 4.5992
2024-10-30 17:58:32: [2024-10-30 17:58:32] iter = 03470, loss = 3.7709
2024-10-30 17:58:36: [2024-10-30 17:58:36] iter = 03480, loss = 2.2787
2024-10-30 17:58:38: [2024-10-30 17:58:38] iter = 03490, loss = 1.8695
2024-10-30 17:58:41: [2024-10-30 17:58:41] iter = 03500, loss = 4.3162
2024-10-30 17:58:45: [2024-10-30 17:58:45] iter = 03510, loss = 1.9042
2024-10-30 17:58:49: [2024-10-30 17:58:49] iter = 03520, loss = 2.2057
2024-10-30 17:58:52: [2024-10-30 17:58:52] iter = 03530, loss = 1.8922
2024-10-30 17:58:56: [2024-10-30 17:58:56] iter = 03540, loss = 1.8946
2024-10-30 17:59:01: [2024-10-30 17:59:01] iter = 03550, loss = 3.4458
2024-10-30 17:59:05: [2024-10-30 17:59:05] iter = 03560, loss = 1.8325
2024-10-30 17:59:08: [2024-10-30 17:59:08] iter = 03570, loss = 2.2208
2024-10-30 17:59:10: [2024-10-30 17:59:10] iter = 03580, loss = 2.6469
2024-10-30 17:59:14: [2024-10-30 17:59:14] iter = 03590, loss = 2.3553
2024-10-30 17:59:17: [2024-10-30 17:59:17] iter = 03600, loss = 2.1541
2024-10-30 17:59:21: [2024-10-30 17:59:21] iter = 03610, loss = 3.9677
2024-10-30 17:59:25: [2024-10-30 17:59:25] iter = 03620, loss = 2.3894
2024-10-30 17:59:28: [2024-10-30 17:59:28] iter = 03630, loss = 2.0477
2024-10-30 17:59:31: [2024-10-30 17:59:31] iter = 03640, loss = 2.1483
2024-10-30 17:59:34: [2024-10-30 17:59:34] iter = 03650, loss = 4.3386
2024-10-30 17:59:37: [2024-10-30 17:59:37] iter = 03660, loss = 2.3509
2024-10-30 17:59:40: [2024-10-30 17:59:40] iter = 03670, loss = 2.8271
2024-10-30 17:59:43: [2024-10-30 17:59:43] iter = 03680, loss = 1.7617
2024-10-30 17:59:47: [2024-10-30 17:59:47] iter = 03690, loss = 2.3666
2024-10-30 17:59:51: [2024-10-30 17:59:51] iter = 03700, loss = 1.9693
2024-10-30 17:59:55: [2024-10-30 17:59:55] iter = 03710, loss = 2.4644
2024-10-30 17:59:58: [2024-10-30 17:59:58] iter = 03720, loss = 2.3725
2024-10-30 18:00:02: [2024-10-30 18:00:02] iter = 03730, loss = 3.0464
2024-10-30 18:00:06: [2024-10-30 18:00:06] iter = 03740, loss = 2.0948
2024-10-30 18:00:10: [2024-10-30 18:00:10] iter = 03750, loss = 4.1201
2024-10-30 18:00:13: [2024-10-30 18:00:13] iter = 03760, loss = 2.4891
2024-10-30 18:00:16: [2024-10-30 18:00:16] iter = 03770, loss = 2.1396
2024-10-30 18:00:19: [2024-10-30 18:00:19] iter = 03780, loss = 1.9492
2024-10-30 18:00:23: [2024-10-30 18:00:23] iter = 03790, loss = 1.8480
2024-10-30 18:00:26: [2024-10-30 18:00:26] iter = 03800, loss = 2.2844
2024-10-30 18:00:30: [2024-10-30 18:00:30] iter = 03810, loss = 3.5008
2024-10-30 18:00:33: [2024-10-30 18:00:33] iter = 03820, loss = 2.3930
2024-10-30 18:00:38: [2024-10-30 18:00:38] iter = 03830, loss = 2.8516
2024-10-30 18:00:41: [2024-10-30 18:00:41] iter = 03840, loss = 4.3103
2024-10-30 18:00:44: [2024-10-30 18:00:44] iter = 03850, loss = 2.2362
2024-10-30 18:00:48: [2024-10-30 18:00:48] iter = 03860, loss = 2.4815
2024-10-30 18:00:51: [2024-10-30 18:00:51] iter = 03870, loss = 2.0200
2024-10-30 18:00:54: [2024-10-30 18:00:54] iter = 03880, loss = 1.7659
2024-10-30 18:00:58: [2024-10-30 18:00:58] iter = 03890, loss = 3.9298
2024-10-30 18:01:01: [2024-10-30 18:01:01] iter = 03900, loss = 2.9740
2024-10-30 18:01:04: [2024-10-30 18:01:04] iter = 03910, loss = 2.6768
2024-10-30 18:01:07: [2024-10-30 18:01:07] iter = 03920, loss = 2.3398
2024-10-30 18:01:10: [2024-10-30 18:01:10] iter = 03930, loss = 3.1390
2024-10-30 18:01:14: [2024-10-30 18:01:14] iter = 03940, loss = 2.1486
2024-10-30 18:01:19: [2024-10-30 18:01:19] iter = 03950, loss = 2.6937
2024-10-30 18:01:22: [2024-10-30 18:01:22] iter = 03960, loss = 2.0952
2024-10-30 18:01:26: [2024-10-30 18:01:26] iter = 03970, loss = 2.0010
2024-10-30 18:01:29: [2024-10-30 18:01:29] iter = 03980, loss = 1.8817
2024-10-30 18:01:31: [2024-10-30 18:01:31] iter = 03990, loss = 2.1879
2024-10-30 18:01:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 18:01:34: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:01:34: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 94276}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:03:54: Evaluate 5 random ConvNet, ACCmean = 0.7793 ACCstd = 0.0048
-------------------------
2024-10-30 18:03:54: Evaluate 5 random ConvNet, SENmean = 0.7730 SENstd = 0.0050
-------------------------
2024-10-30 18:03:54: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0005
-------------------------
2024-10-30 18:03:54: Evaluate 5 random ConvNet, F!mean = 0.7666 F!std = 0.0047
-------------------------
2024-10-30 18:03:54: Evaluate 5 random ConvNet, mean = 0.7793 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:03:55: [2024-10-30 18:03:55] iter = 04000, loss = 3.2832
2024-10-30 18:03:57: [2024-10-30 18:03:57] iter = 04010, loss = 2.0135
2024-10-30 18:04:00: [2024-10-30 18:04:00] iter = 04020, loss = 1.8742
2024-10-30 18:04:03: [2024-10-30 18:04:03] iter = 04030, loss = 2.4504
2024-10-30 18:04:06: [2024-10-30 18:04:06] iter = 04040, loss = 1.7383
2024-10-30 18:04:09: [2024-10-30 18:04:09] iter = 04050, loss = 1.9908
2024-10-30 18:04:12: [2024-10-30 18:04:12] iter = 04060, loss = 2.4765
2024-10-30 18:04:15: [2024-10-30 18:04:15] iter = 04070, loss = 2.0993
2024-10-30 18:04:19: [2024-10-30 18:04:19] iter = 04080, loss = 3.0532
2024-10-30 18:04:22: [2024-10-30 18:04:22] iter = 04090, loss = 2.6391
2024-10-30 18:04:25: [2024-10-30 18:04:25] iter = 04100, loss = 2.2845
2024-10-30 18:04:30: [2024-10-30 18:04:30] iter = 04110, loss = 3.1245
2024-10-30 18:04:33: [2024-10-30 18:04:33] iter = 04120, loss = 2.2643
2024-10-30 18:04:37: [2024-10-30 18:04:37] iter = 04130, loss = 3.0390
2024-10-30 18:04:40: [2024-10-30 18:04:40] iter = 04140, loss = 2.0292
2024-10-30 18:04:43: [2024-10-30 18:04:43] iter = 04150, loss = 1.9203
2024-10-30 18:04:46: [2024-10-30 18:04:46] iter = 04160, loss = 2.0443
2024-10-30 18:04:50: [2024-10-30 18:04:50] iter = 04170, loss = 2.5608
2024-10-30 18:04:55: [2024-10-30 18:04:55] iter = 04180, loss = 1.9796
2024-10-30 18:04:58: [2024-10-30 18:04:58] iter = 04190, loss = 2.3650
2024-10-30 18:05:03: [2024-10-30 18:05:03] iter = 04200, loss = 2.0383
2024-10-30 18:05:06: [2024-10-30 18:05:06] iter = 04210, loss = 2.2197
2024-10-30 18:05:10: [2024-10-30 18:05:10] iter = 04220, loss = 1.9445
2024-10-30 18:05:14: [2024-10-30 18:05:14] iter = 04230, loss = 1.8181
2024-10-30 18:05:18: [2024-10-30 18:05:18] iter = 04240, loss = 3.4118
2024-10-30 18:05:22: [2024-10-30 18:05:22] iter = 04250, loss = 4.1995
2024-10-30 18:05:25: [2024-10-30 18:05:25] iter = 04260, loss = 1.9038
2024-10-30 18:05:28: [2024-10-30 18:05:28] iter = 04270, loss = 3.1549
2024-10-30 18:05:31: [2024-10-30 18:05:31] iter = 04280, loss = 3.9106
2024-10-30 18:05:33: [2024-10-30 18:05:33] iter = 04290, loss = 2.5471
2024-10-30 18:05:35: [2024-10-30 18:05:35] iter = 04300, loss = 3.1910
2024-10-30 18:05:39: [2024-10-30 18:05:39] iter = 04310, loss = 2.2659
2024-10-30 18:05:42: [2024-10-30 18:05:42] iter = 04320, loss = 2.9616
2024-10-30 18:05:46: [2024-10-30 18:05:46] iter = 04330, loss = 1.9411
2024-10-30 18:05:50: [2024-10-30 18:05:50] iter = 04340, loss = 1.9976
2024-10-30 18:05:53: [2024-10-30 18:05:53] iter = 04350, loss = 2.0819
2024-10-30 18:05:57: [2024-10-30 18:05:57] iter = 04360, loss = 2.4908
2024-10-30 18:06:00: [2024-10-30 18:06:00] iter = 04370, loss = 1.7716
2024-10-30 18:06:02: [2024-10-30 18:06:02] iter = 04380, loss = 2.2757
2024-10-30 18:06:06: [2024-10-30 18:06:06] iter = 04390, loss = 1.9026
2024-10-30 18:06:09: [2024-10-30 18:06:09] iter = 04400, loss = 2.1551
2024-10-30 18:06:13: [2024-10-30 18:06:13] iter = 04410, loss = 2.8503
2024-10-30 18:06:16: [2024-10-30 18:06:16] iter = 04420, loss = 2.0937
2024-10-30 18:06:19: [2024-10-30 18:06:19] iter = 04430, loss = 2.0178
2024-10-30 18:06:23: [2024-10-30 18:06:23] iter = 04440, loss = 2.0478
2024-10-30 18:06:27: [2024-10-30 18:06:27] iter = 04450, loss = 2.4432
2024-10-30 18:06:31: [2024-10-30 18:06:31] iter = 04460, loss = 2.0188
2024-10-30 18:06:34: [2024-10-30 18:06:34] iter = 04470, loss = 1.8161
2024-10-30 18:06:37: [2024-10-30 18:06:37] iter = 04480, loss = 2.1731
2024-10-30 18:06:40: [2024-10-30 18:06:40] iter = 04490, loss = 1.9838
2024-10-30 18:06:43: [2024-10-30 18:06:43] iter = 04500, loss = 3.8190
2024-10-30 18:06:46: [2024-10-30 18:06:46] iter = 04510, loss = 3.0875
2024-10-30 18:06:50: [2024-10-30 18:06:50] iter = 04520, loss = 1.9665
2024-10-30 18:06:53: [2024-10-30 18:06:53] iter = 04530, loss = 2.0095
2024-10-30 18:06:57: [2024-10-30 18:06:57] iter = 04540, loss = 2.2761
2024-10-30 18:07:01: [2024-10-30 18:07:01] iter = 04550, loss = 2.2458
2024-10-30 18:07:04: [2024-10-30 18:07:04] iter = 04560, loss = 2.4215
2024-10-30 18:07:08: [2024-10-30 18:07:08] iter = 04570, loss = 4.8816
2024-10-30 18:07:12: [2024-10-30 18:07:12] iter = 04580, loss = 4.8041
2024-10-30 18:07:16: [2024-10-30 18:07:16] iter = 04590, loss = 2.4753
2024-10-30 18:07:21: [2024-10-30 18:07:21] iter = 04600, loss = 2.0645
2024-10-30 18:07:25: [2024-10-30 18:07:25] iter = 04610, loss = 2.3726
2024-10-30 18:07:28: [2024-10-30 18:07:28] iter = 04620, loss = 1.8472
2024-10-30 18:07:33: [2024-10-30 18:07:33] iter = 04630, loss = 2.1294
2024-10-30 18:07:37: [2024-10-30 18:07:37] iter = 04640, loss = 2.0236
2024-10-30 18:07:41: [2024-10-30 18:07:41] iter = 04650, loss = 3.6318
2024-10-30 18:07:46: [2024-10-30 18:07:46] iter = 04660, loss = 1.8874
2024-10-30 18:07:50: [2024-10-30 18:07:50] iter = 04670, loss = 2.2776
2024-10-30 18:07:54: [2024-10-30 18:07:54] iter = 04680, loss = 1.9831
2024-10-30 18:07:57: [2024-10-30 18:07:57] iter = 04690, loss = 2.1092
2024-10-30 18:08:01: [2024-10-30 18:08:01] iter = 04700, loss = 2.2606
2024-10-30 18:08:05: [2024-10-30 18:08:04] iter = 04710, loss = 2.0295
2024-10-30 18:08:08: [2024-10-30 18:08:08] iter = 04720, loss = 2.7211
2024-10-30 18:08:11: [2024-10-30 18:08:11] iter = 04730, loss = 1.9677
2024-10-30 18:08:15: [2024-10-30 18:08:15] iter = 04740, loss = 2.2230
2024-10-30 18:08:18: [2024-10-30 18:08:18] iter = 04750, loss = 2.4482
2024-10-30 18:08:22: [2024-10-30 18:08:22] iter = 04760, loss = 2.2311
2024-10-30 18:08:25: [2024-10-30 18:08:25] iter = 04770, loss = 2.4376
2024-10-30 18:08:29: [2024-10-30 18:08:29] iter = 04780, loss = 2.8814
2024-10-30 18:08:34: [2024-10-30 18:08:34] iter = 04790, loss = 3.8638
2024-10-30 18:08:37: [2024-10-30 18:08:37] iter = 04800, loss = 1.8651
2024-10-30 18:08:39: [2024-10-30 18:08:39] iter = 04810, loss = 4.7641
2024-10-30 18:08:43: [2024-10-30 18:08:43] iter = 04820, loss = 2.0271
2024-10-30 18:08:46: [2024-10-30 18:08:46] iter = 04830, loss = 2.1219
2024-10-30 18:08:50: [2024-10-30 18:08:50] iter = 04840, loss = 1.7317
2024-10-30 18:08:53: [2024-10-30 18:08:53] iter = 04850, loss = 1.9985
2024-10-30 18:08:57: [2024-10-30 18:08:57] iter = 04860, loss = 2.8498
2024-10-30 18:09:01: [2024-10-30 18:09:01] iter = 04870, loss = 2.0292
2024-10-30 18:09:05: [2024-10-30 18:09:05] iter = 04880, loss = 2.6453
2024-10-30 18:09:09: [2024-10-30 18:09:09] iter = 04890, loss = 2.0568
2024-10-30 18:09:13: [2024-10-30 18:09:13] iter = 04900, loss = 2.5178
2024-10-30 18:09:17: [2024-10-30 18:09:17] iter = 04910, loss = 1.9983
2024-10-30 18:09:22: [2024-10-30 18:09:22] iter = 04920, loss = 1.8004
2024-10-30 18:09:24: [2024-10-30 18:09:24] iter = 04930, loss = 2.2610
2024-10-30 18:09:28: [2024-10-30 18:09:28] iter = 04940, loss = 2.6893
2024-10-30 18:09:31: [2024-10-30 18:09:31] iter = 04950, loss = 2.8759
2024-10-30 18:09:34: [2024-10-30 18:09:34] iter = 04960, loss = 2.0366
2024-10-30 18:09:38: [2024-10-30 18:09:38] iter = 04970, loss = 2.5923
2024-10-30 18:09:41: [2024-10-30 18:09:41] iter = 04980, loss = 2.2138
2024-10-30 18:09:44: [2024-10-30 18:09:44] iter = 04990, loss = 2.2071
2024-10-30 18:09:47: [2024-10-30 18:09:47] iter = 05000, loss = 2.1067
2024-10-30 18:09:51: [2024-10-30 18:09:51] iter = 05010, loss = 1.7698
2024-10-30 18:09:55: [2024-10-30 18:09:55] iter = 05020, loss = 2.6662
2024-10-30 18:09:58: [2024-10-30 18:09:58] iter = 05030, loss = 2.0632
2024-10-30 18:10:02: [2024-10-30 18:10:02] iter = 05040, loss = 1.9949
2024-10-30 18:10:06: [2024-10-30 18:10:06] iter = 05050, loss = 2.0697
2024-10-30 18:10:09: [2024-10-30 18:10:09] iter = 05060, loss = 2.1177
2024-10-30 18:10:13: [2024-10-30 18:10:13] iter = 05070, loss = 2.7893
2024-10-30 18:10:16: [2024-10-30 18:10:16] iter = 05080, loss = 2.0650
2024-10-30 18:10:20: [2024-10-30 18:10:20] iter = 05090, loss = 1.7197
2024-10-30 18:10:23: [2024-10-30 18:10:23] iter = 05100, loss = 2.0014
2024-10-30 18:10:28: [2024-10-30 18:10:28] iter = 05110, loss = 1.6772
2024-10-30 18:10:31: [2024-10-30 18:10:31] iter = 05120, loss = 3.2702
2024-10-30 18:10:34: [2024-10-30 18:10:34] iter = 05130, loss = 2.0312
2024-10-30 18:10:38: [2024-10-30 18:10:38] iter = 05140, loss = 1.9764
2024-10-30 18:10:41: [2024-10-30 18:10:41] iter = 05150, loss = 2.5013
2024-10-30 18:10:45: [2024-10-30 18:10:45] iter = 05160, loss = 2.3222
2024-10-30 18:10:48: [2024-10-30 18:10:48] iter = 05170, loss = 2.5130
2024-10-30 18:10:52: [2024-10-30 18:10:52] iter = 05180, loss = 2.7882
2024-10-30 18:10:55: [2024-10-30 18:10:55] iter = 05190, loss = 2.3878
2024-10-30 18:10:59: [2024-10-30 18:10:59] iter = 05200, loss = 2.2742
2024-10-30 18:11:02: [2024-10-30 18:11:02] iter = 05210, loss = 4.1407
2024-10-30 18:11:06: [2024-10-30 18:11:06] iter = 05220, loss = 2.1969
2024-10-30 18:11:09: [2024-10-30 18:11:09] iter = 05230, loss = 3.7671
2024-10-30 18:11:12: [2024-10-30 18:11:12] iter = 05240, loss = 2.1514
2024-10-30 18:11:16: [2024-10-30 18:11:16] iter = 05250, loss = 2.3608
2024-10-30 18:11:19: [2024-10-30 18:11:19] iter = 05260, loss = 1.9686
2024-10-30 18:11:22: [2024-10-30 18:11:22] iter = 05270, loss = 1.9015
2024-10-30 18:11:25: [2024-10-30 18:11:25] iter = 05280, loss = 2.2620
2024-10-30 18:11:30: [2024-10-30 18:11:30] iter = 05290, loss = 2.3120
2024-10-30 18:11:33: [2024-10-30 18:11:33] iter = 05300, loss = 2.2377
2024-10-30 18:11:36: [2024-10-30 18:11:36] iter = 05310, loss = 2.8810
2024-10-30 18:11:40: [2024-10-30 18:11:40] iter = 05320, loss = 2.2277
2024-10-30 18:11:43: [2024-10-30 18:11:43] iter = 05330, loss = 2.0616
2024-10-30 18:11:47: [2024-10-30 18:11:47] iter = 05340, loss = 1.7246
2024-10-30 18:11:51: [2024-10-30 18:11:51] iter = 05350, loss = 2.0054
2024-10-30 18:11:54: [2024-10-30 18:11:54] iter = 05360, loss = 1.9719
2024-10-30 18:11:59: [2024-10-30 18:11:59] iter = 05370, loss = 1.6019
2024-10-30 18:12:02: [2024-10-30 18:12:02] iter = 05380, loss = 2.1020
2024-10-30 18:12:06: [2024-10-30 18:12:06] iter = 05390, loss = 2.7825
2024-10-30 18:12:10: [2024-10-30 18:12:10] iter = 05400, loss = 1.7248
2024-10-30 18:12:13: [2024-10-30 18:12:13] iter = 05410, loss = 2.1426
2024-10-30 18:12:18: [2024-10-30 18:12:18] iter = 05420, loss = 3.1743
2024-10-30 18:12:21: [2024-10-30 18:12:21] iter = 05430, loss = 2.2512
2024-10-30 18:12:24: [2024-10-30 18:12:24] iter = 05440, loss = 1.9114
2024-10-30 18:12:27: [2024-10-30 18:12:27] iter = 05450, loss = 4.4793
2024-10-30 18:12:30: [2024-10-30 18:12:30] iter = 05460, loss = 2.1838
2024-10-30 18:12:33: [2024-10-30 18:12:33] iter = 05470, loss = 5.0892
2024-10-30 18:12:38: [2024-10-30 18:12:38] iter = 05480, loss = 2.7062
2024-10-30 18:12:42: [2024-10-30 18:12:42] iter = 05490, loss = 2.3911
2024-10-30 18:12:46: [2024-10-30 18:12:46] iter = 05500, loss = 1.9693
2024-10-30 18:12:49: [2024-10-30 18:12:49] iter = 05510, loss = 2.0108
2024-10-30 18:12:53: [2024-10-30 18:12:53] iter = 05520, loss = 2.1781
2024-10-30 18:12:57: [2024-10-30 18:12:57] iter = 05530, loss = 3.3713
2024-10-30 18:13:01: [2024-10-30 18:13:01] iter = 05540, loss = 1.7654
2024-10-30 18:13:04: [2024-10-30 18:13:04] iter = 05550, loss = 1.8405
2024-10-30 18:13:08: [2024-10-30 18:13:08] iter = 05560, loss = 1.8752
2024-10-30 18:13:11: [2024-10-30 18:13:11] iter = 05570, loss = 2.0567
2024-10-30 18:13:14: [2024-10-30 18:13:14] iter = 05580, loss = 1.8031
2024-10-30 18:13:18: [2024-10-30 18:13:18] iter = 05590, loss = 3.7054
2024-10-30 18:13:22: [2024-10-30 18:13:22] iter = 05600, loss = 3.2344
2024-10-30 18:13:26: [2024-10-30 18:13:26] iter = 05610, loss = 1.9989
2024-10-30 18:13:29: [2024-10-30 18:13:29] iter = 05620, loss = 2.2656
2024-10-30 18:13:32: [2024-10-30 18:13:32] iter = 05630, loss = 1.8434
2024-10-30 18:13:35: [2024-10-30 18:13:35] iter = 05640, loss = 2.0912
2024-10-30 18:13:39: [2024-10-30 18:13:39] iter = 05650, loss = 2.3733
2024-10-30 18:13:44: [2024-10-30 18:13:44] iter = 05660, loss = 2.9493
2024-10-30 18:13:47: [2024-10-30 18:13:47] iter = 05670, loss = 2.0970
2024-10-30 18:13:50: [2024-10-30 18:13:50] iter = 05680, loss = 1.8181
2024-10-30 18:13:54: [2024-10-30 18:13:54] iter = 05690, loss = 2.1976
2024-10-30 18:13:59: [2024-10-30 18:13:59] iter = 05700, loss = 1.7917
2024-10-30 18:14:02: [2024-10-30 18:14:02] iter = 05710, loss = 2.2648
2024-10-30 18:14:04: [2024-10-30 18:14:04] iter = 05720, loss = 2.0316
2024-10-30 18:14:07: [2024-10-30 18:14:07] iter = 05730, loss = 2.3485
2024-10-30 18:14:11: [2024-10-30 18:14:11] iter = 05740, loss = 1.9325
2024-10-30 18:14:15: [2024-10-30 18:14:15] iter = 05750, loss = 1.8264
2024-10-30 18:14:20: [2024-10-30 18:14:20] iter = 05760, loss = 2.0657
2024-10-30 18:14:24: [2024-10-30 18:14:24] iter = 05770, loss = 2.1104
2024-10-30 18:14:28: [2024-10-30 18:14:28] iter = 05780, loss = 2.2663
2024-10-30 18:14:31: [2024-10-30 18:14:31] iter = 05790, loss = 3.1062
2024-10-30 18:14:35: [2024-10-30 18:14:35] iter = 05800, loss = 2.0472
2024-10-30 18:14:39: [2024-10-30 18:14:39] iter = 05810, loss = 1.9077
2024-10-30 18:14:43: [2024-10-30 18:14:43] iter = 05820, loss = 1.8138
2024-10-30 18:14:47: [2024-10-30 18:14:47] iter = 05830, loss = 2.0034
2024-10-30 18:14:49: [2024-10-30 18:14:49] iter = 05840, loss = 1.9785
2024-10-30 18:14:53: [2024-10-30 18:14:53] iter = 05850, loss = 1.9686
2024-10-30 18:14:56: [2024-10-30 18:14:56] iter = 05860, loss = 1.8871
2024-10-30 18:15:00: [2024-10-30 18:15:00] iter = 05870, loss = 1.9545
2024-10-30 18:15:04: [2024-10-30 18:15:04] iter = 05880, loss = 2.4253
2024-10-30 18:15:08: [2024-10-30 18:15:08] iter = 05890, loss = 3.1017
2024-10-30 18:15:12: [2024-10-30 18:15:12] iter = 05900, loss = 2.2341
2024-10-30 18:15:16: [2024-10-30 18:15:16] iter = 05910, loss = 1.9888
2024-10-30 18:15:19: [2024-10-30 18:15:19] iter = 05920, loss = 2.0157
2024-10-30 18:15:23: [2024-10-30 18:15:23] iter = 05930, loss = 4.3529
2024-10-30 18:15:27: [2024-10-30 18:15:27] iter = 05940, loss = 2.1383
2024-10-30 18:15:30: [2024-10-30 18:15:30] iter = 05950, loss = 3.3454
2024-10-30 18:15:33: [2024-10-30 18:15:33] iter = 05960, loss = 3.1196
2024-10-30 18:15:36: [2024-10-30 18:15:36] iter = 05970, loss = 1.9191
2024-10-30 18:15:39: [2024-10-30 18:15:39] iter = 05980, loss = 1.6013
2024-10-30 18:15:43: [2024-10-30 18:15:43] iter = 05990, loss = 1.8838
2024-10-30 18:15:46: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 18:15:46: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:15:46: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 46870}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:18:02: Evaluate 5 random ConvNet, ACCmean = 0.7838 ACCstd = 0.0018
-------------------------
2024-10-30 18:18:02: Evaluate 5 random ConvNet, SENmean = 0.7750 SENstd = 0.0015
-------------------------
2024-10-30 18:18:02: Evaluate 5 random ConvNet, SPEmean = 0.9781 SPEstd = 0.0002
-------------------------
2024-10-30 18:18:02: Evaluate 5 random ConvNet, F!mean = 0.7700 F!std = 0.0024
-------------------------
2024-10-30 18:18:02: Evaluate 5 random ConvNet, mean = 0.7838 std = 0.0018
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:18:03: [2024-10-30 18:18:03] iter = 06000, loss = 2.1433
2024-10-30 18:18:06: [2024-10-30 18:18:06] iter = 06010, loss = 2.0750
2024-10-30 18:18:10: [2024-10-30 18:18:10] iter = 06020, loss = 2.0336
2024-10-30 18:18:14: [2024-10-30 18:18:14] iter = 06030, loss = 2.5702
2024-10-30 18:18:17: [2024-10-30 18:18:17] iter = 06040, loss = 1.6354
2024-10-30 18:18:21: [2024-10-30 18:18:21] iter = 06050, loss = 2.8008
2024-10-30 18:18:25: [2024-10-30 18:18:25] iter = 06060, loss = 3.0301
2024-10-30 18:18:30: [2024-10-30 18:18:30] iter = 06070, loss = 3.0303
2024-10-30 18:18:34: [2024-10-30 18:18:34] iter = 06080, loss = 1.8909
2024-10-30 18:18:37: [2024-10-30 18:18:37] iter = 06090, loss = 1.9480
2024-10-30 18:18:41: [2024-10-30 18:18:41] iter = 06100, loss = 2.1995
2024-10-30 18:18:45: [2024-10-30 18:18:45] iter = 06110, loss = 2.0001
2024-10-30 18:18:48: [2024-10-30 18:18:48] iter = 06120, loss = 1.8429
2024-10-30 18:18:51: [2024-10-30 18:18:51] iter = 06130, loss = 1.8398
2024-10-30 18:18:53: [2024-10-30 18:18:53] iter = 06140, loss = 2.3820
2024-10-30 18:18:55: [2024-10-30 18:18:55] iter = 06150, loss = 1.9956
2024-10-30 18:18:58: [2024-10-30 18:18:58] iter = 06160, loss = 1.9528
2024-10-30 18:19:02: [2024-10-30 18:19:02] iter = 06170, loss = 2.7537
2024-10-30 18:19:07: [2024-10-30 18:19:07] iter = 06180, loss = 2.0140
2024-10-30 18:19:10: [2024-10-30 18:19:10] iter = 06190, loss = 1.7120
2024-10-30 18:19:13: [2024-10-30 18:19:13] iter = 06200, loss = 3.1925
2024-10-30 18:19:18: [2024-10-30 18:19:18] iter = 06210, loss = 2.5215
2024-10-30 18:19:21: [2024-10-30 18:19:21] iter = 06220, loss = 1.8672
2024-10-30 18:19:24: [2024-10-30 18:19:24] iter = 06230, loss = 2.0715
2024-10-30 18:19:28: [2024-10-30 18:19:28] iter = 06240, loss = 2.4770
2024-10-30 18:19:31: [2024-10-30 18:19:31] iter = 06250, loss = 2.0447
2024-10-30 18:19:34: [2024-10-30 18:19:34] iter = 06260, loss = 2.0120
2024-10-30 18:19:37: [2024-10-30 18:19:37] iter = 06270, loss = 1.8527
2024-10-30 18:19:41: [2024-10-30 18:19:41] iter = 06280, loss = 2.0963
2024-10-30 18:19:45: [2024-10-30 18:19:45] iter = 06290, loss = 2.1005
2024-10-30 18:19:49: [2024-10-30 18:19:49] iter = 06300, loss = 1.9706
2024-10-30 18:19:52: [2024-10-30 18:19:52] iter = 06310, loss = 2.1658
2024-10-30 18:19:55: [2024-10-30 18:19:55] iter = 06320, loss = 2.7711
2024-10-30 18:19:58: [2024-10-30 18:19:58] iter = 06330, loss = 2.2696
2024-10-30 18:20:00: [2024-10-30 18:20:00] iter = 06340, loss = 2.7557
2024-10-30 18:20:04: [2024-10-30 18:20:04] iter = 06350, loss = 2.1380
2024-10-30 18:20:07: [2024-10-30 18:20:07] iter = 06360, loss = 2.0672
2024-10-30 18:20:10: [2024-10-30 18:20:10] iter = 06370, loss = 2.0214
2024-10-30 18:20:14: [2024-10-30 18:20:14] iter = 06380, loss = 2.5285
2024-10-30 18:20:17: [2024-10-30 18:20:17] iter = 06390, loss = 1.7393
2024-10-30 18:20:20: [2024-10-30 18:20:20] iter = 06400, loss = 1.8035
2024-10-30 18:20:24: [2024-10-30 18:20:24] iter = 06410, loss = 2.3892
2024-10-30 18:20:27: [2024-10-30 18:20:27] iter = 06420, loss = 1.8976
2024-10-30 18:20:31: [2024-10-30 18:20:31] iter = 06430, loss = 2.6188
2024-10-30 18:20:35: [2024-10-30 18:20:35] iter = 06440, loss = 2.4267
2024-10-30 18:20:39: [2024-10-30 18:20:39] iter = 06450, loss = 1.4886
2024-10-30 18:20:43: [2024-10-30 18:20:43] iter = 06460, loss = 2.1035
2024-10-30 18:20:47: [2024-10-30 18:20:47] iter = 06470, loss = 1.5861
2024-10-30 18:20:50: [2024-10-30 18:20:50] iter = 06480, loss = 4.6851
2024-10-30 18:20:52: [2024-10-30 18:20:52] iter = 06490, loss = 2.4303
2024-10-30 18:20:56: [2024-10-30 18:20:56] iter = 06500, loss = 2.3523
2024-10-30 18:21:00: [2024-10-30 18:21:00] iter = 06510, loss = 1.7979
2024-10-30 18:21:04: [2024-10-30 18:21:04] iter = 06520, loss = 2.3253
2024-10-30 18:21:07: [2024-10-30 18:21:07] iter = 06530, loss = 1.9169
2024-10-30 18:21:11: [2024-10-30 18:21:11] iter = 06540, loss = 2.8841
2024-10-30 18:21:14: [2024-10-30 18:21:14] iter = 06550, loss = 1.7609
2024-10-30 18:21:17: [2024-10-30 18:21:17] iter = 06560, loss = 4.2787
2024-10-30 18:21:21: [2024-10-30 18:21:21] iter = 06570, loss = 1.6677
2024-10-30 18:21:25: [2024-10-30 18:21:25] iter = 06580, loss = 2.1789
2024-10-30 18:21:29: [2024-10-30 18:21:29] iter = 06590, loss = 2.2574
2024-10-30 18:21:33: [2024-10-30 18:21:33] iter = 06600, loss = 2.3149
2024-10-30 18:21:37: [2024-10-30 18:21:37] iter = 06610, loss = 1.9382
2024-10-30 18:21:41: [2024-10-30 18:21:41] iter = 06620, loss = 2.0000
2024-10-30 18:21:45: [2024-10-30 18:21:45] iter = 06630, loss = 2.5224
2024-10-30 18:21:48: [2024-10-30 18:21:48] iter = 06640, loss = 2.1519
2024-10-30 18:21:52: [2024-10-30 18:21:52] iter = 06650, loss = 2.0317
2024-10-30 18:21:55: [2024-10-30 18:21:55] iter = 06660, loss = 3.1028
2024-10-30 18:21:59: [2024-10-30 18:21:59] iter = 06670, loss = 2.8100
2024-10-30 18:22:02: [2024-10-30 18:22:02] iter = 06680, loss = 1.8387
2024-10-30 18:22:06: [2024-10-30 18:22:06] iter = 06690, loss = 1.8023
2024-10-30 18:22:10: [2024-10-30 18:22:10] iter = 06700, loss = 2.6596
2024-10-30 18:22:14: [2024-10-30 18:22:14] iter = 06710, loss = 2.2842
2024-10-30 18:22:19: [2024-10-30 18:22:19] iter = 06720, loss = 2.3826
2024-10-30 18:22:22: [2024-10-30 18:22:22] iter = 06730, loss = 3.2330
2024-10-30 18:22:26: [2024-10-30 18:22:26] iter = 06740, loss = 1.8712
2024-10-30 18:22:30: [2024-10-30 18:22:30] iter = 06750, loss = 2.2283
2024-10-30 18:22:33: [2024-10-30 18:22:33] iter = 06760, loss = 2.5294
2024-10-30 18:22:38: [2024-10-30 18:22:38] iter = 06770, loss = 1.8490
2024-10-30 18:22:41: [2024-10-30 18:22:41] iter = 06780, loss = 3.3860
2024-10-30 18:22:45: [2024-10-30 18:22:45] iter = 06790, loss = 1.7370
2024-10-30 18:22:48: [2024-10-30 18:22:48] iter = 06800, loss = 1.8243
2024-10-30 18:22:52: [2024-10-30 18:22:52] iter = 06810, loss = 1.8569
2024-10-30 18:22:55: [2024-10-30 18:22:55] iter = 06820, loss = 1.8835
2024-10-30 18:22:59: [2024-10-30 18:22:59] iter = 06830, loss = 2.0342
2024-10-30 18:23:03: [2024-10-30 18:23:03] iter = 06840, loss = 3.0930
2024-10-30 18:23:07: [2024-10-30 18:23:07] iter = 06850, loss = 2.0871
2024-10-30 18:23:10: [2024-10-30 18:23:10] iter = 06860, loss = 1.9460
2024-10-30 18:23:13: [2024-10-30 18:23:13] iter = 06870, loss = 2.3704
2024-10-30 18:23:17: [2024-10-30 18:23:17] iter = 06880, loss = 1.8470
2024-10-30 18:23:21: [2024-10-30 18:23:21] iter = 06890, loss = 3.0410
2024-10-30 18:23:24: [2024-10-30 18:23:24] iter = 06900, loss = 2.8016
2024-10-30 18:23:27: [2024-10-30 18:23:27] iter = 06910, loss = 2.5268
2024-10-30 18:23:31: [2024-10-30 18:23:31] iter = 06920, loss = 2.3183
2024-10-30 18:23:34: [2024-10-30 18:23:34] iter = 06930, loss = 3.3281
2024-10-30 18:23:38: [2024-10-30 18:23:38] iter = 06940, loss = 2.3945
2024-10-30 18:23:41: [2024-10-30 18:23:41] iter = 06950, loss = 2.3414
2024-10-30 18:23:44: [2024-10-30 18:23:44] iter = 06960, loss = 2.4674
2024-10-30 18:23:48: [2024-10-30 18:23:48] iter = 06970, loss = 1.9246
2024-10-30 18:23:51: [2024-10-30 18:23:51] iter = 06980, loss = 2.0245
2024-10-30 18:23:54: [2024-10-30 18:23:54] iter = 06990, loss = 2.0000
2024-10-30 18:23:58: [2024-10-30 18:23:58] iter = 07000, loss = 2.5788
2024-10-30 18:24:03: [2024-10-30 18:24:03] iter = 07010, loss = 1.8092
2024-10-30 18:24:05: [2024-10-30 18:24:05] iter = 07020, loss = 1.6902
2024-10-30 18:24:08: [2024-10-30 18:24:08] iter = 07030, loss = 1.9640
2024-10-30 18:24:12: [2024-10-30 18:24:12] iter = 07040, loss = 2.6124
2024-10-30 18:24:15: [2024-10-30 18:24:15] iter = 07050, loss = 1.8080
2024-10-30 18:24:18: [2024-10-30 18:24:18] iter = 07060, loss = 2.7476
2024-10-30 18:24:22: [2024-10-30 18:24:22] iter = 07070, loss = 1.9422
2024-10-30 18:24:25: [2024-10-30 18:24:25] iter = 07080, loss = 1.8265
2024-10-30 18:24:29: [2024-10-30 18:24:29] iter = 07090, loss = 2.4528
2024-10-30 18:24:32: [2024-10-30 18:24:32] iter = 07100, loss = 1.9099
2024-10-30 18:24:35: [2024-10-30 18:24:35] iter = 07110, loss = 2.0585
2024-10-30 18:24:38: [2024-10-30 18:24:38] iter = 07120, loss = 2.5479
2024-10-30 18:24:40: [2024-10-30 18:24:40] iter = 07130, loss = 2.0088
2024-10-30 18:24:45: [2024-10-30 18:24:45] iter = 07140, loss = 2.0483
2024-10-30 18:24:48: [2024-10-30 18:24:48] iter = 07150, loss = 3.1659
2024-10-30 18:24:52: [2024-10-30 18:24:52] iter = 07160, loss = 2.2628
2024-10-30 18:24:56: [2024-10-30 18:24:56] iter = 07170, loss = 2.3268
2024-10-30 18:24:59: [2024-10-30 18:24:59] iter = 07180, loss = 2.5556
2024-10-30 18:25:02: [2024-10-30 18:25:02] iter = 07190, loss = 2.3061
2024-10-30 18:25:05: [2024-10-30 18:25:05] iter = 07200, loss = 1.8400
2024-10-30 18:25:08: [2024-10-30 18:25:08] iter = 07210, loss = 1.8363
2024-10-30 18:25:12: [2024-10-30 18:25:12] iter = 07220, loss = 2.0965
2024-10-30 18:25:15: [2024-10-30 18:25:15] iter = 07230, loss = 2.7651
2024-10-30 18:25:19: [2024-10-30 18:25:19] iter = 07240, loss = 2.0955
2024-10-30 18:25:22: [2024-10-30 18:25:22] iter = 07250, loss = 2.6808
2024-10-30 18:25:26: [2024-10-30 18:25:26] iter = 07260, loss = 2.0864
2024-10-30 18:25:30: [2024-10-30 18:25:30] iter = 07270, loss = 3.1331
2024-10-30 18:25:33: [2024-10-30 18:25:33] iter = 07280, loss = 2.1224
2024-10-30 18:25:37: [2024-10-30 18:25:37] iter = 07290, loss = 1.7567
2024-10-30 18:25:42: [2024-10-30 18:25:42] iter = 07300, loss = 2.1580
2024-10-30 18:25:45: [2024-10-30 18:25:45] iter = 07310, loss = 2.2352
2024-10-30 18:25:49: [2024-10-30 18:25:49] iter = 07320, loss = 3.0885
2024-10-30 18:25:52: [2024-10-30 18:25:52] iter = 07330, loss = 3.0678
2024-10-30 18:25:56: [2024-10-30 18:25:56] iter = 07340, loss = 2.2465
2024-10-30 18:26:00: [2024-10-30 18:26:00] iter = 07350, loss = 1.8880
2024-10-30 18:26:03: [2024-10-30 18:26:03] iter = 07360, loss = 1.7507
2024-10-30 18:26:05: [2024-10-30 18:26:05] iter = 07370, loss = 1.6202
2024-10-30 18:26:09: [2024-10-30 18:26:09] iter = 07380, loss = 1.9962
2024-10-30 18:26:12: [2024-10-30 18:26:12] iter = 07390, loss = 2.1485
2024-10-30 18:26:16: [2024-10-30 18:26:16] iter = 07400, loss = 1.9233
2024-10-30 18:26:20: [2024-10-30 18:26:20] iter = 07410, loss = 3.8115
2024-10-30 18:26:24: [2024-10-30 18:26:24] iter = 07420, loss = 1.9082
2024-10-30 18:26:28: [2024-10-30 18:26:28] iter = 07430, loss = 1.9393
2024-10-30 18:26:31: [2024-10-30 18:26:31] iter = 07440, loss = 2.3250
2024-10-30 18:26:34: [2024-10-30 18:26:34] iter = 07450, loss = 2.1955
2024-10-30 18:26:36: [2024-10-30 18:26:36] iter = 07460, loss = 2.7170
2024-10-30 18:26:40: [2024-10-30 18:26:40] iter = 07470, loss = 2.9075
2024-10-30 18:26:44: [2024-10-30 18:26:44] iter = 07480, loss = 2.1813
2024-10-30 18:26:47: [2024-10-30 18:26:47] iter = 07490, loss = 3.6474
2024-10-30 18:26:52: [2024-10-30 18:26:52] iter = 07500, loss = 2.2647
2024-10-30 18:26:55: [2024-10-30 18:26:55] iter = 07510, loss = 2.0339
2024-10-30 18:26:59: [2024-10-30 18:26:59] iter = 07520, loss = 1.9292
2024-10-30 18:27:03: [2024-10-30 18:27:03] iter = 07530, loss = 2.2140
2024-10-30 18:27:07: [2024-10-30 18:27:07] iter = 07540, loss = 1.8678
2024-10-30 18:27:10: [2024-10-30 18:27:10] iter = 07550, loss = 2.1386
2024-10-30 18:27:13: [2024-10-30 18:27:13] iter = 07560, loss = 2.0670
2024-10-30 18:27:16: [2024-10-30 18:27:16] iter = 07570, loss = 2.7640
2024-10-30 18:27:19: [2024-10-30 18:27:19] iter = 07580, loss = 1.6819
2024-10-30 18:27:22: [2024-10-30 18:27:22] iter = 07590, loss = 1.8456
2024-10-30 18:27:25: [2024-10-30 18:27:25] iter = 07600, loss = 3.5337
2024-10-30 18:27:27: [2024-10-30 18:27:27] iter = 07610, loss = 1.7046
2024-10-30 18:27:31: [2024-10-30 18:27:31] iter = 07620, loss = 2.0451
2024-10-30 18:27:35: [2024-10-30 18:27:35] iter = 07630, loss = 1.9236
2024-10-30 18:27:39: [2024-10-30 18:27:39] iter = 07640, loss = 2.2505
2024-10-30 18:27:43: [2024-10-30 18:27:43] iter = 07650, loss = 2.9458
2024-10-30 18:27:47: [2024-10-30 18:27:47] iter = 07660, loss = 2.1583
2024-10-30 18:27:49: [2024-10-30 18:27:49] iter = 07670, loss = 2.7159
2024-10-30 18:27:52: [2024-10-30 18:27:52] iter = 07680, loss = 1.9220
2024-10-30 18:27:56: [2024-10-30 18:27:56] iter = 07690, loss = 2.7303
2024-10-30 18:27:59: [2024-10-30 18:27:59] iter = 07700, loss = 1.9002
2024-10-30 18:28:03: [2024-10-30 18:28:03] iter = 07710, loss = 1.9540
2024-10-30 18:28:07: [2024-10-30 18:28:07] iter = 07720, loss = 2.3952
2024-10-30 18:28:10: [2024-10-30 18:28:10] iter = 07730, loss = 2.7462
2024-10-30 18:28:13: [2024-10-30 18:28:13] iter = 07740, loss = 2.3712
2024-10-30 18:28:17: [2024-10-30 18:28:17] iter = 07750, loss = 2.1163
2024-10-30 18:28:21: [2024-10-30 18:28:21] iter = 07760, loss = 2.2640
2024-10-30 18:28:25: [2024-10-30 18:28:24] iter = 07770, loss = 2.1588
2024-10-30 18:28:27: [2024-10-30 18:28:27] iter = 07780, loss = 3.5476
2024-10-30 18:28:29: [2024-10-30 18:28:29] iter = 07790, loss = 2.7461
2024-10-30 18:28:34: [2024-10-30 18:28:34] iter = 07800, loss = 2.1306
2024-10-30 18:28:36: [2024-10-30 18:28:36] iter = 07810, loss = 2.1691
2024-10-30 18:28:39: [2024-10-30 18:28:39] iter = 07820, loss = 2.2141
2024-10-30 18:28:43: [2024-10-30 18:28:43] iter = 07830, loss = 2.2495
2024-10-30 18:28:45: [2024-10-30 18:28:45] iter = 07840, loss = 2.0810
2024-10-30 18:28:49: [2024-10-30 18:28:49] iter = 07850, loss = 1.7496
2024-10-30 18:28:50: [2024-10-30 18:28:50] iter = 07860, loss = 2.0348
2024-10-30 18:28:52: [2024-10-30 18:28:52] iter = 07870, loss = 2.2407
2024-10-30 18:28:54: [2024-10-30 18:28:54] iter = 07880, loss = 2.1472
2024-10-30 18:28:58: [2024-10-30 18:28:58] iter = 07890, loss = 1.6712
2024-10-30 18:29:01: [2024-10-30 18:29:01] iter = 07900, loss = 2.7653
2024-10-30 18:29:03: [2024-10-30 18:29:03] iter = 07910, loss = 2.2414
2024-10-30 18:29:05: [2024-10-30 18:29:05] iter = 07920, loss = 1.7416
2024-10-30 18:29:09: [2024-10-30 18:29:09] iter = 07930, loss = 2.0365
2024-10-30 18:29:13: [2024-10-30 18:29:13] iter = 07940, loss = 4.3367
2024-10-30 18:29:17: [2024-10-30 18:29:17] iter = 07950, loss = 1.9875
2024-10-30 18:29:20: [2024-10-30 18:29:20] iter = 07960, loss = 3.1028
2024-10-30 18:29:24: [2024-10-30 18:29:24] iter = 07970, loss = 2.2528
2024-10-30 18:29:27: [2024-10-30 18:29:27] iter = 07980, loss = 2.1122
2024-10-30 18:29:30: [2024-10-30 18:29:30] iter = 07990, loss = 1.9777
2024-10-30 18:29:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 18:29:34: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:29:34: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 74106}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:31:51: Evaluate 5 random ConvNet, ACCmean = 0.7836 ACCstd = 0.0034
-------------------------
2024-10-30 18:31:51: Evaluate 5 random ConvNet, SENmean = 0.7780 SENstd = 0.0028
-------------------------
2024-10-30 18:31:51: Evaluate 5 random ConvNet, SPEmean = 0.9780 SPEstd = 0.0004
-------------------------
2024-10-30 18:31:51: Evaluate 5 random ConvNet, F!mean = 0.7721 F!std = 0.0031
-------------------------
2024-10-30 18:31:51: Evaluate 5 random ConvNet, mean = 0.7836 std = 0.0034
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:31:51: [2024-10-30 18:31:51] iter = 08000, loss = 2.2547
2024-10-30 18:31:56: [2024-10-30 18:31:56] iter = 08010, loss = 3.3634
2024-10-30 18:31:59: [2024-10-30 18:31:59] iter = 08020, loss = 2.5758
2024-10-30 18:32:02: [2024-10-30 18:32:02] iter = 08030, loss = 1.7852
2024-10-30 18:32:05: [2024-10-30 18:32:05] iter = 08040, loss = 1.8435
2024-10-30 18:32:07: [2024-10-30 18:32:07] iter = 08050, loss = 2.0181
2024-10-30 18:32:11: [2024-10-30 18:32:11] iter = 08060, loss = 2.2245
2024-10-30 18:32:14: [2024-10-30 18:32:14] iter = 08070, loss = 2.2552
2024-10-30 18:32:18: [2024-10-30 18:32:18] iter = 08080, loss = 2.4401
2024-10-30 18:32:21: [2024-10-30 18:32:21] iter = 08090, loss = 4.2658
2024-10-30 18:32:24: [2024-10-30 18:32:24] iter = 08100, loss = 1.9168
2024-10-30 18:32:28: [2024-10-30 18:32:28] iter = 08110, loss = 2.0241
2024-10-30 18:32:31: [2024-10-30 18:32:31] iter = 08120, loss = 2.2456
2024-10-30 18:32:34: [2024-10-30 18:32:34] iter = 08130, loss = 1.7891
2024-10-30 18:32:38: [2024-10-30 18:32:38] iter = 08140, loss = 1.9277
2024-10-30 18:32:42: [2024-10-30 18:32:42] iter = 08150, loss = 2.7110
2024-10-30 18:32:45: [2024-10-30 18:32:45] iter = 08160, loss = 2.0125
2024-10-30 18:32:49: [2024-10-30 18:32:49] iter = 08170, loss = 2.0147
2024-10-30 18:32:52: [2024-10-30 18:32:52] iter = 08180, loss = 1.9671
2024-10-30 18:32:56: [2024-10-30 18:32:56] iter = 08190, loss = 2.9433
2024-10-30 18:33:00: [2024-10-30 18:33:00] iter = 08200, loss = 2.0911
2024-10-30 18:33:03: [2024-10-30 18:33:03] iter = 08210, loss = 1.7145
2024-10-30 18:33:06: [2024-10-30 18:33:06] iter = 08220, loss = 2.1900
2024-10-30 18:33:11: [2024-10-30 18:33:11] iter = 08230, loss = 2.0449
2024-10-30 18:33:13: [2024-10-30 18:33:13] iter = 08240, loss = 2.3478
2024-10-30 18:33:16: [2024-10-30 18:33:16] iter = 08250, loss = 2.0476
2024-10-30 18:33:20: [2024-10-30 18:33:20] iter = 08260, loss = 1.7459
2024-10-30 18:33:24: [2024-10-30 18:33:24] iter = 08270, loss = 2.3253
2024-10-30 18:33:28: [2024-10-30 18:33:28] iter = 08280, loss = 2.1888
2024-10-30 18:33:32: [2024-10-30 18:33:32] iter = 08290, loss = 1.6847
2024-10-30 18:33:35: [2024-10-30 18:33:35] iter = 08300, loss = 1.9195
2024-10-30 18:33:39: [2024-10-30 18:33:39] iter = 08310, loss = 2.1636
2024-10-30 18:33:43: [2024-10-30 18:33:43] iter = 08320, loss = 2.9907
2024-10-30 18:33:46: [2024-10-30 18:33:46] iter = 08330, loss = 2.4060
2024-10-30 18:33:49: [2024-10-30 18:33:49] iter = 08340, loss = 2.2062
2024-10-30 18:33:53: [2024-10-30 18:33:53] iter = 08350, loss = 1.8012
2024-10-30 18:33:56: [2024-10-30 18:33:56] iter = 08360, loss = 2.5793
2024-10-30 18:33:59: [2024-10-30 18:33:59] iter = 08370, loss = 1.6667
2024-10-30 18:34:02: [2024-10-30 18:34:02] iter = 08380, loss = 2.0631
2024-10-30 18:34:06: [2024-10-30 18:34:06] iter = 08390, loss = 3.5779
2024-10-30 18:34:09: [2024-10-30 18:34:09] iter = 08400, loss = 3.1288
2024-10-30 18:34:13: [2024-10-30 18:34:13] iter = 08410, loss = 1.9745
2024-10-30 18:34:17: [2024-10-30 18:34:17] iter = 08420, loss = 1.9548
2024-10-30 18:34:20: [2024-10-30 18:34:20] iter = 08430, loss = 2.0816
2024-10-30 18:34:24: [2024-10-30 18:34:24] iter = 08440, loss = 2.5400
2024-10-30 18:34:28: [2024-10-30 18:34:28] iter = 08450, loss = 2.7537
2024-10-30 18:34:32: [2024-10-30 18:34:32] iter = 08460, loss = 1.7823
2024-10-30 18:34:35: [2024-10-30 18:34:35] iter = 08470, loss = 3.1069
2024-10-30 18:34:38: [2024-10-30 18:34:38] iter = 08480, loss = 2.3481
2024-10-30 18:34:42: [2024-10-30 18:34:42] iter = 08490, loss = 2.6040
2024-10-30 18:34:46: [2024-10-30 18:34:46] iter = 08500, loss = 1.8188
2024-10-30 18:34:49: [2024-10-30 18:34:49] iter = 08510, loss = 1.7847
2024-10-30 18:34:53: [2024-10-30 18:34:53] iter = 08520, loss = 3.0446
2024-10-30 18:34:56: [2024-10-30 18:34:56] iter = 08530, loss = 2.6704
2024-10-30 18:35:00: [2024-10-30 18:35:00] iter = 08540, loss = 3.2704
2024-10-30 18:35:04: [2024-10-30 18:35:04] iter = 08550, loss = 2.0456
2024-10-30 18:35:07: [2024-10-30 18:35:07] iter = 08560, loss = 2.5861
2024-10-30 18:35:10: [2024-10-30 18:35:10] iter = 08570, loss = 2.1497
2024-10-30 18:35:14: [2024-10-30 18:35:14] iter = 08580, loss = 1.6561
2024-10-30 18:35:17: [2024-10-30 18:35:17] iter = 08590, loss = 3.6760
2024-10-30 18:35:21: [2024-10-30 18:35:21] iter = 08600, loss = 2.1180
2024-10-30 18:35:25: [2024-10-30 18:35:25] iter = 08610, loss = 1.9496
2024-10-30 18:35:29: [2024-10-30 18:35:29] iter = 08620, loss = 2.2382
2024-10-30 18:35:32: [2024-10-30 18:35:32] iter = 08630, loss = 3.3587
2024-10-30 18:35:36: [2024-10-30 18:35:36] iter = 08640, loss = 1.9342
2024-10-30 18:35:39: [2024-10-30 18:35:39] iter = 08650, loss = 2.0603
2024-10-30 18:35:42: [2024-10-30 18:35:42] iter = 08660, loss = 1.8652
2024-10-30 18:35:46: [2024-10-30 18:35:46] iter = 08670, loss = 2.0524
2024-10-30 18:35:49: [2024-10-30 18:35:49] iter = 08680, loss = 3.6763
2024-10-30 18:35:53: [2024-10-30 18:35:53] iter = 08690, loss = 2.1426
2024-10-30 18:35:57: [2024-10-30 18:35:57] iter = 08700, loss = 2.2856
2024-10-30 18:36:02: [2024-10-30 18:36:02] iter = 08710, loss = 2.1920
2024-10-30 18:36:06: [2024-10-30 18:36:06] iter = 08720, loss = 2.4953
2024-10-30 18:36:09: [2024-10-30 18:36:09] iter = 08730, loss = 1.5918
2024-10-30 18:36:13: [2024-10-30 18:36:13] iter = 08740, loss = 2.0610
2024-10-30 18:36:16: [2024-10-30 18:36:16] iter = 08750, loss = 2.5403
2024-10-30 18:36:19: [2024-10-30 18:36:19] iter = 08760, loss = 3.8892
2024-10-30 18:36:23: [2024-10-30 18:36:23] iter = 08770, loss = 2.4154
2024-10-30 18:36:27: [2024-10-30 18:36:27] iter = 08780, loss = 2.1987
2024-10-30 18:36:30: [2024-10-30 18:36:30] iter = 08790, loss = 2.0698
2024-10-30 18:36:34: [2024-10-30 18:36:34] iter = 08800, loss = 1.8980
2024-10-30 18:36:38: [2024-10-30 18:36:38] iter = 08810, loss = 3.7108
2024-10-30 18:36:42: [2024-10-30 18:36:42] iter = 08820, loss = 1.8538
2024-10-30 18:36:47: [2024-10-30 18:36:47] iter = 08830, loss = 2.1977
2024-10-30 18:36:51: [2024-10-30 18:36:51] iter = 08840, loss = 2.1398
2024-10-30 18:36:56: [2024-10-30 18:36:56] iter = 08850, loss = 2.0636
2024-10-30 18:37:00: [2024-10-30 18:37:00] iter = 08860, loss = 1.9052
2024-10-30 18:37:04: [2024-10-30 18:37:04] iter = 08870, loss = 3.8208
2024-10-30 18:37:08: [2024-10-30 18:37:08] iter = 08880, loss = 2.4971
2024-10-30 18:37:13: [2024-10-30 18:37:13] iter = 08890, loss = 1.7723
2024-10-30 18:37:16: [2024-10-30 18:37:16] iter = 08900, loss = 1.9986
2024-10-30 18:37:19: [2024-10-30 18:37:19] iter = 08910, loss = 1.9699
2024-10-30 18:37:23: [2024-10-30 18:37:23] iter = 08920, loss = 1.8604
2024-10-30 18:37:26: [2024-10-30 18:37:26] iter = 08930, loss = 1.7548
2024-10-30 18:37:29: [2024-10-30 18:37:29] iter = 08940, loss = 2.5218
2024-10-30 18:37:33: [2024-10-30 18:37:33] iter = 08950, loss = 2.2403
2024-10-30 18:37:36: [2024-10-30 18:37:36] iter = 08960, loss = 2.1353
2024-10-30 18:37:39: [2024-10-30 18:37:39] iter = 08970, loss = 4.4256
2024-10-30 18:37:43: [2024-10-30 18:37:43] iter = 08980, loss = 1.9406
2024-10-30 18:37:46: [2024-10-30 18:37:46] iter = 08990, loss = 4.8773
2024-10-30 18:37:50: [2024-10-30 18:37:50] iter = 09000, loss = 2.0158
2024-10-30 18:37:54: [2024-10-30 18:37:54] iter = 09010, loss = 1.8080
2024-10-30 18:37:58: [2024-10-30 18:37:58] iter = 09020, loss = 2.7080
2024-10-30 18:38:02: [2024-10-30 18:38:02] iter = 09030, loss = 1.8150
2024-10-30 18:38:06: [2024-10-30 18:38:06] iter = 09040, loss = 1.9205
2024-10-30 18:38:10: [2024-10-30 18:38:10] iter = 09050, loss = 1.9555
2024-10-30 18:38:13: [2024-10-30 18:38:13] iter = 09060, loss = 3.0796
2024-10-30 18:38:17: [2024-10-30 18:38:17] iter = 09070, loss = 2.6077
2024-10-30 18:38:22: [2024-10-30 18:38:22] iter = 09080, loss = 2.3970
2024-10-30 18:38:25: [2024-10-30 18:38:25] iter = 09090, loss = 2.1809
2024-10-30 18:38:30: [2024-10-30 18:38:30] iter = 09100, loss = 6.2312
2024-10-30 18:38:33: [2024-10-30 18:38:33] iter = 09110, loss = 1.8910
2024-10-30 18:38:36: [2024-10-30 18:38:36] iter = 09120, loss = 2.2641
2024-10-30 18:38:39: [2024-10-30 18:38:39] iter = 09130, loss = 2.8690
2024-10-30 18:38:43: [2024-10-30 18:38:43] iter = 09140, loss = 1.8390
2024-10-30 18:38:47: [2024-10-30 18:38:47] iter = 09150, loss = 1.7500
2024-10-30 18:38:50: [2024-10-30 18:38:50] iter = 09160, loss = 2.0083
2024-10-30 18:38:53: [2024-10-30 18:38:53] iter = 09170, loss = 1.8523
2024-10-30 18:38:57: [2024-10-30 18:38:57] iter = 09180, loss = 2.2852
2024-10-30 18:39:01: [2024-10-30 18:39:01] iter = 09190, loss = 2.6056
2024-10-30 18:39:05: [2024-10-30 18:39:05] iter = 09200, loss = 2.2387
2024-10-30 18:39:07: [2024-10-30 18:39:07] iter = 09210, loss = 2.2120
2024-10-30 18:39:10: [2024-10-30 18:39:10] iter = 09220, loss = 2.2402
2024-10-30 18:39:14: [2024-10-30 18:39:14] iter = 09230, loss = 1.7167
2024-10-30 18:39:18: [2024-10-30 18:39:18] iter = 09240, loss = 2.6822
2024-10-30 18:39:22: [2024-10-30 18:39:22] iter = 09250, loss = 2.3827
2024-10-30 18:39:25: [2024-10-30 18:39:25] iter = 09260, loss = 2.4415
2024-10-30 18:39:30: [2024-10-30 18:39:30] iter = 09270, loss = 2.4032
2024-10-30 18:39:34: [2024-10-30 18:39:34] iter = 09280, loss = 2.0421
2024-10-30 18:39:38: [2024-10-30 18:39:38] iter = 09290, loss = 3.4580
2024-10-30 18:39:42: [2024-10-30 18:39:42] iter = 09300, loss = 2.0622
2024-10-30 18:39:46: [2024-10-30 18:39:46] iter = 09310, loss = 1.9059
2024-10-30 18:39:49: [2024-10-30 18:39:49] iter = 09320, loss = 1.7667
2024-10-30 18:39:53: [2024-10-30 18:39:53] iter = 09330, loss = 2.2155
2024-10-30 18:39:56: [2024-10-30 18:39:56] iter = 09340, loss = 2.1590
2024-10-30 18:40:00: [2024-10-30 18:40:00] iter = 09350, loss = 2.9806
2024-10-30 18:40:04: [2024-10-30 18:40:04] iter = 09360, loss = 1.8706
2024-10-30 18:40:07: [2024-10-30 18:40:07] iter = 09370, loss = 1.9697
2024-10-30 18:40:11: [2024-10-30 18:40:11] iter = 09380, loss = 2.4205
2024-10-30 18:40:15: [2024-10-30 18:40:15] iter = 09390, loss = 3.6961
2024-10-30 18:40:18: [2024-10-30 18:40:18] iter = 09400, loss = 1.8078
2024-10-30 18:40:21: [2024-10-30 18:40:21] iter = 09410, loss = 2.9014
2024-10-30 18:40:23: [2024-10-30 18:40:23] iter = 09420, loss = 2.7366
2024-10-30 18:40:26: [2024-10-30 18:40:26] iter = 09430, loss = 2.3049
2024-10-30 18:40:30: [2024-10-30 18:40:30] iter = 09440, loss = 3.2933
2024-10-30 18:40:34: [2024-10-30 18:40:34] iter = 09450, loss = 1.9588
2024-10-30 18:40:36: [2024-10-30 18:40:36] iter = 09460, loss = 1.9476
2024-10-30 18:40:40: [2024-10-30 18:40:40] iter = 09470, loss = 2.5497
2024-10-30 18:40:44: [2024-10-30 18:40:44] iter = 09480, loss = 1.9907
2024-10-30 18:40:47: [2024-10-30 18:40:47] iter = 09490, loss = 2.0039
2024-10-30 18:40:51: [2024-10-30 18:40:51] iter = 09500, loss = 1.4761
2024-10-30 18:40:55: [2024-10-30 18:40:55] iter = 09510, loss = 1.9854
2024-10-30 18:40:58: [2024-10-30 18:40:58] iter = 09520, loss = 2.6457
2024-10-30 18:41:02: [2024-10-30 18:41:02] iter = 09530, loss = 1.8128
2024-10-30 18:41:05: [2024-10-30 18:41:05] iter = 09540, loss = 1.7196
2024-10-30 18:41:09: [2024-10-30 18:41:09] iter = 09550, loss = 2.0907
2024-10-30 18:41:11: [2024-10-30 18:41:11] iter = 09560, loss = 2.9791
2024-10-30 18:41:15: [2024-10-30 18:41:15] iter = 09570, loss = 1.9249
2024-10-30 18:41:18: [2024-10-30 18:41:18] iter = 09580, loss = 2.1747
2024-10-30 18:41:22: [2024-10-30 18:41:22] iter = 09590, loss = 1.5472
2024-10-30 18:41:26: [2024-10-30 18:41:26] iter = 09600, loss = 2.6745
2024-10-30 18:41:30: [2024-10-30 18:41:30] iter = 09610, loss = 3.7834
2024-10-30 18:41:34: [2024-10-30 18:41:34] iter = 09620, loss = 1.9514
2024-10-30 18:41:38: [2024-10-30 18:41:38] iter = 09630, loss = 2.3912
2024-10-30 18:41:42: [2024-10-30 18:41:42] iter = 09640, loss = 1.8747
2024-10-30 18:41:46: [2024-10-30 18:41:46] iter = 09650, loss = 1.6739
2024-10-30 18:41:48: [2024-10-30 18:41:48] iter = 09660, loss = 1.6322
2024-10-30 18:41:50: [2024-10-30 18:41:50] iter = 09670, loss = 2.1471
2024-10-30 18:41:54: [2024-10-30 18:41:54] iter = 09680, loss = 2.3737
2024-10-30 18:41:57: [2024-10-30 18:41:57] iter = 09690, loss = 1.9187
2024-10-30 18:42:01: [2024-10-30 18:42:01] iter = 09700, loss = 2.1124
2024-10-30 18:42:05: [2024-10-30 18:42:05] iter = 09710, loss = 1.7267
2024-10-30 18:42:09: [2024-10-30 18:42:09] iter = 09720, loss = 2.5252
2024-10-30 18:42:12: [2024-10-30 18:42:12] iter = 09730, loss = 6.2070
2024-10-30 18:42:16: [2024-10-30 18:42:16] iter = 09740, loss = 1.7633
2024-10-30 18:42:20: [2024-10-30 18:42:20] iter = 09750, loss = 2.8827
2024-10-30 18:42:23: [2024-10-30 18:42:23] iter = 09760, loss = 2.2641
2024-10-30 18:42:26: [2024-10-30 18:42:26] iter = 09770, loss = 2.0748
2024-10-30 18:42:30: [2024-10-30 18:42:30] iter = 09780, loss = 2.5453
2024-10-30 18:42:34: [2024-10-30 18:42:34] iter = 09790, loss = 1.6718
2024-10-30 18:42:38: [2024-10-30 18:42:38] iter = 09800, loss = 2.6210
2024-10-30 18:42:40: [2024-10-30 18:42:40] iter = 09810, loss = 3.1866
2024-10-30 18:42:44: [2024-10-30 18:42:44] iter = 09820, loss = 2.9852
2024-10-30 18:42:47: [2024-10-30 18:42:47] iter = 09830, loss = 2.3909
2024-10-30 18:42:52: [2024-10-30 18:42:52] iter = 09840, loss = 2.0878
2024-10-30 18:42:56: [2024-10-30 18:42:56] iter = 09850, loss = 1.9826
2024-10-30 18:43:00: [2024-10-30 18:43:00] iter = 09860, loss = 2.5500
2024-10-30 18:43:04: [2024-10-30 18:43:04] iter = 09870, loss = 2.4995
2024-10-30 18:43:08: [2024-10-30 18:43:08] iter = 09880, loss = 2.0192
2024-10-30 18:43:12: [2024-10-30 18:43:12] iter = 09890, loss = 2.7093
2024-10-30 18:43:17: [2024-10-30 18:43:17] iter = 09900, loss = 1.7760
2024-10-30 18:43:21: [2024-10-30 18:43:21] iter = 09910, loss = 2.0232
2024-10-30 18:43:24: [2024-10-30 18:43:24] iter = 09920, loss = 1.6239
2024-10-30 18:43:29: [2024-10-30 18:43:29] iter = 09930, loss = 1.9612
2024-10-30 18:43:32: [2024-10-30 18:43:32] iter = 09940, loss = 2.6741
2024-10-30 18:43:34: [2024-10-30 18:43:34] iter = 09950, loss = 2.6708
2024-10-30 18:43:35: [2024-10-30 18:43:35] iter = 09960, loss = 1.9171
2024-10-30 18:43:38: [2024-10-30 18:43:38] iter = 09970, loss = 2.0822
2024-10-30 18:43:41: [2024-10-30 18:43:41] iter = 09980, loss = 2.1261
2024-10-30 18:43:45: [2024-10-30 18:43:45] iter = 09990, loss = 2.4808
2024-10-30 18:43:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 18:43:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:43:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 27936}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:46:11: Evaluate 5 random ConvNet, ACCmean = 0.7853 ACCstd = 0.0065
-------------------------
2024-10-30 18:46:11: Evaluate 5 random ConvNet, SENmean = 0.7764 SENstd = 0.0059
-------------------------
2024-10-30 18:46:11: Evaluate 5 random ConvNet, SPEmean = 0.9782 SPEstd = 0.0007
-------------------------
2024-10-30 18:46:11: Evaluate 5 random ConvNet, F!mean = 0.7709 F!std = 0.0057
-------------------------
2024-10-30 18:46:11: Evaluate 5 random ConvNet, mean = 0.7853 std = 0.0065
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:46:11: [2024-10-30 18:46:11] iter = 10000, loss = 2.0668
2024-10-30 18:46:15: [2024-10-30 18:46:15] iter = 10010, loss = 2.0874
2024-10-30 18:46:19: [2024-10-30 18:46:19] iter = 10020, loss = 3.3601
2024-10-30 18:46:22: [2024-10-30 18:46:22] iter = 10030, loss = 1.6930
2024-10-30 18:46:26: [2024-10-30 18:46:26] iter = 10040, loss = 1.9104
2024-10-30 18:46:29: [2024-10-30 18:46:29] iter = 10050, loss = 2.1932
2024-10-30 18:46:33: [2024-10-30 18:46:33] iter = 10060, loss = 2.0384
2024-10-30 18:46:36: [2024-10-30 18:46:36] iter = 10070, loss = 1.8859
2024-10-30 18:46:40: [2024-10-30 18:46:40] iter = 10080, loss = 2.1190
2024-10-30 18:46:43: [2024-10-30 18:46:43] iter = 10090, loss = 2.7461
2024-10-30 18:46:48: [2024-10-30 18:46:48] iter = 10100, loss = 2.3555
2024-10-30 18:46:51: [2024-10-30 18:46:51] iter = 10110, loss = 2.4209
2024-10-30 18:46:55: [2024-10-30 18:46:55] iter = 10120, loss = 2.7246
2024-10-30 18:46:59: [2024-10-30 18:46:59] iter = 10130, loss = 2.8386
2024-10-30 18:47:03: [2024-10-30 18:47:03] iter = 10140, loss = 2.0023
2024-10-30 18:47:06: [2024-10-30 18:47:06] iter = 10150, loss = 2.0789
2024-10-30 18:47:09: [2024-10-30 18:47:09] iter = 10160, loss = 1.8473
2024-10-30 18:47:12: [2024-10-30 18:47:12] iter = 10170, loss = 2.1111
2024-10-30 18:47:15: [2024-10-30 18:47:15] iter = 10180, loss = 2.4383
2024-10-30 18:47:20: [2024-10-30 18:47:20] iter = 10190, loss = 2.8327
2024-10-30 18:47:24: [2024-10-30 18:47:24] iter = 10200, loss = 2.7385
2024-10-30 18:47:27: [2024-10-30 18:47:27] iter = 10210, loss = 1.8776
2024-10-30 18:47:31: [2024-10-30 18:47:31] iter = 10220, loss = 2.9811
2024-10-30 18:47:35: [2024-10-30 18:47:35] iter = 10230, loss = 2.0477
2024-10-30 18:47:37: [2024-10-30 18:47:37] iter = 10240, loss = 2.3275
2024-10-30 18:47:41: [2024-10-30 18:47:41] iter = 10250, loss = 1.8989
2024-10-30 18:47:44: [2024-10-30 18:47:44] iter = 10260, loss = 2.4916
2024-10-30 18:47:47: [2024-10-30 18:47:47] iter = 10270, loss = 1.9880
2024-10-30 18:47:50: [2024-10-30 18:47:50] iter = 10280, loss = 2.6312
2024-10-30 18:47:55: [2024-10-30 18:47:55] iter = 10290, loss = 1.6933
2024-10-30 18:47:58: [2024-10-30 18:47:58] iter = 10300, loss = 2.4042
2024-10-30 18:48:02: [2024-10-30 18:48:02] iter = 10310, loss = 1.8468
2024-10-30 18:48:06: [2024-10-30 18:48:06] iter = 10320, loss = 1.8139
2024-10-30 18:48:09: [2024-10-30 18:48:09] iter = 10330, loss = 2.0966
2024-10-30 18:48:13: [2024-10-30 18:48:13] iter = 10340, loss = 2.5917
2024-10-30 18:48:15: [2024-10-30 18:48:15] iter = 10350, loss = 1.7991
2024-10-30 18:48:19: [2024-10-30 18:48:19] iter = 10360, loss = 1.9427
2024-10-30 18:48:22: [2024-10-30 18:48:22] iter = 10370, loss = 1.7046
2024-10-30 18:48:25: [2024-10-30 18:48:25] iter = 10380, loss = 2.8375
2024-10-30 18:48:29: [2024-10-30 18:48:29] iter = 10390, loss = 2.7992
2024-10-30 18:48:33: [2024-10-30 18:48:33] iter = 10400, loss = 1.9009
2024-10-30 18:48:36: [2024-10-30 18:48:36] iter = 10410, loss = 2.6199
2024-10-30 18:48:40: [2024-10-30 18:48:40] iter = 10420, loss = 1.9535
2024-10-30 18:48:43: [2024-10-30 18:48:43] iter = 10430, loss = 2.0355
2024-10-30 18:48:46: [2024-10-30 18:48:46] iter = 10440, loss = 1.7043
2024-10-30 18:48:49: [2024-10-30 18:48:49] iter = 10450, loss = 3.6742
2024-10-30 18:48:52: [2024-10-30 18:48:52] iter = 10460, loss = 2.2463
2024-10-30 18:48:54: [2024-10-30 18:48:54] iter = 10470, loss = 2.6756
2024-10-30 18:48:57: [2024-10-30 18:48:57] iter = 10480, loss = 3.1060
2024-10-30 18:49:00: [2024-10-30 18:49:00] iter = 10490, loss = 2.0494
2024-10-30 18:49:04: [2024-10-30 18:49:04] iter = 10500, loss = 4.5982
2024-10-30 18:49:08: [2024-10-30 18:49:08] iter = 10510, loss = 1.9532
2024-10-30 18:49:11: [2024-10-30 18:49:11] iter = 10520, loss = 2.6737
2024-10-30 18:49:14: [2024-10-30 18:49:14] iter = 10530, loss = 1.8959
2024-10-30 18:49:17: [2024-10-30 18:49:17] iter = 10540, loss = 5.1662
2024-10-30 18:49:21: [2024-10-30 18:49:21] iter = 10550, loss = 2.0168
2024-10-30 18:49:25: [2024-10-30 18:49:25] iter = 10560, loss = 2.0844
2024-10-30 18:49:28: [2024-10-30 18:49:28] iter = 10570, loss = 2.4270
2024-10-30 18:49:31: [2024-10-30 18:49:31] iter = 10580, loss = 1.9276
2024-10-30 18:49:35: [2024-10-30 18:49:35] iter = 10590, loss = 2.3890
2024-10-30 18:49:39: [2024-10-30 18:49:39] iter = 10600, loss = 2.9688
2024-10-30 18:49:43: [2024-10-30 18:49:43] iter = 10610, loss = 1.9709
2024-10-30 18:49:47: [2024-10-30 18:49:47] iter = 10620, loss = 1.6025
2024-10-30 18:49:51: [2024-10-30 18:49:51] iter = 10630, loss = 1.9589
2024-10-30 18:49:56: [2024-10-30 18:49:56] iter = 10640, loss = 2.2487
2024-10-30 18:49:59: [2024-10-30 18:49:59] iter = 10650, loss = 2.4239
2024-10-30 18:50:02: [2024-10-30 18:50:02] iter = 10660, loss = 2.1937
2024-10-30 18:50:06: [2024-10-30 18:50:06] iter = 10670, loss = 2.1571
2024-10-30 18:50:08: [2024-10-30 18:50:08] iter = 10680, loss = 1.9361
2024-10-30 18:50:11: [2024-10-30 18:50:11] iter = 10690, loss = 2.1235
2024-10-30 18:50:15: [2024-10-30 18:50:15] iter = 10700, loss = 3.6094
2024-10-30 18:50:19: [2024-10-30 18:50:19] iter = 10710, loss = 2.6651
2024-10-30 18:50:22: [2024-10-30 18:50:22] iter = 10720, loss = 2.7658
2024-10-30 18:50:25: [2024-10-30 18:50:25] iter = 10730, loss = 2.4094
2024-10-30 18:50:29: [2024-10-30 18:50:29] iter = 10740, loss = 2.7303
2024-10-30 18:50:33: [2024-10-30 18:50:33] iter = 10750, loss = 1.7323
2024-10-30 18:50:35: [2024-10-30 18:50:35] iter = 10760, loss = 2.0587
2024-10-30 18:50:38: [2024-10-30 18:50:37] iter = 10770, loss = 1.9745
2024-10-30 18:50:41: [2024-10-30 18:50:41] iter = 10780, loss = 3.0089
2024-10-30 18:50:45: [2024-10-30 18:50:45] iter = 10790, loss = 3.6960
2024-10-30 18:50:48: [2024-10-30 18:50:48] iter = 10800, loss = 1.9911
2024-10-30 18:50:52: [2024-10-30 18:50:52] iter = 10810, loss = 2.7242
2024-10-30 18:50:54: [2024-10-30 18:50:54] iter = 10820, loss = 2.6431
2024-10-30 18:50:58: [2024-10-30 18:50:58] iter = 10830, loss = 4.9934
2024-10-30 18:51:01: [2024-10-30 18:51:01] iter = 10840, loss = 2.1796
2024-10-30 18:51:04: [2024-10-30 18:51:04] iter = 10850, loss = 2.0525
2024-10-30 18:51:08: [2024-10-30 18:51:08] iter = 10860, loss = 2.6006
2024-10-30 18:51:11: [2024-10-30 18:51:11] iter = 10870, loss = 2.4526
2024-10-30 18:51:14: [2024-10-30 18:51:14] iter = 10880, loss = 2.3602
2024-10-30 18:51:18: [2024-10-30 18:51:18] iter = 10890, loss = 2.0168
2024-10-30 18:51:22: [2024-10-30 18:51:22] iter = 10900, loss = 1.8989
2024-10-30 18:51:26: [2024-10-30 18:51:26] iter = 10910, loss = 2.0639
2024-10-30 18:51:29: [2024-10-30 18:51:29] iter = 10920, loss = 2.1290
2024-10-30 18:51:32: [2024-10-30 18:51:32] iter = 10930, loss = 1.8619
2024-10-30 18:51:35: [2024-10-30 18:51:35] iter = 10940, loss = 1.9653
2024-10-30 18:51:38: [2024-10-30 18:51:38] iter = 10950, loss = 2.0250
2024-10-30 18:51:41: [2024-10-30 18:51:41] iter = 10960, loss = 1.8404
2024-10-30 18:51:44: [2024-10-30 18:51:44] iter = 10970, loss = 2.0416
2024-10-30 18:51:47: [2024-10-30 18:51:47] iter = 10980, loss = 2.2878
2024-10-30 18:51:50: [2024-10-30 18:51:50] iter = 10990, loss = 2.4810
2024-10-30 18:51:54: [2024-10-30 18:51:54] iter = 11000, loss = 1.9713
2024-10-30 18:51:57: [2024-10-30 18:51:57] iter = 11010, loss = 1.6724
2024-10-30 18:51:59: [2024-10-30 18:51:59] iter = 11020, loss = 1.9903
2024-10-30 18:52:02: [2024-10-30 18:52:02] iter = 11030, loss = 1.7308
2024-10-30 18:52:06: [2024-10-30 18:52:06] iter = 11040, loss = 1.6957
2024-10-30 18:52:09: [2024-10-30 18:52:09] iter = 11050, loss = 2.0279
2024-10-30 18:52:13: [2024-10-30 18:52:13] iter = 11060, loss = 1.6624
2024-10-30 18:52:17: [2024-10-30 18:52:17] iter = 11070, loss = 1.7352
2024-10-30 18:52:21: [2024-10-30 18:52:21] iter = 11080, loss = 4.7842
2024-10-30 18:52:24: [2024-10-30 18:52:24] iter = 11090, loss = 2.6448
2024-10-30 18:52:27: [2024-10-30 18:52:27] iter = 11100, loss = 3.1066
2024-10-30 18:52:31: [2024-10-30 18:52:31] iter = 11110, loss = 2.8711
2024-10-30 18:52:34: [2024-10-30 18:52:34] iter = 11120, loss = 1.8903
2024-10-30 18:52:37: [2024-10-30 18:52:37] iter = 11130, loss = 2.0691
2024-10-30 18:52:40: [2024-10-30 18:52:40] iter = 11140, loss = 1.9666
2024-10-30 18:52:44: [2024-10-30 18:52:44] iter = 11150, loss = 2.2731
2024-10-30 18:52:47: [2024-10-30 18:52:47] iter = 11160, loss = 2.0824
2024-10-30 18:52:51: [2024-10-30 18:52:51] iter = 11170, loss = 1.5403
2024-10-30 18:52:55: [2024-10-30 18:52:55] iter = 11180, loss = 2.1761
2024-10-30 18:52:58: [2024-10-30 18:52:58] iter = 11190, loss = 1.9554
2024-10-30 18:53:01: [2024-10-30 18:53:01] iter = 11200, loss = 2.4197
2024-10-30 18:53:05: [2024-10-30 18:53:05] iter = 11210, loss = 1.8832
2024-10-30 18:53:07: [2024-10-30 18:53:07] iter = 11220, loss = 2.0108
2024-10-30 18:53:10: [2024-10-30 18:53:10] iter = 11230, loss = 1.8865
2024-10-30 18:53:13: [2024-10-30 18:53:13] iter = 11240, loss = 1.7885
2024-10-30 18:53:17: [2024-10-30 18:53:17] iter = 11250, loss = 1.6347
2024-10-30 18:53:20: [2024-10-30 18:53:20] iter = 11260, loss = 2.2479
2024-10-30 18:53:24: [2024-10-30 18:53:24] iter = 11270, loss = 2.6888
2024-10-30 18:53:27: [2024-10-30 18:53:27] iter = 11280, loss = 2.4640
2024-10-30 18:53:30: [2024-10-30 18:53:30] iter = 11290, loss = 3.8917
2024-10-30 18:53:35: [2024-10-30 18:53:35] iter = 11300, loss = 2.2244
2024-10-30 18:53:38: [2024-10-30 18:53:38] iter = 11310, loss = 4.2479
2024-10-30 18:53:41: [2024-10-30 18:53:41] iter = 11320, loss = 2.0263
2024-10-30 18:53:45: [2024-10-30 18:53:45] iter = 11330, loss = 2.1668
2024-10-30 18:53:47: [2024-10-30 18:53:47] iter = 11340, loss = 2.2150
2024-10-30 18:53:49: [2024-10-30 18:53:49] iter = 11350, loss = 3.2129
2024-10-30 18:53:52: [2024-10-30 18:53:52] iter = 11360, loss = 2.0120
2024-10-30 18:53:56: [2024-10-30 18:53:56] iter = 11370, loss = 2.2393
2024-10-30 18:53:59: [2024-10-30 18:53:59] iter = 11380, loss = 2.1629
2024-10-30 18:54:03: [2024-10-30 18:54:03] iter = 11390, loss = 2.0879
2024-10-30 18:54:06: [2024-10-30 18:54:06] iter = 11400, loss = 4.5323
2024-10-30 18:54:10: [2024-10-30 18:54:10] iter = 11410, loss = 2.2259
2024-10-30 18:54:14: [2024-10-30 18:54:14] iter = 11420, loss = 1.9646
2024-10-30 18:54:17: [2024-10-30 18:54:17] iter = 11430, loss = 1.9960
2024-10-30 18:54:20: [2024-10-30 18:54:20] iter = 11440, loss = 2.4292
2024-10-30 18:54:23: [2024-10-30 18:54:23] iter = 11450, loss = 2.1263
2024-10-30 18:54:27: [2024-10-30 18:54:27] iter = 11460, loss = 1.5059
2024-10-30 18:54:30: [2024-10-30 18:54:30] iter = 11470, loss = 1.8387
2024-10-30 18:54:33: [2024-10-30 18:54:33] iter = 11480, loss = 2.4404
2024-10-30 18:54:36: [2024-10-30 18:54:36] iter = 11490, loss = 1.8527
2024-10-30 18:54:40: [2024-10-30 18:54:40] iter = 11500, loss = 2.3753
2024-10-30 18:54:43: [2024-10-30 18:54:43] iter = 11510, loss = 1.6615
2024-10-30 18:54:47: [2024-10-30 18:54:47] iter = 11520, loss = 2.1467
2024-10-30 18:54:50: [2024-10-30 18:54:50] iter = 11530, loss = 1.6628
2024-10-30 18:54:55: [2024-10-30 18:54:55] iter = 11540, loss = 1.9126
2024-10-30 18:54:58: [2024-10-30 18:54:58] iter = 11550, loss = 1.6981
2024-10-30 18:55:01: [2024-10-30 18:55:01] iter = 11560, loss = 1.9708
2024-10-30 18:55:05: [2024-10-30 18:55:05] iter = 11570, loss = 2.1341
2024-10-30 18:55:09: [2024-10-30 18:55:09] iter = 11580, loss = 1.9357
2024-10-30 18:55:13: [2024-10-30 18:55:13] iter = 11590, loss = 1.6252
2024-10-30 18:55:16: [2024-10-30 18:55:16] iter = 11600, loss = 2.0726
2024-10-30 18:55:20: [2024-10-30 18:55:20] iter = 11610, loss = 1.7402
2024-10-30 18:55:24: [2024-10-30 18:55:24] iter = 11620, loss = 1.4854
2024-10-30 18:55:25: [2024-10-30 18:55:25] iter = 11630, loss = 1.7765
2024-10-30 18:55:27: [2024-10-30 18:55:27] iter = 11640, loss = 1.8051
2024-10-30 18:55:31: [2024-10-30 18:55:31] iter = 11650, loss = 2.1266
2024-10-30 18:55:35: [2024-10-30 18:55:35] iter = 11660, loss = 3.0155
2024-10-30 18:55:38: [2024-10-30 18:55:38] iter = 11670, loss = 1.9620
2024-10-30 18:55:41: [2024-10-30 18:55:41] iter = 11680, loss = 2.4625
2024-10-30 18:55:45: [2024-10-30 18:55:45] iter = 11690, loss = 2.0302
2024-10-30 18:55:49: [2024-10-30 18:55:49] iter = 11700, loss = 3.0893
2024-10-30 18:55:52: [2024-10-30 18:55:52] iter = 11710, loss = 2.3253
2024-10-30 18:55:56: [2024-10-30 18:55:56] iter = 11720, loss = 2.1935
2024-10-30 18:56:00: [2024-10-30 18:56:00] iter = 11730, loss = 1.8454
2024-10-30 18:56:04: [2024-10-30 18:56:04] iter = 11740, loss = 1.9081
2024-10-30 18:56:08: [2024-10-30 18:56:08] iter = 11750, loss = 2.1240
2024-10-30 18:56:12: [2024-10-30 18:56:12] iter = 11760, loss = 2.5972
2024-10-30 18:56:16: [2024-10-30 18:56:16] iter = 11770, loss = 1.9599
2024-10-30 18:56:19: [2024-10-30 18:56:19] iter = 11780, loss = 3.2832
2024-10-30 18:56:22: [2024-10-30 18:56:22] iter = 11790, loss = 1.7010
2024-10-30 18:56:26: [2024-10-30 18:56:26] iter = 11800, loss = 1.7956
2024-10-30 18:56:28: [2024-10-30 18:56:28] iter = 11810, loss = 1.9838
2024-10-30 18:56:32: [2024-10-30 18:56:32] iter = 11820, loss = 2.7509
2024-10-30 18:56:34: [2024-10-30 18:56:34] iter = 11830, loss = 1.9315
2024-10-30 18:56:38: [2024-10-30 18:56:38] iter = 11840, loss = 1.8857
2024-10-30 18:56:42: [2024-10-30 18:56:42] iter = 11850, loss = 3.4329
2024-10-30 18:56:45: [2024-10-30 18:56:45] iter = 11860, loss = 1.8603
2024-10-30 18:56:49: [2024-10-30 18:56:49] iter = 11870, loss = 2.4130
2024-10-30 18:56:53: [2024-10-30 18:56:53] iter = 11880, loss = 2.0616
2024-10-30 18:56:57: [2024-10-30 18:56:57] iter = 11890, loss = 2.3551
2024-10-30 18:57:00: [2024-10-30 18:57:00] iter = 11900, loss = 5.4941
2024-10-30 18:57:04: [2024-10-30 18:57:04] iter = 11910, loss = 1.6701
2024-10-30 18:57:08: [2024-10-30 18:57:08] iter = 11920, loss = 3.1488
2024-10-30 18:57:12: [2024-10-30 18:57:12] iter = 11930, loss = 3.0117
2024-10-30 18:57:16: [2024-10-30 18:57:16] iter = 11940, loss = 1.9791
2024-10-30 18:57:20: [2024-10-30 18:57:20] iter = 11950, loss = 1.9769
2024-10-30 18:57:25: [2024-10-30 18:57:25] iter = 11960, loss = 2.1446
2024-10-30 18:57:28: [2024-10-30 18:57:28] iter = 11970, loss = 2.2652
2024-10-30 18:57:30: [2024-10-30 18:57:30] iter = 11980, loss = 1.9486
2024-10-30 18:57:33: [2024-10-30 18:57:33] iter = 11990, loss = 1.6719
2024-10-30 18:57:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 18:57:36: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:57:36: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 56197}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:59:46: Evaluate 5 random ConvNet, ACCmean = 0.7825 ACCstd = 0.0029
-------------------------
2024-10-30 18:59:46: Evaluate 5 random ConvNet, SENmean = 0.7778 SENstd = 0.0034
-------------------------
2024-10-30 18:59:46: Evaluate 5 random ConvNet, SPEmean = 0.9780 SPEstd = 0.0003
-------------------------
2024-10-30 18:59:46: Evaluate 5 random ConvNet, F!mean = 0.7711 F!std = 0.0021
-------------------------
2024-10-30 18:59:46: Evaluate 5 random ConvNet, mean = 0.7825 std = 0.0029
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:59:46: [2024-10-30 18:59:46] iter = 12000, loss = 1.9000
2024-10-30 18:59:49: [2024-10-30 18:59:49] iter = 12010, loss = 1.9674
2024-10-30 18:59:53: [2024-10-30 18:59:53] iter = 12020, loss = 2.0167
2024-10-30 18:59:56: [2024-10-30 18:59:56] iter = 12030, loss = 2.1060
2024-10-30 19:00:00: [2024-10-30 19:00:00] iter = 12040, loss = 1.6967
2024-10-30 19:00:05: [2024-10-30 19:00:05] iter = 12050, loss = 2.1943
2024-10-30 19:00:08: [2024-10-30 19:00:08] iter = 12060, loss = 1.7843
2024-10-30 19:00:11: [2024-10-30 19:00:11] iter = 12070, loss = 1.8607
2024-10-30 19:00:15: [2024-10-30 19:00:15] iter = 12080, loss = 1.7749
2024-10-30 19:00:18: [2024-10-30 19:00:18] iter = 12090, loss = 2.3285
2024-10-30 19:00:22: [2024-10-30 19:00:22] iter = 12100, loss = 1.8422
2024-10-30 19:00:26: [2024-10-30 19:00:26] iter = 12110, loss = 1.8353
2024-10-30 19:00:31: [2024-10-30 19:00:31] iter = 12120, loss = 4.5282
2024-10-30 19:00:35: [2024-10-30 19:00:35] iter = 12130, loss = 1.6515
2024-10-30 19:00:39: [2024-10-30 19:00:39] iter = 12140, loss = 1.8546
2024-10-30 19:00:42: [2024-10-30 19:00:42] iter = 12150, loss = 1.6943
2024-10-30 19:00:47: [2024-10-30 19:00:47] iter = 12160, loss = 2.9462
2024-10-30 19:00:51: [2024-10-30 19:00:51] iter = 12170, loss = 1.8098
2024-10-30 19:00:55: [2024-10-30 19:00:55] iter = 12180, loss = 2.1465
2024-10-30 19:00:59: [2024-10-30 19:00:59] iter = 12190, loss = 2.0596
2024-10-30 19:01:03: [2024-10-30 19:01:03] iter = 12200, loss = 1.5357
2024-10-30 19:01:06: [2024-10-30 19:01:06] iter = 12210, loss = 3.4217
2024-10-30 19:01:11: [2024-10-30 19:01:11] iter = 12220, loss = 2.3313
2024-10-30 19:01:15: [2024-10-30 19:01:15] iter = 12230, loss = 1.8944
2024-10-30 19:01:19: [2024-10-30 19:01:19] iter = 12240, loss = 2.9318
2024-10-30 19:01:23: [2024-10-30 19:01:23] iter = 12250, loss = 2.7321
2024-10-30 19:01:27: [2024-10-30 19:01:27] iter = 12260, loss = 2.0055
2024-10-30 19:01:31: [2024-10-30 19:01:31] iter = 12270, loss = 3.4530
2024-10-30 19:01:34: [2024-10-30 19:01:34] iter = 12280, loss = 1.4180
2024-10-30 19:01:38: [2024-10-30 19:01:38] iter = 12290, loss = 2.9618
2024-10-30 19:01:43: [2024-10-30 19:01:43] iter = 12300, loss = 1.9762
2024-10-30 19:01:47: [2024-10-30 19:01:47] iter = 12310, loss = 1.7424
2024-10-30 19:01:49: [2024-10-30 19:01:49] iter = 12320, loss = 3.2732
2024-10-30 19:01:52: [2024-10-30 19:01:52] iter = 12330, loss = 2.1147
2024-10-30 19:01:55: [2024-10-30 19:01:55] iter = 12340, loss = 3.9730
2024-10-30 19:01:59: [2024-10-30 19:01:59] iter = 12350, loss = 2.1187
2024-10-30 19:02:02: [2024-10-30 19:02:02] iter = 12360, loss = 1.4508
2024-10-30 19:02:05: [2024-10-30 19:02:05] iter = 12370, loss = 1.8723
2024-10-30 19:02:08: [2024-10-30 19:02:08] iter = 12380, loss = 1.9480
2024-10-30 19:02:10: [2024-10-30 19:02:10] iter = 12390, loss = 4.5672
2024-10-30 19:02:13: [2024-10-30 19:02:13] iter = 12400, loss = 1.9021
2024-10-30 19:02:15: [2024-10-30 19:02:15] iter = 12410, loss = 2.2667
2024-10-30 19:02:18: [2024-10-30 19:02:18] iter = 12420, loss = 1.9132
2024-10-30 19:02:22: [2024-10-30 19:02:22] iter = 12430, loss = 2.8294
2024-10-30 19:02:26: [2024-10-30 19:02:26] iter = 12440, loss = 1.8869
2024-10-30 19:02:29: [2024-10-30 19:02:29] iter = 12450, loss = 1.9293
2024-10-30 19:02:33: [2024-10-30 19:02:33] iter = 12460, loss = 2.0331
2024-10-30 19:02:36: [2024-10-30 19:02:36] iter = 12470, loss = 2.5607
2024-10-30 19:02:39: [2024-10-30 19:02:39] iter = 12480, loss = 3.6490
2024-10-30 19:02:43: [2024-10-30 19:02:43] iter = 12490, loss = 1.7073
2024-10-30 19:02:47: [2024-10-30 19:02:47] iter = 12500, loss = 2.0247
2024-10-30 19:02:50: [2024-10-30 19:02:50] iter = 12510, loss = 2.1032
2024-10-30 19:02:53: [2024-10-30 19:02:53] iter = 12520, loss = 2.3699
2024-10-30 19:02:57: [2024-10-30 19:02:57] iter = 12530, loss = 1.9053
2024-10-30 19:03:00: [2024-10-30 19:03:00] iter = 12540, loss = 3.3694
2024-10-30 19:03:04: [2024-10-30 19:03:04] iter = 12550, loss = 2.1028
2024-10-30 19:03:09: [2024-10-30 19:03:09] iter = 12560, loss = 6.6565
2024-10-30 19:03:12: [2024-10-30 19:03:12] iter = 12570, loss = 2.0073
2024-10-30 19:03:16: [2024-10-30 19:03:16] iter = 12580, loss = 1.8805
2024-10-30 19:03:20: [2024-10-30 19:03:20] iter = 12590, loss = 1.7640
2024-10-30 19:03:25: [2024-10-30 19:03:25] iter = 12600, loss = 2.1894
2024-10-30 19:03:28: [2024-10-30 19:03:28] iter = 12610, loss = 2.2098
2024-10-30 19:03:33: [2024-10-30 19:03:33] iter = 12620, loss = 2.0320
2024-10-30 19:03:37: [2024-10-30 19:03:37] iter = 12630, loss = 3.8449
2024-10-30 19:03:42: [2024-10-30 19:03:42] iter = 12640, loss = 1.9709
2024-10-30 19:03:46: [2024-10-30 19:03:46] iter = 12650, loss = 2.1579
2024-10-30 19:03:50: [2024-10-30 19:03:50] iter = 12660, loss = 2.2574
2024-10-30 19:03:53: [2024-10-30 19:03:53] iter = 12670, loss = 2.6312
2024-10-30 19:03:58: [2024-10-30 19:03:58] iter = 12680, loss = 1.9418
2024-10-30 19:04:02: [2024-10-30 19:04:02] iter = 12690, loss = 2.1290
2024-10-30 19:04:06: [2024-10-30 19:04:06] iter = 12700, loss = 2.1329
2024-10-30 19:04:10: [2024-10-30 19:04:10] iter = 12710, loss = 1.6999
2024-10-30 19:04:14: [2024-10-30 19:04:14] iter = 12720, loss = 1.7340
2024-10-30 19:04:18: [2024-10-30 19:04:18] iter = 12730, loss = 2.4699
2024-10-30 19:04:22: [2024-10-30 19:04:22] iter = 12740, loss = 1.7358
2024-10-30 19:04:26: [2024-10-30 19:04:26] iter = 12750, loss = 2.3259
2024-10-30 19:04:30: [2024-10-30 19:04:30] iter = 12760, loss = 1.9436
2024-10-30 19:04:34: [2024-10-30 19:04:34] iter = 12770, loss = 1.6777
2024-10-30 19:04:38: [2024-10-30 19:04:38] iter = 12780, loss = 1.7124
2024-10-30 19:04:42: [2024-10-30 19:04:42] iter = 12790, loss = 2.0939
2024-10-30 19:04:46: [2024-10-30 19:04:46] iter = 12800, loss = 1.6431
2024-10-30 19:04:50: [2024-10-30 19:04:50] iter = 12810, loss = 1.6661
2024-10-30 19:04:55: [2024-10-30 19:04:55] iter = 12820, loss = 2.7673
2024-10-30 19:04:58: [2024-10-30 19:04:58] iter = 12830, loss = 1.8242
2024-10-30 19:05:03: [2024-10-30 19:05:03] iter = 12840, loss = 1.7997
2024-10-30 19:05:07: [2024-10-30 19:05:07] iter = 12850, loss = 1.8400
2024-10-30 19:05:11: [2024-10-30 19:05:11] iter = 12860, loss = 2.7283
2024-10-30 19:05:14: [2024-10-30 19:05:14] iter = 12870, loss = 1.6362
2024-10-30 19:05:18: [2024-10-30 19:05:18] iter = 12880, loss = 4.1162
2024-10-30 19:05:22: [2024-10-30 19:05:22] iter = 12890, loss = 2.1960
2024-10-30 19:05:26: [2024-10-30 19:05:26] iter = 12900, loss = 1.7102
2024-10-30 19:05:31: [2024-10-30 19:05:31] iter = 12910, loss = 2.1096
2024-10-30 19:05:35: [2024-10-30 19:05:35] iter = 12920, loss = 1.9868
2024-10-30 19:05:39: [2024-10-30 19:05:39] iter = 12930, loss = 1.9665
2024-10-30 19:05:43: [2024-10-30 19:05:43] iter = 12940, loss = 2.8264
2024-10-30 19:05:47: [2024-10-30 19:05:47] iter = 12950, loss = 2.0773
2024-10-30 19:05:51: [2024-10-30 19:05:51] iter = 12960, loss = 1.8342
2024-10-30 19:05:55: [2024-10-30 19:05:55] iter = 12970, loss = 1.6301
2024-10-30 19:05:58: [2024-10-30 19:05:58] iter = 12980, loss = 1.8732
2024-10-30 19:06:01: [2024-10-30 19:06:01] iter = 12990, loss = 2.1826
2024-10-30 19:06:05: [2024-10-30 19:06:05] iter = 13000, loss = 1.7323
2024-10-30 19:06:08: [2024-10-30 19:06:08] iter = 13010, loss = 1.7715
2024-10-30 19:06:12: [2024-10-30 19:06:12] iter = 13020, loss = 2.2478
2024-10-30 19:06:16: [2024-10-30 19:06:16] iter = 13030, loss = 2.5373
2024-10-30 19:06:20: [2024-10-30 19:06:20] iter = 13040, loss = 2.3886
2024-10-30 19:06:24: [2024-10-30 19:06:24] iter = 13050, loss = 1.7041
2024-10-30 19:06:26: [2024-10-30 19:06:26] iter = 13060, loss = 1.8556
2024-10-30 19:06:30: [2024-10-30 19:06:30] iter = 13070, loss = 1.9226
2024-10-30 19:06:33: [2024-10-30 19:06:33] iter = 13080, loss = 1.7503
2024-10-30 19:06:37: [2024-10-30 19:06:37] iter = 13090, loss = 3.1650
2024-10-30 19:06:40: [2024-10-30 19:06:40] iter = 13100, loss = 1.5528
2024-10-30 19:06:44: [2024-10-30 19:06:44] iter = 13110, loss = 2.9476
2024-10-30 19:06:47: [2024-10-30 19:06:47] iter = 13120, loss = 3.3493
2024-10-30 19:06:51: [2024-10-30 19:06:51] iter = 13130, loss = 2.5391
2024-10-30 19:06:55: [2024-10-30 19:06:55] iter = 13140, loss = 3.6772
2024-10-30 19:06:59: [2024-10-30 19:06:59] iter = 13150, loss = 2.2074
2024-10-30 19:07:03: [2024-10-30 19:07:03] iter = 13160, loss = 2.3374
2024-10-30 19:07:07: [2024-10-30 19:07:07] iter = 13170, loss = 3.4610
2024-10-30 19:07:11: [2024-10-30 19:07:11] iter = 13180, loss = 3.4150
2024-10-30 19:07:15: [2024-10-30 19:07:15] iter = 13190, loss = 4.1853
2024-10-30 19:07:19: [2024-10-30 19:07:19] iter = 13200, loss = 1.9591
2024-10-30 19:07:23: [2024-10-30 19:07:23] iter = 13210, loss = 2.7878
2024-10-30 19:07:26: [2024-10-30 19:07:26] iter = 13220, loss = 1.9945
2024-10-30 19:07:30: [2024-10-30 19:07:30] iter = 13230, loss = 2.4730
2024-10-30 19:07:34: [2024-10-30 19:07:34] iter = 13240, loss = 1.9382
2024-10-30 19:07:37: [2024-10-30 19:07:37] iter = 13250, loss = 1.8489
2024-10-30 19:07:40: [2024-10-30 19:07:40] iter = 13260, loss = 2.5437
2024-10-30 19:07:44: [2024-10-30 19:07:44] iter = 13270, loss = 2.1628
2024-10-30 19:07:48: [2024-10-30 19:07:48] iter = 13280, loss = 1.9172
2024-10-30 19:07:52: [2024-10-30 19:07:52] iter = 13290, loss = 1.8825
2024-10-30 19:07:56: [2024-10-30 19:07:56] iter = 13300, loss = 2.3054
2024-10-30 19:07:59: [2024-10-30 19:07:59] iter = 13310, loss = 3.0414
2024-10-30 19:08:03: [2024-10-30 19:08:03] iter = 13320, loss = 2.5163
2024-10-30 19:08:07: [2024-10-30 19:08:07] iter = 13330, loss = 2.7525
2024-10-30 19:08:11: [2024-10-30 19:08:11] iter = 13340, loss = 1.7414
2024-10-30 19:08:15: [2024-10-30 19:08:15] iter = 13350, loss = 2.5645
2024-10-30 19:08:19: [2024-10-30 19:08:19] iter = 13360, loss = 2.0018
2024-10-30 19:08:22: [2024-10-30 19:08:22] iter = 13370, loss = 1.8386
2024-10-30 19:08:25: [2024-10-30 19:08:25] iter = 13380, loss = 2.2493
2024-10-30 19:08:29: [2024-10-30 19:08:29] iter = 13390, loss = 1.8184
2024-10-30 19:08:33: [2024-10-30 19:08:33] iter = 13400, loss = 1.9108
2024-10-30 19:08:37: [2024-10-30 19:08:37] iter = 13410, loss = 1.9888
2024-10-30 19:08:41: [2024-10-30 19:08:41] iter = 13420, loss = 1.9780
2024-10-30 19:08:45: [2024-10-30 19:08:45] iter = 13430, loss = 3.4846
2024-10-30 19:08:49: [2024-10-30 19:08:49] iter = 13440, loss = 3.0277
2024-10-30 19:08:53: [2024-10-30 19:08:53] iter = 13450, loss = 2.4018
2024-10-30 19:08:57: [2024-10-30 19:08:57] iter = 13460, loss = 1.9419
2024-10-30 19:09:01: [2024-10-30 19:09:01] iter = 13470, loss = 2.4833
2024-10-30 19:09:04: [2024-10-30 19:09:04] iter = 13480, loss = 2.0288
2024-10-30 19:09:08: [2024-10-30 19:09:08] iter = 13490, loss = 3.7853
2024-10-30 19:09:12: [2024-10-30 19:09:12] iter = 13500, loss = 1.7337
2024-10-30 19:09:16: [2024-10-30 19:09:16] iter = 13510, loss = 2.0211
2024-10-30 19:09:20: [2024-10-30 19:09:20] iter = 13520, loss = 1.6091
2024-10-30 19:09:24: [2024-10-30 19:09:24] iter = 13530, loss = 1.7472
2024-10-30 19:09:27: [2024-10-30 19:09:27] iter = 13540, loss = 1.7512
2024-10-30 19:09:30: [2024-10-30 19:09:30] iter = 13550, loss = 2.0971
2024-10-30 19:09:33: [2024-10-30 19:09:33] iter = 13560, loss = 2.4128
2024-10-30 19:09:37: [2024-10-30 19:09:37] iter = 13570, loss = 1.8688
2024-10-30 19:09:40: [2024-10-30 19:09:40] iter = 13580, loss = 2.0601
2024-10-30 19:09:43: [2024-10-30 19:09:43] iter = 13590, loss = 2.1452
2024-10-30 19:09:47: [2024-10-30 19:09:47] iter = 13600, loss = 2.4687
2024-10-30 19:09:50: [2024-10-30 19:09:50] iter = 13610, loss = 1.9247
2024-10-30 19:09:53: [2024-10-30 19:09:53] iter = 13620, loss = 2.5737
2024-10-30 19:09:56: [2024-10-30 19:09:56] iter = 13630, loss = 2.1525
2024-10-30 19:09:59: [2024-10-30 19:09:59] iter = 13640, loss = 2.6308
2024-10-30 19:10:02: [2024-10-30 19:10:02] iter = 13650, loss = 2.7697
2024-10-30 19:10:06: [2024-10-30 19:10:06] iter = 13660, loss = 1.7347
2024-10-30 19:10:09: [2024-10-30 19:10:09] iter = 13670, loss = 2.3450
2024-10-30 19:10:12: [2024-10-30 19:10:12] iter = 13680, loss = 2.0719
2024-10-30 19:10:16: [2024-10-30 19:10:16] iter = 13690, loss = 2.7800
2024-10-30 19:10:19: [2024-10-30 19:10:19] iter = 13700, loss = 1.7711
2024-10-30 19:10:22: [2024-10-30 19:10:22] iter = 13710, loss = 2.5167
2024-10-30 19:10:25: [2024-10-30 19:10:25] iter = 13720, loss = 2.1591
2024-10-30 19:10:28: [2024-10-30 19:10:28] iter = 13730, loss = 2.1557
2024-10-30 19:10:32: [2024-10-30 19:10:32] iter = 13740, loss = 1.6939
2024-10-30 19:10:36: [2024-10-30 19:10:36] iter = 13750, loss = 1.8149
2024-10-30 19:10:38: [2024-10-30 19:10:38] iter = 13760, loss = 2.7993
2024-10-30 19:10:42: [2024-10-30 19:10:42] iter = 13770, loss = 2.1403
2024-10-30 19:10:45: [2024-10-30 19:10:45] iter = 13780, loss = 1.8692
2024-10-30 19:10:47: [2024-10-30 19:10:47] iter = 13790, loss = 1.8003
2024-10-30 19:10:50: [2024-10-30 19:10:50] iter = 13800, loss = 4.4572
2024-10-30 19:10:55: [2024-10-30 19:10:55] iter = 13810, loss = 3.2026
2024-10-30 19:10:59: [2024-10-30 19:10:59] iter = 13820, loss = 2.3206
2024-10-30 19:11:01: [2024-10-30 19:11:01] iter = 13830, loss = 3.0344
2024-10-30 19:11:05: [2024-10-30 19:11:05] iter = 13840, loss = 2.1550
2024-10-30 19:11:09: [2024-10-30 19:11:09] iter = 13850, loss = 1.6947
2024-10-30 19:11:12: [2024-10-30 19:11:12] iter = 13860, loss = 1.8756
2024-10-30 19:11:15: [2024-10-30 19:11:15] iter = 13870, loss = 3.0942
2024-10-30 19:11:18: [2024-10-30 19:11:18] iter = 13880, loss = 1.9618
2024-10-30 19:11:22: [2024-10-30 19:11:22] iter = 13890, loss = 2.6849
2024-10-30 19:11:25: [2024-10-30 19:11:25] iter = 13900, loss = 1.8261
2024-10-30 19:11:28: [2024-10-30 19:11:28] iter = 13910, loss = 2.2314
2024-10-30 19:11:33: [2024-10-30 19:11:33] iter = 13920, loss = 1.9820
2024-10-30 19:11:37: [2024-10-30 19:11:37] iter = 13930, loss = 1.8285
2024-10-30 19:11:41: [2024-10-30 19:11:41] iter = 13940, loss = 2.4692
2024-10-30 19:11:44: [2024-10-30 19:11:44] iter = 13950, loss = 5.8951
2024-10-30 19:11:47: [2024-10-30 19:11:47] iter = 13960, loss = 2.5780
2024-10-30 19:11:50: [2024-10-30 19:11:50] iter = 13970, loss = 2.2884
2024-10-30 19:11:54: [2024-10-30 19:11:54] iter = 13980, loss = 2.8279
2024-10-30 19:11:58: [2024-10-30 19:11:58] iter = 13990, loss = 1.9434
2024-10-30 19:12:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 19:12:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:12:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 21451}

[2024-10-30 17:15:25] Evaluate_00: epoch = 1000 train time = 31 s train loss = 0.014878 train acc = 1.0000, test acc = 0.7763, test_sen =0.7753, test_spe =0.9774, test_f1 =0.7648
[2024-10-30 17:16:00] Evaluate_01: epoch = 1000 train time = 34 s train loss = 0.013137 train acc = 1.0000, test acc = 0.7762, test_sen =0.7701, test_spe =0.9774, test_f1 =0.7627
[2024-10-30 17:16:35] Evaluate_02: epoch = 1000 train time = 34 s train loss = 0.003435 train acc = 1.0000, test acc = 0.7791, test_sen =0.7760, test_spe =0.9778, test_f1 =0.7646
[2024-10-30 17:17:06] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.010154 train acc = 1.0000, test acc = 0.7815, test_sen =0.7762, test_spe =0.9779, test_f1 =0.7694
[2024-10-30 17:17:31] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.033630 train acc = 1.0000, test acc = 0.7765, test_sen =0.7750, test_spe =0.9775, test_f1 =0.7640
[2024-10-30 17:31:20] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.003988 train acc = 1.0000, test acc = 0.7815, test_sen =0.7750, test_spe =0.9779, test_f1 =0.7673
[2024-10-30 17:31:47] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.009343 train acc = 1.0000, test acc = 0.7847, test_sen =0.7781, test_spe =0.9781, test_f1 =0.7706
[2024-10-30 17:32:16] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.014732 train acc = 1.0000, test acc = 0.7824, test_sen =0.7756, test_spe =0.9780, test_f1 =0.7679
[2024-10-30 17:32:45] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.003126 train acc = 1.0000, test acc = 0.7781, test_sen =0.7722, test_spe =0.9775, test_f1 =0.7666
[2024-10-30 17:33:12] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.003509 train acc = 1.0000, test acc = 0.7760, test_sen =0.7698, test_spe =0.9772, test_f1 =0.7636
[2024-10-30 17:33:39] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.009868 train acc = 1.0000, test acc = 0.7016, test_sen =0.6966, test_spe =0.9699, test_f1 =0.6860
[2024-10-30 17:34:10] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.002264 train acc = 1.0000, test acc = 0.7012, test_sen =0.6965, test_spe =0.9697, test_f1 =0.6874
[2024-10-30 17:34:40] Evaluate_02: epoch = 1000 train time = 29 s train loss = 0.043483 train acc = 0.9909, test acc = 0.6973, test_sen =0.6924, test_spe =0.9695, test_f1 =0.6812
[2024-10-30 17:35:13] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.009357 train acc = 1.0000, test acc = 0.6990, test_sen =0.6951, test_spe =0.9697, test_f1 =0.6847
[2024-10-30 17:35:41] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.011105 train acc = 1.0000, test acc = 0.6969, test_sen =0.6922, test_spe =0.9694, test_f1 =0.6813
[2024-10-30 17:47:56] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.006649 train acc = 1.0000, test acc = 0.7823, test_sen =0.7758, test_spe =0.9780, test_f1 =0.7665
[2024-10-30 17:48:23] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.005959 train acc = 1.0000, test acc = 0.7842, test_sen =0.7788, test_spe =0.9783, test_f1 =0.7678
[2024-10-30 17:48:51] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.003856 train acc = 1.0000, test acc = 0.7857, test_sen =0.7780, test_spe =0.9783, test_f1 =0.7707
[2024-10-30 17:49:20] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.003433 train acc = 1.0000, test acc = 0.7785, test_sen =0.7704, test_spe =0.9776, test_f1 =0.7628
[2024-10-30 17:49:49] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.003287 train acc = 1.0000, test acc = 0.7837, test_sen =0.7785, test_spe =0.9782, test_f1 =0.7685
[2024-10-30 18:02:00] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.002266 train acc = 1.0000, test acc = 0.7852, test_sen =0.7762, test_spe =0.9782, test_f1 =0.7702
[2024-10-30 18:02:31] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.004422 train acc = 1.0000, test acc = 0.7753, test_sen =0.7700, test_spe =0.9773, test_f1 =0.7632
[2024-10-30 18:02:58] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.015633 train acc = 1.0000, test acc = 0.7816, test_sen =0.7734, test_spe =0.9779, test_f1 =0.7686
[2024-10-30 18:03:26] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.009800 train acc = 1.0000, test acc = 0.7824, test_sen =0.7800, test_spe =0.9780, test_f1 =0.7719
[2024-10-30 18:03:54] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.003012 train acc = 1.0000, test acc = 0.7722, test_sen =0.7653, test_spe =0.9770, test_f1 =0.7592
[2024-10-30 18:16:13] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.010134 train acc = 1.0000, test acc = 0.7821, test_sen =0.7756, test_spe =0.9780, test_f1 =0.7697
[2024-10-30 18:16:34] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.029500 train acc = 1.0000, test acc = 0.7852, test_sen =0.7756, test_spe =0.9782, test_f1 =0.7719
[2024-10-30 18:17:05] Evaluate_02: epoch = 1000 train time = 30 s train loss = 0.025049 train acc = 1.0000, test acc = 0.7810, test_sen =0.7722, test_spe =0.9778, test_f1 =0.7657
[2024-10-30 18:17:35] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.003594 train acc = 1.0000, test acc = 0.7857, test_sen =0.7751, test_spe =0.9783, test_f1 =0.7705
[2024-10-30 18:18:02] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.010095 train acc = 1.0000, test acc = 0.7848, test_sen =0.7768, test_spe =0.9782, test_f1 =0.7724
[2024-10-30 18:30:04] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.003340 train acc = 1.0000, test acc = 0.7859, test_sen =0.7786, test_spe =0.9783, test_f1 =0.7731
[2024-10-30 18:30:32] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.005184 train acc = 1.0000, test acc = 0.7770, test_sen =0.7734, test_spe =0.9773, test_f1 =0.7670
[2024-10-30 18:30:56] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.003492 train acc = 1.0000, test acc = 0.7863, test_sen =0.7814, test_spe =0.9783, test_f1 =0.7764
[2024-10-30 18:31:23] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.008950 train acc = 1.0000, test acc = 0.7853, test_sen =0.7801, test_spe =0.9782, test_f1 =0.7734
[2024-10-30 18:31:51] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.009960 train acc = 1.0000, test acc = 0.7833, test_sen =0.7766, test_spe =0.9780, test_f1 =0.7705
[2024-10-30 18:44:14] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.009333 train acc = 1.0000, test acc = 0.7765, test_sen =0.7688, test_spe =0.9773, test_f1 =0.7629
[2024-10-30 18:44:46] Evaluate_01: epoch = 1000 train time = 30 s train loss = 0.002437 train acc = 1.0000, test acc = 0.7796, test_sen =0.7709, test_spe =0.9776, test_f1 =0.7664
[2024-10-30 18:45:15] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.003151 train acc = 1.0000, test acc = 0.7894, test_sen =0.7808, test_spe =0.9786, test_f1 =0.7758
[2024-10-30 18:45:44] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.007358 train acc = 1.0000, test acc = 0.7863, test_sen =0.7768, test_spe =0.9783, test_f1 =0.7712
[2024-10-30 18:46:11] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.018052 train acc = 1.0000, test acc = 0.7945, test_sen =0.7847, test_spe =0.9792, test_f1 =0.7783
[2024-10-30 18:57:57] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.002722 train acc = 1.0000, test acc = 0.7809, test_sen =0.7745, test_spe =0.9778, test_f1 =0.7701
[2024-10-30 18:58:25] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.009617 train acc = 1.0000, test acc = 0.7864, test_sen =0.7829, test_spe =0.9784, test_f1 =0.7742
[2024-10-30 18:58:50] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.015340 train acc = 1.0000, test acc = 0.7844, test_sen =0.7755, test_spe =0.9782, test_f1 =0.7712
[2024-10-30 18:59:17] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.035981 train acc = 0.9909, test acc = 0.7779, test_sen =0.7752, test_spe =0.9776, test_f1 =0.7679
[2024-10-30 18:59:46] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.017233 train acc = 1.0000, test acc = 0.7829, test_sen =0.7807, test_spe =0.9781, test_f1 =0.7721
[2024-10-30 19:12:28] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.014734 train acc = 1.0000, test acc = 0.7843, test_sen =0.7757, test_spe =0.9781, test_f1 =0.7703/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:14:23: Evaluate 5 random ConvNet, ACCmean = 0.7811 ACCstd = 0.0023
-------------------------
2024-10-30 19:14:23: Evaluate 5 random ConvNet, SENmean = 0.7714 SENstd = 0.0025
-------------------------
2024-10-30 19:14:23: Evaluate 5 random ConvNet, SPEmean = 0.9778 SPEstd = 0.0002
-------------------------
2024-10-30 19:14:23: Evaluate 5 random ConvNet, F!mean = 0.7661 F!std = 0.0029
-------------------------
2024-10-30 19:14:23: Evaluate 5 random ConvNet, mean = 0.7811 std = 0.0023
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:14:24: [2024-10-30 19:14:24] iter = 14000, loss = 2.1650
2024-10-30 19:14:27: [2024-10-30 19:14:27] iter = 14010, loss = 2.5928
2024-10-30 19:14:30: [2024-10-30 19:14:30] iter = 14020, loss = 1.8389
2024-10-30 19:14:33: [2024-10-30 19:14:33] iter = 14030, loss = 1.8577
2024-10-30 19:14:36: [2024-10-30 19:14:36] iter = 14040, loss = 2.2920
2024-10-30 19:14:40: [2024-10-30 19:14:40] iter = 14050, loss = 2.2787
2024-10-30 19:14:43: [2024-10-30 19:14:43] iter = 14060, loss = 1.8489
2024-10-30 19:14:47: [2024-10-30 19:14:47] iter = 14070, loss = 2.2739
2024-10-30 19:14:50: [2024-10-30 19:14:50] iter = 14080, loss = 1.8026
2024-10-30 19:14:54: [2024-10-30 19:14:54] iter = 14090, loss = 2.1941
2024-10-30 19:14:58: [2024-10-30 19:14:58] iter = 14100, loss = 1.8202
2024-10-30 19:15:00: [2024-10-30 19:15:00] iter = 14110, loss = 2.4336
2024-10-30 19:15:05: [2024-10-30 19:15:05] iter = 14120, loss = 2.9270
2024-10-30 19:15:08: [2024-10-30 19:15:08] iter = 14130, loss = 2.8676
2024-10-30 19:15:12: [2024-10-30 19:15:12] iter = 14140, loss = 1.9090
2024-10-30 19:15:15: [2024-10-30 19:15:15] iter = 14150, loss = 2.1482
2024-10-30 19:15:18: [2024-10-30 19:15:18] iter = 14160, loss = 1.9915
2024-10-30 19:15:21: [2024-10-30 19:15:21] iter = 14170, loss = 3.9931
2024-10-30 19:15:25: [2024-10-30 19:15:25] iter = 14180, loss = 1.8891
2024-10-30 19:15:29: [2024-10-30 19:15:29] iter = 14190, loss = 1.8094
2024-10-30 19:15:33: [2024-10-30 19:15:33] iter = 14200, loss = 2.3202
2024-10-30 19:15:36: [2024-10-30 19:15:36] iter = 14210, loss = 2.2116
2024-10-30 19:15:41: [2024-10-30 19:15:41] iter = 14220, loss = 3.3327
2024-10-30 19:15:45: [2024-10-30 19:15:45] iter = 14230, loss = 2.7013
2024-10-30 19:15:49: [2024-10-30 19:15:49] iter = 14240, loss = 2.8615
2024-10-30 19:15:53: [2024-10-30 19:15:53] iter = 14250, loss = 1.7051
2024-10-30 19:15:57: [2024-10-30 19:15:57] iter = 14260, loss = 1.9135
2024-10-30 19:16:00: [2024-10-30 19:16:00] iter = 14270, loss = 1.7753
2024-10-30 19:16:04: [2024-10-30 19:16:04] iter = 14280, loss = 1.7076
2024-10-30 19:16:08: [2024-10-30 19:16:08] iter = 14290, loss = 2.1789
2024-10-30 19:16:12: [2024-10-30 19:16:12] iter = 14300, loss = 2.0826
2024-10-30 19:16:14: [2024-10-30 19:16:14] iter = 14310, loss = 1.6162
2024-10-30 19:16:18: [2024-10-30 19:16:18] iter = 14320, loss = 2.0335
2024-10-30 19:16:21: [2024-10-30 19:16:21] iter = 14330, loss = 3.3019
2024-10-30 19:16:24: [2024-10-30 19:16:24] iter = 14340, loss = 3.3499
2024-10-30 19:16:28: [2024-10-30 19:16:28] iter = 14350, loss = 2.3546
2024-10-30 19:16:31: [2024-10-30 19:16:31] iter = 14360, loss = 2.0418
2024-10-30 19:16:34: [2024-10-30 19:16:34] iter = 14370, loss = 1.9636
2024-10-30 19:16:38: [2024-10-30 19:16:38] iter = 14380, loss = 2.6856
2024-10-30 19:16:41: [2024-10-30 19:16:41] iter = 14390, loss = 1.7572
2024-10-30 19:16:45: [2024-10-30 19:16:45] iter = 14400, loss = 1.8557
2024-10-30 19:16:49: [2024-10-30 19:16:49] iter = 14410, loss = 2.1458
2024-10-30 19:16:53: [2024-10-30 19:16:53] iter = 14420, loss = 2.9526
2024-10-30 19:16:57: [2024-10-30 19:16:57] iter = 14430, loss = 1.8818
2024-10-30 19:17:01: [2024-10-30 19:17:01] iter = 14440, loss = 2.6083
2024-10-30 19:17:04: [2024-10-30 19:17:04] iter = 14450, loss = 1.7730
2024-10-30 19:17:07: [2024-10-30 19:17:07] iter = 14460, loss = 2.1019
2024-10-30 19:17:12: [2024-10-30 19:17:12] iter = 14470, loss = 2.2456
2024-10-30 19:17:16: [2024-10-30 19:17:16] iter = 14480, loss = 2.0650
2024-10-30 19:17:19: [2024-10-30 19:17:19] iter = 14490, loss = 2.1359
2024-10-30 19:17:24: [2024-10-30 19:17:24] iter = 14500, loss = 2.5191
2024-10-30 19:17:27: [2024-10-30 19:17:27] iter = 14510, loss = 2.2593
2024-10-30 19:17:31: [2024-10-30 19:17:31] iter = 14520, loss = 1.7727
2024-10-30 19:17:35: [2024-10-30 19:17:35] iter = 14530, loss = 2.0895
2024-10-30 19:17:38: [2024-10-30 19:17:38] iter = 14540, loss = 2.0098
2024-10-30 19:17:41: [2024-10-30 19:17:41] iter = 14550, loss = 1.9061
2024-10-30 19:17:45: [2024-10-30 19:17:45] iter = 14560, loss = 1.8224
2024-10-30 19:17:49: [2024-10-30 19:17:49] iter = 14570, loss = 1.8105
2024-10-30 19:17:53: [2024-10-30 19:17:53] iter = 14580, loss = 1.6178
2024-10-30 19:17:57: [2024-10-30 19:17:57] iter = 14590, loss = 2.1704
2024-10-30 19:18:01: [2024-10-30 19:18:01] iter = 14600, loss = 1.9213
2024-10-30 19:18:05: [2024-10-30 19:18:05] iter = 14610, loss = 1.7237
2024-10-30 19:18:09: [2024-10-30 19:18:09] iter = 14620, loss = 2.6875
2024-10-30 19:18:13: [2024-10-30 19:18:13] iter = 14630, loss = 1.8397
2024-10-30 19:18:17: [2024-10-30 19:18:17] iter = 14640, loss = 2.6078
2024-10-30 19:18:21: [2024-10-30 19:18:21] iter = 14650, loss = 3.5801
2024-10-30 19:18:25: [2024-10-30 19:18:25] iter = 14660, loss = 2.6721
2024-10-30 19:18:29: [2024-10-30 19:18:29] iter = 14670, loss = 1.6685
2024-10-30 19:18:32: [2024-10-30 19:18:32] iter = 14680, loss = 1.9514
2024-10-30 19:18:36: [2024-10-30 19:18:36] iter = 14690, loss = 1.8277
2024-10-30 19:18:39: [2024-10-30 19:18:39] iter = 14700, loss = 1.6919
2024-10-30 19:18:43: [2024-10-30 19:18:43] iter = 14710, loss = 1.9754
2024-10-30 19:18:46: [2024-10-30 19:18:46] iter = 14720, loss = 1.9907
2024-10-30 19:18:50: [2024-10-30 19:18:50] iter = 14730, loss = 2.4730
2024-10-30 19:18:54: [2024-10-30 19:18:54] iter = 14740, loss = 2.2105
2024-10-30 19:18:57: [2024-10-30 19:18:57] iter = 14750, loss = 2.3839
2024-10-30 19:19:01: [2024-10-30 19:19:01] iter = 14760, loss = 3.3125
2024-10-30 19:19:05: [2024-10-30 19:19:05] iter = 14770, loss = 2.3791
2024-10-30 19:19:09: [2024-10-30 19:19:09] iter = 14780, loss = 2.7153
2024-10-30 19:19:12: [2024-10-30 19:19:12] iter = 14790, loss = 2.3058
2024-10-30 19:19:16: [2024-10-30 19:19:16] iter = 14800, loss = 2.0641
2024-10-30 19:19:20: [2024-10-30 19:19:20] iter = 14810, loss = 2.9038
2024-10-30 19:19:22: [2024-10-30 19:19:22] iter = 14820, loss = 1.9485
2024-10-30 19:19:27: [2024-10-30 19:19:27] iter = 14830, loss = 2.8119
2024-10-30 19:19:31: [2024-10-30 19:19:31] iter = 14840, loss = 2.1835
2024-10-30 19:19:34: [2024-10-30 19:19:34] iter = 14850, loss = 2.4092
2024-10-30 19:19:39: [2024-10-30 19:19:39] iter = 14860, loss = 1.9269
2024-10-30 19:19:43: [2024-10-30 19:19:43] iter = 14870, loss = 2.0981
2024-10-30 19:19:47: [2024-10-30 19:19:47] iter = 14880, loss = 3.3084
2024-10-30 19:19:50: [2024-10-30 19:19:50] iter = 14890, loss = 1.8182
2024-10-30 19:19:53: [2024-10-30 19:19:53] iter = 14900, loss = 1.9850
2024-10-30 19:19:58: [2024-10-30 19:19:58] iter = 14910, loss = 2.0754
2024-10-30 19:20:02: [2024-10-30 19:20:02] iter = 14920, loss = 2.0904
2024-10-30 19:20:06: [2024-10-30 19:20:06] iter = 14930, loss = 1.8778
2024-10-30 19:20:09: [2024-10-30 19:20:09] iter = 14940, loss = 2.6037
2024-10-30 19:20:13: [2024-10-30 19:20:13] iter = 14950, loss = 2.5216
2024-10-30 19:20:16: [2024-10-30 19:20:16] iter = 14960, loss = 2.0906
2024-10-30 19:20:21: [2024-10-30 19:20:21] iter = 14970, loss = 1.9288
2024-10-30 19:20:24: [2024-10-30 19:20:24] iter = 14980, loss = 1.9018
2024-10-30 19:20:28: [2024-10-30 19:20:28] iter = 14990, loss = 1.9707
2024-10-30 19:20:31: [2024-10-30 19:20:31] iter = 15000, loss = 1.7601
2024-10-30 19:20:35: [2024-10-30 19:20:35] iter = 15010, loss = 1.6307
2024-10-30 19:20:38: [2024-10-30 19:20:38] iter = 15020, loss = 2.3673
2024-10-30 19:20:42: [2024-10-30 19:20:42] iter = 15030, loss = 3.3590
2024-10-30 19:20:45: [2024-10-30 19:20:45] iter = 15040, loss = 2.1829
2024-10-30 19:20:49: [2024-10-30 19:20:49] iter = 15050, loss = 1.7556
2024-10-30 19:20:52: [2024-10-30 19:20:52] iter = 15060, loss = 2.2233
2024-10-30 19:20:54: [2024-10-30 19:20:54] iter = 15070, loss = 2.2657
2024-10-30 19:20:58: [2024-10-30 19:20:58] iter = 15080, loss = 3.0422
2024-10-30 19:21:02: [2024-10-30 19:21:02] iter = 15090, loss = 2.0977
2024-10-30 19:21:06: [2024-10-30 19:21:06] iter = 15100, loss = 2.1421
2024-10-30 19:21:09: [2024-10-30 19:21:09] iter = 15110, loss = 2.7552
2024-10-30 19:21:12: [2024-10-30 19:21:12] iter = 15120, loss = 1.8390
2024-10-30 19:21:16: [2024-10-30 19:21:16] iter = 15130, loss = 2.9298
2024-10-30 19:21:19: [2024-10-30 19:21:19] iter = 15140, loss = 2.2805
2024-10-30 19:21:22: [2024-10-30 19:21:22] iter = 15150, loss = 2.0405
2024-10-30 19:21:25: [2024-10-30 19:21:25] iter = 15160, loss = 3.7119
2024-10-30 19:21:29: [2024-10-30 19:21:29] iter = 15170, loss = 1.8564
2024-10-30 19:21:32: [2024-10-30 19:21:32] iter = 15180, loss = 1.9784
2024-10-30 19:21:36: [2024-10-30 19:21:36] iter = 15190, loss = 2.1445
2024-10-30 19:21:40: [2024-10-30 19:21:40] iter = 15200, loss = 1.8192
2024-10-30 19:21:43: [2024-10-30 19:21:43] iter = 15210, loss = 1.8248
2024-10-30 19:21:47: [2024-10-30 19:21:47] iter = 15220, loss = 2.3331
2024-10-30 19:21:50: [2024-10-30 19:21:50] iter = 15230, loss = 2.1040
2024-10-30 19:21:54: [2024-10-30 19:21:54] iter = 15240, loss = 1.8736
2024-10-30 19:21:57: [2024-10-30 19:21:57] iter = 15250, loss = 1.7625
2024-10-30 19:22:01: [2024-10-30 19:22:01] iter = 15260, loss = 2.0742
2024-10-30 19:22:05: [2024-10-30 19:22:05] iter = 15270, loss = 6.0223
2024-10-30 19:22:09: [2024-10-30 19:22:09] iter = 15280, loss = 2.8401
2024-10-30 19:22:13: [2024-10-30 19:22:13] iter = 15290, loss = 2.2976
2024-10-30 19:22:16: [2024-10-30 19:22:16] iter = 15300, loss = 2.9346
2024-10-30 19:22:20: [2024-10-30 19:22:20] iter = 15310, loss = 1.6070
2024-10-30 19:22:23: [2024-10-30 19:22:23] iter = 15320, loss = 2.6835
2024-10-30 19:22:26: [2024-10-30 19:22:26] iter = 15330, loss = 2.1007
2024-10-30 19:22:30: [2024-10-30 19:22:30] iter = 15340, loss = 2.0089
2024-10-30 19:22:34: [2024-10-30 19:22:34] iter = 15350, loss = 2.4575
2024-10-30 19:22:37: [2024-10-30 19:22:37] iter = 15360, loss = 2.0140
2024-10-30 19:22:40: [2024-10-30 19:22:40] iter = 15370, loss = 2.6714
2024-10-30 19:22:44: [2024-10-30 19:22:44] iter = 15380, loss = 2.2499
2024-10-30 19:22:48: [2024-10-30 19:22:48] iter = 15390, loss = 1.6652
2024-10-30 19:22:52: [2024-10-30 19:22:52] iter = 15400, loss = 2.0367
2024-10-30 19:22:55: [2024-10-30 19:22:55] iter = 15410, loss = 2.4491
2024-10-30 19:22:58: [2024-10-30 19:22:58] iter = 15420, loss = 2.4022
2024-10-30 19:23:02: [2024-10-30 19:23:02] iter = 15430, loss = 2.3333
2024-10-30 19:23:05: [2024-10-30 19:23:05] iter = 15440, loss = 1.8695
2024-10-30 19:23:09: [2024-10-30 19:23:09] iter = 15450, loss = 1.8342
2024-10-30 19:23:12: [2024-10-30 19:23:12] iter = 15460, loss = 1.9786
2024-10-30 19:23:15: [2024-10-30 19:23:15] iter = 15470, loss = 2.3570
2024-10-30 19:23:20: [2024-10-30 19:23:20] iter = 15480, loss = 1.8391
2024-10-30 19:23:24: [2024-10-30 19:23:24] iter = 15490, loss = 2.5181
2024-10-30 19:23:28: [2024-10-30 19:23:28] iter = 15500, loss = 4.6587
2024-10-30 19:23:32: [2024-10-30 19:23:32] iter = 15510, loss = 3.4515
2024-10-30 19:23:35: [2024-10-30 19:23:35] iter = 15520, loss = 1.7654
2024-10-30 19:23:39: [2024-10-30 19:23:39] iter = 15530, loss = 2.0638
2024-10-30 19:23:42: [2024-10-30 19:23:42] iter = 15540, loss = 2.0602
2024-10-30 19:23:45: [2024-10-30 19:23:45] iter = 15550, loss = 2.3573
2024-10-30 19:23:48: [2024-10-30 19:23:48] iter = 15560, loss = 1.8699
2024-10-30 19:23:52: [2024-10-30 19:23:52] iter = 15570, loss = 2.7497
2024-10-30 19:23:55: [2024-10-30 19:23:55] iter = 15580, loss = 1.7298
2024-10-30 19:24:00: [2024-10-30 19:24:00] iter = 15590, loss = 2.1231
2024-10-30 19:24:04: [2024-10-30 19:24:04] iter = 15600, loss = 1.8960
2024-10-30 19:24:08: [2024-10-30 19:24:08] iter = 15610, loss = 2.0900
2024-10-30 19:24:12: [2024-10-30 19:24:12] iter = 15620, loss = 2.2767
2024-10-30 19:24:16: [2024-10-30 19:24:16] iter = 15630, loss = 2.8575
2024-10-30 19:24:20: [2024-10-30 19:24:20] iter = 15640, loss = 2.0381
2024-10-30 19:24:23: [2024-10-30 19:24:23] iter = 15650, loss = 1.8695
2024-10-30 19:24:26: [2024-10-30 19:24:26] iter = 15660, loss = 1.8049
2024-10-30 19:24:29: [2024-10-30 19:24:29] iter = 15670, loss = 2.1382
2024-10-30 19:24:32: [2024-10-30 19:24:32] iter = 15680, loss = 1.7828
2024-10-30 19:24:35: [2024-10-30 19:24:35] iter = 15690, loss = 2.2223
2024-10-30 19:24:38: [2024-10-30 19:24:38] iter = 15700, loss = 2.3743
2024-10-30 19:24:41: [2024-10-30 19:24:41] iter = 15710, loss = 2.1478
2024-10-30 19:24:44: [2024-10-30 19:24:44] iter = 15720, loss = 2.1263
2024-10-30 19:24:48: [2024-10-30 19:24:48] iter = 15730, loss = 5.0232
2024-10-30 19:24:51: [2024-10-30 19:24:51] iter = 15740, loss = 2.5510
2024-10-30 19:24:55: [2024-10-30 19:24:55] iter = 15750, loss = 2.4210
2024-10-30 19:24:59: [2024-10-30 19:24:59] iter = 15760, loss = 2.0712
2024-10-30 19:25:02: [2024-10-30 19:25:02] iter = 15770, loss = 2.2455
2024-10-30 19:25:05: [2024-10-30 19:25:05] iter = 15780, loss = 3.2846
2024-10-30 19:25:09: [2024-10-30 19:25:09] iter = 15790, loss = 3.4701
2024-10-30 19:25:13: [2024-10-30 19:25:13] iter = 15800, loss = 2.6268
2024-10-30 19:25:17: [2024-10-30 19:25:17] iter = 15810, loss = 1.7648
2024-10-30 19:25:21: [2024-10-30 19:25:21] iter = 15820, loss = 2.5581
2024-10-30 19:25:25: [2024-10-30 19:25:25] iter = 15830, loss = 1.8072
2024-10-30 19:25:27: [2024-10-30 19:25:27] iter = 15840, loss = 2.3892
2024-10-30 19:25:30: [2024-10-30 19:25:30] iter = 15850, loss = 2.0338
2024-10-30 19:25:33: [2024-10-30 19:25:33] iter = 15860, loss = 1.5970
2024-10-30 19:25:38: [2024-10-30 19:25:38] iter = 15870, loss = 2.0613
2024-10-30 19:25:40: [2024-10-30 19:25:40] iter = 15880, loss = 2.4000
2024-10-30 19:25:44: [2024-10-30 19:25:44] iter = 15890, loss = 2.8694
2024-10-30 19:25:48: [2024-10-30 19:25:48] iter = 15900, loss = 2.0151
2024-10-30 19:25:52: [2024-10-30 19:25:52] iter = 15910, loss = 1.6199
2024-10-30 19:25:56: [2024-10-30 19:25:56] iter = 15920, loss = 1.6506
2024-10-30 19:25:59: [2024-10-30 19:25:59] iter = 15930, loss = 2.3949
2024-10-30 19:26:02: [2024-10-30 19:26:02] iter = 15940, loss = 2.7213
2024-10-30 19:26:07: [2024-10-30 19:26:07] iter = 15950, loss = 1.7176
2024-10-30 19:26:09: [2024-10-30 19:26:09] iter = 15960, loss = 2.0781
2024-10-30 19:26:14: [2024-10-30 19:26:14] iter = 15970, loss = 1.8122
2024-10-30 19:26:18: [2024-10-30 19:26:18] iter = 15980, loss = 2.4712
2024-10-30 19:26:21: [2024-10-30 19:26:21] iter = 15990, loss = 2.2942
2024-10-30 19:26:24: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 19:26:24: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:26:24: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 84847}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:28:48: Evaluate 5 random ConvNet, ACCmean = 0.7897 ACCstd = 0.0019
-------------------------
2024-10-30 19:28:48: Evaluate 5 random ConvNet, SENmean = 0.7831 SENstd = 0.0015
-------------------------
2024-10-30 19:28:48: Evaluate 5 random ConvNet, SPEmean = 0.9787 SPEstd = 0.0002
-------------------------
2024-10-30 19:28:48: Evaluate 5 random ConvNet, F!mean = 0.7761 F!std = 0.0020
-------------------------
2024-10-30 19:28:48: Evaluate 5 random ConvNet, mean = 0.7897 std = 0.0019
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:28:49: [2024-10-30 19:28:49] iter = 16000, loss = 2.0562
2024-10-30 19:28:53: [2024-10-30 19:28:53] iter = 16010, loss = 2.1551
2024-10-30 19:28:57: [2024-10-30 19:28:57] iter = 16020, loss = 2.3311
2024-10-30 19:29:00: [2024-10-30 19:29:00] iter = 16030, loss = 2.3138
2024-10-30 19:29:04: [2024-10-30 19:29:04] iter = 16040, loss = 1.6699
2024-10-30 19:29:07: [2024-10-30 19:29:07] iter = 16050, loss = 2.4534
2024-10-30 19:29:11: [2024-10-30 19:29:11] iter = 16060, loss = 3.2336
2024-10-30 19:29:13: [2024-10-30 19:29:13] iter = 16070, loss = 1.9239
2024-10-30 19:29:16: [2024-10-30 19:29:16] iter = 16080, loss = 1.7175
2024-10-30 19:29:19: [2024-10-30 19:29:19] iter = 16090, loss = 1.5998
2024-10-30 19:29:22: [2024-10-30 19:29:22] iter = 16100, loss = 2.5914
2024-10-30 19:29:25: [2024-10-30 19:29:25] iter = 16110, loss = 2.6900
2024-10-30 19:29:28: [2024-10-30 19:29:28] iter = 16120, loss = 2.2592
2024-10-30 19:29:31: [2024-10-30 19:29:31] iter = 16130, loss = 2.0991
2024-10-30 19:29:35: [2024-10-30 19:29:35] iter = 16140, loss = 1.9815
2024-10-30 19:29:37: [2024-10-30 19:29:37] iter = 16150, loss = 2.3063
2024-10-30 19:29:40: [2024-10-30 19:29:40] iter = 16160, loss = 1.9511
2024-10-30 19:29:43: [2024-10-30 19:29:43] iter = 16170, loss = 1.7926
2024-10-30 19:29:47: [2024-10-30 19:29:47] iter = 16180, loss = 1.7323
2024-10-30 19:29:50: [2024-10-30 19:29:50] iter = 16190, loss = 2.2325
2024-10-30 19:29:54: [2024-10-30 19:29:54] iter = 16200, loss = 2.5773
2024-10-30 19:29:57: [2024-10-30 19:29:57] iter = 16210, loss = 2.2997
2024-10-30 19:30:01: [2024-10-30 19:30:01] iter = 16220, loss = 2.8726
2024-10-30 19:30:04: [2024-10-30 19:30:04] iter = 16230, loss = 3.8792
2024-10-30 19:30:07: [2024-10-30 19:30:07] iter = 16240, loss = 2.6222
2024-10-30 19:30:10: [2024-10-30 19:30:10] iter = 16250, loss = 2.2023
2024-10-30 19:30:13: [2024-10-30 19:30:13] iter = 16260, loss = 1.7761
2024-10-30 19:30:17: [2024-10-30 19:30:17] iter = 16270, loss = 2.1782
2024-10-30 19:30:21: [2024-10-30 19:30:21] iter = 16280, loss = 2.0974
2024-10-30 19:30:24: [2024-10-30 19:30:24] iter = 16290, loss = 1.9590
2024-10-30 19:30:28: [2024-10-30 19:30:28] iter = 16300, loss = 2.6438
2024-10-30 19:30:32: [2024-10-30 19:30:32] iter = 16310, loss = 2.1739
2024-10-30 19:30:35: [2024-10-30 19:30:35] iter = 16320, loss = 1.9356
2024-10-30 19:30:38: [2024-10-30 19:30:38] iter = 16330, loss = 2.4613
2024-10-30 19:30:41: [2024-10-30 19:30:41] iter = 16340, loss = 2.1877
2024-10-30 19:30:44: [2024-10-30 19:30:44] iter = 16350, loss = 1.9739
2024-10-30 19:30:47: [2024-10-30 19:30:47] iter = 16360, loss = 2.1574
2024-10-30 19:30:51: [2024-10-30 19:30:51] iter = 16370, loss = 2.0418
2024-10-30 19:30:54: [2024-10-30 19:30:54] iter = 16380, loss = 2.0664
2024-10-30 19:30:58: [2024-10-30 19:30:58] iter = 16390, loss = 1.6809
2024-10-30 19:31:01: [2024-10-30 19:31:01] iter = 16400, loss = 2.0432
2024-10-30 19:31:05: [2024-10-30 19:31:05] iter = 16410, loss = 2.4655
2024-10-30 19:31:09: [2024-10-30 19:31:09] iter = 16420, loss = 1.9961
2024-10-30 19:31:12: [2024-10-30 19:31:12] iter = 16430, loss = 2.6228
2024-10-30 19:31:16: [2024-10-30 19:31:16] iter = 16440, loss = 1.8532
2024-10-30 19:31:19: [2024-10-30 19:31:19] iter = 16450, loss = 2.0676
2024-10-30 19:31:24: [2024-10-30 19:31:24] iter = 16460, loss = 2.3741
2024-10-30 19:31:27: [2024-10-30 19:31:27] iter = 16470, loss = 2.1478
2024-10-30 19:31:30: [2024-10-30 19:31:30] iter = 16480, loss = 1.7034
2024-10-30 19:31:32: [2024-10-30 19:31:32] iter = 16490, loss = 2.2587
2024-10-30 19:31:37: [2024-10-30 19:31:37] iter = 16500, loss = 1.8988
2024-10-30 19:31:41: [2024-10-30 19:31:41] iter = 16510, loss = 2.1016
2024-10-30 19:31:44: [2024-10-30 19:31:44] iter = 16520, loss = 3.4160
2024-10-30 19:31:48: [2024-10-30 19:31:48] iter = 16530, loss = 2.6407
2024-10-30 19:31:51: [2024-10-30 19:31:51] iter = 16540, loss = 2.6542
2024-10-30 19:31:56: [2024-10-30 19:31:56] iter = 16550, loss = 2.5342
2024-10-30 19:32:00: [2024-10-30 19:32:00] iter = 16560, loss = 1.7918
2024-10-30 19:32:03: [2024-10-30 19:32:03] iter = 16570, loss = 1.7958
2024-10-30 19:32:07: [2024-10-30 19:32:07] iter = 16580, loss = 1.7197
2024-10-30 19:32:10: [2024-10-30 19:32:10] iter = 16590, loss = 1.8539
2024-10-30 19:32:13: [2024-10-30 19:32:13] iter = 16600, loss = 1.9709
2024-10-30 19:32:16: [2024-10-30 19:32:16] iter = 16610, loss = 1.8955
2024-10-30 19:32:20: [2024-10-30 19:32:20] iter = 16620, loss = 1.7854
2024-10-30 19:32:22: [2024-10-30 19:32:22] iter = 16630, loss = 2.0917
2024-10-30 19:32:26: [2024-10-30 19:32:26] iter = 16640, loss = 4.9019
2024-10-30 19:32:29: [2024-10-30 19:32:29] iter = 16650, loss = 1.5305
2024-10-30 19:32:33: [2024-10-30 19:32:33] iter = 16660, loss = 2.6559
2024-10-30 19:32:38: [2024-10-30 19:32:38] iter = 16670, loss = 1.7706
2024-10-30 19:32:41: [2024-10-30 19:32:41] iter = 16680, loss = 1.9401
2024-10-30 19:32:45: [2024-10-30 19:32:45] iter = 16690, loss = 2.5195
2024-10-30 19:32:49: [2024-10-30 19:32:49] iter = 16700, loss = 1.7104
2024-10-30 19:32:53: [2024-10-30 19:32:53] iter = 16710, loss = 2.2649
2024-10-30 19:32:57: [2024-10-30 19:32:57] iter = 16720, loss = 2.9351
2024-10-30 19:33:00: [2024-10-30 19:33:00] iter = 16730, loss = 2.3605
2024-10-30 19:33:04: [2024-10-30 19:33:04] iter = 16740, loss = 2.1157
2024-10-30 19:33:08: [2024-10-30 19:33:08] iter = 16750, loss = 3.0216
2024-10-30 19:33:11: [2024-10-30 19:33:11] iter = 16760, loss = 1.6505
2024-10-30 19:33:15: [2024-10-30 19:33:15] iter = 16770, loss = 1.9204
2024-10-30 19:33:18: [2024-10-30 19:33:18] iter = 16780, loss = 4.6326
2024-10-30 19:33:21: [2024-10-30 19:33:21] iter = 16790, loss = 3.0329
2024-10-30 19:33:25: [2024-10-30 19:33:25] iter = 16800, loss = 2.0668
2024-10-30 19:33:29: [2024-10-30 19:33:29] iter = 16810, loss = 2.7215
2024-10-30 19:33:33: [2024-10-30 19:33:33] iter = 16820, loss = 2.0974
2024-10-30 19:33:36: [2024-10-30 19:33:36] iter = 16830, loss = 1.6306
2024-10-30 19:33:39: [2024-10-30 19:33:39] iter = 16840, loss = 2.0905
2024-10-30 19:33:42: [2024-10-30 19:33:42] iter = 16850, loss = 2.6958
2024-10-30 19:33:46: [2024-10-30 19:33:46] iter = 16860, loss = 2.1617
2024-10-30 19:33:49: [2024-10-30 19:33:49] iter = 16870, loss = 2.9977
2024-10-30 19:33:53: [2024-10-30 19:33:53] iter = 16880, loss = 1.8422
2024-10-30 19:33:57: [2024-10-30 19:33:57] iter = 16890, loss = 4.6104
2024-10-30 19:34:01: [2024-10-30 19:34:01] iter = 16900, loss = 2.2006
2024-10-30 19:34:05: [2024-10-30 19:34:05] iter = 16910, loss = 2.0450
2024-10-30 19:34:09: [2024-10-30 19:34:09] iter = 16920, loss = 1.7591
2024-10-30 19:34:12: [2024-10-30 19:34:12] iter = 16930, loss = 2.6857
2024-10-30 19:34:15: [2024-10-30 19:34:15] iter = 16940, loss = 1.7786
2024-10-30 19:34:18: [2024-10-30 19:34:18] iter = 16950, loss = 2.6348
2024-10-30 19:34:22: [2024-10-30 19:34:22] iter = 16960, loss = 2.1142
2024-10-30 19:34:25: [2024-10-30 19:34:25] iter = 16970, loss = 2.0863
2024-10-30 19:34:28: [2024-10-30 19:34:28] iter = 16980, loss = 1.7670
2024-10-30 19:34:32: [2024-10-30 19:34:32] iter = 16990, loss = 2.0749
2024-10-30 19:34:36: [2024-10-30 19:34:36] iter = 17000, loss = 1.7848
2024-10-30 19:34:39: [2024-10-30 19:34:39] iter = 17010, loss = 1.8008
2024-10-30 19:34:41: [2024-10-30 19:34:41] iter = 17020, loss = 1.6553
2024-10-30 19:34:45: [2024-10-30 19:34:45] iter = 17030, loss = 5.8058
2024-10-30 19:34:49: [2024-10-30 19:34:49] iter = 17040, loss = 2.2947
2024-10-30 19:34:53: [2024-10-30 19:34:53] iter = 17050, loss = 2.9556
2024-10-30 19:34:58: [2024-10-30 19:34:58] iter = 17060, loss = 2.1047
2024-10-30 19:35:01: [2024-10-30 19:35:01] iter = 17070, loss = 3.1134
2024-10-30 19:35:04: [2024-10-30 19:35:04] iter = 17080, loss = 2.5736
2024-10-30 19:35:09: [2024-10-30 19:35:09] iter = 17090, loss = 3.3624
2024-10-30 19:35:13: [2024-10-30 19:35:13] iter = 17100, loss = 2.6988
2024-10-30 19:35:16: [2024-10-30 19:35:16] iter = 17110, loss = 2.6607
2024-10-30 19:35:19: [2024-10-30 19:35:19] iter = 17120, loss = 2.3328
2024-10-30 19:35:22: [2024-10-30 19:35:22] iter = 17130, loss = 3.0852
2024-10-30 19:35:25: [2024-10-30 19:35:25] iter = 17140, loss = 2.0691
2024-10-30 19:35:28: [2024-10-30 19:35:28] iter = 17150, loss = 2.0122
2024-10-30 19:35:32: [2024-10-30 19:35:32] iter = 17160, loss = 2.4817
2024-10-30 19:35:36: [2024-10-30 19:35:36] iter = 17170, loss = 2.0521
2024-10-30 19:35:39: [2024-10-30 19:35:39] iter = 17180, loss = 3.4538
2024-10-30 19:35:43: [2024-10-30 19:35:43] iter = 17190, loss = 2.0139
2024-10-30 19:35:46: [2024-10-30 19:35:46] iter = 17200, loss = 3.6465
2024-10-30 19:35:50: [2024-10-30 19:35:50] iter = 17210, loss = 2.1252
2024-10-30 19:35:54: [2024-10-30 19:35:54] iter = 17220, loss = 1.8808
2024-10-30 19:35:57: [2024-10-30 19:35:57] iter = 17230, loss = 1.9878
2024-10-30 19:36:01: [2024-10-30 19:36:01] iter = 17240, loss = 2.4071
2024-10-30 19:36:04: [2024-10-30 19:36:04] iter = 17250, loss = 1.8703
2024-10-30 19:36:08: [2024-10-30 19:36:08] iter = 17260, loss = 1.7952
2024-10-30 19:36:12: [2024-10-30 19:36:12] iter = 17270, loss = 1.7403
2024-10-30 19:36:16: [2024-10-30 19:36:16] iter = 17280, loss = 2.9302
2024-10-30 19:36:19: [2024-10-30 19:36:19] iter = 17290, loss = 2.3632
2024-10-30 19:36:23: [2024-10-30 19:36:23] iter = 17300, loss = 3.2369
2024-10-30 19:36:27: [2024-10-30 19:36:27] iter = 17310, loss = 2.9290
2024-10-30 19:36:29: [2024-10-30 19:36:29] iter = 17320, loss = 1.8325
2024-10-30 19:36:33: [2024-10-30 19:36:33] iter = 17330, loss = 2.9760
2024-10-30 19:36:36: [2024-10-30 19:36:36] iter = 17340, loss = 2.5960
2024-10-30 19:36:40: [2024-10-30 19:36:40] iter = 17350, loss = 2.4181
2024-10-30 19:36:44: [2024-10-30 19:36:44] iter = 17360, loss = 2.0896
2024-10-30 19:36:47: [2024-10-30 19:36:47] iter = 17370, loss = 2.0892
2024-10-30 19:36:50: [2024-10-30 19:36:50] iter = 17380, loss = 2.2439
2024-10-30 19:36:54: [2024-10-30 19:36:54] iter = 17390, loss = 1.7957
2024-10-30 19:36:57: [2024-10-30 19:36:57] iter = 17400, loss = 1.7602
2024-10-30 19:37:01: [2024-10-30 19:37:01] iter = 17410, loss = 6.3627
2024-10-30 19:37:04: [2024-10-30 19:37:04] iter = 17420, loss = 2.1022
2024-10-30 19:37:07: [2024-10-30 19:37:07] iter = 17430, loss = 2.4569
2024-10-30 19:37:10: [2024-10-30 19:37:10] iter = 17440, loss = 1.8094
2024-10-30 19:37:14: [2024-10-30 19:37:14] iter = 17450, loss = 1.9111
2024-10-30 19:37:16: [2024-10-30 19:37:16] iter = 17460, loss = 1.9344
2024-10-30 19:37:19: [2024-10-30 19:37:19] iter = 17470, loss = 1.9449
2024-10-30 19:37:23: [2024-10-30 19:37:23] iter = 17480, loss = 1.7595
2024-10-30 19:37:26: [2024-10-30 19:37:26] iter = 17490, loss = 2.1791
2024-10-30 19:37:30: [2024-10-30 19:37:30] iter = 17500, loss = 1.9138
2024-10-30 19:37:33: [2024-10-30 19:37:33] iter = 17510, loss = 1.9987
2024-10-30 19:37:37: [2024-10-30 19:37:37] iter = 17520, loss = 1.8226
2024-10-30 19:37:40: [2024-10-30 19:37:40] iter = 17530, loss = 2.6843
2024-10-30 19:37:43: [2024-10-30 19:37:43] iter = 17540, loss = 1.7515
2024-10-30 19:37:47: [2024-10-30 19:37:47] iter = 17550, loss = 2.1462
2024-10-30 19:37:50: [2024-10-30 19:37:50] iter = 17560, loss = 1.9728
2024-10-30 19:37:54: [2024-10-30 19:37:54] iter = 17570, loss = 1.7070
2024-10-30 19:37:58: [2024-10-30 19:37:58] iter = 17580, loss = 2.2713
2024-10-30 19:38:02: [2024-10-30 19:38:02] iter = 17590, loss = 2.4268
2024-10-30 19:38:05: [2024-10-30 19:38:05] iter = 17600, loss = 2.7359
2024-10-30 19:38:09: [2024-10-30 19:38:09] iter = 17610, loss = 1.9852
2024-10-30 19:38:13: [2024-10-30 19:38:13] iter = 17620, loss = 1.9957
2024-10-30 19:38:16: [2024-10-30 19:38:16] iter = 17630, loss = 2.3916
2024-10-30 19:38:20: [2024-10-30 19:38:20] iter = 17640, loss = 1.9070
2024-10-30 19:38:24: [2024-10-30 19:38:24] iter = 17650, loss = 1.7691
2024-10-30 19:38:27: [2024-10-30 19:38:27] iter = 17660, loss = 2.5744
2024-10-30 19:38:30: [2024-10-30 19:38:30] iter = 17670, loss = 2.1722
2024-10-30 19:38:34: [2024-10-30 19:38:34] iter = 17680, loss = 2.7801
2024-10-30 19:38:38: [2024-10-30 19:38:38] iter = 17690, loss = 1.9845
2024-10-30 19:38:42: [2024-10-30 19:38:42] iter = 17700, loss = 1.9345
2024-10-30 19:38:46: [2024-10-30 19:38:46] iter = 17710, loss = 2.1114
2024-10-30 19:38:49: [2024-10-30 19:38:49] iter = 17720, loss = 2.6875
2024-10-30 19:38:53: [2024-10-30 19:38:53] iter = 17730, loss = 2.6452
2024-10-30 19:38:56: [2024-10-30 19:38:56] iter = 17740, loss = 2.7263
2024-10-30 19:39:00: [2024-10-30 19:39:00] iter = 17750, loss = 2.6982
2024-10-30 19:39:04: [2024-10-30 19:39:04] iter = 17760, loss = 2.4426
2024-10-30 19:39:08: [2024-10-30 19:39:08] iter = 17770, loss = 2.1669
2024-10-30 19:39:12: [2024-10-30 19:39:12] iter = 17780, loss = 2.0786
2024-10-30 19:39:16: [2024-10-30 19:39:16] iter = 17790, loss = 1.8672
2024-10-30 19:39:19: [2024-10-30 19:39:19] iter = 17800, loss = 2.3533
2024-10-30 19:39:22: [2024-10-30 19:39:22] iter = 17810, loss = 1.7467
2024-10-30 19:39:26: [2024-10-30 19:39:26] iter = 17820, loss = 2.3905
2024-10-30 19:39:29: [2024-10-30 19:39:29] iter = 17830, loss = 1.6526
2024-10-30 19:39:32: [2024-10-30 19:39:32] iter = 17840, loss = 3.0931
2024-10-30 19:39:36: [2024-10-30 19:39:36] iter = 17850, loss = 1.9128
2024-10-30 19:39:39: [2024-10-30 19:39:39] iter = 17860, loss = 1.7704
2024-10-30 19:39:42: [2024-10-30 19:39:42] iter = 17870, loss = 2.6906
2024-10-30 19:39:45: [2024-10-30 19:39:45] iter = 17880, loss = 3.4765
2024-10-30 19:39:48: [2024-10-30 19:39:48] iter = 17890, loss = 2.2995
2024-10-30 19:39:52: [2024-10-30 19:39:52] iter = 17900, loss = 1.8683
2024-10-30 19:39:56: [2024-10-30 19:39:56] iter = 17910, loss = 2.4901
2024-10-30 19:40:00: [2024-10-30 19:40:00] iter = 17920, loss = 2.3523
2024-10-30 19:40:03: [2024-10-30 19:40:03] iter = 17930, loss = 1.7555
2024-10-30 19:40:07: [2024-10-30 19:40:07] iter = 17940, loss = 1.6966
2024-10-30 19:40:10: [2024-10-30 19:40:10] iter = 17950, loss = 3.7821
2024-10-30 19:40:13: [2024-10-30 19:40:13] iter = 17960, loss = 1.7231
2024-10-30 19:40:16: [2024-10-30 19:40:16] iter = 17970, loss = 1.7292
2024-10-30 19:40:20: [2024-10-30 19:40:20] iter = 17980, loss = 4.0120
2024-10-30 19:40:24: [2024-10-30 19:40:24] iter = 17990, loss = 1.8163
2024-10-30 19:40:28: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 19:40:28: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:40:28: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 28114}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:42:52: Evaluate 5 random ConvNet, ACCmean = 0.7878 ACCstd = 0.0041
-------------------------
2024-10-30 19:42:52: Evaluate 5 random ConvNet, SENmean = 0.7794 SENstd = 0.0038
-------------------------
2024-10-30 19:42:52: Evaluate 5 random ConvNet, SPEmean = 0.9786 SPEstd = 0.0004
-------------------------
2024-10-30 19:42:52: Evaluate 5 random ConvNet, F!mean = 0.7722 F!std = 0.0047
-------------------------
2024-10-30 19:42:52: Evaluate 5 random ConvNet, mean = 0.7878 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:42:52: [2024-10-30 19:42:52] iter = 18000, loss = 1.9519
2024-10-30 19:42:56: [2024-10-30 19:42:56] iter = 18010, loss = 2.4189
2024-10-30 19:42:59: [2024-10-30 19:42:59] iter = 18020, loss = 2.1926
2024-10-30 19:43:03: [2024-10-30 19:43:03] iter = 18030, loss = 2.6360
2024-10-30 19:43:07: [2024-10-30 19:43:07] iter = 18040, loss = 1.7768
2024-10-30 19:43:11: [2024-10-30 19:43:11] iter = 18050, loss = 1.6539
2024-10-30 19:43:15: [2024-10-30 19:43:15] iter = 18060, loss = 1.6193
2024-10-30 19:43:19: [2024-10-30 19:43:19] iter = 18070, loss = 2.8901
2024-10-30 19:43:22: [2024-10-30 19:43:22] iter = 18080, loss = 2.1275
2024-10-30 19:43:26: [2024-10-30 19:43:26] iter = 18090, loss = 2.2079
2024-10-30 19:43:30: [2024-10-30 19:43:30] iter = 18100, loss = 2.1672
2024-10-30 19:43:34: [2024-10-30 19:43:34] iter = 18110, loss = 3.0249
2024-10-30 19:43:38: [2024-10-30 19:43:38] iter = 18120, loss = 1.8775
2024-10-30 19:43:41: [2024-10-30 19:43:41] iter = 18130, loss = 3.5524
2024-10-30 19:43:44: [2024-10-30 19:43:44] iter = 18140, loss = 2.4969
2024-10-30 19:43:47: [2024-10-30 19:43:47] iter = 18150, loss = 2.9024
2024-10-30 19:43:51: [2024-10-30 19:43:51] iter = 18160, loss = 2.4305
2024-10-30 19:43:56: [2024-10-30 19:43:56] iter = 18170, loss = 1.6561
2024-10-30 19:43:59: [2024-10-30 19:43:59] iter = 18180, loss = 2.1821
2024-10-30 19:44:02: [2024-10-30 19:44:02] iter = 18190, loss = 2.6221
2024-10-30 19:44:05: [2024-10-30 19:44:05] iter = 18200, loss = 1.8141
2024-10-30 19:44:08: [2024-10-30 19:44:08] iter = 18210, loss = 3.8252
2024-10-30 19:44:12: [2024-10-30 19:44:12] iter = 18220, loss = 2.2859
2024-10-30 19:44:15: [2024-10-30 19:44:15] iter = 18230, loss = 3.3386
2024-10-30 19:44:19: [2024-10-30 19:44:19] iter = 18240, loss = 1.9727
2024-10-30 19:44:22: [2024-10-30 19:44:22] iter = 18250, loss = 2.5963
2024-10-30 19:44:26: [2024-10-30 19:44:26] iter = 18260, loss = 1.9680
2024-10-30 19:44:30: [2024-10-30 19:44:30] iter = 18270, loss = 1.8744
2024-10-30 19:44:35: [2024-10-30 19:44:35] iter = 18280, loss = 3.9725
2024-10-30 19:44:38: [2024-10-30 19:44:38] iter = 18290, loss = 1.8399
2024-10-30 19:44:41: [2024-10-30 19:44:41] iter = 18300, loss = 2.3702
2024-10-30 19:44:45: [2024-10-30 19:44:45] iter = 18310, loss = 1.7429
2024-10-30 19:44:49: [2024-10-30 19:44:49] iter = 18320, loss = 1.8548
2024-10-30 19:44:52: [2024-10-30 19:44:52] iter = 18330, loss = 1.8575
2024-10-30 19:44:55: [2024-10-30 19:44:55] iter = 18340, loss = 2.8083
2024-10-30 19:44:58: [2024-10-30 19:44:58] iter = 18350, loss = 2.0752
2024-10-30 19:45:01: [2024-10-30 19:45:01] iter = 18360, loss = 3.5762
2024-10-30 19:45:06: [2024-10-30 19:45:06] iter = 18370, loss = 1.8308
2024-10-30 19:45:09: [2024-10-30 19:45:09] iter = 18380, loss = 1.8066
2024-10-30 19:45:13: [2024-10-30 19:45:13] iter = 18390, loss = 1.8225
2024-10-30 19:45:17: [2024-10-30 19:45:17] iter = 18400, loss = 2.5466
2024-10-30 19:45:21: [2024-10-30 19:45:21] iter = 18410, loss = 2.4660
2024-10-30 19:45:25: [2024-10-30 19:45:25] iter = 18420, loss = 2.6169
2024-10-30 19:45:29: [2024-10-30 19:45:29] iter = 18430, loss = 3.5060
2024-10-30 19:45:32: [2024-10-30 19:45:32] iter = 18440, loss = 2.7826
2024-10-30 19:45:36: [2024-10-30 19:45:36] iter = 18450, loss = 2.2749
2024-10-30 19:45:40: [2024-10-30 19:45:40] iter = 18460, loss = 2.7705
2024-10-30 19:45:43: [2024-10-30 19:45:43] iter = 18470, loss = 2.2153
2024-10-30 19:45:48: [2024-10-30 19:45:48] iter = 18480, loss = 3.5158
2024-10-30 19:45:51: [2024-10-30 19:45:51] iter = 18490, loss = 1.6843
2024-10-30 19:45:55: [2024-10-30 19:45:55] iter = 18500, loss = 2.4178
2024-10-30 19:45:59: [2024-10-30 19:45:59] iter = 18510, loss = 2.1182
2024-10-30 19:46:01: [2024-10-30 19:46:01] iter = 18520, loss = 2.5228
2024-10-30 19:46:05: [2024-10-30 19:46:05] iter = 18530, loss = 1.7843
2024-10-30 19:46:08: [2024-10-30 19:46:08] iter = 18540, loss = 2.3347
2024-10-30 19:46:13: [2024-10-30 19:46:13] iter = 18550, loss = 2.8945
2024-10-30 19:46:18: [2024-10-30 19:46:18] iter = 18560, loss = 2.2571
2024-10-30 19:46:21: [2024-10-30 19:46:21] iter = 18570, loss = 1.7526
2024-10-30 19:46:26: [2024-10-30 19:46:26] iter = 18580, loss = 2.1695
2024-10-30 19:46:31: [2024-10-30 19:46:31] iter = 18590, loss = 1.9269
2024-10-30 19:46:35: [2024-10-30 19:46:35] iter = 18600, loss = 2.0320
2024-10-30 19:46:40: [2024-10-30 19:46:40] iter = 18610, loss = 1.8422
2024-10-30 19:46:44: [2024-10-30 19:46:44] iter = 18620, loss = 1.9337
2024-10-30 19:46:48: [2024-10-30 19:46:48] iter = 18630, loss = 1.6819
2024-10-30 19:46:52: [2024-10-30 19:46:52] iter = 18640, loss = 1.9594
2024-10-30 19:46:56: [2024-10-30 19:46:56] iter = 18650, loss = 2.0470
2024-10-30 19:47:00: [2024-10-30 19:47:00] iter = 18660, loss = 2.6466
2024-10-30 19:47:04: [2024-10-30 19:47:04] iter = 18670, loss = 2.7144
2024-10-30 19:47:08: [2024-10-30 19:47:08] iter = 18680, loss = 2.1181
2024-10-30 19:47:12: [2024-10-30 19:47:12] iter = 18690, loss = 2.2767
2024-10-30 19:47:16: [2024-10-30 19:47:16] iter = 18700, loss = 1.8030
2024-10-30 19:47:20: [2024-10-30 19:47:20] iter = 18710, loss = 2.4174
2024-10-30 19:47:24: [2024-10-30 19:47:24] iter = 18720, loss = 1.7807
2024-10-30 19:47:28: [2024-10-30 19:47:28] iter = 18730, loss = 2.5630
2024-10-30 19:47:32: [2024-10-30 19:47:32] iter = 18740, loss = 2.9784
2024-10-30 19:47:36: [2024-10-30 19:47:36] iter = 18750, loss = 2.0683
2024-10-30 19:47:40: [2024-10-30 19:47:40] iter = 18760, loss = 1.6254
2024-10-30 19:47:43: [2024-10-30 19:47:43] iter = 18770, loss = 2.0265
2024-10-30 19:47:47: [2024-10-30 19:47:47] iter = 18780, loss = 1.9189
2024-10-30 19:47:52: [2024-10-30 19:47:52] iter = 18790, loss = 2.4660
2024-10-30 19:47:55: [2024-10-30 19:47:55] iter = 18800, loss = 1.8673
2024-10-30 19:47:59: [2024-10-30 19:47:59] iter = 18810, loss = 1.9673
2024-10-30 19:48:02: [2024-10-30 19:48:02] iter = 18820, loss = 1.9246
2024-10-30 19:48:06: [2024-10-30 19:48:06] iter = 18830, loss = 2.1754
2024-10-30 19:48:10: [2024-10-30 19:48:10] iter = 18840, loss = 2.4131
2024-10-30 19:48:13: [2024-10-30 19:48:13] iter = 18850, loss = 2.4073
2024-10-30 19:48:17: [2024-10-30 19:48:17] iter = 18860, loss = 2.2176
2024-10-30 19:48:21: [2024-10-30 19:48:21] iter = 18870, loss = 1.9011
2024-10-30 19:48:25: [2024-10-30 19:48:25] iter = 18880, loss = 2.3987
2024-10-30 19:48:30: [2024-10-30 19:48:30] iter = 18890, loss = 2.2868
2024-10-30 19:48:33: [2024-10-30 19:48:33] iter = 18900, loss = 2.2481
2024-10-30 19:48:36: [2024-10-30 19:48:36] iter = 18910, loss = 1.6102
2024-10-30 19:48:39: [2024-10-30 19:48:39] iter = 18920, loss = 3.1083
2024-10-30 19:48:44: [2024-10-30 19:48:44] iter = 18930, loss = 2.2890
2024-10-30 19:48:47: [2024-10-30 19:48:47] iter = 18940, loss = 2.7622
2024-10-30 19:48:51: [2024-10-30 19:48:51] iter = 18950, loss = 2.4887
2024-10-30 19:48:55: [2024-10-30 19:48:55] iter = 18960, loss = 2.0831
2024-10-30 19:48:58: [2024-10-30 19:48:58] iter = 18970, loss = 1.7597
2024-10-30 19:49:02: [2024-10-30 19:49:02] iter = 18980, loss = 1.8443
2024-10-30 19:49:06: [2024-10-30 19:49:06] iter = 18990, loss = 2.7312
2024-10-30 19:49:10: [2024-10-30 19:49:10] iter = 19000, loss = 2.0837
2024-10-30 19:49:13: [2024-10-30 19:49:13] iter = 19010, loss = 2.0175
2024-10-30 19:49:17: [2024-10-30 19:49:17] iter = 19020, loss = 2.1455
2024-10-30 19:49:21: [2024-10-30 19:49:21] iter = 19030, loss = 2.4251
2024-10-30 19:49:24: [2024-10-30 19:49:24] iter = 19040, loss = 1.9505
2024-10-30 19:49:29: [2024-10-30 19:49:29] iter = 19050, loss = 2.2021
2024-10-30 19:49:33: [2024-10-30 19:49:33] iter = 19060, loss = 1.7276
2024-10-30 19:49:37: [2024-10-30 19:49:37] iter = 19070, loss = 1.9240
2024-10-30 19:49:39: [2024-10-30 19:49:39] iter = 19080, loss = 2.2629
2024-10-30 19:49:42: [2024-10-30 19:49:42] iter = 19090, loss = 3.2144
2024-10-30 19:49:45: [2024-10-30 19:49:45] iter = 19100, loss = 2.3953
2024-10-30 19:49:48: [2024-10-30 19:49:48] iter = 19110, loss = 3.2516
2024-10-30 19:49:52: [2024-10-30 19:49:52] iter = 19120, loss = 1.9456
2024-10-30 19:49:57: [2024-10-30 19:49:57] iter = 19130, loss = 1.8034
2024-10-30 19:50:02: [2024-10-30 19:50:02] iter = 19140, loss = 1.9440
2024-10-30 19:50:06: [2024-10-30 19:50:06] iter = 19150, loss = 4.4578
2024-10-30 19:50:10: [2024-10-30 19:50:10] iter = 19160, loss = 2.5614
2024-10-30 19:50:14: [2024-10-30 19:50:14] iter = 19170, loss = 3.6227
2024-10-30 19:50:17: [2024-10-30 19:50:17] iter = 19180, loss = 2.2970
2024-10-30 19:50:21: [2024-10-30 19:50:21] iter = 19190, loss = 2.1888
2024-10-30 19:50:26: [2024-10-30 19:50:26] iter = 19200, loss = 2.0033
2024-10-30 19:50:29: [2024-10-30 19:50:29] iter = 19210, loss = 2.6319
2024-10-30 19:50:33: [2024-10-30 19:50:33] iter = 19220, loss = 1.7401
2024-10-30 19:50:37: [2024-10-30 19:50:37] iter = 19230, loss = 1.9657
2024-10-30 19:50:41: [2024-10-30 19:50:41] iter = 19240, loss = 2.3037
2024-10-30 19:50:45: [2024-10-30 19:50:45] iter = 19250, loss = 2.5446
2024-10-30 19:50:48: [2024-10-30 19:50:48] iter = 19260, loss = 1.9178
2024-10-30 19:50:51: [2024-10-30 19:50:51] iter = 19270, loss = 2.7881
2024-10-30 19:50:55: [2024-10-30 19:50:55] iter = 19280, loss = 1.6786
2024-10-30 19:50:58: [2024-10-30 19:50:58] iter = 19290, loss = 2.2489
2024-10-30 19:51:00: [2024-10-30 19:51:00] iter = 19300, loss = 1.9108
2024-10-30 19:51:03: [2024-10-30 19:51:03] iter = 19310, loss = 1.8132
2024-10-30 19:51:07: [2024-10-30 19:51:07] iter = 19320, loss = 1.8582
2024-10-30 19:51:11: [2024-10-30 19:51:11] iter = 19330, loss = 4.2104
2024-10-30 19:51:15: [2024-10-30 19:51:15] iter = 19340, loss = 1.8352
2024-10-30 19:51:19: [2024-10-30 19:51:19] iter = 19350, loss = 1.8332
2024-10-30 19:51:23: [2024-10-30 19:51:23] iter = 19360, loss = 1.7917
2024-10-30 19:51:28: [2024-10-30 19:51:28] iter = 19370, loss = 1.5810
2024-10-30 19:51:31: [2024-10-30 19:51:31] iter = 19380, loss = 1.9126
2024-10-30 19:51:34: [2024-10-30 19:51:34] iter = 19390, loss = 1.7326
2024-10-30 19:51:37: [2024-10-30 19:51:37] iter = 19400, loss = 1.8935
2024-10-30 19:51:40: [2024-10-30 19:51:40] iter = 19410, loss = 1.7903
2024-10-30 19:51:44: [2024-10-30 19:51:44] iter = 19420, loss = 1.7668
2024-10-30 19:51:48: [2024-10-30 19:51:48] iter = 19430, loss = 2.1173
2024-10-30 19:51:51: [2024-10-30 19:51:51] iter = 19440, loss = 2.3232
2024-10-30 19:51:55: [2024-10-30 19:51:55] iter = 19450, loss = 1.9541
2024-10-30 19:51:59: [2024-10-30 19:51:59] iter = 19460, loss = 2.7607
2024-10-30 19:52:03: [2024-10-30 19:52:03] iter = 19470, loss = 2.0234
2024-10-30 19:52:06: [2024-10-30 19:52:06] iter = 19480, loss = 2.0330
2024-10-30 19:52:08: [2024-10-30 19:52:08] iter = 19490, loss = 1.8583
2024-10-30 19:52:12: [2024-10-30 19:52:12] iter = 19500, loss = 1.9257
2024-10-30 19:52:16: [2024-10-30 19:52:16] iter = 19510, loss = 1.7463
2024-10-30 19:52:19: [2024-10-30 19:52:19] iter = 19520, loss = 1.6851
2024-10-30 19:52:22: [2024-10-30 19:52:22] iter = 19530, loss = 3.3647
2024-10-30 19:52:25: [2024-10-30 19:52:25] iter = 19540, loss = 1.9274
2024-10-30 19:52:28: [2024-10-30 19:52:28] iter = 19550, loss = 1.9040
2024-10-30 19:52:31: [2024-10-30 19:52:31] iter = 19560, loss = 2.0631
2024-10-30 19:52:35: [2024-10-30 19:52:35] iter = 19570, loss = 1.7486
2024-10-30 19:52:40: [2024-10-30 19:52:40] iter = 19580, loss = 2.1747
2024-10-30 19:52:44: [2024-10-30 19:52:44] iter = 19590, loss = 2.3705
2024-10-30 19:52:47: [2024-10-30 19:52:47] iter = 19600, loss = 2.8478
2024-10-30 19:52:51: [2024-10-30 19:52:51] iter = 19610, loss = 2.0189
2024-10-30 19:52:57: [2024-10-30 19:52:57] iter = 19620, loss = 4.7957
2024-10-30 19:53:00: [2024-10-30 19:53:00] iter = 19630, loss = 2.9204
2024-10-30 19:53:04: [2024-10-30 19:53:04] iter = 19640, loss = 2.0684
2024-10-30 19:53:10: [2024-10-30 19:53:10] iter = 19650, loss = 2.4877
2024-10-30 19:53:15: [2024-10-30 19:53:15] iter = 19660, loss = 1.6518
2024-10-30 19:53:19: [2024-10-30 19:53:19] iter = 19670, loss = 1.9886
2024-10-30 19:53:23: [2024-10-30 19:53:23] iter = 19680, loss = 1.8965
2024-10-30 19:53:28: [2024-10-30 19:53:28] iter = 19690, loss = 2.6244
2024-10-30 19:53:31: [2024-10-30 19:53:31] iter = 19700, loss = 1.9554
2024-10-30 19:53:36: [2024-10-30 19:53:36] iter = 19710, loss = 1.7676
2024-10-30 19:53:40: [2024-10-30 19:53:40] iter = 19720, loss = 2.0045
2024-10-30 19:53:44: [2024-10-30 19:53:44] iter = 19730, loss = 4.6045
2024-10-30 19:53:47: [2024-10-30 19:53:47] iter = 19740, loss = 3.5849
2024-10-30 19:53:51: [2024-10-30 19:53:51] iter = 19750, loss = 2.7618
2024-10-30 19:53:55: [2024-10-30 19:53:55] iter = 19760, loss = 1.5367
2024-10-30 19:54:00: [2024-10-30 19:54:00] iter = 19770, loss = 1.8341
2024-10-30 19:54:05: [2024-10-30 19:54:05] iter = 19780, loss = 2.7042
2024-10-30 19:54:09: [2024-10-30 19:54:09] iter = 19790, loss = 2.0383
2024-10-30 19:54:13: [2024-10-30 19:54:13] iter = 19800, loss = 2.1149
2024-10-30 19:54:18: [2024-10-30 19:54:18] iter = 19810, loss = 1.7988
2024-10-30 19:54:22: [2024-10-30 19:54:22] iter = 19820, loss = 1.8153
2024-10-30 19:54:27: [2024-10-30 19:54:27] iter = 19830, loss = 1.6775
2024-10-30 19:54:31: [2024-10-30 19:54:31] iter = 19840, loss = 2.8435
2024-10-30 19:54:35: [2024-10-30 19:54:35] iter = 19850, loss = 2.0316
2024-10-30 19:54:38: [2024-10-30 19:54:38] iter = 19860, loss = 2.1374
2024-10-30 19:54:41: [2024-10-30 19:54:41] iter = 19870, loss = 2.2265
2024-10-30 19:54:46: [2024-10-30 19:54:46] iter = 19880, loss = 2.4954
2024-10-30 19:54:50: [2024-10-30 19:54:50] iter = 19890, loss = 1.6968
2024-10-30 19:54:53: [2024-10-30 19:54:53] iter = 19900, loss = 2.1278
2024-10-30 19:54:56: [2024-10-30 19:54:56] iter = 19910, loss = 2.0172
2024-10-30 19:55:01: [2024-10-30 19:55:01] iter = 19920, loss = 2.2088
2024-10-30 19:55:04: [2024-10-30 19:55:04] iter = 19930, loss = 2.4953
2024-10-30 19:55:08: [2024-10-30 19:55:08] iter = 19940, loss = 1.9810
2024-10-30 19:55:12: [2024-10-30 19:55:12] iter = 19950, loss = 1.6678
2024-10-30 19:55:16: [2024-10-30 19:55:16] iter = 19960, loss = 2.4123
2024-10-30 19:55:20: [2024-10-30 19:55:20] iter = 19970, loss = 2.4158
2024-10-30 19:55:22: [2024-10-30 19:55:22] iter = 19980, loss = 2.8765
2024-10-30 19:55:26: [2024-10-30 19:55:26] iter = 19990, loss = 2.1901
2024-10-30 19:55:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 19:55:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:55:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 29613}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:57:53: Evaluate 5 random ConvNet, ACCmean = 0.7856 ACCstd = 0.0019
-------------------------
2024-10-30 19:57:53: Evaluate 5 random ConvNet, SENmean = 0.7780 SENstd = 0.0024
-------------------------
2024-10-30 19:57:53: Evaluate 5 random ConvNet, SPEmean = 0.9783 SPEstd = 0.0002
-------------------------
2024-10-30 19:57:53: Evaluate 5 random ConvNet, F!mean = 0.7717 F!std = 0.0023
-------------------------
2024-10-30 19:57:53: Evaluate 5 random ConvNet, mean = 0.7856 std = 0.0019
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:57:53: [2024-10-30 19:57:53] iter = 20000, loss = 2.1672
2024-10-30 19:57:53: 
================== Exp 2 ==================
 
2024-10-30 19:57:53: Hyper-parameters: 
{'dataset': 'OrganCMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f9aa0d64b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganCMNIST (INFO)>}
2024-10-30 19:57:53: Evaluation model pool: ['ConvNet']
2024-10-30 19:57:54: class c = 0: 1148 real images
2024-10-30 19:57:54: class c = 1: 619 real images
2024-10-30 19:57:54: class c = 2: 595 real images
2024-10-30 19:57:54: class c = 3: 600 real images
2024-10-30 19:57:54: class c = 4: 1088 real images
2024-10-30 19:57:54: class c = 5: 1170 real images
2024-10-30 19:57:54: class c = 6: 2986 real images
2024-10-30 19:57:54: class c = 7: 1002 real images
2024-10-30 19:57:54: class c = 8: 1022 real images
2024-10-30 19:57:54: class c = 9: 1173 real images
2024-10-30 19:57:54: class c = 10: 1572 real images
2024-10-30 19:57:54: real images channel 0, mean = 0.4942, std = 0.2834
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 19:57:54: initialize synthetic data from random real images
2024-10-30 19:57:54: [2024-10-30 19:57:54] training begins
2024-10-30 19:57:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 19:57:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:57:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 73433}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:00:01: Evaluate 5 random ConvNet, ACCmean = 0.6937 ACCstd = 0.0067
-------------------------
2024-10-30 20:00:01: Evaluate 5 random ConvNet, SENmean = 0.6978 SENstd = 0.0058
-------------------------
2024-10-30 20:00:01: Evaluate 5 random ConvNet, SPEmean = 0.9694 SPEstd = 0.0007
-------------------------
2024-10-30 20:00:01: Evaluate 5 random ConvNet, F!mean = 0.6815 F!std = 0.0064
-------------------------
2024-10-30 20:00:01: Evaluate 5 random ConvNet, mean = 0.6937 std = 0.0067
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:00:02: [2024-10-30 20:00:02] iter = 00000, loss = 14.1076
2024-10-30 20:00:06: [2024-10-30 20:00:06] iter = 00010, loss = 5.4632
2024-10-30 20:00:09: [2024-10-30 20:00:09] iter = 00020, loss = 3.5204
2024-10-30 20:00:13: [2024-10-30 20:00:13] iter = 00030, loss = 3.3394
2024-10-30 20:00:16: [2024-10-30 20:00:16] iter = 00040, loss = 3.3365
2024-10-30 20:00:20: [2024-10-30 20:00:20] iter = 00050, loss = 3.1954
2024-10-30 20:00:24: [2024-10-30 20:00:24] iter = 00060, loss = 2.3074
2024-10-30 20:00:28: [2024-10-30 20:00:28] iter = 00070, loss = 2.1776
2024-10-30 20:00:32: [2024-10-30 20:00:32] iter = 00080, loss = 2.6497
2024-10-30 20:00:36: [2024-10-30 20:00:36] iter = 00090, loss = 3.4352
2024-10-30 20:00:39: [2024-10-30 20:00:39] iter = 00100, loss = 2.6979
2024-10-30 20:00:43: [2024-10-30 20:00:43] iter = 00110, loss = 2.6243
2024-10-30 20:00:48: [2024-10-30 20:00:48] iter = 00120, loss = 2.9836
2024-10-30 20:00:51: [2024-10-30 20:00:51] iter = 00130, loss = 2.1521
2024-10-30 20:00:54: [2024-10-30 20:00:54] iter = 00140, loss = 2.0603
2024-10-30 20:00:58: [2024-10-30 20:00:58] iter = 00150, loss = 2.5037
2024-10-30 20:01:01: [2024-10-30 20:01:01] iter = 00160, loss = 2.4185
2024-10-30 20:01:05: [2024-10-30 20:01:05] iter = 00170, loss = 3.1270
2024-10-30 20:01:08: [2024-10-30 20:01:08] iter = 00180, loss = 3.0411
2024-10-30 20:01:12: [2024-10-30 20:01:12] iter = 00190, loss = 2.0712
2024-10-30 20:01:16: [2024-10-30 20:01:16] iter = 00200, loss = 2.8166
2024-10-30 20:01:21: [2024-10-30 20:01:21] iter = 00210, loss = 2.5056
2024-10-30 20:01:25: [2024-10-30 20:01:25] iter = 00220, loss = 1.9844
2024-10-30 20:01:29: [2024-10-30 20:01:29] iter = 00230, loss = 1.9931
2024-10-30 20:01:33: [2024-10-30 20:01:33] iter = 00240, loss = 1.8174
2024-10-30 20:01:36: [2024-10-30 20:01:36] iter = 00250, loss = 2.4064
2024-10-30 20:01:39: [2024-10-30 20:01:39] iter = 00260, loss = 2.5436
2024-10-30 20:01:43: [2024-10-30 20:01:43] iter = 00270, loss = 2.5417
2024-10-30 20:01:47: [2024-10-30 20:01:47] iter = 00280, loss = 2.9410
2024-10-30 20:01:50: [2024-10-30 20:01:50] iter = 00290, loss = 2.4887
2024-10-30 20:01:53: [2024-10-30 20:01:53] iter = 00300, loss = 4.0137
2024-10-30 20:01:57: [2024-10-30 20:01:57] iter = 00310, loss = 3.4476
2024-10-30 20:02:01: [2024-10-30 20:02:01] iter = 00320, loss = 2.4935
2024-10-30 20:02:05: [2024-10-30 20:02:05] iter = 00330, loss = 1.9182
2024-10-30 20:02:09: [2024-10-30 20:02:09] iter = 00340, loss = 3.0322
2024-10-30 20:02:12: [2024-10-30 20:02:12] iter = 00350, loss = 1.9195
2024-10-30 20:02:14: [2024-10-30 20:02:14] iter = 00360, loss = 3.3338
2024-10-30 20:02:18: [2024-10-30 20:02:18] iter = 00370, loss = 2.2441
2024-10-30 20:02:22: [2024-10-30 20:02:22] iter = 00380, loss = 2.5506
2024-10-30 20:02:25: [2024-10-30 20:02:25] iter = 00390, loss = 2.6820
2024-10-30 20:02:29: [2024-10-30 20:02:29] iter = 00400, loss = 2.7315
2024-10-30 20:02:33: [2024-10-30 20:02:33] iter = 00410, loss = 2.2827
2024-10-30 20:02:37: [2024-10-30 20:02:37] iter = 00420, loss = 1.7873
2024-10-30 20:02:40: [2024-10-30 20:02:40] iter = 00430, loss = 2.3434
2024-10-30 20:02:44: [2024-10-30 20:02:44] iter = 00440, loss = 2.6062
2024-10-30 20:02:46: [2024-10-30 20:02:46] iter = 00450, loss = 2.2635
2024-10-30 20:02:50: [2024-10-30 20:02:50] iter = 00460, loss = 2.3555
2024-10-30 20:02:54: [2024-10-30 20:02:54] iter = 00470, loss = 1.7744
2024-10-30 20:02:57: [2024-10-30 20:02:57] iter = 00480, loss = 2.1325
2024-10-30 20:03:02: [2024-10-30 20:03:02] iter = 00490, loss = 2.1283
2024-10-30 20:03:07: [2024-10-30 20:03:07] iter = 00500, loss = 2.6985
2024-10-30 20:03:11: [2024-10-30 20:03:11] iter = 00510, loss = 2.7277
2024-10-30 20:03:14: [2024-10-30 20:03:14] iter = 00520, loss = 2.0230
2024-10-30 20:03:17: [2024-10-30 20:03:17] iter = 00530, loss = 2.1562
2024-10-30 20:03:21: [2024-10-30 20:03:21] iter = 00540, loss = 2.2857
2024-10-30 20:03:25: [2024-10-30 20:03:25] iter = 00550, loss = 2.1523
2024-10-30 20:03:28: [2024-10-30 20:03:28] iter = 00560, loss = 1.8874
2024-10-30 20:03:31: [2024-10-30 20:03:31] iter = 00570, loss = 2.3555
2024-10-30 20:03:36: [2024-10-30 20:03:36] iter = 00580, loss = 2.1023
2024-10-30 20:03:41: [2024-10-30 20:03:41] iter = 00590, loss = 2.0606
2024-10-30 20:03:45: [2024-10-30 20:03:45] iter = 00600, loss = 1.8856
2024-10-30 20:03:49: [2024-10-30 20:03:49] iter = 00610, loss = 2.3893
2024-10-30 20:03:53: [2024-10-30 20:03:53] iter = 00620, loss = 2.8709
2024-10-30 20:03:56: [2024-10-30 20:03:56] iter = 00630, loss = 1.8896
2024-10-30 20:04:00: [2024-10-30 20:04:00] iter = 00640, loss = 2.3159
2024-10-30 20:04:03: [2024-10-30 20:04:03] iter = 00650, loss = 2.0550
2024-10-30 20:04:06: [2024-10-30 20:04:06] iter = 00660, loss = 2.3461
2024-10-30 20:04:10: [2024-10-30 20:04:10] iter = 00670, loss = 2.8939
2024-10-30 20:04:13: [2024-10-30 20:04:13] iter = 00680, loss = 3.0271
2024-10-30 20:04:17: [2024-10-30 20:04:17] iter = 00690, loss = 2.8028
2024-10-30 20:04:21: [2024-10-30 20:04:21] iter = 00700, loss = 1.9290
2024-10-30 20:04:25: [2024-10-30 20:04:25] iter = 00710, loss = 3.2286
2024-10-30 20:04:28: [2024-10-30 20:04:28] iter = 00720, loss = 2.6419
2024-10-30 20:04:32: [2024-10-30 20:04:32] iter = 00730, loss = 2.0875
2024-10-30 20:04:34: [2024-10-30 20:04:34] iter = 00740, loss = 3.8896
2024-10-30 20:04:38: [2024-10-30 20:04:38] iter = 00750, loss = 2.3781
2024-10-30 20:04:42: [2024-10-30 20:04:42] iter = 00760, loss = 2.3441
2024-10-30 20:04:45: [2024-10-30 20:04:45] iter = 00770, loss = 2.2804
2024-10-30 20:04:49: [2024-10-30 20:04:49] iter = 00780, loss = 2.3233
2024-10-30 20:04:54: [2024-10-30 20:04:54] iter = 00790, loss = 2.4313
2024-10-30 20:04:58: [2024-10-30 20:04:58] iter = 00800, loss = 2.6494
2024-10-30 20:05:02: [2024-10-30 20:05:02] iter = 00810, loss = 2.1936
2024-10-30 20:05:05: [2024-10-30 20:05:05] iter = 00820, loss = 2.0854
2024-10-30 20:05:09: [2024-10-30 20:05:09] iter = 00830, loss = 2.1210
2024-10-30 20:05:13: [2024-10-30 20:05:13] iter = 00840, loss = 2.1747
2024-10-30 20:05:17: [2024-10-30 20:05:17] iter = 00850, loss = 2.0575
2024-10-30 20:05:20: [2024-10-30 20:05:20] iter = 00860, loss = 2.0631
2024-10-30 20:05:25: [2024-10-30 20:05:25] iter = 00870, loss = 2.2963
2024-10-30 20:05:28: [2024-10-30 20:05:28] iter = 00880, loss = 2.1405
2024-10-30 20:05:32: [2024-10-30 20:05:32] iter = 00890, loss = 2.7685
2024-10-30 20:05:36: [2024-10-30 20:05:36] iter = 00900, loss = 1.8236
2024-10-30 20:05:39: [2024-10-30 20:05:39] iter = 00910, loss = 5.9015
2024-10-30 20:05:42: [2024-10-30 20:05:42] iter = 00920, loss = 2.3844
2024-10-30 20:05:45: [2024-10-30 20:05:45] iter = 00930, loss = 3.5773
2024-10-30 20:05:49: [2024-10-30 20:05:49] iter = 00940, loss = 3.0364
2024-10-30 20:05:53: [2024-10-30 20:05:53] iter = 00950, loss = 2.4783
2024-10-30 20:05:56: [2024-10-30 20:05:56] iter = 00960, loss = 2.5702
2024-10-30 20:06:00: [2024-10-30 20:06:00] iter = 00970, loss = 1.7910
2024-10-30 20:06:03: [2024-10-30 20:06:03] iter = 00980, loss = 2.5104
2024-10-30 20:06:06: [2024-10-30 20:06:06] iter = 00990, loss = 2.0604
2024-10-30 20:06:09: [2024-10-30 20:06:09] iter = 01000, loss = 2.2096
2024-10-30 20:06:13: [2024-10-30 20:06:13] iter = 01010, loss = 2.1106
2024-10-30 20:06:16: [2024-10-30 20:06:16] iter = 01020, loss = 2.0504
2024-10-30 20:06:19: [2024-10-30 20:06:19] iter = 01030, loss = 1.9783
2024-10-30 20:06:22: [2024-10-30 20:06:22] iter = 01040, loss = 1.9451
2024-10-30 20:06:26: [2024-10-30 20:06:26] iter = 01050, loss = 1.9518
2024-10-30 20:06:30: [2024-10-30 20:06:30] iter = 01060, loss = 2.0106
2024-10-30 20:06:33: [2024-10-30 20:06:33] iter = 01070, loss = 2.1672
2024-10-30 20:06:37: [2024-10-30 20:06:37] iter = 01080, loss = 1.8746
2024-10-30 20:06:41: [2024-10-30 20:06:41] iter = 01090, loss = 1.8982
2024-10-30 20:06:44: [2024-10-30 20:06:44] iter = 01100, loss = 1.7989
2024-10-30 20:06:48: [2024-10-30 20:06:48] iter = 01110, loss = 1.9545
2024-10-30 20:06:51: [2024-10-30 20:06:51] iter = 01120, loss = 1.9607
2024-10-30 20:06:54: [2024-10-30 20:06:54] iter = 01130, loss = 2.0914
2024-10-30 20:06:57: [2024-10-30 20:06:57] iter = 01140, loss = 1.9120
2024-10-30 20:07:00: [2024-10-30 20:07:00] iter = 01150, loss = 1.8460
2024-10-30 20:07:03: [2024-10-30 20:07:03] iter = 01160, loss = 2.8026
2024-10-30 20:07:06: [2024-10-30 20:07:06] iter = 01170, loss = 2.3552
2024-10-30 20:07:09: [2024-10-30 20:07:09] iter = 01180, loss = 1.6811
2024-10-30 20:07:13: [2024-10-30 20:07:13] iter = 01190, loss = 2.4529
2024-10-30 20:07:16: [2024-10-30 20:07:16] iter = 01200, loss = 2.1719
2024-10-30 20:07:20: [2024-10-30 20:07:20] iter = 01210, loss = 2.3989
2024-10-30 20:07:23: [2024-10-30 20:07:23] iter = 01220, loss = 1.8674
2024-10-30 20:07:26: [2024-10-30 20:07:26] iter = 01230, loss = 1.9420
2024-10-30 20:07:29: [2024-10-30 20:07:29] iter = 01240, loss = 1.9878
2024-10-30 20:07:32: [2024-10-30 20:07:32] iter = 01250, loss = 2.2877
2024-10-30 20:07:36: [2024-10-30 20:07:36] iter = 01260, loss = 2.2490
2024-10-30 20:07:38: [2024-10-30 20:07:38] iter = 01270, loss = 3.7798
2024-10-30 20:07:41: [2024-10-30 20:07:41] iter = 01280, loss = 2.2721
2024-10-30 20:07:46: [2024-10-30 20:07:46] iter = 01290, loss = 2.2051
2024-10-30 20:07:50: [2024-10-30 20:07:50] iter = 01300, loss = 1.9465
2024-10-30 20:07:54: [2024-10-30 20:07:54] iter = 01310, loss = 2.2572
2024-10-30 20:07:57: [2024-10-30 20:07:57] iter = 01320, loss = 3.0867
2024-10-30 20:08:01: [2024-10-30 20:08:01] iter = 01330, loss = 1.9312
2024-10-30 20:08:04: [2024-10-30 20:08:04] iter = 01340, loss = 1.9975
2024-10-30 20:08:08: [2024-10-30 20:08:08] iter = 01350, loss = 1.8111
2024-10-30 20:08:12: [2024-10-30 20:08:12] iter = 01360, loss = 2.5241
2024-10-30 20:08:16: [2024-10-30 20:08:16] iter = 01370, loss = 1.9478
2024-10-30 20:08:19: [2024-10-30 20:08:19] iter = 01380, loss = 2.1675
2024-10-30 20:08:23: [2024-10-30 20:08:23] iter = 01390, loss = 2.0992
2024-10-30 20:08:26: [2024-10-30 20:08:26] iter = 01400, loss = 2.0955
2024-10-30 20:08:29: [2024-10-30 20:08:29] iter = 01410, loss = 3.4024
2024-10-30 20:08:33: [2024-10-30 20:08:33] iter = 01420, loss = 1.7767
2024-10-30 20:08:37: [2024-10-30 20:08:37] iter = 01430, loss = 1.9690
2024-10-30 20:08:41: [2024-10-30 20:08:41] iter = 01440, loss = 1.6403
2024-10-30 20:08:44: [2024-10-30 20:08:44] iter = 01450, loss = 3.6570
2024-10-30 20:08:48: [2024-10-30 20:08:48] iter = 01460, loss = 2.1927
2024-10-30 20:08:51: [2024-10-30 20:08:51] iter = 01470, loss = 3.6278
2024-10-30 20:08:55: [2024-10-30 20:08:55] iter = 01480, loss = 2.1372
2024-10-30 20:08:59: [2024-10-30 20:08:59] iter = 01490, loss = 1.9260
2024-10-30 20:09:02: [2024-10-30 20:09:02] iter = 01500, loss = 2.1997
2024-10-30 20:09:05: [2024-10-30 20:09:05] iter = 01510, loss = 1.8473
2024-10-30 20:09:08: [2024-10-30 20:09:08] iter = 01520, loss = 2.1630
2024-10-30 20:09:11: [2024-10-30 20:09:11] iter = 01530, loss = 2.6132
2024-10-30 20:09:13: [2024-10-30 20:09:13] iter = 01540, loss = 2.4877
2024-10-30 20:09:16: [2024-10-30 20:09:16] iter = 01550, loss = 2.9920
2024-10-30 20:09:18: [2024-10-30 20:09:18] iter = 01560, loss = 1.9752
2024-10-30 20:09:21: [2024-10-30 20:09:21] iter = 01570, loss = 1.9374
2024-10-30 20:09:25: [2024-10-30 20:09:25] iter = 01580, loss = 1.8889
2024-10-30 20:09:28: [2024-10-30 20:09:28] iter = 01590, loss = 3.4567
2024-10-30 20:09:31: [2024-10-30 20:09:31] iter = 01600, loss = 3.2002
2024-10-30 20:09:35: [2024-10-30 20:09:35] iter = 01610, loss = 2.4434
2024-10-30 20:09:38: [2024-10-30 20:09:38] iter = 01620, loss = 2.7960
2024-10-30 20:09:41: [2024-10-30 20:09:41] iter = 01630, loss = 2.0402
2024-10-30 20:09:44: [2024-10-30 20:09:44] iter = 01640, loss = 3.1494
2024-10-30 20:09:48: [2024-10-30 20:09:48] iter = 01650, loss = 1.7254
2024-10-30 20:09:51: [2024-10-30 20:09:51] iter = 01660, loss = 8.8830
2024-10-30 20:09:55: [2024-10-30 20:09:55] iter = 01670, loss = 1.6592
2024-10-30 20:09:58: [2024-10-30 20:09:58] iter = 01680, loss = 2.4009
2024-10-30 20:10:02: [2024-10-30 20:10:02] iter = 01690, loss = 2.7897
2024-10-30 20:10:06: [2024-10-30 20:10:06] iter = 01700, loss = 1.8997
2024-10-30 20:10:10: [2024-10-30 20:10:10] iter = 01710, loss = 3.1473
2024-10-30 20:10:12: [2024-10-30 20:10:12] iter = 01720, loss = 2.2600
2024-10-30 20:10:16: [2024-10-30 20:10:16] iter = 01730, loss = 2.1421
2024-10-30 20:10:18: [2024-10-30 20:10:18] iter = 01740, loss = 2.1122
2024-10-30 20:10:21: [2024-10-30 20:10:21] iter = 01750, loss = 2.2475
2024-10-30 20:10:25: [2024-10-30 20:10:25] iter = 01760, loss = 2.1982
2024-10-30 20:10:29: [2024-10-30 20:10:29] iter = 01770, loss = 1.8993
2024-10-30 20:10:32: [2024-10-30 20:10:32] iter = 01780, loss = 3.0247
2024-10-30 20:10:36: [2024-10-30 20:10:36] iter = 01790, loss = 3.0396
2024-10-30 20:10:40: [2024-10-30 20:10:40] iter = 01800, loss = 1.8903
2024-10-30 20:10:43: [2024-10-30 20:10:43] iter = 01810, loss = 2.0557
2024-10-30 20:10:46: [2024-10-30 20:10:46] iter = 01820, loss = 2.1903
2024-10-30 20:10:49: [2024-10-30 20:10:49] iter = 01830, loss = 1.8800
2024-10-30 20:10:52: [2024-10-30 20:10:52] iter = 01840, loss = 2.8386
2024-10-30 20:10:56: [2024-10-30 20:10:56] iter = 01850, loss = 2.0685
2024-10-30 20:10:59: [2024-10-30 20:10:59] iter = 01860, loss = 2.1684
2024-10-30 20:11:02: [2024-10-30 20:11:02] iter = 01870, loss = 2.0532
2024-10-30 20:11:06: [2024-10-30 20:11:06] iter = 01880, loss = 2.2213
2024-10-30 20:11:09: [2024-10-30 20:11:09] iter = 01890, loss = 2.2440
2024-10-30 20:11:13: [2024-10-30 20:11:13] iter = 01900, loss = 3.3884
2024-10-30 20:11:17: [2024-10-30 20:11:17] iter = 01910, loss = 2.0590
2024-10-30 20:11:20: [2024-10-30 20:11:20] iter = 01920, loss = 1.8734
2024-10-30 20:11:24: [2024-10-30 20:11:24] iter = 01930, loss = 2.9361
2024-10-30 20:11:27: [2024-10-30 20:11:27] iter = 01940, loss = 3.1936
2024-10-30 20:11:30: [2024-10-30 20:11:30] iter = 01950, loss = 1.7604
2024-10-30 20:11:33: [2024-10-30 20:11:33] iter = 01960, loss = 2.5566
2024-10-30 20:11:36: [2024-10-30 20:11:36] iter = 01970, loss = 2.4745
2024-10-30 20:11:40: [2024-10-30 20:11:40] iter = 01980, loss = 2.5123
2024-10-30 20:11:44: [2024-10-30 20:11:44] iter = 01990, loss = 2.6846
2024-10-30 20:11:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 20:11:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:11:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 7547}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:14:05: Evaluate 5 random ConvNet, ACCmean = 0.7782 ACCstd = 0.0060
-------------------------
2024-10-30 20:14:05: Evaluate 5 random ConvNet, SENmean = 0.7749 SENstd = 0.0049
-------------------------
2024-10-30 20:14:05: Evaluate 5 random ConvNet, SPEmean = 0.9776 SPEstd = 0.0006
-------------------------
2024-10-30 20:14:05: Evaluate 5 random ConvNet, F!mean = 0.7654 F!std = 0.0055
-------------------------
2024-10-30 20:14:05: Evaluate 5 random ConvNet, mean = 0.7782 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:14:05: [2024-10-30 20:14:05] iter = 02000, loss = 1.8635
2024-10-30 20:14:08: [2024-10-30 20:14:08] iter = 02010, loss = 2.7002
2024-10-30 20:14:11: [2024-10-30 20:14:11] iter = 02020, loss = 1.8848
2024-10-30 20:14:15: [2024-10-30 20:14:15] iter = 02030, loss = 2.7957
2024-10-30 20:14:18: [2024-10-30 20:14:18] iter = 02040, loss = 2.1448
2024-10-30 20:14:22: [2024-10-30 20:14:22] iter = 02050, loss = 2.0183
2024-10-30 20:14:25: [2024-10-30 20:14:25] iter = 02060, loss = 2.1167
2024-10-30 20:14:28: [2024-10-30 20:14:28] iter = 02070, loss = 2.6776
2024-10-30 20:14:30: [2024-10-30 20:14:30] iter = 02080, loss = 2.8349
2024-10-30 20:14:33: [2024-10-30 20:14:33] iter = 02090, loss = 1.6379
2024-10-30 20:14:36: [2024-10-30 20:14:36] iter = 02100, loss = 1.6466
2024-10-30 20:14:40: [2024-10-30 20:14:40] iter = 02110, loss = 2.3399
2024-10-30 20:14:43: [2024-10-30 20:14:43] iter = 02120, loss = 2.7873
2024-10-30 20:14:46: [2024-10-30 20:14:46] iter = 02130, loss = 2.0645
2024-10-30 20:14:49: [2024-10-30 20:14:49] iter = 02140, loss = 3.0315
2024-10-30 20:14:51: [2024-10-30 20:14:51] iter = 02150, loss = 2.2853
2024-10-30 20:14:54: [2024-10-30 20:14:54] iter = 02160, loss = 1.7499
2024-10-30 20:14:57: [2024-10-30 20:14:57] iter = 02170, loss = 2.1325
2024-10-30 20:15:01: [2024-10-30 20:15:01] iter = 02180, loss = 1.9859
2024-10-30 20:15:03: [2024-10-30 20:15:03] iter = 02190, loss = 2.3762
2024-10-30 20:15:05: [2024-10-30 20:15:05] iter = 02200, loss = 2.3704
2024-10-30 20:15:10: [2024-10-30 20:15:10] iter = 02210, loss = 2.8885
2024-10-30 20:15:13: [2024-10-30 20:15:13] iter = 02220, loss = 2.8348
2024-10-30 20:15:17: [2024-10-30 20:15:17] iter = 02230, loss = 3.8399
2024-10-30 20:15:21: [2024-10-30 20:15:21] iter = 02240, loss = 2.0181
2024-10-30 20:15:24: [2024-10-30 20:15:24] iter = 02250, loss = 2.3414
2024-10-30 20:15:27: [2024-10-30 20:15:27] iter = 02260, loss = 1.8574
2024-10-30 20:15:31: [2024-10-30 20:15:31] iter = 02270, loss = 1.7083
2024-10-30 20:15:35: [2024-10-30 20:15:35] iter = 02280, loss = 2.0576
2024-10-30 20:15:39: [2024-10-30 20:15:39] iter = 02290, loss = 2.0258
2024-10-30 20:15:43: [2024-10-30 20:15:43] iter = 02300, loss = 2.2032
2024-10-30 20:15:47: [2024-10-30 20:15:47] iter = 02310, loss = 1.8097
2024-10-30 20:15:51: [2024-10-30 20:15:51] iter = 02320, loss = 1.7061
2024-10-30 20:15:54: [2024-10-30 20:15:54] iter = 02330, loss = 1.6724
2024-10-30 20:15:58: [2024-10-30 20:15:58] iter = 02340, loss = 1.7767
2024-10-30 20:16:02: [2024-10-30 20:16:02] iter = 02350, loss = 2.8682
2024-10-30 20:16:05: [2024-10-30 20:16:05] iter = 02360, loss = 2.5653
2024-10-30 20:16:09: [2024-10-30 20:16:09] iter = 02370, loss = 2.0291
2024-10-30 20:16:14: [2024-10-30 20:16:14] iter = 02380, loss = 2.1135
2024-10-30 20:16:18: [2024-10-30 20:16:18] iter = 02390, loss = 2.5681
2024-10-30 20:16:21: [2024-10-30 20:16:21] iter = 02400, loss = 4.8160
2024-10-30 20:16:24: [2024-10-30 20:16:24] iter = 02410, loss = 2.2001
2024-10-30 20:16:28: [2024-10-30 20:16:28] iter = 02420, loss = 2.4136
2024-10-30 20:16:33: [2024-10-30 20:16:33] iter = 02430, loss = 2.2960
2024-10-30 20:16:36: [2024-10-30 20:16:36] iter = 02440, loss = 3.3791
2024-10-30 20:16:41: [2024-10-30 20:16:41] iter = 02450, loss = 3.5651
2024-10-30 20:16:44: [2024-10-30 20:16:44] iter = 02460, loss = 2.1605
2024-10-30 20:16:48: [2024-10-30 20:16:48] iter = 02470, loss = 2.8399
2024-10-30 20:16:51: [2024-10-30 20:16:51] iter = 02480, loss = 2.6453
2024-10-30 20:16:54: [2024-10-30 20:16:54] iter = 02490, loss = 2.1140
2024-10-30 20:16:58: [2024-10-30 20:16:58] iter = 02500, loss = 2.8866
2024-10-30 20:17:03: [2024-10-30 20:17:03] iter = 02510, loss = 2.7332
2024-10-30 20:17:06: [2024-10-30 20:17:06] iter = 02520, loss = 1.8119
2024-10-30 20:17:10: [2024-10-30 20:17:10] iter = 02530, loss = 4.2907
2024-10-30 20:17:14: [2024-10-30 20:17:14] iter = 02540, loss = 2.3223
2024-10-30 20:17:18: [2024-10-30 20:17:18] iter = 02550, loss = 2.2394
2024-10-30 20:17:22: [2024-10-30 20:17:22] iter = 02560, loss = 1.6896
2024-10-30 20:17:26: [2024-10-30 20:17:26] iter = 02570, loss = 1.9180
2024-10-30 20:17:30: [2024-10-30 20:17:30] iter = 02580, loss = 2.0127
2024-10-30 20:17:33: [2024-10-30 20:17:33] iter = 02590, loss = 2.4436
2024-10-30 20:17:38: [2024-10-30 20:17:38] iter = 02600, loss = 2.0244
2024-10-30 20:17:42: [2024-10-30 20:17:42] iter = 02610, loss = 2.6585
2024-10-30 20:17:46: [2024-10-30 20:17:46] iter = 02620, loss = 2.4095
2024-10-30 20:17:50: [2024-10-30 20:17:50] iter = 02630, loss = 2.8834
2024-10-30 20:17:54: [2024-10-30 20:17:54] iter = 02640, loss = 1.9108
2024-10-30 20:17:58: [2024-10-30 20:17:58] iter = 02650, loss = 2.1394
2024-10-30 20:18:02: [2024-10-30 20:18:02] iter = 02660, loss = 1.8040
2024-10-30 20:18:06: [2024-10-30 20:18:06] iter = 02670, loss = 2.7244
2024-10-30 20:18:08: [2024-10-30 20:18:08] iter = 02680, loss = 2.5872
2024-10-30 20:18:12: [2024-10-30 20:18:12] iter = 02690, loss = 2.3171
2024-10-30 20:18:16: [2024-10-30 20:18:16] iter = 02700, loss = 2.1330
2024-10-30 20:18:22: [2024-10-30 20:18:22] iter = 02710, loss = 2.3752
2024-10-30 20:18:26: [2024-10-30 20:18:26] iter = 02720, loss = 2.6407
2024-10-30 20:18:31: [2024-10-30 20:18:31] iter = 02730, loss = 2.1910
2024-10-30 20:18:35: [2024-10-30 20:18:34] iter = 02740, loss = 2.0425
2024-10-30 20:18:38: [2024-10-30 20:18:38] iter = 02750, loss = 2.5480
2024-10-30 20:18:42: [2024-10-30 20:18:42] iter = 02760, loss = 2.3891
2024-10-30 20:18:46: [2024-10-30 20:18:46] iter = 02770, loss = 2.9793
2024-10-30 20:18:48: [2024-10-30 20:18:48] iter = 02780, loss = 2.8318
2024-10-30 20:18:52: [2024-10-30 20:18:52] iter = 02790, loss = 2.0843
2024-10-30 20:18:56: [2024-10-30 20:18:56] iter = 02800, loss = 2.4466
2024-10-30 20:19:01: [2024-10-30 20:19:01] iter = 02810, loss = 2.8958
2024-10-30 20:19:05: [2024-10-30 20:19:05] iter = 02820, loss = 1.9614
2024-10-30 20:19:09: [2024-10-30 20:19:09] iter = 02830, loss = 2.0343
2024-10-30 20:19:13: [2024-10-30 20:19:13] iter = 02840, loss = 2.0311
2024-10-30 20:19:16: [2024-10-30 20:19:16] iter = 02850, loss = 2.2858
2024-10-30 20:19:20: [2024-10-30 20:19:20] iter = 02860, loss = 3.0746
2024-10-30 20:19:24: [2024-10-30 20:19:24] iter = 02870, loss = 1.9757
2024-10-30 20:19:28: [2024-10-30 20:19:28] iter = 02880, loss = 2.3476
2024-10-30 20:19:31: [2024-10-30 20:19:31] iter = 02890, loss = 1.8068
2024-10-30 20:19:36: [2024-10-30 20:19:36] iter = 02900, loss = 1.8153
2024-10-30 20:19:39: [2024-10-30 20:19:39] iter = 02910, loss = 2.3686
2024-10-30 20:19:43: [2024-10-30 20:19:43] iter = 02920, loss = 2.8124
2024-10-30 20:19:47: [2024-10-30 20:19:47] iter = 02930, loss = 2.4886
2024-10-30 20:19:51: [2024-10-30 20:19:51] iter = 02940, loss = 2.2754
2024-10-30 20:19:55: [2024-10-30 20:19:55] iter = 02950, loss = 1.9086
2024-10-30 20:19:58: [2024-10-30 20:19:58] iter = 02960, loss = 2.9989
2024-10-30 20:20:01: [2024-10-30 20:20:01] iter = 02970, loss = 2.6135
2024-10-30 20:20:04: [2024-10-30 20:20:04] iter = 02980, loss = 1.9062
2024-10-30 20:20:06: [2024-10-30 20:20:06] iter = 02990, loss = 3.2988
2024-10-30 20:20:11: [2024-10-30 20:20:11] iter = 03000, loss = 1.9903
2024-10-30 20:20:14: [2024-10-30 20:20:14] iter = 03010, loss = 3.6087
2024-10-30 20:20:18: [2024-10-30 20:20:18] iter = 03020, loss = 1.9314
2024-10-30 20:20:21: [2024-10-30 20:20:21] iter = 03030, loss = 2.4548
2024-10-30 20:20:23: [2024-10-30 20:20:23] iter = 03040, loss = 2.2252
2024-10-30 20:20:27: [2024-10-30 20:20:27] iter = 03050, loss = 1.9548
2024-10-30 20:20:31: [2024-10-30 20:20:31] iter = 03060, loss = 2.9789
2024-10-30 20:20:34: [2024-10-30 20:20:34] iter = 03070, loss = 3.1628
2024-10-30 20:20:39: [2024-10-30 20:20:39] iter = 03080, loss = 1.7187
2024-10-30 20:20:42: [2024-10-30 20:20:42] iter = 03090, loss = 1.8419
2024-10-30 20:20:45: [2024-10-30 20:20:45] iter = 03100, loss = 1.9778
2024-10-30 20:20:49: [2024-10-30 20:20:49] iter = 03110, loss = 3.6638
2024-10-30 20:20:52: [2024-10-30 20:20:52] iter = 03120, loss = 1.9485
2024-10-30 20:20:56: [2024-10-30 20:20:56] iter = 03130, loss = 2.2023
2024-10-30 20:21:00: [2024-10-30 20:21:00] iter = 03140, loss = 1.9566
2024-10-30 20:21:04: [2024-10-30 20:21:04] iter = 03150, loss = 3.2299
2024-10-30 20:21:08: [2024-10-30 20:21:08] iter = 03160, loss = 2.1919
2024-10-30 20:21:12: [2024-10-30 20:21:12] iter = 03170, loss = 1.8058
2024-10-30 20:21:18: [2024-10-30 20:21:18] iter = 03180, loss = 2.2102
2024-10-30 20:21:22: [2024-10-30 20:21:22] iter = 03190, loss = 2.9305
2024-10-30 20:21:25: [2024-10-30 20:21:25] iter = 03200, loss = 1.6137
2024-10-30 20:21:29: [2024-10-30 20:21:29] iter = 03210, loss = 2.4134
2024-10-30 20:21:33: [2024-10-30 20:21:33] iter = 03220, loss = 2.0856
2024-10-30 20:21:36: [2024-10-30 20:21:36] iter = 03230, loss = 2.0398
2024-10-30 20:21:38: [2024-10-30 20:21:38] iter = 03240, loss = 2.0186
2024-10-30 20:21:42: [2024-10-30 20:21:42] iter = 03250, loss = 2.1970
2024-10-30 20:21:47: [2024-10-30 20:21:47] iter = 03260, loss = 1.6745
2024-10-30 20:21:50: [2024-10-30 20:21:50] iter = 03270, loss = 3.3712
2024-10-30 20:21:54: [2024-10-30 20:21:54] iter = 03280, loss = 3.0352
2024-10-30 20:21:58: [2024-10-30 20:21:58] iter = 03290, loss = 1.8665
2024-10-30 20:22:02: [2024-10-30 20:22:02] iter = 03300, loss = 2.4546
2024-10-30 20:22:07: [2024-10-30 20:22:07] iter = 03310, loss = 1.9767
2024-10-30 20:22:11: [2024-10-30 20:22:11] iter = 03320, loss = 2.2418
2024-10-30 20:22:15: [2024-10-30 20:22:15] iter = 03330, loss = 2.7343
2024-10-30 20:22:19: [2024-10-30 20:22:19] iter = 03340, loss = 2.2158
2024-10-30 20:22:23: [2024-10-30 20:22:23] iter = 03350, loss = 2.4399
2024-10-30 20:22:25: [2024-10-30 20:22:25] iter = 03360, loss = 3.5742
2024-10-30 20:22:29: [2024-10-30 20:22:29] iter = 03370, loss = 2.3911
2024-10-30 20:22:33: [2024-10-30 20:22:33] iter = 03380, loss = 2.0399
2024-10-30 20:22:37: [2024-10-30 20:22:37] iter = 03390, loss = 2.6587
2024-10-30 20:22:40: [2024-10-30 20:22:40] iter = 03400, loss = 2.1372
2024-10-30 20:22:44: [2024-10-30 20:22:44] iter = 03410, loss = 3.2466
2024-10-30 20:22:46: [2024-10-30 20:22:46] iter = 03420, loss = 2.2480
2024-10-30 20:22:48: [2024-10-30 20:22:48] iter = 03430, loss = 1.7869
2024-10-30 20:22:51: [2024-10-30 20:22:51] iter = 03440, loss = 2.5602
2024-10-30 20:22:55: [2024-10-30 20:22:55] iter = 03450, loss = 2.2415
2024-10-30 20:23:00: [2024-10-30 20:23:00] iter = 03460, loss = 1.9582
2024-10-30 20:23:04: [2024-10-30 20:23:04] iter = 03470, loss = 2.3456
2024-10-30 20:23:07: [2024-10-30 20:23:07] iter = 03480, loss = 1.9250
2024-10-30 20:23:11: [2024-10-30 20:23:11] iter = 03490, loss = 3.0976
2024-10-30 20:23:15: [2024-10-30 20:23:15] iter = 03500, loss = 1.9058
2024-10-30 20:23:20: [2024-10-30 20:23:20] iter = 03510, loss = 2.4233
2024-10-30 20:23:24: [2024-10-30 20:23:24] iter = 03520, loss = 3.2688
2024-10-30 20:23:29: [2024-10-30 20:23:29] iter = 03530, loss = 2.6869
2024-10-30 20:23:33: [2024-10-30 20:23:33] iter = 03540, loss = 1.7616
2024-10-30 20:23:36: [2024-10-30 20:23:36] iter = 03550, loss = 1.9440
2024-10-30 20:23:40: [2024-10-30 20:23:40] iter = 03560, loss = 3.2857
2024-10-30 20:23:44: [2024-10-30 20:23:44] iter = 03570, loss = 2.3836
2024-10-30 20:23:48: [2024-10-30 20:23:48] iter = 03580, loss = 1.6859
2024-10-30 20:23:52: [2024-10-30 20:23:52] iter = 03590, loss = 1.9766
2024-10-30 20:23:56: [2024-10-30 20:23:56] iter = 03600, loss = 1.8272
2024-10-30 20:24:01: [2024-10-30 20:24:01] iter = 03610, loss = 1.8943
2024-10-30 20:24:06: [2024-10-30 20:24:06] iter = 03620, loss = 2.2831
2024-10-30 20:24:10: [2024-10-30 20:24:10] iter = 03630, loss = 1.7547
2024-10-30 20:24:14: [2024-10-30 20:24:14] iter = 03640, loss = 2.1434
2024-10-30 20:24:18: [2024-10-30 20:24:18] iter = 03650, loss = 3.4304
2024-10-30 20:24:22: [2024-10-30 20:24:22] iter = 03660, loss = 2.3554
2024-10-30 20:24:26: [2024-10-30 20:24:26] iter = 03670, loss = 2.2418
2024-10-30 20:24:30: [2024-10-30 20:24:30] iter = 03680, loss = 2.1696
2024-10-30 20:24:33: [2024-10-30 20:24:33] iter = 03690, loss = 2.2111
2024-10-30 20:24:37: [2024-10-30 20:24:37] iter = 03700, loss = 1.8849
2024-10-30 20:24:41: [2024-10-30 20:24:41] iter = 03710, loss = 2.2715
2024-10-30 20:24:44: [2024-10-30 20:24:44] iter = 03720, loss = 1.8664
2024-10-30 20:24:48: [2024-10-30 20:24:48] iter = 03730, loss = 1.7484
2024-10-30 20:24:52: [2024-10-30 20:24:52] iter = 03740, loss = 2.5100
2024-10-30 20:24:56: [2024-10-30 20:24:56] iter = 03750, loss = 2.0436
2024-10-30 20:24:59: [2024-10-30 20:24:59] iter = 03760, loss = 2.5230
2024-10-30 20:25:02: [2024-10-30 20:25:02] iter = 03770, loss = 2.6511
2024-10-30 20:25:07: [2024-10-30 20:25:07] iter = 03780, loss = 2.0022
2024-10-30 20:25:10: [2024-10-30 20:25:10] iter = 03790, loss = 2.4884
2024-10-30 20:25:15: [2024-10-30 20:25:15] iter = 03800, loss = 1.9569
2024-10-30 20:25:18: [2024-10-30 20:25:18] iter = 03810, loss = 2.4367
2024-10-30 20:25:22: [2024-10-30 20:25:22] iter = 03820, loss = 2.6180
2024-10-30 20:25:26: [2024-10-30 20:25:26] iter = 03830, loss = 2.6227
2024-10-30 20:25:30: [2024-10-30 20:25:30] iter = 03840, loss = 2.1941
2024-10-30 20:25:34: [2024-10-30 20:25:34] iter = 03850, loss = 1.9937
2024-10-30 20:25:37: [2024-10-30 20:25:37] iter = 03860, loss = 2.1975
2024-10-30 20:25:42: [2024-10-30 20:25:42] iter = 03870, loss = 2.2696
2024-10-30 20:25:45: [2024-10-30 20:25:45] iter = 03880, loss = 2.0887
2024-10-30 20:25:49: [2024-10-30 20:25:49] iter = 03890, loss = 2.5704
2024-10-30 20:25:54: [2024-10-30 20:25:54] iter = 03900, loss = 2.0472
2024-10-30 20:25:58: [2024-10-30 20:25:58] iter = 03910, loss = 1.9321
2024-10-30 20:26:02: [2024-10-30 20:26:02] iter = 03920, loss = 2.3164
2024-10-30 20:26:06: [2024-10-30 20:26:06] iter = 03930, loss = 2.7856
2024-10-30 20:26:10: [2024-10-30 20:26:10] iter = 03940, loss = 2.0243
2024-10-30 20:26:14: [2024-10-30 20:26:14] iter = 03950, loss = 2.1999
2024-10-30 20:26:17: [2024-10-30 20:26:17] iter = 03960, loss = 2.6692
2024-10-30 20:26:22: [2024-10-30 20:26:22] iter = 03970, loss = 1.7649
2024-10-30 20:26:26: [2024-10-30 20:26:26] iter = 03980, loss = 1.8051
2024-10-30 20:26:30: [2024-10-30 20:26:30] iter = 03990, loss = 1.8120
2024-10-30 20:26:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 20:26:34: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:26:34: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 94325}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:29:06: Evaluate 5 random ConvNet, ACCmean = 0.7703 ACCstd = 0.0053
-------------------------
2024-10-30 20:29:06: Evaluate 5 random ConvNet, SENmean = 0.7639 SENstd = 0.0062
-------------------------
2024-10-30 20:29:06: Evaluate 5 random ConvNet, SPEmean = 0.9767 SPEstd = 0.0005
-------------------------
2024-10-30 20:29:06: Evaluate 5 random ConvNet, F!mean = 0.7584 F!std = 0.0058
-------------------------
2024-10-30 20:29:06: Evaluate 5 random ConvNet, mean = 0.7703 std = 0.0053
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:29:07: [2024-10-30 20:29:07] iter = 04000, loss = 2.2033
2024-10-30 20:29:11: [2024-10-30 20:29:11] iter = 04010, loss = 1.8838
2024-10-30 20:29:16: [2024-10-30 20:29:16] iter = 04020, loss = 2.9557
2024-10-30 20:29:20: [2024-10-30 20:29:20] iter = 04030, loss = 2.7240
2024-10-30 20:29:25: [2024-10-30 20:29:25] iter = 04040, loss = 1.9499
2024-10-30 20:29:29: [2024-10-30 20:29:29] iter = 04050, loss = 2.7191
2024-10-30 20:29:34: [2024-10-30 20:29:34] iter = 04060, loss = 3.1309
2024-10-30 20:29:39: [2024-10-30 20:29:39] iter = 04070, loss = 1.8282
2024-10-30 20:29:42: [2024-10-30 20:29:42] iter = 04080, loss = 2.0657
2024-10-30 20:29:46: [2024-10-30 20:29:46] iter = 04090, loss = 3.3324
2024-10-30 20:29:50: [2024-10-30 20:29:50] iter = 04100, loss = 2.0649
2024-10-30 20:29:54: [2024-10-30 20:29:54] iter = 04110, loss = 1.7326
2024-10-30 20:29:59: [2024-10-30 20:29:59] iter = 04120, loss = 2.1219
2024-10-30 20:30:03: [2024-10-30 20:30:03] iter = 04130, loss = 2.7046
2024-10-30 20:30:07: [2024-10-30 20:30:07] iter = 04140, loss = 2.3110
2024-10-30 20:30:11: [2024-10-30 20:30:11] iter = 04150, loss = 2.0999
2024-10-30 20:30:14: [2024-10-30 20:30:14] iter = 04160, loss = 2.9103
2024-10-30 20:30:19: [2024-10-30 20:30:19] iter = 04170, loss = 1.9118
2024-10-30 20:30:23: [2024-10-30 20:30:23] iter = 04180, loss = 2.1084
2024-10-30 20:30:27: [2024-10-30 20:30:27] iter = 04190, loss = 1.9593
2024-10-30 20:30:32: [2024-10-30 20:30:32] iter = 04200, loss = 2.2586
2024-10-30 20:30:37: [2024-10-30 20:30:37] iter = 04210, loss = 1.9488
2024-10-30 20:30:41: [2024-10-30 20:30:41] iter = 04220, loss = 2.0355
2024-10-30 20:30:45: [2024-10-30 20:30:45] iter = 04230, loss = 2.1271
2024-10-30 20:30:49: [2024-10-30 20:30:49] iter = 04240, loss = 3.3138
2024-10-30 20:30:53: [2024-10-30 20:30:53] iter = 04250, loss = 2.6690
2024-10-30 20:30:56: [2024-10-30 20:30:56] iter = 04260, loss = 2.3306
2024-10-30 20:31:01: [2024-10-30 20:31:01] iter = 04270, loss = 1.8092
2024-10-30 20:31:06: [2024-10-30 20:31:06] iter = 04280, loss = 2.0646
2024-10-30 20:31:10: [2024-10-30 20:31:10] iter = 04290, loss = 7.3871
2024-10-30 20:31:14: [2024-10-30 20:31:14] iter = 04300, loss = 2.1267
2024-10-30 20:31:18: [2024-10-30 20:31:18] iter = 04310, loss = 2.1122
2024-10-30 20:31:21: [2024-10-30 20:31:21] iter = 04320, loss = 1.9747
2024-10-30 20:31:25: [2024-10-30 20:31:25] iter = 04330, loss = 2.9435
2024-10-30 20:31:29: [2024-10-30 20:31:29] iter = 04340, loss = 2.4030
2024-10-30 20:31:33: [2024-10-30 20:31:33] iter = 04350, loss = 1.8634
2024-10-30 20:31:37: [2024-10-30 20:31:37] iter = 04360, loss = 2.5475
2024-10-30 20:31:41: [2024-10-30 20:31:41] iter = 04370, loss = 2.6871
2024-10-30 20:31:45: [2024-10-30 20:31:45] iter = 04380, loss = 2.0637
2024-10-30 20:31:49: [2024-10-30 20:31:49] iter = 04390, loss = 2.1595
2024-10-30 20:31:54: [2024-10-30 20:31:54] iter = 04400, loss = 1.9316
2024-10-30 20:31:57: [2024-10-30 20:31:57] iter = 04410, loss = 1.9569
2024-10-30 20:32:01: [2024-10-30 20:32:01] iter = 04420, loss = 1.7422
2024-10-30 20:32:04: [2024-10-30 20:32:04] iter = 04430, loss = 2.1651
2024-10-30 20:32:09: [2024-10-30 20:32:09] iter = 04440, loss = 3.2944
2024-10-30 20:32:13: [2024-10-30 20:32:13] iter = 04450, loss = 1.6690
2024-10-30 20:32:17: [2024-10-30 20:32:17] iter = 04460, loss = 1.9269
2024-10-30 20:32:20: [2024-10-30 20:32:20] iter = 04470, loss = 2.5179
2024-10-30 20:32:24: [2024-10-30 20:32:24] iter = 04480, loss = 2.1951
2024-10-30 20:32:28: [2024-10-30 20:32:28] iter = 04490, loss = 1.9256
2024-10-30 20:32:31: [2024-10-30 20:32:31] iter = 04500, loss = 3.5752
2024-10-30 20:32:34: [2024-10-30 20:32:34] iter = 04510, loss = 2.2645
2024-10-30 20:32:38: [2024-10-30 20:32:38] iter = 04520, loss = 2.1261
2024-10-30 20:32:41: [2024-10-30 20:32:41] iter = 04530, loss = 2.0854
2024-10-30 20:32:45: [2024-10-30 20:32:45] iter = 04540, loss = 2.8398
2024-10-30 20:32:49: [2024-10-30 20:32:49] iter = 04550, loss = 1.8787
2024-10-30 20:32:52: [2024-10-30 20:32:52] iter = 04560, loss = 2.2712
2024-10-30 20:32:55: [2024-10-30 20:32:55] iter = 04570, loss = 2.2548
2024-10-30 20:32:59: [2024-10-30 20:32:59] iter = 04580, loss = 2.9643
2024-10-30 20:33:03: [2024-10-30 20:33:03] iter = 04590, loss = 3.0348
2024-10-30 20:33:06: [2024-10-30 20:33:06] iter = 04600, loss = 2.4751
2024-10-30 20:33:10: [2024-10-30 20:33:10] iter = 04610, loss = 1.9652
2024-10-30 20:33:14: [2024-10-30 20:33:14] iter = 04620, loss = 3.5836
2024-10-30 20:33:18: [2024-10-30 20:33:18] iter = 04630, loss = 1.8786
2024-10-30 20:33:21: [2024-10-30 20:33:21] iter = 04640, loss = 2.4411
2024-10-30 20:33:24: [2024-10-30 20:33:24] iter = 04650, loss = 2.2590
2024-10-30 20:33:28: [2024-10-30 20:33:28] iter = 04660, loss = 1.9134
2024-10-30 20:33:31: [2024-10-30 20:33:31] iter = 04670, loss = 3.2755
2024-10-30 20:33:34: [2024-10-30 20:33:34] iter = 04680, loss = 2.3483
2024-10-30 20:33:37: [2024-10-30 20:33:37] iter = 04690, loss = 1.7718
2024-10-30 20:33:40: [2024-10-30 20:33:40] iter = 04700, loss = 1.9506
2024-10-30 20:33:42: [2024-10-30 20:33:42] iter = 04710, loss = 2.9655
2024-10-30 20:33:44: [2024-10-30 20:33:44] iter = 04720, loss = 2.4978
2024-10-30 20:33:47: [2024-10-30 20:33:47] iter = 04730, loss = 2.2092
2024-10-30 20:33:50: [2024-10-30 20:33:50] iter = 04740, loss = 1.8995
2024-10-30 20:33:53: [2024-10-30 20:33:53] iter = 04750, loss = 3.3259
2024-10-30 20:33:57: [2024-10-30 20:33:57] iter = 04760, loss = 2.0847
2024-10-30 20:34:00: [2024-10-30 20:34:00] iter = 04770, loss = 1.7946
2024-10-30 20:34:03: [2024-10-30 20:34:03] iter = 04780, loss = 1.7734
2024-10-30 20:34:06: [2024-10-30 20:34:06] iter = 04790, loss = 3.1063
2024-10-30 20:34:10: [2024-10-30 20:34:10] iter = 04800, loss = 2.6966
2024-10-30 20:34:14: [2024-10-30 20:34:14] iter = 04810, loss = 1.7354
2024-10-30 20:34:18: [2024-10-30 20:34:18] iter = 04820, loss = 1.8454
2024-10-30 20:34:22: [2024-10-30 20:34:22] iter = 04830, loss = 2.4790
2024-10-30 20:34:26: [2024-10-30 20:34:26] iter = 04840, loss = 1.8669
2024-10-30 20:34:30: [2024-10-30 20:34:30] iter = 04850, loss = 1.7678
2024-10-30 20:34:34: [2024-10-30 20:34:34] iter = 04860, loss = 1.8537
2024-10-30 20:34:38: [2024-10-30 20:34:38] iter = 04870, loss = 2.9324
2024-10-30 20:34:42: [2024-10-30 20:34:42] iter = 04880, loss = 2.0928
2024-10-30 20:34:45: [2024-10-30 20:34:45] iter = 04890, loss = 2.7947
2024-10-30 20:34:50: [2024-10-30 20:34:50] iter = 04900, loss = 3.5448
2024-10-30 20:34:53: [2024-10-30 20:34:53] iter = 04910, loss = 2.0072
2024-10-30 20:34:58: [2024-10-30 20:34:58] iter = 04920, loss = 2.1441
2024-10-30 20:35:02: [2024-10-30 20:35:02] iter = 04930, loss = 2.2569
2024-10-30 20:35:05: [2024-10-30 20:35:05] iter = 04940, loss = 2.1123
2024-10-30 20:35:10: [2024-10-30 20:35:10] iter = 04950, loss = 1.9153
2024-10-30 20:35:14: [2024-10-30 20:35:14] iter = 04960, loss = 1.5258
2024-10-30 20:35:18: [2024-10-30 20:35:18] iter = 04970, loss = 1.9133
2024-10-30 20:35:22: [2024-10-30 20:35:22] iter = 04980, loss = 1.8771
2024-10-30 20:35:25: [2024-10-30 20:35:25] iter = 04990, loss = 1.9970
2024-10-30 20:35:29: [2024-10-30 20:35:29] iter = 05000, loss = 2.6150
2024-10-30 20:35:32: [2024-10-30 20:35:32] iter = 05010, loss = 3.0250
2024-10-30 20:35:36: [2024-10-30 20:35:36] iter = 05020, loss = 3.2830
2024-10-30 20:35:39: [2024-10-30 20:35:39] iter = 05030, loss = 1.8832
2024-10-30 20:35:43: [2024-10-30 20:35:43] iter = 05040, loss = 2.8033
2024-10-30 20:35:46: [2024-10-30 20:35:46] iter = 05050, loss = 1.9912
2024-10-30 20:35:50: [2024-10-30 20:35:50] iter = 05060, loss = 3.6951
2024-10-30 20:35:53: [2024-10-30 20:35:53] iter = 05070, loss = 2.3139
2024-10-30 20:35:58: [2024-10-30 20:35:58] iter = 05080, loss = 1.9777
2024-10-30 20:36:02: [2024-10-30 20:36:02] iter = 05090, loss = 1.8712
2024-10-30 20:36:05: [2024-10-30 20:36:05] iter = 05100, loss = 2.1878
2024-10-30 20:36:08: [2024-10-30 20:36:08] iter = 05110, loss = 3.4214
2024-10-30 20:36:12: [2024-10-30 20:36:12] iter = 05120, loss = 1.9809
2024-10-30 20:36:15: [2024-10-30 20:36:15] iter = 05130, loss = 2.1836
2024-10-30 20:36:18: [2024-10-30 20:36:18] iter = 05140, loss = 1.9816
2024-10-30 20:36:21: [2024-10-30 20:36:21] iter = 05150, loss = 2.1081
2024-10-30 20:36:25: [2024-10-30 20:36:25] iter = 05160, loss = 1.9020
2024-10-30 20:36:28: [2024-10-30 20:36:28] iter = 05170, loss = 2.7538
2024-10-30 20:36:31: [2024-10-30 20:36:31] iter = 05180, loss = 1.9974
2024-10-30 20:36:34: [2024-10-30 20:36:34] iter = 05190, loss = 2.1694
2024-10-30 20:36:39: [2024-10-30 20:36:39] iter = 05200, loss = 2.3557
2024-10-30 20:36:43: [2024-10-30 20:36:43] iter = 05210, loss = 2.6866
2024-10-30 20:36:46: [2024-10-30 20:36:46] iter = 05220, loss = 1.8384
2024-10-30 20:36:50: [2024-10-30 20:36:50] iter = 05230, loss = 3.6985
2024-10-30 20:36:53: [2024-10-30 20:36:53] iter = 05240, loss = 1.9391
2024-10-30 20:36:57: [2024-10-30 20:36:57] iter = 05250, loss = 2.2624
2024-10-30 20:37:01: [2024-10-30 20:37:01] iter = 05260, loss = 2.5808
2024-10-30 20:37:05: [2024-10-30 20:37:05] iter = 05270, loss = 2.2891
2024-10-30 20:37:09: [2024-10-30 20:37:09] iter = 05280, loss = 2.5483
2024-10-30 20:37:13: [2024-10-30 20:37:13] iter = 05290, loss = 2.3121
2024-10-30 20:37:16: [2024-10-30 20:37:16] iter = 05300, loss = 2.0307
2024-10-30 20:37:19: [2024-10-30 20:37:19] iter = 05310, loss = 2.6593
2024-10-30 20:37:23: [2024-10-30 20:37:23] iter = 05320, loss = 2.5818
2024-10-30 20:37:27: [2024-10-30 20:37:27] iter = 05330, loss = 2.0532
2024-10-30 20:37:30: [2024-10-30 20:37:30] iter = 05340, loss = 1.8383
2024-10-30 20:37:34: [2024-10-30 20:37:34] iter = 05350, loss = 1.9042
2024-10-30 20:37:37: [2024-10-30 20:37:37] iter = 05360, loss = 1.5892
2024-10-30 20:37:41: [2024-10-30 20:37:41] iter = 05370, loss = 1.8074
2024-10-30 20:37:46: [2024-10-30 20:37:46] iter = 05380, loss = 1.6853
2024-10-30 20:37:49: [2024-10-30 20:37:49] iter = 05390, loss = 2.0932
2024-10-30 20:37:54: [2024-10-30 20:37:54] iter = 05400, loss = 2.0832
2024-10-30 20:37:58: [2024-10-30 20:37:58] iter = 05410, loss = 1.7527
2024-10-30 20:38:02: [2024-10-30 20:38:02] iter = 05420, loss = 1.8518
2024-10-30 20:38:06: [2024-10-30 20:38:06] iter = 05430, loss = 2.1780
2024-10-30 20:38:10: [2024-10-30 20:38:10] iter = 05440, loss = 1.9951
2024-10-30 20:38:13: [2024-10-30 20:38:13] iter = 05450, loss = 2.0432
2024-10-30 20:38:17: [2024-10-30 20:38:17] iter = 05460, loss = 1.9781
2024-10-30 20:38:22: [2024-10-30 20:38:22] iter = 05470, loss = 2.2448
2024-10-30 20:38:26: [2024-10-30 20:38:26] iter = 05480, loss = 2.1984
2024-10-30 20:38:30: [2024-10-30 20:38:30] iter = 05490, loss = 1.8121
2024-10-30 20:38:33: [2024-10-30 20:38:33] iter = 05500, loss = 1.9763
2024-10-30 20:38:37: [2024-10-30 20:38:37] iter = 05510, loss = 2.8632
2024-10-30 20:38:41: [2024-10-30 20:38:41] iter = 05520, loss = 1.8129
2024-10-30 20:38:45: [2024-10-30 20:38:45] iter = 05530, loss = 1.9030
2024-10-30 20:38:49: [2024-10-30 20:38:49] iter = 05540, loss = 2.0074
2024-10-30 20:38:53: [2024-10-30 20:38:53] iter = 05550, loss = 3.4084
2024-10-30 20:38:58: [2024-10-30 20:38:58] iter = 05560, loss = 2.1994
2024-10-30 20:39:02: [2024-10-30 20:39:02] iter = 05570, loss = 3.0787
2024-10-30 20:39:06: [2024-10-30 20:39:06] iter = 05580, loss = 1.9657
2024-10-30 20:39:10: [2024-10-30 20:39:10] iter = 05590, loss = 1.7516
2024-10-30 20:39:14: [2024-10-30 20:39:14] iter = 05600, loss = 3.0253
2024-10-30 20:39:18: [2024-10-30 20:39:18] iter = 05610, loss = 2.3087
2024-10-30 20:39:22: [2024-10-30 20:39:22] iter = 05620, loss = 2.1806
2024-10-30 20:39:26: [2024-10-30 20:39:26] iter = 05630, loss = 1.7285
2024-10-30 20:39:30: [2024-10-30 20:39:30] iter = 05640, loss = 1.8878
2024-10-30 20:39:35: [2024-10-30 20:39:35] iter = 05650, loss = 2.3823
2024-10-30 20:39:39: [2024-10-30 20:39:39] iter = 05660, loss = 2.8666
2024-10-30 20:39:43: [2024-10-30 20:39:43] iter = 05670, loss = 1.7924
2024-10-30 20:39:47: [2024-10-30 20:39:47] iter = 05680, loss = 2.6007
2024-10-30 20:39:52: [2024-10-30 20:39:52] iter = 05690, loss = 2.1336
2024-10-30 20:39:56: [2024-10-30 20:39:56] iter = 05700, loss = 1.8692
2024-10-30 20:40:02: [2024-10-30 20:40:02] iter = 05710, loss = 2.0428
2024-10-30 20:40:06: [2024-10-30 20:40:06] iter = 05720, loss = 1.8034
2024-10-30 20:40:10: [2024-10-30 20:40:10] iter = 05730, loss = 2.1423
2024-10-30 20:40:14: [2024-10-30 20:40:14] iter = 05740, loss = 2.8860
2024-10-30 20:40:18: [2024-10-30 20:40:18] iter = 05750, loss = 2.1536
2024-10-30 20:40:22: [2024-10-30 20:40:22] iter = 05760, loss = 1.6859
2024-10-30 20:40:26: [2024-10-30 20:40:26] iter = 05770, loss = 2.7130
2024-10-30 20:40:30: [2024-10-30 20:40:30] iter = 05780, loss = 1.8473
2024-10-30 20:40:34: [2024-10-30 20:40:34] iter = 05790, loss = 2.2496
2024-10-30 20:40:38: [2024-10-30 20:40:38] iter = 05800, loss = 2.7002
2024-10-30 20:40:43: [2024-10-30 20:40:43] iter = 05810, loss = 2.7759
2024-10-30 20:40:47: [2024-10-30 20:40:47] iter = 05820, loss = 1.8690
2024-10-30 20:40:51: [2024-10-30 20:40:51] iter = 05830, loss = 1.9973
2024-10-30 20:40:56: [2024-10-30 20:40:56] iter = 05840, loss = 1.9622
2024-10-30 20:41:00: [2024-10-30 20:41:00] iter = 05850, loss = 1.8390
2024-10-30 20:41:04: [2024-10-30 20:41:04] iter = 05860, loss = 2.3772
2024-10-30 20:41:08: [2024-10-30 20:41:08] iter = 05870, loss = 1.8464
2024-10-30 20:41:11: [2024-10-30 20:41:11] iter = 05880, loss = 2.0810
2024-10-30 20:41:15: [2024-10-30 20:41:15] iter = 05890, loss = 3.3526
2024-10-30 20:41:19: [2024-10-30 20:41:19] iter = 05900, loss = 1.9789
2024-10-30 20:41:24: [2024-10-30 20:41:24] iter = 05910, loss = 2.2526
2024-10-30 20:41:28: [2024-10-30 20:41:28] iter = 05920, loss = 2.1396
2024-10-30 20:41:31: [2024-10-30 20:41:31] iter = 05930, loss = 3.0358
2024-10-30 20:41:35: [2024-10-30 20:41:35] iter = 05940, loss = 2.7881
2024-10-30 20:41:38: [2024-10-30 20:41:38] iter = 05950, loss = 2.2382
2024-10-30 20:41:40: [2024-10-30 20:41:40] iter = 05960, loss = 3.2026
2024-10-30 20:41:44: [2024-10-30 20:41:44] iter = 05970, loss = 1.8323
2024-10-30 20:41:48: [2024-10-30 20:41:48] iter = 05980, loss = 1.9096
2024-10-30 20:41:52: [2024-10-30 20:41:52] iter = 05990, loss = 2.9019
2024-10-30 20:41:56: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 20:41:56: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:41:56: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 16551}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:44:35: Evaluate 5 random ConvNet, ACCmean = 0.7837 ACCstd = 0.0035
-------------------------
2024-10-30 20:44:35: Evaluate 5 random ConvNet, SENmean = 0.7774 SENstd = 0.0036
-------------------------
2024-10-30 20:44:35: Evaluate 5 random ConvNet, SPEmean = 0.9782 SPEstd = 0.0004
-------------------------
2024-10-30 20:44:35: Evaluate 5 random ConvNet, F!mean = 0.7702 F!std = 0.0029
-------------------------
2024-10-30 20:44:35: Evaluate 5 random ConvNet, mean = 0.7837 std = 0.0035
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:44:36: [2024-10-30 20:44:36] iter = 06000, loss = 1.9070
2024-10-30 20:44:39: [2024-10-30 20:44:39] iter = 06010, loss = 1.6405
2024-10-30 20:44:44: [2024-10-30 20:44:44] iter = 06020, loss = 2.0930
2024-10-30 20:44:49: [2024-10-30 20:44:49] iter = 06030, loss = 2.1448
2024-10-30 20:44:53: [2024-10-30 20:44:53] iter = 06040, loss = 1.9476
2024-10-30 20:44:58: [2024-10-30 20:44:58] iter = 06050, loss = 3.4411
2024-10-30 20:45:03: [2024-10-30 20:45:03] iter = 06060, loss = 2.5594
2024-10-30 20:45:05: [2024-10-30 20:45:05] iter = 06070, loss = 2.1820
2024-10-30 20:45:10: [2024-10-30 20:45:10] iter = 06080, loss = 2.2915
2024-10-30 20:45:14: [2024-10-30 20:45:14] iter = 06090, loss = 2.1672
2024-10-30 20:45:17: [2024-10-30 20:45:17] iter = 06100, loss = 2.5449
2024-10-30 20:45:21: [2024-10-30 20:45:21] iter = 06110, loss = 2.1492
2024-10-30 20:45:25: [2024-10-30 20:45:25] iter = 06120, loss = 2.9452
2024-10-30 20:45:30: [2024-10-30 20:45:30] iter = 06130, loss = 2.7399
2024-10-30 20:45:34: [2024-10-30 20:45:34] iter = 06140, loss = 2.3552
2024-10-30 20:45:38: [2024-10-30 20:45:38] iter = 06150, loss = 1.9041
2024-10-30 20:45:42: [2024-10-30 20:45:42] iter = 06160, loss = 2.2049
2024-10-30 20:45:47: [2024-10-30 20:45:47] iter = 06170, loss = 2.8661
2024-10-30 20:45:51: [2024-10-30 20:45:51] iter = 06180, loss = 2.2664
2024-10-30 20:45:55: [2024-10-30 20:45:55] iter = 06190, loss = 2.3736
2024-10-30 20:45:58: [2024-10-30 20:45:58] iter = 06200, loss = 2.2948
2024-10-30 20:46:02: [2024-10-30 20:46:02] iter = 06210, loss = 2.3591
2024-10-30 20:46:06: [2024-10-30 20:46:06] iter = 06220, loss = 1.7986
2024-10-30 20:46:10: [2024-10-30 20:46:10] iter = 06230, loss = 3.2057
2024-10-30 20:46:13: [2024-10-30 20:46:13] iter = 06240, loss = 2.0202
2024-10-30 20:46:18: [2024-10-30 20:46:18] iter = 06250, loss = 1.9654
2024-10-30 20:46:22: [2024-10-30 20:46:22] iter = 06260, loss = 2.8212
2024-10-30 20:46:25: [2024-10-30 20:46:25] iter = 06270, loss = 2.5986
2024-10-30 20:46:30: [2024-10-30 20:46:30] iter = 06280, loss = 1.9553
2024-10-30 20:46:33: [2024-10-30 20:46:33] iter = 06290, loss = 1.9213
2024-10-30 20:46:36: [2024-10-30 20:46:36] iter = 06300, loss = 2.1546
2024-10-30 20:46:40: [2024-10-30 20:46:40] iter = 06310, loss = 1.9123
2024-10-30 20:46:44: [2024-10-30 20:46:44] iter = 06320, loss = 2.6567
2024-10-30 20:46:49: [2024-10-30 20:46:49] iter = 06330, loss = 2.5173
2024-10-30 20:46:52: [2024-10-30 20:46:52] iter = 06340, loss = 1.5888
2024-10-30 20:46:56: [2024-10-30 20:46:56] iter = 06350, loss = 2.3664
2024-10-30 20:47:00: [2024-10-30 20:47:00] iter = 06360, loss = 2.0770
2024-10-30 20:47:04: [2024-10-30 20:47:04] iter = 06370, loss = 2.1633
2024-10-30 20:47:09: [2024-10-30 20:47:09] iter = 06380, loss = 1.9691
2024-10-30 20:47:12: [2024-10-30 20:47:12] iter = 06390, loss = 2.3596
2024-10-30 20:47:17: [2024-10-30 20:47:17] iter = 06400, loss = 1.7093
2024-10-30 20:47:20: [2024-10-30 20:47:20] iter = 06410, loss = 2.3514
2024-10-30 20:47:24: [2024-10-30 20:47:24] iter = 06420, loss = 1.7124
2024-10-30 20:47:28: [2024-10-30 20:47:28] iter = 06430, loss = 1.8593
2024-10-30 20:47:32: [2024-10-30 20:47:32] iter = 06440, loss = 1.8006
2024-10-30 20:47:35: [2024-10-30 20:47:35] iter = 06450, loss = 1.8434
2024-10-30 20:47:39: [2024-10-30 20:47:39] iter = 06460, loss = 2.1244
2024-10-30 20:47:43: [2024-10-30 20:47:43] iter = 06470, loss = 2.2446
2024-10-30 20:47:47: [2024-10-30 20:47:47] iter = 06480, loss = 3.3896
2024-10-30 20:47:53: [2024-10-30 20:47:53] iter = 06490, loss = 2.3169
2024-10-30 20:47:57: [2024-10-30 20:47:57] iter = 06500, loss = 2.3927
2024-10-30 20:48:01: [2024-10-30 20:48:01] iter = 06510, loss = 2.8732
2024-10-30 20:48:05: [2024-10-30 20:48:05] iter = 06520, loss = 2.4516
2024-10-30 20:48:09: [2024-10-30 20:48:09] iter = 06530, loss = 2.2096
2024-10-30 20:48:12: [2024-10-30 20:48:12] iter = 06540, loss = 2.3395
2024-10-30 20:48:17: [2024-10-30 20:48:17] iter = 06550, loss = 2.3175
2024-10-30 20:48:20: [2024-10-30 20:48:20] iter = 06560, loss = 2.5796
2024-10-30 20:48:25: [2024-10-30 20:48:25] iter = 06570, loss = 3.0825
2024-10-30 20:48:28: [2024-10-30 20:48:28] iter = 06580, loss = 2.4223
2024-10-30 20:48:32: [2024-10-30 20:48:32] iter = 06590, loss = 2.5431
2024-10-30 20:48:36: [2024-10-30 20:48:36] iter = 06600, loss = 1.8768
2024-10-30 20:48:40: [2024-10-30 20:48:40] iter = 06610, loss = 2.0049
2024-10-30 20:48:44: [2024-10-30 20:48:44] iter = 06620, loss = 2.5873
2024-10-30 20:48:47: [2024-10-30 20:48:47] iter = 06630, loss = 1.9617
2024-10-30 20:48:51: [2024-10-30 20:48:51] iter = 06640, loss = 1.8429
2024-10-30 20:48:53: [2024-10-30 20:48:53] iter = 06650, loss = 2.7513
2024-10-30 20:48:56: [2024-10-30 20:48:56] iter = 06660, loss = 1.9309
2024-10-30 20:49:00: [2024-10-30 20:49:00] iter = 06670, loss = 1.7178
2024-10-30 20:49:03: [2024-10-30 20:49:03] iter = 06680, loss = 2.1705
2024-10-30 20:49:07: [2024-10-30 20:49:07] iter = 06690, loss = 2.3460
2024-10-30 20:49:09: [2024-10-30 20:49:09] iter = 06700, loss = 2.2437
2024-10-30 20:49:13: [2024-10-30 20:49:13] iter = 06710, loss = 2.8363
2024-10-30 20:49:17: [2024-10-30 20:49:17] iter = 06720, loss = 2.5913
2024-10-30 20:49:20: [2024-10-30 20:49:20] iter = 06730, loss = 1.9006
2024-10-30 20:49:23: [2024-10-30 20:49:23] iter = 06740, loss = 1.8852
2024-10-30 20:49:27: [2024-10-30 20:49:27] iter = 06750, loss = 2.2497
2024-10-30 20:49:31: [2024-10-30 20:49:31] iter = 06760, loss = 2.0557
2024-10-30 20:49:35: [2024-10-30 20:49:35] iter = 06770, loss = 2.3180
2024-10-30 20:49:38: [2024-10-30 20:49:38] iter = 06780, loss = 5.1181
2024-10-30 20:49:42: [2024-10-30 20:49:42] iter = 06790, loss = 1.9656
2024-10-30 20:49:46: [2024-10-30 20:49:46] iter = 06800, loss = 2.7509
2024-10-30 20:49:50: [2024-10-30 20:49:50] iter = 06810, loss = 1.6256
2024-10-30 20:49:54: [2024-10-30 20:49:54] iter = 06820, loss = 2.2420
2024-10-30 20:49:58: [2024-10-30 20:49:58] iter = 06830, loss = 3.0337
2024-10-30 20:50:03: [2024-10-30 20:50:03] iter = 06840, loss = 2.8949
2024-10-30 20:50:07: [2024-10-30 20:50:07] iter = 06850, loss = 1.8798
2024-10-30 20:50:11: [2024-10-30 20:50:11] iter = 06860, loss = 1.8424
2024-10-30 20:50:15: [2024-10-30 20:50:15] iter = 06870, loss = 1.8754
2024-10-30 20:50:18: [2024-10-30 20:50:18] iter = 06880, loss = 1.8605
2024-10-30 20:50:22: [2024-10-30 20:50:22] iter = 06890, loss = 1.9997
2024-10-30 20:50:26: [2024-10-30 20:50:26] iter = 06900, loss = 2.1901
2024-10-30 20:50:30: [2024-10-30 20:50:30] iter = 06910, loss = 3.3450
2024-10-30 20:50:35: [2024-10-30 20:50:35] iter = 06920, loss = 2.7384
2024-10-30 20:50:38: [2024-10-30 20:50:38] iter = 06930, loss = 2.3505
2024-10-30 20:50:42: [2024-10-30 20:50:42] iter = 06940, loss = 1.9372
2024-10-30 20:50:47: [2024-10-30 20:50:47] iter = 06950, loss = 2.4155
2024-10-30 20:50:51: [2024-10-30 20:50:51] iter = 06960, loss = 2.2192
2024-10-30 20:50:54: [2024-10-30 20:50:54] iter = 06970, loss = 3.2625
2024-10-30 20:50:59: [2024-10-30 20:50:59] iter = 06980, loss = 3.2172
2024-10-30 20:51:03: [2024-10-30 20:51:03] iter = 06990, loss = 3.1366
2024-10-30 20:51:06: [2024-10-30 20:51:06] iter = 07000, loss = 1.8612
2024-10-30 20:51:10: [2024-10-30 20:51:10] iter = 07010, loss = 1.8883
2024-10-30 20:51:15: [2024-10-30 20:51:15] iter = 07020, loss = 2.0782
2024-10-30 20:51:19: [2024-10-30 20:51:19] iter = 07030, loss = 2.6879
2024-10-30 20:51:23: [2024-10-30 20:51:23] iter = 07040, loss = 2.3637
2024-10-30 20:51:26: [2024-10-30 20:51:26] iter = 07050, loss = 1.9645
2024-10-30 20:51:29: [2024-10-30 20:51:29] iter = 07060, loss = 3.8652
2024-10-30 20:51:33: [2024-10-30 20:51:33] iter = 07070, loss = 2.0897
2024-10-30 20:51:38: [2024-10-30 20:51:38] iter = 07080, loss = 2.3916
2024-10-30 20:51:42: [2024-10-30 20:51:42] iter = 07090, loss = 2.4856
2024-10-30 20:51:46: [2024-10-30 20:51:46] iter = 07100, loss = 1.8311
2024-10-30 20:51:49: [2024-10-30 20:51:49] iter = 07110, loss = 1.7365
2024-10-30 20:51:53: [2024-10-30 20:51:53] iter = 07120, loss = 2.4420
2024-10-30 20:51:58: [2024-10-30 20:51:58] iter = 07130, loss = 2.9798
2024-10-30 20:52:02: [2024-10-30 20:52:02] iter = 07140, loss = 2.5159
2024-10-30 20:52:06: [2024-10-30 20:52:06] iter = 07150, loss = 1.8290
2024-10-30 20:52:10: [2024-10-30 20:52:10] iter = 07160, loss = 1.7697
2024-10-30 20:52:13: [2024-10-30 20:52:13] iter = 07170, loss = 2.1559
2024-10-30 20:52:17: [2024-10-30 20:52:17] iter = 07180, loss = 2.0902
2024-10-30 20:52:20: [2024-10-30 20:52:20] iter = 07190, loss = 3.0560
2024-10-30 20:52:24: [2024-10-30 20:52:24] iter = 07200, loss = 2.2236
2024-10-30 20:52:28: [2024-10-30 20:52:28] iter = 07210, loss = 1.7865
2024-10-30 20:52:32: [2024-10-30 20:52:32] iter = 07220, loss = 2.2096
2024-10-30 20:52:37: [2024-10-30 20:52:37] iter = 07230, loss = 2.3200
2024-10-30 20:52:41: [2024-10-30 20:52:41] iter = 07240, loss = 2.7266
2024-10-30 20:52:45: [2024-10-30 20:52:45] iter = 07250, loss = 5.2425
2024-10-30 20:52:49: [2024-10-30 20:52:49] iter = 07260, loss = 2.2712
2024-10-30 20:52:53: [2024-10-30 20:52:53] iter = 07270, loss = 2.1456
2024-10-30 20:52:57: [2024-10-30 20:52:57] iter = 07280, loss = 3.6210
2024-10-30 20:53:01: [2024-10-30 20:53:01] iter = 07290, loss = 2.0530
2024-10-30 20:53:05: [2024-10-30 20:53:05] iter = 07300, loss = 3.0163
2024-10-30 20:53:09: [2024-10-30 20:53:09] iter = 07310, loss = 2.5330
2024-10-30 20:53:13: [2024-10-30 20:53:13] iter = 07320, loss = 1.9941
2024-10-30 20:53:18: [2024-10-30 20:53:18] iter = 07330, loss = 2.7152
2024-10-30 20:53:22: [2024-10-30 20:53:22] iter = 07340, loss = 2.4261
2024-10-30 20:53:27: [2024-10-30 20:53:27] iter = 07350, loss = 2.2185
2024-10-30 20:53:30: [2024-10-30 20:53:30] iter = 07360, loss = 1.8871
2024-10-30 20:53:34: [2024-10-30 20:53:34] iter = 07370, loss = 3.0635
2024-10-30 20:53:39: [2024-10-30 20:53:39] iter = 07380, loss = 2.5499
2024-10-30 20:53:43: [2024-10-30 20:53:43] iter = 07390, loss = 2.3598
2024-10-30 20:53:49: [2024-10-30 20:53:49] iter = 07400, loss = 1.8071
2024-10-30 20:53:55: [2024-10-30 20:53:55] iter = 07410, loss = 1.8269
2024-10-30 20:54:00: [2024-10-30 20:54:00] iter = 07420, loss = 1.9040
2024-10-30 20:54:05: [2024-10-30 20:54:05] iter = 07430, loss = 1.8445
2024-10-30 20:54:09: [2024-10-30 20:54:09] iter = 07440, loss = 2.1510
2024-10-30 20:54:15: [2024-10-30 20:54:15] iter = 07450, loss = 2.0651
2024-10-30 20:54:20: [2024-10-30 20:54:20] iter = 07460, loss = 2.0304
2024-10-30 20:54:24: [2024-10-30 20:54:24] iter = 07470, loss = 3.1111
2024-10-30 20:54:28: [2024-10-30 20:54:28] iter = 07480, loss = 2.5098
2024-10-30 20:54:33: [2024-10-30 20:54:33] iter = 07490, loss = 2.0305
2024-10-30 20:54:36: [2024-10-30 20:54:36] iter = 07500, loss = 3.1081
2024-10-30 20:54:41: [2024-10-30 20:54:41] iter = 07510, loss = 6.0520
2024-10-30 20:54:45: [2024-10-30 20:54:45] iter = 07520, loss = 2.2855
2024-10-30 20:54:50: [2024-10-30 20:54:50] iter = 07530, loss = 1.8732
2024-10-30 20:54:53: [2024-10-30 20:54:53] iter = 07540, loss = 1.9127
2024-10-30 20:54:57: [2024-10-30 20:54:57] iter = 07550, loss = 2.2155
2024-10-30 20:55:01: [2024-10-30 20:55:01] iter = 07560, loss = 3.8607
2024-10-30 20:55:05: [2024-10-30 20:55:05] iter = 07570, loss = 2.2947
2024-10-30 20:55:09: [2024-10-30 20:55:09] iter = 07580, loss = 1.6808
2024-10-30 20:55:12: [2024-10-30 20:55:12] iter = 07590, loss = 2.2794
2024-10-30 20:55:16: [2024-10-30 20:55:16] iter = 07600, loss = 2.0163
2024-10-30 20:55:20: [2024-10-30 20:55:20] iter = 07610, loss = 1.6008
2024-10-30 20:55:24: [2024-10-30 20:55:24] iter = 07620, loss = 1.7956
2024-10-30 20:55:28: [2024-10-30 20:55:28] iter = 07630, loss = 1.6866
2024-10-30 20:55:33: [2024-10-30 20:55:33] iter = 07640, loss = 2.1702
2024-10-30 20:55:38: [2024-10-30 20:55:38] iter = 07650, loss = 1.9708
2024-10-30 20:55:43: [2024-10-30 20:55:43] iter = 07660, loss = 1.9471
2024-10-30 20:55:47: [2024-10-30 20:55:47] iter = 07670, loss = 1.7853
2024-10-30 20:55:50: [2024-10-30 20:55:50] iter = 07680, loss = 2.1119
2024-10-30 20:55:55: [2024-10-30 20:55:55] iter = 07690, loss = 1.7283
2024-10-30 20:55:59: [2024-10-30 20:55:59] iter = 07700, loss = 1.7022
2024-10-30 20:56:04: [2024-10-30 20:56:04] iter = 07710, loss = 2.6334
2024-10-30 20:56:07: [2024-10-30 20:56:07] iter = 07720, loss = 1.9162
2024-10-30 20:56:11: [2024-10-30 20:56:11] iter = 07730, loss = 1.9403
2024-10-30 20:56:15: [2024-10-30 20:56:15] iter = 07740, loss = 2.8230
2024-10-30 20:56:20: [2024-10-30 20:56:20] iter = 07750, loss = 2.3568
2024-10-30 20:56:24: [2024-10-30 20:56:24] iter = 07760, loss = 2.0808
2024-10-30 20:56:28: [2024-10-30 20:56:28] iter = 07770, loss = 1.8022
2024-10-30 20:56:33: [2024-10-30 20:56:33] iter = 07780, loss = 2.0292
2024-10-30 20:56:38: [2024-10-30 20:56:38] iter = 07790, loss = 1.8743
2024-10-30 20:56:43: [2024-10-30 20:56:43] iter = 07800, loss = 1.7867
2024-10-30 20:56:47: [2024-10-30 20:56:47] iter = 07810, loss = 3.2118
2024-10-30 20:56:50: [2024-10-30 20:56:50] iter = 07820, loss = 2.2740
2024-10-30 20:56:55: [2024-10-30 20:56:55] iter = 07830, loss = 1.9078
2024-10-30 20:56:58: [2024-10-30 20:56:58] iter = 07840, loss = 5.3614
2024-10-30 20:57:03: [2024-10-30 20:57:03] iter = 07850, loss = 2.4844
2024-10-30 20:57:06: [2024-10-30 20:57:06] iter = 07860, loss = 2.6460
2024-10-30 20:57:11: [2024-10-30 20:57:11] iter = 07870, loss = 1.7754
2024-10-30 20:57:15: [2024-10-30 20:57:15] iter = 07880, loss = 1.7074
2024-10-30 20:57:19: [2024-10-30 20:57:19] iter = 07890, loss = 2.0428
2024-10-30 20:57:23: [2024-10-30 20:57:23] iter = 07900, loss = 1.7701
2024-10-30 20:57:27: [2024-10-30 20:57:27] iter = 07910, loss = 2.3100
2024-10-30 20:57:32: [2024-10-30 20:57:32] iter = 07920, loss = 3.0420
2024-10-30 20:57:36: [2024-10-30 20:57:36] iter = 07930, loss = 1.9130
2024-10-30 20:57:39: [2024-10-30 20:57:39] iter = 07940, loss = 3.9799
2024-10-30 20:57:44: [2024-10-30 20:57:44] iter = 07950, loss = 1.8649
2024-10-30 20:57:48: [2024-10-30 20:57:48] iter = 07960, loss = 1.8826
2024-10-30 20:57:52: [2024-10-30 20:57:52] iter = 07970, loss = 2.1224
2024-10-30 20:57:57: [2024-10-30 20:57:57] iter = 07980, loss = 2.1921
2024-10-30 20:58:01: [2024-10-30 20:58:01] iter = 07990, loss = 3.4021
2024-10-30 20:58:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 20:58:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:58:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 84810}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:01:09: Evaluate 5 random ConvNet, ACCmean = 0.7823 ACCstd = 0.0029
-------------------------
2024-10-30 21:01:09: Evaluate 5 random ConvNet, SENmean = 0.7785 SENstd = 0.0021
-------------------------
2024-10-30 21:01:09: Evaluate 5 random ConvNet, SPEmean = 0.9780 SPEstd = 0.0003
-------------------------
2024-10-30 21:01:09: Evaluate 5 random ConvNet, F!mean = 0.7713 F!std = 0.0025
-------------------------
2024-10-30 21:01:09: Evaluate 5 random ConvNet, mean = 0.7823 std = 0.0029
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:01:10: [2024-10-30 21:01:10] iter = 08000, loss = 5.7680
2024-10-30 21:01:14: [2024-10-30 21:01:14] iter = 08010, loss = 1.9135
2024-10-30 21:01:18: [2024-10-30 21:01:18] iter = 08020, loss = 1.8614
2024-10-30 21:01:23: [2024-10-30 21:01:23] iter = 08030, loss = 2.5127
2024-10-30 21:01:27: [2024-10-30 21:01:27] iter = 08040, loss = 2.2839
2024-10-30 21:01:32: [2024-10-30 21:01:32] iter = 08050, loss = 2.2502
2024-10-30 21:01:35: [2024-10-30 21:01:35] iter = 08060, loss = 1.9129
2024-10-30 21:01:40: [2024-10-30 21:01:40] iter = 08070, loss = 2.0024
2024-10-30 21:01:44: [2024-10-30 21:01:44] iter = 08080, loss = 2.5806
2024-10-30 21:01:49: [2024-10-30 21:01:49] iter = 08090, loss = 1.8087
2024-10-30 21:01:53: [2024-10-30 21:01:53] iter = 08100, loss = 1.9126
2024-10-30 21:01:59: [2024-10-30 21:01:59] iter = 08110, loss = 2.4529
2024-10-30 21:02:03: [2024-10-30 21:02:03] iter = 08120, loss = 1.7030
2024-10-30 21:02:08: [2024-10-30 21:02:08] iter = 08130, loss = 1.8584
2024-10-30 21:02:11: [2024-10-30 21:02:11] iter = 08140, loss = 1.6898
2024-10-30 21:02:16: [2024-10-30 21:02:16] iter = 08150, loss = 1.8031
2024-10-30 21:02:20: [2024-10-30 21:02:20] iter = 08160, loss = 1.6906
2024-10-30 21:02:23: [2024-10-30 21:02:23] iter = 08170, loss = 2.0087
2024-10-30 21:02:28: [2024-10-30 21:02:28] iter = 08180, loss = 1.8830
2024-10-30 21:02:32: [2024-10-30 21:02:32] iter = 08190, loss = 1.7583
2024-10-30 21:02:37: [2024-10-30 21:02:36] iter = 08200, loss = 1.9741
2024-10-30 21:02:40: [2024-10-30 21:02:40] iter = 08210, loss = 2.3274
2024-10-30 21:02:44: [2024-10-30 21:02:44] iter = 08220, loss = 2.8375
2024-10-30 21:02:48: [2024-10-30 21:02:48] iter = 08230, loss = 2.8934
2024-10-30 21:02:53: [2024-10-30 21:02:53] iter = 08240, loss = 1.7481
2024-10-30 21:02:56: [2024-10-30 21:02:56] iter = 08250, loss = 1.6214
2024-10-30 21:03:02: [2024-10-30 21:03:02] iter = 08260, loss = 2.0627
2024-10-30 21:03:06: [2024-10-30 21:03:06] iter = 08270, loss = 2.3865
2024-10-30 21:03:11: [2024-10-30 21:03:11] iter = 08280, loss = 2.0169
2024-10-30 21:03:15: [2024-10-30 21:03:15] iter = 08290, loss = 1.7950
2024-10-30 21:03:20: [2024-10-30 21:03:20] iter = 08300, loss = 2.5788
2024-10-30 21:03:24: [2024-10-30 21:03:24] iter = 08310, loss = 2.0789
2024-10-30 21:03:28: [2024-10-30 21:03:28] iter = 08320, loss = 2.4916
2024-10-30 21:03:32: [2024-10-30 21:03:32] iter = 08330, loss = 3.3244
2024-10-30 21:03:36: [2024-10-30 21:03:36] iter = 08340, loss = 2.0342
2024-10-30 21:03:40: [2024-10-30 21:03:40] iter = 08350, loss = 2.0262
2024-10-30 21:03:44: [2024-10-30 21:03:44] iter = 08360, loss = 2.6874
2024-10-30 21:03:49: [2024-10-30 21:03:49] iter = 08370, loss = 2.0794
2024-10-30 21:03:53: [2024-10-30 21:03:53] iter = 08380, loss = 2.3611
2024-10-30 21:03:57: [2024-10-30 21:03:57] iter = 08390, loss = 2.0477
2024-10-30 21:04:01: [2024-10-30 21:04:01] iter = 08400, loss = 2.7753
2024-10-30 21:04:05: [2024-10-30 21:04:05] iter = 08410, loss = 2.0006
2024-10-30 21:04:10: [2024-10-30 21:04:10] iter = 08420, loss = 2.1702
2024-10-30 21:04:15: [2024-10-30 21:04:15] iter = 08430, loss = 2.2593
2024-10-30 21:04:20: [2024-10-30 21:04:20] iter = 08440, loss = 2.7287
2024-10-30 21:04:24: [2024-10-30 21:04:24] iter = 08450, loss = 3.7043
2024-10-30 21:04:28: [2024-10-30 21:04:28] iter = 08460, loss = 2.4923
2024-10-30 21:04:32: [2024-10-30 21:04:32] iter = 08470, loss = 2.3982
2024-10-30 21:04:36: [2024-10-30 21:04:36] iter = 08480, loss = 1.7439
2024-10-30 21:04:40: [2024-10-30 21:04:40] iter = 08490, loss = 2.1156
2024-10-30 21:04:44: [2024-10-30 21:04:44] iter = 08500, loss = 2.0657
2024-10-30 21:04:48: [2024-10-30 21:04:48] iter = 08510, loss = 1.8577
2024-10-30 21:04:52: [2024-10-30 21:04:52] iter = 08520, loss = 1.7212
2024-10-30 21:04:58: [2024-10-30 21:04:58] iter = 08530, loss = 1.8858
2024-10-30 21:05:02: [2024-10-30 21:05:02] iter = 08540, loss = 2.0845
2024-10-30 21:05:06: [2024-10-30 21:05:06] iter = 08550, loss = 2.0092
2024-10-30 21:05:11: [2024-10-30 21:05:11] iter = 08560, loss = 2.9334
2024-10-30 21:05:14: [2024-10-30 21:05:14] iter = 08570, loss = 1.8816
2024-10-30 21:05:19: [2024-10-30 21:05:19] iter = 08580, loss = 2.8224
2024-10-30 21:05:22: [2024-10-30 21:05:22] iter = 08590, loss = 2.1698
2024-10-30 21:05:26: [2024-10-30 21:05:26] iter = 08600, loss = 1.7235
2024-10-30 21:05:29: [2024-10-30 21:05:29] iter = 08610, loss = 2.5792
2024-10-30 21:05:32: [2024-10-30 21:05:32] iter = 08620, loss = 2.0559
2024-10-30 21:05:36: [2024-10-30 21:05:36] iter = 08630, loss = 2.2014
2024-10-30 21:05:40: [2024-10-30 21:05:40] iter = 08640, loss = 2.9348
2024-10-30 21:05:44: [2024-10-30 21:05:44] iter = 08650, loss = 2.1980
2024-10-30 21:05:49: [2024-10-30 21:05:49] iter = 08660, loss = 1.8738
2024-10-30 21:05:52: [2024-10-30 21:05:52] iter = 08670, loss = 2.3828
2024-10-30 21:05:55: [2024-10-30 21:05:55] iter = 08680, loss = 1.6264
2024-10-30 21:05:57: [2024-10-30 21:05:57] iter = 08690, loss = 1.7871
2024-10-30 21:06:01: [2024-10-30 21:06:01] iter = 08700, loss = 2.6291
2024-10-30 21:06:04: [2024-10-30 21:06:04] iter = 08710, loss = 3.8849
2024-10-30 21:06:09: [2024-10-30 21:06:09] iter = 08720, loss = 2.2550
2024-10-30 21:06:13: [2024-10-30 21:06:13] iter = 08730, loss = 4.5149
2024-10-30 21:06:16: [2024-10-30 21:06:16] iter = 08740, loss = 3.0789
2024-10-30 21:06:20: [2024-10-30 21:06:20] iter = 08750, loss = 2.5349
2024-10-30 21:06:23: [2024-10-30 21:06:23] iter = 08760, loss = 2.4723
2024-10-30 21:06:27: [2024-10-30 21:06:27] iter = 08770, loss = 1.8839
2024-10-30 21:06:31: [2024-10-30 21:06:31] iter = 08780, loss = 1.7898
2024-10-30 21:06:35: [2024-10-30 21:06:35] iter = 08790, loss = 2.0549
2024-10-30 21:06:39: [2024-10-30 21:06:39] iter = 08800, loss = 2.4243
2024-10-30 21:06:43: [2024-10-30 21:06:43] iter = 08810, loss = 1.8116
2024-10-30 21:06:47: [2024-10-30 21:06:47] iter = 08820, loss = 1.6774
2024-10-30 21:06:50: [2024-10-30 21:06:50] iter = 08830, loss = 1.7560
2024-10-30 21:06:53: [2024-10-30 21:06:53] iter = 08840, loss = 2.0211
2024-10-30 21:06:57: [2024-10-30 21:06:57] iter = 08850, loss = 2.0237
2024-10-30 21:07:00: [2024-10-30 21:07:00] iter = 08860, loss = 2.0722
2024-10-30 21:07:04: [2024-10-30 21:07:04] iter = 08870, loss = 1.9424
2024-10-30 21:07:08: [2024-10-30 21:07:08] iter = 08880, loss = 2.0178
2024-10-30 21:07:12: [2024-10-30 21:07:12] iter = 08890, loss = 3.7715
2024-10-30 21:07:15: [2024-10-30 21:07:15] iter = 08900, loss = 2.0586
2024-10-30 21:07:19: [2024-10-30 21:07:19] iter = 08910, loss = 2.5038
2024-10-30 21:07:22: [2024-10-30 21:07:22] iter = 08920, loss = 1.9446
2024-10-30 21:07:26: [2024-10-30 21:07:26] iter = 08930, loss = 1.9162
2024-10-30 21:07:30: [2024-10-30 21:07:30] iter = 08940, loss = 2.1460
2024-10-30 21:07:33: [2024-10-30 21:07:33] iter = 08950, loss = 1.9294
2024-10-30 21:07:37: [2024-10-30 21:07:37] iter = 08960, loss = 2.8097
2024-10-30 21:07:42: [2024-10-30 21:07:42] iter = 08970, loss = 2.7605
2024-10-30 21:07:45: [2024-10-30 21:07:45] iter = 08980, loss = 1.9688
2024-10-30 21:07:49: [2024-10-30 21:07:49] iter = 08990, loss = 2.5582
2024-10-30 21:07:52: [2024-10-30 21:07:52] iter = 09000, loss = 1.6373
2024-10-30 21:07:56: [2024-10-30 21:07:56] iter = 09010, loss = 2.6482
2024-10-30 21:08:01: [2024-10-30 21:08:01] iter = 09020, loss = 1.8859
2024-10-30 21:08:04: [2024-10-30 21:08:04] iter = 09030, loss = 2.5082
2024-10-30 21:08:09: [2024-10-30 21:08:09] iter = 09040, loss = 2.0963
2024-10-30 21:08:13: [2024-10-30 21:08:13] iter = 09050, loss = 2.2676
2024-10-30 21:08:18: [2024-10-30 21:08:18] iter = 09060, loss = 1.6545
2024-10-30 21:08:23: [2024-10-30 21:08:23] iter = 09070, loss = 2.1001
2024-10-30 21:08:26: [2024-10-30 21:08:26] iter = 09080, loss = 2.0168
2024-10-30 21:08:31: [2024-10-30 21:08:31] iter = 09090, loss = 3.4912
2024-10-30 21:08:35: [2024-10-30 21:08:35] iter = 09100, loss = 2.1926
2024-10-30 21:08:39: [2024-10-30 21:08:39] iter = 09110, loss = 2.6058
2024-10-30 21:08:42: [2024-10-30 21:08:42] iter = 09120, loss = 1.6874
2024-10-30 21:08:47: [2024-10-30 21:08:47] iter = 09130, loss = 2.1141
2024-10-30 21:08:53: [2024-10-30 21:08:53] iter = 09140, loss = 2.3838
2024-10-30 21:08:57: [2024-10-30 21:08:57] iter = 09150, loss = 1.7193
2024-10-30 21:09:02: [2024-10-30 21:09:02] iter = 09160, loss = 2.4556
2024-10-30 21:09:06: [2024-10-30 21:09:06] iter = 09170, loss = 2.4478
2024-10-30 21:09:10: [2024-10-30 21:09:10] iter = 09180, loss = 2.5159
2024-10-30 21:09:15: [2024-10-30 21:09:15] iter = 09190, loss = 2.0295
2024-10-30 21:09:19: [2024-10-30 21:09:19] iter = 09200, loss = 1.9163
2024-10-30 21:09:24: [2024-10-30 21:09:24] iter = 09210, loss = 1.9823
2024-10-30 21:09:28: [2024-10-30 21:09:28] iter = 09220, loss = 3.3904
2024-10-30 21:09:33: [2024-10-30 21:09:33] iter = 09230, loss = 2.0467
2024-10-30 21:09:37: [2024-10-30 21:09:37] iter = 09240, loss = 3.5825
2024-10-30 21:09:41: [2024-10-30 21:09:41] iter = 09250, loss = 2.7303
2024-10-30 21:09:46: [2024-10-30 21:09:46] iter = 09260, loss = 2.2467
2024-10-30 21:09:50: [2024-10-30 21:09:50] iter = 09270, loss = 1.8906
2024-10-30 21:09:55: [2024-10-30 21:09:55] iter = 09280, loss = 1.6657
2024-10-30 21:09:58: [2024-10-30 21:09:58] iter = 09290, loss = 3.1003
2024-10-30 21:10:03: [2024-10-30 21:10:03] iter = 09300, loss = 1.8971
2024-10-30 21:10:09: [2024-10-30 21:10:09] iter = 09310, loss = 2.0323
2024-10-30 21:10:14: [2024-10-30 21:10:14] iter = 09320, loss = 1.5305
2024-10-30 21:10:18: [2024-10-30 21:10:18] iter = 09330, loss = 3.3618
2024-10-30 21:10:21: [2024-10-30 21:10:21] iter = 09340, loss = 2.3292
2024-10-30 21:10:25: [2024-10-30 21:10:25] iter = 09350, loss = 2.0979
2024-10-30 21:10:28: [2024-10-30 21:10:28] iter = 09360, loss = 1.6633
2024-10-30 21:10:31: [2024-10-30 21:10:31] iter = 09370, loss = 1.8606
2024-10-30 21:10:35: [2024-10-30 21:10:35] iter = 09380, loss = 2.1384
2024-10-30 21:10:39: [2024-10-30 21:10:39] iter = 09390, loss = 2.1597
2024-10-30 21:10:43: [2024-10-30 21:10:43] iter = 09400, loss = 2.1170
2024-10-30 21:10:47: [2024-10-30 21:10:47] iter = 09410, loss = 2.1896
2024-10-30 21:10:51: [2024-10-30 21:10:51] iter = 09420, loss = 2.0146
2024-10-30 21:10:55: [2024-10-30 21:10:55] iter = 09430, loss = 1.8838
2024-10-30 21:11:01: [2024-10-30 21:11:01] iter = 09440, loss = 2.0256
2024-10-30 21:11:05: [2024-10-30 21:11:05] iter = 09450, loss = 1.8046
2024-10-30 21:11:09: [2024-10-30 21:11:09] iter = 09460, loss = 2.2312
2024-10-30 21:11:11: [2024-10-30 21:11:11] iter = 09470, loss = 3.0662
2024-10-30 21:11:14: [2024-10-30 21:11:14] iter = 09480, loss = 2.6618
2024-10-30 21:11:17: [2024-10-30 21:11:17] iter = 09490, loss = 3.5101
2024-10-30 21:11:21: [2024-10-30 21:11:21] iter = 09500, loss = 2.0024
2024-10-30 21:11:23: [2024-10-30 21:11:23] iter = 09510, loss = 2.0109
2024-10-30 21:11:27: [2024-10-30 21:11:27] iter = 09520, loss = 1.7901
2024-10-30 21:11:30: [2024-10-30 21:11:30] iter = 09530, loss = 1.8170
2024-10-30 21:11:33: [2024-10-30 21:11:33] iter = 09540, loss = 2.9036
2024-10-30 21:11:37: [2024-10-30 21:11:37] iter = 09550, loss = 2.6156
2024-10-30 21:11:39: [2024-10-30 21:11:39] iter = 09560, loss = 4.3139
2024-10-30 21:11:42: [2024-10-30 21:11:42] iter = 09570, loss = 2.0222
2024-10-30 21:11:45: [2024-10-30 21:11:45] iter = 09580, loss = 1.7955
2024-10-30 21:11:48: [2024-10-30 21:11:48] iter = 09590, loss = 2.4217
2024-10-30 21:11:51: [2024-10-30 21:11:51] iter = 09600, loss = 2.3180
2024-10-30 21:11:55: [2024-10-30 21:11:55] iter = 09610, loss = 3.2234
2024-10-30 21:11:59: [2024-10-30 21:11:59] iter = 09620, loss = 3.4692
2024-10-30 21:12:03: [2024-10-30 21:12:03] iter = 09630, loss = 2.1044
2024-10-30 21:12:06: [2024-10-30 21:12:06] iter = 09640, loss = 1.5461
2024-10-30 21:12:09: [2024-10-30 21:12:09] iter = 09650, loss = 2.3509
2024-10-30 21:12:13: [2024-10-30 21:12:13] iter = 09660, loss = 1.9208
2024-10-30 21:12:17: [2024-10-30 21:12:17] iter = 09670, loss = 2.1921
2024-10-30 21:12:20: [2024-10-30 21:12:20] iter = 09680, loss = 2.3282
2024-10-30 21:12:24: [2024-10-30 21:12:24] iter = 09690, loss = 2.6220
2024-10-30 21:12:29: [2024-10-30 21:12:29] iter = 09700, loss = 1.9062
2024-10-30 21:12:32: [2024-10-30 21:12:32] iter = 09710, loss = 2.6987
2024-10-30 21:12:36: [2024-10-30 21:12:36] iter = 09720, loss = 2.2059
2024-10-30 21:12:40: [2024-10-30 21:12:40] iter = 09730, loss = 1.5609
2024-10-30 21:12:43: [2024-10-30 21:12:43] iter = 09740, loss = 3.1588
2024-10-30 21:12:47: [2024-10-30 21:12:47] iter = 09750, loss = 4.9437
2024-10-30 21:12:52: [2024-10-30 21:12:52] iter = 09760, loss = 2.3357
2024-10-30 21:12:56: [2024-10-30 21:12:56] iter = 09770, loss = 2.6167
2024-10-30 21:13:00: [2024-10-30 21:13:00] iter = 09780, loss = 2.0027
2024-10-30 21:13:04: [2024-10-30 21:13:04] iter = 09790, loss = 2.1917
2024-10-30 21:13:09: [2024-10-30 21:13:09] iter = 09800, loss = 2.1159
2024-10-30 21:13:12: [2024-10-30 21:13:12] iter = 09810, loss = 1.8006
2024-10-30 21:13:16: [2024-10-30 21:13:16] iter = 09820, loss = 4.4303
2024-10-30 21:13:20: [2024-10-30 21:13:20] iter = 09830, loss = 1.7114
2024-10-30 21:13:24: [2024-10-30 21:13:24] iter = 09840, loss = 3.0179
2024-10-30 21:13:29: [2024-10-30 21:13:29] iter = 09850, loss = 2.0553
2024-10-30 21:13:32: [2024-10-30 21:13:32] iter = 09860, loss = 1.9102
2024-10-30 21:13:36: [2024-10-30 21:13:36] iter = 09870, loss = 2.2377
2024-10-30 21:13:39: [2024-10-30 21:13:39] iter = 09880, loss = 1.7539
2024-10-30 21:13:43: [2024-10-30 21:13:43] iter = 09890, loss = 2.0635
2024-10-30 21:13:47: [2024-10-30 21:13:47] iter = 09900, loss = 2.1192
2024-10-30 21:13:51: [2024-10-30 21:13:51] iter = 09910, loss = 2.8349
2024-10-30 21:13:54: [2024-10-30 21:13:54] iter = 09920, loss = 2.7268
2024-10-30 21:13:57: [2024-10-30 21:13:57] iter = 09930, loss = 1.7872
2024-10-30 21:14:01: [2024-10-30 21:14:01] iter = 09940, loss = 3.0217
2024-10-30 21:14:05: [2024-10-30 21:14:05] iter = 09950, loss = 1.8799
2024-10-30 21:14:09: [2024-10-30 21:14:09] iter = 09960, loss = 2.5940
2024-10-30 21:14:12: [2024-10-30 21:14:12] iter = 09970, loss = 3.5687
2024-10-30 21:14:16: [2024-10-30 21:14:16] iter = 09980, loss = 2.2375
2024-10-30 21:14:20: [2024-10-30 21:14:20] iter = 09990, loss = 3.0869
2024-10-30 21:14:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 21:14:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:14:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62805}

[2024-10-30 19:12:58] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.014148 train acc = 1.0000, test acc = 0.7796, test_sen =0.7693, test_spe =0.9777, test_f1 =0.7635
[2024-10-30 19:13:25] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.005075 train acc = 1.0000, test acc = 0.7780, test_sen =0.7685, test_spe =0.9775, test_f1 =0.7623
[2024-10-30 19:13:54] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.002242 train acc = 1.0000, test acc = 0.7829, test_sen =0.7724, test_spe =0.9780, test_f1 =0.7673
[2024-10-30 19:14:23] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.001693 train acc = 1.0000, test acc = 0.7807, test_sen =0.7711, test_spe =0.9777, test_f1 =0.7670
[2024-10-30 19:26:57] Evaluate_00: epoch = 1000 train time = 31 s train loss = 0.012984 train acc = 1.0000, test acc = 0.7882, test_sen =0.7804, test_spe =0.9786, test_f1 =0.7740
[2024-10-30 19:27:27] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.002654 train acc = 1.0000, test acc = 0.7882, test_sen =0.7829, test_spe =0.9785, test_f1 =0.7760
[2024-10-30 19:27:55] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.004400 train acc = 1.0000, test acc = 0.7933, test_sen =0.7849, test_spe =0.9790, test_f1 =0.7798
[2024-10-30 19:28:21] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.005839 train acc = 1.0000, test acc = 0.7893, test_sen =0.7829, test_spe =0.9787, test_f1 =0.7747
[2024-10-30 19:28:48] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.005108 train acc = 1.0000, test acc = 0.7894, test_sen =0.7842, test_spe =0.9787, test_f1 =0.7760
[2024-10-30 19:40:58] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.012647 train acc = 1.0000, test acc = 0.7802, test_sen =0.7721, test_spe =0.9778, test_f1 =0.7639
[2024-10-30 19:41:28] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.002490 train acc = 1.0000, test acc = 0.7919, test_sen =0.7828, test_spe =0.9789, test_f1 =0.7781
[2024-10-30 19:41:58] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.046517 train acc = 0.9909, test acc = 0.7907, test_sen =0.7818, test_spe =0.9788, test_f1 =0.7744
[2024-10-30 19:42:24] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.013467 train acc = 1.0000, test acc = 0.7870, test_sen =0.7799, test_spe =0.9785, test_f1 =0.7715
[2024-10-30 19:42:52] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.004615 train acc = 1.0000, test acc = 0.7891, test_sen =0.7803, test_spe =0.9787, test_f1 =0.7728
[2024-10-30 19:55:59] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.022462 train acc = 1.0000, test acc = 0.7880, test_sen =0.7800, test_spe =0.9784, test_f1 =0.7760
[2024-10-30 19:56:28] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.022350 train acc = 1.0000, test acc = 0.7833, test_sen =0.7748, test_spe =0.9781, test_f1 =0.7690
[2024-10-30 19:56:55] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.003617 train acc = 1.0000, test acc = 0.7838, test_sen =0.7754, test_spe =0.9782, test_f1 =0.7704
[2024-10-30 19:57:23] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.003889 train acc = 1.0000, test acc = 0.7875, test_sen =0.7802, test_spe =0.9786, test_f1 =0.7712
[2024-10-30 19:57:53] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.003202 train acc = 1.0000, test acc = 0.7855, test_sen =0.7796, test_spe =0.9784, test_f1 =0.7718
[2024-10-30 19:58:21] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.007286 train acc = 1.0000, test acc = 0.6899, test_sen =0.6906, test_spe =0.9690, test_f1 =0.6748
[2024-10-30 19:58:47] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.001644 train acc = 1.0000, test acc = 0.7047, test_sen =0.7064, test_spe =0.9705, test_f1 =0.6914
[2024-10-30 19:59:11] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.034968 train acc = 1.0000, test acc = 0.6905, test_sen =0.6978, test_spe =0.9691, test_f1 =0.6797
[2024-10-30 19:59:37] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.052373 train acc = 0.9909, test acc = 0.6977, test_sen =0.7017, test_spe =0.9698, test_f1 =0.6861
[2024-10-30 20:00:01] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.042883 train acc = 1.0000, test acc = 0.6859, test_sen =0.6924, test_spe =0.9686, test_f1 =0.6755
[2024-10-30 20:12:11] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.010469 train acc = 1.0000, test acc = 0.7741, test_sen =0.7732, test_spe =0.9772, test_f1 =0.7630
[2024-10-30 20:12:38] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.022656 train acc = 1.0000, test acc = 0.7723, test_sen =0.7685, test_spe =0.9770, test_f1 =0.7586
[2024-10-30 20:13:04] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.003640 train acc = 1.0000, test acc = 0.7824, test_sen =0.7778, test_spe =0.9781, test_f1 =0.7686
[2024-10-30 20:13:35] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.009966 train acc = 1.0000, test acc = 0.7743, test_sen =0.7723, test_spe =0.9773, test_f1 =0.7622
[2024-10-30 20:14:05] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.029980 train acc = 1.0000, test acc = 0.7880, test_sen =0.7827, test_spe =0.9786, test_f1 =0.7744
[2024-10-30 20:27:05] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.004054 train acc = 1.0000, test acc = 0.7715, test_sen =0.7671, test_spe =0.9769, test_f1 =0.7596
[2024-10-30 20:27:34] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.010832 train acc = 1.0000, test acc = 0.7801, test_sen =0.7745, test_spe =0.9776, test_f1 =0.7692
[2024-10-30 20:28:07] Evaluate_02: epoch = 1000 train time = 31 s train loss = 0.008745 train acc = 1.0000, test acc = 0.7676, test_sen =0.7611, test_spe =0.9764, test_f1 =0.7546
[2024-10-30 20:28:33] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.017741 train acc = 1.0000, test acc = 0.7647, test_sen =0.7595, test_spe =0.9761, test_f1 =0.7542
[2024-10-30 20:29:06] Evaluate_04: epoch = 1000 train time = 31 s train loss = 0.006566 train acc = 1.0000, test acc = 0.7676, test_sen =0.7573, test_spe =0.9764, test_f1 =0.7543
[2024-10-30 20:42:26] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.016639 train acc = 1.0000, test acc = 0.7876, test_sen =0.7806, test_spe =0.9786, test_f1 =0.7730
[2024-10-30 20:42:59] Evaluate_01: epoch = 1000 train time = 31 s train loss = 0.005109 train acc = 1.0000, test acc = 0.7844, test_sen =0.7758, test_spe =0.9782, test_f1 =0.7707
[2024-10-30 20:43:29] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.005156 train acc = 1.0000, test acc = 0.7816, test_sen =0.7762, test_spe =0.9780, test_f1 =0.7689
[2024-10-30 20:44:02] Evaluate_03: epoch = 1000 train time = 32 s train loss = 0.004651 train acc = 1.0000, test acc = 0.7781, test_sen =0.7721, test_spe =0.9776, test_f1 =0.7653
[2024-10-30 20:44:35] Evaluate_04: epoch = 1000 train time = 31 s train loss = 0.010467 train acc = 1.0000, test acc = 0.7868, test_sen =0.7822, test_spe =0.9785, test_f1 =0.7730
[2024-10-30 20:58:40] Evaluate_00: epoch = 1000 train time = 34 s train loss = 0.012367 train acc = 1.0000, test acc = 0.7790, test_sen =0.7776, test_spe =0.9777, test_f1 =0.7684
[2024-10-30 20:59:14] Evaluate_01: epoch = 1000 train time = 33 s train loss = 0.004177 train acc = 1.0000, test acc = 0.7851, test_sen =0.7805, test_spe =0.9783, test_f1 =0.7730
[2024-10-30 20:59:52] Evaluate_02: epoch = 1000 train time = 36 s train loss = 0.015620 train acc = 1.0000, test acc = 0.7791, test_sen =0.7751, test_spe =0.9777, test_f1 =0.7685
[2024-10-30 21:00:30] Evaluate_03: epoch = 1000 train time = 37 s train loss = 0.003208 train acc = 1.0000, test acc = 0.7858, test_sen =0.7809, test_spe =0.9783, test_f1 =0.7747
[2024-10-30 21:01:09] Evaluate_04: epoch = 1000 train time = 37 s train loss = 0.004447 train acc = 1.0000, test acc = 0.7824, test_sen =0.7784, test_spe =0.9780, test_f1 =0.7716
[2024-10-30 21:14:50] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.003731 train acc = 1.0000, test acc = 0.7829, test_sen =0.7783, test_spe =0.9781, test_f1 =0.7702
[2024-10-30 21:15:18] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.003154 train acc = 1.0000, test acc = 0.7871, test_sen =0.7811, test_spe =0.9785, test_f1 =0.7749/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:16:40: Evaluate 5 random ConvNet, ACCmean = 0.7860 ACCstd = 0.0025
-------------------------
2024-10-30 21:16:40: Evaluate 5 random ConvNet, SENmean = 0.7802 SENstd = 0.0014
-------------------------
2024-10-30 21:16:40: Evaluate 5 random ConvNet, SPEmean = 0.9784 SPEstd = 0.0003
-------------------------
2024-10-30 21:16:40: Evaluate 5 random ConvNet, F!mean = 0.7730 F!std = 0.0020
-------------------------
2024-10-30 21:16:40: Evaluate 5 random ConvNet, mean = 0.7860 std = 0.0025
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:16:41: [2024-10-30 21:16:41] iter = 10000, loss = 2.0455
2024-10-30 21:16:44: [2024-10-30 21:16:44] iter = 10010, loss = 1.7338
2024-10-30 21:16:48: [2024-10-30 21:16:48] iter = 10020, loss = 1.7853
2024-10-30 21:16:52: [2024-10-30 21:16:52] iter = 10030, loss = 1.5372
2024-10-30 21:16:55: [2024-10-30 21:16:55] iter = 10040, loss = 2.9362
2024-10-30 21:16:59: [2024-10-30 21:16:59] iter = 10050, loss = 1.7889
2024-10-30 21:17:03: [2024-10-30 21:17:03] iter = 10060, loss = 2.3605
2024-10-30 21:17:07: [2024-10-30 21:17:07] iter = 10070, loss = 1.8154
2024-10-30 21:17:12: [2024-10-30 21:17:11] iter = 10080, loss = 2.2527
2024-10-30 21:17:15: [2024-10-30 21:17:15] iter = 10090, loss = 1.8384
2024-10-30 21:17:19: [2024-10-30 21:17:19] iter = 10100, loss = 1.9804
2024-10-30 21:17:23: [2024-10-30 21:17:23] iter = 10110, loss = 2.4375
2024-10-30 21:17:26: [2024-10-30 21:17:26] iter = 10120, loss = 2.2997
2024-10-30 21:17:30: [2024-10-30 21:17:30] iter = 10130, loss = 1.9589
2024-10-30 21:17:34: [2024-10-30 21:17:34] iter = 10140, loss = 2.7259
2024-10-30 21:17:37: [2024-10-30 21:17:37] iter = 10150, loss = 4.0946
2024-10-30 21:17:40: [2024-10-30 21:17:40] iter = 10160, loss = 1.9794
2024-10-30 21:17:44: [2024-10-30 21:17:44] iter = 10170, loss = 1.9521
2024-10-30 21:17:48: [2024-10-30 21:17:48] iter = 10180, loss = 3.9777
2024-10-30 21:17:51: [2024-10-30 21:17:51] iter = 10190, loss = 3.3801
2024-10-30 21:17:55: [2024-10-30 21:17:55] iter = 10200, loss = 1.9884
2024-10-30 21:17:58: [2024-10-30 21:17:58] iter = 10210, loss = 1.9761
2024-10-30 21:18:01: [2024-10-30 21:18:01] iter = 10220, loss = 1.8694
2024-10-30 21:18:04: [2024-10-30 21:18:04] iter = 10230, loss = 1.9094
2024-10-30 21:18:09: [2024-10-30 21:18:09] iter = 10240, loss = 1.7564
2024-10-30 21:18:11: [2024-10-30 21:18:11] iter = 10250, loss = 1.9337
2024-10-30 21:18:15: [2024-10-30 21:18:15] iter = 10260, loss = 2.3469
2024-10-30 21:18:19: [2024-10-30 21:18:19] iter = 10270, loss = 2.1226
2024-10-30 21:18:22: [2024-10-30 21:18:22] iter = 10280, loss = 2.3971
2024-10-30 21:18:26: [2024-10-30 21:18:26] iter = 10290, loss = 1.8921
2024-10-30 21:18:30: [2024-10-30 21:18:30] iter = 10300, loss = 1.5113
2024-10-30 21:18:34: [2024-10-30 21:18:34] iter = 10310, loss = 2.0990
2024-10-30 21:18:37: [2024-10-30 21:18:37] iter = 10320, loss = 3.9561
2024-10-30 21:18:40: [2024-10-30 21:18:40] iter = 10330, loss = 1.7784
2024-10-30 21:18:44: [2024-10-30 21:18:44] iter = 10340, loss = 2.1168
2024-10-30 21:18:48: [2024-10-30 21:18:48] iter = 10350, loss = 1.6467
2024-10-30 21:18:52: [2024-10-30 21:18:52] iter = 10360, loss = 2.2753
2024-10-30 21:18:55: [2024-10-30 21:18:55] iter = 10370, loss = 2.1609
2024-10-30 21:18:59: [2024-10-30 21:18:59] iter = 10380, loss = 1.9737
2024-10-30 21:19:01: [2024-10-30 21:19:01] iter = 10390, loss = 2.1649
2024-10-30 21:19:06: [2024-10-30 21:19:06] iter = 10400, loss = 1.7201
2024-10-30 21:19:10: [2024-10-30 21:19:10] iter = 10410, loss = 2.1029
2024-10-30 21:19:13: [2024-10-30 21:19:13] iter = 10420, loss = 1.6739
2024-10-30 21:19:17: [2024-10-30 21:19:17] iter = 10430, loss = 2.3757
2024-10-30 21:19:21: [2024-10-30 21:19:21] iter = 10440, loss = 1.6706
2024-10-30 21:19:24: [2024-10-30 21:19:24] iter = 10450, loss = 1.7905
2024-10-30 21:19:28: [2024-10-30 21:19:28] iter = 10460, loss = 2.7156
2024-10-30 21:19:31: [2024-10-30 21:19:31] iter = 10470, loss = 3.8347
2024-10-30 21:19:35: [2024-10-30 21:19:35] iter = 10480, loss = 2.0100
2024-10-30 21:19:38: [2024-10-30 21:19:38] iter = 10490, loss = 2.0066
2024-10-30 21:19:42: [2024-10-30 21:19:42] iter = 10500, loss = 1.7948
2024-10-30 21:19:46: [2024-10-30 21:19:46] iter = 10510, loss = 2.3389
2024-10-30 21:19:50: [2024-10-30 21:19:50] iter = 10520, loss = 1.5117
2024-10-30 21:19:54: [2024-10-30 21:19:54] iter = 10530, loss = 2.9204
2024-10-30 21:19:57: [2024-10-30 21:19:57] iter = 10540, loss = 2.6434
2024-10-30 21:20:01: [2024-10-30 21:20:01] iter = 10550, loss = 2.3731
2024-10-30 21:20:04: [2024-10-30 21:20:04] iter = 10560, loss = 2.9614
2024-10-30 21:20:07: [2024-10-30 21:20:07] iter = 10570, loss = 2.1571
2024-10-30 21:20:10: [2024-10-30 21:20:10] iter = 10580, loss = 2.1573
2024-10-30 21:20:14: [2024-10-30 21:20:14] iter = 10590, loss = 4.8434
2024-10-30 21:20:17: [2024-10-30 21:20:17] iter = 10600, loss = 2.6497
2024-10-30 21:20:20: [2024-10-30 21:20:20] iter = 10610, loss = 1.6086
2024-10-30 21:20:24: [2024-10-30 21:20:24] iter = 10620, loss = 1.9553
2024-10-30 21:20:27: [2024-10-30 21:20:27] iter = 10630, loss = 3.9320
2024-10-30 21:20:32: [2024-10-30 21:20:32] iter = 10640, loss = 1.9653
2024-10-30 21:20:36: [2024-10-30 21:20:36] iter = 10650, loss = 2.0947
2024-10-30 21:20:39: [2024-10-30 21:20:39] iter = 10660, loss = 2.3641
2024-10-30 21:20:43: [2024-10-30 21:20:43] iter = 10670, loss = 1.7251
2024-10-30 21:20:47: [2024-10-30 21:20:47] iter = 10680, loss = 1.8803
2024-10-30 21:20:51: [2024-10-30 21:20:51] iter = 10690, loss = 1.7234
2024-10-30 21:20:56: [2024-10-30 21:20:56] iter = 10700, loss = 2.5626
2024-10-30 21:21:00: [2024-10-30 21:21:00] iter = 10710, loss = 2.0344
2024-10-30 21:21:03: [2024-10-30 21:21:03] iter = 10720, loss = 1.8128
2024-10-30 21:21:06: [2024-10-30 21:21:06] iter = 10730, loss = 1.7957
2024-10-30 21:21:09: [2024-10-30 21:21:09] iter = 10740, loss = 1.7486
2024-10-30 21:21:12: [2024-10-30 21:21:12] iter = 10750, loss = 2.0844
2024-10-30 21:21:16: [2024-10-30 21:21:16] iter = 10760, loss = 2.1973
2024-10-30 21:21:20: [2024-10-30 21:21:20] iter = 10770, loss = 1.7489
2024-10-30 21:21:24: [2024-10-30 21:21:24] iter = 10780, loss = 2.0149
2024-10-30 21:21:28: [2024-10-30 21:21:28] iter = 10790, loss = 1.7003
2024-10-30 21:21:31: [2024-10-30 21:21:31] iter = 10800, loss = 1.8411
2024-10-30 21:21:34: [2024-10-30 21:21:34] iter = 10810, loss = 2.1052
2024-10-30 21:21:38: [2024-10-30 21:21:38] iter = 10820, loss = 1.8942
2024-10-30 21:21:42: [2024-10-30 21:21:42] iter = 10830, loss = 2.7592
2024-10-30 21:21:46: [2024-10-30 21:21:46] iter = 10840, loss = 2.8180
2024-10-30 21:21:50: [2024-10-30 21:21:50] iter = 10850, loss = 2.5795
2024-10-30 21:21:54: [2024-10-30 21:21:54] iter = 10860, loss = 2.4494
2024-10-30 21:21:59: [2024-10-30 21:21:59] iter = 10870, loss = 2.3084
2024-10-30 21:22:02: [2024-10-30 21:22:02] iter = 10880, loss = 2.2015
2024-10-30 21:22:06: [2024-10-30 21:22:06] iter = 10890, loss = 2.0822
2024-10-30 21:22:08: [2024-10-30 21:22:08] iter = 10900, loss = 1.9154
2024-10-30 21:22:11: [2024-10-30 21:22:11] iter = 10910, loss = 2.5203
2024-10-30 21:22:14: [2024-10-30 21:22:14] iter = 10920, loss = 1.9331
2024-10-30 21:22:17: [2024-10-30 21:22:17] iter = 10930, loss = 5.1827
2024-10-30 21:22:20: [2024-10-30 21:22:20] iter = 10940, loss = 2.0887
2024-10-30 21:22:23: [2024-10-30 21:22:23] iter = 10950, loss = 2.0370
2024-10-30 21:22:26: [2024-10-30 21:22:26] iter = 10960, loss = 1.8085
2024-10-30 21:22:28: [2024-10-30 21:22:28] iter = 10970, loss = 4.7953
2024-10-30 21:22:31: [2024-10-30 21:22:31] iter = 10980, loss = 1.8495
2024-10-30 21:22:36: [2024-10-30 21:22:36] iter = 10990, loss = 1.9164
2024-10-30 21:22:40: [2024-10-30 21:22:40] iter = 11000, loss = 1.8819
2024-10-30 21:22:44: [2024-10-30 21:22:44] iter = 11010, loss = 2.3622
2024-10-30 21:22:48: [2024-10-30 21:22:48] iter = 11020, loss = 1.9832
2024-10-30 21:22:53: [2024-10-30 21:22:53] iter = 11030, loss = 2.7318
2024-10-30 21:22:57: [2024-10-30 21:22:57] iter = 11040, loss = 2.8601
2024-10-30 21:23:00: [2024-10-30 21:23:00] iter = 11050, loss = 1.7439
2024-10-30 21:23:03: [2024-10-30 21:23:03] iter = 11060, loss = 1.7974
2024-10-30 21:23:08: [2024-10-30 21:23:08] iter = 11070, loss = 1.8825
2024-10-30 21:23:12: [2024-10-30 21:23:12] iter = 11080, loss = 1.9507
2024-10-30 21:23:16: [2024-10-30 21:23:16] iter = 11090, loss = 1.8995
2024-10-30 21:23:19: [2024-10-30 21:23:19] iter = 11100, loss = 2.4555
2024-10-30 21:23:23: [2024-10-30 21:23:23] iter = 11110, loss = 2.2583
2024-10-30 21:23:26: [2024-10-30 21:23:26] iter = 11120, loss = 3.0267
2024-10-30 21:23:31: [2024-10-30 21:23:31] iter = 11130, loss = 2.8208
2024-10-30 21:23:34: [2024-10-30 21:23:34] iter = 11140, loss = 1.8366
2024-10-30 21:23:39: [2024-10-30 21:23:39] iter = 11150, loss = 2.1043
2024-10-30 21:23:43: [2024-10-30 21:23:43] iter = 11160, loss = 2.2236
2024-10-30 21:23:48: [2024-10-30 21:23:48] iter = 11170, loss = 3.4843
2024-10-30 21:23:52: [2024-10-30 21:23:52] iter = 11180, loss = 1.6706
2024-10-30 21:23:56: [2024-10-30 21:23:56] iter = 11190, loss = 2.3113
2024-10-30 21:24:00: [2024-10-30 21:24:00] iter = 11200, loss = 1.8453
2024-10-30 21:24:04: [2024-10-30 21:24:04] iter = 11210, loss = 2.4799
2024-10-30 21:24:08: [2024-10-30 21:24:08] iter = 11220, loss = 2.6269
2024-10-30 21:24:12: [2024-10-30 21:24:12] iter = 11230, loss = 3.1525
2024-10-30 21:24:15: [2024-10-30 21:24:15] iter = 11240, loss = 2.0075
2024-10-30 21:24:18: [2024-10-30 21:24:18] iter = 11250, loss = 2.1926
2024-10-30 21:24:21: [2024-10-30 21:24:21] iter = 11260, loss = 1.8922
2024-10-30 21:24:25: [2024-10-30 21:24:25] iter = 11270, loss = 2.4984
2024-10-30 21:24:31: [2024-10-30 21:24:31] iter = 11280, loss = 2.1052
2024-10-30 21:24:36: [2024-10-30 21:24:36] iter = 11290, loss = 1.8488
2024-10-30 21:24:40: [2024-10-30 21:24:40] iter = 11300, loss = 2.3748
2024-10-30 21:24:44: [2024-10-30 21:24:44] iter = 11310, loss = 3.0909
2024-10-30 21:24:49: [2024-10-30 21:24:49] iter = 11320, loss = 1.8810
2024-10-30 21:24:53: [2024-10-30 21:24:53] iter = 11330, loss = 2.5978
2024-10-30 21:24:58: [2024-10-30 21:24:58] iter = 11340, loss = 2.1110
2024-10-30 21:25:03: [2024-10-30 21:25:03] iter = 11350, loss = 1.9563
2024-10-30 21:25:07: [2024-10-30 21:25:07] iter = 11360, loss = 1.6307
2024-10-30 21:25:11: [2024-10-30 21:25:11] iter = 11370, loss = 2.0478
2024-10-30 21:25:15: [2024-10-30 21:25:15] iter = 11380, loss = 2.0799
2024-10-30 21:25:19: [2024-10-30 21:25:19] iter = 11390, loss = 2.2759
2024-10-30 21:25:24: [2024-10-30 21:25:24] iter = 11400, loss = 2.1246
2024-10-30 21:25:28: [2024-10-30 21:25:28] iter = 11410, loss = 2.1726
2024-10-30 21:25:33: [2024-10-30 21:25:33] iter = 11420, loss = 2.0442
2024-10-30 21:25:37: [2024-10-30 21:25:37] iter = 11430, loss = 2.0244
2024-10-30 21:25:42: [2024-10-30 21:25:42] iter = 11440, loss = 2.0286
2024-10-30 21:25:44: [2024-10-30 21:25:44] iter = 11450, loss = 2.3312
2024-10-30 21:25:49: [2024-10-30 21:25:49] iter = 11460, loss = 1.8544
2024-10-30 21:25:53: [2024-10-30 21:25:53] iter = 11470, loss = 1.6967
2024-10-30 21:25:57: [2024-10-30 21:25:57] iter = 11480, loss = 2.5269
2024-10-30 21:26:01: [2024-10-30 21:26:01] iter = 11490, loss = 1.9496
2024-10-30 21:26:04: [2024-10-30 21:26:04] iter = 11500, loss = 4.0974
2024-10-30 21:26:08: [2024-10-30 21:26:08] iter = 11510, loss = 1.8631
2024-10-30 21:26:11: [2024-10-30 21:26:11] iter = 11520, loss = 1.7783
2024-10-30 21:26:15: [2024-10-30 21:26:15] iter = 11530, loss = 1.9884
2024-10-30 21:26:18: [2024-10-30 21:26:18] iter = 11540, loss = 1.8561
2024-10-30 21:26:23: [2024-10-30 21:26:23] iter = 11550, loss = 1.9953
2024-10-30 21:26:26: [2024-10-30 21:26:26] iter = 11560, loss = 2.2479
2024-10-30 21:26:27: [2024-10-30 21:26:27] iter = 11570, loss = 2.7988
2024-10-30 21:26:31: [2024-10-30 21:26:31] iter = 11580, loss = 1.8178
2024-10-30 21:26:34: [2024-10-30 21:26:34] iter = 11590, loss = 3.0865
2024-10-30 21:26:38: [2024-10-30 21:26:38] iter = 11600, loss = 1.8304
2024-10-30 21:26:42: [2024-10-30 21:26:42] iter = 11610, loss = 2.0773
2024-10-30 21:26:45: [2024-10-30 21:26:45] iter = 11620, loss = 1.9556
2024-10-30 21:26:49: [2024-10-30 21:26:49] iter = 11630, loss = 2.3690
2024-10-30 21:26:53: [2024-10-30 21:26:53] iter = 11640, loss = 4.1993
2024-10-30 21:26:58: [2024-10-30 21:26:58] iter = 11650, loss = 2.4498
2024-10-30 21:27:02: [2024-10-30 21:27:02] iter = 11660, loss = 2.2866
2024-10-30 21:27:06: [2024-10-30 21:27:06] iter = 11670, loss = 2.0056
2024-10-30 21:27:10: [2024-10-30 21:27:10] iter = 11680, loss = 2.0486
2024-10-30 21:27:14: [2024-10-30 21:27:14] iter = 11690, loss = 1.7538
2024-10-30 21:27:18: [2024-10-30 21:27:18] iter = 11700, loss = 1.6662
2024-10-30 21:27:23: [2024-10-30 21:27:23] iter = 11710, loss = 1.7817
2024-10-30 21:27:28: [2024-10-30 21:27:28] iter = 11720, loss = 1.9987
2024-10-30 21:27:32: [2024-10-30 21:27:32] iter = 11730, loss = 1.9870
2024-10-30 21:27:35: [2024-10-30 21:27:35] iter = 11740, loss = 1.7403
2024-10-30 21:27:39: [2024-10-30 21:27:39] iter = 11750, loss = 3.0247
2024-10-30 21:27:43: [2024-10-30 21:27:43] iter = 11760, loss = 1.7640
2024-10-30 21:27:46: [2024-10-30 21:27:46] iter = 11770, loss = 1.9924
2024-10-30 21:27:51: [2024-10-30 21:27:51] iter = 11780, loss = 3.4812
2024-10-30 21:27:56: [2024-10-30 21:27:56] iter = 11790, loss = 1.9082
2024-10-30 21:28:00: [2024-10-30 21:28:00] iter = 11800, loss = 1.6411
2024-10-30 21:28:03: [2024-10-30 21:28:03] iter = 11810, loss = 1.7865
2024-10-30 21:28:08: [2024-10-30 21:28:08] iter = 11820, loss = 1.9093
2024-10-30 21:28:11: [2024-10-30 21:28:11] iter = 11830, loss = 3.7827
2024-10-30 21:28:16: [2024-10-30 21:28:16] iter = 11840, loss = 3.1929
2024-10-30 21:28:21: [2024-10-30 21:28:21] iter = 11850, loss = 3.7398
2024-10-30 21:28:25: [2024-10-30 21:28:25] iter = 11860, loss = 2.4123
2024-10-30 21:28:29: [2024-10-30 21:28:29] iter = 11870, loss = 1.6657
2024-10-30 21:28:32: [2024-10-30 21:28:32] iter = 11880, loss = 2.8512
2024-10-30 21:28:36: [2024-10-30 21:28:36] iter = 11890, loss = 1.9867
2024-10-30 21:28:41: [2024-10-30 21:28:41] iter = 11900, loss = 1.7960
2024-10-30 21:28:44: [2024-10-30 21:28:44] iter = 11910, loss = 2.0156
2024-10-30 21:28:48: [2024-10-30 21:28:48] iter = 11920, loss = 2.2687
2024-10-30 21:28:52: [2024-10-30 21:28:52] iter = 11930, loss = 1.7602
2024-10-30 21:28:56: [2024-10-30 21:28:56] iter = 11940, loss = 1.9432
2024-10-30 21:29:00: [2024-10-30 21:29:00] iter = 11950, loss = 2.5523
2024-10-30 21:29:04: [2024-10-30 21:29:04] iter = 11960, loss = 2.5064
2024-10-30 21:29:09: [2024-10-30 21:29:09] iter = 11970, loss = 1.7625
2024-10-30 21:29:13: [2024-10-30 21:29:13] iter = 11980, loss = 1.9698
2024-10-30 21:29:16: [2024-10-30 21:29:16] iter = 11990, loss = 1.7460
2024-10-30 21:29:19: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 21:29:19: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:29:19: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59947}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:31:51: Evaluate 5 random ConvNet, ACCmean = 0.7809 ACCstd = 0.0050
-------------------------
2024-10-30 21:31:51: Evaluate 5 random ConvNet, SENmean = 0.7722 SENstd = 0.0053
-------------------------
2024-10-30 21:31:51: Evaluate 5 random ConvNet, SPEmean = 0.9778 SPEstd = 0.0005
-------------------------
2024-10-30 21:31:51: Evaluate 5 random ConvNet, F!mean = 0.7679 F!std = 0.0053
-------------------------
2024-10-30 21:31:51: Evaluate 5 random ConvNet, mean = 0.7809 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:31:52: [2024-10-30 21:31:52] iter = 12000, loss = 1.6250
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:31:55: [2024-10-30 21:31:55] iter = 12010, loss = 2.0067
2024-10-30 21:31:59: [2024-10-30 21:31:59] iter = 12020, loss = 2.1709
2024-10-30 21:32:03: [2024-10-30 21:32:03] iter = 12030, loss = 2.7312
2024-10-30 21:32:06: [2024-10-30 21:32:06] iter = 12040, loss = 2.0011
2024-10-30 21:32:10: [2024-10-30 21:32:09] iter = 12050, loss = 1.8940
2024-10-30 21:32:13: [2024-10-30 21:32:13] iter = 12060, loss = 4.1747
2024-10-30 21:32:16: [2024-10-30 21:32:16] iter = 12070, loss = 1.9021
2024-10-30 21:32:20: [2024-10-30 21:32:20] iter = 12080, loss = 2.3790
2024-10-30 21:32:23: [2024-10-30 21:32:23] iter = 12090, loss = 2.0260
2024-10-30 21:32:26: [2024-10-30 21:32:26] iter = 12100, loss = 2.5297
2024-10-30 21:32:29: [2024-10-30 21:32:29] iter = 12110, loss = 3.3822
2024-10-30 21:32:33: [2024-10-30 21:32:33] iter = 12120, loss = 1.8487
2024-10-30 21:32:37: [2024-10-30 21:32:37] iter = 12130, loss = 3.5479
2024-10-30 21:32:40: [2024-10-30 21:32:40] iter = 12140, loss = 2.2124
2024-10-30 21:32:43: [2024-10-30 21:32:43] iter = 12150, loss = 1.9698
2024-10-30 21:32:46: [2024-10-30 21:32:46] iter = 12160, loss = 1.8357
2024-10-30 21:32:49: [2024-10-30 21:32:49] iter = 12170, loss = 2.4675
2024-10-30 21:32:53: [2024-10-30 21:32:53] iter = 12180, loss = 2.2773
2024-10-30 21:32:57: [2024-10-30 21:32:57] iter = 12190, loss = 2.2322
2024-10-30 21:33:01: [2024-10-30 21:33:01] iter = 12200, loss = 2.7908
2024-10-30 21:33:05: [2024-10-30 21:33:05] iter = 12210, loss = 2.5798
2024-10-30 21:33:09: [2024-10-30 21:33:09] iter = 12220, loss = 1.7788
2024-10-30 21:33:12: [2024-10-30 21:33:12] iter = 12230, loss = 1.8477
2024-10-30 21:33:16: [2024-10-30 21:33:16] iter = 12240, loss = 2.9320
2024-10-30 21:33:19: [2024-10-30 21:33:19] iter = 12250, loss = 1.8999
2024-10-30 21:33:23: [2024-10-30 21:33:23] iter = 12260, loss = 2.0857
2024-10-30 21:33:28: [2024-10-30 21:33:28] iter = 12270, loss = 3.6548
2024-10-30 21:33:33: [2024-10-30 21:33:33] iter = 12280, loss = 2.6260
2024-10-30 21:33:36: [2024-10-30 21:33:36] iter = 12290, loss = 2.3070
2024-10-30 21:33:39: [2024-10-30 21:33:39] iter = 12300, loss = 1.8839
2024-10-30 21:33:42: [2024-10-30 21:33:42] iter = 12310, loss = 2.3347
2024-10-30 21:33:44: [2024-10-30 21:33:44] iter = 12320, loss = 1.9878
2024-10-30 21:33:46: [2024-10-30 21:33:46] iter = 12330, loss = 2.9733
2024-10-30 21:33:49: [2024-10-30 21:33:49] iter = 12340, loss = 5.8993
2024-10-30 21:33:53: [2024-10-30 21:33:53] iter = 12350, loss = 1.9286
2024-10-30 21:33:57: [2024-10-30 21:33:57] iter = 12360, loss = 2.2825
2024-10-30 21:34:00: [2024-10-30 21:34:00] iter = 12370, loss = 2.3784
2024-10-30 21:34:03: [2024-10-30 21:34:03] iter = 12380, loss = 2.0208
2024-10-30 21:34:06: [2024-10-30 21:34:06] iter = 12390, loss = 3.1587
2024-10-30 21:34:10: [2024-10-30 21:34:10] iter = 12400, loss = 2.2152
2024-10-30 21:34:13: [2024-10-30 21:34:13] iter = 12410, loss = 2.2140
2024-10-30 21:34:15: [2024-10-30 21:34:15] iter = 12420, loss = 3.0969
2024-10-30 21:34:19: [2024-10-30 21:34:19] iter = 12430, loss = 1.8563
2024-10-30 21:34:22: [2024-10-30 21:34:22] iter = 12440, loss = 2.1733
2024-10-30 21:34:26: [2024-10-30 21:34:26] iter = 12450, loss = 2.3835
2024-10-30 21:34:30: [2024-10-30 21:34:30] iter = 12460, loss = 4.8046
2024-10-30 21:34:34: [2024-10-30 21:34:34] iter = 12470, loss = 1.8273
2024-10-30 21:34:38: [2024-10-30 21:34:38] iter = 12480, loss = 2.0397
2024-10-30 21:34:42: [2024-10-30 21:34:42] iter = 12490, loss = 1.9909
2024-10-30 21:34:45: [2024-10-30 21:34:45] iter = 12500, loss = 2.8050
2024-10-30 21:34:48: [2024-10-30 21:34:48] iter = 12510, loss = 3.8590
2024-10-30 21:34:52: [2024-10-30 21:34:52] iter = 12520, loss = 2.7111
2024-10-30 21:34:55: [2024-10-30 21:34:55] iter = 12530, loss = 2.0439
2024-10-30 21:34:59: [2024-10-30 21:34:59] iter = 12540, loss = 2.4617
2024-10-30 21:35:04: [2024-10-30 21:35:04] iter = 12550, loss = 2.5594
2024-10-30 21:35:09: [2024-10-30 21:35:09] iter = 12560, loss = 1.8800
2024-10-30 21:35:13: [2024-10-30 21:35:13] iter = 12570, loss = 1.8653
2024-10-30 21:35:17: [2024-10-30 21:35:17] iter = 12580, loss = 1.7566
2024-10-30 21:35:21: [2024-10-30 21:35:21] iter = 12590, loss = 1.9452
2024-10-30 21:35:25: [2024-10-30 21:35:25] iter = 12600, loss = 1.9297
2024-10-30 21:35:29: [2024-10-30 21:35:29] iter = 12610, loss = 1.9548
2024-10-30 21:35:33: [2024-10-30 21:35:33] iter = 12620, loss = 2.0635
2024-10-30 21:35:37: [2024-10-30 21:35:37] iter = 12630, loss = 2.0769
2024-10-30 21:35:41: [2024-10-30 21:35:41] iter = 12640, loss = 2.9460
2024-10-30 21:35:46: [2024-10-30 21:35:46] iter = 12650, loss = 2.0199
2024-10-30 21:35:52: [2024-10-30 21:35:52] iter = 12660, loss = 2.1948
2024-10-30 21:35:58: [2024-10-30 21:35:58] iter = 12670, loss = 1.9100
2024-10-30 21:36:03: [2024-10-30 21:36:03] iter = 12680, loss = 2.3334
2024-10-30 21:36:08: [2024-10-30 21:36:08] iter = 12690, loss = 2.7291
2024-10-30 21:36:12: [2024-10-30 21:36:12] iter = 12700, loss = 1.7488
2024-10-30 21:36:18: [2024-10-30 21:36:18] iter = 12710, loss = 2.0670
2024-10-30 21:36:22: [2024-10-30 21:36:22] iter = 12720, loss = 1.9724
2024-10-30 21:36:27: [2024-10-30 21:36:27] iter = 12730, loss = 2.6149
2024-10-30 21:36:31: [2024-10-30 21:36:31] iter = 12740, loss = 3.2663
2024-10-30 21:36:36: [2024-10-30 21:36:36] iter = 12750, loss = 2.6838
2024-10-30 21:36:41: [2024-10-30 21:36:41] iter = 12760, loss = 1.6350
2024-10-30 21:36:44: [2024-10-30 21:36:44] iter = 12770, loss = 2.0167
2024-10-30 21:36:49: [2024-10-30 21:36:49] iter = 12780, loss = 2.8377
2024-10-30 21:36:53: [2024-10-30 21:36:53] iter = 12790, loss = 2.2656
2024-10-30 21:36:57: [2024-10-30 21:36:57] iter = 12800, loss = 1.7237
2024-10-30 21:37:01: [2024-10-30 21:37:01] iter = 12810, loss = 1.7924
2024-10-30 21:37:05: [2024-10-30 21:37:05] iter = 12820, loss = 1.8841
2024-10-30 21:37:09: [2024-10-30 21:37:09] iter = 12830, loss = 1.8486
2024-10-30 21:37:13: [2024-10-30 21:37:13] iter = 12840, loss = 2.8266
2024-10-30 21:37:17: [2024-10-30 21:37:17] iter = 12850, loss = 2.5865
2024-10-30 21:37:20: [2024-10-30 21:37:20] iter = 12860, loss = 2.2821
2024-10-30 21:37:23: [2024-10-30 21:37:23] iter = 12870, loss = 2.5475
2024-10-30 21:37:26: [2024-10-30 21:37:26] iter = 12880, loss = 1.9439
2024-10-30 21:37:28: [2024-10-30 21:37:28] iter = 12890, loss = 1.9927
2024-10-30 21:37:33: [2024-10-30 21:37:33] iter = 12900, loss = 1.7817
2024-10-30 21:37:37: [2024-10-30 21:37:37] iter = 12910, loss = 2.9758
2024-10-30 21:37:42: [2024-10-30 21:37:42] iter = 12920, loss = 2.2053
2024-10-30 21:37:47: [2024-10-30 21:37:47] iter = 12930, loss = 2.0692
2024-10-30 21:37:51: [2024-10-30 21:37:51] iter = 12940, loss = 1.9987
2024-10-30 21:37:56: [2024-10-30 21:37:56] iter = 12950, loss = 2.7347
2024-10-30 21:38:00: [2024-10-30 21:38:00] iter = 12960, loss = 1.7636
2024-10-30 21:38:04: [2024-10-30 21:38:04] iter = 12970, loss = 2.4357
2024-10-30 21:38:08: [2024-10-30 21:38:08] iter = 12980, loss = 1.9537
2024-10-30 21:38:12: [2024-10-30 21:38:12] iter = 12990, loss = 2.3382
2024-10-30 21:38:16: [2024-10-30 21:38:16] iter = 13000, loss = 2.4773
2024-10-30 21:38:19: [2024-10-30 21:38:19] iter = 13010, loss = 1.8977
2024-10-30 21:38:22: [2024-10-30 21:38:22] iter = 13020, loss = 1.6987
2024-10-30 21:38:26: [2024-10-30 21:38:26] iter = 13030, loss = 1.6778
2024-10-30 21:38:30: [2024-10-30 21:38:30] iter = 13040, loss = 2.7451
2024-10-30 21:38:34: [2024-10-30 21:38:34] iter = 13050, loss = 2.1896
2024-10-30 21:38:38: [2024-10-30 21:38:38] iter = 13060, loss = 2.8771
2024-10-30 21:38:43: [2024-10-30 21:38:43] iter = 13070, loss = 1.9565
2024-10-30 21:38:47: [2024-10-30 21:38:47] iter = 13080, loss = 1.7442
2024-10-30 21:38:50: [2024-10-30 21:38:50] iter = 13090, loss = 2.2312
2024-10-30 21:38:54: [2024-10-30 21:38:54] iter = 13100, loss = 3.7581
2024-10-30 21:38:57: [2024-10-30 21:38:57] iter = 13110, loss = 1.7160
2024-10-30 21:39:01: [2024-10-30 21:39:01] iter = 13120, loss = 2.2974
2024-10-30 21:39:04: [2024-10-30 21:39:04] iter = 13130, loss = 1.8642
2024-10-30 21:39:08: [2024-10-30 21:39:08] iter = 13140, loss = 2.0400
2024-10-30 21:39:11: [2024-10-30 21:39:11] iter = 13150, loss = 1.7034
2024-10-30 21:39:15: [2024-10-30 21:39:15] iter = 13160, loss = 2.2560
2024-10-30 21:39:19: [2024-10-30 21:39:19] iter = 13170, loss = 1.8533
2024-10-30 21:39:23: [2024-10-30 21:39:23] iter = 13180, loss = 2.3001
2024-10-30 21:39:26: [2024-10-30 21:39:26] iter = 13190, loss = 1.9931
2024-10-30 21:39:30: [2024-10-30 21:39:30] iter = 13200, loss = 2.5127
2024-10-30 21:39:33: [2024-10-30 21:39:33] iter = 13210, loss = 1.9230
2024-10-30 21:39:37: [2024-10-30 21:39:37] iter = 13220, loss = 1.8083
2024-10-30 21:39:41: [2024-10-30 21:39:41] iter = 13230, loss = 2.1115
2024-10-30 21:39:45: [2024-10-30 21:39:45] iter = 13240, loss = 1.9224
2024-10-30 21:39:49: [2024-10-30 21:39:49] iter = 13250, loss = 1.6944
2024-10-30 21:39:52: [2024-10-30 21:39:52] iter = 13260, loss = 1.6396
2024-10-30 21:39:55: [2024-10-30 21:39:55] iter = 13270, loss = 2.5191
2024-10-30 21:39:59: [2024-10-30 21:39:59] iter = 13280, loss = 2.1145
2024-10-30 21:40:04: [2024-10-30 21:40:04] iter = 13290, loss = 2.4941
2024-10-30 21:40:08: [2024-10-30 21:40:08] iter = 13300, loss = 1.9819
2024-10-30 21:40:11: [2024-10-30 21:40:11] iter = 13310, loss = 2.1643
2024-10-30 21:40:16: [2024-10-30 21:40:16] iter = 13320, loss = 2.0228
2024-10-30 21:40:19: [2024-10-30 21:40:19] iter = 13330, loss = 2.2931
2024-10-30 21:40:22: [2024-10-30 21:40:22] iter = 13340, loss = 1.7227
2024-10-30 21:40:26: [2024-10-30 21:40:26] iter = 13350, loss = 2.5102
2024-10-30 21:40:30: [2024-10-30 21:40:30] iter = 13360, loss = 3.1488
2024-10-30 21:40:33: [2024-10-30 21:40:33] iter = 13370, loss = 2.5427
2024-10-30 21:40:36: [2024-10-30 21:40:36] iter = 13380, loss = 1.8563
2024-10-30 21:40:40: [2024-10-30 21:40:40] iter = 13390, loss = 2.0197
2024-10-30 21:40:44: [2024-10-30 21:40:44] iter = 13400, loss = 1.9069
2024-10-30 21:40:47: [2024-10-30 21:40:47] iter = 13410, loss = 1.7307
2024-10-30 21:40:51: [2024-10-30 21:40:51] iter = 13420, loss = 2.1213
2024-10-30 21:40:55: [2024-10-30 21:40:55] iter = 13430, loss = 1.8371
2024-10-30 21:40:58: [2024-10-30 21:40:58] iter = 13440, loss = 1.9052
2024-10-30 21:41:02: [2024-10-30 21:41:02] iter = 13450, loss = 1.7344
2024-10-30 21:41:05: [2024-10-30 21:41:05] iter = 13460, loss = 2.1115
2024-10-30 21:41:08: [2024-10-30 21:41:08] iter = 13470, loss = 2.3616
2024-10-30 21:41:11: [2024-10-30 21:41:11] iter = 13480, loss = 1.8081
2024-10-30 21:41:15: [2024-10-30 21:41:15] iter = 13490, loss = 1.9471
2024-10-30 21:41:19: [2024-10-30 21:41:19] iter = 13500, loss = 1.8163
2024-10-30 21:41:22: [2024-10-30 21:41:22] iter = 13510, loss = 1.7475
2024-10-30 21:41:26: [2024-10-30 21:41:26] iter = 13520, loss = 2.0467
2024-10-30 21:41:30: [2024-10-30 21:41:30] iter = 13530, loss = 2.0582
2024-10-30 21:41:33: [2024-10-30 21:41:33] iter = 13540, loss = 2.1426
2024-10-30 21:41:35: [2024-10-30 21:41:35] iter = 13550, loss = 1.7003
2024-10-30 21:41:38: [2024-10-30 21:41:38] iter = 13560, loss = 1.8298
2024-10-30 21:41:42: [2024-10-30 21:41:42] iter = 13570, loss = 2.9126
2024-10-30 21:41:44: [2024-10-30 21:41:44] iter = 13580, loss = 1.9776
2024-10-30 21:41:48: [2024-10-30 21:41:48] iter = 13590, loss = 1.8649
2024-10-30 21:41:51: [2024-10-30 21:41:51] iter = 13600, loss = 2.7341
2024-10-30 21:41:54: [2024-10-30 21:41:54] iter = 13610, loss = 2.0417
2024-10-30 21:41:58: [2024-10-30 21:41:58] iter = 13620, loss = 2.1366
2024-10-30 21:42:01: [2024-10-30 21:42:01] iter = 13630, loss = 2.5175
2024-10-30 21:42:06: [2024-10-30 21:42:06] iter = 13640, loss = 1.8134
2024-10-30 21:42:10: [2024-10-30 21:42:10] iter = 13650, loss = 2.3960
2024-10-30 21:42:14: [2024-10-30 21:42:14] iter = 13660, loss = 2.7948
2024-10-30 21:42:19: [2024-10-30 21:42:19] iter = 13670, loss = 2.0197
2024-10-30 21:42:22: [2024-10-30 21:42:22] iter = 13680, loss = 2.0257
2024-10-30 21:42:25: [2024-10-30 21:42:25] iter = 13690, loss = 2.7459
2024-10-30 21:42:31: [2024-10-30 21:42:31] iter = 13700, loss = 1.9407
2024-10-30 21:42:34: [2024-10-30 21:42:34] iter = 13710, loss = 1.8603
2024-10-30 21:42:39: [2024-10-30 21:42:39] iter = 13720, loss = 1.9314
2024-10-30 21:42:42: [2024-10-30 21:42:42] iter = 13730, loss = 2.0419
2024-10-30 21:42:47: [2024-10-30 21:42:46] iter = 13740, loss = 1.7264
2024-10-30 21:42:51: [2024-10-30 21:42:51] iter = 13750, loss = 2.1051
2024-10-30 21:42:54: [2024-10-30 21:42:54] iter = 13760, loss = 1.8406
2024-10-30 21:42:59: [2024-10-30 21:42:59] iter = 13770, loss = 2.4713
2024-10-30 21:43:04: [2024-10-30 21:43:04] iter = 13780, loss = 1.8117
2024-10-30 21:43:08: [2024-10-30 21:43:08] iter = 13790, loss = 2.3327
2024-10-30 21:43:11: [2024-10-30 21:43:11] iter = 13800, loss = 1.6912
2024-10-30 21:43:15: [2024-10-30 21:43:15] iter = 13810, loss = 1.7367
2024-10-30 21:43:20: [2024-10-30 21:43:20] iter = 13820, loss = 2.9857
2024-10-30 21:43:24: [2024-10-30 21:43:24] iter = 13830, loss = 3.0476
2024-10-30 21:43:28: [2024-10-30 21:43:28] iter = 13840, loss = 1.9301
2024-10-30 21:43:32: [2024-10-30 21:43:32] iter = 13850, loss = 1.9812
2024-10-30 21:43:36: [2024-10-30 21:43:36] iter = 13860, loss = 1.7805
2024-10-30 21:43:40: [2024-10-30 21:43:40] iter = 13870, loss = 2.5974
2024-10-30 21:43:44: [2024-10-30 21:43:44] iter = 13880, loss = 2.6909
2024-10-30 21:43:48: [2024-10-30 21:43:48] iter = 13890, loss = 2.0234
2024-10-30 21:43:51: [2024-10-30 21:43:51] iter = 13900, loss = 1.7105
2024-10-30 21:43:55: [2024-10-30 21:43:55] iter = 13910, loss = 5.2481
2024-10-30 21:43:58: [2024-10-30 21:43:58] iter = 13920, loss = 2.1547
2024-10-30 21:44:02: [2024-10-30 21:44:02] iter = 13930, loss = 2.0798
2024-10-30 21:44:06: [2024-10-30 21:44:06] iter = 13940, loss = 2.0280
2024-10-30 21:44:09: [2024-10-30 21:44:09] iter = 13950, loss = 1.8918
2024-10-30 21:44:12: [2024-10-30 21:44:12] iter = 13960, loss = 3.6224
2024-10-30 21:44:15: [2024-10-30 21:44:15] iter = 13970, loss = 2.1528
2024-10-30 21:44:19: [2024-10-30 21:44:19] iter = 13980, loss = 2.4227
2024-10-30 21:44:23: [2024-10-30 21:44:23] iter = 13990, loss = 2.7106
2024-10-30 21:44:28: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 21:44:28: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:44:28: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 68092}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:47:00: Evaluate 5 random ConvNet, ACCmean = 0.7769 ACCstd = 0.0034
-------------------------
2024-10-30 21:47:00: Evaluate 5 random ConvNet, SENmean = 0.7771 SENstd = 0.0027
-------------------------
2024-10-30 21:47:00: Evaluate 5 random ConvNet, SPEmean = 0.9775 SPEstd = 0.0004
-------------------------
2024-10-30 21:47:00: Evaluate 5 random ConvNet, F!mean = 0.7681 F!std = 0.0029
-------------------------
2024-10-30 21:47:00: Evaluate 5 random ConvNet, mean = 0.7769 std = 0.0034
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:47:01: [2024-10-30 21:47:01] iter = 14000, loss = 2.0940
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:47:05: [2024-10-30 21:47:05] iter = 14010, loss = 2.2941
2024-10-30 21:47:08: [2024-10-30 21:47:08] iter = 14020, loss = 2.8860
2024-10-30 21:47:12: [2024-10-30 21:47:12] iter = 14030, loss = 1.8727
2024-10-30 21:47:16: [2024-10-30 21:47:16] iter = 14040, loss = 1.9172
2024-10-30 21:47:19: [2024-10-30 21:47:19] iter = 14050, loss = 2.8324
2024-10-30 21:47:23: [2024-10-30 21:47:23] iter = 14060, loss = 3.1171
2024-10-30 21:47:26: [2024-10-30 21:47:26] iter = 14070, loss = 2.7822
2024-10-30 21:47:30: [2024-10-30 21:47:30] iter = 14080, loss = 5.1408
2024-10-30 21:47:33: [2024-10-30 21:47:33] iter = 14090, loss = 1.9430
2024-10-30 21:47:37: [2024-10-30 21:47:37] iter = 14100, loss = 1.7801
2024-10-30 21:47:40: [2024-10-30 21:47:40] iter = 14110, loss = 2.8088
2024-10-30 21:47:43: [2024-10-30 21:47:43] iter = 14120, loss = 2.0945
2024-10-30 21:47:46: [2024-10-30 21:47:46] iter = 14130, loss = 1.8689
2024-10-30 21:47:50: [2024-10-30 21:47:50] iter = 14140, loss = 1.9001
2024-10-30 21:47:54: [2024-10-30 21:47:54] iter = 14150, loss = 1.8824
2024-10-30 21:47:58: [2024-10-30 21:47:58] iter = 14160, loss = 2.0433
2024-10-30 21:48:01: [2024-10-30 21:48:01] iter = 14170, loss = 1.9701
2024-10-30 21:48:05: [2024-10-30 21:48:05] iter = 14180, loss = 1.5117
2024-10-30 21:48:07: [2024-10-30 21:48:07] iter = 14190, loss = 3.9341
2024-10-30 21:48:11: [2024-10-30 21:48:11] iter = 14200, loss = 2.2132
2024-10-30 21:48:15: [2024-10-30 21:48:15] iter = 14210, loss = 2.2142
2024-10-30 21:48:19: [2024-10-30 21:48:19] iter = 14220, loss = 2.4146
2024-10-30 21:48:24: [2024-10-30 21:48:24] iter = 14230, loss = 1.7328
2024-10-30 21:48:28: [2024-10-30 21:48:28] iter = 14240, loss = 2.0831
2024-10-30 21:48:32: [2024-10-30 21:48:32] iter = 14250, loss = 1.6791
2024-10-30 21:48:36: [2024-10-30 21:48:36] iter = 14260, loss = 1.9317
2024-10-30 21:48:38: [2024-10-30 21:48:38] iter = 14270, loss = 1.9735
2024-10-30 21:48:41: [2024-10-30 21:48:41] iter = 14280, loss = 2.8468
2024-10-30 21:48:44: [2024-10-30 21:48:44] iter = 14290, loss = 2.0717
2024-10-30 21:48:47: [2024-10-30 21:48:47] iter = 14300, loss = 1.8673
2024-10-30 21:48:51: [2024-10-30 21:48:51] iter = 14310, loss = 1.9333
2024-10-30 21:48:54: [2024-10-30 21:48:54] iter = 14320, loss = 2.6988
2024-10-30 21:48:59: [2024-10-30 21:48:59] iter = 14330, loss = 2.4023
2024-10-30 21:49:02: [2024-10-30 21:49:02] iter = 14340, loss = 1.8392
2024-10-30 21:49:06: [2024-10-30 21:49:06] iter = 14350, loss = 2.7457
2024-10-30 21:49:09: [2024-10-30 21:49:09] iter = 14360, loss = 1.8536
2024-10-30 21:49:12: [2024-10-30 21:49:12] iter = 14370, loss = 2.7263
2024-10-30 21:49:17: [2024-10-30 21:49:17] iter = 14380, loss = 1.8102
2024-10-30 21:49:21: [2024-10-30 21:49:21] iter = 14390, loss = 1.6672
2024-10-30 21:49:25: [2024-10-30 21:49:25] iter = 14400, loss = 1.9275
2024-10-30 21:49:29: [2024-10-30 21:49:29] iter = 14410, loss = 2.1048
2024-10-30 21:49:33: [2024-10-30 21:49:33] iter = 14420, loss = 2.4016
2024-10-30 21:49:36: [2024-10-30 21:49:36] iter = 14430, loss = 3.9545
2024-10-30 21:49:40: [2024-10-30 21:49:40] iter = 14440, loss = 2.2512
2024-10-30 21:49:45: [2024-10-30 21:49:45] iter = 14450, loss = 1.7809
2024-10-30 21:49:49: [2024-10-30 21:49:49] iter = 14460, loss = 1.9370
2024-10-30 21:49:52: [2024-10-30 21:49:52] iter = 14470, loss = 2.3442
2024-10-30 21:49:56: [2024-10-30 21:49:56] iter = 14480, loss = 2.2434
2024-10-30 21:49:59: [2024-10-30 21:49:59] iter = 14490, loss = 3.3287
2024-10-30 21:50:03: [2024-10-30 21:50:03] iter = 14500, loss = 2.4795
2024-10-30 21:50:07: [2024-10-30 21:50:07] iter = 14510, loss = 2.2430
2024-10-30 21:50:11: [2024-10-30 21:50:11] iter = 14520, loss = 1.5681
2024-10-30 21:50:15: [2024-10-30 21:50:15] iter = 14530, loss = 1.9536
2024-10-30 21:50:18: [2024-10-30 21:50:18] iter = 14540, loss = 1.8680
2024-10-30 21:50:21: [2024-10-30 21:50:21] iter = 14550, loss = 2.8400
2024-10-30 21:50:25: [2024-10-30 21:50:25] iter = 14560, loss = 2.1289
2024-10-30 21:50:29: [2024-10-30 21:50:29] iter = 14570, loss = 1.7635
2024-10-30 21:50:33: [2024-10-30 21:50:33] iter = 14580, loss = 2.9392
2024-10-30 21:50:36: [2024-10-30 21:50:36] iter = 14590, loss = 1.8521
2024-10-30 21:50:41: [2024-10-30 21:50:41] iter = 14600, loss = 2.8498
2024-10-30 21:50:45: [2024-10-30 21:50:45] iter = 14610, loss = 2.0790
2024-10-30 21:50:49: [2024-10-30 21:50:49] iter = 14620, loss = 2.0427
2024-10-30 21:50:53: [2024-10-30 21:50:53] iter = 14630, loss = 1.8538
2024-10-30 21:50:57: [2024-10-30 21:50:57] iter = 14640, loss = 2.1460
2024-10-30 21:51:02: [2024-10-30 21:51:02] iter = 14650, loss = 1.9170
2024-10-30 21:51:07: [2024-10-30 21:51:07] iter = 14660, loss = 2.2189
2024-10-30 21:51:11: [2024-10-30 21:51:11] iter = 14670, loss = 1.9925
2024-10-30 21:51:16: [2024-10-30 21:51:16] iter = 14680, loss = 2.2210
2024-10-30 21:51:20: [2024-10-30 21:51:20] iter = 14690, loss = 2.4828
2024-10-30 21:51:23: [2024-10-30 21:51:23] iter = 14700, loss = 1.8223
2024-10-30 21:51:27: [2024-10-30 21:51:27] iter = 14710, loss = 2.1099
2024-10-30 21:51:31: [2024-10-30 21:51:31] iter = 14720, loss = 2.4381
2024-10-30 21:51:34: [2024-10-30 21:51:34] iter = 14730, loss = 2.9266
2024-10-30 21:51:38: [2024-10-30 21:51:38] iter = 14740, loss = 1.7590
2024-10-30 21:51:41: [2024-10-30 21:51:41] iter = 14750, loss = 2.1692
2024-10-30 21:51:45: [2024-10-30 21:51:45] iter = 14760, loss = 1.9499
2024-10-30 21:51:48: [2024-10-30 21:51:48] iter = 14770, loss = 4.5826
2024-10-30 21:51:52: [2024-10-30 21:51:52] iter = 14780, loss = 1.9643
2024-10-30 21:51:56: [2024-10-30 21:51:56] iter = 14790, loss = 1.8811
2024-10-30 21:52:00: [2024-10-30 21:52:00] iter = 14800, loss = 2.1012
2024-10-30 21:52:04: [2024-10-30 21:52:04] iter = 14810, loss = 2.4096
2024-10-30 21:52:08: [2024-10-30 21:52:08] iter = 14820, loss = 1.8738
2024-10-30 21:52:12: [2024-10-30 21:52:12] iter = 14830, loss = 1.9304
2024-10-30 21:52:15: [2024-10-30 21:52:15] iter = 14840, loss = 3.4234
2024-10-30 21:52:19: [2024-10-30 21:52:19] iter = 14850, loss = 3.4176
2024-10-30 21:52:23: [2024-10-30 21:52:23] iter = 14860, loss = 2.3241
2024-10-30 21:52:28: [2024-10-30 21:52:28] iter = 14870, loss = 3.1572
2024-10-30 21:52:33: [2024-10-30 21:52:33] iter = 14880, loss = 1.7375
2024-10-30 21:52:37: [2024-10-30 21:52:37] iter = 14890, loss = 1.9982
2024-10-30 21:52:41: [2024-10-30 21:52:41] iter = 14900, loss = 1.8495
2024-10-30 21:52:44: [2024-10-30 21:52:44] iter = 14910, loss = 3.0127
2024-10-30 21:52:49: [2024-10-30 21:52:49] iter = 14920, loss = 2.3365
2024-10-30 21:52:53: [2024-10-30 21:52:53] iter = 14930, loss = 2.2238
2024-10-30 21:52:57: [2024-10-30 21:52:57] iter = 14940, loss = 3.0353
2024-10-30 21:53:02: [2024-10-30 21:53:02] iter = 14950, loss = 1.9860
2024-10-30 21:53:06: [2024-10-30 21:53:06] iter = 14960, loss = 2.2340
2024-10-30 21:53:10: [2024-10-30 21:53:10] iter = 14970, loss = 1.9514
2024-10-30 21:53:15: [2024-10-30 21:53:15] iter = 14980, loss = 2.7386
2024-10-30 21:53:18: [2024-10-30 21:53:18] iter = 14990, loss = 1.6521
2024-10-30 21:53:21: [2024-10-30 21:53:21] iter = 15000, loss = 2.0519
2024-10-30 21:53:25: [2024-10-30 21:53:25] iter = 15010, loss = 1.9720
2024-10-30 21:53:29: [2024-10-30 21:53:29] iter = 15020, loss = 2.6857
2024-10-30 21:53:32: [2024-10-30 21:53:32] iter = 15030, loss = 2.0817
2024-10-30 21:53:34: [2024-10-30 21:53:34] iter = 15040, loss = 2.6524
2024-10-30 21:53:38: [2024-10-30 21:53:38] iter = 15050, loss = 2.0853
2024-10-30 21:53:41: [2024-10-30 21:53:41] iter = 15060, loss = 2.0758
2024-10-30 21:53:44: [2024-10-30 21:53:44] iter = 15070, loss = 1.9044
2024-10-30 21:53:47: [2024-10-30 21:53:47] iter = 15080, loss = 3.0983
2024-10-30 21:53:51: [2024-10-30 21:53:51] iter = 15090, loss = 2.4008
2024-10-30 21:53:54: [2024-10-30 21:53:54] iter = 15100, loss = 1.9595
2024-10-30 21:53:58: [2024-10-30 21:53:58] iter = 15110, loss = 3.3732
2024-10-30 21:54:03: [2024-10-30 21:54:03] iter = 15120, loss = 1.9856
2024-10-30 21:54:06: [2024-10-30 21:54:06] iter = 15130, loss = 3.5363
2024-10-30 21:54:10: [2024-10-30 21:54:10] iter = 15140, loss = 2.3406
2024-10-30 21:54:14: [2024-10-30 21:54:14] iter = 15150, loss = 2.0728
2024-10-30 21:54:19: [2024-10-30 21:54:19] iter = 15160, loss = 1.5885
2024-10-30 21:54:23: [2024-10-30 21:54:23] iter = 15170, loss = 2.0400
2024-10-30 21:54:28: [2024-10-30 21:54:28] iter = 15180, loss = 1.9745
2024-10-30 21:54:32: [2024-10-30 21:54:32] iter = 15190, loss = 2.2841
2024-10-30 21:54:36: [2024-10-30 21:54:36] iter = 15200, loss = 2.0178
2024-10-30 21:54:39: [2024-10-30 21:54:39] iter = 15210, loss = 1.9834
2024-10-30 21:54:42: [2024-10-30 21:54:42] iter = 15220, loss = 2.0822
2024-10-30 21:54:46: [2024-10-30 21:54:46] iter = 15230, loss = 2.1951
2024-10-30 21:54:50: [2024-10-30 21:54:50] iter = 15240, loss = 2.1276
2024-10-30 21:54:54: [2024-10-30 21:54:54] iter = 15250, loss = 4.2680
2024-10-30 21:54:59: [2024-10-30 21:54:59] iter = 15260, loss = 2.5209
2024-10-30 21:55:06: [2024-10-30 21:55:06] iter = 15270, loss = 2.0981
2024-10-30 21:55:10: [2024-10-30 21:55:10] iter = 15280, loss = 1.9911
2024-10-30 21:55:13: [2024-10-30 21:55:13] iter = 15290, loss = 2.9834
2024-10-30 21:55:17: [2024-10-30 21:55:17] iter = 15300, loss = 1.6736
2024-10-30 21:55:21: [2024-10-30 21:55:21] iter = 15310, loss = 3.0414
2024-10-30 21:55:23: [2024-10-30 21:55:23] iter = 15320, loss = 2.5838
2024-10-30 21:55:28: [2024-10-30 21:55:28] iter = 15330, loss = 2.0547
2024-10-30 21:55:31: [2024-10-30 21:55:31] iter = 15340, loss = 2.6598
2024-10-30 21:55:35: [2024-10-30 21:55:35] iter = 15350, loss = 2.2837
2024-10-30 21:55:40: [2024-10-30 21:55:40] iter = 15360, loss = 4.8723
2024-10-30 21:55:45: [2024-10-30 21:55:45] iter = 15370, loss = 2.9048
2024-10-30 21:55:49: [2024-10-30 21:55:49] iter = 15380, loss = 1.9319
2024-10-30 21:55:55: [2024-10-30 21:55:55] iter = 15390, loss = 2.0862
2024-10-30 21:55:59: [2024-10-30 21:55:59] iter = 15400, loss = 1.9234
2024-10-30 21:56:04: [2024-10-30 21:56:04] iter = 15410, loss = 2.8832
2024-10-30 21:56:08: [2024-10-30 21:56:08] iter = 15420, loss = 2.0207
2024-10-30 21:56:12: [2024-10-30 21:56:12] iter = 15430, loss = 2.5251
2024-10-30 21:56:17: [2024-10-30 21:56:17] iter = 15440, loss = 2.6217
2024-10-30 21:56:21: [2024-10-30 21:56:21] iter = 15450, loss = 2.2423
2024-10-30 21:56:26: [2024-10-30 21:56:26] iter = 15460, loss = 2.1803
2024-10-30 21:56:31: [2024-10-30 21:56:31] iter = 15470, loss = 1.8320
2024-10-30 21:56:36: [2024-10-30 21:56:36] iter = 15480, loss = 2.0009
2024-10-30 21:56:41: [2024-10-30 21:56:41] iter = 15490, loss = 2.0177
2024-10-30 21:56:46: [2024-10-30 21:56:46] iter = 15500, loss = 2.2871
2024-10-30 21:56:52: [2024-10-30 21:56:52] iter = 15510, loss = 2.0921
2024-10-30 21:56:58: [2024-10-30 21:56:58] iter = 15520, loss = 1.6336
2024-10-30 21:57:02: [2024-10-30 21:57:02] iter = 15530, loss = 1.9303
2024-10-30 21:57:08: [2024-10-30 21:57:08] iter = 15540, loss = 2.8283
2024-10-30 21:57:11: [2024-10-30 21:57:11] iter = 15550, loss = 2.8827
2024-10-30 21:57:15: [2024-10-30 21:57:15] iter = 15560, loss = 1.9481
2024-10-30 21:57:17: [2024-10-30 21:57:17] iter = 15570, loss = 1.7024
2024-10-30 21:57:21: [2024-10-30 21:57:21] iter = 15580, loss = 2.4858
2024-10-30 21:57:25: [2024-10-30 21:57:25] iter = 15590, loss = 2.3585
2024-10-30 21:57:29: [2024-10-30 21:57:29] iter = 15600, loss = 3.4611
2024-10-30 21:57:32: [2024-10-30 21:57:32] iter = 15610, loss = 1.6947
2024-10-30 21:57:37: [2024-10-30 21:57:37] iter = 15620, loss = 2.3798
2024-10-30 21:57:43: [2024-10-30 21:57:43] iter = 15630, loss = 3.0596
2024-10-30 21:57:48: [2024-10-30 21:57:48] iter = 15640, loss = 1.9777
2024-10-30 21:57:53: [2024-10-30 21:57:53] iter = 15650, loss = 2.4965
2024-10-30 21:57:58: [2024-10-30 21:57:58] iter = 15660, loss = 1.8493
2024-10-30 21:58:02: [2024-10-30 21:58:02] iter = 15670, loss = 2.4547
2024-10-30 21:58:06: [2024-10-30 21:58:06] iter = 15680, loss = 2.2923
2024-10-30 21:58:08: [2024-10-30 21:58:08] iter = 15690, loss = 2.0707
2024-10-30 21:58:12: [2024-10-30 21:58:12] iter = 15700, loss = 1.6409
2024-10-30 21:58:16: [2024-10-30 21:58:16] iter = 15710, loss = 2.0081
2024-10-30 21:58:20: [2024-10-30 21:58:20] iter = 15720, loss = 2.4057
2024-10-30 21:58:23: [2024-10-30 21:58:23] iter = 15730, loss = 2.6713
2024-10-30 21:58:26: [2024-10-30 21:58:26] iter = 15740, loss = 2.1751
2024-10-30 21:58:30: [2024-10-30 21:58:30] iter = 15750, loss = 2.3493
2024-10-30 21:58:34: [2024-10-30 21:58:34] iter = 15760, loss = 2.0448
2024-10-30 21:58:38: [2024-10-30 21:58:38] iter = 15770, loss = 2.8269
2024-10-30 21:58:41: [2024-10-30 21:58:41] iter = 15780, loss = 1.5287
2024-10-30 21:58:44: [2024-10-30 21:58:44] iter = 15790, loss = 2.5166
2024-10-30 21:58:48: [2024-10-30 21:58:48] iter = 15800, loss = 1.8574
2024-10-30 21:58:52: [2024-10-30 21:58:52] iter = 15810, loss = 1.8545
2024-10-30 21:58:56: [2024-10-30 21:58:56] iter = 15820, loss = 1.8073
2024-10-30 21:59:00: [2024-10-30 21:59:00] iter = 15830, loss = 1.7900
2024-10-30 21:59:04: [2024-10-30 21:59:04] iter = 15840, loss = 2.1819
2024-10-30 21:59:07: [2024-10-30 21:59:07] iter = 15850, loss = 1.8717
2024-10-30 21:59:11: [2024-10-30 21:59:11] iter = 15860, loss = 1.6536
2024-10-30 21:59:16: [2024-10-30 21:59:16] iter = 15870, loss = 1.7681
2024-10-30 21:59:20: [2024-10-30 21:59:20] iter = 15880, loss = 2.6824
2024-10-30 21:59:26: [2024-10-30 21:59:26] iter = 15890, loss = 2.4147
2024-10-30 21:59:30: [2024-10-30 21:59:30] iter = 15900, loss = 1.9264
2024-10-30 21:59:33: [2024-10-30 21:59:33] iter = 15910, loss = 2.5166
2024-10-30 21:59:39: [2024-10-30 21:59:39] iter = 15920, loss = 2.5705
2024-10-30 21:59:43: [2024-10-30 21:59:43] iter = 15930, loss = 1.5613
2024-10-30 21:59:47: [2024-10-30 21:59:47] iter = 15940, loss = 4.6892
2024-10-30 21:59:52: [2024-10-30 21:59:52] iter = 15950, loss = 1.8993
2024-10-30 21:59:56: [2024-10-30 21:59:56] iter = 15960, loss = 2.1891
2024-10-30 22:00:00: [2024-10-30 22:00:00] iter = 15970, loss = 1.7999
2024-10-30 22:00:03: [2024-10-30 22:00:03] iter = 15980, loss = 1.7626
2024-10-30 22:00:07: [2024-10-30 22:00:07] iter = 15990, loss = 1.8346
2024-10-30 22:00:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 22:00:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:00:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10947}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:03:10: Evaluate 5 random ConvNet, ACCmean = 0.7821 ACCstd = 0.0030
-------------------------
2024-10-30 22:03:10: Evaluate 5 random ConvNet, SENmean = 0.7772 SENstd = 0.0033
-------------------------
2024-10-30 22:03:10: Evaluate 5 random ConvNet, SPEmean = 0.9779 SPEstd = 0.0003
-------------------------
2024-10-30 22:03:10: Evaluate 5 random ConvNet, F!mean = 0.7715 F!std = 0.0029
-------------------------
2024-10-30 22:03:10: Evaluate 5 random ConvNet, mean = 0.7821 std = 0.0030
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:03:11: [2024-10-30 22:03:11] iter = 16000, loss = 2.0182
2024-10-30 22:03:13: [2024-10-30 22:03:13] iter = 16010, loss = 2.7229
2024-10-30 22:03:17: [2024-10-30 22:03:17] iter = 16020, loss = 2.1575
2024-10-30 22:03:20: [2024-10-30 22:03:20] iter = 16030, loss = 3.7920
2024-10-30 22:03:24: [2024-10-30 22:03:24] iter = 16040, loss = 2.1918
2024-10-30 22:03:28: [2024-10-30 22:03:28] iter = 16050, loss = 3.4496
2024-10-30 22:03:32: [2024-10-30 22:03:32] iter = 16060, loss = 2.7096
2024-10-30 22:03:35: [2024-10-30 22:03:35] iter = 16070, loss = 2.1692
2024-10-30 22:03:38: [2024-10-30 22:03:38] iter = 16080, loss = 4.2911
2024-10-30 22:03:42: [2024-10-30 22:03:42] iter = 16090, loss = 1.8887
2024-10-30 22:03:46: [2024-10-30 22:03:46] iter = 16100, loss = 3.7786
2024-10-30 22:03:50: [2024-10-30 22:03:50] iter = 16110, loss = 1.7464
2024-10-30 22:03:53: [2024-10-30 22:03:53] iter = 16120, loss = 2.2150
2024-10-30 22:03:57: [2024-10-30 22:03:57] iter = 16130, loss = 1.8126
2024-10-30 22:04:00: [2024-10-30 22:04:00] iter = 16140, loss = 2.4317
2024-10-30 22:04:04: [2024-10-30 22:04:04] iter = 16150, loss = 3.1189
2024-10-30 22:04:09: [2024-10-30 22:04:09] iter = 16160, loss = 2.4091
2024-10-30 22:04:12: [2024-10-30 22:04:12] iter = 16170, loss = 2.2291
2024-10-30 22:04:16: [2024-10-30 22:04:16] iter = 16180, loss = 2.0159
2024-10-30 22:04:19: [2024-10-30 22:04:19] iter = 16190, loss = 2.1178
2024-10-30 22:04:23: [2024-10-30 22:04:23] iter = 16200, loss = 2.2601
2024-10-30 22:04:25: [2024-10-30 22:04:25] iter = 16210, loss = 2.3048
2024-10-30 22:04:29: [2024-10-30 22:04:29] iter = 16220, loss = 2.4649
2024-10-30 22:04:33: [2024-10-30 22:04:33] iter = 16230, loss = 1.9904
2024-10-30 22:04:37: [2024-10-30 22:04:37] iter = 16240, loss = 1.9569
2024-10-30 22:04:41: [2024-10-30 22:04:41] iter = 16250, loss = 3.7864
2024-10-30 22:04:43: [2024-10-30 22:04:43] iter = 16260, loss = 1.7844
2024-10-30 22:04:47: [2024-10-30 22:04:47] iter = 16270, loss = 1.8620
2024-10-30 22:04:51: [2024-10-30 22:04:51] iter = 16280, loss = 1.8152
2024-10-30 22:04:54: [2024-10-30 22:04:54] iter = 16290, loss = 1.8965
2024-10-30 22:04:58: [2024-10-30 22:04:58] iter = 16300, loss = 3.7544
2024-10-30 22:05:02: [2024-10-30 22:05:02] iter = 16310, loss = 2.3079
2024-10-30 22:05:06: [2024-10-30 22:05:06] iter = 16320, loss = 1.9348
2024-10-30 22:05:10: [2024-10-30 22:05:10] iter = 16330, loss = 2.3540
2024-10-30 22:05:12: [2024-10-30 22:05:12] iter = 16340, loss = 2.0132
2024-10-30 22:05:16: [2024-10-30 22:05:16] iter = 16350, loss = 2.3066
2024-10-30 22:05:18: [2024-10-30 22:05:18] iter = 16360, loss = 2.1421
2024-10-30 22:05:21: [2024-10-30 22:05:21] iter = 16370, loss = 2.0603
2024-10-30 22:05:24: [2024-10-30 22:05:24] iter = 16380, loss = 1.6695
2024-10-30 22:05:27: [2024-10-30 22:05:27] iter = 16390, loss = 2.2136
2024-10-30 22:05:31: [2024-10-30 22:05:31] iter = 16400, loss = 2.2261
2024-10-30 22:05:35: [2024-10-30 22:05:35] iter = 16410, loss = 2.2571
2024-10-30 22:05:38: [2024-10-30 22:05:38] iter = 16420, loss = 2.3547
2024-10-30 22:05:41: [2024-10-30 22:05:41] iter = 16430, loss = 2.1405
2024-10-30 22:05:45: [2024-10-30 22:05:45] iter = 16440, loss = 2.5376
2024-10-30 22:05:48: [2024-10-30 22:05:48] iter = 16450, loss = 1.9766
2024-10-30 22:05:51: [2024-10-30 22:05:51] iter = 16460, loss = 1.9584
2024-10-30 22:05:55: [2024-10-30 22:05:55] iter = 16470, loss = 2.7544
2024-10-30 22:05:59: [2024-10-30 22:05:59] iter = 16480, loss = 2.7097
2024-10-30 22:06:03: [2024-10-30 22:06:03] iter = 16490, loss = 2.2112
2024-10-30 22:06:06: [2024-10-30 22:06:06] iter = 16500, loss = 2.3098
2024-10-30 22:06:09: [2024-10-30 22:06:09] iter = 16510, loss = 2.6545
2024-10-30 22:06:13: [2024-10-30 22:06:13] iter = 16520, loss = 2.4528
2024-10-30 22:06:15: [2024-10-30 22:06:15] iter = 16530, loss = 2.4032
2024-10-30 22:06:18: [2024-10-30 22:06:18] iter = 16540, loss = 1.9745
2024-10-30 22:06:21: [2024-10-30 22:06:21] iter = 16550, loss = 1.9931
2024-10-30 22:06:24: [2024-10-30 22:06:24] iter = 16560, loss = 2.2240
2024-10-30 22:06:28: [2024-10-30 22:06:28] iter = 16570, loss = 2.0658
2024-10-30 22:06:31: [2024-10-30 22:06:31] iter = 16580, loss = 2.9028
2024-10-30 22:06:35: [2024-10-30 22:06:35] iter = 16590, loss = 2.4941
2024-10-30 22:06:39: [2024-10-30 22:06:39] iter = 16600, loss = 2.6623
2024-10-30 22:06:42: [2024-10-30 22:06:42] iter = 16610, loss = 2.0145
2024-10-30 22:06:46: [2024-10-30 22:06:46] iter = 16620, loss = 2.8635
2024-10-30 22:06:51: [2024-10-30 22:06:51] iter = 16630, loss = 1.6575
2024-10-30 22:06:55: [2024-10-30 22:06:55] iter = 16640, loss = 1.8374
2024-10-30 22:06:58: [2024-10-30 22:06:58] iter = 16650, loss = 1.9618
2024-10-30 22:07:03: [2024-10-30 22:07:03] iter = 16660, loss = 1.6667
2024-10-30 22:07:06: [2024-10-30 22:07:06] iter = 16670, loss = 2.2290
2024-10-30 22:07:09: [2024-10-30 22:07:09] iter = 16680, loss = 2.6011
2024-10-30 22:07:13: [2024-10-30 22:07:13] iter = 16690, loss = 1.9814
2024-10-30 22:07:17: [2024-10-30 22:07:17] iter = 16700, loss = 4.7353
2024-10-30 22:07:19: [2024-10-30 22:07:19] iter = 16710, loss = 2.2402
2024-10-30 22:07:23: [2024-10-30 22:07:23] iter = 16720, loss = 1.6405
2024-10-30 22:07:27: [2024-10-30 22:07:27] iter = 16730, loss = 2.2842
2024-10-30 22:07:29: [2024-10-30 22:07:29] iter = 16740, loss = 2.5723
2024-10-30 22:07:33: [2024-10-30 22:07:33] iter = 16750, loss = 1.9678
2024-10-30 22:07:37: [2024-10-30 22:07:37] iter = 16760, loss = 2.5827
2024-10-30 22:07:41: [2024-10-30 22:07:41] iter = 16770, loss = 1.7946
2024-10-30 22:07:46: [2024-10-30 22:07:46] iter = 16780, loss = 2.0002
2024-10-30 22:07:50: [2024-10-30 22:07:50] iter = 16790, loss = 2.6833
2024-10-30 22:07:54: [2024-10-30 22:07:54] iter = 16800, loss = 2.4056
2024-10-30 22:07:58: [2024-10-30 22:07:58] iter = 16810, loss = 1.9431
2024-10-30 22:08:01: [2024-10-30 22:08:01] iter = 16820, loss = 1.8725
2024-10-30 22:08:05: [2024-10-30 22:08:05] iter = 16830, loss = 2.3658
2024-10-30 22:08:08: [2024-10-30 22:08:08] iter = 16840, loss = 2.4738
2024-10-30 22:08:12: [2024-10-30 22:08:12] iter = 16850, loss = 2.6375
2024-10-30 22:08:15: [2024-10-30 22:08:15] iter = 16860, loss = 2.1352
2024-10-30 22:08:19: [2024-10-30 22:08:19] iter = 16870, loss = 1.8388
2024-10-30 22:08:23: [2024-10-30 22:08:23] iter = 16880, loss = 1.9477
2024-10-30 22:08:26: [2024-10-30 22:08:26] iter = 16890, loss = 2.0692
2024-10-30 22:08:30: [2024-10-30 22:08:30] iter = 16900, loss = 1.8871
2024-10-30 22:08:34: [2024-10-30 22:08:34] iter = 16910, loss = 2.4484
2024-10-30 22:08:37: [2024-10-30 22:08:37] iter = 16920, loss = 1.7394
2024-10-30 22:08:41: [2024-10-30 22:08:41] iter = 16930, loss = 2.8978
2024-10-30 22:08:45: [2024-10-30 22:08:45] iter = 16940, loss = 1.7195
2024-10-30 22:08:49: [2024-10-30 22:08:49] iter = 16950, loss = 2.2450
2024-10-30 22:08:53: [2024-10-30 22:08:53] iter = 16960, loss = 1.9024
2024-10-30 22:08:58: [2024-10-30 22:08:58] iter = 16970, loss = 2.3979
2024-10-30 22:09:02: [2024-10-30 22:09:02] iter = 16980, loss = 2.2212
2024-10-30 22:09:06: [2024-10-30 22:09:06] iter = 16990, loss = 2.5910
2024-10-30 22:09:10: [2024-10-30 22:09:10] iter = 17000, loss = 1.6994
2024-10-30 22:09:14: [2024-10-30 22:09:14] iter = 17010, loss = 1.7475
2024-10-30 22:09:18: [2024-10-30 22:09:18] iter = 17020, loss = 2.6050
2024-10-30 22:09:22: [2024-10-30 22:09:22] iter = 17030, loss = 1.7218
2024-10-30 22:09:25: [2024-10-30 22:09:25] iter = 17040, loss = 1.9943
2024-10-30 22:09:29: [2024-10-30 22:09:29] iter = 17050, loss = 2.8000
2024-10-30 22:09:33: [2024-10-30 22:09:33] iter = 17060, loss = 2.4005
2024-10-30 22:09:37: [2024-10-30 22:09:37] iter = 17070, loss = 1.9223
2024-10-30 22:09:40: [2024-10-30 22:09:40] iter = 17080, loss = 2.3502
2024-10-30 22:09:43: [2024-10-30 22:09:43] iter = 17090, loss = 1.7886
2024-10-30 22:09:47: [2024-10-30 22:09:47] iter = 17100, loss = 2.7154
2024-10-30 22:09:52: [2024-10-30 22:09:52] iter = 17110, loss = 2.4794
2024-10-30 22:09:54: [2024-10-30 22:09:54] iter = 17120, loss = 2.0902
2024-10-30 22:09:59: [2024-10-30 22:09:59] iter = 17130, loss = 1.6890
2024-10-30 22:10:03: [2024-10-30 22:10:03] iter = 17140, loss = 2.2491
2024-10-30 22:10:07: [2024-10-30 22:10:07] iter = 17150, loss = 2.0293
2024-10-30 22:10:11: [2024-10-30 22:10:11] iter = 17160, loss = 3.0437
2024-10-30 22:10:15: [2024-10-30 22:10:15] iter = 17170, loss = 1.7365
2024-10-30 22:10:19: [2024-10-30 22:10:19] iter = 17180, loss = 2.5993
2024-10-30 22:10:23: [2024-10-30 22:10:23] iter = 17190, loss = 1.9986
2024-10-30 22:10:27: [2024-10-30 22:10:27] iter = 17200, loss = 2.3920
2024-10-30 22:10:30: [2024-10-30 22:10:30] iter = 17210, loss = 3.4131
2024-10-30 22:10:35: [2024-10-30 22:10:35] iter = 17220, loss = 1.8228
2024-10-30 22:10:40: [2024-10-30 22:10:40] iter = 17230, loss = 1.8040
2024-10-30 22:10:44: [2024-10-30 22:10:44] iter = 17240, loss = 2.2057
2024-10-30 22:10:47: [2024-10-30 22:10:47] iter = 17250, loss = 3.6645
2024-10-30 22:10:51: [2024-10-30 22:10:51] iter = 17260, loss = 2.2105
2024-10-30 22:10:55: [2024-10-30 22:10:54] iter = 17270, loss = 1.8875
2024-10-30 22:10:58: [2024-10-30 22:10:58] iter = 17280, loss = 2.5105
2024-10-30 22:11:02: [2024-10-30 22:11:02] iter = 17290, loss = 2.2165
2024-10-30 22:11:05: [2024-10-30 22:11:05] iter = 17300, loss = 2.2134
2024-10-30 22:11:09: [2024-10-30 22:11:09] iter = 17310, loss = 2.6625
2024-10-30 22:11:13: [2024-10-30 22:11:13] iter = 17320, loss = 1.6320
2024-10-30 22:11:18: [2024-10-30 22:11:18] iter = 17330, loss = 1.5991
2024-10-30 22:11:21: [2024-10-30 22:11:21] iter = 17340, loss = 2.2872
2024-10-30 22:11:23: [2024-10-30 22:11:23] iter = 17350, loss = 2.0093
2024-10-30 22:11:26: [2024-10-30 22:11:26] iter = 17360, loss = 3.4491
2024-10-30 22:11:29: [2024-10-30 22:11:29] iter = 17370, loss = 1.8583
2024-10-30 22:11:33: [2024-10-30 22:11:33] iter = 17380, loss = 2.0052
2024-10-30 22:11:37: [2024-10-30 22:11:37] iter = 17390, loss = 2.0934
2024-10-30 22:11:40: [2024-10-30 22:11:40] iter = 17400, loss = 2.1377
2024-10-30 22:11:44: [2024-10-30 22:11:44] iter = 17410, loss = 2.2974
2024-10-30 22:11:48: [2024-10-30 22:11:48] iter = 17420, loss = 3.0782
2024-10-30 22:11:53: [2024-10-30 22:11:53] iter = 17430, loss = 2.2965
2024-10-30 22:11:57: [2024-10-30 22:11:57] iter = 17440, loss = 2.0563
2024-10-30 22:12:01: [2024-10-30 22:12:01] iter = 17450, loss = 1.6532
2024-10-30 22:12:04: [2024-10-30 22:12:04] iter = 17460, loss = 1.8094
2024-10-30 22:12:07: [2024-10-30 22:12:07] iter = 17470, loss = 2.0200
2024-10-30 22:12:11: [2024-10-30 22:12:11] iter = 17480, loss = 1.8391
2024-10-30 22:12:16: [2024-10-30 22:12:16] iter = 17490, loss = 2.4291
2024-10-30 22:12:19: [2024-10-30 22:12:19] iter = 17500, loss = 2.0397
2024-10-30 22:12:23: [2024-10-30 22:12:23] iter = 17510, loss = 1.7367
2024-10-30 22:12:27: [2024-10-30 22:12:27] iter = 17520, loss = 1.9208
2024-10-30 22:12:31: [2024-10-30 22:12:31] iter = 17530, loss = 2.1548
2024-10-30 22:12:35: [2024-10-30 22:12:35] iter = 17540, loss = 2.6027
2024-10-30 22:12:38: [2024-10-30 22:12:38] iter = 17550, loss = 2.8892
2024-10-30 22:12:41: [2024-10-30 22:12:41] iter = 17560, loss = 3.4918
2024-10-30 22:12:44: [2024-10-30 22:12:44] iter = 17570, loss = 2.6193
2024-10-30 22:12:47: [2024-10-30 22:12:47] iter = 17580, loss = 2.1296
2024-10-30 22:12:51: [2024-10-30 22:12:51] iter = 17590, loss = 2.3684
2024-10-30 22:12:54: [2024-10-30 22:12:54] iter = 17600, loss = 2.1538
2024-10-30 22:12:57: [2024-10-30 22:12:57] iter = 17610, loss = 2.1535
2024-10-30 22:13:00: [2024-10-30 22:13:00] iter = 17620, loss = 2.0838
2024-10-30 22:13:04: [2024-10-30 22:13:04] iter = 17630, loss = 1.9510
2024-10-30 22:13:08: [2024-10-30 22:13:08] iter = 17640, loss = 1.8265
2024-10-30 22:13:10: [2024-10-30 22:13:10] iter = 17650, loss = 2.3810
2024-10-30 22:13:14: [2024-10-30 22:13:14] iter = 17660, loss = 1.9404
2024-10-30 22:13:17: [2024-10-30 22:13:17] iter = 17670, loss = 2.1044
2024-10-30 22:13:21: [2024-10-30 22:13:21] iter = 17680, loss = 2.1143
2024-10-30 22:13:25: [2024-10-30 22:13:25] iter = 17690, loss = 1.9247
2024-10-30 22:13:29: [2024-10-30 22:13:29] iter = 17700, loss = 1.7270
2024-10-30 22:13:33: [2024-10-30 22:13:33] iter = 17710, loss = 2.2811
2024-10-30 22:13:35: [2024-10-30 22:13:35] iter = 17720, loss = 2.8984
2024-10-30 22:13:40: [2024-10-30 22:13:40] iter = 17730, loss = 1.9837
2024-10-30 22:13:43: [2024-10-30 22:13:43] iter = 17740, loss = 2.7276
2024-10-30 22:13:47: [2024-10-30 22:13:47] iter = 17750, loss = 2.2863
2024-10-30 22:13:50: [2024-10-30 22:13:50] iter = 17760, loss = 1.9716
2024-10-30 22:13:55: [2024-10-30 22:13:55] iter = 17770, loss = 2.2723
2024-10-30 22:13:59: [2024-10-30 22:13:59] iter = 17780, loss = 2.0080
2024-10-30 22:14:03: [2024-10-30 22:14:03] iter = 17790, loss = 1.7455
2024-10-30 22:14:07: [2024-10-30 22:14:07] iter = 17800, loss = 2.0748
2024-10-30 22:14:11: [2024-10-30 22:14:11] iter = 17810, loss = 1.5691
2024-10-30 22:14:17: [2024-10-30 22:14:17] iter = 17820, loss = 1.7523
2024-10-30 22:14:21: [2024-10-30 22:14:21] iter = 17830, loss = 2.5351
2024-10-30 22:14:26: [2024-10-30 22:14:26] iter = 17840, loss = 1.7129
2024-10-30 22:14:30: [2024-10-30 22:14:30] iter = 17850, loss = 1.8224
2024-10-30 22:14:33: [2024-10-30 22:14:33] iter = 17860, loss = 2.0210
2024-10-30 22:14:36: [2024-10-30 22:14:36] iter = 17870, loss = 2.8202
2024-10-30 22:14:40: [2024-10-30 22:14:40] iter = 17880, loss = 2.4780
2024-10-30 22:14:45: [2024-10-30 22:14:45] iter = 17890, loss = 2.2345
2024-10-30 22:14:50: [2024-10-30 22:14:50] iter = 17900, loss = 2.1527
2024-10-30 22:14:53: [2024-10-30 22:14:53] iter = 17910, loss = 2.5083
2024-10-30 22:14:58: [2024-10-30 22:14:58] iter = 17920, loss = 1.8864
2024-10-30 22:15:02: [2024-10-30 22:15:02] iter = 17930, loss = 3.0155
2024-10-30 22:15:06: [2024-10-30 22:15:06] iter = 17940, loss = 1.8786
2024-10-30 22:15:09: [2024-10-30 22:15:09] iter = 17950, loss = 2.1957
2024-10-30 22:15:12: [2024-10-30 22:15:12] iter = 17960, loss = 2.4511
2024-10-30 22:15:17: [2024-10-30 22:15:17] iter = 17970, loss = 1.9375
2024-10-30 22:15:21: [2024-10-30 22:15:21] iter = 17980, loss = 1.8398
2024-10-30 22:15:24: [2024-10-30 22:15:24] iter = 17990, loss = 1.8350
2024-10-30 22:15:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 22:15:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:15:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 27573}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:17:58: Evaluate 5 random ConvNet, ACCmean = 0.7835 ACCstd = 0.0012
-------------------------
2024-10-30 22:17:58: Evaluate 5 random ConvNet, SENmean = 0.7764 SENstd = 0.0014
-------------------------
2024-10-30 22:17:58: Evaluate 5 random ConvNet, SPEmean = 0.9781 SPEstd = 0.0001
-------------------------
2024-10-30 22:17:58: Evaluate 5 random ConvNet, F!mean = 0.7709 F!std = 0.0016
-------------------------
2024-10-30 22:17:58: Evaluate 5 random ConvNet, mean = 0.7835 std = 0.0012
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:17:59: [2024-10-30 22:17:59] iter = 18000, loss = 2.8601
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:18:05: [2024-10-30 22:18:05] iter = 18010, loss = 1.7027
2024-10-30 22:18:10: [2024-10-30 22:18:10] iter = 18020, loss = 2.0557
2024-10-30 22:18:15: [2024-10-30 22:18:15] iter = 18030, loss = 2.0156
2024-10-30 22:18:20: [2024-10-30 22:18:20] iter = 18040, loss = 2.0151
2024-10-30 22:18:24: [2024-10-30 22:18:24] iter = 18050, loss = 2.8207
2024-10-30 22:18:29: [2024-10-30 22:18:29] iter = 18060, loss = 2.4424
2024-10-30 22:18:34: [2024-10-30 22:18:34] iter = 18070, loss = 2.4219
2024-10-30 22:18:39: [2024-10-30 22:18:39] iter = 18080, loss = 2.5570
2024-10-30 22:18:44: [2024-10-30 22:18:44] iter = 18090, loss = 1.8713
2024-10-30 22:18:49: [2024-10-30 22:18:49] iter = 18100, loss = 2.5439
2024-10-30 22:18:54: [2024-10-30 22:18:54] iter = 18110, loss = 1.9463
2024-10-30 22:19:00: [2024-10-30 22:19:00] iter = 18120, loss = 1.6938
2024-10-30 22:19:04: [2024-10-30 22:19:04] iter = 18130, loss = 2.0316
2024-10-30 22:19:09: [2024-10-30 22:19:09] iter = 18140, loss = 1.7014
2024-10-30 22:19:14: [2024-10-30 22:19:14] iter = 18150, loss = 2.0035
2024-10-30 22:19:19: [2024-10-30 22:19:19] iter = 18160, loss = 1.9022
2024-10-30 22:19:25: [2024-10-30 22:19:25] iter = 18170, loss = 2.2996
2024-10-30 22:19:28: [2024-10-30 22:19:28] iter = 18180, loss = 2.1965
2024-10-30 22:19:33: [2024-10-30 22:19:33] iter = 18190, loss = 1.7185
2024-10-30 22:19:37: [2024-10-30 22:19:37] iter = 18200, loss = 1.7149
2024-10-30 22:19:41: [2024-10-30 22:19:41] iter = 18210, loss = 2.1482
2024-10-30 22:19:46: [2024-10-30 22:19:46] iter = 18220, loss = 1.9037
2024-10-30 22:19:50: [2024-10-30 22:19:50] iter = 18230, loss = 4.6159
2024-10-30 22:19:54: [2024-10-30 22:19:54] iter = 18240, loss = 1.8954
2024-10-30 22:19:57: [2024-10-30 22:19:57] iter = 18250, loss = 1.8467
2024-10-30 22:20:00: [2024-10-30 22:20:00] iter = 18260, loss = 2.3483
2024-10-30 22:20:04: [2024-10-30 22:20:04] iter = 18270, loss = 2.0111
2024-10-30 22:20:07: [2024-10-30 22:20:07] iter = 18280, loss = 2.1150
2024-10-30 22:20:10: [2024-10-30 22:20:10] iter = 18290, loss = 2.0016
2024-10-30 22:20:14: [2024-10-30 22:20:14] iter = 18300, loss = 1.8537
2024-10-30 22:20:17: [2024-10-30 22:20:17] iter = 18310, loss = 2.7482
2024-10-30 22:20:20: [2024-10-30 22:20:20] iter = 18320, loss = 2.4477
2024-10-30 22:20:23: [2024-10-30 22:20:23] iter = 18330, loss = 2.4510
2024-10-30 22:20:27: [2024-10-30 22:20:27] iter = 18340, loss = 2.1917
2024-10-30 22:20:33: [2024-10-30 22:20:33] iter = 18350, loss = 2.1188
2024-10-30 22:20:37: [2024-10-30 22:20:37] iter = 18360, loss = 1.7836
2024-10-30 22:20:41: [2024-10-30 22:20:41] iter = 18370, loss = 1.7257
2024-10-30 22:20:45: [2024-10-30 22:20:45] iter = 18380, loss = 2.2536
2024-10-30 22:20:49: [2024-10-30 22:20:49] iter = 18390, loss = 6.2323
2024-10-30 22:20:53: [2024-10-30 22:20:53] iter = 18400, loss = 1.8704
2024-10-30 22:20:57: [2024-10-30 22:20:57] iter = 18410, loss = 2.6115
2024-10-30 22:21:01: [2024-10-30 22:21:01] iter = 18420, loss = 1.7683
2024-10-30 22:21:06: [2024-10-30 22:21:06] iter = 18430, loss = 4.0679
2024-10-30 22:21:10: [2024-10-30 22:21:10] iter = 18440, loss = 2.0712
2024-10-30 22:21:14: [2024-10-30 22:21:14] iter = 18450, loss = 2.3289
2024-10-30 22:21:18: [2024-10-30 22:21:18] iter = 18460, loss = 1.7414
2024-10-30 22:21:21: [2024-10-30 22:21:21] iter = 18470, loss = 1.7513
2024-10-30 22:21:25: [2024-10-30 22:21:25] iter = 18480, loss = 2.0632
2024-10-30 22:21:29: [2024-10-30 22:21:29] iter = 18490, loss = 2.3459
2024-10-30 22:21:33: [2024-10-30 22:21:33] iter = 18500, loss = 1.9353
2024-10-30 22:21:36: [2024-10-30 22:21:36] iter = 18510, loss = 2.6236
2024-10-30 22:21:41: [2024-10-30 22:21:41] iter = 18520, loss = 1.9652
2024-10-30 22:21:45: [2024-10-30 22:21:45] iter = 18530, loss = 2.1765
2024-10-30 22:21:49: [2024-10-30 22:21:49] iter = 18540, loss = 2.0700
2024-10-30 22:21:52: [2024-10-30 22:21:52] iter = 18550, loss = 2.3189
2024-10-30 22:21:56: [2024-10-30 22:21:56] iter = 18560, loss = 2.8815
2024-10-30 22:21:59: [2024-10-30 22:21:59] iter = 18570, loss = 2.7597
2024-10-30 22:22:02: [2024-10-30 22:22:02] iter = 18580, loss = 1.9794
2024-10-30 22:22:05: [2024-10-30 22:22:05] iter = 18590, loss = 2.0182
2024-10-30 22:22:09: [2024-10-30 22:22:09] iter = 18600, loss = 3.0128
2024-10-30 22:22:11: [2024-10-30 22:22:11] iter = 18610, loss = 1.7632
2024-10-30 22:22:15: [2024-10-30 22:22:15] iter = 18620, loss = 1.9049
2024-10-30 22:22:18: [2024-10-30 22:22:18] iter = 18630, loss = 2.2548
2024-10-30 22:22:20: [2024-10-30 22:22:20] iter = 18640, loss = 2.0226
2024-10-30 22:22:23: [2024-10-30 22:22:23] iter = 18650, loss = 2.5472
2024-10-30 22:22:27: [2024-10-30 22:22:27] iter = 18660, loss = 1.9944
2024-10-30 22:22:31: [2024-10-30 22:22:31] iter = 18670, loss = 1.9050
2024-10-30 22:22:35: [2024-10-30 22:22:35] iter = 18680, loss = 2.2300
2024-10-30 22:22:39: [2024-10-30 22:22:39] iter = 18690, loss = 2.0467
2024-10-30 22:22:42: [2024-10-30 22:22:42] iter = 18700, loss = 1.8902
2024-10-30 22:22:45: [2024-10-30 22:22:45] iter = 18710, loss = 2.3254
2024-10-30 22:22:49: [2024-10-30 22:22:49] iter = 18720, loss = 2.1416
2024-10-30 22:22:52: [2024-10-30 22:22:52] iter = 18730, loss = 1.7096
2024-10-30 22:22:56: [2024-10-30 22:22:56] iter = 18740, loss = 1.6569
2024-10-30 22:23:00: [2024-10-30 22:23:00] iter = 18750, loss = 1.7511
2024-10-30 22:23:05: [2024-10-30 22:23:05] iter = 18760, loss = 2.0504
2024-10-30 22:23:08: [2024-10-30 22:23:08] iter = 18770, loss = 2.8088
2024-10-30 22:23:12: [2024-10-30 22:23:12] iter = 18780, loss = 3.8844
2024-10-30 22:23:16: [2024-10-30 22:23:16] iter = 18790, loss = 2.4402
2024-10-30 22:23:20: [2024-10-30 22:23:20] iter = 18800, loss = 1.7798
2024-10-30 22:23:24: [2024-10-30 22:23:24] iter = 18810, loss = 2.5841
2024-10-30 22:23:28: [2024-10-30 22:23:28] iter = 18820, loss = 3.5492
2024-10-30 22:23:32: [2024-10-30 22:23:32] iter = 18830, loss = 1.8083
2024-10-30 22:23:36: [2024-10-30 22:23:36] iter = 18840, loss = 1.8014
2024-10-30 22:23:38: [2024-10-30 22:23:38] iter = 18850, loss = 2.3864
2024-10-30 22:23:42: [2024-10-30 22:23:42] iter = 18860, loss = 2.5071
2024-10-30 22:23:46: [2024-10-30 22:23:46] iter = 18870, loss = 2.2239
2024-10-30 22:23:49: [2024-10-30 22:23:49] iter = 18880, loss = 4.4694
2024-10-30 22:23:52: [2024-10-30 22:23:52] iter = 18890, loss = 2.4279
2024-10-30 22:23:56: [2024-10-30 22:23:56] iter = 18900, loss = 1.9771
2024-10-30 22:24:00: [2024-10-30 22:24:00] iter = 18910, loss = 2.7751
2024-10-30 22:24:02: [2024-10-30 22:24:02] iter = 18920, loss = 1.8098
2024-10-30 22:24:06: [2024-10-30 22:24:06] iter = 18930, loss = 2.0466
2024-10-30 22:24:10: [2024-10-30 22:24:10] iter = 18940, loss = 2.1950
2024-10-30 22:24:14: [2024-10-30 22:24:14] iter = 18950, loss = 1.6432
2024-10-30 22:24:18: [2024-10-30 22:24:18] iter = 18960, loss = 1.9642
2024-10-30 22:24:21: [2024-10-30 22:24:21] iter = 18970, loss = 2.2182
2024-10-30 22:24:26: [2024-10-30 22:24:26] iter = 18980, loss = 2.1215
2024-10-30 22:24:29: [2024-10-30 22:24:29] iter = 18990, loss = 1.7262
2024-10-30 22:24:33: [2024-10-30 22:24:33] iter = 19000, loss = 2.5864
2024-10-30 22:24:37: [2024-10-30 22:24:37] iter = 19010, loss = 1.6998
2024-10-30 22:24:43: [2024-10-30 22:24:43] iter = 19020, loss = 1.8376
2024-10-30 22:24:47: [2024-10-30 22:24:47] iter = 19030, loss = 2.5655
2024-10-30 22:24:51: [2024-10-30 22:24:51] iter = 19040, loss = 1.6785
2024-10-30 22:24:55: [2024-10-30 22:24:55] iter = 19050, loss = 1.8124
2024-10-30 22:24:59: [2024-10-30 22:24:59] iter = 19060, loss = 2.6579
2024-10-30 22:25:03: [2024-10-30 22:25:03] iter = 19070, loss = 2.1572
2024-10-30 22:25:07: [2024-10-30 22:25:07] iter = 19080, loss = 2.2669
2024-10-30 22:25:11: [2024-10-30 22:25:11] iter = 19090, loss = 2.1109
2024-10-30 22:25:14: [2024-10-30 22:25:14] iter = 19100, loss = 1.9134
2024-10-30 22:25:18: [2024-10-30 22:25:18] iter = 19110, loss = 1.8556
2024-10-30 22:25:22: [2024-10-30 22:25:22] iter = 19120, loss = 3.0844
2024-10-30 22:25:26: [2024-10-30 22:25:26] iter = 19130, loss = 1.6703
2024-10-30 22:25:30: [2024-10-30 22:25:30] iter = 19140, loss = 3.4471
2024-10-30 22:25:33: [2024-10-30 22:25:33] iter = 19150, loss = 2.3562
2024-10-30 22:25:36: [2024-10-30 22:25:36] iter = 19160, loss = 2.0433
2024-10-30 22:25:40: [2024-10-30 22:25:40] iter = 19170, loss = 2.0183
2024-10-30 22:25:43: [2024-10-30 22:25:43] iter = 19180, loss = 1.7645
2024-10-30 22:25:47: [2024-10-30 22:25:47] iter = 19190, loss = 2.0147
2024-10-30 22:25:50: [2024-10-30 22:25:50] iter = 19200, loss = 3.7306
2024-10-30 22:25:53: [2024-10-30 22:25:53] iter = 19210, loss = 2.4079
2024-10-30 22:25:57: [2024-10-30 22:25:57] iter = 19220, loss = 2.0755
2024-10-30 22:26:00: [2024-10-30 22:26:00] iter = 19230, loss = 2.2996
2024-10-30 22:26:03: [2024-10-30 22:26:03] iter = 19240, loss = 1.6782
2024-10-30 22:26:07: [2024-10-30 22:26:07] iter = 19250, loss = 1.8443
2024-10-30 22:26:11: [2024-10-30 22:26:11] iter = 19260, loss = 1.6007
2024-10-30 22:26:15: [2024-10-30 22:26:15] iter = 19270, loss = 1.7878
2024-10-30 22:26:19: [2024-10-30 22:26:19] iter = 19280, loss = 2.3697
2024-10-30 22:26:23: [2024-10-30 22:26:23] iter = 19290, loss = 2.3410
2024-10-30 22:26:27: [2024-10-30 22:26:27] iter = 19300, loss = 2.2227
2024-10-30 22:26:31: [2024-10-30 22:26:31] iter = 19310, loss = 3.1569
2024-10-30 22:26:35: [2024-10-30 22:26:35] iter = 19320, loss = 2.0111
2024-10-30 22:26:39: [2024-10-30 22:26:39] iter = 19330, loss = 1.8471
2024-10-30 22:26:42: [2024-10-30 22:26:42] iter = 19340, loss = 2.1424
2024-10-30 22:26:46: [2024-10-30 22:26:46] iter = 19350, loss = 1.7695
2024-10-30 22:26:49: [2024-10-30 22:26:49] iter = 19360, loss = 2.8886
2024-10-30 22:26:53: [2024-10-30 22:26:53] iter = 19370, loss = 6.4206
2024-10-30 22:26:57: [2024-10-30 22:26:57] iter = 19380, loss = 2.6468
2024-10-30 22:27:00: [2024-10-30 22:27:00] iter = 19390, loss = 2.0652
2024-10-30 22:27:04: [2024-10-30 22:27:04] iter = 19400, loss = 2.6003
2024-10-30 22:27:08: [2024-10-30 22:27:08] iter = 19410, loss = 2.3307
2024-10-30 22:27:13: [2024-10-30 22:27:13] iter = 19420, loss = 1.9697
2024-10-30 22:27:16: [2024-10-30 22:27:16] iter = 19430, loss = 1.9869
2024-10-30 22:27:18: [2024-10-30 22:27:18] iter = 19440, loss = 1.8406
2024-10-30 22:27:21: [2024-10-30 22:27:21] iter = 19450, loss = 2.9001
2024-10-30 22:27:23: [2024-10-30 22:27:23] iter = 19460, loss = 2.3211
2024-10-30 22:27:26: [2024-10-30 22:27:26] iter = 19470, loss = 1.8278
2024-10-30 22:27:29: [2024-10-30 22:27:29] iter = 19480, loss = 1.7137
2024-10-30 22:27:32: [2024-10-30 22:27:32] iter = 19490, loss = 2.7502
2024-10-30 22:27:35: [2024-10-30 22:27:35] iter = 19500, loss = 2.6165
2024-10-30 22:27:38: [2024-10-30 22:27:38] iter = 19510, loss = 2.1775
2024-10-30 22:27:41: [2024-10-30 22:27:41] iter = 19520, loss = 1.8496
2024-10-30 22:27:45: [2024-10-30 22:27:45] iter = 19530, loss = 1.9988
2024-10-30 22:27:47: [2024-10-30 22:27:47] iter = 19540, loss = 1.9835
2024-10-30 22:27:50: [2024-10-30 22:27:50] iter = 19550, loss = 2.1749
2024-10-30 22:27:53: [2024-10-30 22:27:53] iter = 19560, loss = 2.4321
2024-10-30 22:27:56: [2024-10-30 22:27:56] iter = 19570, loss = 1.8517
2024-10-30 22:27:59: [2024-10-30 22:27:59] iter = 19580, loss = 2.2419
2024-10-30 22:28:03: [2024-10-30 22:28:03] iter = 19590, loss = 1.8792
2024-10-30 22:28:06: [2024-10-30 22:28:06] iter = 19600, loss = 1.9951
2024-10-30 22:28:10: [2024-10-30 22:28:10] iter = 19610, loss = 1.9986
2024-10-30 22:28:14: [2024-10-30 22:28:14] iter = 19620, loss = 2.4522
2024-10-30 22:28:18: [2024-10-30 22:28:18] iter = 19630, loss = 2.3797
2024-10-30 22:28:21: [2024-10-30 22:28:21] iter = 19640, loss = 1.9462
2024-10-30 22:28:25: [2024-10-30 22:28:25] iter = 19650, loss = 2.6379
2024-10-30 22:28:29: [2024-10-30 22:28:29] iter = 19660, loss = 3.0429
2024-10-30 22:28:32: [2024-10-30 22:28:32] iter = 19670, loss = 2.0813
2024-10-30 22:28:36: [2024-10-30 22:28:36] iter = 19680, loss = 1.6792
2024-10-30 22:28:40: [2024-10-30 22:28:40] iter = 19690, loss = 1.8836
2024-10-30 22:28:43: [2024-10-30 22:28:43] iter = 19700, loss = 2.2047
2024-10-30 22:28:46: [2024-10-30 22:28:46] iter = 19710, loss = 1.7254
2024-10-30 22:28:49: [2024-10-30 22:28:49] iter = 19720, loss = 2.0444
2024-10-30 22:28:53: [2024-10-30 22:28:53] iter = 19730, loss = 2.7300
2024-10-30 22:28:56: [2024-10-30 22:28:56] iter = 19740, loss = 1.7003
2024-10-30 22:29:00: [2024-10-30 22:29:00] iter = 19750, loss = 2.1203
2024-10-30 22:29:03: [2024-10-30 22:29:03] iter = 19760, loss = 2.6294
2024-10-30 22:29:07: [2024-10-30 22:29:07] iter = 19770, loss = 2.0044
2024-10-30 22:29:10: [2024-10-30 22:29:10] iter = 19780, loss = 1.8532
2024-10-30 22:29:13: [2024-10-30 22:29:13] iter = 19790, loss = 1.8708
2024-10-30 22:29:17: [2024-10-30 22:29:17] iter = 19800, loss = 2.0187
2024-10-30 22:29:21: [2024-10-30 22:29:21] iter = 19810, loss = 2.2228
2024-10-30 22:29:24: [2024-10-30 22:29:24] iter = 19820, loss = 2.0037
2024-10-30 22:29:28: [2024-10-30 22:29:28] iter = 19830, loss = 2.6521
2024-10-30 22:29:30: [2024-10-30 22:29:30] iter = 19840, loss = 1.7214
2024-10-30 22:29:33: [2024-10-30 22:29:33] iter = 19850, loss = 1.7472
2024-10-30 22:29:36: [2024-10-30 22:29:36] iter = 19860, loss = 2.4109
2024-10-30 22:29:38: [2024-10-30 22:29:38] iter = 19870, loss = 3.8886
2024-10-30 22:29:41: [2024-10-30 22:29:41] iter = 19880, loss = 1.9350
2024-10-30 22:29:44: [2024-10-30 22:29:44] iter = 19890, loss = 2.3545
2024-10-30 22:29:48: [2024-10-30 22:29:48] iter = 19900, loss = 2.1246
2024-10-30 22:29:50: [2024-10-30 22:29:50] iter = 19910, loss = 1.4772
2024-10-30 22:29:54: [2024-10-30 22:29:54] iter = 19920, loss = 2.1017
2024-10-30 22:29:58: [2024-10-30 22:29:58] iter = 19930, loss = 2.1055
2024-10-30 22:30:00: [2024-10-30 22:30:00] iter = 19940, loss = 1.9842
2024-10-30 22:30:03: [2024-10-30 22:30:03] iter = 19950, loss = 2.9056
2024-10-30 22:30:07: [2024-10-30 22:30:07] iter = 19960, loss = 3.9204
2024-10-30 22:30:10: [2024-10-30 22:30:10] iter = 19970, loss = 2.0277
2024-10-30 22:30:13: [2024-10-30 22:30:13] iter = 19980, loss = 1.6861
2024-10-30 22:30:17: [2024-10-30 22:30:17] iter = 19990, loss = 2.3421
2024-10-30 22:30:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 22:30:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:30:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 20248}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:32:40: Evaluate 5 random ConvNet, ACCmean = 0.7790 ACCstd = 0.0043
-------------------------
2024-10-30 22:32:40: Evaluate 5 random ConvNet, SENmean = 0.7772 SENstd = 0.0024
-------------------------
2024-10-30 22:32:40: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0004
-------------------------
2024-10-30 22:32:40: Evaluate 5 random ConvNet, F!mean = 0.7688 F!std = 0.0043
-------------------------
2024-10-30 22:32:40: Evaluate 5 random ConvNet, mean = 0.7790 std = 0.0043
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:32:40: [2024-10-30 22:32:40] iter = 20000, loss = 2.0357
2024-10-30 22:32:40: 
================== Exp 3 ==================
 
2024-10-30 22:32:40: Hyper-parameters: 
{'dataset': 'OrganCMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f9aa0d64b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganCMNIST (INFO)>}
2024-10-30 22:32:40: Evaluation model pool: ['ConvNet']
2024-10-30 22:32:40: class c = 0: 1148 real images
2024-10-30 22:32:40: class c = 1: 619 real images
2024-10-30 22:32:40: class c = 2: 595 real images
2024-10-30 22:32:40: class c = 3: 600 real images
2024-10-30 22:32:40: class c = 4: 1088 real images
2024-10-30 22:32:40: class c = 5: 1170 real images
2024-10-30 22:32:40: class c = 6: 2986 real images
2024-10-30 22:32:40: class c = 7: 1002 real images
2024-10-30 22:32:40: class c = 8: 1022 real images
2024-10-30 22:32:40: class c = 9: 1173 real images
2024-10-30 22:32:40: class c = 10: 1572 real images
2024-10-30 22:32:40: real images channel 0, mean = 0.4942, std = 0.2834
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 22:32:40: initialize synthetic data from random real images
2024-10-30 22:32:40: [2024-10-30 22:32:40] training begins
2024-10-30 22:32:40: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 22:32:40: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:32:40: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60307}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:35:03: Evaluate 5 random ConvNet, ACCmean = 0.6975 ACCstd = 0.0048
-------------------------
2024-10-30 22:35:03: Evaluate 5 random ConvNet, SENmean = 0.6903 SENstd = 0.0042
-------------------------
2024-10-30 22:35:03: Evaluate 5 random ConvNet, SPEmean = 0.9695 SPEstd = 0.0005
-------------------------
2024-10-30 22:35:03: Evaluate 5 random ConvNet, F!mean = 0.6858 F!std = 0.0038
-------------------------
2024-10-30 22:35:03: Evaluate 5 random ConvNet, mean = 0.6975 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:35:04: [2024-10-30 22:35:04] iter = 00000, loss = 15.1595
2024-10-30 22:35:07: [2024-10-30 22:35:07] iter = 00010, loss = 5.9220
2024-10-30 22:35:12: [2024-10-30 22:35:12] iter = 00020, loss = 3.0311
2024-10-30 22:35:15: [2024-10-30 22:35:15] iter = 00030, loss = 2.6033
2024-10-30 22:35:19: [2024-10-30 22:35:19] iter = 00040, loss = 3.8921
2024-10-30 22:35:23: [2024-10-30 22:35:23] iter = 00050, loss = 2.9441
2024-10-30 22:35:26: [2024-10-30 22:35:26] iter = 00060, loss = 3.7081
2024-10-30 22:35:29: [2024-10-30 22:35:29] iter = 00070, loss = 4.8617
2024-10-30 22:35:33: [2024-10-30 22:35:33] iter = 00080, loss = 3.8385
2024-10-30 22:35:37: [2024-10-30 22:35:37] iter = 00090, loss = 2.5491
2024-10-30 22:35:40: [2024-10-30 22:35:40] iter = 00100, loss = 2.5037
2024-10-30 22:35:43: [2024-10-30 22:35:43] iter = 00110, loss = 2.1598
2024-10-30 22:35:46: [2024-10-30 22:35:46] iter = 00120, loss = 2.7666
2024-10-30 22:35:50: [2024-10-30 22:35:50] iter = 00130, loss = 2.3611
2024-10-30 22:35:53: [2024-10-30 22:35:53] iter = 00140, loss = 2.5584
2024-10-30 22:35:56: [2024-10-30 22:35:56] iter = 00150, loss = 3.1081
2024-10-30 22:35:59: [2024-10-30 22:35:59] iter = 00160, loss = 2.7388
2024-10-30 22:36:02: [2024-10-30 22:36:02] iter = 00170, loss = 3.2334
2024-10-30 22:36:05: [2024-10-30 22:36:05] iter = 00180, loss = 2.7871
2024-10-30 22:36:07: [2024-10-30 22:36:07] iter = 00190, loss = 5.8315
2024-10-30 22:36:12: [2024-10-30 22:36:12] iter = 00200, loss = 3.5086
2024-10-30 22:36:16: [2024-10-30 22:36:16] iter = 00210, loss = 1.9379
2024-10-30 22:36:19: [2024-10-30 22:36:19] iter = 00220, loss = 2.3443
2024-10-30 22:36:23: [2024-10-30 22:36:23] iter = 00230, loss = 3.7358
2024-10-30 22:36:26: [2024-10-30 22:36:26] iter = 00240, loss = 2.4422
2024-10-30 22:36:30: [2024-10-30 22:36:30] iter = 00250, loss = 2.0499
2024-10-30 22:36:34: [2024-10-30 22:36:34] iter = 00260, loss = 2.3027
2024-10-30 22:36:37: [2024-10-30 22:36:37] iter = 00270, loss = 2.7517
2024-10-30 22:36:41: [2024-10-30 22:36:41] iter = 00280, loss = 1.9831
2024-10-30 22:36:45: [2024-10-30 22:36:45] iter = 00290, loss = 2.0681
2024-10-30 22:36:48: [2024-10-30 22:36:48] iter = 00300, loss = 1.9261
2024-10-30 22:36:52: [2024-10-30 22:36:52] iter = 00310, loss = 2.1326
2024-10-30 22:36:55: [2024-10-30 22:36:55] iter = 00320, loss = 2.6504
2024-10-30 22:36:59: [2024-10-30 22:36:59] iter = 00330, loss = 2.4787
2024-10-30 22:37:02: [2024-10-30 22:37:02] iter = 00340, loss = 2.1388
2024-10-30 22:37:06: [2024-10-30 22:37:06] iter = 00350, loss = 2.9381
2024-10-30 22:37:09: [2024-10-30 22:37:09] iter = 00360, loss = 2.0277
2024-10-30 22:37:13: [2024-10-30 22:37:13] iter = 00370, loss = 2.3255
2024-10-30 22:37:17: [2024-10-30 22:37:17] iter = 00380, loss = 1.9666
2024-10-30 22:37:21: [2024-10-30 22:37:21] iter = 00390, loss = 1.8699
2024-10-30 22:37:23: [2024-10-30 22:37:23] iter = 00400, loss = 2.5500
2024-10-30 22:37:27: [2024-10-30 22:37:27] iter = 00410, loss = 2.2749
2024-10-30 22:37:29: [2024-10-30 22:37:29] iter = 00420, loss = 2.3158
2024-10-30 22:37:31: [2024-10-30 22:37:31] iter = 00430, loss = 2.0246
2024-10-30 22:37:34: [2024-10-30 22:37:34] iter = 00440, loss = 2.1119
2024-10-30 22:37:36: [2024-10-30 22:37:36] iter = 00450, loss = 2.7093
2024-10-30 22:37:40: [2024-10-30 22:37:40] iter = 00460, loss = 2.1124
2024-10-30 22:37:43: [2024-10-30 22:37:43] iter = 00470, loss = 1.8982
2024-10-30 22:37:46: [2024-10-30 22:37:46] iter = 00480, loss = 2.4764
2024-10-30 22:37:49: [2024-10-30 22:37:49] iter = 00490, loss = 2.7191
2024-10-30 22:37:52: [2024-10-30 22:37:52] iter = 00500, loss = 2.6695
2024-10-30 22:37:56: [2024-10-30 22:37:56] iter = 00510, loss = 3.3269
2024-10-30 22:37:59: [2024-10-30 22:37:59] iter = 00520, loss = 2.0739
2024-10-30 22:38:02: [2024-10-30 22:38:02] iter = 00530, loss = 1.9049
2024-10-30 22:38:06: [2024-10-30 22:38:06] iter = 00540, loss = 2.9378
2024-10-30 22:38:10: [2024-10-30 22:38:10] iter = 00550, loss = 2.2067
2024-10-30 22:38:13: [2024-10-30 22:38:13] iter = 00560, loss = 3.4495
2024-10-30 22:38:16: [2024-10-30 22:38:16] iter = 00570, loss = 2.1100
2024-10-30 22:38:19: [2024-10-30 22:38:19] iter = 00580, loss = 1.8710
2024-10-30 22:38:22: [2024-10-30 22:38:22] iter = 00590, loss = 2.2689
2024-10-30 22:38:27: [2024-10-30 22:38:27] iter = 00600, loss = 1.7521
2024-10-30 22:38:30: [2024-10-30 22:38:30] iter = 00610, loss = 2.7514
2024-10-30 22:38:34: [2024-10-30 22:38:34] iter = 00620, loss = 2.7132
2024-10-30 22:38:37: [2024-10-30 22:38:37] iter = 00630, loss = 2.1981
2024-10-30 22:38:41: [2024-10-30 22:38:41] iter = 00640, loss = 2.6898
2024-10-30 22:38:44: [2024-10-30 22:38:44] iter = 00650, loss = 1.8800
2024-10-30 22:38:48: [2024-10-30 22:38:48] iter = 00660, loss = 2.7301
2024-10-30 22:38:51: [2024-10-30 22:38:51] iter = 00670, loss = 2.1515
2024-10-30 22:38:54: [2024-10-30 22:38:54] iter = 00680, loss = 1.6623
2024-10-30 22:38:57: [2024-10-30 22:38:57] iter = 00690, loss = 1.7895
2024-10-30 22:39:00: [2024-10-30 22:39:00] iter = 00700, loss = 1.9361
2024-10-30 22:39:03: [2024-10-30 22:39:03] iter = 00710, loss = 1.9910
2024-10-30 22:39:07: [2024-10-30 22:39:07] iter = 00720, loss = 1.9460
2024-10-30 22:39:11: [2024-10-30 22:39:11] iter = 00730, loss = 6.1416
2024-10-30 22:39:14: [2024-10-30 22:39:14] iter = 00740, loss = 1.7385
2024-10-30 22:39:16: [2024-10-30 22:39:16] iter = 00750, loss = 1.9367
2024-10-30 22:39:20: [2024-10-30 22:39:20] iter = 00760, loss = 4.2796
2024-10-30 22:39:24: [2024-10-30 22:39:24] iter = 00770, loss = 2.3065
2024-10-30 22:39:27: [2024-10-30 22:39:27] iter = 00780, loss = 2.4779
2024-10-30 22:39:30: [2024-10-30 22:39:30] iter = 00790, loss = 2.1174
2024-10-30 22:39:34: [2024-10-30 22:39:34] iter = 00800, loss = 1.9237
2024-10-30 22:39:37: [2024-10-30 22:39:37] iter = 00810, loss = 2.0480
2024-10-30 22:39:40: [2024-10-30 22:39:40] iter = 00820, loss = 1.9625
2024-10-30 22:39:44: [2024-10-30 22:39:44] iter = 00830, loss = 2.2239
2024-10-30 22:39:48: [2024-10-30 22:39:48] iter = 00840, loss = 2.0924
2024-10-30 22:39:51: [2024-10-30 22:39:51] iter = 00850, loss = 2.2555
2024-10-30 22:39:55: [2024-10-30 22:39:55] iter = 00860, loss = 2.5621
2024-10-30 22:39:58: [2024-10-30 22:39:58] iter = 00870, loss = 1.8172
2024-10-30 22:40:01: [2024-10-30 22:40:01] iter = 00880, loss = 1.7453
2024-10-30 22:40:04: [2024-10-30 22:40:04] iter = 00890, loss = 1.6943
2024-10-30 22:40:07: [2024-10-30 22:40:07] iter = 00900, loss = 2.3509
2024-10-30 22:40:11: [2024-10-30 22:40:11] iter = 00910, loss = 1.8124
2024-10-30 22:40:15: [2024-10-30 22:40:15] iter = 00920, loss = 1.9949
2024-10-30 22:40:18: [2024-10-30 22:40:18] iter = 00930, loss = 3.3663
2024-10-30 22:40:22: [2024-10-30 22:40:22] iter = 00940, loss = 2.1317
2024-10-30 22:40:26: [2024-10-30 22:40:26] iter = 00950, loss = 3.1087
2024-10-30 22:40:29: [2024-10-30 22:40:29] iter = 00960, loss = 2.4890
2024-10-30 22:40:33: [2024-10-30 22:40:33] iter = 00970, loss = 4.4928
2024-10-30 22:40:36: [2024-10-30 22:40:36] iter = 00980, loss = 2.4044
2024-10-30 22:40:40: [2024-10-30 22:40:40] iter = 00990, loss = 1.7663
2024-10-30 22:40:43: [2024-10-30 22:40:43] iter = 01000, loss = 2.3061
2024-10-30 22:40:47: [2024-10-30 22:40:47] iter = 01010, loss = 1.9386
2024-10-30 22:40:50: [2024-10-30 22:40:50] iter = 01020, loss = 1.9241
2024-10-30 22:40:54: [2024-10-30 22:40:54] iter = 01030, loss = 2.2667
2024-10-30 22:40:58: [2024-10-30 22:40:58] iter = 01040, loss = 1.8058
2024-10-30 22:41:01: [2024-10-30 22:41:01] iter = 01050, loss = 2.6751
2024-10-30 22:41:05: [2024-10-30 22:41:05] iter = 01060, loss = 1.9588
2024-10-30 22:41:08: [2024-10-30 22:41:08] iter = 01070, loss = 2.4208
2024-10-30 22:41:12: [2024-10-30 22:41:12] iter = 01080, loss = 1.7571
2024-10-30 22:41:16: [2024-10-30 22:41:16] iter = 01090, loss = 1.7748
2024-10-30 22:41:20: [2024-10-30 22:41:20] iter = 01100, loss = 3.3684
2024-10-30 22:41:23: [2024-10-30 22:41:23] iter = 01110, loss = 2.0882
2024-10-30 22:41:27: [2024-10-30 22:41:27] iter = 01120, loss = 1.9252
2024-10-30 22:41:30: [2024-10-30 22:41:30] iter = 01130, loss = 1.9494
2024-10-30 22:41:33: [2024-10-30 22:41:33] iter = 01140, loss = 1.7626
2024-10-30 22:41:36: [2024-10-30 22:41:36] iter = 01150, loss = 1.9927
2024-10-30 22:41:39: [2024-10-30 22:41:39] iter = 01160, loss = 1.9062
2024-10-30 22:41:43: [2024-10-30 22:41:43] iter = 01170, loss = 2.1826
2024-10-30 22:41:46: [2024-10-30 22:41:46] iter = 01180, loss = 1.9057
2024-10-30 22:41:50: [2024-10-30 22:41:50] iter = 01190, loss = 2.0724
2024-10-30 22:41:53: [2024-10-30 22:41:53] iter = 01200, loss = 2.1833
2024-10-30 22:41:56: [2024-10-30 22:41:56] iter = 01210, loss = 3.0006
2024-10-30 22:42:00: [2024-10-30 22:42:00] iter = 01220, loss = 2.0116
2024-10-30 22:42:03: [2024-10-30 22:42:03] iter = 01230, loss = 3.3984
2024-10-30 22:42:07: [2024-10-30 22:42:07] iter = 01240, loss = 1.5748
2024-10-30 22:42:11: [2024-10-30 22:42:11] iter = 01250, loss = 2.5486
2024-10-30 22:42:15: [2024-10-30 22:42:15] iter = 01260, loss = 1.8489
2024-10-30 22:42:19: [2024-10-30 22:42:19] iter = 01270, loss = 2.6793
2024-10-30 22:42:22: [2024-10-30 22:42:22] iter = 01280, loss = 1.7660
2024-10-30 22:42:25: [2024-10-30 22:42:25] iter = 01290, loss = 1.8173
2024-10-30 22:42:29: [2024-10-30 22:42:29] iter = 01300, loss = 1.9787
2024-10-30 22:42:32: [2024-10-30 22:42:32] iter = 01310, loss = 2.6804
2024-10-30 22:42:35: [2024-10-30 22:42:35] iter = 01320, loss = 2.6824
2024-10-30 22:42:38: [2024-10-30 22:42:38] iter = 01330, loss = 3.1090
2024-10-30 22:42:42: [2024-10-30 22:42:42] iter = 01340, loss = 2.0739
2024-10-30 22:42:45: [2024-10-30 22:42:45] iter = 01350, loss = 1.8951
2024-10-30 22:42:49: [2024-10-30 22:42:49] iter = 01360, loss = 2.2179
2024-10-30 22:42:52: [2024-10-30 22:42:52] iter = 01370, loss = 4.1060
2024-10-30 22:42:55: [2024-10-30 22:42:55] iter = 01380, loss = 1.9694
2024-10-30 22:42:58: [2024-10-30 22:42:58] iter = 01390, loss = 3.8923
2024-10-30 22:43:02: [2024-10-30 22:43:02] iter = 01400, loss = 2.2922
2024-10-30 22:43:04: [2024-10-30 22:43:04] iter = 01410, loss = 2.2958
2024-10-30 22:43:08: [2024-10-30 22:43:08] iter = 01420, loss = 2.2955
2024-10-30 22:43:11: [2024-10-30 22:43:11] iter = 01430, loss = 2.3513
2024-10-30 22:43:15: [2024-10-30 22:43:15] iter = 01440, loss = 2.0489
2024-10-30 22:43:19: [2024-10-30 22:43:19] iter = 01450, loss = 2.9218
2024-10-30 22:43:22: [2024-10-30 22:43:22] iter = 01460, loss = 2.2035
2024-10-30 22:43:26: [2024-10-30 22:43:26] iter = 01470, loss = 2.1131
2024-10-30 22:43:29: [2024-10-30 22:43:29] iter = 01480, loss = 2.2487
2024-10-30 22:43:32: [2024-10-30 22:43:32] iter = 01490, loss = 1.8732
2024-10-30 22:43:35: [2024-10-30 22:43:35] iter = 01500, loss = 1.8442
2024-10-30 22:43:38: [2024-10-30 22:43:38] iter = 01510, loss = 1.9851
2024-10-30 22:43:42: [2024-10-30 22:43:42] iter = 01520, loss = 1.9320
2024-10-30 22:43:45: [2024-10-30 22:43:45] iter = 01530, loss = 2.3706
2024-10-30 22:43:49: [2024-10-30 22:43:49] iter = 01540, loss = 2.4908
2024-10-30 22:43:52: [2024-10-30 22:43:52] iter = 01550, loss = 1.8224
2024-10-30 22:43:54: [2024-10-30 22:43:54] iter = 01560, loss = 1.8435
2024-10-30 22:43:56: [2024-10-30 22:43:56] iter = 01570, loss = 2.8459
2024-10-30 22:43:59: [2024-10-30 22:43:59] iter = 01580, loss = 3.5446
2024-10-30 22:44:02: [2024-10-30 22:44:02] iter = 01590, loss = 2.7308
2024-10-30 22:44:05: [2024-10-30 22:44:05] iter = 01600, loss = 1.7108
2024-10-30 22:44:09: [2024-10-30 22:44:09] iter = 01610, loss = 2.4217
2024-10-30 22:44:12: [2024-10-30 22:44:12] iter = 01620, loss = 2.3775
2024-10-30 22:44:17: [2024-10-30 22:44:17] iter = 01630, loss = 2.1281
2024-10-30 22:44:21: [2024-10-30 22:44:21] iter = 01640, loss = 3.3420
2024-10-30 22:44:24: [2024-10-30 22:44:24] iter = 01650, loss = 1.9139
2024-10-30 22:44:27: [2024-10-30 22:44:27] iter = 01660, loss = 1.8301
2024-10-30 22:44:31: [2024-10-30 22:44:31] iter = 01670, loss = 1.8476
2024-10-30 22:44:35: [2024-10-30 22:44:35] iter = 01680, loss = 1.9855
2024-10-30 22:44:38: [2024-10-30 22:44:38] iter = 01690, loss = 1.8999
2024-10-30 22:44:41: [2024-10-30 22:44:41] iter = 01700, loss = 2.5006
2024-10-30 22:44:45: [2024-10-30 22:44:45] iter = 01710, loss = 2.2206
2024-10-30 22:44:49: [2024-10-30 22:44:49] iter = 01720, loss = 1.7174
2024-10-30 22:44:53: [2024-10-30 22:44:53] iter = 01730, loss = 3.0865
2024-10-30 22:44:56: [2024-10-30 22:44:56] iter = 01740, loss = 2.1301
2024-10-30 22:44:59: [2024-10-30 22:44:59] iter = 01750, loss = 2.4699
2024-10-30 22:45:01: [2024-10-30 22:45:01] iter = 01760, loss = 1.7840
2024-10-30 22:45:04: [2024-10-30 22:45:04] iter = 01770, loss = 2.6286
2024-10-30 22:45:08: [2024-10-30 22:45:08] iter = 01780, loss = 2.3540
2024-10-30 22:45:11: [2024-10-30 22:45:11] iter = 01790, loss = 2.0126
2024-10-30 22:45:16: [2024-10-30 22:45:16] iter = 01800, loss = 1.6721
2024-10-30 22:45:19: [2024-10-30 22:45:19] iter = 01810, loss = 2.0779
2024-10-30 22:45:23: [2024-10-30 22:45:23] iter = 01820, loss = 2.6686
2024-10-30 22:45:26: [2024-10-30 22:45:26] iter = 01830, loss = 6.3642
2024-10-30 22:45:30: [2024-10-30 22:45:30] iter = 01840, loss = 2.0400
2024-10-30 22:45:34: [2024-10-30 22:45:34] iter = 01850, loss = 2.0152
2024-10-30 22:45:38: [2024-10-30 22:45:38] iter = 01860, loss = 2.2917
2024-10-30 22:45:41: [2024-10-30 22:45:41] iter = 01870, loss = 2.2273
2024-10-30 22:45:45: [2024-10-30 22:45:45] iter = 01880, loss = 2.5221
2024-10-30 22:45:49: [2024-10-30 22:45:49] iter = 01890, loss = 2.1767
2024-10-30 22:45:53: [2024-10-30 22:45:53] iter = 01900, loss = 2.2722
2024-10-30 22:45:56: [2024-10-30 22:45:56] iter = 01910, loss = 1.9629
2024-10-30 22:45:59: [2024-10-30 22:45:59] iter = 01920, loss = 1.9346
2024-10-30 22:46:03: [2024-10-30 22:46:03] iter = 01930, loss = 2.1820
2024-10-30 22:46:05: [2024-10-30 22:46:05] iter = 01940, loss = 2.4974
2024-10-30 22:46:09: [2024-10-30 22:46:09] iter = 01950, loss = 2.3659
2024-10-30 22:46:14: [2024-10-30 22:46:14] iter = 01960, loss = 2.2509
2024-10-30 22:46:17: [2024-10-30 22:46:17] iter = 01970, loss = 2.5221
2024-10-30 22:46:20: [2024-10-30 22:46:20] iter = 01980, loss = 2.2275
2024-10-30 22:46:23: [2024-10-30 22:46:23] iter = 01990, loss = 2.5858
2024-10-30 22:46:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 22:46:26: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:46:26: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 86415}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:48:40: Evaluate 5 random ConvNet, ACCmean = 0.7862 ACCstd = 0.0024
-------------------------
2024-10-30 22:48:40: Evaluate 5 random ConvNet, SENmean = 0.7802 SENstd = 0.0022
-------------------------
2024-10-30 22:48:40: Evaluate 5 random ConvNet, SPEmean = 0.9784 SPEstd = 0.0003
-------------------------
2024-10-30 22:48:40: Evaluate 5 random ConvNet, F!mean = 0.7720 F!std = 0.0023
-------------------------
2024-10-30 22:48:40: Evaluate 5 random ConvNet, mean = 0.7862 std = 0.0024
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:48:41: [2024-10-30 22:48:41] iter = 02000, loss = 2.5041
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:48:44: [2024-10-30 22:48:44] iter = 02010, loss = 2.0892
2024-10-30 22:48:48: [2024-10-30 22:48:48] iter = 02020, loss = 1.7270
2024-10-30 22:48:51: [2024-10-30 22:48:51] iter = 02030, loss = 1.8913
2024-10-30 22:48:55: [2024-10-30 22:48:55] iter = 02040, loss = 2.5550
2024-10-30 22:48:59: [2024-10-30 22:48:59] iter = 02050, loss = 2.8384
2024-10-30 22:49:02: [2024-10-30 22:49:02] iter = 02060, loss = 2.4484
2024-10-30 22:49:06: [2024-10-30 22:49:06] iter = 02070, loss = 1.9386
2024-10-30 22:49:08: [2024-10-30 22:49:08] iter = 02080, loss = 3.4998
2024-10-30 22:49:11: [2024-10-30 22:49:11] iter = 02090, loss = 2.4683
2024-10-30 22:49:15: [2024-10-30 22:49:15] iter = 02100, loss = 2.8573
2024-10-30 22:49:18: [2024-10-30 22:49:18] iter = 02110, loss = 1.6755
2024-10-30 22:49:21: [2024-10-30 22:49:21] iter = 02120, loss = 3.5426
2024-10-30 22:49:25: [2024-10-30 22:49:25] iter = 02130, loss = 3.4629
2024-10-30 22:49:29: [2024-10-30 22:49:29] iter = 02140, loss = 2.0295
2024-10-30 22:49:32: [2024-10-30 22:49:32] iter = 02150, loss = 2.1462
2024-10-30 22:49:35: [2024-10-30 22:49:35] iter = 02160, loss = 2.3927
2024-10-30 22:49:39: [2024-10-30 22:49:39] iter = 02170, loss = 1.7574
2024-10-30 22:49:43: [2024-10-30 22:49:43] iter = 02180, loss = 1.7955
2024-10-30 22:49:47: [2024-10-30 22:49:47] iter = 02190, loss = 1.9973
2024-10-30 22:49:50: [2024-10-30 22:49:50] iter = 02200, loss = 2.1369
2024-10-30 22:49:54: [2024-10-30 22:49:54] iter = 02210, loss = 2.3990
2024-10-30 22:49:57: [2024-10-30 22:49:57] iter = 02220, loss = 2.0833
2024-10-30 22:50:02: [2024-10-30 22:50:02] iter = 02230, loss = 2.0894
2024-10-30 22:50:05: [2024-10-30 22:50:04] iter = 02240, loss = 1.5968
2024-10-30 22:50:07: [2024-10-30 22:50:07] iter = 02250, loss = 1.9320
2024-10-30 22:50:10: [2024-10-30 22:50:10] iter = 02260, loss = 1.9156
2024-10-30 22:50:14: [2024-10-30 22:50:14] iter = 02270, loss = 2.3130
2024-10-30 22:50:18: [2024-10-30 22:50:18] iter = 02280, loss = 2.4595
2024-10-30 22:50:22: [2024-10-30 22:50:22] iter = 02290, loss = 3.0113
2024-10-30 22:50:25: [2024-10-30 22:50:25] iter = 02300, loss = 2.1695
2024-10-30 22:50:29: [2024-10-30 22:50:29] iter = 02310, loss = 2.6146
2024-10-30 22:50:32: [2024-10-30 22:50:32] iter = 02320, loss = 1.9701
2024-10-30 22:50:35: [2024-10-30 22:50:35] iter = 02330, loss = 1.9240
2024-10-30 22:50:38: [2024-10-30 22:50:38] iter = 02340, loss = 2.1906
2024-10-30 22:50:42: [2024-10-30 22:50:42] iter = 02350, loss = 2.2551
2024-10-30 22:50:45: [2024-10-30 22:50:45] iter = 02360, loss = 1.6421
2024-10-30 22:50:48: [2024-10-30 22:50:48] iter = 02370, loss = 2.7041
2024-10-30 22:50:51: [2024-10-30 22:50:51] iter = 02380, loss = 2.8571
2024-10-30 22:50:55: [2024-10-30 22:50:55] iter = 02390, loss = 3.2839
2024-10-30 22:50:58: [2024-10-30 22:50:58] iter = 02400, loss = 1.8811
2024-10-30 22:51:01: [2024-10-30 22:51:01] iter = 02410, loss = 1.8652
2024-10-30 22:51:03: [2024-10-30 22:51:03] iter = 02420, loss = 2.1257
2024-10-30 22:51:07: [2024-10-30 22:51:07] iter = 02430, loss = 1.7019
2024-10-30 22:51:11: [2024-10-30 22:51:11] iter = 02440, loss = 2.9754
2024-10-30 22:51:13: [2024-10-30 22:51:13] iter = 02450, loss = 1.8798
2024-10-30 22:51:17: [2024-10-30 22:51:17] iter = 02460, loss = 1.8096
2024-10-30 22:51:21: [2024-10-30 22:51:21] iter = 02470, loss = 1.8579
2024-10-30 22:51:25: [2024-10-30 22:51:25] iter = 02480, loss = 1.9655
2024-10-30 22:51:28: [2024-10-30 22:51:28] iter = 02490, loss = 2.8710
2024-10-30 22:51:31: [2024-10-30 22:51:31] iter = 02500, loss = 2.8926
2024-10-30 22:51:34: [2024-10-30 22:51:34] iter = 02510, loss = 1.8595
2024-10-30 22:51:37: [2024-10-30 22:51:37] iter = 02520, loss = 1.9081
2024-10-30 22:51:40: [2024-10-30 22:51:40] iter = 02530, loss = 2.6062
2024-10-30 22:51:43: [2024-10-30 22:51:43] iter = 02540, loss = 1.8684
2024-10-30 22:51:45: [2024-10-30 22:51:45] iter = 02550, loss = 2.2137
2024-10-30 22:51:49: [2024-10-30 22:51:49] iter = 02560, loss = 2.0261
2024-10-30 22:51:53: [2024-10-30 22:51:53] iter = 02570, loss = 2.2116
2024-10-30 22:51:57: [2024-10-30 22:51:57] iter = 02580, loss = 2.7080
2024-10-30 22:52:00: [2024-10-30 22:52:00] iter = 02590, loss = 1.8509
2024-10-30 22:52:02: [2024-10-30 22:52:02] iter = 02600, loss = 1.9326
2024-10-30 22:52:06: [2024-10-30 22:52:06] iter = 02610, loss = 2.4719
2024-10-30 22:52:08: [2024-10-30 22:52:08] iter = 02620, loss = 2.3558
2024-10-30 22:52:13: [2024-10-30 22:52:13] iter = 02630, loss = 2.2252
2024-10-30 22:52:16: [2024-10-30 22:52:16] iter = 02640, loss = 3.3332
2024-10-30 22:52:20: [2024-10-30 22:52:20] iter = 02650, loss = 2.3196
2024-10-30 22:52:23: [2024-10-30 22:52:23] iter = 02660, loss = 1.9379
2024-10-30 22:52:27: [2024-10-30 22:52:27] iter = 02670, loss = 2.0542
2024-10-30 22:52:30: [2024-10-30 22:52:30] iter = 02680, loss = 2.6577
2024-10-30 22:52:34: [2024-10-30 22:52:34] iter = 02690, loss = 2.0794
2024-10-30 22:52:38: [2024-10-30 22:52:38] iter = 02700, loss = 2.1764
2024-10-30 22:52:42: [2024-10-30 22:52:42] iter = 02710, loss = 2.1195
2024-10-30 22:52:45: [2024-10-30 22:52:45] iter = 02720, loss = 2.7736
2024-10-30 22:52:49: [2024-10-30 22:52:49] iter = 02730, loss = 1.9466
2024-10-30 22:52:53: [2024-10-30 22:52:53] iter = 02740, loss = 2.2630
2024-10-30 22:52:57: [2024-10-30 22:52:57] iter = 02750, loss = 1.8464
2024-10-30 22:53:00: [2024-10-30 22:53:00] iter = 02760, loss = 1.9936
2024-10-30 22:53:04: [2024-10-30 22:53:04] iter = 02770, loss = 3.6689
2024-10-30 22:53:07: [2024-10-30 22:53:07] iter = 02780, loss = 2.1812
2024-10-30 22:53:10: [2024-10-30 22:53:10] iter = 02790, loss = 1.9663
2024-10-30 22:53:14: [2024-10-30 22:53:14] iter = 02800, loss = 3.1080
2024-10-30 22:53:18: [2024-10-30 22:53:18] iter = 02810, loss = 2.2138
2024-10-30 22:53:21: [2024-10-30 22:53:21] iter = 02820, loss = 2.1942
2024-10-30 22:53:24: [2024-10-30 22:53:24] iter = 02830, loss = 2.3652
2024-10-30 22:53:28: [2024-10-30 22:53:28] iter = 02840, loss = 1.9434
2024-10-30 22:53:31: [2024-10-30 22:53:31] iter = 02850, loss = 2.1967
2024-10-30 22:53:34: [2024-10-30 22:53:34] iter = 02860, loss = 2.1991
2024-10-30 22:53:38: [2024-10-30 22:53:38] iter = 02870, loss = 2.1752
2024-10-30 22:53:42: [2024-10-30 22:53:42] iter = 02880, loss = 3.5379
2024-10-30 22:53:45: [2024-10-30 22:53:45] iter = 02890, loss = 2.2836
2024-10-30 22:53:49: [2024-10-30 22:53:49] iter = 02900, loss = 1.5669
2024-10-30 22:53:52: [2024-10-30 22:53:52] iter = 02910, loss = 2.3107
2024-10-30 22:53:56: [2024-10-30 22:53:56] iter = 02920, loss = 2.2590
2024-10-30 22:53:59: [2024-10-30 22:53:59] iter = 02930, loss = 2.9072
2024-10-30 22:54:02: [2024-10-30 22:54:02] iter = 02940, loss = 2.3691
2024-10-30 22:54:05: [2024-10-30 22:54:05] iter = 02950, loss = 2.8467
2024-10-30 22:54:09: [2024-10-30 22:54:09] iter = 02960, loss = 2.4975
2024-10-30 22:54:12: [2024-10-30 22:54:12] iter = 02970, loss = 2.8759
2024-10-30 22:54:16: [2024-10-30 22:54:16] iter = 02980, loss = 2.0198
2024-10-30 22:54:19: [2024-10-30 22:54:19] iter = 02990, loss = 1.8163
2024-10-30 22:54:23: [2024-10-30 22:54:23] iter = 03000, loss = 2.5509
2024-10-30 22:54:27: [2024-10-30 22:54:27] iter = 03010, loss = 1.7885
2024-10-30 22:54:30: [2024-10-30 22:54:30] iter = 03020, loss = 1.7899
2024-10-30 22:54:35: [2024-10-30 22:54:35] iter = 03030, loss = 1.7983
2024-10-30 22:54:39: [2024-10-30 22:54:39] iter = 03040, loss = 2.8283
2024-10-30 22:54:42: [2024-10-30 22:54:42] iter = 03050, loss = 2.3776
2024-10-30 22:54:46: [2024-10-30 22:54:46] iter = 03060, loss = 2.2234
2024-10-30 22:54:50: [2024-10-30 22:54:50] iter = 03070, loss = 2.1932
2024-10-30 22:54:53: [2024-10-30 22:54:53] iter = 03080, loss = 2.1446
2024-10-30 22:54:58: [2024-10-30 22:54:58] iter = 03090, loss = 1.6999
2024-10-30 22:55:02: [2024-10-30 22:55:02] iter = 03100, loss = 2.7223
2024-10-30 22:55:06: [2024-10-30 22:55:06] iter = 03110, loss = 2.2923
2024-10-30 22:55:11: [2024-10-30 22:55:11] iter = 03120, loss = 3.4780
2024-10-30 22:55:14: [2024-10-30 22:55:14] iter = 03130, loss = 1.8596
2024-10-30 22:55:18: [2024-10-30 22:55:18] iter = 03140, loss = 2.8318
2024-10-30 22:55:22: [2024-10-30 22:55:22] iter = 03150, loss = 2.0613
2024-10-30 22:55:25: [2024-10-30 22:55:25] iter = 03160, loss = 1.7634
2024-10-30 22:55:29: [2024-10-30 22:55:29] iter = 03170, loss = 2.0747
2024-10-30 22:55:32: [2024-10-30 22:55:32] iter = 03180, loss = 2.6096
2024-10-30 22:55:36: [2024-10-30 22:55:36] iter = 03190, loss = 1.8912
2024-10-30 22:55:40: [2024-10-30 22:55:40] iter = 03200, loss = 1.8652
2024-10-30 22:55:43: [2024-10-30 22:55:43] iter = 03210, loss = 2.6036
2024-10-30 22:55:47: [2024-10-30 22:55:47] iter = 03220, loss = 2.0661
2024-10-30 22:55:51: [2024-10-30 22:55:51] iter = 03230, loss = 1.8826
2024-10-30 22:55:54: [2024-10-30 22:55:54] iter = 03240, loss = 2.2426
2024-10-30 22:55:58: [2024-10-30 22:55:58] iter = 03250, loss = 1.9526
2024-10-30 22:56:01: [2024-10-30 22:56:01] iter = 03260, loss = 1.6493
2024-10-30 22:56:05: [2024-10-30 22:56:05] iter = 03270, loss = 1.6493
2024-10-30 22:56:09: [2024-10-30 22:56:09] iter = 03280, loss = 2.2882
2024-10-30 22:56:13: [2024-10-30 22:56:13] iter = 03290, loss = 2.1276
2024-10-30 22:56:16: [2024-10-30 22:56:16] iter = 03300, loss = 1.9543
2024-10-30 22:56:20: [2024-10-30 22:56:20] iter = 03310, loss = 3.3552
2024-10-30 22:56:23: [2024-10-30 22:56:23] iter = 03320, loss = 5.8210
2024-10-30 22:56:26: [2024-10-30 22:56:26] iter = 03330, loss = 2.0800
2024-10-30 22:56:29: [2024-10-30 22:56:29] iter = 03340, loss = 2.6991
2024-10-30 22:56:31: [2024-10-30 22:56:31] iter = 03350, loss = 1.8382
2024-10-30 22:56:34: [2024-10-30 22:56:34] iter = 03360, loss = 1.9513
2024-10-30 22:56:38: [2024-10-30 22:56:38] iter = 03370, loss = 2.0048
2024-10-30 22:56:42: [2024-10-30 22:56:42] iter = 03380, loss = 1.9720
2024-10-30 22:56:45: [2024-10-30 22:56:45] iter = 03390, loss = 2.1644
2024-10-30 22:56:49: [2024-10-30 22:56:49] iter = 03400, loss = 1.7247
2024-10-30 22:56:53: [2024-10-30 22:56:53] iter = 03410, loss = 1.5998
2024-10-30 22:56:57: [2024-10-30 22:56:57] iter = 03420, loss = 2.3489
2024-10-30 22:57:00: [2024-10-30 22:57:00] iter = 03430, loss = 2.3667
2024-10-30 22:57:05: [2024-10-30 22:57:05] iter = 03440, loss = 1.6814
2024-10-30 22:57:10: [2024-10-30 22:57:10] iter = 03450, loss = 1.9432
2024-10-30 22:57:15: [2024-10-30 22:57:15] iter = 03460, loss = 2.9070
2024-10-30 22:57:20: [2024-10-30 22:57:20] iter = 03470, loss = 2.7162
2024-10-30 22:57:25: [2024-10-30 22:57:25] iter = 03480, loss = 2.0671
2024-10-30 22:57:29: [2024-10-30 22:57:29] iter = 03490, loss = 2.1832
2024-10-30 22:57:33: [2024-10-30 22:57:33] iter = 03500, loss = 1.8203
2024-10-30 22:57:37: [2024-10-30 22:57:37] iter = 03510, loss = 1.8889
2024-10-30 22:57:41: [2024-10-30 22:57:41] iter = 03520, loss = 1.7990
2024-10-30 22:57:45: [2024-10-30 22:57:45] iter = 03530, loss = 3.3481
2024-10-30 22:57:50: [2024-10-30 22:57:50] iter = 03540, loss = 4.7830
2024-10-30 22:57:54: [2024-10-30 22:57:54] iter = 03550, loss = 2.1771
2024-10-30 22:57:58: [2024-10-30 22:57:58] iter = 03560, loss = 1.9333
2024-10-30 22:58:02: [2024-10-30 22:58:02] iter = 03570, loss = 1.9810
2024-10-30 22:58:05: [2024-10-30 22:58:05] iter = 03580, loss = 1.7661
2024-10-30 22:58:09: [2024-10-30 22:58:09] iter = 03590, loss = 2.1316
2024-10-30 22:58:12: [2024-10-30 22:58:12] iter = 03600, loss = 1.8298
2024-10-30 22:58:16: [2024-10-30 22:58:16] iter = 03610, loss = 3.3857
2024-10-30 22:58:19: [2024-10-30 22:58:19] iter = 03620, loss = 1.8757
2024-10-30 22:58:23: [2024-10-30 22:58:23] iter = 03630, loss = 2.0362
2024-10-30 22:58:27: [2024-10-30 22:58:27] iter = 03640, loss = 1.8565
2024-10-30 22:58:31: [2024-10-30 22:58:31] iter = 03650, loss = 2.0623
2024-10-30 22:58:35: [2024-10-30 22:58:35] iter = 03660, loss = 1.9731
2024-10-30 22:58:40: [2024-10-30 22:58:40] iter = 03670, loss = 1.8553
2024-10-30 22:58:45: [2024-10-30 22:58:45] iter = 03680, loss = 2.1171
2024-10-30 22:58:49: [2024-10-30 22:58:49] iter = 03690, loss = 2.0554
2024-10-30 22:58:52: [2024-10-30 22:58:52] iter = 03700, loss = 2.9356
2024-10-30 22:58:57: [2024-10-30 22:58:57] iter = 03710, loss = 2.4476
2024-10-30 22:59:02: [2024-10-30 22:59:02] iter = 03720, loss = 2.0741
2024-10-30 22:59:06: [2024-10-30 22:59:06] iter = 03730, loss = 2.0499
2024-10-30 22:59:10: [2024-10-30 22:59:10] iter = 03740, loss = 2.5053
2024-10-30 22:59:13: [2024-10-30 22:59:13] iter = 03750, loss = 1.7876
2024-10-30 22:59:16: [2024-10-30 22:59:16] iter = 03760, loss = 1.7193
2024-10-30 22:59:20: [2024-10-30 22:59:20] iter = 03770, loss = 1.7947
2024-10-30 22:59:24: [2024-10-30 22:59:24] iter = 03780, loss = 2.0896
2024-10-30 22:59:29: [2024-10-30 22:59:29] iter = 03790, loss = 2.0922
2024-10-30 22:59:33: [2024-10-30 22:59:33] iter = 03800, loss = 1.6587
2024-10-30 22:59:37: [2024-10-30 22:59:37] iter = 03810, loss = 1.8236
2024-10-30 22:59:41: [2024-10-30 22:59:41] iter = 03820, loss = 2.3474
2024-10-30 22:59:44: [2024-10-30 22:59:44] iter = 03830, loss = 3.2554
2024-10-30 22:59:47: [2024-10-30 22:59:47] iter = 03840, loss = 2.4510
2024-10-30 22:59:50: [2024-10-30 22:59:50] iter = 03850, loss = 1.8576
2024-10-30 22:59:54: [2024-10-30 22:59:54] iter = 03860, loss = 1.9770
2024-10-30 22:59:57: [2024-10-30 22:59:57] iter = 03870, loss = 1.9285
2024-10-30 23:00:01: [2024-10-30 23:00:00] iter = 03880, loss = 1.8481
2024-10-30 23:00:04: [2024-10-30 23:00:04] iter = 03890, loss = 1.8988
2024-10-30 23:00:08: [2024-10-30 23:00:08] iter = 03900, loss = 2.1228
2024-10-30 23:00:12: [2024-10-30 23:00:12] iter = 03910, loss = 1.9397
2024-10-30 23:00:15: [2024-10-30 23:00:15] iter = 03920, loss = 2.1796
2024-10-30 23:00:19: [2024-10-30 23:00:19] iter = 03930, loss = 2.0981
2024-10-30 23:00:23: [2024-10-30 23:00:23] iter = 03940, loss = 2.6429
2024-10-30 23:00:28: [2024-10-30 23:00:28] iter = 03950, loss = 1.8726
2024-10-30 23:00:33: [2024-10-30 23:00:33] iter = 03960, loss = 1.8518
2024-10-30 23:00:37: [2024-10-30 23:00:37] iter = 03970, loss = 1.8947
2024-10-30 23:00:41: [2024-10-30 23:00:41] iter = 03980, loss = 2.5842
2024-10-30 23:00:45: [2024-10-30 23:00:45] iter = 03990, loss = 1.8406
2024-10-30 23:00:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 23:00:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:00:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49563}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:03:09: Evaluate 5 random ConvNet, ACCmean = 0.7918 ACCstd = 0.0021
-------------------------
2024-10-30 23:03:09: Evaluate 5 random ConvNet, SENmean = 0.7861 SENstd = 0.0012
-------------------------
2024-10-30 23:03:09: Evaluate 5 random ConvNet, SPEmean = 0.9790 SPEstd = 0.0002
-------------------------
2024-10-30 23:03:09: Evaluate 5 random ConvNet, F!mean = 0.7791 F!std = 0.0021
-------------------------
2024-10-30 23:03:09: Evaluate 5 random ConvNet, mean = 0.7918 std = 0.0021
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:03:10: [2024-10-30 23:03:10] iter = 04000, loss = 1.8370
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:03:13: [2024-10-30 23:03:13] iter = 04010, loss = 1.9691
2024-10-30 23:03:17: [2024-10-30 23:03:17] iter = 04020, loss = 1.9203
2024-10-30 23:03:21: [2024-10-30 23:03:21] iter = 04030, loss = 2.7224
2024-10-30 23:03:25: [2024-10-30 23:03:25] iter = 04040, loss = 2.2170
2024-10-30 23:03:28: [2024-10-30 23:03:28] iter = 04050, loss = 2.0108
2024-10-30 23:03:31: [2024-10-30 23:03:31] iter = 04060, loss = 2.7640
2024-10-30 23:03:35: [2024-10-30 23:03:35] iter = 04070, loss = 1.7579
2024-10-30 23:03:38: [2024-10-30 23:03:38] iter = 04080, loss = 2.1409
2024-10-30 23:03:41: [2024-10-30 23:03:41] iter = 04090, loss = 2.3290
2024-10-30 23:03:44: [2024-10-30 23:03:44] iter = 04100, loss = 2.4849
2024-10-30 23:03:47: [2024-10-30 23:03:47] iter = 04110, loss = 2.1003
2024-10-30 23:03:51: [2024-10-30 23:03:51] iter = 04120, loss = 1.9790
2024-10-30 23:03:54: [2024-10-30 23:03:54] iter = 04130, loss = 2.0033
2024-10-30 23:03:58: [2024-10-30 23:03:58] iter = 04140, loss = 2.2930
2024-10-30 23:04:02: [2024-10-30 23:04:02] iter = 04150, loss = 2.8791
2024-10-30 23:04:06: [2024-10-30 23:04:06] iter = 04160, loss = 1.7262
2024-10-30 23:04:10: [2024-10-30 23:04:10] iter = 04170, loss = 1.8633
2024-10-30 23:04:13: [2024-10-30 23:04:13] iter = 04180, loss = 1.8382
2024-10-30 23:04:17: [2024-10-30 23:04:17] iter = 04190, loss = 2.0628
2024-10-30 23:04:21: [2024-10-30 23:04:21] iter = 04200, loss = 2.5609
2024-10-30 23:04:25: [2024-10-30 23:04:25] iter = 04210, loss = 2.6767
2024-10-30 23:04:28: [2024-10-30 23:04:28] iter = 04220, loss = 1.8619
2024-10-30 23:04:32: [2024-10-30 23:04:32] iter = 04230, loss = 5.0020
2024-10-30 23:04:35: [2024-10-30 23:04:35] iter = 04240, loss = 2.4978
2024-10-30 23:04:38: [2024-10-30 23:04:38] iter = 04250, loss = 2.3020
2024-10-30 23:04:42: [2024-10-30 23:04:42] iter = 04260, loss = 2.9069
2024-10-30 23:04:45: [2024-10-30 23:04:45] iter = 04270, loss = 2.0833
2024-10-30 23:04:49: [2024-10-30 23:04:49] iter = 04280, loss = 1.9685
2024-10-30 23:04:52: [2024-10-30 23:04:52] iter = 04290, loss = 1.6407
2024-10-30 23:04:56: [2024-10-30 23:04:56] iter = 04300, loss = 2.0060
2024-10-30 23:04:59: [2024-10-30 23:04:59] iter = 04310, loss = 1.8978
2024-10-30 23:05:02: [2024-10-30 23:05:02] iter = 04320, loss = 2.2682
2024-10-30 23:05:06: [2024-10-30 23:05:06] iter = 04330, loss = 2.3390
2024-10-30 23:05:09: [2024-10-30 23:05:09] iter = 04340, loss = 2.1533
2024-10-30 23:05:13: [2024-10-30 23:05:13] iter = 04350, loss = 2.1408
2024-10-30 23:05:17: [2024-10-30 23:05:17] iter = 04360, loss = 2.9065
2024-10-30 23:05:21: [2024-10-30 23:05:21] iter = 04370, loss = 2.0438
2024-10-30 23:05:24: [2024-10-30 23:05:24] iter = 04380, loss = 1.9458
2024-10-30 23:05:28: [2024-10-30 23:05:28] iter = 04390, loss = 1.9966
2024-10-30 23:05:32: [2024-10-30 23:05:32] iter = 04400, loss = 2.1835
2024-10-30 23:05:35: [2024-10-30 23:05:35] iter = 04410, loss = 1.8017
2024-10-30 23:05:38: [2024-10-30 23:05:38] iter = 04420, loss = 2.0374
2024-10-30 23:05:42: [2024-10-30 23:05:42] iter = 04430, loss = 2.4878
2024-10-30 23:05:44: [2024-10-30 23:05:44] iter = 04440, loss = 1.9872
2024-10-30 23:05:48: [2024-10-30 23:05:48] iter = 04450, loss = 4.5834
2024-10-30 23:05:51: [2024-10-30 23:05:51] iter = 04460, loss = 2.5182
2024-10-30 23:05:54: [2024-10-30 23:05:54] iter = 04470, loss = 3.0930
2024-10-30 23:05:58: [2024-10-30 23:05:58] iter = 04480, loss = 1.7007
2024-10-30 23:06:01: [2024-10-30 23:06:01] iter = 04490, loss = 2.8596
2024-10-30 23:06:04: [2024-10-30 23:06:04] iter = 04500, loss = 2.6040
2024-10-30 23:06:07: [2024-10-30 23:06:07] iter = 04510, loss = 2.4677
2024-10-30 23:06:10: [2024-10-30 23:06:10] iter = 04520, loss = 1.7021
2024-10-30 23:06:14: [2024-10-30 23:06:14] iter = 04530, loss = 2.1732
2024-10-30 23:06:18: [2024-10-30 23:06:18] iter = 04540, loss = 1.9997
2024-10-30 23:06:22: [2024-10-30 23:06:22] iter = 04550, loss = 1.8022
2024-10-30 23:06:25: [2024-10-30 23:06:25] iter = 04560, loss = 2.6545
2024-10-30 23:06:29: [2024-10-30 23:06:29] iter = 04570, loss = 2.4730
2024-10-30 23:06:33: [2024-10-30 23:06:33] iter = 04580, loss = 2.2007
2024-10-30 23:06:38: [2024-10-30 23:06:38] iter = 04590, loss = 2.2495
2024-10-30 23:06:40: [2024-10-30 23:06:40] iter = 04600, loss = 2.0628
2024-10-30 23:06:43: [2024-10-30 23:06:43] iter = 04610, loss = 2.9504
2024-10-30 23:06:47: [2024-10-30 23:06:47] iter = 04620, loss = 2.0764
2024-10-30 23:06:50: [2024-10-30 23:06:50] iter = 04630, loss = 1.8863
2024-10-30 23:06:52: [2024-10-30 23:06:52] iter = 04640, loss = 2.6610
2024-10-30 23:06:55: [2024-10-30 23:06:55] iter = 04650, loss = 1.8366
2024-10-30 23:06:59: [2024-10-30 23:06:59] iter = 04660, loss = 2.3530
2024-10-30 23:07:02: [2024-10-30 23:07:02] iter = 04670, loss = 1.7536
2024-10-30 23:07:05: [2024-10-30 23:07:05] iter = 04680, loss = 2.6528
2024-10-30 23:07:09: [2024-10-30 23:07:09] iter = 04690, loss = 2.0167
2024-10-30 23:07:13: [2024-10-30 23:07:13] iter = 04700, loss = 2.2032
2024-10-30 23:07:18: [2024-10-30 23:07:18] iter = 04710, loss = 2.5041
2024-10-30 23:07:21: [2024-10-30 23:07:21] iter = 04720, loss = 2.2520
2024-10-30 23:07:25: [2024-10-30 23:07:25] iter = 04730, loss = 1.9437
2024-10-30 23:07:28: [2024-10-30 23:07:28] iter = 04740, loss = 1.8781
2024-10-30 23:07:32: [2024-10-30 23:07:32] iter = 04750, loss = 1.9365
2024-10-30 23:07:35: [2024-10-30 23:07:35] iter = 04760, loss = 2.1245
2024-10-30 23:07:39: [2024-10-30 23:07:39] iter = 04770, loss = 1.8652
2024-10-30 23:07:43: [2024-10-30 23:07:43] iter = 04780, loss = 2.3610
2024-10-30 23:07:47: [2024-10-30 23:07:47] iter = 04790, loss = 2.1579
2024-10-30 23:07:51: [2024-10-30 23:07:51] iter = 04800, loss = 2.8065
2024-10-30 23:07:54: [2024-10-30 23:07:54] iter = 04810, loss = 2.9680
2024-10-30 23:07:58: [2024-10-30 23:07:58] iter = 04820, loss = 1.8846
2024-10-30 23:08:00: [2024-10-30 23:08:00] iter = 04830, loss = 2.3292
2024-10-30 23:08:03: [2024-10-30 23:08:03] iter = 04840, loss = 2.0102
2024-10-30 23:08:07: [2024-10-30 23:08:07] iter = 04850, loss = 4.2931
2024-10-30 23:08:10: [2024-10-30 23:08:10] iter = 04860, loss = 2.2625
2024-10-30 23:08:15: [2024-10-30 23:08:15] iter = 04870, loss = 2.6832
2024-10-30 23:08:18: [2024-10-30 23:08:18] iter = 04880, loss = 2.6008
2024-10-30 23:08:22: [2024-10-30 23:08:22] iter = 04890, loss = 2.1812
2024-10-30 23:08:26: [2024-10-30 23:08:26] iter = 04900, loss = 2.2578
2024-10-30 23:08:30: [2024-10-30 23:08:30] iter = 04910, loss = 2.7083
2024-10-30 23:08:34: [2024-10-30 23:08:34] iter = 04920, loss = 2.4005
2024-10-30 23:08:38: [2024-10-30 23:08:38] iter = 04930, loss = 1.6267
2024-10-30 23:08:41: [2024-10-30 23:08:41] iter = 04940, loss = 2.1666
2024-10-30 23:08:45: [2024-10-30 23:08:45] iter = 04950, loss = 1.8913
2024-10-30 23:08:49: [2024-10-30 23:08:49] iter = 04960, loss = 1.9951
2024-10-30 23:08:52: [2024-10-30 23:08:52] iter = 04970, loss = 2.1193
2024-10-30 23:08:56: [2024-10-30 23:08:56] iter = 04980, loss = 1.7860
2024-10-30 23:08:59: [2024-10-30 23:08:59] iter = 04990, loss = 1.9934
2024-10-30 23:09:02: [2024-10-30 23:09:02] iter = 05000, loss = 2.1752
2024-10-30 23:09:05: [2024-10-30 23:09:05] iter = 05010, loss = 2.1557
2024-10-30 23:09:09: [2024-10-30 23:09:09] iter = 05020, loss = 2.1131
2024-10-30 23:09:13: [2024-10-30 23:09:13] iter = 05030, loss = 2.0164
2024-10-30 23:09:16: [2024-10-30 23:09:16] iter = 05040, loss = 1.8275
2024-10-30 23:09:20: [2024-10-30 23:09:20] iter = 05050, loss = 3.2808
2024-10-30 23:09:24: [2024-10-30 23:09:24] iter = 05060, loss = 2.0578
2024-10-30 23:09:28: [2024-10-30 23:09:28] iter = 05070, loss = 1.9485
2024-10-30 23:09:31: [2024-10-30 23:09:31] iter = 05080, loss = 2.9451
2024-10-30 23:09:35: [2024-10-30 23:09:35] iter = 05090, loss = 1.7517
2024-10-30 23:09:38: [2024-10-30 23:09:38] iter = 05100, loss = 2.1793
2024-10-30 23:09:41: [2024-10-30 23:09:41] iter = 05110, loss = 1.5945
2024-10-30 23:09:45: [2024-10-30 23:09:45] iter = 05120, loss = 2.5413
2024-10-30 23:09:48: [2024-10-30 23:09:48] iter = 05130, loss = 2.4957
2024-10-30 23:09:51: [2024-10-30 23:09:51] iter = 05140, loss = 2.0488
2024-10-30 23:09:55: [2024-10-30 23:09:55] iter = 05150, loss = 1.8757
2024-10-30 23:09:58: [2024-10-30 23:09:58] iter = 05160, loss = 5.5731
2024-10-30 23:10:01: [2024-10-30 23:10:01] iter = 05170, loss = 1.9770
2024-10-30 23:10:05: [2024-10-30 23:10:05] iter = 05180, loss = 2.2541
2024-10-30 23:10:09: [2024-10-30 23:10:09] iter = 05190, loss = 2.9853
2024-10-30 23:10:13: [2024-10-30 23:10:13] iter = 05200, loss = 1.7794
2024-10-30 23:10:17: [2024-10-30 23:10:17] iter = 05210, loss = 3.1475
2024-10-30 23:10:21: [2024-10-30 23:10:21] iter = 05220, loss = 2.3414
2024-10-30 23:10:25: [2024-10-30 23:10:25] iter = 05230, loss = 2.0770
2024-10-30 23:10:28: [2024-10-30 23:10:28] iter = 05240, loss = 2.3177
2024-10-30 23:10:31: [2024-10-30 23:10:31] iter = 05250, loss = 2.0306
2024-10-30 23:10:35: [2024-10-30 23:10:35] iter = 05260, loss = 2.3118
2024-10-30 23:10:37: [2024-10-30 23:10:37] iter = 05270, loss = 2.1429
2024-10-30 23:10:41: [2024-10-30 23:10:41] iter = 05280, loss = 1.9963
2024-10-30 23:10:44: [2024-10-30 23:10:44] iter = 05290, loss = 2.6114
2024-10-30 23:10:49: [2024-10-30 23:10:49] iter = 05300, loss = 1.7213
2024-10-30 23:10:52: [2024-10-30 23:10:52] iter = 05310, loss = 2.5362
2024-10-30 23:10:56: [2024-10-30 23:10:56] iter = 05320, loss = 1.8351
2024-10-30 23:10:59: [2024-10-30 23:10:59] iter = 05330, loss = 1.9554
2024-10-30 23:11:01: [2024-10-30 23:11:01] iter = 05340, loss = 3.3563
2024-10-30 23:11:03: [2024-10-30 23:11:03] iter = 05350, loss = 2.1679
2024-10-30 23:11:06: [2024-10-30 23:11:06] iter = 05360, loss = 2.7011
2024-10-30 23:11:08: [2024-10-30 23:11:08] iter = 05370, loss = 2.3664
2024-10-30 23:11:11: [2024-10-30 23:11:11] iter = 05380, loss = 2.0665
2024-10-30 23:11:15: [2024-10-30 23:11:15] iter = 05390, loss = 1.8517
2024-10-30 23:11:18: [2024-10-30 23:11:18] iter = 05400, loss = 2.9436
2024-10-30 23:11:22: [2024-10-30 23:11:22] iter = 05410, loss = 2.5443
2024-10-30 23:11:25: [2024-10-30 23:11:25] iter = 05420, loss = 2.0269
2024-10-30 23:11:28: [2024-10-30 23:11:28] iter = 05430, loss = 2.3408
2024-10-30 23:11:32: [2024-10-30 23:11:32] iter = 05440, loss = 2.0482
2024-10-30 23:11:35: [2024-10-30 23:11:35] iter = 05450, loss = 2.0361
2024-10-30 23:11:39: [2024-10-30 23:11:39] iter = 05460, loss = 3.2786
2024-10-30 23:11:43: [2024-10-30 23:11:43] iter = 05470, loss = 2.1659
2024-10-30 23:11:47: [2024-10-30 23:11:47] iter = 05480, loss = 2.0364
2024-10-30 23:11:51: [2024-10-30 23:11:51] iter = 05490, loss = 2.8939
2024-10-30 23:11:55: [2024-10-30 23:11:55] iter = 05500, loss = 2.2220
2024-10-30 23:11:59: [2024-10-30 23:11:59] iter = 05510, loss = 2.3151
2024-10-30 23:12:04: [2024-10-30 23:12:04] iter = 05520, loss = 1.8687
2024-10-30 23:12:07: [2024-10-30 23:12:07] iter = 05530, loss = 2.7348
2024-10-30 23:12:11: [2024-10-30 23:12:11] iter = 05540, loss = 1.8372
2024-10-30 23:12:14: [2024-10-30 23:12:14] iter = 05550, loss = 1.9071
2024-10-30 23:12:17: [2024-10-30 23:12:17] iter = 05560, loss = 2.4877
2024-10-30 23:12:20: [2024-10-30 23:12:20] iter = 05570, loss = 2.2305
2024-10-30 23:12:23: [2024-10-30 23:12:23] iter = 05580, loss = 2.1952
2024-10-30 23:12:26: [2024-10-30 23:12:26] iter = 05590, loss = 2.0475
2024-10-30 23:12:29: [2024-10-30 23:12:29] iter = 05600, loss = 1.9460
2024-10-30 23:12:33: [2024-10-30 23:12:33] iter = 05610, loss = 2.2435
2024-10-30 23:12:36: [2024-10-30 23:12:36] iter = 05620, loss = 2.4618
2024-10-30 23:12:40: [2024-10-30 23:12:40] iter = 05630, loss = 2.0082
2024-10-30 23:12:44: [2024-10-30 23:12:44] iter = 05640, loss = 2.8360
2024-10-30 23:12:47: [2024-10-30 23:12:47] iter = 05650, loss = 2.3519
2024-10-30 23:12:51: [2024-10-30 23:12:51] iter = 05660, loss = 2.3985
2024-10-30 23:12:56: [2024-10-30 23:12:56] iter = 05670, loss = 2.2180
2024-10-30 23:13:00: [2024-10-30 23:13:00] iter = 05680, loss = 1.8493
2024-10-30 23:13:03: [2024-10-30 23:13:03] iter = 05690, loss = 2.6612
2024-10-30 23:13:07: [2024-10-30 23:13:07] iter = 05700, loss = 2.1752
2024-10-30 23:13:11: [2024-10-30 23:13:11] iter = 05710, loss = 2.1994
2024-10-30 23:13:14: [2024-10-30 23:13:14] iter = 05720, loss = 1.8762
2024-10-30 23:13:18: [2024-10-30 23:13:18] iter = 05730, loss = 2.0654
2024-10-30 23:13:21: [2024-10-30 23:13:21] iter = 05740, loss = 1.7643
2024-10-30 23:13:24: [2024-10-30 23:13:24] iter = 05750, loss = 2.0658
2024-10-30 23:13:28: [2024-10-30 23:13:28] iter = 05760, loss = 1.7632
2024-10-30 23:13:30: [2024-10-30 23:13:30] iter = 05770, loss = 1.7595
2024-10-30 23:13:33: [2024-10-30 23:13:33] iter = 05780, loss = 2.0471
2024-10-30 23:13:37: [2024-10-30 23:13:37] iter = 05790, loss = 2.2385
2024-10-30 23:13:41: [2024-10-30 23:13:41] iter = 05800, loss = 1.9394
2024-10-30 23:13:44: [2024-10-30 23:13:44] iter = 05810, loss = 1.8820
2024-10-30 23:13:48: [2024-10-30 23:13:48] iter = 05820, loss = 2.0769
2024-10-30 23:13:51: [2024-10-30 23:13:51] iter = 05830, loss = 2.5963
2024-10-30 23:13:55: [2024-10-30 23:13:55] iter = 05840, loss = 2.1283
2024-10-30 23:13:58: [2024-10-30 23:13:58] iter = 05850, loss = 2.0137
2024-10-30 23:14:01: [2024-10-30 23:14:01] iter = 05860, loss = 2.3814
2024-10-30 23:14:05: [2024-10-30 23:14:05] iter = 05870, loss = 1.8803
2024-10-30 23:14:08: [2024-10-30 23:14:08] iter = 05880, loss = 1.9623
2024-10-30 23:14:11: [2024-10-30 23:14:11] iter = 05890, loss = 2.3623
2024-10-30 23:14:14: [2024-10-30 23:14:14] iter = 05900, loss = 2.0303
2024-10-30 23:14:18: [2024-10-30 23:14:18] iter = 05910, loss = 1.9210
2024-10-30 23:14:22: [2024-10-30 23:14:22] iter = 05920, loss = 1.6622
2024-10-30 23:14:26: [2024-10-30 23:14:26] iter = 05930, loss = 1.7683
2024-10-30 23:14:30: [2024-10-30 23:14:30] iter = 05940, loss = 1.8942
2024-10-30 23:14:33: [2024-10-30 23:14:33] iter = 05950, loss = 2.1489
2024-10-30 23:14:36: [2024-10-30 23:14:36] iter = 05960, loss = 1.9875
2024-10-30 23:14:39: [2024-10-30 23:14:39] iter = 05970, loss = 1.7968
2024-10-30 23:14:43: [2024-10-30 23:14:43] iter = 05980, loss = 2.8889
2024-10-30 23:14:47: [2024-10-30 23:14:47] iter = 05990, loss = 3.7150
2024-10-30 23:14:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 23:14:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:14:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 90043}

[2024-10-30 21:15:46] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.010516 train acc = 1.0000, test acc = 0.7885, test_sen =0.7819, test_spe =0.9787, test_f1 =0.7748
[2024-10-30 21:16:11] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.004303 train acc = 1.0000, test acc = 0.7885, test_sen =0.7810, test_spe =0.9786, test_f1 =0.7743
[2024-10-30 21:16:40] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.004087 train acc = 1.0000, test acc = 0.7830, test_sen =0.7788, test_spe =0.9781, test_f1 =0.7710
[2024-10-30 21:29:47] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.003784 train acc = 1.0000, test acc = 0.7816, test_sen =0.7747, test_spe =0.9779, test_f1 =0.7691
[2024-10-30 21:30:18] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.014472 train acc = 1.0000, test acc = 0.7799, test_sen =0.7722, test_spe =0.9777, test_f1 =0.7674
[2024-10-30 21:30:47] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.019794 train acc = 1.0000, test acc = 0.7843, test_sen =0.7759, test_spe =0.9781, test_f1 =0.7718
[2024-10-30 21:31:18] Evaluate_03: epoch = 1000 train time = 30 s train loss = 0.009533 train acc = 1.0000, test acc = 0.7720, test_sen =0.7620, test_spe =0.9769, test_f1 =0.7581
[2024-10-30 21:31:51] Evaluate_04: epoch = 1000 train time = 32 s train loss = 0.006038 train acc = 1.0000, test acc = 0.7865, test_sen =0.7762, test_spe =0.9784, test_f1 =0.7730
[2024-10-30 21:44:59] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.014052 train acc = 1.0000, test acc = 0.7787, test_sen =0.7786, test_spe =0.9777, test_f1 =0.7700
[2024-10-30 21:45:29] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.019660 train acc = 1.0000, test acc = 0.7748, test_sen =0.7755, test_spe =0.9772, test_f1 =0.7671
[2024-10-30 21:45:59] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.025538 train acc = 1.0000, test acc = 0.7799, test_sen =0.7778, test_spe =0.9778, test_f1 =0.7691
[2024-10-30 21:46:31] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.001713 train acc = 1.0000, test acc = 0.7798, test_sen =0.7807, test_spe =0.9777, test_f1 =0.7714
[2024-10-30 21:47:00] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.002824 train acc = 1.0000, test acc = 0.7712, test_sen =0.7728, test_spe =0.9769, test_f1 =0.7631
[2024-10-30 22:00:50] Evaluate_00: epoch = 1000 train time = 38 s train loss = 0.002110 train acc = 1.0000, test acc = 0.7876, test_sen =0.7826, test_spe =0.9785, test_f1 =0.7761
[2024-10-30 22:01:30] Evaluate_01: epoch = 1000 train time = 39 s train loss = 0.033097 train acc = 1.0000, test acc = 0.7813, test_sen =0.7735, test_spe =0.9778, test_f1 =0.7706
[2024-10-30 22:02:08] Evaluate_02: epoch = 1000 train time = 36 s train loss = 0.021150 train acc = 1.0000, test acc = 0.7820, test_sen =0.7790, test_spe =0.9779, test_f1 =0.7733
[2024-10-30 22:02:38] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.022771 train acc = 1.0000, test acc = 0.7790, test_sen =0.7749, test_spe =0.9776, test_f1 =0.7684
[2024-10-30 22:03:10] Evaluate_04: epoch = 1000 train time = 30 s train loss = 0.003068 train acc = 1.0000, test acc = 0.7804, test_sen =0.7761, test_spe =0.9778, test_f1 =0.7689
[2024-10-30 22:15:59] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.006813 train acc = 1.0000, test acc = 0.7853, test_sen =0.7784, test_spe =0.9782, test_f1 =0.7735
[2024-10-30 22:16:29] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.002101 train acc = 1.0000, test acc = 0.7843, test_sen =0.7770, test_spe =0.9781, test_f1 =0.7723
[2024-10-30 22:16:56] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.002967 train acc = 1.0000, test acc = 0.7823, test_sen =0.7746, test_spe =0.9780, test_f1 =0.7692
[2024-10-30 22:17:25] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.008505 train acc = 1.0000, test acc = 0.7833, test_sen =0.7770, test_spe =0.9781, test_f1 =0.7701
[2024-10-30 22:17:58] Evaluate_04: epoch = 1000 train time = 31 s train loss = 0.002318 train acc = 1.0000, test acc = 0.7824, test_sen =0.7749, test_spe =0.9780, test_f1 =0.7697
[2024-10-30 22:30:47] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.017068 train acc = 1.0000, test acc = 0.7770, test_sen =0.7757, test_spe =0.9775, test_f1 =0.7666
[2024-10-30 22:31:15] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.003226 train acc = 1.0000, test acc = 0.7742, test_sen =0.7749, test_spe =0.9772, test_f1 =0.7648
[2024-10-30 22:31:45] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.004271 train acc = 1.0000, test acc = 0.7859, test_sen =0.7814, test_spe =0.9783, test_f1 =0.7767
[2024-10-30 22:32:11] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.004149 train acc = 1.0000, test acc = 0.7820, test_sen =0.7782, test_spe =0.9780, test_f1 =0.7698
[2024-10-30 22:32:40] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.010960 train acc = 1.0000, test acc = 0.7757, test_sen =0.7758, test_spe =0.9774, test_f1 =0.7661
[2024-10-30 22:33:11] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.013644 train acc = 1.0000, test acc = 0.6974, test_sen =0.6895, test_spe =0.9694, test_f1 =0.6853
[2024-10-30 22:33:39] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.009963 train acc = 1.0000, test acc = 0.6951, test_sen =0.6905, test_spe =0.9693, test_f1 =0.6843
[2024-10-30 22:34:07] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.001784 train acc = 1.0000, test acc = 0.6972, test_sen =0.6900, test_spe =0.9694, test_f1 =0.6851
[2024-10-30 22:34:35] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.010815 train acc = 1.0000, test acc = 0.6918, test_sen =0.6842, test_spe =0.9689, test_f1 =0.6814
[2024-10-30 22:35:03] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.013758 train acc = 1.0000, test acc = 0.7062, test_sen =0.6973, test_spe =0.9703, test_f1 =0.6930
[2024-10-30 22:46:52] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.005388 train acc = 1.0000, test acc = 0.7823, test_sen =0.7769, test_spe =0.9780, test_f1 =0.7681
[2024-10-30 22:47:20] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.011898 train acc = 1.0000, test acc = 0.7888, test_sen =0.7823, test_spe =0.9787, test_f1 =0.7736
[2024-10-30 22:47:46] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.003143 train acc = 1.0000, test acc = 0.7868, test_sen =0.7813, test_spe =0.9785, test_f1 =0.7726
[2024-10-30 22:48:13] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.006361 train acc = 1.0000, test acc = 0.7885, test_sen =0.7822, test_spe =0.9787, test_f1 =0.7748
[2024-10-30 22:48:40] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.020982 train acc = 1.0000, test acc = 0.7848, test_sen =0.7785, test_spe =0.9783, test_f1 =0.7711
[2024-10-30 23:01:21] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.004312 train acc = 1.0000, test acc = 0.7944, test_sen =0.7876, test_spe =0.9792, test_f1 =0.7823
[2024-10-30 23:01:51] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.003736 train acc = 1.0000, test acc = 0.7941, test_sen =0.7867, test_spe =0.9792, test_f1 =0.7810
[2024-10-30 23:02:19] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.005206 train acc = 1.0000, test acc = 0.7915, test_sen =0.7871, test_spe =0.9790, test_f1 =0.7782
[2024-10-30 23:02:42] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.010083 train acc = 1.0000, test acc = 0.7893, test_sen =0.7848, test_spe =0.9788, test_f1 =0.7772
[2024-10-30 23:03:09] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.002947 train acc = 1.0000, test acc = 0.7899, test_sen =0.7845, test_spe =0.9788, test_f1 =0.7771
[2024-10-30 23:15:15] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.003102 train acc = 1.0000, test acc = 0.7734, test_sen =0.7712, test_spe =0.9771, test_f1 =0.7596
[2024-10-30 23:15:38] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.003263 train acc = 1.0000, test acc = 0.7830, test_sen =0.7775, test_spe =0.9781, test_f1 =0.7687
[2024-10-30 23:16:04] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.011370 train acc = 1.0000, test acc = 0.7810, test_sen =0.7792, test_spe =0.9779, test_f1 =0.7678/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:16:56: Evaluate 5 random ConvNet, ACCmean = 0.7789 ACCstd = 0.0033
-------------------------
2024-10-30 23:16:56: Evaluate 5 random ConvNet, SENmean = 0.7758 SENstd = 0.0029
-------------------------
2024-10-30 23:16:56: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0003
-------------------------
2024-10-30 23:16:56: Evaluate 5 random ConvNet, F!mean = 0.7654 F!std = 0.0033
-------------------------
2024-10-30 23:16:56: Evaluate 5 random ConvNet, mean = 0.7789 std = 0.0033
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:16:57: [2024-10-30 23:16:57] iter = 06000, loss = 2.0267
2024-10-30 23:17:01: [2024-10-30 23:17:01] iter = 06010, loss = 2.1570
2024-10-30 23:17:04: [2024-10-30 23:17:04] iter = 06020, loss = 2.0113
2024-10-30 23:17:07: [2024-10-30 23:17:07] iter = 06030, loss = 2.6668
2024-10-30 23:17:11: [2024-10-30 23:17:11] iter = 06040, loss = 1.6452
2024-10-30 23:17:14: [2024-10-30 23:17:14] iter = 06050, loss = 2.4520
2024-10-30 23:17:17: [2024-10-30 23:17:17] iter = 06060, loss = 1.7323
2024-10-30 23:17:20: [2024-10-30 23:17:20] iter = 06070, loss = 3.1611
2024-10-30 23:17:23: [2024-10-30 23:17:23] iter = 06080, loss = 1.9532
2024-10-30 23:17:25: [2024-10-30 23:17:25] iter = 06090, loss = 1.7262
2024-10-30 23:17:27: [2024-10-30 23:17:27] iter = 06100, loss = 2.3579
2024-10-30 23:17:29: [2024-10-30 23:17:29] iter = 06110, loss = 7.1321
2024-10-30 23:17:31: [2024-10-30 23:17:31] iter = 06120, loss = 1.7053
2024-10-30 23:17:33: [2024-10-30 23:17:33] iter = 06130, loss = 2.0224
2024-10-30 23:17:36: [2024-10-30 23:17:36] iter = 06140, loss = 2.7322
2024-10-30 23:17:39: [2024-10-30 23:17:39] iter = 06150, loss = 1.8008
2024-10-30 23:17:43: [2024-10-30 23:17:43] iter = 06160, loss = 2.2152
2024-10-30 23:17:47: [2024-10-30 23:17:47] iter = 06170, loss = 2.1037
2024-10-30 23:17:50: [2024-10-30 23:17:50] iter = 06180, loss = 1.9305
2024-10-30 23:17:53: [2024-10-30 23:17:53] iter = 06190, loss = 2.6936
2024-10-30 23:17:57: [2024-10-30 23:17:57] iter = 06200, loss = 2.0112
2024-10-30 23:18:01: [2024-10-30 23:18:00] iter = 06210, loss = 2.1740
2024-10-30 23:18:04: [2024-10-30 23:18:04] iter = 06220, loss = 2.0301
2024-10-30 23:18:08: [2024-10-30 23:18:08] iter = 06230, loss = 2.0356
2024-10-30 23:18:11: [2024-10-30 23:18:11] iter = 06240, loss = 1.9795
2024-10-30 23:18:14: [2024-10-30 23:18:14] iter = 06250, loss = 1.7945
2024-10-30 23:18:17: [2024-10-30 23:18:17] iter = 06260, loss = 2.8545
2024-10-30 23:18:20: [2024-10-30 23:18:20] iter = 06270, loss = 2.3003
2024-10-30 23:18:24: [2024-10-30 23:18:24] iter = 06280, loss = 2.1058
2024-10-30 23:18:28: [2024-10-30 23:18:28] iter = 06290, loss = 2.3677
2024-10-30 23:18:30: [2024-10-30 23:18:30] iter = 06300, loss = 2.0516
2024-10-30 23:18:34: [2024-10-30 23:18:34] iter = 06310, loss = 2.0720
2024-10-30 23:18:36: [2024-10-30 23:18:36] iter = 06320, loss = 2.0244
2024-10-30 23:18:39: [2024-10-30 23:18:39] iter = 06330, loss = 2.3898
2024-10-30 23:18:42: [2024-10-30 23:18:42] iter = 06340, loss = 2.0483
2024-10-30 23:18:45: [2024-10-30 23:18:45] iter = 06350, loss = 2.3472
2024-10-30 23:18:49: [2024-10-30 23:18:49] iter = 06360, loss = 3.2599
2024-10-30 23:18:52: [2024-10-30 23:18:52] iter = 06370, loss = 2.4344
2024-10-30 23:18:56: [2024-10-30 23:18:56] iter = 06380, loss = 1.7044
2024-10-30 23:19:00: [2024-10-30 23:19:00] iter = 06390, loss = 2.1998
2024-10-30 23:19:03: [2024-10-30 23:19:03] iter = 06400, loss = 1.8259
2024-10-30 23:19:06: [2024-10-30 23:19:06] iter = 06410, loss = 1.6882
2024-10-30 23:19:10: [2024-10-30 23:19:10] iter = 06420, loss = 2.3057
2024-10-30 23:19:12: [2024-10-30 23:19:12] iter = 06430, loss = 2.6233
2024-10-30 23:19:16: [2024-10-30 23:19:16] iter = 06440, loss = 3.0559
2024-10-30 23:19:20: [2024-10-30 23:19:20] iter = 06450, loss = 2.2267
2024-10-30 23:19:23: [2024-10-30 23:19:23] iter = 06460, loss = 2.3410
2024-10-30 23:19:26: [2024-10-30 23:19:26] iter = 06470, loss = 1.8607
2024-10-30 23:19:30: [2024-10-30 23:19:30] iter = 06480, loss = 3.4793
2024-10-30 23:19:34: [2024-10-30 23:19:34] iter = 06490, loss = 1.9067
2024-10-30 23:19:37: [2024-10-30 23:19:37] iter = 06500, loss = 1.8495
2024-10-30 23:19:39: [2024-10-30 23:19:39] iter = 06510, loss = 1.9734
2024-10-30 23:19:43: [2024-10-30 23:19:43] iter = 06520, loss = 1.8290
2024-10-30 23:19:46: [2024-10-30 23:19:46] iter = 06530, loss = 1.7430
2024-10-30 23:19:51: [2024-10-30 23:19:51] iter = 06540, loss = 1.7833
2024-10-30 23:19:54: [2024-10-30 23:19:54] iter = 06550, loss = 1.9852
2024-10-30 23:19:57: [2024-10-30 23:19:57] iter = 06560, loss = 1.8283
2024-10-30 23:20:01: [2024-10-30 23:20:01] iter = 06570, loss = 2.0169
2024-10-30 23:20:05: [2024-10-30 23:20:05] iter = 06580, loss = 3.1348
2024-10-30 23:20:09: [2024-10-30 23:20:09] iter = 06590, loss = 2.0030
2024-10-30 23:20:13: [2024-10-30 23:20:13] iter = 06600, loss = 1.9696
2024-10-30 23:20:16: [2024-10-30 23:20:16] iter = 06610, loss = 1.8910
2024-10-30 23:20:20: [2024-10-30 23:20:20] iter = 06620, loss = 2.1504
2024-10-30 23:20:23: [2024-10-30 23:20:23] iter = 06630, loss = 1.7433
2024-10-30 23:20:26: [2024-10-30 23:20:26] iter = 06640, loss = 1.6602
2024-10-30 23:20:29: [2024-10-30 23:20:29] iter = 06650, loss = 2.4572
2024-10-30 23:20:32: [2024-10-30 23:20:32] iter = 06660, loss = 3.6807
2024-10-30 23:20:35: [2024-10-30 23:20:35] iter = 06670, loss = 2.0682
2024-10-30 23:20:38: [2024-10-30 23:20:38] iter = 06680, loss = 1.9260
2024-10-30 23:20:41: [2024-10-30 23:20:41] iter = 06690, loss = 2.0736
2024-10-30 23:20:44: [2024-10-30 23:20:44] iter = 06700, loss = 2.0745
2024-10-30 23:20:48: [2024-10-30 23:20:48] iter = 06710, loss = 2.5910
2024-10-30 23:20:51: [2024-10-30 23:20:51] iter = 06720, loss = 3.2845
2024-10-30 23:20:54: [2024-10-30 23:20:54] iter = 06730, loss = 2.9369
2024-10-30 23:20:57: [2024-10-30 23:20:57] iter = 06740, loss = 1.6183
2024-10-30 23:21:01: [2024-10-30 23:21:01] iter = 06750, loss = 2.1522
2024-10-30 23:21:04: [2024-10-30 23:21:04] iter = 06760, loss = 2.0282
2024-10-30 23:21:08: [2024-10-30 23:21:08] iter = 06770, loss = 2.3391
2024-10-30 23:21:12: [2024-10-30 23:21:12] iter = 06780, loss = 2.0947
2024-10-30 23:21:15: [2024-10-30 23:21:15] iter = 06790, loss = 2.0901
2024-10-30 23:21:19: [2024-10-30 23:21:19] iter = 06800, loss = 1.7673
2024-10-30 23:21:22: [2024-10-30 23:21:22] iter = 06810, loss = 1.8145
2024-10-30 23:21:25: [2024-10-30 23:21:25] iter = 06820, loss = 2.7216
2024-10-30 23:21:29: [2024-10-30 23:21:29] iter = 06830, loss = 2.0399
2024-10-30 23:21:32: [2024-10-30 23:21:32] iter = 06840, loss = 1.9626
2024-10-30 23:21:35: [2024-10-30 23:21:35] iter = 06850, loss = 1.6726
2024-10-30 23:21:38: [2024-10-30 23:21:38] iter = 06860, loss = 3.5324
2024-10-30 23:21:42: [2024-10-30 23:21:42] iter = 06870, loss = 1.7602
2024-10-30 23:21:46: [2024-10-30 23:21:46] iter = 06880, loss = 4.7424
2024-10-30 23:21:49: [2024-10-30 23:21:49] iter = 06890, loss = 1.9948
2024-10-30 23:21:53: [2024-10-30 23:21:53] iter = 06900, loss = 4.4256
2024-10-30 23:21:58: [2024-10-30 23:21:58] iter = 06910, loss = 2.0466
2024-10-30 23:22:01: [2024-10-30 23:22:01] iter = 06920, loss = 1.5819
2024-10-30 23:22:03: [2024-10-30 23:22:03] iter = 06930, loss = 2.7957
2024-10-30 23:22:06: [2024-10-30 23:22:06] iter = 06940, loss = 1.8863
2024-10-30 23:22:09: [2024-10-30 23:22:09] iter = 06950, loss = 1.9278
2024-10-30 23:22:12: [2024-10-30 23:22:12] iter = 06960, loss = 2.2390
2024-10-30 23:22:16: [2024-10-30 23:22:16] iter = 06970, loss = 2.1325
2024-10-30 23:22:20: [2024-10-30 23:22:20] iter = 06980, loss = 2.7582
2024-10-30 23:22:23: [2024-10-30 23:22:23] iter = 06990, loss = 2.3386
2024-10-30 23:22:27: [2024-10-30 23:22:27] iter = 07000, loss = 1.7597
2024-10-30 23:22:30: [2024-10-30 23:22:30] iter = 07010, loss = 1.8665
2024-10-30 23:22:33: [2024-10-30 23:22:33] iter = 07020, loss = 2.9925
2024-10-30 23:22:36: [2024-10-30 23:22:36] iter = 07030, loss = 4.6772
2024-10-30 23:22:40: [2024-10-30 23:22:40] iter = 07040, loss = 2.2594
2024-10-30 23:22:43: [2024-10-30 23:22:43] iter = 07050, loss = 1.9023
2024-10-30 23:22:46: [2024-10-30 23:22:46] iter = 07060, loss = 1.8631
2024-10-30 23:22:50: [2024-10-30 23:22:50] iter = 07070, loss = 1.9401
2024-10-30 23:22:53: [2024-10-30 23:22:53] iter = 07080, loss = 1.7226
2024-10-30 23:22:57: [2024-10-30 23:22:57] iter = 07090, loss = 1.9725
2024-10-30 23:22:59: [2024-10-30 23:22:59] iter = 07100, loss = 2.5459
2024-10-30 23:23:03: [2024-10-30 23:23:03] iter = 07110, loss = 4.4734
2024-10-30 23:23:06: [2024-10-30 23:23:06] iter = 07120, loss = 1.9428
2024-10-30 23:23:10: [2024-10-30 23:23:10] iter = 07130, loss = 1.8181
2024-10-30 23:23:13: [2024-10-30 23:23:13] iter = 07140, loss = 1.6250
2024-10-30 23:23:16: [2024-10-30 23:23:16] iter = 07150, loss = 2.0071
2024-10-30 23:23:19: [2024-10-30 23:23:19] iter = 07160, loss = 1.8215
2024-10-30 23:23:23: [2024-10-30 23:23:23] iter = 07170, loss = 2.8880
2024-10-30 23:23:27: [2024-10-30 23:23:27] iter = 07180, loss = 1.9404
2024-10-30 23:23:31: [2024-10-30 23:23:31] iter = 07190, loss = 1.6369
2024-10-30 23:23:35: [2024-10-30 23:23:35] iter = 07200, loss = 2.1427
2024-10-30 23:23:38: [2024-10-30 23:23:38] iter = 07210, loss = 2.2460
2024-10-30 23:23:41: [2024-10-30 23:23:41] iter = 07220, loss = 1.9200
2024-10-30 23:23:45: [2024-10-30 23:23:45] iter = 07230, loss = 1.7414
2024-10-30 23:23:48: [2024-10-30 23:23:48] iter = 07240, loss = 2.1157
2024-10-30 23:23:51: [2024-10-30 23:23:51] iter = 07250, loss = 1.7947
2024-10-30 23:23:55: [2024-10-30 23:23:55] iter = 07260, loss = 3.8904
2024-10-30 23:23:58: [2024-10-30 23:23:58] iter = 07270, loss = 1.8939
2024-10-30 23:24:01: [2024-10-30 23:24:01] iter = 07280, loss = 2.9896
2024-10-30 23:24:04: [2024-10-30 23:24:04] iter = 07290, loss = 1.9758
2024-10-30 23:24:08: [2024-10-30 23:24:08] iter = 07300, loss = 2.3146
2024-10-30 23:24:11: [2024-10-30 23:24:11] iter = 07310, loss = 4.2332
2024-10-30 23:24:15: [2024-10-30 23:24:15] iter = 07320, loss = 2.9697
2024-10-30 23:24:19: [2024-10-30 23:24:19] iter = 07330, loss = 2.0686
2024-10-30 23:24:22: [2024-10-30 23:24:22] iter = 07340, loss = 1.8906
2024-10-30 23:24:25: [2024-10-30 23:24:25] iter = 07350, loss = 2.8408
2024-10-30 23:24:29: [2024-10-30 23:24:29] iter = 07360, loss = 2.2687
2024-10-30 23:24:32: [2024-10-30 23:24:32] iter = 07370, loss = 2.2892
2024-10-30 23:24:36: [2024-10-30 23:24:36] iter = 07380, loss = 1.5468
2024-10-30 23:24:39: [2024-10-30 23:24:39] iter = 07390, loss = 2.1576
2024-10-30 23:24:43: [2024-10-30 23:24:43] iter = 07400, loss = 2.1005
2024-10-30 23:24:46: [2024-10-30 23:24:46] iter = 07410, loss = 2.3914
2024-10-30 23:24:49: [2024-10-30 23:24:49] iter = 07420, loss = 2.9451
2024-10-30 23:24:52: [2024-10-30 23:24:52] iter = 07430, loss = 2.1377
2024-10-30 23:24:55: [2024-10-30 23:24:55] iter = 07440, loss = 1.8466
2024-10-30 23:24:58: [2024-10-30 23:24:58] iter = 07450, loss = 1.9439
2024-10-30 23:25:01: [2024-10-30 23:25:01] iter = 07460, loss = 2.4673
2024-10-30 23:25:04: [2024-10-30 23:25:04] iter = 07470, loss = 2.9352
2024-10-30 23:25:07: [2024-10-30 23:25:07] iter = 07480, loss = 1.9351
2024-10-30 23:25:11: [2024-10-30 23:25:11] iter = 07490, loss = 1.9149
2024-10-30 23:25:14: [2024-10-30 23:25:14] iter = 07500, loss = 3.6553
2024-10-30 23:25:17: [2024-10-30 23:25:17] iter = 07510, loss = 2.0528
2024-10-30 23:25:19: [2024-10-30 23:25:19] iter = 07520, loss = 2.1251
2024-10-30 23:25:23: [2024-10-30 23:25:23] iter = 07530, loss = 1.8361
2024-10-30 23:25:27: [2024-10-30 23:25:27] iter = 07540, loss = 1.8782
2024-10-30 23:25:30: [2024-10-30 23:25:30] iter = 07550, loss = 1.9879
2024-10-30 23:25:34: [2024-10-30 23:25:34] iter = 07560, loss = 3.5477
2024-10-30 23:25:37: [2024-10-30 23:25:37] iter = 07570, loss = 2.4670
2024-10-30 23:25:41: [2024-10-30 23:25:41] iter = 07580, loss = 3.2474
2024-10-30 23:25:44: [2024-10-30 23:25:44] iter = 07590, loss = 1.7448
2024-10-30 23:25:47: [2024-10-30 23:25:47] iter = 07600, loss = 2.1478
2024-10-30 23:25:49: [2024-10-30 23:25:49] iter = 07610, loss = 2.2861
2024-10-30 23:25:52: [2024-10-30 23:25:52] iter = 07620, loss = 2.2007
2024-10-30 23:25:56: [2024-10-30 23:25:56] iter = 07630, loss = 2.2282
2024-10-30 23:25:59: [2024-10-30 23:25:59] iter = 07640, loss = 6.8643
2024-10-30 23:26:03: [2024-10-30 23:26:03] iter = 07650, loss = 2.1879
2024-10-30 23:26:05: [2024-10-30 23:26:05] iter = 07660, loss = 3.1781
2024-10-30 23:26:08: [2024-10-30 23:26:08] iter = 07670, loss = 2.2143
2024-10-30 23:26:10: [2024-10-30 23:26:10] iter = 07680, loss = 1.8537
2024-10-30 23:26:15: [2024-10-30 23:26:15] iter = 07690, loss = 2.0678
2024-10-30 23:26:18: [2024-10-30 23:26:18] iter = 07700, loss = 2.7083
2024-10-30 23:26:22: [2024-10-30 23:26:22] iter = 07710, loss = 3.2751
2024-10-30 23:26:26: [2024-10-30 23:26:26] iter = 07720, loss = 1.7253
2024-10-30 23:26:29: [2024-10-30 23:26:29] iter = 07730, loss = 2.2527
2024-10-30 23:26:33: [2024-10-30 23:26:33] iter = 07740, loss = 1.8383
2024-10-30 23:26:36: [2024-10-30 23:26:36] iter = 07750, loss = 2.1119
2024-10-30 23:26:40: [2024-10-30 23:26:40] iter = 07760, loss = 2.9613
2024-10-30 23:26:44: [2024-10-30 23:26:44] iter = 07770, loss = 1.9142
2024-10-30 23:26:48: [2024-10-30 23:26:48] iter = 07780, loss = 2.6516
2024-10-30 23:26:52: [2024-10-30 23:26:52] iter = 07790, loss = 1.7928
2024-10-30 23:26:56: [2024-10-30 23:26:56] iter = 07800, loss = 2.4237
2024-10-30 23:26:59: [2024-10-30 23:26:59] iter = 07810, loss = 2.4184
2024-10-30 23:27:03: [2024-10-30 23:27:03] iter = 07820, loss = 4.5175
2024-10-30 23:27:07: [2024-10-30 23:27:07] iter = 07830, loss = 2.6623
2024-10-30 23:27:10: [2024-10-30 23:27:10] iter = 07840, loss = 2.1038
2024-10-30 23:27:12: [2024-10-30 23:27:12] iter = 07850, loss = 2.1527
2024-10-30 23:27:15: [2024-10-30 23:27:15] iter = 07860, loss = 1.9360
2024-10-30 23:27:18: [2024-10-30 23:27:18] iter = 07870, loss = 2.1197
2024-10-30 23:27:22: [2024-10-30 23:27:22] iter = 07880, loss = 2.0205
2024-10-30 23:27:26: [2024-10-30 23:27:26] iter = 07890, loss = 1.8787
2024-10-30 23:27:28: [2024-10-30 23:27:28] iter = 07900, loss = 2.4340
2024-10-30 23:27:32: [2024-10-30 23:27:32] iter = 07910, loss = 2.4063
2024-10-30 23:27:35: [2024-10-30 23:27:35] iter = 07920, loss = 2.6660
2024-10-30 23:27:39: [2024-10-30 23:27:39] iter = 07930, loss = 3.9056
2024-10-30 23:27:42: [2024-10-30 23:27:42] iter = 07940, loss = 2.6131
2024-10-30 23:27:47: [2024-10-30 23:27:47] iter = 07950, loss = 2.6429
2024-10-30 23:27:50: [2024-10-30 23:27:50] iter = 07960, loss = 1.8399
2024-10-30 23:27:53: [2024-10-30 23:27:53] iter = 07970, loss = 1.9988
2024-10-30 23:27:57: [2024-10-30 23:27:57] iter = 07980, loss = 2.0025
2024-10-30 23:27:59: [2024-10-30 23:27:59] iter = 07990, loss = 2.6166
2024-10-30 23:28:02: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 23:28:02: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:28:02: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 82506}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:30:10: Evaluate 5 random ConvNet, ACCmean = 0.7806 ACCstd = 0.0031
-------------------------
2024-10-30 23:30:10: Evaluate 5 random ConvNet, SENmean = 0.7755 SENstd = 0.0038
-------------------------
2024-10-30 23:30:10: Evaluate 5 random ConvNet, SPEmean = 0.9779 SPEstd = 0.0003
-------------------------
2024-10-30 23:30:10: Evaluate 5 random ConvNet, F!mean = 0.7667 F!std = 0.0034
-------------------------
2024-10-30 23:30:10: Evaluate 5 random ConvNet, mean = 0.7806 std = 0.0031
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:30:10: [2024-10-30 23:30:10] iter = 08000, loss = 1.8113
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:30:14: [2024-10-30 23:30:14] iter = 08010, loss = 2.4541
2024-10-30 23:30:18: [2024-10-30 23:30:18] iter = 08020, loss = 2.1313
2024-10-30 23:30:21: [2024-10-30 23:30:21] iter = 08030, loss = 1.9624
2024-10-30 23:30:25: [2024-10-30 23:30:25] iter = 08040, loss = 2.0325
2024-10-30 23:30:29: [2024-10-30 23:30:29] iter = 08050, loss = 2.0747
2024-10-30 23:30:33: [2024-10-30 23:30:33] iter = 08060, loss = 1.8714
2024-10-30 23:30:38: [2024-10-30 23:30:38] iter = 08070, loss = 2.2570
2024-10-30 23:30:42: [2024-10-30 23:30:42] iter = 08080, loss = 2.4117
2024-10-30 23:30:45: [2024-10-30 23:30:45] iter = 08090, loss = 1.8417
2024-10-30 23:30:50: [2024-10-30 23:30:50] iter = 08100, loss = 2.0510
2024-10-30 23:30:54: [2024-10-30 23:30:54] iter = 08110, loss = 3.6238
2024-10-30 23:30:58: [2024-10-30 23:30:58] iter = 08120, loss = 1.7438
2024-10-30 23:31:02: [2024-10-30 23:31:02] iter = 08130, loss = 1.9459
2024-10-30 23:31:05: [2024-10-30 23:31:05] iter = 08140, loss = 1.8872
2024-10-30 23:31:09: [2024-10-30 23:31:09] iter = 08150, loss = 2.4220
2024-10-30 23:31:13: [2024-10-30 23:31:13] iter = 08160, loss = 3.0352
2024-10-30 23:31:17: [2024-10-30 23:31:17] iter = 08170, loss = 1.7707
2024-10-30 23:31:22: [2024-10-30 23:31:22] iter = 08180, loss = 2.9638
2024-10-30 23:31:26: [2024-10-30 23:31:26] iter = 08190, loss = 2.3742
2024-10-30 23:31:29: [2024-10-30 23:31:29] iter = 08200, loss = 2.0608
2024-10-30 23:31:33: [2024-10-30 23:31:33] iter = 08210, loss = 2.8393
2024-10-30 23:31:38: [2024-10-30 23:31:38] iter = 08220, loss = 2.1838
2024-10-30 23:31:43: [2024-10-30 23:31:43] iter = 08230, loss = 1.9370
2024-10-30 23:31:47: [2024-10-30 23:31:47] iter = 08240, loss = 2.2181
2024-10-30 23:31:50: [2024-10-30 23:31:50] iter = 08250, loss = 2.0597
2024-10-30 23:31:54: [2024-10-30 23:31:54] iter = 08260, loss = 2.6743
2024-10-30 23:31:58: [2024-10-30 23:31:58] iter = 08270, loss = 2.2645
2024-10-30 23:32:01: [2024-10-30 23:32:01] iter = 08280, loss = 2.1603
2024-10-30 23:32:04: [2024-10-30 23:32:04] iter = 08290, loss = 2.0792
2024-10-30 23:32:09: [2024-10-30 23:32:09] iter = 08300, loss = 2.1553
2024-10-30 23:32:13: [2024-10-30 23:32:13] iter = 08310, loss = 4.0677
2024-10-30 23:32:16: [2024-10-30 23:32:16] iter = 08320, loss = 2.5795
2024-10-30 23:32:20: [2024-10-30 23:32:20] iter = 08330, loss = 1.7688
2024-10-30 23:32:25: [2024-10-30 23:32:25] iter = 08340, loss = 1.7977
2024-10-30 23:32:29: [2024-10-30 23:32:29] iter = 08350, loss = 2.6991
2024-10-30 23:32:33: [2024-10-30 23:32:33] iter = 08360, loss = 2.2207
2024-10-30 23:32:37: [2024-10-30 23:32:37] iter = 08370, loss = 2.8458
2024-10-30 23:32:42: [2024-10-30 23:32:42] iter = 08380, loss = 2.7073
2024-10-30 23:32:46: [2024-10-30 23:32:46] iter = 08390, loss = 1.8933
2024-10-30 23:32:49: [2024-10-30 23:32:49] iter = 08400, loss = 1.8543
2024-10-30 23:32:52: [2024-10-30 23:32:52] iter = 08410, loss = 1.9237
2024-10-30 23:32:55: [2024-10-30 23:32:55] iter = 08420, loss = 3.4755
2024-10-30 23:32:58: [2024-10-30 23:32:58] iter = 08430, loss = 2.3157
2024-10-30 23:33:02: [2024-10-30 23:33:02] iter = 08440, loss = 2.0010
2024-10-30 23:33:05: [2024-10-30 23:33:05] iter = 08450, loss = 1.8136
2024-10-30 23:33:08: [2024-10-30 23:33:08] iter = 08460, loss = 2.4178
2024-10-30 23:33:11: [2024-10-30 23:33:11] iter = 08470, loss = 2.0014
2024-10-30 23:33:15: [2024-10-30 23:33:15] iter = 08480, loss = 2.3095
2024-10-30 23:33:18: [2024-10-30 23:33:18] iter = 08490, loss = 2.8579
2024-10-30 23:33:22: [2024-10-30 23:33:22] iter = 08500, loss = 2.4081
2024-10-30 23:33:25: [2024-10-30 23:33:25] iter = 08510, loss = 2.9062
2024-10-30 23:33:28: [2024-10-30 23:33:28] iter = 08520, loss = 3.3615
2024-10-30 23:33:32: [2024-10-30 23:33:32] iter = 08530, loss = 2.7026
2024-10-30 23:33:36: [2024-10-30 23:33:36] iter = 08540, loss = 1.6707
2024-10-30 23:33:39: [2024-10-30 23:33:39] iter = 08550, loss = 2.1070
2024-10-30 23:33:43: [2024-10-30 23:33:43] iter = 08560, loss = 2.3997
2024-10-30 23:33:47: [2024-10-30 23:33:47] iter = 08570, loss = 2.0835
2024-10-30 23:33:51: [2024-10-30 23:33:51] iter = 08580, loss = 2.3430
2024-10-30 23:33:55: [2024-10-30 23:33:55] iter = 08590, loss = 2.0778
2024-10-30 23:33:57: [2024-10-30 23:33:57] iter = 08600, loss = 1.8981
2024-10-30 23:34:01: [2024-10-30 23:34:01] iter = 08610, loss = 2.4127
2024-10-30 23:34:05: [2024-10-30 23:34:05] iter = 08620, loss = 2.3686
2024-10-30 23:34:09: [2024-10-30 23:34:09] iter = 08630, loss = 2.1996
2024-10-30 23:34:12: [2024-10-30 23:34:12] iter = 08640, loss = 1.7099
2024-10-30 23:34:15: [2024-10-30 23:34:15] iter = 08650, loss = 2.0132
2024-10-30 23:34:20: [2024-10-30 23:34:20] iter = 08660, loss = 2.1429
2024-10-30 23:34:23: [2024-10-30 23:34:23] iter = 08670, loss = 2.5066
2024-10-30 23:34:27: [2024-10-30 23:34:27] iter = 08680, loss = 1.8429
2024-10-30 23:34:31: [2024-10-30 23:34:31] iter = 08690, loss = 2.0569
2024-10-30 23:34:35: [2024-10-30 23:34:35] iter = 08700, loss = 3.3819
2024-10-30 23:34:38: [2024-10-30 23:34:38] iter = 08710, loss = 1.8062
2024-10-30 23:34:43: [2024-10-30 23:34:43] iter = 08720, loss = 1.5246
2024-10-30 23:34:46: [2024-10-30 23:34:46] iter = 08730, loss = 1.9495
2024-10-30 23:34:51: [2024-10-30 23:34:51] iter = 08740, loss = 2.0644
2024-10-30 23:34:55: [2024-10-30 23:34:55] iter = 08750, loss = 2.7929
2024-10-30 23:34:59: [2024-10-30 23:34:59] iter = 08760, loss = 2.0799
2024-10-30 23:35:03: [2024-10-30 23:35:03] iter = 08770, loss = 2.3982
2024-10-30 23:35:07: [2024-10-30 23:35:07] iter = 08780, loss = 1.8703
2024-10-30 23:35:12: [2024-10-30 23:35:12] iter = 08790, loss = 2.0810
2024-10-30 23:35:16: [2024-10-30 23:35:16] iter = 08800, loss = 4.2237
2024-10-30 23:35:20: [2024-10-30 23:35:20] iter = 08810, loss = 2.2086
2024-10-30 23:35:22: [2024-10-30 23:35:22] iter = 08820, loss = 2.0068
2024-10-30 23:35:26: [2024-10-30 23:35:26] iter = 08830, loss = 3.4685
2024-10-30 23:35:29: [2024-10-30 23:35:29] iter = 08840, loss = 2.8255
2024-10-30 23:35:32: [2024-10-30 23:35:32] iter = 08850, loss = 2.7751
2024-10-30 23:35:36: [2024-10-30 23:35:36] iter = 08860, loss = 2.3333
2024-10-30 23:35:39: [2024-10-30 23:35:39] iter = 08870, loss = 2.5710
2024-10-30 23:35:43: [2024-10-30 23:35:43] iter = 08880, loss = 1.9539
2024-10-30 23:35:47: [2024-10-30 23:35:47] iter = 08890, loss = 2.3754
2024-10-30 23:35:50: [2024-10-30 23:35:50] iter = 08900, loss = 2.7194
2024-10-30 23:35:54: [2024-10-30 23:35:54] iter = 08910, loss = 2.6049
2024-10-30 23:35:58: [2024-10-30 23:35:58] iter = 08920, loss = 3.0342
2024-10-30 23:36:02: [2024-10-30 23:36:02] iter = 08930, loss = 2.9899
2024-10-30 23:36:06: [2024-10-30 23:36:06] iter = 08940, loss = 2.0187
2024-10-30 23:36:10: [2024-10-30 23:36:10] iter = 08950, loss = 2.4123
2024-10-30 23:36:14: [2024-10-30 23:36:14] iter = 08960, loss = 1.9152
2024-10-30 23:36:17: [2024-10-30 23:36:17] iter = 08970, loss = 1.9024
2024-10-30 23:36:21: [2024-10-30 23:36:21] iter = 08980, loss = 2.3316
2024-10-30 23:36:24: [2024-10-30 23:36:24] iter = 08990, loss = 2.0687
2024-10-30 23:36:28: [2024-10-30 23:36:28] iter = 09000, loss = 2.0289
2024-10-30 23:36:31: [2024-10-30 23:36:31] iter = 09010, loss = 2.1879
2024-10-30 23:36:36: [2024-10-30 23:36:36] iter = 09020, loss = 2.3606
2024-10-30 23:36:40: [2024-10-30 23:36:40] iter = 09030, loss = 2.7336
2024-10-30 23:36:43: [2024-10-30 23:36:43] iter = 09040, loss = 1.7415
2024-10-30 23:36:47: [2024-10-30 23:36:47] iter = 09050, loss = 1.9082
2024-10-30 23:36:51: [2024-10-30 23:36:51] iter = 09060, loss = 2.6387
2024-10-30 23:36:55: [2024-10-30 23:36:55] iter = 09070, loss = 1.8775
2024-10-30 23:36:59: [2024-10-30 23:36:59] iter = 09080, loss = 2.5478
2024-10-30 23:37:03: [2024-10-30 23:37:03] iter = 09090, loss = 2.0337
2024-10-30 23:37:07: [2024-10-30 23:37:07] iter = 09100, loss = 2.1151
2024-10-30 23:37:10: [2024-10-30 23:37:10] iter = 09110, loss = 2.3769
2024-10-30 23:37:13: [2024-10-30 23:37:13] iter = 09120, loss = 2.0126
2024-10-30 23:37:17: [2024-10-30 23:37:17] iter = 09130, loss = 1.7338
2024-10-30 23:37:20: [2024-10-30 23:37:20] iter = 09140, loss = 1.9482
2024-10-30 23:37:23: [2024-10-30 23:37:23] iter = 09150, loss = 2.2424
2024-10-30 23:37:26: [2024-10-30 23:37:26] iter = 09160, loss = 3.6690
2024-10-30 23:37:29: [2024-10-30 23:37:29] iter = 09170, loss = 2.1320
2024-10-30 23:37:33: [2024-10-30 23:37:33] iter = 09180, loss = 2.0880
2024-10-30 23:37:36: [2024-10-30 23:37:36] iter = 09190, loss = 1.7726
2024-10-30 23:37:40: [2024-10-30 23:37:40] iter = 09200, loss = 1.9736
2024-10-30 23:37:44: [2024-10-30 23:37:44] iter = 09210, loss = 3.3993
2024-10-30 23:37:48: [2024-10-30 23:37:48] iter = 09220, loss = 2.2420
2024-10-30 23:37:51: [2024-10-30 23:37:51] iter = 09230, loss = 2.5952
2024-10-30 23:37:55: [2024-10-30 23:37:55] iter = 09240, loss = 4.8641
2024-10-30 23:37:57: [2024-10-30 23:37:57] iter = 09250, loss = 2.6212
2024-10-30 23:38:01: [2024-10-30 23:38:01] iter = 09260, loss = 1.9305
2024-10-30 23:38:04: [2024-10-30 23:38:04] iter = 09270, loss = 2.5559
2024-10-30 23:38:08: [2024-10-30 23:38:08] iter = 09280, loss = 1.8974
2024-10-30 23:38:12: [2024-10-30 23:38:12] iter = 09290, loss = 1.7196
2024-10-30 23:38:16: [2024-10-30 23:38:16] iter = 09300, loss = 2.1924
2024-10-30 23:38:20: [2024-10-30 23:38:20] iter = 09310, loss = 1.9881
2024-10-30 23:38:24: [2024-10-30 23:38:24] iter = 09320, loss = 1.7875
2024-10-30 23:38:27: [2024-10-30 23:38:27] iter = 09330, loss = 1.6395
2024-10-30 23:38:28: [2024-10-30 23:38:28] iter = 09340, loss = 2.1958
2024-10-30 23:38:31: [2024-10-30 23:38:31] iter = 09350, loss = 2.1264
2024-10-30 23:38:34: [2024-10-30 23:38:34] iter = 09360, loss = 2.1205
2024-10-30 23:38:38: [2024-10-30 23:38:38] iter = 09370, loss = 1.8139
2024-10-30 23:38:40: [2024-10-30 23:38:40] iter = 09380, loss = 1.8948
2024-10-30 23:38:43: [2024-10-30 23:38:43] iter = 09390, loss = 3.1600
2024-10-30 23:38:45: [2024-10-30 23:38:45] iter = 09400, loss = 1.6340
2024-10-30 23:38:47: [2024-10-30 23:38:47] iter = 09410, loss = 1.7655
2024-10-30 23:38:49: [2024-10-30 23:38:49] iter = 09420, loss = 1.8966
2024-10-30 23:38:53: [2024-10-30 23:38:53] iter = 09430, loss = 1.6576
2024-10-30 23:38:56: [2024-10-30 23:38:56] iter = 09440, loss = 1.9997
2024-10-30 23:39:00: [2024-10-30 23:39:00] iter = 09450, loss = 2.1650
2024-10-30 23:39:04: [2024-10-30 23:39:04] iter = 09460, loss = 1.7578
2024-10-30 23:39:07: [2024-10-30 23:39:07] iter = 09470, loss = 1.9514
2024-10-30 23:39:11: [2024-10-30 23:39:11] iter = 09480, loss = 2.0601
2024-10-30 23:39:15: [2024-10-30 23:39:15] iter = 09490, loss = 2.4727
2024-10-30 23:39:17: [2024-10-30 23:39:17] iter = 09500, loss = 2.1352
2024-10-30 23:39:21: [2024-10-30 23:39:21] iter = 09510, loss = 3.6628
2024-10-30 23:39:25: [2024-10-30 23:39:25] iter = 09520, loss = 1.7084
2024-10-30 23:39:29: [2024-10-30 23:39:29] iter = 09530, loss = 2.6202
2024-10-30 23:39:33: [2024-10-30 23:39:33] iter = 09540, loss = 1.8452
2024-10-30 23:39:37: [2024-10-30 23:39:37] iter = 09550, loss = 2.0462
2024-10-30 23:39:40: [2024-10-30 23:39:40] iter = 09560, loss = 2.0044
2024-10-30 23:39:44: [2024-10-30 23:39:44] iter = 09570, loss = 3.0246
2024-10-30 23:39:47: [2024-10-30 23:39:47] iter = 09580, loss = 1.6900
2024-10-30 23:39:50: [2024-10-30 23:39:50] iter = 09590, loss = 2.6260
2024-10-30 23:39:54: [2024-10-30 23:39:54] iter = 09600, loss = 2.4455
2024-10-30 23:39:58: [2024-10-30 23:39:58] iter = 09610, loss = 4.6655
2024-10-30 23:40:01: [2024-10-30 23:40:01] iter = 09620, loss = 2.3951
2024-10-30 23:40:05: [2024-10-30 23:40:05] iter = 09630, loss = 1.8662
2024-10-30 23:40:09: [2024-10-30 23:40:09] iter = 09640, loss = 2.0105
2024-10-30 23:40:13: [2024-10-30 23:40:13] iter = 09650, loss = 2.1995
2024-10-30 23:40:17: [2024-10-30 23:40:17] iter = 09660, loss = 2.3557
2024-10-30 23:40:20: [2024-10-30 23:40:20] iter = 09670, loss = 2.8631
2024-10-30 23:40:23: [2024-10-30 23:40:23] iter = 09680, loss = 1.9863
2024-10-30 23:40:25: [2024-10-30 23:40:25] iter = 09690, loss = 2.0541
2024-10-30 23:40:28: [2024-10-30 23:40:28] iter = 09700, loss = 2.2661
2024-10-30 23:40:32: [2024-10-30 23:40:32] iter = 09710, loss = 2.4571
2024-10-30 23:40:36: [2024-10-30 23:40:36] iter = 09720, loss = 1.7572
2024-10-30 23:40:38: [2024-10-30 23:40:38] iter = 09730, loss = 1.9399
2024-10-30 23:40:42: [2024-10-30 23:40:42] iter = 09740, loss = 2.6106
2024-10-30 23:40:45: [2024-10-30 23:40:45] iter = 09750, loss = 2.7171
2024-10-30 23:40:48: [2024-10-30 23:40:48] iter = 09760, loss = 2.4996
2024-10-30 23:40:51: [2024-10-30 23:40:51] iter = 09770, loss = 1.8009
2024-10-30 23:40:56: [2024-10-30 23:40:56] iter = 09780, loss = 1.9881
2024-10-30 23:41:00: [2024-10-30 23:41:00] iter = 09790, loss = 2.5101
2024-10-30 23:41:05: [2024-10-30 23:41:05] iter = 09800, loss = 2.6438
2024-10-30 23:41:08: [2024-10-30 23:41:08] iter = 09810, loss = 2.6593
2024-10-30 23:41:12: [2024-10-30 23:41:12] iter = 09820, loss = 2.2424
2024-10-30 23:41:15: [2024-10-30 23:41:15] iter = 09830, loss = 3.0835
2024-10-30 23:41:18: [2024-10-30 23:41:18] iter = 09840, loss = 1.9750
2024-10-30 23:41:22: [2024-10-30 23:41:22] iter = 09850, loss = 1.6383
2024-10-30 23:41:26: [2024-10-30 23:41:26] iter = 09860, loss = 2.1349
2024-10-30 23:41:30: [2024-10-30 23:41:30] iter = 09870, loss = 2.3218
2024-10-30 23:41:33: [2024-10-30 23:41:33] iter = 09880, loss = 2.6578
2024-10-30 23:41:38: [2024-10-30 23:41:38] iter = 09890, loss = 2.2852
2024-10-30 23:41:41: [2024-10-30 23:41:41] iter = 09900, loss = 2.5458
2024-10-30 23:41:45: [2024-10-30 23:41:44] iter = 09910, loss = 2.8972
2024-10-30 23:41:48: [2024-10-30 23:41:48] iter = 09920, loss = 1.9664
2024-10-30 23:41:52: [2024-10-30 23:41:52] iter = 09930, loss = 2.1883
2024-10-30 23:41:55: [2024-10-30 23:41:55] iter = 09940, loss = 2.2157
2024-10-30 23:41:59: [2024-10-30 23:41:59] iter = 09950, loss = 2.0942
2024-10-30 23:42:02: [2024-10-30 23:42:02] iter = 09960, loss = 1.9742
2024-10-30 23:42:07: [2024-10-30 23:42:07] iter = 09970, loss = 2.2653
2024-10-30 23:42:11: [2024-10-30 23:42:11] iter = 09980, loss = 3.4988
2024-10-30 23:42:15: [2024-10-30 23:42:15] iter = 09990, loss = 1.9842
2024-10-30 23:42:18: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 23:42:18: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:42:18: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 38621}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:44:34: Evaluate 5 random ConvNet, ACCmean = 0.7794 ACCstd = 0.0026
-------------------------
2024-10-30 23:44:34: Evaluate 5 random ConvNet, SENmean = 0.7761 SENstd = 0.0021
-------------------------
2024-10-30 23:44:34: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0002
-------------------------
2024-10-30 23:44:34: Evaluate 5 random ConvNet, F!mean = 0.7667 F!std = 0.0029
-------------------------
2024-10-30 23:44:34: Evaluate 5 random ConvNet, mean = 0.7794 std = 0.0026
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:44:35: [2024-10-30 23:44:35] iter = 10000, loss = 1.7472
2024-10-30 23:44:37: [2024-10-30 23:44:37] iter = 10010, loss = 2.1816
2024-10-30 23:44:41: [2024-10-30 23:44:41] iter = 10020, loss = 1.7950
2024-10-30 23:44:44: [2024-10-30 23:44:44] iter = 10030, loss = 6.1833
2024-10-30 23:44:48: [2024-10-30 23:44:48] iter = 10040, loss = 2.0668
2024-10-30 23:44:52: [2024-10-30 23:44:52] iter = 10050, loss = 2.1654
2024-10-30 23:44:55: [2024-10-30 23:44:55] iter = 10060, loss = 1.7271
2024-10-30 23:44:59: [2024-10-30 23:44:59] iter = 10070, loss = 2.1561
2024-10-30 23:45:04: [2024-10-30 23:45:04] iter = 10080, loss = 1.6074
2024-10-30 23:45:07: [2024-10-30 23:45:07] iter = 10090, loss = 2.2275
2024-10-30 23:45:10: [2024-10-30 23:45:10] iter = 10100, loss = 2.8890
2024-10-30 23:45:14: [2024-10-30 23:45:14] iter = 10110, loss = 1.6744
2024-10-30 23:45:18: [2024-10-30 23:45:18] iter = 10120, loss = 2.0209
2024-10-30 23:45:22: [2024-10-30 23:45:22] iter = 10130, loss = 1.8049
2024-10-30 23:45:25: [2024-10-30 23:45:25] iter = 10140, loss = 2.1820
2024-10-30 23:45:28: [2024-10-30 23:45:28] iter = 10150, loss = 3.3020
2024-10-30 23:45:31: [2024-10-30 23:45:30] iter = 10160, loss = 3.4796
2024-10-30 23:45:34: [2024-10-30 23:45:34] iter = 10170, loss = 2.4751
2024-10-30 23:45:38: [2024-10-30 23:45:38] iter = 10180, loss = 2.3889
2024-10-30 23:45:41: [2024-10-30 23:45:41] iter = 10190, loss = 2.1173
2024-10-30 23:45:45: [2024-10-30 23:45:45] iter = 10200, loss = 1.8324
2024-10-30 23:45:49: [2024-10-30 23:45:49] iter = 10210, loss = 2.3162
2024-10-30 23:45:52: [2024-10-30 23:45:52] iter = 10220, loss = 2.5306
2024-10-30 23:45:56: [2024-10-30 23:45:56] iter = 10230, loss = 2.2040
2024-10-30 23:46:00: [2024-10-30 23:46:00] iter = 10240, loss = 2.1112
2024-10-30 23:46:03: [2024-10-30 23:46:03] iter = 10250, loss = 2.1546
2024-10-30 23:46:07: [2024-10-30 23:46:07] iter = 10260, loss = 2.0809
2024-10-30 23:46:11: [2024-10-30 23:46:11] iter = 10270, loss = 2.5545
2024-10-30 23:46:15: [2024-10-30 23:46:15] iter = 10280, loss = 1.6210
2024-10-30 23:46:18: [2024-10-30 23:46:18] iter = 10290, loss = 2.3776
2024-10-30 23:46:22: [2024-10-30 23:46:22] iter = 10300, loss = 2.5597
2024-10-30 23:46:26: [2024-10-30 23:46:26] iter = 10310, loss = 3.3971
2024-10-30 23:46:29: [2024-10-30 23:46:29] iter = 10320, loss = 2.3883
2024-10-30 23:46:32: [2024-10-30 23:46:32] iter = 10330, loss = 1.9810
2024-10-30 23:46:35: [2024-10-30 23:46:35] iter = 10340, loss = 1.9062
2024-10-30 23:46:39: [2024-10-30 23:46:39] iter = 10350, loss = 2.1051
2024-10-30 23:46:42: [2024-10-30 23:46:42] iter = 10360, loss = 1.9353
2024-10-30 23:46:45: [2024-10-30 23:46:45] iter = 10370, loss = 2.6118
2024-10-30 23:46:50: [2024-10-30 23:46:50] iter = 10380, loss = 2.8802
2024-10-30 23:46:53: [2024-10-30 23:46:53] iter = 10390, loss = 2.1243
2024-10-30 23:46:58: [2024-10-30 23:46:58] iter = 10400, loss = 2.3129
2024-10-30 23:47:00: [2024-10-30 23:47:00] iter = 10410, loss = 2.8795
2024-10-30 23:47:03: [2024-10-30 23:47:03] iter = 10420, loss = 1.9350
2024-10-30 23:47:06: [2024-10-30 23:47:06] iter = 10430, loss = 2.1559
2024-10-30 23:47:10: [2024-10-30 23:47:10] iter = 10440, loss = 2.0702
2024-10-30 23:47:14: [2024-10-30 23:47:14] iter = 10450, loss = 2.3422
2024-10-30 23:47:16: [2024-10-30 23:47:16] iter = 10460, loss = 2.5666
2024-10-30 23:47:19: [2024-10-30 23:47:19] iter = 10470, loss = 1.9714
2024-10-30 23:47:22: [2024-10-30 23:47:22] iter = 10480, loss = 1.8678
2024-10-30 23:47:26: [2024-10-30 23:47:26] iter = 10490, loss = 2.4113
2024-10-30 23:47:30: [2024-10-30 23:47:30] iter = 10500, loss = 2.3901
2024-10-30 23:47:33: [2024-10-30 23:47:33] iter = 10510, loss = 2.0734
2024-10-30 23:47:36: [2024-10-30 23:47:36] iter = 10520, loss = 2.1125
2024-10-30 23:47:40: [2024-10-30 23:47:40] iter = 10530, loss = 3.0627
2024-10-30 23:47:43: [2024-10-30 23:47:43] iter = 10540, loss = 2.3475
2024-10-30 23:47:47: [2024-10-30 23:47:47] iter = 10550, loss = 2.1172
2024-10-30 23:47:50: [2024-10-30 23:47:50] iter = 10560, loss = 2.1046
2024-10-30 23:47:52: [2024-10-30 23:47:52] iter = 10570, loss = 2.1775
2024-10-30 23:47:56: [2024-10-30 23:47:56] iter = 10580, loss = 2.0986
2024-10-30 23:47:59: [2024-10-30 23:47:59] iter = 10590, loss = 1.6210
2024-10-30 23:48:02: [2024-10-30 23:48:02] iter = 10600, loss = 2.2147
2024-10-30 23:48:05: [2024-10-30 23:48:05] iter = 10610, loss = 1.8346
2024-10-30 23:48:08: [2024-10-30 23:48:08] iter = 10620, loss = 1.6215
2024-10-30 23:48:11: [2024-10-30 23:48:11] iter = 10630, loss = 1.8693
2024-10-30 23:48:14: [2024-10-30 23:48:14] iter = 10640, loss = 2.3575
2024-10-30 23:48:17: [2024-10-30 23:48:17] iter = 10650, loss = 2.7964
2024-10-30 23:48:20: [2024-10-30 23:48:20] iter = 10660, loss = 2.0820
2024-10-30 23:48:24: [2024-10-30 23:48:24] iter = 10670, loss = 2.7754
2024-10-30 23:48:27: [2024-10-30 23:48:27] iter = 10680, loss = 1.8236
2024-10-30 23:48:31: [2024-10-30 23:48:31] iter = 10690, loss = 2.0004
2024-10-30 23:48:33: [2024-10-30 23:48:33] iter = 10700, loss = 2.0575
2024-10-30 23:48:37: [2024-10-30 23:48:37] iter = 10710, loss = 1.7567
2024-10-30 23:48:40: [2024-10-30 23:48:40] iter = 10720, loss = 1.9254
2024-10-30 23:48:43: [2024-10-30 23:48:43] iter = 10730, loss = 2.4420
2024-10-30 23:48:46: [2024-10-30 23:48:46] iter = 10740, loss = 2.1526
2024-10-30 23:48:50: [2024-10-30 23:48:50] iter = 10750, loss = 2.2869
2024-10-30 23:48:53: [2024-10-30 23:48:53] iter = 10760, loss = 2.4459
2024-10-30 23:48:56: [2024-10-30 23:48:56] iter = 10770, loss = 2.4930
2024-10-30 23:48:59: [2024-10-30 23:48:59] iter = 10780, loss = 3.5693
2024-10-30 23:49:01: [2024-10-30 23:49:01] iter = 10790, loss = 2.6259
2024-10-30 23:49:04: [2024-10-30 23:49:04] iter = 10800, loss = 2.0033
2024-10-30 23:49:08: [2024-10-30 23:49:08] iter = 10810, loss = 2.3077
2024-10-30 23:49:12: [2024-10-30 23:49:12] iter = 10820, loss = 1.6990
2024-10-30 23:49:16: [2024-10-30 23:49:16] iter = 10830, loss = 2.7511
2024-10-30 23:49:20: [2024-10-30 23:49:20] iter = 10840, loss = 2.2452
2024-10-30 23:49:23: [2024-10-30 23:49:23] iter = 10850, loss = 1.9873
2024-10-30 23:49:25: [2024-10-30 23:49:25] iter = 10860, loss = 2.5787
2024-10-30 23:49:28: [2024-10-30 23:49:28] iter = 10870, loss = 2.1868
2024-10-30 23:49:31: [2024-10-30 23:49:31] iter = 10880, loss = 1.9050
2024-10-30 23:49:34: [2024-10-30 23:49:34] iter = 10890, loss = 1.5667
2024-10-30 23:49:37: [2024-10-30 23:49:37] iter = 10900, loss = 1.9507
2024-10-30 23:49:40: [2024-10-30 23:49:40] iter = 10910, loss = 2.7039
2024-10-30 23:49:44: [2024-10-30 23:49:44] iter = 10920, loss = 2.3118
2024-10-30 23:49:48: [2024-10-30 23:49:48] iter = 10930, loss = 1.7373
2024-10-30 23:49:51: [2024-10-30 23:49:51] iter = 10940, loss = 2.9716
2024-10-30 23:49:55: [2024-10-30 23:49:55] iter = 10950, loss = 1.9172
2024-10-30 23:49:59: [2024-10-30 23:49:59] iter = 10960, loss = 2.0792
2024-10-30 23:50:03: [2024-10-30 23:50:03] iter = 10970, loss = 1.8886
2024-10-30 23:50:06: [2024-10-30 23:50:06] iter = 10980, loss = 2.4146
2024-10-30 23:50:09: [2024-10-30 23:50:09] iter = 10990, loss = 1.9424
2024-10-30 23:50:12: [2024-10-30 23:50:12] iter = 11000, loss = 2.0263
2024-10-30 23:50:16: [2024-10-30 23:50:16] iter = 11010, loss = 3.5518
2024-10-30 23:50:19: [2024-10-30 23:50:19] iter = 11020, loss = 2.1965
2024-10-30 23:50:21: [2024-10-30 23:50:21] iter = 11030, loss = 2.2331
2024-10-30 23:50:25: [2024-10-30 23:50:25] iter = 11040, loss = 2.2716
2024-10-30 23:50:28: [2024-10-30 23:50:28] iter = 11050, loss = 1.9364
2024-10-30 23:50:31: [2024-10-30 23:50:31] iter = 11060, loss = 2.3400
2024-10-30 23:50:34: [2024-10-30 23:50:34] iter = 11070, loss = 1.9582
2024-10-30 23:50:38: [2024-10-30 23:50:38] iter = 11080, loss = 1.8453
2024-10-30 23:50:41: [2024-10-30 23:50:41] iter = 11090, loss = 2.3204
2024-10-30 23:50:45: [2024-10-30 23:50:45] iter = 11100, loss = 1.7658
2024-10-30 23:50:49: [2024-10-30 23:50:49] iter = 11110, loss = 1.5570
2024-10-30 23:50:52: [2024-10-30 23:50:52] iter = 11120, loss = 2.5367
2024-10-30 23:50:55: [2024-10-30 23:50:55] iter = 11130, loss = 1.9260
2024-10-30 23:50:58: [2024-10-30 23:50:58] iter = 11140, loss = 1.9513
2024-10-30 23:51:02: [2024-10-30 23:51:02] iter = 11150, loss = 1.7785
2024-10-30 23:51:05: [2024-10-30 23:51:05] iter = 11160, loss = 2.4000
2024-10-30 23:51:08: [2024-10-30 23:51:08] iter = 11170, loss = 2.3933
2024-10-30 23:51:12: [2024-10-30 23:51:12] iter = 11180, loss = 1.7514
2024-10-30 23:51:15: [2024-10-30 23:51:15] iter = 11190, loss = 1.9957
2024-10-30 23:51:19: [2024-10-30 23:51:19] iter = 11200, loss = 4.0409
2024-10-30 23:51:23: [2024-10-30 23:51:23] iter = 11210, loss = 1.8670
2024-10-30 23:51:26: [2024-10-30 23:51:26] iter = 11220, loss = 2.9235
2024-10-30 23:51:29: [2024-10-30 23:51:29] iter = 11230, loss = 2.1898
2024-10-30 23:51:33: [2024-10-30 23:51:33] iter = 11240, loss = 2.1616
2024-10-30 23:51:35: [2024-10-30 23:51:35] iter = 11250, loss = 2.8236
2024-10-30 23:51:39: [2024-10-30 23:51:39] iter = 11260, loss = 1.9042
2024-10-30 23:51:44: [2024-10-30 23:51:44] iter = 11270, loss = 1.7721
2024-10-30 23:51:47: [2024-10-30 23:51:47] iter = 11280, loss = 1.4978
2024-10-30 23:51:52: [2024-10-30 23:51:52] iter = 11290, loss = 2.0715
2024-10-30 23:51:55: [2024-10-30 23:51:55] iter = 11300, loss = 2.3890
2024-10-30 23:51:58: [2024-10-30 23:51:58] iter = 11310, loss = 1.6492
2024-10-30 23:52:01: [2024-10-30 23:52:01] iter = 11320, loss = 2.8763
2024-10-30 23:52:05: [2024-10-30 23:52:05] iter = 11330, loss = 2.6224
2024-10-30 23:52:08: [2024-10-30 23:52:08] iter = 11340, loss = 2.4071
2024-10-30 23:52:11: [2024-10-30 23:52:11] iter = 11350, loss = 2.2897
2024-10-30 23:52:15: [2024-10-30 23:52:15] iter = 11360, loss = 1.9794
2024-10-30 23:52:18: [2024-10-30 23:52:18] iter = 11370, loss = 2.5383
2024-10-30 23:52:22: [2024-10-30 23:52:22] iter = 11380, loss = 2.6261
2024-10-30 23:52:24: [2024-10-30 23:52:24] iter = 11390, loss = 1.9033
2024-10-30 23:52:28: [2024-10-30 23:52:28] iter = 11400, loss = 1.8038
2024-10-30 23:52:31: [2024-10-30 23:52:31] iter = 11410, loss = 1.8034
2024-10-30 23:52:34: [2024-10-30 23:52:34] iter = 11420, loss = 1.8207
2024-10-30 23:52:38: [2024-10-30 23:52:38] iter = 11430, loss = 2.9114
2024-10-30 23:52:42: [2024-10-30 23:52:42] iter = 11440, loss = 2.1162
2024-10-30 23:52:44: [2024-10-30 23:52:44] iter = 11450, loss = 2.6877
2024-10-30 23:52:47: [2024-10-30 23:52:47] iter = 11460, loss = 2.0851
2024-10-30 23:52:50: [2024-10-30 23:52:50] iter = 11470, loss = 3.4681
2024-10-30 23:52:52: [2024-10-30 23:52:52] iter = 11480, loss = 2.4034
2024-10-30 23:52:55: [2024-10-30 23:52:55] iter = 11490, loss = 1.9319
2024-10-30 23:52:57: [2024-10-30 23:52:57] iter = 11500, loss = 2.3248
2024-10-30 23:53:01: [2024-10-30 23:53:01] iter = 11510, loss = 2.1516
2024-10-30 23:53:05: [2024-10-30 23:53:05] iter = 11520, loss = 3.3355
2024-10-30 23:53:08: [2024-10-30 23:53:08] iter = 11530, loss = 2.0888
2024-10-30 23:53:12: [2024-10-30 23:53:12] iter = 11540, loss = 2.2954
2024-10-30 23:53:15: [2024-10-30 23:53:15] iter = 11550, loss = 2.0807
2024-10-30 23:53:19: [2024-10-30 23:53:19] iter = 11560, loss = 1.9504
2024-10-30 23:53:22: [2024-10-30 23:53:22] iter = 11570, loss = 1.7800
2024-10-30 23:53:26: [2024-10-30 23:53:26] iter = 11580, loss = 1.7713
2024-10-30 23:53:29: [2024-10-30 23:53:29] iter = 11590, loss = 2.4291
2024-10-30 23:53:33: [2024-10-30 23:53:33] iter = 11600, loss = 1.9065
2024-10-30 23:53:36: [2024-10-30 23:53:36] iter = 11610, loss = 1.9746
2024-10-30 23:53:39: [2024-10-30 23:53:39] iter = 11620, loss = 2.3410
2024-10-30 23:53:42: [2024-10-30 23:53:42] iter = 11630, loss = 1.5496
2024-10-30 23:53:45: [2024-10-30 23:53:45] iter = 11640, loss = 2.0144
2024-10-30 23:53:49: [2024-10-30 23:53:49] iter = 11650, loss = 2.7836
2024-10-30 23:53:53: [2024-10-30 23:53:53] iter = 11660, loss = 2.5914
2024-10-30 23:53:56: [2024-10-30 23:53:56] iter = 11670, loss = 2.2823
2024-10-30 23:54:00: [2024-10-30 23:54:00] iter = 11680, loss = 1.8130
2024-10-30 23:54:04: [2024-10-30 23:54:04] iter = 11690, loss = 1.8354
2024-10-30 23:54:07: [2024-10-30 23:54:07] iter = 11700, loss = 1.9024
2024-10-30 23:54:09: [2024-10-30 23:54:09] iter = 11710, loss = 1.9558
2024-10-30 23:54:12: [2024-10-30 23:54:12] iter = 11720, loss = 2.2073
2024-10-30 23:54:15: [2024-10-30 23:54:15] iter = 11730, loss = 1.7394
2024-10-30 23:54:18: [2024-10-30 23:54:18] iter = 11740, loss = 2.3258
2024-10-30 23:54:20: [2024-10-30 23:54:20] iter = 11750, loss = 3.0258
2024-10-30 23:54:22: [2024-10-30 23:54:22] iter = 11760, loss = 2.0003
2024-10-30 23:54:25: [2024-10-30 23:54:25] iter = 11770, loss = 1.8854
2024-10-30 23:54:29: [2024-10-30 23:54:29] iter = 11780, loss = 2.2132
2024-10-30 23:54:32: [2024-10-30 23:54:32] iter = 11790, loss = 3.5610
2024-10-30 23:54:35: [2024-10-30 23:54:35] iter = 11800, loss = 1.9502
2024-10-30 23:54:38: [2024-10-30 23:54:38] iter = 11810, loss = 2.8162
2024-10-30 23:54:41: [2024-10-30 23:54:41] iter = 11820, loss = 2.1914
2024-10-30 23:54:44: [2024-10-30 23:54:44] iter = 11830, loss = 1.9100
2024-10-30 23:54:46: [2024-10-30 23:54:46] iter = 11840, loss = 2.4201
2024-10-30 23:54:48: [2024-10-30 23:54:48] iter = 11850, loss = 2.0911
2024-10-30 23:54:52: [2024-10-30 23:54:52] iter = 11860, loss = 1.7693
2024-10-30 23:54:56: [2024-10-30 23:54:56] iter = 11870, loss = 1.6411
2024-10-30 23:54:59: [2024-10-30 23:54:59] iter = 11880, loss = 1.7441
2024-10-30 23:55:02: [2024-10-30 23:55:02] iter = 11890, loss = 2.2511
2024-10-30 23:55:06: [2024-10-30 23:55:06] iter = 11900, loss = 1.8592
2024-10-30 23:55:09: [2024-10-30 23:55:09] iter = 11910, loss = 2.0732
2024-10-30 23:55:11: [2024-10-30 23:55:11] iter = 11920, loss = 2.1203
2024-10-30 23:55:14: [2024-10-30 23:55:14] iter = 11930, loss = 1.6119
2024-10-30 23:55:18: [2024-10-30 23:55:18] iter = 11940, loss = 1.9206
2024-10-30 23:55:21: [2024-10-30 23:55:21] iter = 11950, loss = 2.1259
2024-10-30 23:55:25: [2024-10-30 23:55:25] iter = 11960, loss = 2.8902
2024-10-30 23:55:28: [2024-10-30 23:55:28] iter = 11970, loss = 1.9620
2024-10-30 23:55:32: [2024-10-30 23:55:32] iter = 11980, loss = 1.9812
2024-10-30 23:55:36: [2024-10-30 23:55:36] iter = 11990, loss = 1.8446
2024-10-30 23:55:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 23:55:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:55:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 39164}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:57:47: Evaluate 5 random ConvNet, ACCmean = 0.7746 ACCstd = 0.0045
-------------------------
2024-10-30 23:57:47: Evaluate 5 random ConvNet, SENmean = 0.7702 SENstd = 0.0050
-------------------------
2024-10-30 23:57:47: Evaluate 5 random ConvNet, SPEmean = 0.9771 SPEstd = 0.0005
-------------------------
2024-10-30 23:57:47: Evaluate 5 random ConvNet, F!mean = 0.7633 F!std = 0.0047
-------------------------
2024-10-30 23:57:47: Evaluate 5 random ConvNet, mean = 0.7746 std = 0.0045
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:57:47: [2024-10-30 23:57:47] iter = 12000, loss = 2.5875
2024-10-30 23:57:51: [2024-10-30 23:57:51] iter = 12010, loss = 2.7156
2024-10-30 23:57:54: [2024-10-30 23:57:54] iter = 12020, loss = 2.1365
2024-10-30 23:57:58: [2024-10-30 23:57:58] iter = 12030, loss = 2.1203
2024-10-30 23:58:01: [2024-10-30 23:58:01] iter = 12040, loss = 1.9466
2024-10-30 23:58:04: [2024-10-30 23:58:04] iter = 12050, loss = 1.9831
2024-10-30 23:58:07: [2024-10-30 23:58:07] iter = 12060, loss = 1.8623
2024-10-30 23:58:10: [2024-10-30 23:58:10] iter = 12070, loss = 1.9641
2024-10-30 23:58:14: [2024-10-30 23:58:14] iter = 12080, loss = 2.1653
2024-10-30 23:58:17: [2024-10-30 23:58:17] iter = 12090, loss = 2.1062
2024-10-30 23:58:21: [2024-10-30 23:58:21] iter = 12100, loss = 1.9432
2024-10-30 23:58:24: [2024-10-30 23:58:24] iter = 12110, loss = 2.0079
2024-10-30 23:58:27: [2024-10-30 23:58:27] iter = 12120, loss = 5.0810
2024-10-30 23:58:30: [2024-10-30 23:58:30] iter = 12130, loss = 1.9134
2024-10-30 23:58:32: [2024-10-30 23:58:32] iter = 12140, loss = 2.5020
2024-10-30 23:58:36: [2024-10-30 23:58:36] iter = 12150, loss = 1.8203
2024-10-30 23:58:39: [2024-10-30 23:58:39] iter = 12160, loss = 1.9222
2024-10-30 23:58:42: [2024-10-30 23:58:42] iter = 12170, loss = 2.3270
2024-10-30 23:58:46: [2024-10-30 23:58:46] iter = 12180, loss = 2.0507
2024-10-30 23:58:50: [2024-10-30 23:58:50] iter = 12190, loss = 1.9646
2024-10-30 23:58:53: [2024-10-30 23:58:53] iter = 12200, loss = 2.3747
2024-10-30 23:58:55: [2024-10-30 23:58:55] iter = 12210, loss = 2.2256
2024-10-30 23:58:58: [2024-10-30 23:58:58] iter = 12220, loss = 1.9805
2024-10-30 23:59:01: [2024-10-30 23:59:01] iter = 12230, loss = 1.9161
2024-10-30 23:59:04: [2024-10-30 23:59:04] iter = 12240, loss = 3.0630
2024-10-30 23:59:08: [2024-10-30 23:59:08] iter = 12250, loss = 2.0274
2024-10-30 23:59:12: [2024-10-30 23:59:12] iter = 12260, loss = 2.2434
2024-10-30 23:59:15: [2024-10-30 23:59:15] iter = 12270, loss = 3.0934
2024-10-30 23:59:18: [2024-10-30 23:59:18] iter = 12280, loss = 2.1148
2024-10-30 23:59:22: [2024-10-30 23:59:22] iter = 12290, loss = 2.7897
2024-10-30 23:59:25: [2024-10-30 23:59:25] iter = 12300, loss = 2.1448
2024-10-30 23:59:28: [2024-10-30 23:59:28] iter = 12310, loss = 3.4782
2024-10-30 23:59:31: [2024-10-30 23:59:31] iter = 12320, loss = 1.6005
2024-10-30 23:59:34: [2024-10-30 23:59:34] iter = 12330, loss = 2.0158
2024-10-30 23:59:37: [2024-10-30 23:59:37] iter = 12340, loss = 2.0486
2024-10-30 23:59:40: [2024-10-30 23:59:40] iter = 12350, loss = 2.1172
2024-10-30 23:59:43: [2024-10-30 23:59:43] iter = 12360, loss = 2.5289
2024-10-30 23:59:46: [2024-10-30 23:59:46] iter = 12370, loss = 2.1944
2024-10-30 23:59:49: [2024-10-30 23:59:49] iter = 12380, loss = 2.1130
2024-10-30 23:59:52: [2024-10-30 23:59:52] iter = 12390, loss = 1.7827
2024-10-30 23:59:56: [2024-10-30 23:59:56] iter = 12400, loss = 2.0183
2024-10-30 23:59:59: [2024-10-30 23:59:59] iter = 12410, loss = 2.2408
2024-10-31 00:00:02: [2024-10-31 00:00:02] iter = 12420, loss = 2.1314
2024-10-31 00:00:05: [2024-10-31 00:00:05] iter = 12430, loss = 2.5592
2024-10-31 00:00:08: [2024-10-31 00:00:08] iter = 12440, loss = 2.1215
2024-10-31 00:00:12: [2024-10-31 00:00:12] iter = 12450, loss = 3.4898
2024-10-31 00:00:15: [2024-10-31 00:00:15] iter = 12460, loss = 2.2748
2024-10-31 00:00:19: [2024-10-31 00:00:19] iter = 12470, loss = 4.0486
2024-10-31 00:00:22: [2024-10-31 00:00:22] iter = 12480, loss = 2.0539
2024-10-31 00:00:25: [2024-10-31 00:00:25] iter = 12490, loss = 2.6491
2024-10-31 00:00:28: [2024-10-31 00:00:28] iter = 12500, loss = 2.3016
2024-10-31 00:00:32: [2024-10-31 00:00:32] iter = 12510, loss = 1.8142
2024-10-31 00:00:35: [2024-10-31 00:00:35] iter = 12520, loss = 2.3334
2024-10-31 00:00:39: [2024-10-31 00:00:39] iter = 12530, loss = 2.1808
2024-10-31 00:00:42: [2024-10-31 00:00:42] iter = 12540, loss = 2.6887
2024-10-31 00:00:45: [2024-10-31 00:00:45] iter = 12550, loss = 1.9307
2024-10-31 00:00:49: [2024-10-31 00:00:48] iter = 12560, loss = 2.0805
2024-10-31 00:00:52: [2024-10-31 00:00:52] iter = 12570, loss = 2.2530
2024-10-31 00:00:55: [2024-10-31 00:00:55] iter = 12580, loss = 2.0810
2024-10-31 00:00:59: [2024-10-31 00:00:59] iter = 12590, loss = 3.3066
2024-10-31 00:01:02: [2024-10-31 00:01:02] iter = 12600, loss = 4.0933
2024-10-31 00:01:06: [2024-10-31 00:01:06] iter = 12610, loss = 2.5507
2024-10-31 00:01:08: [2024-10-31 00:01:08] iter = 12620, loss = 1.8325
2024-10-31 00:01:11: [2024-10-31 00:01:11] iter = 12630, loss = 2.6206
2024-10-31 00:01:14: [2024-10-31 00:01:14] iter = 12640, loss = 1.6005
2024-10-31 00:01:17: [2024-10-31 00:01:17] iter = 12650, loss = 2.2534
2024-10-31 00:01:20: [2024-10-31 00:01:20] iter = 12660, loss = 2.4850
2024-10-31 00:01:24: [2024-10-31 00:01:24] iter = 12670, loss = 2.1164
2024-10-31 00:01:27: [2024-10-31 00:01:27] iter = 12680, loss = 2.4224
2024-10-31 00:01:30: [2024-10-31 00:01:30] iter = 12690, loss = 1.9970
2024-10-31 00:01:34: [2024-10-31 00:01:34] iter = 12700, loss = 2.2864
2024-10-31 00:01:38: [2024-10-31 00:01:38] iter = 12710, loss = 1.7509
2024-10-31 00:01:41: [2024-10-31 00:01:41] iter = 12720, loss = 1.8149
2024-10-31 00:01:44: [2024-10-31 00:01:44] iter = 12730, loss = 1.6982
2024-10-31 00:01:47: [2024-10-31 00:01:47] iter = 12740, loss = 2.2542
2024-10-31 00:01:51: [2024-10-31 00:01:51] iter = 12750, loss = 2.3755
2024-10-31 00:01:54: [2024-10-31 00:01:54] iter = 12760, loss = 1.8823
2024-10-31 00:01:58: [2024-10-31 00:01:58] iter = 12770, loss = 1.9030
2024-10-31 00:02:01: [2024-10-31 00:02:01] iter = 12780, loss = 1.8717
2024-10-31 00:02:03: [2024-10-31 00:02:03] iter = 12790, loss = 2.2862
2024-10-31 00:02:07: [2024-10-31 00:02:07] iter = 12800, loss = 1.9119
2024-10-31 00:02:11: [2024-10-31 00:02:11] iter = 12810, loss = 1.8907
2024-10-31 00:02:14: [2024-10-31 00:02:14] iter = 12820, loss = 1.8630
2024-10-31 00:02:19: [2024-10-31 00:02:19] iter = 12830, loss = 1.7284
2024-10-31 00:02:22: [2024-10-31 00:02:22] iter = 12840, loss = 1.8440
2024-10-31 00:02:25: [2024-10-31 00:02:25] iter = 12850, loss = 1.7870
2024-10-31 00:02:29: [2024-10-31 00:02:29] iter = 12860, loss = 2.3240
2024-10-31 00:02:32: [2024-10-31 00:02:32] iter = 12870, loss = 1.5063
2024-10-31 00:02:36: [2024-10-31 00:02:36] iter = 12880, loss = 2.1896
2024-10-31 00:02:39: [2024-10-31 00:02:39] iter = 12890, loss = 1.8439
2024-10-31 00:02:42: [2024-10-31 00:02:42] iter = 12900, loss = 1.7900
2024-10-31 00:02:46: [2024-10-31 00:02:46] iter = 12910, loss = 2.0624
2024-10-31 00:02:50: [2024-10-31 00:02:50] iter = 12920, loss = 3.4675
2024-10-31 00:02:53: [2024-10-31 00:02:53] iter = 12930, loss = 2.1764
2024-10-31 00:02:57: [2024-10-31 00:02:57] iter = 12940, loss = 2.7484
2024-10-31 00:03:01: [2024-10-31 00:03:01] iter = 12950, loss = 2.6833
2024-10-31 00:03:04: [2024-10-31 00:03:04] iter = 12960, loss = 1.9962
2024-10-31 00:03:07: [2024-10-31 00:03:07] iter = 12970, loss = 2.3325
2024-10-31 00:03:11: [2024-10-31 00:03:11] iter = 12980, loss = 1.5919
2024-10-31 00:03:14: [2024-10-31 00:03:14] iter = 12990, loss = 2.5358
2024-10-31 00:03:18: [2024-10-31 00:03:18] iter = 13000, loss = 2.5222
2024-10-31 00:03:22: [2024-10-31 00:03:22] iter = 13010, loss = 2.0905
2024-10-31 00:03:26: [2024-10-31 00:03:26] iter = 13020, loss = 2.3698
2024-10-31 00:03:29: [2024-10-31 00:03:29] iter = 13030, loss = 2.4214
2024-10-31 00:03:32: [2024-10-31 00:03:32] iter = 13040, loss = 1.7747
2024-10-31 00:03:35: [2024-10-31 00:03:35] iter = 13050, loss = 2.3663
2024-10-31 00:03:39: [2024-10-31 00:03:39] iter = 13060, loss = 1.6849
2024-10-31 00:03:42: [2024-10-31 00:03:42] iter = 13070, loss = 3.7681
2024-10-31 00:03:46: [2024-10-31 00:03:46] iter = 13080, loss = 1.8119
2024-10-31 00:03:50: [2024-10-31 00:03:50] iter = 13090, loss = 1.9575
2024-10-31 00:03:53: [2024-10-31 00:03:53] iter = 13100, loss = 2.5777
2024-10-31 00:03:56: [2024-10-31 00:03:56] iter = 13110, loss = 2.3149
2024-10-31 00:04:00: [2024-10-31 00:04:00] iter = 13120, loss = 1.9016
2024-10-31 00:04:04: [2024-10-31 00:04:04] iter = 13130, loss = 1.5847
2024-10-31 00:04:07: [2024-10-31 00:04:07] iter = 13140, loss = 1.8371
2024-10-31 00:04:10: [2024-10-31 00:04:10] iter = 13150, loss = 1.8449
2024-10-31 00:04:14: [2024-10-31 00:04:14] iter = 13160, loss = 1.4126
2024-10-31 00:04:18: [2024-10-31 00:04:18] iter = 13170, loss = 1.9405
2024-10-31 00:04:21: [2024-10-31 00:04:21] iter = 13180, loss = 2.1307
2024-10-31 00:04:25: [2024-10-31 00:04:25] iter = 13190, loss = 2.1166
2024-10-31 00:04:29: [2024-10-31 00:04:29] iter = 13200, loss = 2.3021
2024-10-31 00:04:33: [2024-10-31 00:04:33] iter = 13210, loss = 1.8032
2024-10-31 00:04:36: [2024-10-31 00:04:36] iter = 13220, loss = 1.8270
2024-10-31 00:04:40: [2024-10-31 00:04:40] iter = 13230, loss = 2.0286
2024-10-31 00:04:43: [2024-10-31 00:04:43] iter = 13240, loss = 1.7987
2024-10-31 00:04:46: [2024-10-31 00:04:46] iter = 13250, loss = 3.2775
2024-10-31 00:04:49: [2024-10-31 00:04:49] iter = 13260, loss = 1.8703
2024-10-31 00:04:52: [2024-10-31 00:04:52] iter = 13270, loss = 1.8579
2024-10-31 00:04:56: [2024-10-31 00:04:56] iter = 13280, loss = 1.8260
2024-10-31 00:04:59: [2024-10-31 00:04:59] iter = 13290, loss = 1.9796
2024-10-31 00:05:03: [2024-10-31 00:05:03] iter = 13300, loss = 2.9873
2024-10-31 00:05:06: [2024-10-31 00:05:06] iter = 13310, loss = 1.7461
2024-10-31 00:05:10: [2024-10-31 00:05:10] iter = 13320, loss = 2.1563
2024-10-31 00:05:13: [2024-10-31 00:05:13] iter = 13330, loss = 1.7121
2024-10-31 00:05:17: [2024-10-31 00:05:17] iter = 13340, loss = 2.4343
2024-10-31 00:05:21: [2024-10-31 00:05:21] iter = 13350, loss = 1.8474
2024-10-31 00:05:24: [2024-10-31 00:05:24] iter = 13360, loss = 3.3397
2024-10-31 00:05:26: [2024-10-31 00:05:26] iter = 13370, loss = 1.8902
2024-10-31 00:05:29: [2024-10-31 00:05:29] iter = 13380, loss = 3.1591
2024-10-31 00:05:33: [2024-10-31 00:05:33] iter = 13390, loss = 3.0135
2024-10-31 00:05:36: [2024-10-31 00:05:36] iter = 13400, loss = 3.2720
2024-10-31 00:05:39: [2024-10-31 00:05:39] iter = 13410, loss = 1.8551
2024-10-31 00:05:43: [2024-10-31 00:05:43] iter = 13420, loss = 1.7758
2024-10-31 00:05:47: [2024-10-31 00:05:47] iter = 13430, loss = 2.0535
2024-10-31 00:05:50: [2024-10-31 00:05:50] iter = 13440, loss = 2.6489
2024-10-31 00:05:54: [2024-10-31 00:05:54] iter = 13450, loss = 2.7995
2024-10-31 00:05:58: [2024-10-31 00:05:58] iter = 13460, loss = 2.6994
2024-10-31 00:06:02: [2024-10-31 00:06:02] iter = 13470, loss = 1.8981
2024-10-31 00:06:04: [2024-10-31 00:06:04] iter = 13480, loss = 1.8237
2024-10-31 00:06:07: [2024-10-31 00:06:07] iter = 13490, loss = 1.8125
2024-10-31 00:06:11: [2024-10-31 00:06:11] iter = 13500, loss = 1.7394
2024-10-31 00:06:14: [2024-10-31 00:06:14] iter = 13510, loss = 2.2595
2024-10-31 00:06:17: [2024-10-31 00:06:17] iter = 13520, loss = 2.4930
2024-10-31 00:06:20: [2024-10-31 00:06:20] iter = 13530, loss = 3.0120
2024-10-31 00:06:23: [2024-10-31 00:06:23] iter = 13540, loss = 2.5445
2024-10-31 00:06:26: [2024-10-31 00:06:26] iter = 13550, loss = 2.3695
2024-10-31 00:06:29: [2024-10-31 00:06:29] iter = 13560, loss = 1.9777
2024-10-31 00:06:32: [2024-10-31 00:06:32] iter = 13570, loss = 2.0151
2024-10-31 00:06:36: [2024-10-31 00:06:36] iter = 13580, loss = 1.5702
2024-10-31 00:06:38: [2024-10-31 00:06:38] iter = 13590, loss = 3.5701
2024-10-31 00:06:42: [2024-10-31 00:06:42] iter = 13600, loss = 1.8442
2024-10-31 00:06:45: [2024-10-31 00:06:45] iter = 13610, loss = 2.1882
2024-10-31 00:06:48: [2024-10-31 00:06:48] iter = 13620, loss = 2.1361
2024-10-31 00:06:52: [2024-10-31 00:06:52] iter = 13630, loss = 2.7802
2024-10-31 00:06:55: [2024-10-31 00:06:55] iter = 13640, loss = 1.7492
2024-10-31 00:06:58: [2024-10-31 00:06:58] iter = 13650, loss = 1.9757
2024-10-31 00:07:02: [2024-10-31 00:07:02] iter = 13660, loss = 1.9717
2024-10-31 00:07:05: [2024-10-31 00:07:05] iter = 13670, loss = 2.0125
2024-10-31 00:07:08: [2024-10-31 00:07:08] iter = 13680, loss = 2.6353
2024-10-31 00:07:12: [2024-10-31 00:07:12] iter = 13690, loss = 1.9185
2024-10-31 00:07:15: [2024-10-31 00:07:15] iter = 13700, loss = 1.9562
2024-10-31 00:07:18: [2024-10-31 00:07:18] iter = 13710, loss = 1.8967
2024-10-31 00:07:22: [2024-10-31 00:07:22] iter = 13720, loss = 1.7519
2024-10-31 00:07:25: [2024-10-31 00:07:25] iter = 13730, loss = 1.9210
2024-10-31 00:07:28: [2024-10-31 00:07:28] iter = 13740, loss = 1.8688
2024-10-31 00:07:32: [2024-10-31 00:07:32] iter = 13750, loss = 2.5161
2024-10-31 00:07:35: [2024-10-31 00:07:35] iter = 13760, loss = 2.2503
2024-10-31 00:07:38: [2024-10-31 00:07:38] iter = 13770, loss = 2.7771
2024-10-31 00:07:42: [2024-10-31 00:07:42] iter = 13780, loss = 2.1258
2024-10-31 00:07:46: [2024-10-31 00:07:46] iter = 13790, loss = 1.8924
2024-10-31 00:07:49: [2024-10-31 00:07:49] iter = 13800, loss = 1.9917
2024-10-31 00:07:53: [2024-10-31 00:07:53] iter = 13810, loss = 1.7888
2024-10-31 00:07:56: [2024-10-31 00:07:56] iter = 13820, loss = 1.9083
2024-10-31 00:08:00: [2024-10-31 00:08:00] iter = 13830, loss = 2.6031
2024-10-31 00:08:04: [2024-10-31 00:08:04] iter = 13840, loss = 1.9856
2024-10-31 00:08:07: [2024-10-31 00:08:07] iter = 13850, loss = 2.9146
2024-10-31 00:08:10: [2024-10-31 00:08:10] iter = 13860, loss = 1.7845
2024-10-31 00:08:14: [2024-10-31 00:08:14] iter = 13870, loss = 2.2832
2024-10-31 00:08:17: [2024-10-31 00:08:17] iter = 13880, loss = 1.8574
2024-10-31 00:08:21: [2024-10-31 00:08:21] iter = 13890, loss = 2.0387
2024-10-31 00:08:23: [2024-10-31 00:08:23] iter = 13900, loss = 2.0394
2024-10-31 00:08:26: [2024-10-31 00:08:26] iter = 13910, loss = 2.5214
2024-10-31 00:08:29: [2024-10-31 00:08:29] iter = 13920, loss = 2.2348
2024-10-31 00:08:32: [2024-10-31 00:08:32] iter = 13930, loss = 2.1797
2024-10-31 00:08:35: [2024-10-31 00:08:35] iter = 13940, loss = 2.0069
2024-10-31 00:08:38: [2024-10-31 00:08:38] iter = 13950, loss = 3.1724
2024-10-31 00:08:42: [2024-10-31 00:08:42] iter = 13960, loss = 1.9620
2024-10-31 00:08:45: [2024-10-31 00:08:45] iter = 13970, loss = 1.9701
2024-10-31 00:08:48: [2024-10-31 00:08:48] iter = 13980, loss = 4.5693
2024-10-31 00:08:52: [2024-10-31 00:08:52] iter = 13990, loss = 2.0819
2024-10-31 00:08:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-31 00:08:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:08:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 35218}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:11:01: Evaluate 5 random ConvNet, ACCmean = 0.7767 ACCstd = 0.0051
-------------------------
2024-10-31 00:11:01: Evaluate 5 random ConvNet, SENmean = 0.7722 SENstd = 0.0043
-------------------------
2024-10-31 00:11:01: Evaluate 5 random ConvNet, SPEmean = 0.9775 SPEstd = 0.0005
-------------------------
2024-10-31 00:11:01: Evaluate 5 random ConvNet, F!mean = 0.7619 F!std = 0.0050
-------------------------
2024-10-31 00:11:01: Evaluate 5 random ConvNet, mean = 0.7767 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:11:01: [2024-10-31 00:11:01] iter = 14000, loss = 3.4538
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:11:04: [2024-10-31 00:11:04] iter = 14010, loss = 1.5850
2024-10-31 00:11:08: [2024-10-31 00:11:08] iter = 14020, loss = 4.1966
2024-10-31 00:11:11: [2024-10-31 00:11:11] iter = 14030, loss = 1.7961
2024-10-31 00:11:14: [2024-10-31 00:11:14] iter = 14040, loss = 1.6485
2024-10-31 00:11:17: [2024-10-31 00:11:17] iter = 14050, loss = 1.8505
2024-10-31 00:11:19: [2024-10-31 00:11:19] iter = 14060, loss = 3.6408
2024-10-31 00:11:24: [2024-10-31 00:11:24] iter = 14070, loss = 1.7455
2024-10-31 00:11:27: [2024-10-31 00:11:27] iter = 14080, loss = 3.2992
2024-10-31 00:11:31: [2024-10-31 00:11:31] iter = 14090, loss = 2.1334
2024-10-31 00:11:35: [2024-10-31 00:11:35] iter = 14100, loss = 2.2003
2024-10-31 00:11:37: [2024-10-31 00:11:37] iter = 14110, loss = 2.0256
2024-10-31 00:11:41: [2024-10-31 00:11:41] iter = 14120, loss = 2.1969
2024-10-31 00:11:44: [2024-10-31 00:11:44] iter = 14130, loss = 2.9535
2024-10-31 00:11:46: [2024-10-31 00:11:46] iter = 14140, loss = 1.8910
2024-10-31 00:11:50: [2024-10-31 00:11:50] iter = 14150, loss = 2.0900
2024-10-31 00:11:53: [2024-10-31 00:11:53] iter = 14160, loss = 1.9555
2024-10-31 00:11:56: [2024-10-31 00:11:56] iter = 14170, loss = 1.9384
2024-10-31 00:12:01: [2024-10-31 00:12:01] iter = 14180, loss = 2.1479
2024-10-31 00:12:03: [2024-10-31 00:12:03] iter = 14190, loss = 1.8828
2024-10-31 00:12:06: [2024-10-31 00:12:06] iter = 14200, loss = 1.8631
2024-10-31 00:12:11: [2024-10-31 00:12:11] iter = 14210, loss = 2.3585
2024-10-31 00:12:15: [2024-10-31 00:12:15] iter = 14220, loss = 1.7889
2024-10-31 00:12:18: [2024-10-31 00:12:18] iter = 14230, loss = 2.0346
2024-10-31 00:12:21: [2024-10-31 00:12:21] iter = 14240, loss = 1.9248
2024-10-31 00:12:24: [2024-10-31 00:12:24] iter = 14250, loss = 1.8803
2024-10-31 00:12:27: [2024-10-31 00:12:27] iter = 14260, loss = 3.3062
2024-10-31 00:12:31: [2024-10-31 00:12:31] iter = 14270, loss = 2.1708
2024-10-31 00:12:34: [2024-10-31 00:12:34] iter = 14280, loss = 1.7629
2024-10-31 00:12:37: [2024-10-31 00:12:37] iter = 14290, loss = 3.4285
2024-10-31 00:12:39: [2024-10-31 00:12:39] iter = 14300, loss = 2.3853
2024-10-31 00:12:43: [2024-10-31 00:12:43] iter = 14310, loss = 2.0721
2024-10-31 00:12:46: [2024-10-31 00:12:46] iter = 14320, loss = 3.1130
2024-10-31 00:12:50: [2024-10-31 00:12:50] iter = 14330, loss = 2.2964
2024-10-31 00:12:54: [2024-10-31 00:12:54] iter = 14340, loss = 3.3032
2024-10-31 00:12:57: [2024-10-31 00:12:57] iter = 14350, loss = 3.6858
2024-10-31 00:13:01: [2024-10-31 00:13:01] iter = 14360, loss = 2.2584
2024-10-31 00:13:04: [2024-10-31 00:13:04] iter = 14370, loss = 2.2108
2024-10-31 00:13:08: [2024-10-31 00:13:08] iter = 14380, loss = 2.1521
2024-10-31 00:13:12: [2024-10-31 00:13:12] iter = 14390, loss = 2.1278
2024-10-31 00:13:16: [2024-10-31 00:13:16] iter = 14400, loss = 1.8902
2024-10-31 00:13:19: [2024-10-31 00:13:19] iter = 14410, loss = 2.0562
2024-10-31 00:13:23: [2024-10-31 00:13:23] iter = 14420, loss = 2.4787
2024-10-31 00:13:26: [2024-10-31 00:13:26] iter = 14430, loss = 3.1225
2024-10-31 00:13:31: [2024-10-31 00:13:31] iter = 14440, loss = 2.0604
2024-10-31 00:13:34: [2024-10-31 00:13:34] iter = 14450, loss = 1.8589
2024-10-31 00:13:38: [2024-10-31 00:13:38] iter = 14460, loss = 1.9139
2024-10-31 00:13:41: [2024-10-31 00:13:41] iter = 14470, loss = 2.0954
2024-10-31 00:13:45: [2024-10-31 00:13:45] iter = 14480, loss = 2.0284
2024-10-31 00:13:48: [2024-10-31 00:13:48] iter = 14490, loss = 2.1526
2024-10-31 00:13:52: [2024-10-31 00:13:52] iter = 14500, loss = 2.0384
2024-10-31 00:13:56: [2024-10-31 00:13:56] iter = 14510, loss = 2.7554
2024-10-31 00:13:59: [2024-10-31 00:13:59] iter = 14520, loss = 2.3872
2024-10-31 00:14:03: [2024-10-31 00:14:03] iter = 14530, loss = 1.6125
2024-10-31 00:14:07: [2024-10-31 00:14:07] iter = 14540, loss = 1.8492
2024-10-31 00:14:11: [2024-10-31 00:14:11] iter = 14550, loss = 1.9256
2024-10-31 00:14:15: [2024-10-31 00:14:15] iter = 14560, loss = 1.7853
2024-10-31 00:14:17: [2024-10-31 00:14:17] iter = 14570, loss = 2.0767
2024-10-31 00:14:20: [2024-10-31 00:14:20] iter = 14580, loss = 2.1947
2024-10-31 00:14:24: [2024-10-31 00:14:24] iter = 14590, loss = 1.9844
2024-10-31 00:14:28: [2024-10-31 00:14:28] iter = 14600, loss = 2.2867
2024-10-31 00:14:32: [2024-10-31 00:14:32] iter = 14610, loss = 1.7707
2024-10-31 00:14:36: [2024-10-31 00:14:36] iter = 14620, loss = 2.3040
2024-10-31 00:14:40: [2024-10-31 00:14:40] iter = 14630, loss = 2.2480
2024-10-31 00:14:44: [2024-10-31 00:14:44] iter = 14640, loss = 1.6533
2024-10-31 00:14:47: [2024-10-31 00:14:47] iter = 14650, loss = 2.1242
2024-10-31 00:14:50: [2024-10-31 00:14:50] iter = 14660, loss = 1.9932
2024-10-31 00:14:54: [2024-10-31 00:14:54] iter = 14670, loss = 2.9378
2024-10-31 00:14:57: [2024-10-31 00:14:57] iter = 14680, loss = 3.2072
2024-10-31 00:15:02: [2024-10-31 00:15:01] iter = 14690, loss = 2.6221
2024-10-31 00:15:05: [2024-10-31 00:15:05] iter = 14700, loss = 2.0743
2024-10-31 00:15:09: [2024-10-31 00:15:09] iter = 14710, loss = 2.4715
2024-10-31 00:15:12: [2024-10-31 00:15:12] iter = 14720, loss = 1.7721
2024-10-31 00:15:16: [2024-10-31 00:15:16] iter = 14730, loss = 1.9379
2024-10-31 00:15:20: [2024-10-31 00:15:20] iter = 14740, loss = 1.9295
2024-10-31 00:15:23: [2024-10-31 00:15:23] iter = 14750, loss = 1.8569
2024-10-31 00:15:27: [2024-10-31 00:15:27] iter = 14760, loss = 1.9915
2024-10-31 00:15:31: [2024-10-31 00:15:31] iter = 14770, loss = 2.2911
2024-10-31 00:15:34: [2024-10-31 00:15:34] iter = 14780, loss = 2.2858
2024-10-31 00:15:37: [2024-10-31 00:15:37] iter = 14790, loss = 2.3598
2024-10-31 00:15:40: [2024-10-31 00:15:40] iter = 14800, loss = 2.8618
2024-10-31 00:15:43: [2024-10-31 00:15:43] iter = 14810, loss = 1.8701
2024-10-31 00:15:46: [2024-10-31 00:15:46] iter = 14820, loss = 1.9673
2024-10-31 00:15:49: [2024-10-31 00:15:49] iter = 14830, loss = 3.6536
2024-10-31 00:15:53: [2024-10-31 00:15:53] iter = 14840, loss = 1.9277
2024-10-31 00:15:58: [2024-10-31 00:15:58] iter = 14850, loss = 2.0448
2024-10-31 00:16:01: [2024-10-31 00:16:01] iter = 14860, loss = 2.7522
2024-10-31 00:16:04: [2024-10-31 00:16:04] iter = 14870, loss = 2.2072
2024-10-31 00:16:08: [2024-10-31 00:16:08] iter = 14880, loss = 1.9852
2024-10-31 00:16:11: [2024-10-31 00:16:11] iter = 14890, loss = 2.4033
2024-10-31 00:16:15: [2024-10-31 00:16:15] iter = 14900, loss = 2.3224
2024-10-31 00:16:18: [2024-10-31 00:16:18] iter = 14910, loss = 1.9096
2024-10-31 00:16:22: [2024-10-31 00:16:22] iter = 14920, loss = 2.0585
2024-10-31 00:16:25: [2024-10-31 00:16:25] iter = 14930, loss = 2.3062
2024-10-31 00:16:29: [2024-10-31 00:16:29] iter = 14940, loss = 2.1552
2024-10-31 00:16:32: [2024-10-31 00:16:32] iter = 14950, loss = 2.5797
2024-10-31 00:16:36: [2024-10-31 00:16:36] iter = 14960, loss = 2.1184
2024-10-31 00:16:39: [2024-10-31 00:16:39] iter = 14970, loss = 1.7576
2024-10-31 00:16:42: [2024-10-31 00:16:42] iter = 14980, loss = 2.7881
2024-10-31 00:16:44: [2024-10-31 00:16:44] iter = 14990, loss = 2.5169
2024-10-31 00:16:47: [2024-10-31 00:16:47] iter = 15000, loss = 1.9788
2024-10-31 00:16:50: [2024-10-31 00:16:50] iter = 15010, loss = 1.8298
2024-10-31 00:16:54: [2024-10-31 00:16:54] iter = 15020, loss = 1.7475
2024-10-31 00:16:57: [2024-10-31 00:16:57] iter = 15030, loss = 2.2378
2024-10-31 00:17:01: [2024-10-31 00:17:01] iter = 15040, loss = 1.7622
2024-10-31 00:17:04: [2024-10-31 00:17:04] iter = 15050, loss = 1.8250
2024-10-31 00:17:08: [2024-10-31 00:17:08] iter = 15060, loss = 1.9164
2024-10-31 00:17:11: [2024-10-31 00:17:11] iter = 15070, loss = 2.0194
2024-10-31 00:17:15: [2024-10-31 00:17:15] iter = 15080, loss = 2.2809
2024-10-31 00:17:19: [2024-10-31 00:17:19] iter = 15090, loss = 1.7300
2024-10-31 00:17:22: [2024-10-31 00:17:22] iter = 15100, loss = 1.7810
2024-10-31 00:17:25: [2024-10-31 00:17:25] iter = 15110, loss = 3.1509
2024-10-31 00:17:29: [2024-10-31 00:17:29] iter = 15120, loss = 2.0044
2024-10-31 00:17:32: [2024-10-31 00:17:32] iter = 15130, loss = 2.3959
2024-10-31 00:17:36: [2024-10-31 00:17:36] iter = 15140, loss = 2.1587
2024-10-31 00:17:39: [2024-10-31 00:17:39] iter = 15150, loss = 3.0837
2024-10-31 00:17:42: [2024-10-31 00:17:41] iter = 15160, loss = 1.8357
2024-10-31 00:17:45: [2024-10-31 00:17:45] iter = 15170, loss = 2.1177
2024-10-31 00:17:49: [2024-10-31 00:17:49] iter = 15180, loss = 2.7942
2024-10-31 00:17:52: [2024-10-31 00:17:52] iter = 15190, loss = 2.1769
2024-10-31 00:17:55: [2024-10-31 00:17:55] iter = 15200, loss = 2.3101
2024-10-31 00:17:58: [2024-10-31 00:17:58] iter = 15210, loss = 2.0083
2024-10-31 00:18:02: [2024-10-31 00:18:02] iter = 15220, loss = 1.9105
2024-10-31 00:18:06: [2024-10-31 00:18:06] iter = 15230, loss = 2.2056
2024-10-31 00:18:09: [2024-10-31 00:18:09] iter = 15240, loss = 2.3632
2024-10-31 00:18:13: [2024-10-31 00:18:13] iter = 15250, loss = 2.6654
2024-10-31 00:18:17: [2024-10-31 00:18:17] iter = 15260, loss = 2.6506
2024-10-31 00:18:20: [2024-10-31 00:18:20] iter = 15270, loss = 2.1042
2024-10-31 00:18:24: [2024-10-31 00:18:24] iter = 15280, loss = 2.7964
2024-10-31 00:18:28: [2024-10-31 00:18:28] iter = 15290, loss = 1.9772
2024-10-31 00:18:32: [2024-10-31 00:18:32] iter = 15300, loss = 2.3275
2024-10-31 00:18:36: [2024-10-31 00:18:36] iter = 15310, loss = 2.3807
2024-10-31 00:18:39: [2024-10-31 00:18:39] iter = 15320, loss = 1.8948
2024-10-31 00:18:43: [2024-10-31 00:18:43] iter = 15330, loss = 2.2045
2024-10-31 00:18:46: [2024-10-31 00:18:46] iter = 15340, loss = 2.4896
2024-10-31 00:18:49: [2024-10-31 00:18:49] iter = 15350, loss = 2.0819
2024-10-31 00:18:53: [2024-10-31 00:18:53] iter = 15360, loss = 2.7913
2024-10-31 00:18:56: [2024-10-31 00:18:56] iter = 15370, loss = 2.3674
2024-10-31 00:19:00: [2024-10-31 00:19:00] iter = 15380, loss = 2.5687
2024-10-31 00:19:04: [2024-10-31 00:19:04] iter = 15390, loss = 2.3481
2024-10-31 00:19:08: [2024-10-31 00:19:08] iter = 15400, loss = 2.1832
2024-10-31 00:19:11: [2024-10-31 00:19:11] iter = 15410, loss = 2.3682
2024-10-31 00:19:14: [2024-10-31 00:19:14] iter = 15420, loss = 3.2418
2024-10-31 00:19:17: [2024-10-31 00:19:17] iter = 15430, loss = 1.6301
2024-10-31 00:19:20: [2024-10-31 00:19:20] iter = 15440, loss = 2.1945
2024-10-31 00:19:23: [2024-10-31 00:19:23] iter = 15450, loss = 2.3747
2024-10-31 00:19:27: [2024-10-31 00:19:27] iter = 15460, loss = 1.8771
2024-10-31 00:19:30: [2024-10-31 00:19:30] iter = 15470, loss = 2.3654
2024-10-31 00:19:34: [2024-10-31 00:19:34] iter = 15480, loss = 1.8013
2024-10-31 00:19:37: [2024-10-31 00:19:37] iter = 15490, loss = 1.9437
2024-10-31 00:19:40: [2024-10-31 00:19:40] iter = 15500, loss = 3.1750
2024-10-31 00:19:44: [2024-10-31 00:19:44] iter = 15510, loss = 2.1454
2024-10-31 00:19:47: [2024-10-31 00:19:47] iter = 15520, loss = 2.6990
2024-10-31 00:19:50: [2024-10-31 00:19:50] iter = 15530, loss = 3.9241
2024-10-31 00:19:54: [2024-10-31 00:19:54] iter = 15540, loss = 2.6313
2024-10-31 00:19:57: [2024-10-31 00:19:57] iter = 15550, loss = 1.5899
2024-10-31 00:20:01: [2024-10-31 00:20:01] iter = 15560, loss = 2.1567
2024-10-31 00:20:04: [2024-10-31 00:20:04] iter = 15570, loss = 3.9361
2024-10-31 00:20:07: [2024-10-31 00:20:07] iter = 15580, loss = 2.0151
2024-10-31 00:20:09: [2024-10-31 00:20:09] iter = 15590, loss = 2.9362
2024-10-31 00:20:12: [2024-10-31 00:20:12] iter = 15600, loss = 1.9682
2024-10-31 00:20:16: [2024-10-31 00:20:16] iter = 15610, loss = 1.9416
2024-10-31 00:20:19: [2024-10-31 00:20:19] iter = 15620, loss = 1.7013
2024-10-31 00:20:23: [2024-10-31 00:20:23] iter = 15630, loss = 1.9076
2024-10-31 00:20:26: [2024-10-31 00:20:26] iter = 15640, loss = 4.1598
2024-10-31 00:20:29: [2024-10-31 00:20:29] iter = 15650, loss = 2.8804
2024-10-31 00:20:32: [2024-10-31 00:20:32] iter = 15660, loss = 1.7105
2024-10-31 00:20:34: [2024-10-31 00:20:34] iter = 15670, loss = 2.4402
2024-10-31 00:20:37: [2024-10-31 00:20:37] iter = 15680, loss = 1.9259
2024-10-31 00:20:40: [2024-10-31 00:20:40] iter = 15690, loss = 1.6612
2024-10-31 00:20:44: [2024-10-31 00:20:44] iter = 15700, loss = 1.8054
2024-10-31 00:20:47: [2024-10-31 00:20:47] iter = 15710, loss = 1.7747
2024-10-31 00:20:51: [2024-10-31 00:20:51] iter = 15720, loss = 2.0249
2024-10-31 00:20:55: [2024-10-31 00:20:55] iter = 15730, loss = 3.0306
2024-10-31 00:20:58: [2024-10-31 00:20:58] iter = 15740, loss = 1.5535
2024-10-31 00:21:02: [2024-10-31 00:21:02] iter = 15750, loss = 1.8211
2024-10-31 00:21:05: [2024-10-31 00:21:05] iter = 15760, loss = 3.1452
2024-10-31 00:21:08: [2024-10-31 00:21:08] iter = 15770, loss = 2.1558
2024-10-31 00:21:11: [2024-10-31 00:21:11] iter = 15780, loss = 2.0056
2024-10-31 00:21:15: [2024-10-31 00:21:14] iter = 15790, loss = 1.6737
2024-10-31 00:21:18: [2024-10-31 00:21:18] iter = 15800, loss = 2.1366
2024-10-31 00:21:22: [2024-10-31 00:21:22] iter = 15810, loss = 2.0747
2024-10-31 00:21:26: [2024-10-31 00:21:26] iter = 15820, loss = 2.1201
2024-10-31 00:21:30: [2024-10-31 00:21:30] iter = 15830, loss = 3.0535
2024-10-31 00:21:33: [2024-10-31 00:21:33] iter = 15840, loss = 2.5884
2024-10-31 00:21:36: [2024-10-31 00:21:36] iter = 15850, loss = 2.1050
2024-10-31 00:21:39: [2024-10-31 00:21:39] iter = 15860, loss = 2.7619
2024-10-31 00:21:42: [2024-10-31 00:21:42] iter = 15870, loss = 1.7124
2024-10-31 00:21:45: [2024-10-31 00:21:45] iter = 15880, loss = 2.1215
2024-10-31 00:21:50: [2024-10-31 00:21:50] iter = 15890, loss = 2.0746
2024-10-31 00:21:52: [2024-10-31 00:21:52] iter = 15900, loss = 1.8537
2024-10-31 00:21:55: [2024-10-31 00:21:55] iter = 15910, loss = 2.2088
2024-10-31 00:21:57: [2024-10-31 00:21:57] iter = 15920, loss = 1.7992
2024-10-31 00:22:00: [2024-10-31 00:22:00] iter = 15930, loss = 2.7144
2024-10-31 00:22:03: [2024-10-31 00:22:03] iter = 15940, loss = 2.3240
2024-10-31 00:22:07: [2024-10-31 00:22:07] iter = 15950, loss = 2.6240
2024-10-31 00:22:10: [2024-10-31 00:22:10] iter = 15960, loss = 2.5528
2024-10-31 00:22:13: [2024-10-31 00:22:13] iter = 15970, loss = 1.9837
2024-10-31 00:22:16: [2024-10-31 00:22:16] iter = 15980, loss = 2.1604
2024-10-31 00:22:18: [2024-10-31 00:22:18] iter = 15990, loss = 2.1563
2024-10-31 00:22:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-31 00:22:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:22:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 40748}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:24:26: Evaluate 5 random ConvNet, ACCmean = 0.7864 ACCstd = 0.0023
-------------------------
2024-10-31 00:24:26: Evaluate 5 random ConvNet, SENmean = 0.7805 SENstd = 0.0014
-------------------------
2024-10-31 00:24:26: Evaluate 5 random ConvNet, SPEmean = 0.9784 SPEstd = 0.0002
-------------------------
2024-10-31 00:24:26: Evaluate 5 random ConvNet, F!mean = 0.7737 F!std = 0.0016
-------------------------
2024-10-31 00:24:26: Evaluate 5 random ConvNet, mean = 0.7864 std = 0.0023
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:24:27: [2024-10-31 00:24:27] iter = 16000, loss = 2.7406
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:24:30: [2024-10-31 00:24:30] iter = 16010, loss = 2.1072
2024-10-31 00:24:34: [2024-10-31 00:24:34] iter = 16020, loss = 2.3465
2024-10-31 00:24:38: [2024-10-31 00:24:38] iter = 16030, loss = 2.4914
2024-10-31 00:24:40: [2024-10-31 00:24:40] iter = 16040, loss = 1.9275
2024-10-31 00:24:44: [2024-10-31 00:24:44] iter = 16050, loss = 2.0132
2024-10-31 00:24:47: [2024-10-31 00:24:47] iter = 16060, loss = 2.7198
2024-10-31 00:24:50: [2024-10-31 00:24:50] iter = 16070, loss = 1.6555
2024-10-31 00:24:54: [2024-10-31 00:24:54] iter = 16080, loss = 2.3368
2024-10-31 00:24:58: [2024-10-31 00:24:58] iter = 16090, loss = 2.3927
2024-10-31 00:25:02: [2024-10-31 00:25:02] iter = 16100, loss = 1.8224
2024-10-31 00:25:06: [2024-10-31 00:25:06] iter = 16110, loss = 1.6924
2024-10-31 00:25:09: [2024-10-31 00:25:09] iter = 16120, loss = 3.3345
2024-10-31 00:25:13: [2024-10-31 00:25:13] iter = 16130, loss = 2.8601
2024-10-31 00:25:18: [2024-10-31 00:25:18] iter = 16140, loss = 1.8756
2024-10-31 00:25:21: [2024-10-31 00:25:21] iter = 16150, loss = 1.7096
2024-10-31 00:25:25: [2024-10-31 00:25:25] iter = 16160, loss = 1.8027
2024-10-31 00:25:30: [2024-10-31 00:25:30] iter = 16170, loss = 3.2275
2024-10-31 00:25:34: [2024-10-31 00:25:34] iter = 16180, loss = 2.1951
2024-10-31 00:25:37: [2024-10-31 00:25:37] iter = 16190, loss = 1.6702
2024-10-31 00:25:42: [2024-10-31 00:25:42] iter = 16200, loss = 2.5495
2024-10-31 00:25:45: [2024-10-31 00:25:45] iter = 16210, loss = 2.6688
2024-10-31 00:25:50: [2024-10-31 00:25:50] iter = 16220, loss = 2.0315
2024-10-31 00:25:54: [2024-10-31 00:25:54] iter = 16230, loss = 1.9861
2024-10-31 00:25:58: [2024-10-31 00:25:58] iter = 16240, loss = 2.4525
2024-10-31 00:26:02: [2024-10-31 00:26:02] iter = 16250, loss = 2.8476
2024-10-31 00:26:05: [2024-10-31 00:26:05] iter = 16260, loss = 2.5785
2024-10-31 00:26:10: [2024-10-31 00:26:10] iter = 16270, loss = 1.9294
2024-10-31 00:26:14: [2024-10-31 00:26:14] iter = 16280, loss = 1.8628
2024-10-31 00:26:18: [2024-10-31 00:26:18] iter = 16290, loss = 2.0480
2024-10-31 00:26:22: [2024-10-31 00:26:22] iter = 16300, loss = 2.4841
2024-10-31 00:26:25: [2024-10-31 00:26:25] iter = 16310, loss = 1.7615
2024-10-31 00:26:29: [2024-10-31 00:26:29] iter = 16320, loss = 2.2280
2024-10-31 00:26:32: [2024-10-31 00:26:32] iter = 16330, loss = 2.5105
2024-10-31 00:26:35: [2024-10-31 00:26:35] iter = 16340, loss = 2.0433
2024-10-31 00:26:39: [2024-10-31 00:26:39] iter = 16350, loss = 1.7156
2024-10-31 00:26:42: [2024-10-31 00:26:42] iter = 16360, loss = 1.8459
2024-10-31 00:26:45: [2024-10-31 00:26:45] iter = 16370, loss = 2.2623
2024-10-31 00:26:49: [2024-10-31 00:26:49] iter = 16380, loss = 2.3014
2024-10-31 00:26:52: [2024-10-31 00:26:52] iter = 16390, loss = 2.4519
2024-10-31 00:26:55: [2024-10-31 00:26:55] iter = 16400, loss = 1.9544
2024-10-31 00:26:58: [2024-10-31 00:26:58] iter = 16410, loss = 2.2358
2024-10-31 00:27:01: [2024-10-31 00:27:01] iter = 16420, loss = 1.8228
2024-10-31 00:27:04: [2024-10-31 00:27:04] iter = 16430, loss = 1.8049
2024-10-31 00:27:07: [2024-10-31 00:27:07] iter = 16440, loss = 2.1907
2024-10-31 00:27:11: [2024-10-31 00:27:11] iter = 16450, loss = 1.9152
2024-10-31 00:27:15: [2024-10-31 00:27:15] iter = 16460, loss = 1.7676
2024-10-31 00:27:18: [2024-10-31 00:27:18] iter = 16470, loss = 1.8583
2024-10-31 00:27:21: [2024-10-31 00:27:21] iter = 16480, loss = 3.0390
2024-10-31 00:27:24: [2024-10-31 00:27:24] iter = 16490, loss = 2.3934
2024-10-31 00:27:27: [2024-10-31 00:27:27] iter = 16500, loss = 2.2773
2024-10-31 00:27:31: [2024-10-31 00:27:31] iter = 16510, loss = 1.8869
2024-10-31 00:27:34: [2024-10-31 00:27:34] iter = 16520, loss = 2.2921
2024-10-31 00:27:37: [2024-10-31 00:27:37] iter = 16530, loss = 2.7479
2024-10-31 00:27:41: [2024-10-31 00:27:41] iter = 16540, loss = 1.9167
2024-10-31 00:27:45: [2024-10-31 00:27:45] iter = 16550, loss = 5.1864
2024-10-31 00:27:48: [2024-10-31 00:27:48] iter = 16560, loss = 1.9396
2024-10-31 00:27:52: [2024-10-31 00:27:52] iter = 16570, loss = 2.1378
2024-10-31 00:27:56: [2024-10-31 00:27:56] iter = 16580, loss = 2.0110
2024-10-31 00:28:01: [2024-10-31 00:28:01] iter = 16590, loss = 2.0605
2024-10-31 00:28:05: [2024-10-31 00:28:05] iter = 16600, loss = 1.7401
2024-10-31 00:28:08: [2024-10-31 00:28:08] iter = 16610, loss = 2.3574
2024-10-31 00:28:11: [2024-10-31 00:28:11] iter = 16620, loss = 2.0094
2024-10-31 00:28:15: [2024-10-31 00:28:15] iter = 16630, loss = 2.1097
2024-10-31 00:28:19: [2024-10-31 00:28:19] iter = 16640, loss = 2.0644
2024-10-31 00:28:22: [2024-10-31 00:28:22] iter = 16650, loss = 2.0439
2024-10-31 00:28:26: [2024-10-31 00:28:26] iter = 16660, loss = 1.9690
2024-10-31 00:28:30: [2024-10-31 00:28:30] iter = 16670, loss = 2.5049
2024-10-31 00:28:33: [2024-10-31 00:28:33] iter = 16680, loss = 2.4404
2024-10-31 00:28:36: [2024-10-31 00:28:36] iter = 16690, loss = 2.5260
2024-10-31 00:28:39: [2024-10-31 00:28:39] iter = 16700, loss = 3.4354
2024-10-31 00:28:42: [2024-10-31 00:28:42] iter = 16710, loss = 1.8210
2024-10-31 00:28:46: [2024-10-31 00:28:46] iter = 16720, loss = 1.9402
2024-10-31 00:28:50: [2024-10-31 00:28:50] iter = 16730, loss = 2.1443
2024-10-31 00:28:54: [2024-10-31 00:28:54] iter = 16740, loss = 2.3387
2024-10-31 00:28:57: [2024-10-31 00:28:57] iter = 16750, loss = 2.3761
2024-10-31 00:29:01: [2024-10-31 00:29:01] iter = 16760, loss = 2.6632
2024-10-31 00:29:04: [2024-10-31 00:29:04] iter = 16770, loss = 2.3393
2024-10-31 00:29:07: [2024-10-31 00:29:07] iter = 16780, loss = 1.9824
2024-10-31 00:29:10: [2024-10-31 00:29:10] iter = 16790, loss = 1.8573
2024-10-31 00:29:13: [2024-10-31 00:29:13] iter = 16800, loss = 1.8089
2024-10-31 00:29:16: [2024-10-31 00:29:16] iter = 16810, loss = 2.1222
2024-10-31 00:29:19: [2024-10-31 00:29:19] iter = 16820, loss = 2.4992
2024-10-31 00:29:23: [2024-10-31 00:29:23] iter = 16830, loss = 1.7582
2024-10-31 00:29:26: [2024-10-31 00:29:26] iter = 16840, loss = 1.6028
2024-10-31 00:29:29: [2024-10-31 00:29:29] iter = 16850, loss = 2.2792
2024-10-31 00:29:32: [2024-10-31 00:29:32] iter = 16860, loss = 2.1609
2024-10-31 00:29:36: [2024-10-31 00:29:36] iter = 16870, loss = 2.0273
2024-10-31 00:29:40: [2024-10-31 00:29:40] iter = 16880, loss = 1.7568
2024-10-31 00:29:43: [2024-10-31 00:29:43] iter = 16890, loss = 2.6594
2024-10-31 00:29:47: [2024-10-31 00:29:47] iter = 16900, loss = 2.0966
2024-10-31 00:29:51: [2024-10-31 00:29:51] iter = 16910, loss = 2.5112
2024-10-31 00:29:55: [2024-10-31 00:29:55] iter = 16920, loss = 2.2547
2024-10-31 00:29:58: [2024-10-31 00:29:58] iter = 16930, loss = 1.9919
2024-10-31 00:30:02: [2024-10-31 00:30:02] iter = 16940, loss = 4.4201
2024-10-31 00:30:06: [2024-10-31 00:30:06] iter = 16950, loss = 1.9187
2024-10-31 00:30:09: [2024-10-31 00:30:09] iter = 16960, loss = 2.3581
2024-10-31 00:30:13: [2024-10-31 00:30:13] iter = 16970, loss = 1.8061
2024-10-31 00:30:16: [2024-10-31 00:30:16] iter = 16980, loss = 2.1385
2024-10-31 00:30:20: [2024-10-31 00:30:20] iter = 16990, loss = 2.7920
2024-10-31 00:30:25: [2024-10-31 00:30:25] iter = 17000, loss = 2.0276
2024-10-31 00:30:29: [2024-10-31 00:30:29] iter = 17010, loss = 1.9040
2024-10-31 00:30:33: [2024-10-31 00:30:33] iter = 17020, loss = 1.6760
2024-10-31 00:30:36: [2024-10-31 00:30:36] iter = 17030, loss = 2.7141
2024-10-31 00:30:40: [2024-10-31 00:30:40] iter = 17040, loss = 2.4742
2024-10-31 00:30:43: [2024-10-31 00:30:43] iter = 17050, loss = 2.4859
2024-10-31 00:30:47: [2024-10-31 00:30:47] iter = 17060, loss = 2.9170
2024-10-31 00:30:50: [2024-10-31 00:30:50] iter = 17070, loss = 2.2298
2024-10-31 00:30:54: [2024-10-31 00:30:54] iter = 17080, loss = 1.8977
2024-10-31 00:30:57: [2024-10-31 00:30:57] iter = 17090, loss = 2.2565
2024-10-31 00:31:01: [2024-10-31 00:31:01] iter = 17100, loss = 2.9537
2024-10-31 00:31:05: [2024-10-31 00:31:05] iter = 17110, loss = 1.7656
2024-10-31 00:31:09: [2024-10-31 00:31:09] iter = 17120, loss = 1.8132
2024-10-31 00:31:13: [2024-10-31 00:31:13] iter = 17130, loss = 2.2011
2024-10-31 00:31:16: [2024-10-31 00:31:16] iter = 17140, loss = 2.4640
2024-10-31 00:31:19: [2024-10-31 00:31:19] iter = 17150, loss = 2.0403
2024-10-31 00:31:23: [2024-10-31 00:31:23] iter = 17160, loss = 3.2883
2024-10-31 00:31:26: [2024-10-31 00:31:26] iter = 17170, loss = 1.8523
2024-10-31 00:31:30: [2024-10-31 00:31:30] iter = 17180, loss = 2.6340
2024-10-31 00:31:33: [2024-10-31 00:31:33] iter = 17190, loss = 2.6690
2024-10-31 00:31:37: [2024-10-31 00:31:37] iter = 17200, loss = 2.2009
2024-10-31 00:31:41: [2024-10-31 00:31:41] iter = 17210, loss = 3.7040
2024-10-31 00:31:43: [2024-10-31 00:31:43] iter = 17220, loss = 2.4408
2024-10-31 00:31:48: [2024-10-31 00:31:48] iter = 17230, loss = 2.4112
2024-10-31 00:31:51: [2024-10-31 00:31:51] iter = 17240, loss = 2.2295
2024-10-31 00:31:55: [2024-10-31 00:31:55] iter = 17250, loss = 2.3099
2024-10-31 00:31:59: [2024-10-31 00:31:59] iter = 17260, loss = 2.1506
2024-10-31 00:32:02: [2024-10-31 00:32:02] iter = 17270, loss = 1.9880
2024-10-31 00:32:06: [2024-10-31 00:32:06] iter = 17280, loss = 2.7159
2024-10-31 00:32:09: [2024-10-31 00:32:09] iter = 17290, loss = 2.4168
2024-10-31 00:32:12: [2024-10-31 00:32:12] iter = 17300, loss = 5.2638
2024-10-31 00:32:16: [2024-10-31 00:32:16] iter = 17310, loss = 2.0490
2024-10-31 00:32:20: [2024-10-31 00:32:20] iter = 17320, loss = 1.8725
2024-10-31 00:32:23: [2024-10-31 00:32:23] iter = 17330, loss = 2.8677
2024-10-31 00:32:26: [2024-10-31 00:32:26] iter = 17340, loss = 1.7593
2024-10-31 00:32:30: [2024-10-31 00:32:30] iter = 17350, loss = 1.8203
2024-10-31 00:32:34: [2024-10-31 00:32:34] iter = 17360, loss = 1.8412
2024-10-31 00:32:37: [2024-10-31 00:32:37] iter = 17370, loss = 2.6578
2024-10-31 00:32:41: [2024-10-31 00:32:41] iter = 17380, loss = 2.2107
2024-10-31 00:32:44: [2024-10-31 00:32:44] iter = 17390, loss = 2.5759
2024-10-31 00:32:48: [2024-10-31 00:32:48] iter = 17400, loss = 2.4679
2024-10-31 00:32:52: [2024-10-31 00:32:52] iter = 17410, loss = 2.2373
2024-10-31 00:32:55: [2024-10-31 00:32:55] iter = 17420, loss = 2.2443
2024-10-31 00:32:59: [2024-10-31 00:32:59] iter = 17430, loss = 1.9145
2024-10-31 00:33:02: [2024-10-31 00:33:02] iter = 17440, loss = 2.5728
2024-10-31 00:33:05: [2024-10-31 00:33:05] iter = 17450, loss = 2.3666
2024-10-31 00:33:08: [2024-10-31 00:33:08] iter = 17460, loss = 1.8396
2024-10-31 00:33:12: [2024-10-31 00:33:12] iter = 17470, loss = 1.9922
2024-10-31 00:33:15: [2024-10-31 00:33:15] iter = 17480, loss = 1.7367
2024-10-31 00:33:19: [2024-10-31 00:33:19] iter = 17490, loss = 2.1695
2024-10-31 00:33:23: [2024-10-31 00:33:23] iter = 17500, loss = 2.5248
2024-10-31 00:33:27: [2024-10-31 00:33:27] iter = 17510, loss = 2.2257
2024-10-31 00:33:30: [2024-10-31 00:33:30] iter = 17520, loss = 1.6144
2024-10-31 00:33:34: [2024-10-31 00:33:34] iter = 17530, loss = 2.6821
2024-10-31 00:33:37: [2024-10-31 00:33:37] iter = 17540, loss = 2.4336
2024-10-31 00:33:40: [2024-10-31 00:33:40] iter = 17550, loss = 2.1314
2024-10-31 00:33:44: [2024-10-31 00:33:44] iter = 17560, loss = 1.9169
2024-10-31 00:33:47: [2024-10-31 00:33:47] iter = 17570, loss = 3.5828
2024-10-31 00:33:51: [2024-10-31 00:33:51] iter = 17580, loss = 3.2547
2024-10-31 00:33:55: [2024-10-31 00:33:55] iter = 17590, loss = 2.2207
2024-10-31 00:33:58: [2024-10-31 00:33:58] iter = 17600, loss = 2.4139
2024-10-31 00:34:00: [2024-10-31 00:34:00] iter = 17610, loss = 2.7998
2024-10-31 00:34:04: [2024-10-31 00:34:04] iter = 17620, loss = 2.8941
2024-10-31 00:34:07: [2024-10-31 00:34:07] iter = 17630, loss = 1.7538
2024-10-31 00:34:10: [2024-10-31 00:34:10] iter = 17640, loss = 1.9829
2024-10-31 00:34:14: [2024-10-31 00:34:14] iter = 17650, loss = 2.0583
2024-10-31 00:34:16: [2024-10-31 00:34:16] iter = 17660, loss = 2.0077
2024-10-31 00:34:20: [2024-10-31 00:34:20] iter = 17670, loss = 1.7893
2024-10-31 00:34:23: [2024-10-31 00:34:23] iter = 17680, loss = 2.2422
2024-10-31 00:34:26: [2024-10-31 00:34:26] iter = 17690, loss = 1.9256
2024-10-31 00:34:29: [2024-10-31 00:34:29] iter = 17700, loss = 1.9691
2024-10-31 00:34:33: [2024-10-31 00:34:33] iter = 17710, loss = 2.8757
2024-10-31 00:34:36: [2024-10-31 00:34:36] iter = 17720, loss = 2.6912
2024-10-31 00:34:39: [2024-10-31 00:34:39] iter = 17730, loss = 4.1596
2024-10-31 00:34:43: [2024-10-31 00:34:43] iter = 17740, loss = 1.9511
2024-10-31 00:34:47: [2024-10-31 00:34:47] iter = 17750, loss = 2.0515
2024-10-31 00:34:50: [2024-10-31 00:34:50] iter = 17760, loss = 1.8538
2024-10-31 00:34:53: [2024-10-31 00:34:53] iter = 17770, loss = 1.8004
2024-10-31 00:34:56: [2024-10-31 00:34:56] iter = 17780, loss = 1.4741
2024-10-31 00:35:00: [2024-10-31 00:35:00] iter = 17790, loss = 1.8615
2024-10-31 00:35:03: [2024-10-31 00:35:03] iter = 17800, loss = 2.1113
2024-10-31 00:35:07: [2024-10-31 00:35:07] iter = 17810, loss = 2.4024
2024-10-31 00:35:10: [2024-10-31 00:35:10] iter = 17820, loss = 2.1241
2024-10-31 00:35:15: [2024-10-31 00:35:15] iter = 17830, loss = 1.7020
2024-10-31 00:35:18: [2024-10-31 00:35:18] iter = 17840, loss = 2.5922
2024-10-31 00:35:22: [2024-10-31 00:35:22] iter = 17850, loss = 1.9569
2024-10-31 00:35:26: [2024-10-31 00:35:26] iter = 17860, loss = 2.4878
2024-10-31 00:35:29: [2024-10-31 00:35:29] iter = 17870, loss = 2.5284
2024-10-31 00:35:33: [2024-10-31 00:35:33] iter = 17880, loss = 1.8412
2024-10-31 00:35:37: [2024-10-31 00:35:37] iter = 17890, loss = 2.3685
2024-10-31 00:35:40: [2024-10-31 00:35:40] iter = 17900, loss = 2.3686
2024-10-31 00:35:43: [2024-10-31 00:35:43] iter = 17910, loss = 1.9733
2024-10-31 00:35:47: [2024-10-31 00:35:47] iter = 17920, loss = 2.1363
2024-10-31 00:35:51: [2024-10-31 00:35:51] iter = 17930, loss = 1.8197
2024-10-31 00:35:54: [2024-10-31 00:35:54] iter = 17940, loss = 1.9608
2024-10-31 00:35:57: [2024-10-31 00:35:57] iter = 17950, loss = 2.7803
2024-10-31 00:36:01: [2024-10-31 00:36:01] iter = 17960, loss = 1.8925
2024-10-31 00:36:03: [2024-10-31 00:36:03] iter = 17970, loss = 2.0086
2024-10-31 00:36:07: [2024-10-31 00:36:07] iter = 17980, loss = 2.3116
2024-10-31 00:36:11: [2024-10-31 00:36:11] iter = 17990, loss = 2.2812
2024-10-31 00:36:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-31 00:36:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:36:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 74491}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:38:18: Evaluate 5 random ConvNet, ACCmean = 0.7833 ACCstd = 0.0030
-------------------------
2024-10-31 00:38:18: Evaluate 5 random ConvNet, SENmean = 0.7790 SENstd = 0.0024
-------------------------
2024-10-31 00:38:18: Evaluate 5 random ConvNet, SPEmean = 0.9781 SPEstd = 0.0003
-------------------------
2024-10-31 00:38:18: Evaluate 5 random ConvNet, F!mean = 0.7713 F!std = 0.0030
-------------------------
2024-10-31 00:38:18: Evaluate 5 random ConvNet, mean = 0.7833 std = 0.0030
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:38:19: [2024-10-31 00:38:19] iter = 18000, loss = 1.7732
2024-10-31 00:38:22: [2024-10-31 00:38:22] iter = 18010, loss = 1.7353
2024-10-31 00:38:26: [2024-10-31 00:38:26] iter = 18020, loss = 2.8422
2024-10-31 00:38:29: [2024-10-31 00:38:29] iter = 18030, loss = 5.3173
2024-10-31 00:38:31: [2024-10-31 00:38:31] iter = 18040, loss = 2.7966
2024-10-31 00:38:35: [2024-10-31 00:38:35] iter = 18050, loss = 3.4119
2024-10-31 00:38:39: [2024-10-31 00:38:39] iter = 18060, loss = 1.8629
2024-10-31 00:38:42: [2024-10-31 00:38:42] iter = 18070, loss = 2.0791
2024-10-31 00:38:45: [2024-10-31 00:38:45] iter = 18080, loss = 1.8505
2024-10-31 00:38:47: [2024-10-31 00:38:47] iter = 18090, loss = 1.9021
2024-10-31 00:38:50: [2024-10-31 00:38:50] iter = 18100, loss = 2.5491
2024-10-31 00:38:52: [2024-10-31 00:38:52] iter = 18110, loss = 2.6688
2024-10-31 00:38:55: [2024-10-31 00:38:55] iter = 18120, loss = 3.0051
2024-10-31 00:38:58: [2024-10-31 00:38:58] iter = 18130, loss = 2.5447
2024-10-31 00:39:01: [2024-10-31 00:39:01] iter = 18140, loss = 2.0261
2024-10-31 00:39:05: [2024-10-31 00:39:05] iter = 18150, loss = 2.0507
2024-10-31 00:39:08: [2024-10-31 00:39:08] iter = 18160, loss = 1.9561
2024-10-31 00:39:11: [2024-10-31 00:39:11] iter = 18170, loss = 3.4275
2024-10-31 00:39:15: [2024-10-31 00:39:15] iter = 18180, loss = 2.2224
2024-10-31 00:39:18: [2024-10-31 00:39:18] iter = 18190, loss = 1.9208
2024-10-31 00:39:20: [2024-10-31 00:39:20] iter = 18200, loss = 2.2043
2024-10-31 00:39:23: [2024-10-31 00:39:23] iter = 18210, loss = 2.3585
2024-10-31 00:39:26: [2024-10-31 00:39:26] iter = 18220, loss = 2.0755
2024-10-31 00:39:29: [2024-10-31 00:39:29] iter = 18230, loss = 2.8705
2024-10-31 00:39:32: [2024-10-31 00:39:32] iter = 18240, loss = 2.5168
2024-10-31 00:39:35: [2024-10-31 00:39:35] iter = 18250, loss = 1.8830
2024-10-31 00:39:39: [2024-10-31 00:39:39] iter = 18260, loss = 1.8290
2024-10-31 00:39:42: [2024-10-31 00:39:42] iter = 18270, loss = 2.4080
2024-10-31 00:39:45: [2024-10-31 00:39:45] iter = 18280, loss = 2.2470
2024-10-31 00:39:48: [2024-10-31 00:39:48] iter = 18290, loss = 3.0121
2024-10-31 00:39:51: [2024-10-31 00:39:51] iter = 18300, loss = 1.6955
2024-10-31 00:39:53: [2024-10-31 00:39:53] iter = 18310, loss = 2.1300
2024-10-31 00:39:55: [2024-10-31 00:39:55] iter = 18320, loss = 2.3472
2024-10-31 00:39:59: [2024-10-31 00:39:59] iter = 18330, loss = 3.0556
2024-10-31 00:40:02: [2024-10-31 00:40:02] iter = 18340, loss = 2.1251
2024-10-31 00:40:06: [2024-10-31 00:40:06] iter = 18350, loss = 2.2568
2024-10-31 00:40:10: [2024-10-31 00:40:10] iter = 18360, loss = 1.8328
2024-10-31 00:40:14: [2024-10-31 00:40:14] iter = 18370, loss = 1.7649
2024-10-31 00:40:17: [2024-10-31 00:40:17] iter = 18380, loss = 2.2431
2024-10-31 00:40:21: [2024-10-31 00:40:21] iter = 18390, loss = 2.8662
2024-10-31 00:40:23: [2024-10-31 00:40:23] iter = 18400, loss = 1.9599
2024-10-31 00:40:26: [2024-10-31 00:40:26] iter = 18410, loss = 1.5081
2024-10-31 00:40:29: [2024-10-31 00:40:29] iter = 18420, loss = 2.4157
2024-10-31 00:40:32: [2024-10-31 00:40:32] iter = 18430, loss = 1.8373
2024-10-31 00:40:35: [2024-10-31 00:40:35] iter = 18440, loss = 2.0187
2024-10-31 00:40:39: [2024-10-31 00:40:39] iter = 18450, loss = 2.1499
2024-10-31 00:40:42: [2024-10-31 00:40:42] iter = 18460, loss = 2.1956
2024-10-31 00:40:46: [2024-10-31 00:40:46] iter = 18470, loss = 2.3547
2024-10-31 00:40:49: [2024-10-31 00:40:49] iter = 18480, loss = 3.4713
2024-10-31 00:40:53: [2024-10-31 00:40:53] iter = 18490, loss = 1.9417
2024-10-31 00:40:57: [2024-10-31 00:40:57] iter = 18500, loss = 3.8039
2024-10-31 00:41:00: [2024-10-31 00:41:00] iter = 18510, loss = 2.3862
2024-10-31 00:41:04: [2024-10-31 00:41:04] iter = 18520, loss = 3.1867
2024-10-31 00:41:06: [2024-10-31 00:41:06] iter = 18530, loss = 2.1088
2024-10-31 00:41:09: [2024-10-31 00:41:09] iter = 18540, loss = 1.8004
2024-10-31 00:41:12: [2024-10-31 00:41:12] iter = 18550, loss = 3.1218
2024-10-31 00:41:16: [2024-10-31 00:41:16] iter = 18560, loss = 1.8814
2024-10-31 00:41:20: [2024-10-31 00:41:20] iter = 18570, loss = 1.6784
2024-10-31 00:41:24: [2024-10-31 00:41:24] iter = 18580, loss = 2.4161
2024-10-31 00:41:27: [2024-10-31 00:41:27] iter = 18590, loss = 1.8480
2024-10-31 00:41:30: [2024-10-31 00:41:30] iter = 18600, loss = 1.6391
2024-10-31 00:41:33: [2024-10-31 00:41:33] iter = 18610, loss = 2.2610
2024-10-31 00:41:36: [2024-10-31 00:41:36] iter = 18620, loss = 2.6327
2024-10-31 00:41:39: [2024-10-31 00:41:39] iter = 18630, loss = 2.0415
2024-10-31 00:41:43: [2024-10-31 00:41:43] iter = 18640, loss = 1.7464
2024-10-31 00:41:47: [2024-10-31 00:41:47] iter = 18650, loss = 1.6812
2024-10-31 00:41:50: [2024-10-31 00:41:50] iter = 18660, loss = 2.9435
2024-10-31 00:41:53: [2024-10-31 00:41:53] iter = 18670, loss = 1.6145
2024-10-31 00:41:56: [2024-10-31 00:41:56] iter = 18680, loss = 2.0529
2024-10-31 00:42:00: [2024-10-31 00:42:00] iter = 18690, loss = 1.9399
2024-10-31 00:42:04: [2024-10-31 00:42:04] iter = 18700, loss = 3.3353
2024-10-31 00:42:07: [2024-10-31 00:42:07] iter = 18710, loss = 4.2302
2024-10-31 00:42:11: [2024-10-31 00:42:11] iter = 18720, loss = 2.5909
2024-10-31 00:42:14: [2024-10-31 00:42:14] iter = 18730, loss = 1.8978
2024-10-31 00:42:17: [2024-10-31 00:42:17] iter = 18740, loss = 1.9580
2024-10-31 00:42:19: [2024-10-31 00:42:19] iter = 18750, loss = 2.4018
2024-10-31 00:42:23: [2024-10-31 00:42:23] iter = 18760, loss = 2.5150
2024-10-31 00:42:25: [2024-10-31 00:42:25] iter = 18770, loss = 2.9924
2024-10-31 00:42:29: [2024-10-31 00:42:29] iter = 18780, loss = 1.8530
2024-10-31 00:42:33: [2024-10-31 00:42:33] iter = 18790, loss = 2.2261
2024-10-31 00:42:36: [2024-10-31 00:42:36] iter = 18800, loss = 2.1697
2024-10-31 00:42:40: [2024-10-31 00:42:40] iter = 18810, loss = 1.9843
2024-10-31 00:42:43: [2024-10-31 00:42:43] iter = 18820, loss = 2.0317
2024-10-31 00:42:46: [2024-10-31 00:42:46] iter = 18830, loss = 2.1327
2024-10-31 00:42:50: [2024-10-31 00:42:50] iter = 18840, loss = 1.9522
2024-10-31 00:42:53: [2024-10-31 00:42:53] iter = 18850, loss = 1.7265
2024-10-31 00:42:57: [2024-10-31 00:42:57] iter = 18860, loss = 2.7518
2024-10-31 00:43:00: [2024-10-31 00:43:00] iter = 18870, loss = 1.8723
2024-10-31 00:43:05: [2024-10-31 00:43:05] iter = 18880, loss = 1.9654
2024-10-31 00:43:09: [2024-10-31 00:43:09] iter = 18890, loss = 1.9509
2024-10-31 00:43:12: [2024-10-31 00:43:12] iter = 18900, loss = 1.8996
2024-10-31 00:43:15: [2024-10-31 00:43:15] iter = 18910, loss = 1.8114
2024-10-31 00:43:18: [2024-10-31 00:43:18] iter = 18920, loss = 2.0937
2024-10-31 00:43:22: [2024-10-31 00:43:22] iter = 18930, loss = 1.9993
2024-10-31 00:43:25: [2024-10-31 00:43:25] iter = 18940, loss = 1.7694
2024-10-31 00:43:28: [2024-10-31 00:43:28] iter = 18950, loss = 2.0541
2024-10-31 00:43:32: [2024-10-31 00:43:32] iter = 18960, loss = 2.2899
2024-10-31 00:43:36: [2024-10-31 00:43:36] iter = 18970, loss = 1.9411
2024-10-31 00:43:39: [2024-10-31 00:43:39] iter = 18980, loss = 2.3316
2024-10-31 00:43:43: [2024-10-31 00:43:43] iter = 18990, loss = 2.6572
2024-10-31 00:43:46: [2024-10-31 00:43:46] iter = 19000, loss = 1.9457
2024-10-31 00:43:50: [2024-10-31 00:43:50] iter = 19010, loss = 1.6394
2024-10-31 00:43:53: [2024-10-31 00:43:53] iter = 19020, loss = 1.7976
2024-10-31 00:43:58: [2024-10-31 00:43:58] iter = 19030, loss = 2.1653
2024-10-31 00:44:01: [2024-10-31 00:44:01] iter = 19040, loss = 2.4150
2024-10-31 00:44:05: [2024-10-31 00:44:05] iter = 19050, loss = 2.0083
2024-10-31 00:44:08: [2024-10-31 00:44:08] iter = 19060, loss = 2.0646
2024-10-31 00:44:11: [2024-10-31 00:44:11] iter = 19070, loss = 2.9797
2024-10-31 00:44:15: [2024-10-31 00:44:15] iter = 19080, loss = 2.0096
2024-10-31 00:44:19: [2024-10-31 00:44:19] iter = 19090, loss = 2.0993
2024-10-31 00:44:23: [2024-10-31 00:44:23] iter = 19100, loss = 2.1578
2024-10-31 00:44:25: [2024-10-31 00:44:25] iter = 19110, loss = 1.8373
2024-10-31 00:44:29: [2024-10-31 00:44:29] iter = 19120, loss = 2.0285
2024-10-31 00:44:32: [2024-10-31 00:44:32] iter = 19130, loss = 2.1631
2024-10-31 00:44:35: [2024-10-31 00:44:35] iter = 19140, loss = 3.1401
2024-10-31 00:44:39: [2024-10-31 00:44:39] iter = 19150, loss = 1.6090
2024-10-31 00:44:43: [2024-10-31 00:44:43] iter = 19160, loss = 4.2298
2024-10-31 00:44:46: [2024-10-31 00:44:46] iter = 19170, loss = 2.1505
2024-10-31 00:44:50: [2024-10-31 00:44:50] iter = 19180, loss = 1.8527
2024-10-31 00:44:52: [2024-10-31 00:44:52] iter = 19190, loss = 1.5440
2024-10-31 00:44:56: [2024-10-31 00:44:56] iter = 19200, loss = 1.9299
2024-10-31 00:45:00: [2024-10-31 00:45:00] iter = 19210, loss = 2.1247
2024-10-31 00:45:04: [2024-10-31 00:45:04] iter = 19220, loss = 1.7297
2024-10-31 00:45:08: [2024-10-31 00:45:08] iter = 19230, loss = 2.3443
2024-10-31 00:45:11: [2024-10-31 00:45:11] iter = 19240, loss = 2.6943
2024-10-31 00:45:15: [2024-10-31 00:45:15] iter = 19250, loss = 1.8471
2024-10-31 00:45:19: [2024-10-31 00:45:19] iter = 19260, loss = 1.9685
2024-10-31 00:45:22: [2024-10-31 00:45:22] iter = 19270, loss = 2.6106
2024-10-31 00:45:25: [2024-10-31 00:45:25] iter = 19280, loss = 3.3575
2024-10-31 00:45:29: [2024-10-31 00:45:29] iter = 19290, loss = 2.1895
2024-10-31 00:45:32: [2024-10-31 00:45:32] iter = 19300, loss = 2.5522
2024-10-31 00:45:37: [2024-10-31 00:45:36] iter = 19310, loss = 2.2134
2024-10-31 00:45:40: [2024-10-31 00:45:40] iter = 19320, loss = 3.6484
2024-10-31 00:45:43: [2024-10-31 00:45:43] iter = 19330, loss = 1.7690
2024-10-31 00:45:47: [2024-10-31 00:45:47] iter = 19340, loss = 2.4337
2024-10-31 00:45:50: [2024-10-31 00:45:50] iter = 19350, loss = 1.7945
2024-10-31 00:45:54: [2024-10-31 00:45:54] iter = 19360, loss = 1.8277
2024-10-31 00:45:58: [2024-10-31 00:45:58] iter = 19370, loss = 2.1069
2024-10-31 00:46:02: [2024-10-31 00:46:02] iter = 19380, loss = 1.9387
2024-10-31 00:46:04: [2024-10-31 00:46:04] iter = 19390, loss = 5.4496
2024-10-31 00:46:08: [2024-10-31 00:46:08] iter = 19400, loss = 2.0706
2024-10-31 00:46:11: [2024-10-31 00:46:11] iter = 19410, loss = 1.9283
2024-10-31 00:46:14: [2024-10-31 00:46:14] iter = 19420, loss = 1.4345
2024-10-31 00:46:17: [2024-10-31 00:46:17] iter = 19430, loss = 2.4718
2024-10-31 00:46:21: [2024-10-31 00:46:21] iter = 19440, loss = 1.7581
2024-10-31 00:46:26: [2024-10-31 00:46:26] iter = 19450, loss = 1.8710
2024-10-31 00:46:29: [2024-10-31 00:46:29] iter = 19460, loss = 2.0449
2024-10-31 00:46:32: [2024-10-31 00:46:32] iter = 19470, loss = 3.6334
2024-10-31 00:46:35: [2024-10-31 00:46:35] iter = 19480, loss = 1.6820
2024-10-31 00:46:39: [2024-10-31 00:46:39] iter = 19490, loss = 1.9512
2024-10-31 00:46:42: [2024-10-31 00:46:42] iter = 19500, loss = 2.0876
2024-10-31 00:46:45: [2024-10-31 00:46:45] iter = 19510, loss = 3.0175
2024-10-31 00:46:48: [2024-10-31 00:46:48] iter = 19520, loss = 2.5244
2024-10-31 00:46:52: [2024-10-31 00:46:52] iter = 19530, loss = 2.2726
2024-10-31 00:46:56: [2024-10-31 00:46:56] iter = 19540, loss = 2.8911
2024-10-31 00:46:59: [2024-10-31 00:46:59] iter = 19550, loss = 2.0096
2024-10-31 00:47:03: [2024-10-31 00:47:03] iter = 19560, loss = 2.3117
2024-10-31 00:47:07: [2024-10-31 00:47:07] iter = 19570, loss = 2.0376
2024-10-31 00:47:11: [2024-10-31 00:47:11] iter = 19580, loss = 2.0958
2024-10-31 00:47:15: [2024-10-31 00:47:15] iter = 19590, loss = 1.7863
2024-10-31 00:47:18: [2024-10-31 00:47:18] iter = 19600, loss = 2.3307
2024-10-31 00:47:23: [2024-10-31 00:47:23] iter = 19610, loss = 2.7092
2024-10-31 00:47:26: [2024-10-31 00:47:26] iter = 19620, loss = 1.7299
2024-10-31 00:47:30: [2024-10-31 00:47:30] iter = 19630, loss = 2.4830
2024-10-31 00:47:33: [2024-10-31 00:47:33] iter = 19640, loss = 1.8228
2024-10-31 00:47:36: [2024-10-31 00:47:36] iter = 19650, loss = 3.1693
2024-10-31 00:47:39: [2024-10-31 00:47:39] iter = 19660, loss = 2.7417
2024-10-31 00:47:42: [2024-10-31 00:47:42] iter = 19670, loss = 1.9269
2024-10-31 00:47:45: [2024-10-31 00:47:45] iter = 19680, loss = 1.5171
2024-10-31 00:47:49: [2024-10-31 00:47:49] iter = 19690, loss = 5.7250
2024-10-31 00:47:53: [2024-10-31 00:47:53] iter = 19700, loss = 1.5564
2024-10-31 00:47:56: [2024-10-31 00:47:56] iter = 19710, loss = 1.6550
2024-10-31 00:48:00: [2024-10-31 00:48:00] iter = 19720, loss = 2.2664
2024-10-31 00:48:03: [2024-10-31 00:48:03] iter = 19730, loss = 1.9695
2024-10-31 00:48:07: [2024-10-31 00:48:07] iter = 19740, loss = 2.5668
2024-10-31 00:48:11: [2024-10-31 00:48:11] iter = 19750, loss = 2.0977
2024-10-31 00:48:13: [2024-10-31 00:48:13] iter = 19760, loss = 1.9456
2024-10-31 00:48:17: [2024-10-31 00:48:17] iter = 19770, loss = 3.1859
2024-10-31 00:48:19: [2024-10-31 00:48:19] iter = 19780, loss = 1.9010
2024-10-31 00:48:22: [2024-10-31 00:48:22] iter = 19790, loss = 2.6220
2024-10-31 00:48:25: [2024-10-31 00:48:25] iter = 19800, loss = 3.2149
2024-10-31 00:48:29: [2024-10-31 00:48:29] iter = 19810, loss = 2.0703
2024-10-31 00:48:33: [2024-10-31 00:48:32] iter = 19820, loss = 3.0022
2024-10-31 00:48:35: [2024-10-31 00:48:35] iter = 19830, loss = 2.7909
2024-10-31 00:48:38: [2024-10-31 00:48:38] iter = 19840, loss = 2.3021
2024-10-31 00:48:41: [2024-10-31 00:48:41] iter = 19850, loss = 1.9315
2024-10-31 00:48:45: [2024-10-31 00:48:45] iter = 19860, loss = 2.9021
2024-10-31 00:48:49: [2024-10-31 00:48:49] iter = 19870, loss = 4.0584
2024-10-31 00:48:52: [2024-10-31 00:48:52] iter = 19880, loss = 1.8792
2024-10-31 00:48:55: [2024-10-31 00:48:55] iter = 19890, loss = 1.8881
2024-10-31 00:48:58: [2024-10-31 00:48:58] iter = 19900, loss = 3.2348
2024-10-31 00:49:02: [2024-10-31 00:49:02] iter = 19910, loss = 2.4630
2024-10-31 00:49:07: [2024-10-31 00:49:07] iter = 19920, loss = 2.2226
2024-10-31 00:49:11: [2024-10-31 00:49:11] iter = 19930, loss = 2.0534
2024-10-31 00:49:14: [2024-10-31 00:49:14] iter = 19940, loss = 1.5836
2024-10-31 00:49:18: [2024-10-31 00:49:18] iter = 19950, loss = 1.8519
2024-10-31 00:49:22: [2024-10-31 00:49:22] iter = 19960, loss = 2.8882
2024-10-31 00:49:25: [2024-10-31 00:49:25] iter = 19970, loss = 2.2973
2024-10-31 00:49:28: [2024-10-31 00:49:28] iter = 19980, loss = 1.7759
2024-10-31 00:49:32: [2024-10-31 00:49:32] iter = 19990, loss = 2.4760
2024-10-31 00:49:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-31 00:49:36: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:49:36: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 76299}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:51:49: Evaluate 5 random ConvNet, ACCmean = 0.7712 ACCstd = 0.0050
-------------------------
2024-10-31 00:51:49: Evaluate 5 random ConvNet, SENmean = 0.7661 SENstd = 0.0043
-------------------------
2024-10-31 00:51:49: Evaluate 5 random ConvNet, SPEmean = 0.9768 SPEstd = 0.0005
-------------------------
2024-10-31 00:51:49: Evaluate 5 random ConvNet, F!mean = 0.7590 F!std = 0.0050
-------------------------
2024-10-31 00:51:49: Evaluate 5 random ConvNet, mean = 0.7712 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:51:50: [2024-10-31 00:51:50] iter = 20000, loss = 3.4383
2024-10-31 00:51:50: 
================== Exp 4 ==================
 
2024-10-31 00:51:50: Hyper-parameters: 
{'dataset': 'OrganCMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f9aa0d64b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganCMNIST (INFO)>}
2024-10-31 00:51:50: Evaluation model pool: ['ConvNet']
2024-10-31 00:51:51: class c = 0: 1148 real images
2024-10-31 00:51:51: class c = 1: 619 real images
2024-10-31 00:51:51: class c = 2: 595 real images
2024-10-31 00:51:51: class c = 3: 600 real images
2024-10-31 00:51:51: class c = 4: 1088 real images
2024-10-31 00:51:51: class c = 5: 1170 real images
2024-10-31 00:51:51: class c = 6: 2986 real images
2024-10-31 00:51:51: class c = 7: 1002 real images
2024-10-31 00:51:51: class c = 8: 1022 real images
2024-10-31 00:51:51: class c = 9: 1173 real images
2024-10-31 00:51:51: class c = 10: 1572 real images
2024-10-31 00:51:51: real images channel 0, mean = 0.4942, std = 0.2834
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-31 00:51:51: initialize synthetic data from random real images
2024-10-31 00:51:51: [2024-10-31 00:51:51] training begins
2024-10-31 00:51:51: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-31 00:51:51: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:51:51: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10259}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:53:57: Evaluate 5 random ConvNet, ACCmean = 0.6913 ACCstd = 0.0060
-------------------------
2024-10-31 00:53:57: Evaluate 5 random ConvNet, SENmean = 0.7047 SENstd = 0.0053
-------------------------
2024-10-31 00:53:57: Evaluate 5 random ConvNet, SPEmean = 0.9692 SPEstd = 0.0006
-------------------------
2024-10-31 00:53:57: Evaluate 5 random ConvNet, F!mean = 0.6839 F!std = 0.0053
-------------------------
2024-10-31 00:53:57: Evaluate 5 random ConvNet, mean = 0.6913 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:53:57: [2024-10-31 00:53:57] iter = 00000, loss = 13.1377
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:54:00: [2024-10-31 00:54:00] iter = 00010, loss = 3.9255
2024-10-31 00:54:03: [2024-10-31 00:54:03] iter = 00020, loss = 3.8004
2024-10-31 00:54:07: [2024-10-31 00:54:07] iter = 00030, loss = 2.9650
2024-10-31 00:54:09: [2024-10-31 00:54:09] iter = 00040, loss = 2.6918
2024-10-31 00:54:12: [2024-10-31 00:54:12] iter = 00050, loss = 2.5329
2024-10-31 00:54:16: [2024-10-31 00:54:16] iter = 00060, loss = 3.6535
2024-10-31 00:54:18: [2024-10-31 00:54:18] iter = 00070, loss = 2.9315
2024-10-31 00:54:21: [2024-10-31 00:54:21] iter = 00080, loss = 2.7804
2024-10-31 00:54:25: [2024-10-31 00:54:25] iter = 00090, loss = 3.2291
2024-10-31 00:54:28: [2024-10-31 00:54:28] iter = 00100, loss = 3.0107
2024-10-31 00:54:32: [2024-10-31 00:54:32] iter = 00110, loss = 2.1831
2024-10-31 00:54:36: [2024-10-31 00:54:36] iter = 00120, loss = 2.8243
2024-10-31 00:54:39: [2024-10-31 00:54:39] iter = 00130, loss = 6.3439
2024-10-31 00:54:43: [2024-10-31 00:54:43] iter = 00140, loss = 2.6789
2024-10-31 00:54:46: [2024-10-31 00:54:46] iter = 00150, loss = 2.6130
2024-10-31 00:54:49: [2024-10-31 00:54:49] iter = 00160, loss = 2.8381
2024-10-31 00:54:52: [2024-10-31 00:54:52] iter = 00170, loss = 2.3853
2024-10-31 00:54:55: [2024-10-31 00:54:55] iter = 00180, loss = 4.7969
2024-10-31 00:54:58: [2024-10-31 00:54:58] iter = 00190, loss = 2.6004
2024-10-31 00:55:01: [2024-10-31 00:55:01] iter = 00200, loss = 2.6366
2024-10-31 00:55:05: [2024-10-31 00:55:05] iter = 00210, loss = 2.4416
2024-10-31 00:55:09: [2024-10-31 00:55:09] iter = 00220, loss = 1.9665
2024-10-31 00:55:12: [2024-10-31 00:55:12] iter = 00230, loss = 2.2823
2024-10-31 00:55:16: [2024-10-31 00:55:16] iter = 00240, loss = 2.4703
2024-10-31 00:55:18: [2024-10-31 00:55:18] iter = 00250, loss = 2.7214
2024-10-31 00:55:21: [2024-10-31 00:55:21] iter = 00260, loss = 2.1602
2024-10-31 00:55:24: [2024-10-31 00:55:24] iter = 00270, loss = 3.1899
2024-10-31 00:55:27: [2024-10-31 00:55:27] iter = 00280, loss = 2.4981
2024-10-31 00:55:31: [2024-10-31 00:55:31] iter = 00290, loss = 2.0379
2024-10-31 00:55:34: [2024-10-31 00:55:34] iter = 00300, loss = 1.9764
2024-10-31 00:55:37: [2024-10-31 00:55:37] iter = 00310, loss = 2.4243
2024-10-31 00:55:40: [2024-10-31 00:55:40] iter = 00320, loss = 3.4968
2024-10-31 00:55:43: [2024-10-31 00:55:43] iter = 00330, loss = 2.0033
2024-10-31 00:55:46: [2024-10-31 00:55:46] iter = 00340, loss = 2.5824
2024-10-31 00:55:50: [2024-10-31 00:55:50] iter = 00350, loss = 2.4501
2024-10-31 00:55:53: [2024-10-31 00:55:53] iter = 00360, loss = 2.1796
2024-10-31 00:55:56: [2024-10-31 00:55:56] iter = 00370, loss = 2.4894
2024-10-31 00:55:59: [2024-10-31 00:55:59] iter = 00380, loss = 2.4502
2024-10-31 00:56:02: [2024-10-31 00:56:02] iter = 00390, loss = 2.3281
2024-10-31 00:56:05: [2024-10-31 00:56:05] iter = 00400, loss = 2.8605
2024-10-31 00:56:10: [2024-10-31 00:56:10] iter = 00410, loss = 1.8789
2024-10-31 00:56:14: [2024-10-31 00:56:14] iter = 00420, loss = 1.8999
2024-10-31 00:56:18: [2024-10-31 00:56:18] iter = 00430, loss = 2.3136
2024-10-31 00:56:21: [2024-10-31 00:56:21] iter = 00440, loss = 2.0980
2024-10-31 00:56:25: [2024-10-31 00:56:25] iter = 00450, loss = 1.6366
2024-10-31 00:56:29: [2024-10-31 00:56:29] iter = 00460, loss = 2.4857
2024-10-31 00:56:34: [2024-10-31 00:56:34] iter = 00470, loss = 2.8880
2024-10-31 00:56:37: [2024-10-31 00:56:37] iter = 00480, loss = 1.9174
2024-10-31 00:56:41: [2024-10-31 00:56:41] iter = 00490, loss = 2.2634
2024-10-31 00:56:44: [2024-10-31 00:56:44] iter = 00500, loss = 2.2063
2024-10-31 00:56:48: [2024-10-31 00:56:48] iter = 00510, loss = 1.6313
2024-10-31 00:56:52: [2024-10-31 00:56:52] iter = 00520, loss = 1.9990
2024-10-31 00:56:55: [2024-10-31 00:56:55] iter = 00530, loss = 2.6092
2024-10-31 00:56:58: [2024-10-31 00:56:58] iter = 00540, loss = 1.7735
2024-10-31 00:57:01: [2024-10-31 00:57:01] iter = 00550, loss = 2.4146
2024-10-31 00:57:04: [2024-10-31 00:57:04] iter = 00560, loss = 2.1509
2024-10-31 00:57:08: [2024-10-31 00:57:08] iter = 00570, loss = 1.7430
2024-10-31 00:57:10: [2024-10-31 00:57:10] iter = 00580, loss = 2.0653
2024-10-31 00:57:14: [2024-10-31 00:57:14] iter = 00590, loss = 2.2780
2024-10-31 00:57:18: [2024-10-31 00:57:18] iter = 00600, loss = 2.4176
2024-10-31 00:57:22: [2024-10-31 00:57:22] iter = 00610, loss = 1.9436
2024-10-31 00:57:25: [2024-10-31 00:57:25] iter = 00620, loss = 2.6299
2024-10-31 00:57:29: [2024-10-31 00:57:29] iter = 00630, loss = 1.9221
2024-10-31 00:57:33: [2024-10-31 00:57:33] iter = 00640, loss = 2.6093
2024-10-31 00:57:37: [2024-10-31 00:57:37] iter = 00650, loss = 2.0612
2024-10-31 00:57:40: [2024-10-31 00:57:40] iter = 00660, loss = 1.8519
2024-10-31 00:57:44: [2024-10-31 00:57:44] iter = 00670, loss = 2.8285
2024-10-31 00:57:47: [2024-10-31 00:57:47] iter = 00680, loss = 2.3954
2024-10-31 00:57:51: [2024-10-31 00:57:51] iter = 00690, loss = 2.7146
2024-10-31 00:57:55: [2024-10-31 00:57:55] iter = 00700, loss = 2.1601
2024-10-31 00:57:57: [2024-10-31 00:57:57] iter = 00710, loss = 1.7038
2024-10-31 00:58:00: [2024-10-31 00:58:00] iter = 00720, loss = 1.7815
2024-10-31 00:58:04: [2024-10-31 00:58:04] iter = 00730, loss = 2.5206
2024-10-31 00:58:08: [2024-10-31 00:58:08] iter = 00740, loss = 1.9538
2024-10-31 00:58:12: [2024-10-31 00:58:12] iter = 00750, loss = 2.0724
2024-10-31 00:58:15: [2024-10-31 00:58:15] iter = 00760, loss = 2.4265
2024-10-31 00:58:19: [2024-10-31 00:58:19] iter = 00770, loss = 4.0243
2024-10-31 00:58:22: [2024-10-31 00:58:22] iter = 00780, loss = 2.0929
2024-10-31 00:58:25: [2024-10-31 00:58:25] iter = 00790, loss = 2.3365
2024-10-31 00:58:28: [2024-10-31 00:58:28] iter = 00800, loss = 2.3318
2024-10-31 00:58:31: [2024-10-31 00:58:31] iter = 00810, loss = 2.2596
2024-10-31 00:58:34: [2024-10-31 00:58:34] iter = 00820, loss = 5.4508
2024-10-31 00:58:38: [2024-10-31 00:58:38] iter = 00830, loss = 2.3328
2024-10-31 00:58:41: [2024-10-31 00:58:41] iter = 00840, loss = 1.7576
2024-10-31 00:58:45: [2024-10-31 00:58:45] iter = 00850, loss = 2.0535
2024-10-31 00:58:48: [2024-10-31 00:58:48] iter = 00860, loss = 3.5924
2024-10-31 00:58:52: [2024-10-31 00:58:52] iter = 00870, loss = 1.8049
2024-10-31 00:58:55: [2024-10-31 00:58:55] iter = 00880, loss = 1.8299
2024-10-31 00:58:58: [2024-10-31 00:58:58] iter = 00890, loss = 2.4765
2024-10-31 00:59:01: [2024-10-31 00:59:01] iter = 00900, loss = 1.9601
2024-10-31 00:59:03: [2024-10-31 00:59:03] iter = 00910, loss = 2.8009
2024-10-31 00:59:07: [2024-10-31 00:59:07] iter = 00920, loss = 2.1476
2024-10-31 00:59:10: [2024-10-31 00:59:10] iter = 00930, loss = 2.0139
2024-10-31 00:59:13: [2024-10-31 00:59:13] iter = 00940, loss = 3.0551
2024-10-31 00:59:17: [2024-10-31 00:59:17] iter = 00950, loss = 1.8721
2024-10-31 00:59:21: [2024-10-31 00:59:21] iter = 00960, loss = 2.0415
2024-10-31 00:59:24: [2024-10-31 00:59:24] iter = 00970, loss = 2.3325
2024-10-31 00:59:28: [2024-10-31 00:59:28] iter = 00980, loss = 1.8218
2024-10-31 00:59:31: [2024-10-31 00:59:31] iter = 00990, loss = 2.0283
2024-10-31 00:59:35: [2024-10-31 00:59:35] iter = 01000, loss = 2.2867
2024-10-31 00:59:39: [2024-10-31 00:59:39] iter = 01010, loss = 4.4325
2024-10-31 00:59:43: [2024-10-31 00:59:43] iter = 01020, loss = 1.7660
2024-10-31 00:59:46: [2024-10-31 00:59:46] iter = 01030, loss = 2.3654
2024-10-31 00:59:50: [2024-10-31 00:59:50] iter = 01040, loss = 2.8540
2024-10-31 00:59:53: [2024-10-31 00:59:53] iter = 01050, loss = 1.7809
2024-10-31 00:59:56: [2024-10-31 00:59:56] iter = 01060, loss = 2.7861
2024-10-31 00:59:59: [2024-10-31 00:59:59] iter = 01070, loss = 2.4215
2024-10-31 01:00:02: [2024-10-31 01:00:02] iter = 01080, loss = 2.5558
2024-10-31 01:00:06: [2024-10-31 01:00:06] iter = 01090, loss = 2.2676
2024-10-31 01:00:09: [2024-10-31 01:00:09] iter = 01100, loss = 2.7594
2024-10-31 01:00:13: [2024-10-31 01:00:13] iter = 01110, loss = 1.8472
2024-10-31 01:00:17: [2024-10-31 01:00:17] iter = 01120, loss = 2.0545
2024-10-31 01:00:21: [2024-10-31 01:00:21] iter = 01130, loss = 2.1435
2024-10-31 01:00:24: [2024-10-31 01:00:24] iter = 01140, loss = 2.6203
2024-10-31 01:00:28: [2024-10-31 01:00:28] iter = 01150, loss = 1.7395
2024-10-31 01:00:31: [2024-10-31 01:00:31] iter = 01160, loss = 2.0400
2024-10-31 01:00:35: [2024-10-31 01:00:35] iter = 01170, loss = 1.9082
2024-10-31 01:00:39: [2024-10-31 01:00:39] iter = 01180, loss = 2.8882
2024-10-31 01:00:42: [2024-10-31 01:00:42] iter = 01190, loss = 1.8476
2024-10-31 01:00:46: [2024-10-31 01:00:46] iter = 01200, loss = 2.2478
2024-10-31 01:00:49: [2024-10-31 01:00:49] iter = 01210, loss = 2.0483
2024-10-31 01:00:53: [2024-10-31 01:00:53] iter = 01220, loss = 2.0734
2024-10-31 01:00:56: [2024-10-31 01:00:56] iter = 01230, loss = 2.0388
2024-10-31 01:00:58: [2024-10-31 01:00:58] iter = 01240, loss = 2.1171
2024-10-31 01:01:01: [2024-10-31 01:01:01] iter = 01250, loss = 6.4063
2024-10-31 01:01:06: [2024-10-31 01:01:06] iter = 01260, loss = 4.4194
2024-10-31 01:01:09: [2024-10-31 01:01:09] iter = 01270, loss = 2.3562
2024-10-31 01:01:13: [2024-10-31 01:01:13] iter = 01280, loss = 1.9612
2024-10-31 01:01:17: [2024-10-31 01:01:17] iter = 01290, loss = 1.9970
2024-10-31 01:01:20: [2024-10-31 01:01:20] iter = 01300, loss = 1.7650
2024-10-31 01:01:23: [2024-10-31 01:01:23] iter = 01310, loss = 2.1294
2024-10-31 01:01:27: [2024-10-31 01:01:27] iter = 01320, loss = 2.5923
2024-10-31 01:01:31: [2024-10-31 01:01:31] iter = 01330, loss = 1.8723
2024-10-31 01:01:34: [2024-10-31 01:01:34] iter = 01340, loss = 1.7663
2024-10-31 01:01:37: [2024-10-31 01:01:37] iter = 01350, loss = 2.8035
2024-10-31 01:01:41: [2024-10-31 01:01:41] iter = 01360, loss = 2.9449
2024-10-31 01:01:43: [2024-10-31 01:01:43] iter = 01370, loss = 2.4734
2024-10-31 01:01:46: [2024-10-31 01:01:46] iter = 01380, loss = 1.9672
2024-10-31 01:01:50: [2024-10-31 01:01:50] iter = 01390, loss = 2.5815
2024-10-31 01:01:53: [2024-10-31 01:01:53] iter = 01400, loss = 1.6391
2024-10-31 01:01:56: [2024-10-31 01:01:56] iter = 01410, loss = 2.0362
2024-10-31 01:02:00: [2024-10-31 01:02:00] iter = 01420, loss = 2.0387
2024-10-31 01:02:04: [2024-10-31 01:02:04] iter = 01430, loss = 4.8536
2024-10-31 01:02:08: [2024-10-31 01:02:08] iter = 01440, loss = 5.6435
2024-10-31 01:02:12: [2024-10-31 01:02:12] iter = 01450, loss = 2.2288
2024-10-31 01:02:16: [2024-10-31 01:02:16] iter = 01460, loss = 2.7315
2024-10-31 01:02:19: [2024-10-31 01:02:19] iter = 01470, loss = 2.8696
2024-10-31 01:02:22: [2024-10-31 01:02:22] iter = 01480, loss = 3.8129
2024-10-31 01:02:25: [2024-10-31 01:02:25] iter = 01490, loss = 2.4542
2024-10-31 01:02:30: [2024-10-31 01:02:30] iter = 01500, loss = 1.8863
2024-10-31 01:02:34: [2024-10-31 01:02:34] iter = 01510, loss = 2.2796
2024-10-31 01:02:38: [2024-10-31 01:02:38] iter = 01520, loss = 2.4921
2024-10-31 01:02:41: [2024-10-31 01:02:41] iter = 01530, loss = 2.2144
2024-10-31 01:02:44: [2024-10-31 01:02:44] iter = 01540, loss = 2.2532
2024-10-31 01:02:47: [2024-10-31 01:02:47] iter = 01550, loss = 2.0599
2024-10-31 01:02:50: [2024-10-31 01:02:50] iter = 01560, loss = 2.7409
2024-10-31 01:02:54: [2024-10-31 01:02:54] iter = 01570, loss = 2.0207
2024-10-31 01:02:57: [2024-10-31 01:02:57] iter = 01580, loss = 1.9504
2024-10-31 01:03:01: [2024-10-31 01:03:01] iter = 01590, loss = 1.9601
2024-10-31 01:03:06: [2024-10-31 01:03:06] iter = 01600, loss = 2.3418
2024-10-31 01:03:10: [2024-10-31 01:03:10] iter = 01610, loss = 3.1175
2024-10-31 01:03:14: [2024-10-31 01:03:14] iter = 01620, loss = 2.3272
2024-10-31 01:03:18: [2024-10-31 01:03:18] iter = 01630, loss = 2.2237
2024-10-31 01:03:22: [2024-10-31 01:03:22] iter = 01640, loss = 2.2221
2024-10-31 01:03:26: [2024-10-31 01:03:26] iter = 01650, loss = 1.7490
2024-10-31 01:03:29: [2024-10-31 01:03:29] iter = 01660, loss = 2.2107
2024-10-31 01:03:32: [2024-10-31 01:03:32] iter = 01670, loss = 2.8096
2024-10-31 01:03:35: [2024-10-31 01:03:35] iter = 01680, loss = 2.5305
2024-10-31 01:03:40: [2024-10-31 01:03:40] iter = 01690, loss = 1.8091
2024-10-31 01:03:43: [2024-10-31 01:03:43] iter = 01700, loss = 2.2819
2024-10-31 01:03:47: [2024-10-31 01:03:47] iter = 01710, loss = 1.7896
2024-10-31 01:03:51: [2024-10-31 01:03:51] iter = 01720, loss = 3.1873
2024-10-31 01:03:54: [2024-10-31 01:03:54] iter = 01730, loss = 1.9041
2024-10-31 01:03:57: [2024-10-31 01:03:57] iter = 01740, loss = 1.8434
2024-10-31 01:04:01: [2024-10-31 01:04:01] iter = 01750, loss = 2.3242
2024-10-31 01:04:04: [2024-10-31 01:04:04] iter = 01760, loss = 1.9852
2024-10-31 01:04:08: [2024-10-31 01:04:08] iter = 01770, loss = 2.0702
2024-10-31 01:04:11: [2024-10-31 01:04:11] iter = 01780, loss = 2.0528
2024-10-31 01:04:15: [2024-10-31 01:04:15] iter = 01790, loss = 1.8387
2024-10-31 01:04:19: [2024-10-31 01:04:19] iter = 01800, loss = 1.6435
2024-10-31 01:04:22: [2024-10-31 01:04:22] iter = 01810, loss = 2.2850
2024-10-31 01:04:26: [2024-10-31 01:04:26] iter = 01820, loss = 2.5542
2024-10-31 01:04:29: [2024-10-31 01:04:29] iter = 01830, loss = 3.1166
2024-10-31 01:04:33: [2024-10-31 01:04:33] iter = 01840, loss = 2.1732
2024-10-31 01:04:36: [2024-10-31 01:04:36] iter = 01850, loss = 2.2102
2024-10-31 01:04:40: [2024-10-31 01:04:40] iter = 01860, loss = 2.9758
2024-10-31 01:04:43: [2024-10-31 01:04:43] iter = 01870, loss = 2.0471
2024-10-31 01:04:46: [2024-10-31 01:04:46] iter = 01880, loss = 2.2293
2024-10-31 01:04:50: [2024-10-31 01:04:50] iter = 01890, loss = 1.6345
2024-10-31 01:04:54: [2024-10-31 01:04:54] iter = 01900, loss = 3.0343
2024-10-31 01:04:57: [2024-10-31 01:04:57] iter = 01910, loss = 2.0391
2024-10-31 01:05:00: [2024-10-31 01:05:00] iter = 01920, loss = 1.9622
2024-10-31 01:05:03: [2024-10-31 01:05:03] iter = 01930, loss = 2.2420
2024-10-31 01:05:06: [2024-10-31 01:05:06] iter = 01940, loss = 2.2088
2024-10-31 01:05:10: [2024-10-31 01:05:10] iter = 01950, loss = 2.2976
2024-10-31 01:05:12: [2024-10-31 01:05:12] iter = 01960, loss = 1.9894
2024-10-31 01:05:16: [2024-10-31 01:05:16] iter = 01970, loss = 2.4921
2024-10-31 01:05:19: [2024-10-31 01:05:19] iter = 01980, loss = 1.8833
2024-10-31 01:05:23: [2024-10-31 01:05:23] iter = 01990, loss = 2.7615
2024-10-31 01:05:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-31 01:05:26: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:05:26: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 26442}

[2024-10-30 23:16:30] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.028586 train acc = 0.9909, test acc = 0.7773, test_sen =0.7740, test_spe =0.9775, test_f1 =0.7639
[2024-10-30 23:16:56] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.005974 train acc = 1.0000, test acc = 0.7797, test_sen =0.7773, test_spe =0.9778, test_f1 =0.7671
[2024-10-30 23:28:27] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.013850 train acc = 1.0000, test acc = 0.7775, test_sen =0.7736, test_spe =0.9776, test_f1 =0.7636
[2024-10-30 23:28:51] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.003655 train acc = 1.0000, test acc = 0.7835, test_sen =0.7785, test_spe =0.9781, test_f1 =0.7699
[2024-10-30 23:29:16] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.003648 train acc = 1.0000, test acc = 0.7838, test_sen =0.7792, test_spe =0.9782, test_f1 =0.7697
[2024-10-30 23:29:45] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.005270 train acc = 1.0000, test acc = 0.7820, test_sen =0.7769, test_spe =0.9780, test_f1 =0.7685
[2024-10-30 23:30:10] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.003303 train acc = 1.0000, test acc = 0.7764, test_sen =0.7690, test_spe =0.9774, test_f1 =0.7617
[2024-10-30 23:42:44] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.005506 train acc = 1.0000, test acc = 0.7797, test_sen =0.7779, test_spe =0.9777, test_f1 =0.7695
[2024-10-30 23:43:13] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.049926 train acc = 1.0000, test acc = 0.7827, test_sen =0.7771, test_spe =0.9780, test_f1 =0.7689
[2024-10-30 23:43:40] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.011886 train acc = 1.0000, test acc = 0.7771, test_sen =0.7763, test_spe =0.9775, test_f1 =0.7650
[2024-10-30 23:44:05] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.003984 train acc = 1.0000, test acc = 0.7758, test_sen =0.7720, test_spe =0.9774, test_f1 =0.7619
[2024-10-30 23:44:34] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.027689 train acc = 1.0000, test acc = 0.7816, test_sen =0.7772, test_spe =0.9779, test_f1 =0.7684
[2024-10-30 23:56:05] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.013299 train acc = 1.0000, test acc = 0.7700, test_sen =0.7673, test_spe =0.9766, test_f1 =0.7599
[2024-10-30 23:56:29] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.005975 train acc = 1.0000, test acc = 0.7739, test_sen =0.7687, test_spe =0.9770, test_f1 =0.7630
[2024-10-30 23:56:54] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.003313 train acc = 1.0000, test acc = 0.7830, test_sen =0.7800, test_spe =0.9780, test_f1 =0.7724
[2024-10-30 23:57:20] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.004177 train acc = 1.0000, test acc = 0.7714, test_sen =0.7688, test_spe =0.9768, test_f1 =0.7604
[2024-10-30 23:57:47] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.040031 train acc = 0.9909, test acc = 0.7746, test_sen =0.7664, test_spe =0.9771, test_f1 =0.7607
[2024-10-31 00:09:20] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.024657 train acc = 1.0000, test acc = 0.7735, test_sen =0.7697, test_spe =0.9772, test_f1 =0.7583
[2024-10-31 00:09:43] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.010985 train acc = 1.0000, test acc = 0.7847, test_sen =0.7796, test_spe =0.9784, test_f1 =0.7702
[2024-10-31 00:10:10] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.022687 train acc = 1.0000, test acc = 0.7723, test_sen =0.7687, test_spe =0.9771, test_f1 =0.7581
[2024-10-31 00:10:35] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.009151 train acc = 1.0000, test acc = 0.7722, test_sen =0.7688, test_spe =0.9771, test_f1 =0.7577
[2024-10-31 00:11:01] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.023180 train acc = 1.0000, test acc = 0.7809, test_sen =0.7745, test_spe =0.9779, test_f1 =0.7653
[2024-10-31 00:22:43] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.008111 train acc = 1.0000, test acc = 0.7849, test_sen =0.7805, test_spe =0.9782, test_f1 =0.7734
[2024-10-31 00:23:07] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.002847 train acc = 1.0000, test acc = 0.7835, test_sen =0.7787, test_spe =0.9781, test_f1 =0.7720
[2024-10-31 00:23:32] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.010802 train acc = 1.0000, test acc = 0.7897, test_sen =0.7828, test_spe =0.9787, test_f1 =0.7765
[2024-10-31 00:23:59] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.015055 train acc = 1.0000, test acc = 0.7857, test_sen =0.7796, test_spe =0.9783, test_f1 =0.7724
[2024-10-31 00:24:26] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.002071 train acc = 1.0000, test acc = 0.7883, test_sen =0.7809, test_spe =0.9786, test_f1 =0.7741
[2024-10-31 00:36:39] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.018791 train acc = 1.0000, test acc = 0.7808, test_sen =0.7784, test_spe =0.9778, test_f1 =0.7702
[2024-10-31 00:37:05] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.004171 train acc = 1.0000, test acc = 0.7827, test_sen =0.7753, test_spe =0.9780, test_f1 =0.7695
[2024-10-31 00:37:28] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.018945 train acc = 1.0000, test acc = 0.7831, test_sen =0.7797, test_spe =0.9781, test_f1 =0.7704
[2024-10-31 00:37:54] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.006813 train acc = 1.0000, test acc = 0.7889, test_sen =0.7828, test_spe =0.9786, test_f1 =0.7772
[2024-10-31 00:38:18] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.002811 train acc = 1.0000, test acc = 0.7809, test_sen =0.7789, test_spe =0.9779, test_f1 =0.7693
[2024-10-31 00:50:01] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.021007 train acc = 1.0000, test acc = 0.7622, test_sen =0.7581, test_spe =0.9759, test_f1 =0.7501
[2024-10-31 00:50:27] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.002915 train acc = 1.0000, test acc = 0.7703, test_sen =0.7659, test_spe =0.9767, test_f1 =0.7589
[2024-10-31 00:50:53] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.012226 train acc = 1.0000, test acc = 0.7728, test_sen =0.7700, test_spe =0.9770, test_f1 =0.7610
[2024-10-31 00:51:20] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.031158 train acc = 1.0000, test acc = 0.7769, test_sen =0.7697, test_spe =0.9774, test_f1 =0.7652
[2024-10-31 00:51:49] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.004023 train acc = 1.0000, test acc = 0.7736, test_sen =0.7670, test_spe =0.9770, test_f1 =0.7601
[2024-10-31 00:52:15] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.014158 train acc = 1.0000, test acc = 0.6979, test_sen =0.7108, test_spe =0.9699, test_f1 =0.6903
[2024-10-31 00:52:40] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.008324 train acc = 1.0000, test acc = 0.6932, test_sen =0.7051, test_spe =0.9694, test_f1 =0.6841
[2024-10-31 00:53:07] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.001979 train acc = 1.0000, test acc = 0.6800, test_sen =0.6947, test_spe =0.9682, test_f1 =0.6741
[2024-10-31 00:53:32] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.012560 train acc = 1.0000, test acc = 0.6922, test_sen =0.7063, test_spe =0.9694, test_f1 =0.6861
[2024-10-31 00:53:57] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.006164 train acc = 1.0000, test acc = 0.6930, test_sen =0.7064, test_spe =0.9694, test_f1 =0.6849
[2024-10-31 01:05:53] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.012483 train acc = 1.0000, test acc = 0.7843, test_sen =0.7801, test_spe =0.9783, test_f1 =0.7713
[2024-10-31 01:06:20] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.004124 train acc = 1.0000, test acc = 0.7830, test_sen =0.7790, test_spe =0.9781, test_f1 =0.7699
[2024-10-31 01:06:45] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.002595 train acc = 1.0000, test acc = 0.7797, test_sen =0.7755, test_spe =0.9778, test_f1 =0.7664
[2024-10-31 01:07:12] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.010883 train acc = 1.0000, test acc = 0.7815, test_sen =0.7760, test_spe =0.9779, test_f1 =0.7691/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:07:40: Evaluate 5 random ConvNet, ACCmean = 0.7802 ACCstd = 0.0041
-------------------------
2024-10-31 01:07:40: Evaluate 5 random ConvNet, SENmean = 0.7761 SENstd = 0.0036
-------------------------
2024-10-31 01:07:40: Evaluate 5 random ConvNet, SPEmean = 0.9778 SPEstd = 0.0004
-------------------------
2024-10-31 01:07:40: Evaluate 5 random ConvNet, F!mean = 0.7675 F!std = 0.0037
-------------------------
2024-10-31 01:07:40: Evaluate 5 random ConvNet, mean = 0.7802 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:07:41: [2024-10-31 01:07:41] iter = 02000, loss = 1.8658
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:07:45: [2024-10-31 01:07:45] iter = 02010, loss = 2.0413
2024-10-31 01:07:49: [2024-10-31 01:07:49] iter = 02020, loss = 1.6540
2024-10-31 01:07:53: [2024-10-31 01:07:53] iter = 02030, loss = 1.7741
2024-10-31 01:07:57: [2024-10-31 01:07:57] iter = 02040, loss = 1.9853
2024-10-31 01:08:01: [2024-10-31 01:08:01] iter = 02050, loss = 2.3094
2024-10-31 01:08:04: [2024-10-31 01:08:04] iter = 02060, loss = 2.1028
2024-10-31 01:08:08: [2024-10-31 01:08:08] iter = 02070, loss = 2.6998
2024-10-31 01:08:11: [2024-10-31 01:08:11] iter = 02080, loss = 1.8183
2024-10-31 01:08:15: [2024-10-31 01:08:15] iter = 02090, loss = 1.9464
2024-10-31 01:08:17: [2024-10-31 01:08:17] iter = 02100, loss = 2.0174
2024-10-31 01:08:19: [2024-10-31 01:08:19] iter = 02110, loss = 2.2244
2024-10-31 01:08:21: [2024-10-31 01:08:21] iter = 02120, loss = 1.8969
2024-10-31 01:08:24: [2024-10-31 01:08:24] iter = 02130, loss = 1.8246
2024-10-31 01:08:28: [2024-10-31 01:08:28] iter = 02140, loss = 1.8721
2024-10-31 01:08:31: [2024-10-31 01:08:31] iter = 02150, loss = 1.6115
2024-10-31 01:08:34: [2024-10-31 01:08:34] iter = 02160, loss = 2.0091
2024-10-31 01:08:38: [2024-10-31 01:08:38] iter = 02170, loss = 2.1663
2024-10-31 01:08:41: [2024-10-31 01:08:41] iter = 02180, loss = 1.7676
2024-10-31 01:08:46: [2024-10-31 01:08:46] iter = 02190, loss = 2.4000
2024-10-31 01:08:50: [2024-10-31 01:08:50] iter = 02200, loss = 1.9237
2024-10-31 01:08:54: [2024-10-31 01:08:54] iter = 02210, loss = 2.4976
2024-10-31 01:08:57: [2024-10-31 01:08:57] iter = 02220, loss = 2.1002
2024-10-31 01:09:01: [2024-10-31 01:09:01] iter = 02230, loss = 2.4711
2024-10-31 01:09:04: [2024-10-31 01:09:04] iter = 02240, loss = 1.9765
2024-10-31 01:09:09: [2024-10-31 01:09:09] iter = 02250, loss = 2.5320
2024-10-31 01:09:12: [2024-10-31 01:09:12] iter = 02260, loss = 3.6493
2024-10-31 01:09:15: [2024-10-31 01:09:15] iter = 02270, loss = 1.7611
2024-10-31 01:09:19: [2024-10-31 01:09:19] iter = 02280, loss = 1.8836
2024-10-31 01:09:22: [2024-10-31 01:09:22] iter = 02290, loss = 1.8457
2024-10-31 01:09:26: [2024-10-31 01:09:26] iter = 02300, loss = 1.9405
2024-10-31 01:09:29: [2024-10-31 01:09:29] iter = 02310, loss = 2.0846
2024-10-31 01:09:33: [2024-10-31 01:09:33] iter = 02320, loss = 1.8456
2024-10-31 01:09:37: [2024-10-31 01:09:37] iter = 02330, loss = 2.3055
2024-10-31 01:09:41: [2024-10-31 01:09:41] iter = 02340, loss = 2.7472
2024-10-31 01:09:44: [2024-10-31 01:09:44] iter = 02350, loss = 1.8333
2024-10-31 01:09:48: [2024-10-31 01:09:48] iter = 02360, loss = 2.7070
2024-10-31 01:09:51: [2024-10-31 01:09:51] iter = 02370, loss = 2.2766
2024-10-31 01:09:54: [2024-10-31 01:09:54] iter = 02380, loss = 3.1814
2024-10-31 01:09:56: [2024-10-31 01:09:56] iter = 02390, loss = 2.6032
2024-10-31 01:10:00: [2024-10-31 01:10:00] iter = 02400, loss = 1.9567
2024-10-31 01:10:03: [2024-10-31 01:10:03] iter = 02410, loss = 3.3589
2024-10-31 01:10:07: [2024-10-31 01:10:07] iter = 02420, loss = 2.0863
2024-10-31 01:10:10: [2024-10-31 01:10:10] iter = 02430, loss = 2.0513
2024-10-31 01:10:14: [2024-10-31 01:10:14] iter = 02440, loss = 1.7447
2024-10-31 01:10:16: [2024-10-31 01:10:16] iter = 02450, loss = 1.7803
2024-10-31 01:10:19: [2024-10-31 01:10:19] iter = 02460, loss = 2.0612
2024-10-31 01:10:22: [2024-10-31 01:10:22] iter = 02470, loss = 2.4638
2024-10-31 01:10:26: [2024-10-31 01:10:26] iter = 02480, loss = 1.7464
2024-10-31 01:10:29: [2024-10-31 01:10:29] iter = 02490, loss = 4.4429
2024-10-31 01:10:32: [2024-10-31 01:10:32] iter = 02500, loss = 1.9737
2024-10-31 01:10:35: [2024-10-31 01:10:35] iter = 02510, loss = 2.5467
2024-10-31 01:10:39: [2024-10-31 01:10:39] iter = 02520, loss = 2.4279
2024-10-31 01:10:43: [2024-10-31 01:10:43] iter = 02530, loss = 1.9439
2024-10-31 01:10:45: [2024-10-31 01:10:45] iter = 02540, loss = 2.1835
2024-10-31 01:10:48: [2024-10-31 01:10:48] iter = 02550, loss = 2.1377
2024-10-31 01:10:52: [2024-10-31 01:10:52] iter = 02560, loss = 1.8946
2024-10-31 01:10:56: [2024-10-31 01:10:56] iter = 02570, loss = 1.9880
2024-10-31 01:10:59: [2024-10-31 01:10:59] iter = 02580, loss = 1.6843
2024-10-31 01:11:03: [2024-10-31 01:11:03] iter = 02590, loss = 2.2977
2024-10-31 01:11:07: [2024-10-31 01:11:07] iter = 02600, loss = 2.1509
2024-10-31 01:11:11: [2024-10-31 01:11:11] iter = 02610, loss = 1.7836
2024-10-31 01:11:14: [2024-10-31 01:11:14] iter = 02620, loss = 1.7908
2024-10-31 01:11:17: [2024-10-31 01:11:17] iter = 02630, loss = 2.2260
2024-10-31 01:11:20: [2024-10-31 01:11:20] iter = 02640, loss = 3.0644
2024-10-31 01:11:23: [2024-10-31 01:11:23] iter = 02650, loss = 2.8753
2024-10-31 01:11:27: [2024-10-31 01:11:27] iter = 02660, loss = 3.3620
2024-10-31 01:11:31: [2024-10-31 01:11:31] iter = 02670, loss = 2.3527
2024-10-31 01:11:35: [2024-10-31 01:11:35] iter = 02680, loss = 1.7519
2024-10-31 01:11:38: [2024-10-31 01:11:38] iter = 02690, loss = 3.1720
2024-10-31 01:11:41: [2024-10-31 01:11:41] iter = 02700, loss = 1.7824
2024-10-31 01:11:45: [2024-10-31 01:11:45] iter = 02710, loss = 1.7444
2024-10-31 01:11:49: [2024-10-31 01:11:49] iter = 02720, loss = 2.9127
2024-10-31 01:11:51: [2024-10-31 01:11:51] iter = 02730, loss = 6.5979
2024-10-31 01:11:54: [2024-10-31 01:11:54] iter = 02740, loss = 2.2477
2024-10-31 01:11:59: [2024-10-31 01:11:59] iter = 02750, loss = 3.9912
2024-10-31 01:12:02: [2024-10-31 01:12:02] iter = 02760, loss = 2.2097
2024-10-31 01:12:05: [2024-10-31 01:12:05] iter = 02770, loss = 2.6783
2024-10-31 01:12:09: [2024-10-31 01:12:09] iter = 02780, loss = 2.4450
2024-10-31 01:12:13: [2024-10-31 01:12:13] iter = 02790, loss = 1.8350
2024-10-31 01:12:16: [2024-10-31 01:12:16] iter = 02800, loss = 2.2173
2024-10-31 01:12:20: [2024-10-31 01:12:20] iter = 02810, loss = 1.8934
2024-10-31 01:12:25: [2024-10-31 01:12:25] iter = 02820, loss = 1.8896
2024-10-31 01:12:28: [2024-10-31 01:12:28] iter = 02830, loss = 1.9612
2024-10-31 01:12:32: [2024-10-31 01:12:32] iter = 02840, loss = 3.1787
2024-10-31 01:12:36: [2024-10-31 01:12:36] iter = 02850, loss = 1.9420
2024-10-31 01:12:39: [2024-10-31 01:12:39] iter = 02860, loss = 1.9631
2024-10-31 01:12:43: [2024-10-31 01:12:43] iter = 02870, loss = 3.8618
2024-10-31 01:12:46: [2024-10-31 01:12:46] iter = 02880, loss = 2.1131
2024-10-31 01:12:49: [2024-10-31 01:12:49] iter = 02890, loss = 2.0477
2024-10-31 01:12:53: [2024-10-31 01:12:53] iter = 02900, loss = 3.6235
2024-10-31 01:12:56: [2024-10-31 01:12:56] iter = 02910, loss = 1.9046
2024-10-31 01:13:00: [2024-10-31 01:13:00] iter = 02920, loss = 2.1530
2024-10-31 01:13:03: [2024-10-31 01:13:03] iter = 02930, loss = 1.7396
2024-10-31 01:13:06: [2024-10-31 01:13:06] iter = 02940, loss = 1.7168
2024-10-31 01:13:10: [2024-10-31 01:13:10] iter = 02950, loss = 1.6504
2024-10-31 01:13:13: [2024-10-31 01:13:13] iter = 02960, loss = 2.0234
2024-10-31 01:13:17: [2024-10-31 01:13:17] iter = 02970, loss = 2.3085
2024-10-31 01:13:21: [2024-10-31 01:13:21] iter = 02980, loss = 1.9758
2024-10-31 01:13:24: [2024-10-31 01:13:24] iter = 02990, loss = 2.4748
2024-10-31 01:13:28: [2024-10-31 01:13:28] iter = 03000, loss = 1.8386
2024-10-31 01:13:31: [2024-10-31 01:13:31] iter = 03010, loss = 1.6618
2024-10-31 01:13:34: [2024-10-31 01:13:34] iter = 03020, loss = 2.2816
2024-10-31 01:13:38: [2024-10-31 01:13:38] iter = 03030, loss = 2.0971
2024-10-31 01:13:41: [2024-10-31 01:13:41] iter = 03040, loss = 1.7996
2024-10-31 01:13:44: [2024-10-31 01:13:44] iter = 03050, loss = 2.4293
2024-10-31 01:13:49: [2024-10-31 01:13:49] iter = 03060, loss = 2.3773
2024-10-31 01:13:52: [2024-10-31 01:13:52] iter = 03070, loss = 2.2382
2024-10-31 01:13:55: [2024-10-31 01:13:55] iter = 03080, loss = 4.5529
2024-10-31 01:13:58: [2024-10-31 01:13:58] iter = 03090, loss = 2.4381
2024-10-31 01:14:01: [2024-10-31 01:14:01] iter = 03100, loss = 1.7496
2024-10-31 01:14:04: [2024-10-31 01:14:04] iter = 03110, loss = 3.2428
2024-10-31 01:14:08: [2024-10-31 01:14:08] iter = 03120, loss = 3.8095
2024-10-31 01:14:11: [2024-10-31 01:14:11] iter = 03130, loss = 1.9444
2024-10-31 01:14:15: [2024-10-31 01:14:15] iter = 03140, loss = 2.0932
2024-10-31 01:14:18: [2024-10-31 01:14:18] iter = 03150, loss = 1.9650
2024-10-31 01:14:21: [2024-10-31 01:14:21] iter = 03160, loss = 1.9741
2024-10-31 01:14:25: [2024-10-31 01:14:25] iter = 03170, loss = 1.9725
2024-10-31 01:14:28: [2024-10-31 01:14:28] iter = 03180, loss = 1.9742
2024-10-31 01:14:31: [2024-10-31 01:14:31] iter = 03190, loss = 2.1352
2024-10-31 01:14:35: [2024-10-31 01:14:35] iter = 03200, loss = 2.6800
2024-10-31 01:14:38: [2024-10-31 01:14:38] iter = 03210, loss = 2.1840
2024-10-31 01:14:41: [2024-10-31 01:14:41] iter = 03220, loss = 1.8082
2024-10-31 01:14:45: [2024-10-31 01:14:45] iter = 03230, loss = 1.7126
2024-10-31 01:14:49: [2024-10-31 01:14:49] iter = 03240, loss = 2.5173
2024-10-31 01:14:52: [2024-10-31 01:14:52] iter = 03250, loss = 2.7982
2024-10-31 01:14:55: [2024-10-31 01:14:55] iter = 03260, loss = 2.5619
2024-10-31 01:14:59: [2024-10-31 01:14:59] iter = 03270, loss = 1.9032
2024-10-31 01:15:03: [2024-10-31 01:15:03] iter = 03280, loss = 1.7086
2024-10-31 01:15:06: [2024-10-31 01:15:06] iter = 03290, loss = 2.2801
2024-10-31 01:15:09: [2024-10-31 01:15:09] iter = 03300, loss = 1.8089
2024-10-31 01:15:12: [2024-10-31 01:15:12] iter = 03310, loss = 1.8424
2024-10-31 01:15:15: [2024-10-31 01:15:15] iter = 03320, loss = 2.9254
2024-10-31 01:15:19: [2024-10-31 01:15:19] iter = 03330, loss = 1.9904
2024-10-31 01:15:22: [2024-10-31 01:15:22] iter = 03340, loss = 2.0422
2024-10-31 01:15:26: [2024-10-31 01:15:26] iter = 03350, loss = 1.7849
2024-10-31 01:15:29: [2024-10-31 01:15:29] iter = 03360, loss = 2.0539
2024-10-31 01:15:32: [2024-10-31 01:15:32] iter = 03370, loss = 1.9696
2024-10-31 01:15:36: [2024-10-31 01:15:36] iter = 03380, loss = 1.8017
2024-10-31 01:15:39: [2024-10-31 01:15:39] iter = 03390, loss = 1.7836
2024-10-31 01:15:42: [2024-10-31 01:15:42] iter = 03400, loss = 1.8768
2024-10-31 01:15:46: [2024-10-31 01:15:46] iter = 03410, loss = 1.9949
2024-10-31 01:15:49: [2024-10-31 01:15:49] iter = 03420, loss = 1.8833
2024-10-31 01:15:52: [2024-10-31 01:15:52] iter = 03430, loss = 2.6347
2024-10-31 01:15:56: [2024-10-31 01:15:56] iter = 03440, loss = 1.9678
2024-10-31 01:16:00: [2024-10-31 01:15:59] iter = 03450, loss = 2.3649
2024-10-31 01:16:03: [2024-10-31 01:16:03] iter = 03460, loss = 1.8205
2024-10-31 01:16:08: [2024-10-31 01:16:08] iter = 03470, loss = 2.0554
2024-10-31 01:16:11: [2024-10-31 01:16:11] iter = 03480, loss = 3.3458
2024-10-31 01:16:14: [2024-10-31 01:16:14] iter = 03490, loss = 2.7101
2024-10-31 01:16:17: [2024-10-31 01:16:17] iter = 03500, loss = 2.0354
2024-10-31 01:16:21: [2024-10-31 01:16:21] iter = 03510, loss = 1.7969
2024-10-31 01:16:25: [2024-10-31 01:16:25] iter = 03520, loss = 1.7702
2024-10-31 01:16:28: [2024-10-31 01:16:28] iter = 03530, loss = 1.9345
2024-10-31 01:16:32: [2024-10-31 01:16:32] iter = 03540, loss = 1.8252
2024-10-31 01:16:35: [2024-10-31 01:16:35] iter = 03550, loss = 2.1451
2024-10-31 01:16:39: [2024-10-31 01:16:39] iter = 03560, loss = 2.3712
2024-10-31 01:16:43: [2024-10-31 01:16:43] iter = 03570, loss = 2.0046
2024-10-31 01:16:45: [2024-10-31 01:16:45] iter = 03580, loss = 2.3345
2024-10-31 01:16:49: [2024-10-31 01:16:49] iter = 03590, loss = 1.9479
2024-10-31 01:16:53: [2024-10-31 01:16:53] iter = 03600, loss = 3.4473
2024-10-31 01:16:56: [2024-10-31 01:16:56] iter = 03610, loss = 2.4644
2024-10-31 01:17:00: [2024-10-31 01:17:00] iter = 03620, loss = 2.2396
2024-10-31 01:17:03: [2024-10-31 01:17:03] iter = 03630, loss = 2.0661
2024-10-31 01:17:06: [2024-10-31 01:17:06] iter = 03640, loss = 4.0119
2024-10-31 01:17:09: [2024-10-31 01:17:09] iter = 03650, loss = 2.9296
2024-10-31 01:17:13: [2024-10-31 01:17:13] iter = 03660, loss = 2.4220
2024-10-31 01:17:16: [2024-10-31 01:17:16] iter = 03670, loss = 2.2855
2024-10-31 01:17:19: [2024-10-31 01:17:19] iter = 03680, loss = 1.6473
2024-10-31 01:17:22: [2024-10-31 01:17:22] iter = 03690, loss = 1.8668
2024-10-31 01:17:26: [2024-10-31 01:17:26] iter = 03700, loss = 1.8570
2024-10-31 01:17:29: [2024-10-31 01:17:29] iter = 03710, loss = 1.7140
2024-10-31 01:17:33: [2024-10-31 01:17:33] iter = 03720, loss = 2.5853
2024-10-31 01:17:37: [2024-10-31 01:17:37] iter = 03730, loss = 2.2369
2024-10-31 01:17:40: [2024-10-31 01:17:40] iter = 03740, loss = 2.2424
2024-10-31 01:17:43: [2024-10-31 01:17:43] iter = 03750, loss = 2.1956
2024-10-31 01:17:46: [2024-10-31 01:17:46] iter = 03760, loss = 1.8296
2024-10-31 01:17:49: [2024-10-31 01:17:49] iter = 03770, loss = 1.6885
2024-10-31 01:17:52: [2024-10-31 01:17:52] iter = 03780, loss = 1.9649
2024-10-31 01:17:54: [2024-10-31 01:17:54] iter = 03790, loss = 1.8752
2024-10-31 01:17:56: [2024-10-31 01:17:56] iter = 03800, loss = 1.8060
2024-10-31 01:17:58: [2024-10-31 01:17:58] iter = 03810, loss = 2.0620
2024-10-31 01:18:01: [2024-10-31 01:18:01] iter = 03820, loss = 2.0728
2024-10-31 01:18:04: [2024-10-31 01:18:04] iter = 03830, loss = 2.0035
2024-10-31 01:18:08: [2024-10-31 01:18:08] iter = 03840, loss = 2.2491
2024-10-31 01:18:11: [2024-10-31 01:18:11] iter = 03850, loss = 3.4931
2024-10-31 01:18:14: [2024-10-31 01:18:14] iter = 03860, loss = 1.8193
2024-10-31 01:18:17: [2024-10-31 01:18:17] iter = 03870, loss = 1.6896
2024-10-31 01:18:21: [2024-10-31 01:18:21] iter = 03880, loss = 2.1855
2024-10-31 01:18:25: [2024-10-31 01:18:25] iter = 03890, loss = 1.8642
2024-10-31 01:18:29: [2024-10-31 01:18:29] iter = 03900, loss = 2.4162
2024-10-31 01:18:32: [2024-10-31 01:18:32] iter = 03910, loss = 1.8226
2024-10-31 01:18:36: [2024-10-31 01:18:36] iter = 03920, loss = 2.0335
2024-10-31 01:18:40: [2024-10-31 01:18:40] iter = 03930, loss = 2.2643
2024-10-31 01:18:43: [2024-10-31 01:18:43] iter = 03940, loss = 1.9157
2024-10-31 01:18:46: [2024-10-31 01:18:46] iter = 03950, loss = 1.8514
2024-10-31 01:18:50: [2024-10-31 01:18:50] iter = 03960, loss = 3.2976
2024-10-31 01:18:53: [2024-10-31 01:18:53] iter = 03970, loss = 2.3076
2024-10-31 01:18:56: [2024-10-31 01:18:56] iter = 03980, loss = 2.2596
2024-10-31 01:19:00: [2024-10-31 01:19:00] iter = 03990, loss = 2.4795
2024-10-31 01:19:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-31 01:19:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:19:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 43080}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:21:08: Evaluate 5 random ConvNet, ACCmean = 0.7763 ACCstd = 0.0046
-------------------------
2024-10-31 01:21:08: Evaluate 5 random ConvNet, SENmean = 0.7721 SENstd = 0.0029
-------------------------
2024-10-31 01:21:08: Evaluate 5 random ConvNet, SPEmean = 0.9774 SPEstd = 0.0005
-------------------------
2024-10-31 01:21:08: Evaluate 5 random ConvNet, F!mean = 0.7647 F!std = 0.0036
-------------------------
2024-10-31 01:21:08: Evaluate 5 random ConvNet, mean = 0.7763 std = 0.0046
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:21:08: [2024-10-31 01:21:08] iter = 04000, loss = 2.3977
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:21:11: [2024-10-31 01:21:11] iter = 04010, loss = 1.8945
2024-10-31 01:21:14: [2024-10-31 01:21:14] iter = 04020, loss = 2.0787
2024-10-31 01:21:18: [2024-10-31 01:21:18] iter = 04030, loss = 2.4015
2024-10-31 01:21:21: [2024-10-31 01:21:21] iter = 04040, loss = 1.8407
2024-10-31 01:21:24: [2024-10-31 01:21:24] iter = 04050, loss = 1.5159
2024-10-31 01:21:28: [2024-10-31 01:21:28] iter = 04060, loss = 2.2874
2024-10-31 01:21:31: [2024-10-31 01:21:31] iter = 04070, loss = 1.6658
2024-10-31 01:21:34: [2024-10-31 01:21:34] iter = 04080, loss = 2.5407
2024-10-31 01:21:38: [2024-10-31 01:21:38] iter = 04090, loss = 2.0484
2024-10-31 01:21:41: [2024-10-31 01:21:41] iter = 04100, loss = 2.1827
2024-10-31 01:21:44: [2024-10-31 01:21:44] iter = 04110, loss = 2.3562
2024-10-31 01:21:47: [2024-10-31 01:21:47] iter = 04120, loss = 2.0265
2024-10-31 01:21:51: [2024-10-31 01:21:51] iter = 04130, loss = 1.6399
2024-10-31 01:21:54: [2024-10-31 01:21:54] iter = 04140, loss = 2.0015
2024-10-31 01:21:58: [2024-10-31 01:21:58] iter = 04150, loss = 1.8143
2024-10-31 01:22:01: [2024-10-31 01:22:01] iter = 04160, loss = 2.0603
2024-10-31 01:22:05: [2024-10-31 01:22:05] iter = 04170, loss = 2.5487
2024-10-31 01:22:08: [2024-10-31 01:22:08] iter = 04180, loss = 2.4565
2024-10-31 01:22:12: [2024-10-31 01:22:12] iter = 04190, loss = 1.8148
2024-10-31 01:22:16: [2024-10-31 01:22:16] iter = 04200, loss = 1.7857
2024-10-31 01:22:19: [2024-10-31 01:22:19] iter = 04210, loss = 6.9850
2024-10-31 01:22:22: [2024-10-31 01:22:22] iter = 04220, loss = 3.9563
2024-10-31 01:22:26: [2024-10-31 01:22:26] iter = 04230, loss = 2.4383
2024-10-31 01:22:29: [2024-10-31 01:22:29] iter = 04240, loss = 2.1285
2024-10-31 01:22:32: [2024-10-31 01:22:32] iter = 04250, loss = 2.3353
2024-10-31 01:22:35: [2024-10-31 01:22:35] iter = 04260, loss = 1.5746
2024-10-31 01:22:38: [2024-10-31 01:22:38] iter = 04270, loss = 1.8057
2024-10-31 01:22:42: [2024-10-31 01:22:42] iter = 04280, loss = 2.8244
2024-10-31 01:22:46: [2024-10-31 01:22:46] iter = 04290, loss = 2.2942
2024-10-31 01:22:50: [2024-10-31 01:22:50] iter = 04300, loss = 2.6115
2024-10-31 01:22:53: [2024-10-31 01:22:53] iter = 04310, loss = 1.8764
2024-10-31 01:22:57: [2024-10-31 01:22:57] iter = 04320, loss = 2.3385
2024-10-31 01:23:00: [2024-10-31 01:23:00] iter = 04330, loss = 1.4806
2024-10-31 01:23:04: [2024-10-31 01:23:04] iter = 04340, loss = 2.2271
2024-10-31 01:23:08: [2024-10-31 01:23:08] iter = 04350, loss = 2.1837
2024-10-31 01:23:12: [2024-10-31 01:23:12] iter = 04360, loss = 2.1484
2024-10-31 01:23:17: [2024-10-31 01:23:17] iter = 04370, loss = 1.8149
2024-10-31 01:23:21: [2024-10-31 01:23:21] iter = 04380, loss = 3.1754
2024-10-31 01:23:25: [2024-10-31 01:23:25] iter = 04390, loss = 2.1375
2024-10-31 01:23:29: [2024-10-31 01:23:29] iter = 04400, loss = 2.1918
2024-10-31 01:23:33: [2024-10-31 01:23:33] iter = 04410, loss = 1.8043
2024-10-31 01:23:37: [2024-10-31 01:23:37] iter = 04420, loss = 2.0414
2024-10-31 01:23:41: [2024-10-31 01:23:41] iter = 04430, loss = 1.9477
2024-10-31 01:23:45: [2024-10-31 01:23:45] iter = 04440, loss = 2.9156
2024-10-31 01:23:48: [2024-10-31 01:23:48] iter = 04450, loss = 2.0427
2024-10-31 01:23:53: [2024-10-31 01:23:53] iter = 04460, loss = 2.2292
2024-10-31 01:23:56: [2024-10-31 01:23:56] iter = 04470, loss = 1.7247
2024-10-31 01:24:00: [2024-10-31 01:24:00] iter = 04480, loss = 2.1101
2024-10-31 01:24:04: [2024-10-31 01:24:04] iter = 04490, loss = 2.8286
2024-10-31 01:24:07: [2024-10-31 01:24:07] iter = 04500, loss = 1.8082
2024-10-31 01:24:10: [2024-10-31 01:24:10] iter = 04510, loss = 1.9780
2024-10-31 01:24:14: [2024-10-31 01:24:14] iter = 04520, loss = 1.9024
2024-10-31 01:24:18: [2024-10-31 01:24:18] iter = 04530, loss = 1.9225
2024-10-31 01:24:22: [2024-10-31 01:24:22] iter = 04540, loss = 2.3082
2024-10-31 01:24:25: [2024-10-31 01:24:25] iter = 04550, loss = 3.0112
2024-10-31 01:24:28: [2024-10-31 01:24:28] iter = 04560, loss = 2.1655
2024-10-31 01:24:32: [2024-10-31 01:24:32] iter = 04570, loss = 2.6173
2024-10-31 01:24:35: [2024-10-31 01:24:35] iter = 04580, loss = 1.9668
2024-10-31 01:24:38: [2024-10-31 01:24:38] iter = 04590, loss = 2.2192
2024-10-31 01:24:42: [2024-10-31 01:24:42] iter = 04600, loss = 1.9437
2024-10-31 01:24:46: [2024-10-31 01:24:46] iter = 04610, loss = 3.4212
2024-10-31 01:24:49: [2024-10-31 01:24:49] iter = 04620, loss = 2.2751
2024-10-31 01:24:52: [2024-10-31 01:24:52] iter = 04630, loss = 1.6893
2024-10-31 01:24:55: [2024-10-31 01:24:55] iter = 04640, loss = 2.5666
2024-10-31 01:24:58: [2024-10-31 01:24:58] iter = 04650, loss = 2.0108
2024-10-31 01:25:01: [2024-10-31 01:25:01] iter = 04660, loss = 1.8167
2024-10-31 01:25:05: [2024-10-31 01:25:05] iter = 04670, loss = 3.0741
2024-10-31 01:25:08: [2024-10-31 01:25:08] iter = 04680, loss = 2.0469
2024-10-31 01:25:11: [2024-10-31 01:25:11] iter = 04690, loss = 2.2175
2024-10-31 01:25:15: [2024-10-31 01:25:15] iter = 04700, loss = 1.9746
2024-10-31 01:25:18: [2024-10-31 01:25:18] iter = 04710, loss = 2.1213
2024-10-31 01:25:22: [2024-10-31 01:25:22] iter = 04720, loss = 1.8873
2024-10-31 01:25:25: [2024-10-31 01:25:25] iter = 04730, loss = 1.8675
2024-10-31 01:25:29: [2024-10-31 01:25:29] iter = 04740, loss = 2.0022
2024-10-31 01:25:32: [2024-10-31 01:25:32] iter = 04750, loss = 3.9871
2024-10-31 01:25:36: [2024-10-31 01:25:36] iter = 04760, loss = 1.7511
2024-10-31 01:25:39: [2024-10-31 01:25:39] iter = 04770, loss = 2.4260
2024-10-31 01:25:43: [2024-10-31 01:25:43] iter = 04780, loss = 1.8566
2024-10-31 01:25:47: [2024-10-31 01:25:47] iter = 04790, loss = 3.2433
2024-10-31 01:25:50: [2024-10-31 01:25:50] iter = 04800, loss = 1.9094
2024-10-31 01:25:54: [2024-10-31 01:25:54] iter = 04810, loss = 2.7105
2024-10-31 01:25:57: [2024-10-31 01:25:57] iter = 04820, loss = 1.7564
2024-10-31 01:26:00: [2024-10-31 01:26:00] iter = 04830, loss = 2.0510
2024-10-31 01:26:03: [2024-10-31 01:26:03] iter = 04840, loss = 1.8760
2024-10-31 01:26:06: [2024-10-31 01:26:06] iter = 04850, loss = 3.1037
2024-10-31 01:26:09: [2024-10-31 01:26:09] iter = 04860, loss = 2.5576
2024-10-31 01:26:13: [2024-10-31 01:26:13] iter = 04870, loss = 2.1910
2024-10-31 01:26:16: [2024-10-31 01:26:16] iter = 04880, loss = 1.9302
2024-10-31 01:26:18: [2024-10-31 01:26:18] iter = 04890, loss = 2.2841
2024-10-31 01:26:23: [2024-10-31 01:26:23] iter = 04900, loss = 3.4633
2024-10-31 01:26:27: [2024-10-31 01:26:27] iter = 04910, loss = 1.8034
2024-10-31 01:26:30: [2024-10-31 01:26:30] iter = 04920, loss = 1.9977
2024-10-31 01:26:34: [2024-10-31 01:26:34] iter = 04930, loss = 1.9947
2024-10-31 01:26:38: [2024-10-31 01:26:38] iter = 04940, loss = 1.8935
2024-10-31 01:26:41: [2024-10-31 01:26:41] iter = 04950, loss = 1.9275
2024-10-31 01:26:44: [2024-10-31 01:26:44] iter = 04960, loss = 2.1086
2024-10-31 01:26:48: [2024-10-31 01:26:48] iter = 04970, loss = 2.7921
2024-10-31 01:26:53: [2024-10-31 01:26:53] iter = 04980, loss = 1.4859
2024-10-31 01:26:56: [2024-10-31 01:26:56] iter = 04990, loss = 1.9110
2024-10-31 01:27:00: [2024-10-31 01:27:00] iter = 05000, loss = 3.1342
2024-10-31 01:27:03: [2024-10-31 01:27:03] iter = 05010, loss = 2.7794
2024-10-31 01:27:07: [2024-10-31 01:27:07] iter = 05020, loss = 2.9284
2024-10-31 01:27:10: [2024-10-31 01:27:10] iter = 05030, loss = 1.8260
2024-10-31 01:27:14: [2024-10-31 01:27:14] iter = 05040, loss = 2.0610
2024-10-31 01:27:17: [2024-10-31 01:27:17] iter = 05050, loss = 2.3524
2024-10-31 01:27:20: [2024-10-31 01:27:20] iter = 05060, loss = 2.1264
2024-10-31 01:27:23: [2024-10-31 01:27:23] iter = 05070, loss = 1.9461
2024-10-31 01:27:26: [2024-10-31 01:27:26] iter = 05080, loss = 2.3698
2024-10-31 01:27:29: [2024-10-31 01:27:29] iter = 05090, loss = 2.6057
2024-10-31 01:27:32: [2024-10-31 01:27:32] iter = 05100, loss = 2.0749
2024-10-31 01:27:36: [2024-10-31 01:27:36] iter = 05110, loss = 1.8984
2024-10-31 01:27:40: [2024-10-31 01:27:40] iter = 05120, loss = 3.0734
2024-10-31 01:27:44: [2024-10-31 01:27:44] iter = 05130, loss = 1.7995
2024-10-31 01:27:48: [2024-10-31 01:27:48] iter = 05140, loss = 2.5777
2024-10-31 01:27:51: [2024-10-31 01:27:51] iter = 05150, loss = 2.3479
2024-10-31 01:27:55: [2024-10-31 01:27:55] iter = 05160, loss = 1.7950
2024-10-31 01:27:58: [2024-10-31 01:27:58] iter = 05170, loss = 1.7333
2024-10-31 01:28:01: [2024-10-31 01:28:01] iter = 05180, loss = 2.4285
2024-10-31 01:28:05: [2024-10-31 01:28:05] iter = 05190, loss = 2.3646
2024-10-31 01:28:08: [2024-10-31 01:28:08] iter = 05200, loss = 1.7333
2024-10-31 01:28:12: [2024-10-31 01:28:12] iter = 05210, loss = 1.7239
2024-10-31 01:28:15: [2024-10-31 01:28:15] iter = 05220, loss = 1.7220
2024-10-31 01:28:19: [2024-10-31 01:28:19] iter = 05230, loss = 2.1369
2024-10-31 01:28:22: [2024-10-31 01:28:22] iter = 05240, loss = 2.1998
2024-10-31 01:28:26: [2024-10-31 01:28:26] iter = 05250, loss = 2.7333
2024-10-31 01:28:29: [2024-10-31 01:28:29] iter = 05260, loss = 2.9194
2024-10-31 01:28:32: [2024-10-31 01:28:32] iter = 05270, loss = 2.8412
2024-10-31 01:28:36: [2024-10-31 01:28:36] iter = 05280, loss = 1.8061
2024-10-31 01:28:40: [2024-10-31 01:28:40] iter = 05290, loss = 1.6798
2024-10-31 01:28:43: [2024-10-31 01:28:43] iter = 05300, loss = 2.5954
2024-10-31 01:28:46: [2024-10-31 01:28:46] iter = 05310, loss = 1.8673
2024-10-31 01:28:49: [2024-10-31 01:28:49] iter = 05320, loss = 2.0594
2024-10-31 01:28:53: [2024-10-31 01:28:53] iter = 05330, loss = 1.9695
2024-10-31 01:28:56: [2024-10-31 01:28:56] iter = 05340, loss = 2.1767
2024-10-31 01:28:58: [2024-10-31 01:28:58] iter = 05350, loss = 2.3100
2024-10-31 01:29:01: [2024-10-31 01:29:01] iter = 05360, loss = 2.2573
2024-10-31 01:29:04: [2024-10-31 01:29:04] iter = 05370, loss = 1.6600
2024-10-31 01:29:07: [2024-10-31 01:29:07] iter = 05380, loss = 3.8955
2024-10-31 01:29:10: [2024-10-31 01:29:10] iter = 05390, loss = 1.9584
2024-10-31 01:29:14: [2024-10-31 01:29:14] iter = 05400, loss = 2.0634
2024-10-31 01:29:17: [2024-10-31 01:29:17] iter = 05410, loss = 2.4188
2024-10-31 01:29:20: [2024-10-31 01:29:20] iter = 05420, loss = 2.7880
2024-10-31 01:29:24: [2024-10-31 01:29:24] iter = 05430, loss = 2.0286
2024-10-31 01:29:26: [2024-10-31 01:29:26] iter = 05440, loss = 2.7232
2024-10-31 01:29:29: [2024-10-31 01:29:29] iter = 05450, loss = 2.0517
2024-10-31 01:29:32: [2024-10-31 01:29:32] iter = 05460, loss = 2.1686
2024-10-31 01:29:34: [2024-10-31 01:29:34] iter = 05470, loss = 1.7439
2024-10-31 01:29:38: [2024-10-31 01:29:38] iter = 05480, loss = 2.4256
2024-10-31 01:29:41: [2024-10-31 01:29:41] iter = 05490, loss = 2.4532
2024-10-31 01:29:44: [2024-10-31 01:29:44] iter = 05500, loss = 1.9173
2024-10-31 01:29:48: [2024-10-31 01:29:48] iter = 05510, loss = 2.1543
2024-10-31 01:29:52: [2024-10-31 01:29:52] iter = 05520, loss = 2.0785
2024-10-31 01:29:55: [2024-10-31 01:29:55] iter = 05530, loss = 1.8469
2024-10-31 01:29:58: [2024-10-31 01:29:58] iter = 05540, loss = 3.1857
2024-10-31 01:30:01: [2024-10-31 01:30:01] iter = 05550, loss = 1.9447
2024-10-31 01:30:05: [2024-10-31 01:30:05] iter = 05560, loss = 2.1033
2024-10-31 01:30:08: [2024-10-31 01:30:08] iter = 05570, loss = 4.4112
2024-10-31 01:30:11: [2024-10-31 01:30:11] iter = 05580, loss = 2.1495
2024-10-31 01:30:15: [2024-10-31 01:30:15] iter = 05590, loss = 1.7725
2024-10-31 01:30:18: [2024-10-31 01:30:18] iter = 05600, loss = 2.2905
2024-10-31 01:30:21: [2024-10-31 01:30:21] iter = 05610, loss = 2.9199
2024-10-31 01:30:24: [2024-10-31 01:30:24] iter = 05620, loss = 2.1596
2024-10-31 01:30:27: [2024-10-31 01:30:27] iter = 05630, loss = 2.2805
2024-10-31 01:30:30: [2024-10-31 01:30:30] iter = 05640, loss = 1.9309
2024-10-31 01:30:33: [2024-10-31 01:30:33] iter = 05650, loss = 2.3775
2024-10-31 01:30:38: [2024-10-31 01:30:38] iter = 05660, loss = 2.6802
2024-10-31 01:30:42: [2024-10-31 01:30:42] iter = 05670, loss = 2.0113
2024-10-31 01:30:46: [2024-10-31 01:30:46] iter = 05680, loss = 2.2823
2024-10-31 01:30:49: [2024-10-31 01:30:49] iter = 05690, loss = 2.0574
2024-10-31 01:30:52: [2024-10-31 01:30:52] iter = 05700, loss = 2.1911
2024-10-31 01:30:55: [2024-10-31 01:30:55] iter = 05710, loss = 2.7417
2024-10-31 01:30:59: [2024-10-31 01:30:59] iter = 05720, loss = 1.7050
2024-10-31 01:31:03: [2024-10-31 01:31:03] iter = 05730, loss = 1.9798
2024-10-31 01:31:07: [2024-10-31 01:31:07] iter = 05740, loss = 1.8151
2024-10-31 01:31:10: [2024-10-31 01:31:10] iter = 05750, loss = 1.9915
2024-10-31 01:31:13: [2024-10-31 01:31:13] iter = 05760, loss = 2.0695
2024-10-31 01:31:17: [2024-10-31 01:31:17] iter = 05770, loss = 2.1036
2024-10-31 01:31:20: [2024-10-31 01:31:20] iter = 05780, loss = 1.7860
2024-10-31 01:31:23: [2024-10-31 01:31:23] iter = 05790, loss = 2.3116
2024-10-31 01:31:26: [2024-10-31 01:31:26] iter = 05800, loss = 1.9837
2024-10-31 01:31:29: [2024-10-31 01:31:29] iter = 05810, loss = 2.3653
2024-10-31 01:31:33: [2024-10-31 01:31:33] iter = 05820, loss = 2.2819
2024-10-31 01:31:36: [2024-10-31 01:31:36] iter = 05830, loss = 2.5448
2024-10-31 01:31:40: [2024-10-31 01:31:40] iter = 05840, loss = 3.4385
2024-10-31 01:31:43: [2024-10-31 01:31:43] iter = 05850, loss = 1.6952
2024-10-31 01:31:46: [2024-10-31 01:31:46] iter = 05860, loss = 1.7603
2024-10-31 01:31:49: [2024-10-31 01:31:49] iter = 05870, loss = 1.7593
2024-10-31 01:31:52: [2024-10-31 01:31:52] iter = 05880, loss = 1.6579
2024-10-31 01:31:54: [2024-10-31 01:31:54] iter = 05890, loss = 2.1548
2024-10-31 01:31:58: [2024-10-31 01:31:58] iter = 05900, loss = 1.9505
2024-10-31 01:32:00: [2024-10-31 01:32:00] iter = 05910, loss = 2.3054
2024-10-31 01:32:03: [2024-10-31 01:32:03] iter = 05920, loss = 2.4554
2024-10-31 01:32:06: [2024-10-31 01:32:06] iter = 05930, loss = 2.3410
2024-10-31 01:32:09: [2024-10-31 01:32:09] iter = 05940, loss = 2.2231
2024-10-31 01:32:12: [2024-10-31 01:32:12] iter = 05950, loss = 1.8796
2024-10-31 01:32:15: [2024-10-31 01:32:15] iter = 05960, loss = 1.9107
2024-10-31 01:32:18: [2024-10-31 01:32:18] iter = 05970, loss = 2.2397
2024-10-31 01:32:21: [2024-10-31 01:32:21] iter = 05980, loss = 3.7888
2024-10-31 01:32:24: [2024-10-31 01:32:24] iter = 05990, loss = 1.9909
2024-10-31 01:32:28: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-31 01:32:28: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:32:28: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 48643}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:34:22: Evaluate 5 random ConvNet, ACCmean = 0.7846 ACCstd = 0.0040
-------------------------
2024-10-31 01:34:22: Evaluate 5 random ConvNet, SENmean = 0.7788 SENstd = 0.0042
-------------------------
2024-10-31 01:34:22: Evaluate 5 random ConvNet, SPEmean = 0.9781 SPEstd = 0.0004
-------------------------
2024-10-31 01:34:22: Evaluate 5 random ConvNet, F!mean = 0.7733 F!std = 0.0035
-------------------------
2024-10-31 01:34:22: Evaluate 5 random ConvNet, mean = 0.7846 std = 0.0040
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:34:23: [2024-10-31 01:34:23] iter = 06000, loss = 2.1411
2024-10-31 01:34:26: [2024-10-31 01:34:26] iter = 06010, loss = 1.8976
2024-10-31 01:34:29: [2024-10-31 01:34:29] iter = 06020, loss = 2.0001
2024-10-31 01:34:32: [2024-10-31 01:34:32] iter = 06030, loss = 2.9670
2024-10-31 01:34:35: [2024-10-31 01:34:35] iter = 06040, loss = 2.1370
2024-10-31 01:34:38: [2024-10-31 01:34:38] iter = 06050, loss = 1.9513
2024-10-31 01:34:42: [2024-10-31 01:34:42] iter = 06060, loss = 1.6648
2024-10-31 01:34:45: [2024-10-31 01:34:45] iter = 06070, loss = 2.8366
2024-10-31 01:34:49: [2024-10-31 01:34:49] iter = 06080, loss = 1.9341
2024-10-31 01:34:52: [2024-10-31 01:34:52] iter = 06090, loss = 1.9579
2024-10-31 01:34:55: [2024-10-31 01:34:55] iter = 06100, loss = 2.8283
2024-10-31 01:34:59: [2024-10-31 01:34:59] iter = 06110, loss = 2.4279
2024-10-31 01:35:02: [2024-10-31 01:35:02] iter = 06120, loss = 1.7497
2024-10-31 01:35:06: [2024-10-31 01:35:06] iter = 06130, loss = 2.0783
2024-10-31 01:35:09: [2024-10-31 01:35:09] iter = 06140, loss = 1.8160
2024-10-31 01:35:13: [2024-10-31 01:35:13] iter = 06150, loss = 1.8802
2024-10-31 01:35:16: [2024-10-31 01:35:16] iter = 06160, loss = 1.6985
2024-10-31 01:35:18: [2024-10-31 01:35:18] iter = 06170, loss = 1.9570
2024-10-31 01:35:21: [2024-10-31 01:35:21] iter = 06180, loss = 2.3460
2024-10-31 01:35:24: [2024-10-31 01:35:24] iter = 06190, loss = 3.1043
2024-10-31 01:35:27: [2024-10-31 01:35:27] iter = 06200, loss = 2.8098
2024-10-31 01:35:30: [2024-10-31 01:35:30] iter = 06210, loss = 3.5117
2024-10-31 01:35:34: [2024-10-31 01:35:34] iter = 06220, loss = 2.1545
2024-10-31 01:35:37: [2024-10-31 01:35:37] iter = 06230, loss = 2.0514
2024-10-31 01:35:41: [2024-10-31 01:35:41] iter = 06240, loss = 2.6137
2024-10-31 01:35:44: [2024-10-31 01:35:44] iter = 06250, loss = 2.2180
2024-10-31 01:35:47: [2024-10-31 01:35:47] iter = 06260, loss = 1.7082
2024-10-31 01:35:50: [2024-10-31 01:35:50] iter = 06270, loss = 2.6661
2024-10-31 01:35:53: [2024-10-31 01:35:53] iter = 06280, loss = 2.0032
2024-10-31 01:35:56: [2024-10-31 01:35:56] iter = 06290, loss = 1.8951
2024-10-31 01:35:58: [2024-10-31 01:35:58] iter = 06300, loss = 1.8499
2024-10-31 01:36:02: [2024-10-31 01:36:02] iter = 06310, loss = 2.0415
2024-10-31 01:36:05: [2024-10-31 01:36:05] iter = 06320, loss = 3.1624
2024-10-31 01:36:09: [2024-10-31 01:36:09] iter = 06330, loss = 2.5104
2024-10-31 01:36:12: [2024-10-31 01:36:12] iter = 06340, loss = 2.6171
2024-10-31 01:36:15: [2024-10-31 01:36:15] iter = 06350, loss = 2.0327
2024-10-31 01:36:19: [2024-10-31 01:36:19] iter = 06360, loss = 3.0092
2024-10-31 01:36:21: [2024-10-31 01:36:21] iter = 06370, loss = 2.3368
2024-10-31 01:36:24: [2024-10-31 01:36:24] iter = 06380, loss = 2.1885
2024-10-31 01:36:27: [2024-10-31 01:36:27] iter = 06390, loss = 1.8971
2024-10-31 01:36:30: [2024-10-31 01:36:30] iter = 06400, loss = 1.6948
2024-10-31 01:36:34: [2024-10-31 01:36:34] iter = 06410, loss = 1.9864
2024-10-31 01:36:37: [2024-10-31 01:36:37] iter = 06420, loss = 2.0088
2024-10-31 01:36:40: [2024-10-31 01:36:40] iter = 06430, loss = 1.8128
2024-10-31 01:36:43: [2024-10-31 01:36:43] iter = 06440, loss = 3.0409
2024-10-31 01:36:47: [2024-10-31 01:36:47] iter = 06450, loss = 2.1688
2024-10-31 01:36:50: [2024-10-31 01:36:50] iter = 06460, loss = 2.1695
2024-10-31 01:36:53: [2024-10-31 01:36:53] iter = 06470, loss = 1.6622
2024-10-31 01:36:57: [2024-10-31 01:36:57] iter = 06480, loss = 1.9259
2024-10-31 01:37:00: [2024-10-31 01:37:00] iter = 06490, loss = 1.5467
2024-10-31 01:37:03: [2024-10-31 01:37:03] iter = 06500, loss = 1.9582
2024-10-31 01:37:07: [2024-10-31 01:37:07] iter = 06510, loss = 2.9043
2024-10-31 01:37:09: [2024-10-31 01:37:09] iter = 06520, loss = 2.1417
2024-10-31 01:37:13: [2024-10-31 01:37:13] iter = 06530, loss = 1.9665
2024-10-31 01:37:16: [2024-10-31 01:37:16] iter = 06540, loss = 2.2629
2024-10-31 01:37:19: [2024-10-31 01:37:19] iter = 06550, loss = 2.5322
2024-10-31 01:37:21: [2024-10-31 01:37:21] iter = 06560, loss = 3.1893
2024-10-31 01:37:25: [2024-10-31 01:37:25] iter = 06570, loss = 4.5642
2024-10-31 01:37:27: [2024-10-31 01:37:27] iter = 06580, loss = 2.1335
2024-10-31 01:37:30: [2024-10-31 01:37:30] iter = 06590, loss = 2.3264
2024-10-31 01:37:33: [2024-10-31 01:37:33] iter = 06600, loss = 1.8458
2024-10-31 01:37:36: [2024-10-31 01:37:36] iter = 06610, loss = 2.0276
2024-10-31 01:37:39: [2024-10-31 01:37:39] iter = 06620, loss = 1.9413
2024-10-31 01:37:41: [2024-10-31 01:37:41] iter = 06630, loss = 1.9751
2024-10-31 01:37:45: [2024-10-31 01:37:45] iter = 06640, loss = 2.9056
2024-10-31 01:37:49: [2024-10-31 01:37:49] iter = 06650, loss = 1.6939
2024-10-31 01:37:53: [2024-10-31 01:37:53] iter = 06660, loss = 1.6662
2024-10-31 01:37:56: [2024-10-31 01:37:56] iter = 06670, loss = 2.3905
2024-10-31 01:37:59: [2024-10-31 01:37:59] iter = 06680, loss = 2.8092
2024-10-31 01:38:02: [2024-10-31 01:38:02] iter = 06690, loss = 2.5120
2024-10-31 01:38:06: [2024-10-31 01:38:06] iter = 06700, loss = 2.1538
2024-10-31 01:38:10: [2024-10-31 01:38:10] iter = 06710, loss = 1.6608
2024-10-31 01:38:14: [2024-10-31 01:38:14] iter = 06720, loss = 2.5532
2024-10-31 01:38:18: [2024-10-31 01:38:18] iter = 06730, loss = 1.6536
2024-10-31 01:38:21: [2024-10-31 01:38:21] iter = 06740, loss = 1.7330
2024-10-31 01:38:24: [2024-10-31 01:38:24] iter = 06750, loss = 2.1339
2024-10-31 01:38:27: [2024-10-31 01:38:27] iter = 06760, loss = 2.3507
2024-10-31 01:38:30: [2024-10-31 01:38:30] iter = 06770, loss = 2.4130
2024-10-31 01:38:34: [2024-10-31 01:38:34] iter = 06780, loss = 4.0123
2024-10-31 01:38:37: [2024-10-31 01:38:37] iter = 06790, loss = 5.9178
2024-10-31 01:38:40: [2024-10-31 01:38:40] iter = 06800, loss = 2.1346
2024-10-31 01:38:44: [2024-10-31 01:38:44] iter = 06810, loss = 2.1853
2024-10-31 01:38:47: [2024-10-31 01:38:47] iter = 06820, loss = 1.9339
2024-10-31 01:38:51: [2024-10-31 01:38:51] iter = 06830, loss = 1.9170
2024-10-31 01:38:53: [2024-10-31 01:38:53] iter = 06840, loss = 2.0850
2024-10-31 01:38:56: [2024-10-31 01:38:56] iter = 06850, loss = 2.6185
2024-10-31 01:38:59: [2024-10-31 01:38:59] iter = 06860, loss = 2.0447
2024-10-31 01:39:02: [2024-10-31 01:39:02] iter = 06870, loss = 2.1300
2024-10-31 01:39:05: [2024-10-31 01:39:05] iter = 06880, loss = 2.3405
2024-10-31 01:39:08: [2024-10-31 01:39:08] iter = 06890, loss = 1.8291
2024-10-31 01:39:12: [2024-10-31 01:39:12] iter = 06900, loss = 1.7452
2024-10-31 01:39:15: [2024-10-31 01:39:15] iter = 06910, loss = 2.7473
2024-10-31 01:39:19: [2024-10-31 01:39:19] iter = 06920, loss = 1.9775
2024-10-31 01:39:21: [2024-10-31 01:39:21] iter = 06930, loss = 1.8765
2024-10-31 01:39:25: [2024-10-31 01:39:25] iter = 06940, loss = 3.3671
2024-10-31 01:39:28: [2024-10-31 01:39:28] iter = 06950, loss = 2.3637
2024-10-31 01:39:31: [2024-10-31 01:39:31] iter = 06960, loss = 2.2066
2024-10-31 01:39:35: [2024-10-31 01:39:35] iter = 06970, loss = 1.7715
2024-10-31 01:39:38: [2024-10-31 01:39:38] iter = 06980, loss = 2.5920
2024-10-31 01:39:42: [2024-10-31 01:39:42] iter = 06990, loss = 3.1613
2024-10-31 01:39:45: [2024-10-31 01:39:45] iter = 07000, loss = 1.7777
2024-10-31 01:39:49: [2024-10-31 01:39:49] iter = 07010, loss = 2.4021
2024-10-31 01:39:52: [2024-10-31 01:39:52] iter = 07020, loss = 2.5885
2024-10-31 01:39:55: [2024-10-31 01:39:55] iter = 07030, loss = 2.0858
2024-10-31 01:39:59: [2024-10-31 01:39:59] iter = 07040, loss = 2.5941
2024-10-31 01:40:02: [2024-10-31 01:40:02] iter = 07050, loss = 2.0358
2024-10-31 01:40:06: [2024-10-31 01:40:06] iter = 07060, loss = 1.9239
2024-10-31 01:40:09: [2024-10-31 01:40:09] iter = 07070, loss = 2.5058
2024-10-31 01:40:12: [2024-10-31 01:40:12] iter = 07080, loss = 1.8298
2024-10-31 01:40:15: [2024-10-31 01:40:15] iter = 07090, loss = 2.3615
2024-10-31 01:40:19: [2024-10-31 01:40:19] iter = 07100, loss = 3.5566
2024-10-31 01:40:22: [2024-10-31 01:40:22] iter = 07110, loss = 2.2856
2024-10-31 01:40:26: [2024-10-31 01:40:26] iter = 07120, loss = 3.1780
2024-10-31 01:40:29: [2024-10-31 01:40:29] iter = 07130, loss = 2.5334
2024-10-31 01:40:33: [2024-10-31 01:40:33] iter = 07140, loss = 1.9691
2024-10-31 01:40:37: [2024-10-31 01:40:37] iter = 07150, loss = 1.9773
2024-10-31 01:40:41: [2024-10-31 01:40:41] iter = 07160, loss = 4.6989
2024-10-31 01:40:44: [2024-10-31 01:40:44] iter = 07170, loss = 2.1318
2024-10-31 01:40:47: [2024-10-31 01:40:47] iter = 07180, loss = 2.1768
2024-10-31 01:40:50: [2024-10-31 01:40:50] iter = 07190, loss = 3.0104
2024-10-31 01:40:53: [2024-10-31 01:40:53] iter = 07200, loss = 1.9885
2024-10-31 01:40:55: [2024-10-31 01:40:55] iter = 07210, loss = 1.9215
2024-10-31 01:41:00: [2024-10-31 01:41:00] iter = 07220, loss = 2.4666
2024-10-31 01:41:02: [2024-10-31 01:41:02] iter = 07230, loss = 1.8942
2024-10-31 01:41:05: [2024-10-31 01:41:05] iter = 07240, loss = 1.7424
2024-10-31 01:41:09: [2024-10-31 01:41:09] iter = 07250, loss = 1.6660
2024-10-31 01:41:13: [2024-10-31 01:41:13] iter = 07260, loss = 4.3428
2024-10-31 01:41:17: [2024-10-31 01:41:17] iter = 07270, loss = 1.8359
2024-10-31 01:41:20: [2024-10-31 01:41:20] iter = 07280, loss = 1.9955
2024-10-31 01:41:23: [2024-10-31 01:41:23] iter = 07290, loss = 2.0845
2024-10-31 01:41:27: [2024-10-31 01:41:27] iter = 07300, loss = 1.9867
2024-10-31 01:41:30: [2024-10-31 01:41:30] iter = 07310, loss = 2.9428
2024-10-31 01:41:34: [2024-10-31 01:41:34] iter = 07320, loss = 1.8947
2024-10-31 01:41:37: [2024-10-31 01:41:37] iter = 07330, loss = 3.1377
2024-10-31 01:41:40: [2024-10-31 01:41:40] iter = 07340, loss = 1.9709
2024-10-31 01:41:44: [2024-10-31 01:41:44] iter = 07350, loss = 3.3463
2024-10-31 01:41:46: [2024-10-31 01:41:46] iter = 07360, loss = 2.7131
2024-10-31 01:41:50: [2024-10-31 01:41:50] iter = 07370, loss = 2.3617
2024-10-31 01:41:53: [2024-10-31 01:41:53] iter = 07380, loss = 2.0855
2024-10-31 01:41:55: [2024-10-31 01:41:55] iter = 07390, loss = 2.2176
2024-10-31 01:41:57: [2024-10-31 01:41:57] iter = 07400, loss = 2.3089
2024-10-31 01:42:00: [2024-10-31 01:42:00] iter = 07410, loss = 1.6816
2024-10-31 01:42:04: [2024-10-31 01:42:04] iter = 07420, loss = 2.2529
2024-10-31 01:42:06: [2024-10-31 01:42:06] iter = 07430, loss = 1.6381
2024-10-31 01:42:08: [2024-10-31 01:42:08] iter = 07440, loss = 1.6867
2024-10-31 01:42:12: [2024-10-31 01:42:12] iter = 07450, loss = 1.8511
2024-10-31 01:42:15: [2024-10-31 01:42:15] iter = 07460, loss = 3.0112
2024-10-31 01:42:19: [2024-10-31 01:42:19] iter = 07470, loss = 2.1918
2024-10-31 01:42:21: [2024-10-31 01:42:21] iter = 07480, loss = 2.4853
2024-10-31 01:42:25: [2024-10-31 01:42:25] iter = 07490, loss = 2.0663
2024-10-31 01:42:29: [2024-10-31 01:42:29] iter = 07500, loss = 3.5157
2024-10-31 01:42:32: [2024-10-31 01:42:32] iter = 07510, loss = 2.4168
2024-10-31 01:42:35: [2024-10-31 01:42:35] iter = 07520, loss = 2.1202
2024-10-31 01:42:38: [2024-10-31 01:42:38] iter = 07530, loss = 1.8827
2024-10-31 01:42:42: [2024-10-31 01:42:42] iter = 07540, loss = 1.9112
2024-10-31 01:42:45: [2024-10-31 01:42:45] iter = 07550, loss = 2.0816
2024-10-31 01:42:49: [2024-10-31 01:42:49] iter = 07560, loss = 1.9466
2024-10-31 01:42:52: [2024-10-31 01:42:52] iter = 07570, loss = 2.3726
2024-10-31 01:42:55: [2024-10-31 01:42:55] iter = 07580, loss = 2.2270
2024-10-31 01:42:59: [2024-10-31 01:42:59] iter = 07590, loss = 3.0707
2024-10-31 01:43:02: [2024-10-31 01:43:02] iter = 07600, loss = 2.5378
2024-10-31 01:43:05: [2024-10-31 01:43:05] iter = 07610, loss = 1.9824
2024-10-31 01:43:09: [2024-10-31 01:43:09] iter = 07620, loss = 1.6985
2024-10-31 01:43:11: [2024-10-31 01:43:11] iter = 07630, loss = 3.3188
2024-10-31 01:43:14: [2024-10-31 01:43:14] iter = 07640, loss = 2.3519
2024-10-31 01:43:18: [2024-10-31 01:43:18] iter = 07650, loss = 2.7580
2024-10-31 01:43:21: [2024-10-31 01:43:21] iter = 07660, loss = 1.7721
2024-10-31 01:43:24: [2024-10-31 01:43:24] iter = 07670, loss = 1.9030
2024-10-31 01:43:27: [2024-10-31 01:43:27] iter = 07680, loss = 3.0115
2024-10-31 01:43:30: [2024-10-31 01:43:30] iter = 07690, loss = 2.0305
2024-10-31 01:43:34: [2024-10-31 01:43:34] iter = 07700, loss = 3.2968
2024-10-31 01:43:37: [2024-10-31 01:43:37] iter = 07710, loss = 1.9597
2024-10-31 01:43:40: [2024-10-31 01:43:40] iter = 07720, loss = 2.7976
2024-10-31 01:43:44: [2024-10-31 01:43:44] iter = 07730, loss = 1.9654
2024-10-31 01:43:47: [2024-10-31 01:43:47] iter = 07740, loss = 1.8198
2024-10-31 01:43:50: [2024-10-31 01:43:50] iter = 07750, loss = 2.4368
2024-10-31 01:43:53: [2024-10-31 01:43:53] iter = 07760, loss = 1.9081
2024-10-31 01:43:55: [2024-10-31 01:43:55] iter = 07770, loss = 1.9545
2024-10-31 01:43:59: [2024-10-31 01:43:59] iter = 07780, loss = 1.7470
2024-10-31 01:44:01: [2024-10-31 01:44:01] iter = 07790, loss = 3.7292
2024-10-31 01:44:05: [2024-10-31 01:44:05] iter = 07800, loss = 2.2443
2024-10-31 01:44:07: [2024-10-31 01:44:07] iter = 07810, loss = 2.9966
2024-10-31 01:44:10: [2024-10-31 01:44:10] iter = 07820, loss = 3.2336
2024-10-31 01:44:13: [2024-10-31 01:44:13] iter = 07830, loss = 2.5763
2024-10-31 01:44:16: [2024-10-31 01:44:16] iter = 07840, loss = 2.3561
2024-10-31 01:44:19: [2024-10-31 01:44:19] iter = 07850, loss = 1.7092
2024-10-31 01:44:22: [2024-10-31 01:44:22] iter = 07860, loss = 3.9925
2024-10-31 01:44:26: [2024-10-31 01:44:26] iter = 07870, loss = 1.9463
2024-10-31 01:44:29: [2024-10-31 01:44:29] iter = 07880, loss = 2.3435
2024-10-31 01:44:32: [2024-10-31 01:44:32] iter = 07890, loss = 1.6461
2024-10-31 01:44:35: [2024-10-31 01:44:35] iter = 07900, loss = 2.0236
2024-10-31 01:44:38: [2024-10-31 01:44:38] iter = 07910, loss = 1.6790
2024-10-31 01:44:42: [2024-10-31 01:44:42] iter = 07920, loss = 1.6665
2024-10-31 01:44:46: [2024-10-31 01:44:46] iter = 07930, loss = 2.7578
2024-10-31 01:44:49: [2024-10-31 01:44:49] iter = 07940, loss = 2.3021
2024-10-31 01:44:53: [2024-10-31 01:44:53] iter = 07950, loss = 1.9664
2024-10-31 01:44:57: [2024-10-31 01:44:57] iter = 07960, loss = 1.8500
2024-10-31 01:45:00: [2024-10-31 01:45:00] iter = 07970, loss = 1.8304
2024-10-31 01:45:04: [2024-10-31 01:45:04] iter = 07980, loss = 2.7162
2024-10-31 01:45:08: [2024-10-31 01:45:08] iter = 07990, loss = 2.1931
2024-10-31 01:45:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-31 01:45:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:45:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 12082}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:47:10: Evaluate 5 random ConvNet, ACCmean = 0.7801 ACCstd = 0.0026
-------------------------
2024-10-31 01:47:10: Evaluate 5 random ConvNet, SENmean = 0.7706 SENstd = 0.0017
-------------------------
2024-10-31 01:47:10: Evaluate 5 random ConvNet, SPEmean = 0.9777 SPEstd = 0.0003
-------------------------
2024-10-31 01:47:10: Evaluate 5 random ConvNet, F!mean = 0.7663 F!std = 0.0022
-------------------------
2024-10-31 01:47:10: Evaluate 5 random ConvNet, mean = 0.7801 std = 0.0026
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:47:11: [2024-10-31 01:47:11] iter = 08000, loss = 2.2192
2024-10-31 01:47:14: [2024-10-31 01:47:14] iter = 08010, loss = 2.0832
2024-10-31 01:47:16: [2024-10-31 01:47:16] iter = 08020, loss = 2.0902
2024-10-31 01:47:19: [2024-10-31 01:47:19] iter = 08030, loss = 1.9882
2024-10-31 01:47:22: [2024-10-31 01:47:22] iter = 08040, loss = 2.1963
2024-10-31 01:47:25: [2024-10-31 01:47:25] iter = 08050, loss = 2.0688
2024-10-31 01:47:27: [2024-10-31 01:47:27] iter = 08060, loss = 3.2360
2024-10-31 01:47:30: [2024-10-31 01:47:30] iter = 08070, loss = 2.0185
2024-10-31 01:47:33: [2024-10-31 01:47:33] iter = 08080, loss = 2.2020
2024-10-31 01:47:36: [2024-10-31 01:47:36] iter = 08090, loss = 1.6466
2024-10-31 01:47:38: [2024-10-31 01:47:38] iter = 08100, loss = 2.0443
2024-10-31 01:47:41: [2024-10-31 01:47:41] iter = 08110, loss = 2.1127
2024-10-31 01:47:44: [2024-10-31 01:47:44] iter = 08120, loss = 1.9373
2024-10-31 01:47:47: [2024-10-31 01:47:47] iter = 08130, loss = 2.5436
2024-10-31 01:47:50: [2024-10-31 01:47:50] iter = 08140, loss = 2.2259
2024-10-31 01:47:53: [2024-10-31 01:47:53] iter = 08150, loss = 1.7586
2024-10-31 01:47:56: [2024-10-31 01:47:56] iter = 08160, loss = 2.5602
2024-10-31 01:47:59: [2024-10-31 01:47:59] iter = 08170, loss = 1.7649
2024-10-31 01:48:02: [2024-10-31 01:48:02] iter = 08180, loss = 2.0202
2024-10-31 01:48:04: [2024-10-31 01:48:04] iter = 08190, loss = 1.8476
2024-10-31 01:48:07: [2024-10-31 01:48:07] iter = 08200, loss = 1.7129
2024-10-31 01:48:09: [2024-10-31 01:48:09] iter = 08210, loss = 2.1944
2024-10-31 01:48:12: [2024-10-31 01:48:12] iter = 08220, loss = 2.1722
2024-10-31 01:48:16: [2024-10-31 01:48:16] iter = 08230, loss = 1.9683
2024-10-31 01:48:19: [2024-10-31 01:48:19] iter = 08240, loss = 1.8487
2024-10-31 01:48:23: [2024-10-31 01:48:23] iter = 08250, loss = 1.8606
2024-10-31 01:48:26: [2024-10-31 01:48:26] iter = 08260, loss = 1.8412
2024-10-31 01:48:28: [2024-10-31 01:48:28] iter = 08270, loss = 2.4518
2024-10-31 01:48:31: [2024-10-31 01:48:31] iter = 08280, loss = 2.1541
2024-10-31 01:48:34: [2024-10-31 01:48:34] iter = 08290, loss = 2.5844
2024-10-31 01:48:37: [2024-10-31 01:48:37] iter = 08300, loss = 2.4536
2024-10-31 01:48:39: [2024-10-31 01:48:39] iter = 08310, loss = 1.9160
2024-10-31 01:48:42: [2024-10-31 01:48:42] iter = 08320, loss = 1.6773
2024-10-31 01:48:45: [2024-10-31 01:48:45] iter = 08330, loss = 1.7967
2024-10-31 01:48:48: [2024-10-31 01:48:48] iter = 08340, loss = 1.8339
2024-10-31 01:48:50: [2024-10-31 01:48:50] iter = 08350, loss = 2.2310
2024-10-31 01:48:53: [2024-10-31 01:48:53] iter = 08360, loss = 1.9355
2024-10-31 01:48:56: [2024-10-31 01:48:56] iter = 08370, loss = 1.9180
2024-10-31 01:49:00: [2024-10-31 01:49:00] iter = 08380, loss = 1.6595
2024-10-31 01:49:02: [2024-10-31 01:49:02] iter = 08390, loss = 1.7724
2024-10-31 01:49:06: [2024-10-31 01:49:06] iter = 08400, loss = 2.6091
2024-10-31 01:49:09: [2024-10-31 01:49:09] iter = 08410, loss = 2.2681
2024-10-31 01:49:12: [2024-10-31 01:49:12] iter = 08420, loss = 1.7817
2024-10-31 01:49:15: [2024-10-31 01:49:15] iter = 08430, loss = 1.9011
2024-10-31 01:49:18: [2024-10-31 01:49:18] iter = 08440, loss = 3.5053
2024-10-31 01:49:22: [2024-10-31 01:49:22] iter = 08450, loss = 1.8143
2024-10-31 01:49:25: [2024-10-31 01:49:25] iter = 08460, loss = 1.8912
2024-10-31 01:49:28: [2024-10-31 01:49:28] iter = 08470, loss = 1.9212
2024-10-31 01:49:31: [2024-10-31 01:49:31] iter = 08480, loss = 2.4317
2024-10-31 01:49:34: [2024-10-31 01:49:34] iter = 08490, loss = 1.9765
2024-10-31 01:49:36: [2024-10-31 01:49:36] iter = 08500, loss = 2.3556
2024-10-31 01:49:39: [2024-10-31 01:49:39] iter = 08510, loss = 2.4011
2024-10-31 01:49:42: [2024-10-31 01:49:42] iter = 08520, loss = 1.9733
2024-10-31 01:49:45: [2024-10-31 01:49:45] iter = 08530, loss = 1.5748
2024-10-31 01:49:47: [2024-10-31 01:49:47] iter = 08540, loss = 3.6449
2024-10-31 01:49:51: [2024-10-31 01:49:51] iter = 08550, loss = 2.0586
2024-10-31 01:49:55: [2024-10-31 01:49:55] iter = 08560, loss = 1.9277
2024-10-31 01:49:59: [2024-10-31 01:49:59] iter = 08570, loss = 1.8038
2024-10-31 01:50:01: [2024-10-31 01:50:01] iter = 08580, loss = 4.7953
2024-10-31 01:50:05: [2024-10-31 01:50:05] iter = 08590, loss = 3.2562
2024-10-31 01:50:08: [2024-10-31 01:50:08] iter = 08600, loss = 4.6846
2024-10-31 01:50:11: [2024-10-31 01:50:11] iter = 08610, loss = 2.3478
2024-10-31 01:50:14: [2024-10-31 01:50:14] iter = 08620, loss = 2.0227
2024-10-31 01:50:17: [2024-10-31 01:50:17] iter = 08630, loss = 1.7952
2024-10-31 01:50:21: [2024-10-31 01:50:21] iter = 08640, loss = 2.8360
2024-10-31 01:50:24: [2024-10-31 01:50:24] iter = 08650, loss = 2.1438
2024-10-31 01:50:27: [2024-10-31 01:50:27] iter = 08660, loss = 2.2852
2024-10-31 01:50:29: [2024-10-31 01:50:29] iter = 08670, loss = 3.1104
2024-10-31 01:50:33: [2024-10-31 01:50:33] iter = 08680, loss = 1.8357
2024-10-31 01:50:35: [2024-10-31 01:50:35] iter = 08690, loss = 2.5054
2024-10-31 01:50:38: [2024-10-31 01:50:38] iter = 08700, loss = 2.8843
2024-10-31 01:50:41: [2024-10-31 01:50:41] iter = 08710, loss = 2.5777
2024-10-31 01:50:44: [2024-10-31 01:50:44] iter = 08720, loss = 2.1649
2024-10-31 01:50:48: [2024-10-31 01:50:48] iter = 08730, loss = 2.4213
2024-10-31 01:50:50: [2024-10-31 01:50:50] iter = 08740, loss = 3.2185
2024-10-31 01:50:54: [2024-10-31 01:50:54] iter = 08750, loss = 2.0846
2024-10-31 01:50:57: [2024-10-31 01:50:57] iter = 08760, loss = 1.5662
2024-10-31 01:51:01: [2024-10-31 01:51:01] iter = 08770, loss = 2.1390
2024-10-31 01:51:04: [2024-10-31 01:51:04] iter = 08780, loss = 1.8023
2024-10-31 01:51:07: [2024-10-31 01:51:07] iter = 08790, loss = 3.1338
2024-10-31 01:51:10: [2024-10-31 01:51:10] iter = 08800, loss = 1.9023
2024-10-31 01:51:14: [2024-10-31 01:51:14] iter = 08810, loss = 2.3555
2024-10-31 01:51:17: [2024-10-31 01:51:17] iter = 08820, loss = 2.9056
2024-10-31 01:51:20: [2024-10-31 01:51:20] iter = 08830, loss = 2.0426
2024-10-31 01:51:24: [2024-10-31 01:51:24] iter = 08840, loss = 1.9750
2024-10-31 01:51:27: [2024-10-31 01:51:27] iter = 08850, loss = 3.1101
2024-10-31 01:51:31: [2024-10-31 01:51:31] iter = 08860, loss = 2.3623
2024-10-31 01:51:35: [2024-10-31 01:51:35] iter = 08870, loss = 2.0306
2024-10-31 01:51:38: [2024-10-31 01:51:38] iter = 08880, loss = 2.1791
2024-10-31 01:51:42: [2024-10-31 01:51:42] iter = 08890, loss = 2.7437
2024-10-31 01:51:45: [2024-10-31 01:51:45] iter = 08900, loss = 2.1101
2024-10-31 01:51:49: [2024-10-31 01:51:49] iter = 08910, loss = 1.6390
2024-10-31 01:51:53: [2024-10-31 01:51:53] iter = 08920, loss = 1.7094
2024-10-31 01:51:56: [2024-10-31 01:51:56] iter = 08930, loss = 1.7335
2024-10-31 01:51:59: [2024-10-31 01:51:59] iter = 08940, loss = 2.2905
2024-10-31 01:52:03: [2024-10-31 01:52:03] iter = 08950, loss = 1.7696
2024-10-31 01:52:06: [2024-10-31 01:52:06] iter = 08960, loss = 2.7689
2024-10-31 01:52:08: [2024-10-31 01:52:08] iter = 08970, loss = 3.5569
2024-10-31 01:52:13: [2024-10-31 01:52:13] iter = 08980, loss = 4.0198
2024-10-31 01:52:16: [2024-10-31 01:52:16] iter = 08990, loss = 1.8177
2024-10-31 01:52:19: [2024-10-31 01:52:19] iter = 09000, loss = 2.4238
2024-10-31 01:52:23: [2024-10-31 01:52:23] iter = 09010, loss = 2.4637
2024-10-31 01:52:26: [2024-10-31 01:52:26] iter = 09020, loss = 2.0303
2024-10-31 01:52:29: [2024-10-31 01:52:29] iter = 09030, loss = 1.9509
2024-10-31 01:52:32: [2024-10-31 01:52:32] iter = 09040, loss = 2.3907
2024-10-31 01:52:36: [2024-10-31 01:52:36] iter = 09050, loss = 2.6424
2024-10-31 01:52:40: [2024-10-31 01:52:40] iter = 09060, loss = 2.2940
2024-10-31 01:52:43: [2024-10-31 01:52:43] iter = 09070, loss = 1.7135
2024-10-31 01:52:47: [2024-10-31 01:52:47] iter = 09080, loss = 1.6810
2024-10-31 01:52:50: [2024-10-31 01:52:50] iter = 09090, loss = 3.6406
2024-10-31 01:52:53: [2024-10-31 01:52:53] iter = 09100, loss = 1.6922
2024-10-31 01:52:56: [2024-10-31 01:52:56] iter = 09110, loss = 1.9090
2024-10-31 01:53:00: [2024-10-31 01:53:00] iter = 09120, loss = 2.7046
2024-10-31 01:53:04: [2024-10-31 01:53:04] iter = 09130, loss = 1.9121
2024-10-31 01:53:07: [2024-10-31 01:53:07] iter = 09140, loss = 3.0320
2024-10-31 01:53:10: [2024-10-31 01:53:10] iter = 09150, loss = 1.7919
2024-10-31 01:53:13: [2024-10-31 01:53:13] iter = 09160, loss = 2.0683
2024-10-31 01:53:16: [2024-10-31 01:53:16] iter = 09170, loss = 2.1158
2024-10-31 01:53:20: [2024-10-31 01:53:20] iter = 09180, loss = 2.2980
2024-10-31 01:53:23: [2024-10-31 01:53:23] iter = 09190, loss = 1.9184
2024-10-31 01:53:26: [2024-10-31 01:53:26] iter = 09200, loss = 1.8194
2024-10-31 01:53:30: [2024-10-31 01:53:30] iter = 09210, loss = 1.8622
2024-10-31 01:53:32: [2024-10-31 01:53:32] iter = 09220, loss = 2.3379
2024-10-31 01:53:36: [2024-10-31 01:53:36] iter = 09230, loss = 1.8461
2024-10-31 01:53:39: [2024-10-31 01:53:39] iter = 09240, loss = 2.0498
2024-10-31 01:53:41: [2024-10-31 01:53:41] iter = 09250, loss = 2.3193
2024-10-31 01:53:44: [2024-10-31 01:53:44] iter = 09260, loss = 3.0253
2024-10-31 01:53:46: [2024-10-31 01:53:46] iter = 09270, loss = 1.7477
2024-10-31 01:53:49: [2024-10-31 01:53:49] iter = 09280, loss = 1.9628
2024-10-31 01:53:52: [2024-10-31 01:53:52] iter = 09290, loss = 1.9974
2024-10-31 01:53:56: [2024-10-31 01:53:56] iter = 09300, loss = 1.9744
2024-10-31 01:53:59: [2024-10-31 01:53:59] iter = 09310, loss = 1.9916
2024-10-31 01:54:03: [2024-10-31 01:54:03] iter = 09320, loss = 1.7465
2024-10-31 01:54:06: [2024-10-31 01:54:06] iter = 09330, loss = 2.0478
2024-10-31 01:54:11: [2024-10-31 01:54:11] iter = 09340, loss = 2.2004
2024-10-31 01:54:14: [2024-10-31 01:54:14] iter = 09350, loss = 2.6765
2024-10-31 01:54:17: [2024-10-31 01:54:17] iter = 09360, loss = 1.5397
2024-10-31 01:54:21: [2024-10-31 01:54:21] iter = 09370, loss = 1.9631
2024-10-31 01:54:24: [2024-10-31 01:54:24] iter = 09380, loss = 2.1223
2024-10-31 01:54:28: [2024-10-31 01:54:28] iter = 09390, loss = 1.8343
2024-10-31 01:54:32: [2024-10-31 01:54:32] iter = 09400, loss = 3.0787
2024-10-31 01:54:35: [2024-10-31 01:54:35] iter = 09410, loss = 1.6950
2024-10-31 01:54:39: [2024-10-31 01:54:39] iter = 09420, loss = 2.9040
2024-10-31 01:54:42: [2024-10-31 01:54:42] iter = 09430, loss = 2.9391
2024-10-31 01:54:46: [2024-10-31 01:54:46] iter = 09440, loss = 2.0192
2024-10-31 01:54:49: [2024-10-31 01:54:49] iter = 09450, loss = 2.2712
2024-10-31 01:54:53: [2024-10-31 01:54:53] iter = 09460, loss = 2.6888
2024-10-31 01:54:57: [2024-10-31 01:54:57] iter = 09470, loss = 2.3010
2024-10-31 01:55:00: [2024-10-31 01:55:00] iter = 09480, loss = 2.9689
2024-10-31 01:55:03: [2024-10-31 01:55:03] iter = 09490, loss = 3.3754
2024-10-31 01:55:06: [2024-10-31 01:55:06] iter = 09500, loss = 2.1316
2024-10-31 01:55:09: [2024-10-31 01:55:09] iter = 09510, loss = 2.0751
2024-10-31 01:55:12: [2024-10-31 01:55:12] iter = 09520, loss = 1.9052
2024-10-31 01:55:15: [2024-10-31 01:55:15] iter = 09530, loss = 1.5359
2024-10-31 01:55:18: [2024-10-31 01:55:18] iter = 09540, loss = 2.3001
2024-10-31 01:55:21: [2024-10-31 01:55:21] iter = 09550, loss = 6.0527
2024-10-31 01:55:25: [2024-10-31 01:55:25] iter = 09560, loss = 1.8989
2024-10-31 01:55:29: [2024-10-31 01:55:29] iter = 09570, loss = 1.7632
2024-10-31 01:55:32: [2024-10-31 01:55:32] iter = 09580, loss = 1.8803
2024-10-31 01:55:36: [2024-10-31 01:55:36] iter = 09590, loss = 1.5969
2024-10-31 01:55:40: [2024-10-31 01:55:40] iter = 09600, loss = 4.2076
2024-10-31 01:55:44: [2024-10-31 01:55:44] iter = 09610, loss = 1.8436
2024-10-31 01:55:48: [2024-10-31 01:55:48] iter = 09620, loss = 2.2173
2024-10-31 01:55:51: [2024-10-31 01:55:51] iter = 09630, loss = 2.1335
2024-10-31 01:55:55: [2024-10-31 01:55:55] iter = 09640, loss = 2.0797
2024-10-31 01:56:00: [2024-10-31 01:56:00] iter = 09650, loss = 1.8431
2024-10-31 01:56:03: [2024-10-31 01:56:03] iter = 09660, loss = 1.6213
2024-10-31 01:56:06: [2024-10-31 01:56:06] iter = 09670, loss = 1.8675
2024-10-31 01:56:09: [2024-10-31 01:56:09] iter = 09680, loss = 1.9379
2024-10-31 01:56:13: [2024-10-31 01:56:13] iter = 09690, loss = 1.7850
2024-10-31 01:56:17: [2024-10-31 01:56:17] iter = 09700, loss = 3.8587
2024-10-31 01:56:20: [2024-10-31 01:56:20] iter = 09710, loss = 4.2915
2024-10-31 01:56:24: [2024-10-31 01:56:24] iter = 09720, loss = 1.9627
2024-10-31 01:56:27: [2024-10-31 01:56:27] iter = 09730, loss = 2.4158
2024-10-31 01:56:31: [2024-10-31 01:56:31] iter = 09740, loss = 1.8684
2024-10-31 01:56:33: [2024-10-31 01:56:33] iter = 09750, loss = 2.1673
2024-10-31 01:56:37: [2024-10-31 01:56:37] iter = 09760, loss = 2.1320
2024-10-31 01:56:40: [2024-10-31 01:56:40] iter = 09770, loss = 1.8678
2024-10-31 01:56:43: [2024-10-31 01:56:43] iter = 09780, loss = 2.6576
2024-10-31 01:56:45: [2024-10-31 01:56:45] iter = 09790, loss = 1.9653
2024-10-31 01:56:47: [2024-10-31 01:56:47] iter = 09800, loss = 1.6854
2024-10-31 01:56:50: [2024-10-31 01:56:50] iter = 09810, loss = 1.7996
2024-10-31 01:56:53: [2024-10-31 01:56:53] iter = 09820, loss = 1.9077
2024-10-31 01:56:56: [2024-10-31 01:56:56] iter = 09830, loss = 1.8323
2024-10-31 01:56:59: [2024-10-31 01:56:59] iter = 09840, loss = 1.9682
2024-10-31 01:57:03: [2024-10-31 01:57:03] iter = 09850, loss = 1.7623
2024-10-31 01:57:06: [2024-10-31 01:57:06] iter = 09860, loss = 3.9997
2024-10-31 01:57:09: [2024-10-31 01:57:09] iter = 09870, loss = 1.9904
2024-10-31 01:57:12: [2024-10-31 01:57:12] iter = 09880, loss = 2.9991
2024-10-31 01:57:15: [2024-10-31 01:57:15] iter = 09890, loss = 1.7686
2024-10-31 01:57:19: [2024-10-31 01:57:19] iter = 09900, loss = 1.7547
2024-10-31 01:57:22: [2024-10-31 01:57:22] iter = 09910, loss = 3.8829
2024-10-31 01:57:26: [2024-10-31 01:57:26] iter = 09920, loss = 1.9165
2024-10-31 01:57:29: [2024-10-31 01:57:29] iter = 09930, loss = 2.5755
2024-10-31 01:57:32: [2024-10-31 01:57:31] iter = 09940, loss = 2.1687
2024-10-31 01:57:35: [2024-10-31 01:57:35] iter = 09950, loss = 2.2277
2024-10-31 01:57:38: [2024-10-31 01:57:38] iter = 09960, loss = 1.7199
2024-10-31 01:57:42: [2024-10-31 01:57:42] iter = 09970, loss = 1.7544
2024-10-31 01:57:44: [2024-10-31 01:57:44] iter = 09980, loss = 1.7927
2024-10-31 01:57:48: [2024-10-31 01:57:48] iter = 09990, loss = 1.7616
2024-10-31 01:57:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-31 01:57:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:57:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 70875}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:59:51: Evaluate 5 random ConvNet, ACCmean = 0.7763 ACCstd = 0.0038
-------------------------
2024-10-31 01:59:51: Evaluate 5 random ConvNet, SENmean = 0.7677 SENstd = 0.0039
-------------------------
2024-10-31 01:59:51: Evaluate 5 random ConvNet, SPEmean = 0.9773 SPEstd = 0.0004
-------------------------
2024-10-31 01:59:51: Evaluate 5 random ConvNet, F!mean = 0.7623 F!std = 0.0044
-------------------------
2024-10-31 01:59:51: Evaluate 5 random ConvNet, mean = 0.7763 std = 0.0038
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:59:52: [2024-10-31 01:59:52] iter = 10000, loss = 2.4762
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:59:54: [2024-10-31 01:59:54] iter = 10010, loss = 2.2775
2024-10-31 01:59:57: [2024-10-31 01:59:57] iter = 10020, loss = 1.6600
2024-10-31 02:00:00: [2024-10-31 02:00:00] iter = 10030, loss = 2.1731
2024-10-31 02:00:03: [2024-10-31 02:00:03] iter = 10040, loss = 2.2032
2024-10-31 02:00:06: [2024-10-31 02:00:06] iter = 10050, loss = 3.6612
2024-10-31 02:00:09: [2024-10-31 02:00:09] iter = 10060, loss = 2.7904
2024-10-31 02:00:11: [2024-10-31 02:00:11] iter = 10070, loss = 2.9530
2024-10-31 02:00:15: [2024-10-31 02:00:15] iter = 10080, loss = 2.0680
2024-10-31 02:00:19: [2024-10-31 02:00:19] iter = 10090, loss = 1.9240
2024-10-31 02:00:23: [2024-10-31 02:00:23] iter = 10100, loss = 1.7592
2024-10-31 02:00:26: [2024-10-31 02:00:26] iter = 10110, loss = 1.7811
2024-10-31 02:00:30: [2024-10-31 02:00:30] iter = 10120, loss = 1.9348
2024-10-31 02:00:34: [2024-10-31 02:00:34] iter = 10130, loss = 1.9739
2024-10-31 02:00:37: [2024-10-31 02:00:37] iter = 10140, loss = 1.7513
2024-10-31 02:00:41: [2024-10-31 02:00:41] iter = 10150, loss = 1.7403
2024-10-31 02:00:43: [2024-10-31 02:00:43] iter = 10160, loss = 2.2736
2024-10-31 02:00:46: [2024-10-31 02:00:46] iter = 10170, loss = 3.1332
2024-10-31 02:00:49: [2024-10-31 02:00:49] iter = 10180, loss = 2.2757
2024-10-31 02:00:53: [2024-10-31 02:00:53] iter = 10190, loss = 1.9605
2024-10-31 02:00:57: [2024-10-31 02:00:57] iter = 10200, loss = 2.3226
2024-10-31 02:00:59: [2024-10-31 02:00:59] iter = 10210, loss = 1.8534
2024-10-31 02:01:02: [2024-10-31 02:01:02] iter = 10220, loss = 1.7925
2024-10-31 02:01:05: [2024-10-31 02:01:05] iter = 10230, loss = 3.4281
2024-10-31 02:01:09: [2024-10-31 02:01:09] iter = 10240, loss = 1.9744
2024-10-31 02:01:12: [2024-10-31 02:01:12] iter = 10250, loss = 2.4545
2024-10-31 02:01:15: [2024-10-31 02:01:15] iter = 10260, loss = 1.8535
2024-10-31 02:01:18: [2024-10-31 02:01:18] iter = 10270, loss = 1.9363
2024-10-31 02:01:21: [2024-10-31 02:01:21] iter = 10280, loss = 1.6874
2024-10-31 02:01:24: [2024-10-31 02:01:24] iter = 10290, loss = 2.1867
2024-10-31 02:01:27: [2024-10-31 02:01:27] iter = 10300, loss = 3.1581
2024-10-31 02:01:30: [2024-10-31 02:01:30] iter = 10310, loss = 1.9219
2024-10-31 02:01:33: [2024-10-31 02:01:33] iter = 10320, loss = 2.7127
2024-10-31 02:01:37: [2024-10-31 02:01:37] iter = 10330, loss = 2.1060
2024-10-31 02:01:40: [2024-10-31 02:01:40] iter = 10340, loss = 2.4061
2024-10-31 02:01:44: [2024-10-31 02:01:44] iter = 10350, loss = 1.6191
2024-10-31 02:01:47: [2024-10-31 02:01:47] iter = 10360, loss = 1.8600
2024-10-31 02:01:51: [2024-10-31 02:01:51] iter = 10370, loss = 2.1646
2024-10-31 02:01:54: [2024-10-31 02:01:54] iter = 10380, loss = 2.3249
2024-10-31 02:01:57: [2024-10-31 02:01:57] iter = 10390, loss = 2.4645
2024-10-31 02:02:00: [2024-10-31 02:02:00] iter = 10400, loss = 1.7877
2024-10-31 02:02:03: [2024-10-31 02:02:03] iter = 10410, loss = 1.7526
2024-10-31 02:02:05: [2024-10-31 02:02:05] iter = 10420, loss = 2.1464
2024-10-31 02:02:08: [2024-10-31 02:02:08] iter = 10430, loss = 1.9757
2024-10-31 02:02:12: [2024-10-31 02:02:12] iter = 10440, loss = 3.1682
2024-10-31 02:02:15: [2024-10-31 02:02:15] iter = 10450, loss = 1.8974
2024-10-31 02:02:19: [2024-10-31 02:02:19] iter = 10460, loss = 2.3308
2024-10-31 02:02:22: [2024-10-31 02:02:22] iter = 10470, loss = 1.7965
2024-10-31 02:02:26: [2024-10-31 02:02:26] iter = 10480, loss = 2.3448
2024-10-31 02:02:28: [2024-10-31 02:02:28] iter = 10490, loss = 2.1417
2024-10-31 02:02:32: [2024-10-31 02:02:32] iter = 10500, loss = 1.7155
2024-10-31 02:02:36: [2024-10-31 02:02:36] iter = 10510, loss = 1.8230
2024-10-31 02:02:39: [2024-10-31 02:02:39] iter = 10520, loss = 2.4489
2024-10-31 02:02:43: [2024-10-31 02:02:43] iter = 10530, loss = 7.9669
2024-10-31 02:02:46: [2024-10-31 02:02:46] iter = 10540, loss = 1.9349
2024-10-31 02:02:49: [2024-10-31 02:02:49] iter = 10550, loss = 2.2261
2024-10-31 02:02:52: [2024-10-31 02:02:52] iter = 10560, loss = 1.7692
2024-10-31 02:02:55: [2024-10-31 02:02:55] iter = 10570, loss = 2.0064
2024-10-31 02:02:58: [2024-10-31 02:02:58] iter = 10580, loss = 1.9505
2024-10-31 02:03:02: [2024-10-31 02:03:02] iter = 10590, loss = 1.6629
2024-10-31 02:03:06: [2024-10-31 02:03:06] iter = 10600, loss = 1.7825
2024-10-31 02:03:09: [2024-10-31 02:03:09] iter = 10610, loss = 2.5564
2024-10-31 02:03:12: [2024-10-31 02:03:12] iter = 10620, loss = 3.5209
2024-10-31 02:03:15: [2024-10-31 02:03:15] iter = 10630, loss = 2.3897
2024-10-31 02:03:19: [2024-10-31 02:03:19] iter = 10640, loss = 2.6429
2024-10-31 02:03:22: [2024-10-31 02:03:22] iter = 10650, loss = 1.7939
2024-10-31 02:03:25: [2024-10-31 02:03:25] iter = 10660, loss = 1.8132
2024-10-31 02:03:29: [2024-10-31 02:03:29] iter = 10670, loss = 1.5780
2024-10-31 02:03:33: [2024-10-31 02:03:33] iter = 10680, loss = 1.6416
2024-10-31 02:03:37: [2024-10-31 02:03:37] iter = 10690, loss = 1.8183
2024-10-31 02:03:40: [2024-10-31 02:03:40] iter = 10700, loss = 1.8238
2024-10-31 02:03:44: [2024-10-31 02:03:44] iter = 10710, loss = 2.8790
2024-10-31 02:03:48: [2024-10-31 02:03:48] iter = 10720, loss = 2.9375
2024-10-31 02:03:52: [2024-10-31 02:03:52] iter = 10730, loss = 2.2504
2024-10-31 02:03:55: [2024-10-31 02:03:55] iter = 10740, loss = 1.8711
2024-10-31 02:03:58: [2024-10-31 02:03:58] iter = 10750, loss = 2.0888
2024-10-31 02:04:01: [2024-10-31 02:04:01] iter = 10760, loss = 1.7385
2024-10-31 02:04:05: [2024-10-31 02:04:05] iter = 10770, loss = 1.8801
2024-10-31 02:04:08: [2024-10-31 02:04:08] iter = 10780, loss = 1.8482
2024-10-31 02:04:12: [2024-10-31 02:04:12] iter = 10790, loss = 2.3078
2024-10-31 02:04:15: [2024-10-31 02:04:15] iter = 10800, loss = 1.9239
2024-10-31 02:04:18: [2024-10-31 02:04:18] iter = 10810, loss = 3.0155
2024-10-31 02:04:21: [2024-10-31 02:04:21] iter = 10820, loss = 2.6983
2024-10-31 02:04:24: [2024-10-31 02:04:24] iter = 10830, loss = 2.1922
2024-10-31 02:04:27: [2024-10-31 02:04:27] iter = 10840, loss = 2.1726
2024-10-31 02:04:31: [2024-10-31 02:04:31] iter = 10850, loss = 1.9476
2024-10-31 02:04:35: [2024-10-31 02:04:35] iter = 10860, loss = 2.9682
2024-10-31 02:04:37: [2024-10-31 02:04:37] iter = 10870, loss = 2.6002
2024-10-31 02:04:41: [2024-10-31 02:04:41] iter = 10880, loss = 2.2718
2024-10-31 02:04:44: [2024-10-31 02:04:44] iter = 10890, loss = 1.7060
2024-10-31 02:04:47: [2024-10-31 02:04:47] iter = 10900, loss = 1.7912
2024-10-31 02:04:50: [2024-10-31 02:04:50] iter = 10910, loss = 2.2205
2024-10-31 02:04:53: [2024-10-31 02:04:53] iter = 10920, loss = 1.7825
2024-10-31 02:04:56: [2024-10-31 02:04:56] iter = 10930, loss = 1.9000
2024-10-31 02:04:59: [2024-10-31 02:04:59] iter = 10940, loss = 2.8212
2024-10-31 02:05:01: [2024-10-31 02:05:01] iter = 10950, loss = 3.1596
2024-10-31 02:05:05: [2024-10-31 02:05:05] iter = 10960, loss = 2.0028
2024-10-31 02:05:09: [2024-10-31 02:05:09] iter = 10970, loss = 2.2694
2024-10-31 02:05:13: [2024-10-31 02:05:13] iter = 10980, loss = 2.8878
2024-10-31 02:05:16: [2024-10-31 02:05:16] iter = 10990, loss = 1.8519
2024-10-31 02:05:20: [2024-10-31 02:05:20] iter = 11000, loss = 1.5345
2024-10-31 02:05:23: [2024-10-31 02:05:23] iter = 11010, loss = 1.7361
2024-10-31 02:05:25: [2024-10-31 02:05:25] iter = 11020, loss = 2.0958
2024-10-31 02:05:28: [2024-10-31 02:05:28] iter = 11030, loss = 2.3143
2024-10-31 02:05:31: [2024-10-31 02:05:31] iter = 11040, loss = 6.4418
2024-10-31 02:05:33: [2024-10-31 02:05:33] iter = 11050, loss = 2.1683
2024-10-31 02:05:37: [2024-10-31 02:05:37] iter = 11060, loss = 1.8720
2024-10-31 02:05:41: [2024-10-31 02:05:41] iter = 11070, loss = 2.0539
2024-10-31 02:05:44: [2024-10-31 02:05:44] iter = 11080, loss = 1.9322
2024-10-31 02:05:47: [2024-10-31 02:05:47] iter = 11090, loss = 1.8637
2024-10-31 02:05:50: [2024-10-31 02:05:50] iter = 11100, loss = 2.2066
2024-10-31 02:05:54: [2024-10-31 02:05:54] iter = 11110, loss = 2.8257
2024-10-31 02:05:57: [2024-10-31 02:05:57] iter = 11120, loss = 2.2304
2024-10-31 02:06:01: [2024-10-31 02:06:01] iter = 11130, loss = 2.1116
2024-10-31 02:06:04: [2024-10-31 02:06:04] iter = 11140, loss = 2.7692
2024-10-31 02:06:07: [2024-10-31 02:06:07] iter = 11150, loss = 1.8275
2024-10-31 02:06:10: [2024-10-31 02:06:10] iter = 11160, loss = 2.1210
2024-10-31 02:06:13: [2024-10-31 02:06:13] iter = 11170, loss = 2.3548
2024-10-31 02:06:16: [2024-10-31 02:06:16] iter = 11180, loss = 2.7913
2024-10-31 02:06:19: [2024-10-31 02:06:19] iter = 11190, loss = 2.4655
2024-10-31 02:06:23: [2024-10-31 02:06:23] iter = 11200, loss = 1.9446
2024-10-31 02:06:26: [2024-10-31 02:06:26] iter = 11210, loss = 2.8890
2024-10-31 02:06:30: [2024-10-31 02:06:30] iter = 11220, loss = 1.7299
2024-10-31 02:06:33: [2024-10-31 02:06:33] iter = 11230, loss = 1.9270
2024-10-31 02:06:35: [2024-10-31 02:06:35] iter = 11240, loss = 1.8211
2024-10-31 02:06:38: [2024-10-31 02:06:38] iter = 11250, loss = 1.7134
2024-10-31 02:06:40: [2024-10-31 02:06:40] iter = 11260, loss = 1.6688
2024-10-31 02:06:44: [2024-10-31 02:06:44] iter = 11270, loss = 1.9944
2024-10-31 02:06:48: [2024-10-31 02:06:48] iter = 11280, loss = 7.1856
2024-10-31 02:06:51: [2024-10-31 02:06:51] iter = 11290, loss = 2.3852
2024-10-31 02:06:54: [2024-10-31 02:06:54] iter = 11300, loss = 2.3089
2024-10-31 02:06:57: [2024-10-31 02:06:57] iter = 11310, loss = 1.7912
2024-10-31 02:07:00: [2024-10-31 02:07:00] iter = 11320, loss = 2.5080
2024-10-31 02:07:04: [2024-10-31 02:07:04] iter = 11330, loss = 2.1183
2024-10-31 02:07:07: [2024-10-31 02:07:07] iter = 11340, loss = 1.6551
2024-10-31 02:07:10: [2024-10-31 02:07:10] iter = 11350, loss = 2.0522
2024-10-31 02:07:13: [2024-10-31 02:07:13] iter = 11360, loss = 2.1556
2024-10-31 02:07:17: [2024-10-31 02:07:17] iter = 11370, loss = 1.7489
2024-10-31 02:07:20: [2024-10-31 02:07:20] iter = 11380, loss = 2.1190
2024-10-31 02:07:25: [2024-10-31 02:07:25] iter = 11390, loss = 1.9796
2024-10-31 02:07:29: [2024-10-31 02:07:29] iter = 11400, loss = 2.0208
2024-10-31 02:07:32: [2024-10-31 02:07:32] iter = 11410, loss = 2.0224
2024-10-31 02:07:36: [2024-10-31 02:07:36] iter = 11420, loss = 1.9666
2024-10-31 02:07:39: [2024-10-31 02:07:39] iter = 11430, loss = 1.8647
2024-10-31 02:07:42: [2024-10-31 02:07:42] iter = 11440, loss = 1.5746
2024-10-31 02:07:46: [2024-10-31 02:07:46] iter = 11450, loss = 1.8553
2024-10-31 02:07:49: [2024-10-31 02:07:49] iter = 11460, loss = 4.6373
2024-10-31 02:07:52: [2024-10-31 02:07:52] iter = 11470, loss = 2.1673
2024-10-31 02:07:56: [2024-10-31 02:07:56] iter = 11480, loss = 2.1777
2024-10-31 02:07:59: [2024-10-31 02:07:59] iter = 11490, loss = 1.7885
2024-10-31 02:08:03: [2024-10-31 02:08:03] iter = 11500, loss = 3.7714
2024-10-31 02:08:06: [2024-10-31 02:08:06] iter = 11510, loss = 3.5454
2024-10-31 02:08:10: [2024-10-31 02:08:10] iter = 11520, loss = 1.7753
2024-10-31 02:08:13: [2024-10-31 02:08:13] iter = 11530, loss = 2.0538
2024-10-31 02:08:17: [2024-10-31 02:08:17] iter = 11540, loss = 1.8635
2024-10-31 02:08:20: [2024-10-31 02:08:20] iter = 11550, loss = 1.8258
2024-10-31 02:08:23: [2024-10-31 02:08:23] iter = 11560, loss = 1.7895
2024-10-31 02:08:27: [2024-10-31 02:08:27] iter = 11570, loss = 2.5939
2024-10-31 02:08:30: [2024-10-31 02:08:30] iter = 11580, loss = 1.8286
2024-10-31 02:08:33: [2024-10-31 02:08:33] iter = 11590, loss = 1.6023
2024-10-31 02:08:37: [2024-10-31 02:08:37] iter = 11600, loss = 2.1308
2024-10-31 02:08:40: [2024-10-31 02:08:40] iter = 11610, loss = 1.7975
2024-10-31 02:08:44: [2024-10-31 02:08:44] iter = 11620, loss = 2.3575
2024-10-31 02:08:46: [2024-10-31 02:08:46] iter = 11630, loss = 1.8746
2024-10-31 02:08:49: [2024-10-31 02:08:49] iter = 11640, loss = 2.2534
2024-10-31 02:08:51: [2024-10-31 02:08:51] iter = 11650, loss = 1.6652
2024-10-31 02:08:55: [2024-10-31 02:08:55] iter = 11660, loss = 1.8809
2024-10-31 02:08:58: [2024-10-31 02:08:58] iter = 11670, loss = 2.2904
2024-10-31 02:09:01: [2024-10-31 02:09:01] iter = 11680, loss = 1.9389
2024-10-31 02:09:05: [2024-10-31 02:09:05] iter = 11690, loss = 4.1873
2024-10-31 02:09:09: [2024-10-31 02:09:09] iter = 11700, loss = 2.4220
2024-10-31 02:09:12: [2024-10-31 02:09:12] iter = 11710, loss = 4.0447
2024-10-31 02:09:16: [2024-10-31 02:09:16] iter = 11720, loss = 2.4253
2024-10-31 02:09:20: [2024-10-31 02:09:20] iter = 11730, loss = 2.5683
2024-10-31 02:09:23: [2024-10-31 02:09:23] iter = 11740, loss = 1.7128
2024-10-31 02:09:27: [2024-10-31 02:09:27] iter = 11750, loss = 1.4799
2024-10-31 02:09:30: [2024-10-31 02:09:30] iter = 11760, loss = 2.1861
2024-10-31 02:09:33: [2024-10-31 02:09:33] iter = 11770, loss = 1.6892
2024-10-31 02:09:36: [2024-10-31 02:09:36] iter = 11780, loss = 2.5282
2024-10-31 02:09:39: [2024-10-31 02:09:39] iter = 11790, loss = 2.0092
2024-10-31 02:09:42: [2024-10-31 02:09:42] iter = 11800, loss = 1.9590
2024-10-31 02:09:45: [2024-10-31 02:09:45] iter = 11810, loss = 2.1860
2024-10-31 02:09:49: [2024-10-31 02:09:49] iter = 11820, loss = 1.7189
2024-10-31 02:09:52: [2024-10-31 02:09:52] iter = 11830, loss = 2.6975
2024-10-31 02:09:56: [2024-10-31 02:09:56] iter = 11840, loss = 2.2468
2024-10-31 02:10:00: [2024-10-31 02:10:00] iter = 11850, loss = 1.7732
2024-10-31 02:10:03: [2024-10-31 02:10:03] iter = 11860, loss = 2.3295
2024-10-31 02:10:05: [2024-10-31 02:10:05] iter = 11870, loss = 2.0980
2024-10-31 02:10:08: [2024-10-31 02:10:08] iter = 11880, loss = 2.2844
2024-10-31 02:10:10: [2024-10-31 02:10:10] iter = 11890, loss = 2.1472
2024-10-31 02:10:13: [2024-10-31 02:10:13] iter = 11900, loss = 1.7348
2024-10-31 02:10:16: [2024-10-31 02:10:16] iter = 11910, loss = 2.2859
2024-10-31 02:10:19: [2024-10-31 02:10:19] iter = 11920, loss = 1.9314
2024-10-31 02:10:22: [2024-10-31 02:10:22] iter = 11930, loss = 2.2851
2024-10-31 02:10:26: [2024-10-31 02:10:26] iter = 11940, loss = 2.1020
2024-10-31 02:10:30: [2024-10-31 02:10:30] iter = 11950, loss = 3.7815
2024-10-31 02:10:33: [2024-10-31 02:10:33] iter = 11960, loss = 1.9726
2024-10-31 02:10:35: [2024-10-31 02:10:35] iter = 11970, loss = 1.7716
2024-10-31 02:10:38: [2024-10-31 02:10:38] iter = 11980, loss = 2.0019
2024-10-31 02:10:42: [2024-10-31 02:10:42] iter = 11990, loss = 2.9074
2024-10-31 02:10:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-31 02:10:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:10:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 45125}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:12:38: Evaluate 5 random ConvNet, ACCmean = 0.7810 ACCstd = 0.0021
-------------------------
2024-10-31 02:12:38: Evaluate 5 random ConvNet, SENmean = 0.7769 SENstd = 0.0018
-------------------------
2024-10-31 02:12:38: Evaluate 5 random ConvNet, SPEmean = 0.9778 SPEstd = 0.0002
-------------------------
2024-10-31 02:12:38: Evaluate 5 random ConvNet, F!mean = 0.7693 F!std = 0.0021
-------------------------
2024-10-31 02:12:38: Evaluate 5 random ConvNet, mean = 0.7810 std = 0.0021
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:12:39: [2024-10-31 02:12:39] iter = 12000, loss = 1.7082
2024-10-31 02:12:41: [2024-10-31 02:12:41] iter = 12010, loss = 2.2351
2024-10-31 02:12:44: [2024-10-31 02:12:44] iter = 12020, loss = 2.1247
2024-10-31 02:12:46: [2024-10-31 02:12:46] iter = 12030, loss = 2.2051
2024-10-31 02:12:49: [2024-10-31 02:12:49] iter = 12040, loss = 2.3728
2024-10-31 02:12:52: [2024-10-31 02:12:52] iter = 12050, loss = 2.3737
2024-10-31 02:12:55: [2024-10-31 02:12:55] iter = 12060, loss = 2.2200
2024-10-31 02:12:57: [2024-10-31 02:12:57] iter = 12070, loss = 1.5446
2024-10-31 02:13:00: [2024-10-31 02:13:00] iter = 12080, loss = 3.0764
2024-10-31 02:13:02: [2024-10-31 02:13:02] iter = 12090, loss = 2.6264
2024-10-31 02:13:05: [2024-10-31 02:13:05] iter = 12100, loss = 1.6184
2024-10-31 02:13:08: [2024-10-31 02:13:08] iter = 12110, loss = 2.2182
2024-10-31 02:13:10: [2024-10-31 02:13:10] iter = 12120, loss = 2.9081
2024-10-31 02:13:13: [2024-10-31 02:13:13] iter = 12130, loss = 2.2005
2024-10-31 02:13:15: [2024-10-31 02:13:15] iter = 12140, loss = 1.7478
2024-10-31 02:13:18: [2024-10-31 02:13:18] iter = 12150, loss = 1.9638
2024-10-31 02:13:21: [2024-10-31 02:13:21] iter = 12160, loss = 6.7822
2024-10-31 02:13:24: [2024-10-31 02:13:24] iter = 12170, loss = 1.8376
2024-10-31 02:13:27: [2024-10-31 02:13:27] iter = 12180, loss = 3.0531
2024-10-31 02:13:29: [2024-10-31 02:13:29] iter = 12190, loss = 2.7492
2024-10-31 02:13:31: [2024-10-31 02:13:31] iter = 12200, loss = 1.8307
2024-10-31 02:13:34: [2024-10-31 02:13:34] iter = 12210, loss = 2.4644
2024-10-31 02:13:37: [2024-10-31 02:13:37] iter = 12220, loss = 2.0025
2024-10-31 02:13:40: [2024-10-31 02:13:40] iter = 12230, loss = 2.4594
2024-10-31 02:13:42: [2024-10-31 02:13:42] iter = 12240, loss = 2.3809
2024-10-31 02:13:45: [2024-10-31 02:13:45] iter = 12250, loss = 2.1620
2024-10-31 02:13:49: [2024-10-31 02:13:49] iter = 12260, loss = 4.0274
2024-10-31 02:13:52: [2024-10-31 02:13:52] iter = 12270, loss = 2.5545
2024-10-31 02:13:55: [2024-10-31 02:13:55] iter = 12280, loss = 1.7267
2024-10-31 02:13:58: [2024-10-31 02:13:58] iter = 12290, loss = 1.7087
2024-10-31 02:14:00: [2024-10-31 02:14:00] iter = 12300, loss = 2.5564
2024-10-31 02:14:03: [2024-10-31 02:14:03] iter = 12310, loss = 1.9817
2024-10-31 02:14:06: [2024-10-31 02:14:06] iter = 12320, loss = 2.4691
2024-10-31 02:14:09: [2024-10-31 02:14:09] iter = 12330, loss = 1.6768
2024-10-31 02:14:12: [2024-10-31 02:14:12] iter = 12340, loss = 1.6935
2024-10-31 02:14:15: [2024-10-31 02:14:15] iter = 12350, loss = 2.2744
2024-10-31 02:14:17: [2024-10-31 02:14:17] iter = 12360, loss = 2.1910
2024-10-31 02:14:19: [2024-10-31 02:14:19] iter = 12370, loss = 2.1105
2024-10-31 02:14:22: [2024-10-31 02:14:22] iter = 12380, loss = 2.2763
2024-10-31 02:14:25: [2024-10-31 02:14:25] iter = 12390, loss = 2.5045
2024-10-31 02:14:28: [2024-10-31 02:14:28] iter = 12400, loss = 2.3805
2024-10-31 02:14:30: [2024-10-31 02:14:30] iter = 12410, loss = 2.7079
2024-10-31 02:14:33: [2024-10-31 02:14:33] iter = 12420, loss = 1.8990
2024-10-31 02:14:36: [2024-10-31 02:14:36] iter = 12430, loss = 2.0320
2024-10-31 02:14:40: [2024-10-31 02:14:40] iter = 12440, loss = 2.1920
2024-10-31 02:14:43: [2024-10-31 02:14:43] iter = 12450, loss = 4.7169
2024-10-31 02:14:46: [2024-10-31 02:14:46] iter = 12460, loss = 2.1674
2024-10-31 02:14:49: [2024-10-31 02:14:49] iter = 12470, loss = 2.8579
2024-10-31 02:14:52: [2024-10-31 02:14:52] iter = 12480, loss = 1.8679
2024-10-31 02:14:56: [2024-10-31 02:14:56] iter = 12490, loss = 2.0198
2024-10-31 02:14:59: [2024-10-31 02:14:59] iter = 12500, loss = 1.5816
2024-10-31 02:15:02: [2024-10-31 02:15:02] iter = 12510, loss = 2.2135
2024-10-31 02:15:06: [2024-10-31 02:15:06] iter = 12520, loss = 2.3658
2024-10-31 02:15:09: [2024-10-31 02:15:09] iter = 12530, loss = 4.1847
2024-10-31 02:15:14: [2024-10-31 02:15:14] iter = 12540, loss = 3.2399
2024-10-31 02:15:17: [2024-10-31 02:15:17] iter = 12550, loss = 3.0819
2024-10-31 02:15:20: [2024-10-31 02:15:20] iter = 12560, loss = 2.0339
2024-10-31 02:15:23: [2024-10-31 02:15:23] iter = 12570, loss = 2.0925
2024-10-31 02:15:26: [2024-10-31 02:15:26] iter = 12580, loss = 1.9294
2024-10-31 02:15:30: [2024-10-31 02:15:30] iter = 12590, loss = 1.8857
2024-10-31 02:15:33: [2024-10-31 02:15:33] iter = 12600, loss = 1.5715
2024-10-31 02:15:36: [2024-10-31 02:15:36] iter = 12610, loss = 2.9618
2024-10-31 02:15:39: [2024-10-31 02:15:39] iter = 12620, loss = 1.8813
2024-10-31 02:15:42: [2024-10-31 02:15:42] iter = 12630, loss = 2.2542
2024-10-31 02:15:45: [2024-10-31 02:15:45] iter = 12640, loss = 1.8106
2024-10-31 02:15:48: [2024-10-31 02:15:48] iter = 12650, loss = 1.9389
2024-10-31 02:15:51: [2024-10-31 02:15:51] iter = 12660, loss = 2.1387
2024-10-31 02:15:54: [2024-10-31 02:15:54] iter = 12670, loss = 2.3872
2024-10-31 02:15:58: [2024-10-31 02:15:58] iter = 12680, loss = 2.1672
2024-10-31 02:16:00: [2024-10-31 02:16:00] iter = 12690, loss = 1.7756
2024-10-31 02:16:03: [2024-10-31 02:16:03] iter = 12700, loss = 2.0816
2024-10-31 02:16:06: [2024-10-31 02:16:06] iter = 12710, loss = 2.1376
2024-10-31 02:16:09: [2024-10-31 02:16:09] iter = 12720, loss = 1.9295
2024-10-31 02:16:12: [2024-10-31 02:16:12] iter = 12730, loss = 2.1068
2024-10-31 02:16:15: [2024-10-31 02:16:15] iter = 12740, loss = 2.6204
2024-10-31 02:16:19: [2024-10-31 02:16:19] iter = 12750, loss = 4.1675
2024-10-31 02:16:22: [2024-10-31 02:16:22] iter = 12760, loss = 1.8427
2024-10-31 02:16:25: [2024-10-31 02:16:25] iter = 12770, loss = 1.7614
2024-10-31 02:16:26: [2024-10-31 02:16:26] iter = 12780, loss = 3.2392
2024-10-31 02:16:29: [2024-10-31 02:16:29] iter = 12790, loss = 1.8072
2024-10-31 02:16:31: [2024-10-31 02:16:31] iter = 12800, loss = 6.4786
2024-10-31 02:16:33: [2024-10-31 02:16:33] iter = 12810, loss = 2.5140
2024-10-31 02:16:36: [2024-10-31 02:16:36] iter = 12820, loss = 2.9057
2024-10-31 02:16:38: [2024-10-31 02:16:38] iter = 12830, loss = 2.8544
2024-10-31 02:16:41: [2024-10-31 02:16:41] iter = 12840, loss = 1.7233
2024-10-31 02:16:44: [2024-10-31 02:16:44] iter = 12850, loss = 2.6059
2024-10-31 02:16:47: [2024-10-31 02:16:47] iter = 12860, loss = 1.9932
2024-10-31 02:16:49: [2024-10-31 02:16:49] iter = 12870, loss = 3.5635
2024-10-31 02:16:52: [2024-10-31 02:16:52] iter = 12880, loss = 2.2021
2024-10-31 02:16:55: [2024-10-31 02:16:55] iter = 12890, loss = 2.6245
2024-10-31 02:16:57: [2024-10-31 02:16:57] iter = 12900, loss = 1.7221
2024-10-31 02:17:01: [2024-10-31 02:17:01] iter = 12910, loss = 1.6239
2024-10-31 02:17:04: [2024-10-31 02:17:04] iter = 12920, loss = 2.1461
2024-10-31 02:17:06: [2024-10-31 02:17:06] iter = 12930, loss = 1.8101
2024-10-31 02:17:09: [2024-10-31 02:17:09] iter = 12940, loss = 1.9804
2024-10-31 02:17:12: [2024-10-31 02:17:12] iter = 12950, loss = 2.2395
2024-10-31 02:17:15: [2024-10-31 02:17:15] iter = 12960, loss = 2.8870
2024-10-31 02:17:18: [2024-10-31 02:17:18] iter = 12970, loss = 1.8589
2024-10-31 02:17:21: [2024-10-31 02:17:21] iter = 12980, loss = 2.3619
2024-10-31 02:17:24: [2024-10-31 02:17:24] iter = 12990, loss = 2.1248
2024-10-31 02:17:27: [2024-10-31 02:17:27] iter = 13000, loss = 1.7277
2024-10-31 02:17:30: [2024-10-31 02:17:30] iter = 13010, loss = 1.9688
2024-10-31 02:17:32: [2024-10-31 02:17:32] iter = 13020, loss = 2.1743
2024-10-31 02:17:34: [2024-10-31 02:17:34] iter = 13030, loss = 1.9839
2024-10-31 02:17:37: [2024-10-31 02:17:37] iter = 13040, loss = 1.8780
2024-10-31 02:17:39: [2024-10-31 02:17:39] iter = 13050, loss = 1.9356
2024-10-31 02:17:42: [2024-10-31 02:17:42] iter = 13060, loss = 1.7687
2024-10-31 02:17:45: [2024-10-31 02:17:45] iter = 13070, loss = 2.3648
2024-10-31 02:17:48: [2024-10-31 02:17:48] iter = 13080, loss = 2.3909
2024-10-31 02:17:51: [2024-10-31 02:17:51] iter = 13090, loss = 1.7497
2024-10-31 02:17:53: [2024-10-31 02:17:53] iter = 13100, loss = 1.8554
2024-10-31 02:17:56: [2024-10-31 02:17:56] iter = 13110, loss = 2.0829
2024-10-31 02:17:59: [2024-10-31 02:17:59] iter = 13120, loss = 1.8114
2024-10-31 02:18:02: [2024-10-31 02:18:02] iter = 13130, loss = 1.6667
2024-10-31 02:18:05: [2024-10-31 02:18:05] iter = 13140, loss = 2.0403
2024-10-31 02:18:08: [2024-10-31 02:18:08] iter = 13150, loss = 2.9501
2024-10-31 02:18:11: [2024-10-31 02:18:11] iter = 13160, loss = 1.8571
2024-10-31 02:18:13: [2024-10-31 02:18:13] iter = 13170, loss = 2.1848
2024-10-31 02:18:15: [2024-10-31 02:18:15] iter = 13180, loss = 1.9781
2024-10-31 02:18:19: [2024-10-31 02:18:19] iter = 13190, loss = 3.0027
2024-10-31 02:18:23: [2024-10-31 02:18:23] iter = 13200, loss = 2.6067
2024-10-31 02:18:26: [2024-10-31 02:18:26] iter = 13210, loss = 1.8483
2024-10-31 02:18:29: [2024-10-31 02:18:29] iter = 13220, loss = 1.6040
2024-10-31 02:18:31: [2024-10-31 02:18:31] iter = 13230, loss = 2.2036
2024-10-31 02:18:34: [2024-10-31 02:18:34] iter = 13240, loss = 2.2831
2024-10-31 02:18:37: [2024-10-31 02:18:37] iter = 13250, loss = 1.9552
2024-10-31 02:18:39: [2024-10-31 02:18:39] iter = 13260, loss = 2.3245
2024-10-31 02:18:42: [2024-10-31 02:18:42] iter = 13270, loss = 2.1620
2024-10-31 02:18:44: [2024-10-31 02:18:44] iter = 13280, loss = 3.0151
2024-10-31 02:18:47: [2024-10-31 02:18:47] iter = 13290, loss = 2.2895
2024-10-31 02:18:51: [2024-10-31 02:18:51] iter = 13300, loss = 2.8622
2024-10-31 02:18:54: [2024-10-31 02:18:54] iter = 13310, loss = 2.1301
2024-10-31 02:18:57: [2024-10-31 02:18:57] iter = 13320, loss = 1.8728
2024-10-31 02:19:01: [2024-10-31 02:19:01] iter = 13330, loss = 2.8861
2024-10-31 02:19:04: [2024-10-31 02:19:04] iter = 13340, loss = 2.5977
2024-10-31 02:19:06: [2024-10-31 02:19:06] iter = 13350, loss = 1.9547
2024-10-31 02:19:09: [2024-10-31 02:19:09] iter = 13360, loss = 2.2728
2024-10-31 02:19:12: [2024-10-31 02:19:12] iter = 13370, loss = 1.9955
2024-10-31 02:19:15: [2024-10-31 02:19:15] iter = 13380, loss = 1.9465
2024-10-31 02:19:17: [2024-10-31 02:19:17] iter = 13390, loss = 1.9085
2024-10-31 02:19:21: [2024-10-31 02:19:21] iter = 13400, loss = 1.8124
2024-10-31 02:19:24: [2024-10-31 02:19:24] iter = 13410, loss = 1.9411
2024-10-31 02:19:27: [2024-10-31 02:19:27] iter = 13420, loss = 1.9801
2024-10-31 02:19:31: [2024-10-31 02:19:31] iter = 13430, loss = 3.0425
2024-10-31 02:19:34: [2024-10-31 02:19:34] iter = 13440, loss = 1.8831
2024-10-31 02:19:37: [2024-10-31 02:19:37] iter = 13450, loss = 2.7552
2024-10-31 02:19:40: [2024-10-31 02:19:40] iter = 13460, loss = 1.8902
2024-10-31 02:19:43: [2024-10-31 02:19:43] iter = 13470, loss = 1.9276
2024-10-31 02:19:46: [2024-10-31 02:19:46] iter = 13480, loss = 1.8282
2024-10-31 02:19:49: [2024-10-31 02:19:49] iter = 13490, loss = 1.9205
2024-10-31 02:19:52: [2024-10-31 02:19:52] iter = 13500, loss = 1.7834
2024-10-31 02:19:55: [2024-10-31 02:19:55] iter = 13510, loss = 2.2079
2024-10-31 02:19:57: [2024-10-31 02:19:57] iter = 13520, loss = 1.9467
2024-10-31 02:19:59: [2024-10-31 02:19:59] iter = 13530, loss = 2.3438
2024-10-31 02:20:02: [2024-10-31 02:20:02] iter = 13540, loss = 1.9775
2024-10-31 02:20:04: [2024-10-31 02:20:04] iter = 13550, loss = 2.0549
2024-10-31 02:20:06: [2024-10-31 02:20:06] iter = 13560, loss = 4.5765
2024-10-31 02:20:09: [2024-10-31 02:20:09] iter = 13570, loss = 2.2923
2024-10-31 02:20:11: [2024-10-31 02:20:11] iter = 13580, loss = 3.5364
2024-10-31 02:20:14: [2024-10-31 02:20:14] iter = 13590, loss = 1.7695
2024-10-31 02:20:16: [2024-10-31 02:20:16] iter = 13600, loss = 2.7851
2024-10-31 02:20:19: [2024-10-31 02:20:19] iter = 13610, loss = 3.4051
2024-10-31 02:20:21: [2024-10-31 02:20:21] iter = 13620, loss = 2.1737
2024-10-31 02:20:24: [2024-10-31 02:20:24] iter = 13630, loss = 1.8303
2024-10-31 02:20:27: [2024-10-31 02:20:27] iter = 13640, loss = 1.9867
2024-10-31 02:20:30: [2024-10-31 02:20:30] iter = 13650, loss = 2.1605
2024-10-31 02:20:33: [2024-10-31 02:20:33] iter = 13660, loss = 3.9278
2024-10-31 02:20:36: [2024-10-31 02:20:36] iter = 13670, loss = 1.6902
2024-10-31 02:20:38: [2024-10-31 02:20:38] iter = 13680, loss = 2.6752
2024-10-31 02:20:41: [2024-10-31 02:20:41] iter = 13690, loss = 2.6791
2024-10-31 02:20:43: [2024-10-31 02:20:43] iter = 13700, loss = 1.9751
2024-10-31 02:20:46: [2024-10-31 02:20:46] iter = 13710, loss = 1.7487
2024-10-31 02:20:48: [2024-10-31 02:20:48] iter = 13720, loss = 2.0481
2024-10-31 02:20:51: [2024-10-31 02:20:51] iter = 13730, loss = 3.9730
2024-10-31 02:20:55: [2024-10-31 02:20:55] iter = 13740, loss = 3.0892
2024-10-31 02:20:58: [2024-10-31 02:20:58] iter = 13750, loss = 1.7084
2024-10-31 02:21:00: [2024-10-31 02:21:00] iter = 13760, loss = 2.0325
2024-10-31 02:21:03: [2024-10-31 02:21:03] iter = 13770, loss = 3.0336
2024-10-31 02:21:06: [2024-10-31 02:21:06] iter = 13780, loss = 1.8232
2024-10-31 02:21:08: [2024-10-31 02:21:08] iter = 13790, loss = 1.9544
2024-10-31 02:21:11: [2024-10-31 02:21:11] iter = 13800, loss = 2.0505
2024-10-31 02:21:14: [2024-10-31 02:21:14] iter = 13810, loss = 2.9165
2024-10-31 02:21:17: [2024-10-31 02:21:17] iter = 13820, loss = 3.4366
2024-10-31 02:21:20: [2024-10-31 02:21:20] iter = 13830, loss = 2.8925
2024-10-31 02:21:23: [2024-10-31 02:21:23] iter = 13840, loss = 1.5017
2024-10-31 02:21:26: [2024-10-31 02:21:26] iter = 13850, loss = 1.9559
2024-10-31 02:21:29: [2024-10-31 02:21:29] iter = 13860, loss = 1.5616
2024-10-31 02:21:32: [2024-10-31 02:21:32] iter = 13870, loss = 2.0687
2024-10-31 02:21:35: [2024-10-31 02:21:35] iter = 13880, loss = 2.1961
2024-10-31 02:21:38: [2024-10-31 02:21:38] iter = 13890, loss = 2.5706
2024-10-31 02:21:41: [2024-10-31 02:21:41] iter = 13900, loss = 1.9372
2024-10-31 02:21:44: [2024-10-31 02:21:44] iter = 13910, loss = 1.7623
2024-10-31 02:21:47: [2024-10-31 02:21:47] iter = 13920, loss = 2.0400
2024-10-31 02:21:50: [2024-10-31 02:21:50] iter = 13930, loss = 1.5361
2024-10-31 02:21:53: [2024-10-31 02:21:53] iter = 13940, loss = 2.1021
2024-10-31 02:21:55: [2024-10-31 02:21:55] iter = 13950, loss = 2.4756
2024-10-31 02:21:57: [2024-10-31 02:21:57] iter = 13960, loss = 2.2139
2024-10-31 02:22:00: [2024-10-31 02:22:00] iter = 13970, loss = 1.7709
2024-10-31 02:22:03: [2024-10-31 02:22:03] iter = 13980, loss = 2.0269
2024-10-31 02:22:05: [2024-10-31 02:22:05] iter = 13990, loss = 2.0960
2024-10-31 02:22:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-31 02:22:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:22:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 28340}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:23:57: Evaluate 5 random ConvNet, ACCmean = 0.7869 ACCstd = 0.0025
-------------------------
2024-10-31 02:23:57: Evaluate 5 random ConvNet, SENmean = 0.7791 SENstd = 0.0028
-------------------------
2024-10-31 02:23:57: Evaluate 5 random ConvNet, SPEmean = 0.9784 SPEstd = 0.0003
-------------------------
2024-10-31 02:23:57: Evaluate 5 random ConvNet, F!mean = 0.7722 F!std = 0.0016
-------------------------
2024-10-31 02:23:57: Evaluate 5 random ConvNet, mean = 0.7869 std = 0.0025
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:23:57: [2024-10-31 02:23:57] iter = 14000, loss = 2.6182
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:24:00: [2024-10-31 02:24:00] iter = 14010, loss = 1.8697
2024-10-31 02:24:03: [2024-10-31 02:24:03] iter = 14020, loss = 2.6493
2024-10-31 02:24:06: [2024-10-31 02:24:06] iter = 14030, loss = 2.7461
2024-10-31 02:24:09: [2024-10-31 02:24:09] iter = 14040, loss = 3.1098
2024-10-31 02:24:10: [2024-10-31 02:24:10] iter = 14050, loss = 1.9623
2024-10-31 02:24:13: [2024-10-31 02:24:13] iter = 14060, loss = 1.7268
2024-10-31 02:24:15: [2024-10-31 02:24:15] iter = 14070, loss = 1.9285
2024-10-31 02:24:17: [2024-10-31 02:24:17] iter = 14080, loss = 1.6689
2024-10-31 02:24:19: [2024-10-31 02:24:19] iter = 14090, loss = 1.8550
2024-10-31 02:24:22: [2024-10-31 02:24:22] iter = 14100, loss = 1.9240
2024-10-31 02:24:24: [2024-10-31 02:24:24] iter = 14110, loss = 2.9845
2024-10-31 02:24:27: [2024-10-31 02:24:27] iter = 14120, loss = 1.7460
2024-10-31 02:24:29: [2024-10-31 02:24:29] iter = 14130, loss = 1.9199
2024-10-31 02:24:32: [2024-10-31 02:24:32] iter = 14140, loss = 2.6948
2024-10-31 02:24:34: [2024-10-31 02:24:34] iter = 14150, loss = 1.7881
2024-10-31 02:24:37: [2024-10-31 02:24:37] iter = 14160, loss = 2.5797
2024-10-31 02:24:39: [2024-10-31 02:24:39] iter = 14170, loss = 1.8019
2024-10-31 02:24:42: [2024-10-31 02:24:42] iter = 14180, loss = 1.6805
2024-10-31 02:24:45: [2024-10-31 02:24:45] iter = 14190, loss = 1.6959
2024-10-31 02:24:47: [2024-10-31 02:24:47] iter = 14200, loss = 2.1900
2024-10-31 02:24:50: [2024-10-31 02:24:50] iter = 14210, loss = 2.2324
2024-10-31 02:24:52: [2024-10-31 02:24:52] iter = 14220, loss = 2.2125
2024-10-31 02:24:55: [2024-10-31 02:24:55] iter = 14230, loss = 2.1949
2024-10-31 02:24:58: [2024-10-31 02:24:58] iter = 14240, loss = 3.3056
2024-10-31 02:25:00: [2024-10-31 02:25:00] iter = 14250, loss = 1.7094
2024-10-31 02:25:03: [2024-10-31 02:25:03] iter = 14260, loss = 1.6600
2024-10-31 02:25:05: [2024-10-31 02:25:05] iter = 14270, loss = 2.2357
2024-10-31 02:25:08: [2024-10-31 02:25:08] iter = 14280, loss = 1.7376
2024-10-31 02:25:11: [2024-10-31 02:25:11] iter = 14290, loss = 4.3377
2024-10-31 02:25:14: [2024-10-31 02:25:14] iter = 14300, loss = 3.1313
2024-10-31 02:25:16: [2024-10-31 02:25:16] iter = 14310, loss = 1.6428
2024-10-31 02:25:19: [2024-10-31 02:25:19] iter = 14320, loss = 2.9514
2024-10-31 02:25:22: [2024-10-31 02:25:22] iter = 14330, loss = 1.5179
2024-10-31 02:25:24: [2024-10-31 02:25:24] iter = 14340, loss = 3.0154
2024-10-31 02:25:27: [2024-10-31 02:25:27] iter = 14350, loss = 3.1171
2024-10-31 02:25:30: [2024-10-31 02:25:30] iter = 14360, loss = 2.2974
2024-10-31 02:25:33: [2024-10-31 02:25:33] iter = 14370, loss = 2.4753
2024-10-31 02:25:35: [2024-10-31 02:25:35] iter = 14380, loss = 2.9273
2024-10-31 02:25:37: [2024-10-31 02:25:37] iter = 14390, loss = 2.3248
2024-10-31 02:25:40: [2024-10-31 02:25:40] iter = 14400, loss = 2.1205
2024-10-31 02:25:43: [2024-10-31 02:25:43] iter = 14410, loss = 2.4309
2024-10-31 02:25:46: [2024-10-31 02:25:46] iter = 14420, loss = 2.2719
2024-10-31 02:25:49: [2024-10-31 02:25:49] iter = 14430, loss = 2.4356
2024-10-31 02:25:52: [2024-10-31 02:25:52] iter = 14440, loss = 2.1787
2024-10-31 02:25:54: [2024-10-31 02:25:54] iter = 14450, loss = 1.8522
2024-10-31 02:25:57: [2024-10-31 02:25:57] iter = 14460, loss = 1.9224
2024-10-31 02:25:59: [2024-10-31 02:25:59] iter = 14470, loss = 2.0908
2024-10-31 02:26:03: [2024-10-31 02:26:03] iter = 14480, loss = 1.8868
2024-10-31 02:26:07: [2024-10-31 02:26:07] iter = 14490, loss = 1.8282
2024-10-31 02:26:09: [2024-10-31 02:26:09] iter = 14500, loss = 2.3530
2024-10-31 02:26:11: [2024-10-31 02:26:11] iter = 14510, loss = 3.3060
2024-10-31 02:26:14: [2024-10-31 02:26:14] iter = 14520, loss = 2.2491
2024-10-31 02:26:17: [2024-10-31 02:26:17] iter = 14530, loss = 1.5282
2024-10-31 02:26:21: [2024-10-31 02:26:21] iter = 14540, loss = 1.7889
2024-10-31 02:26:24: [2024-10-31 02:26:24] iter = 14550, loss = 2.1137
2024-10-31 02:26:26: [2024-10-31 02:26:26] iter = 14560, loss = 2.0274
2024-10-31 02:26:30: [2024-10-31 02:26:30] iter = 14570, loss = 1.9108
2024-10-31 02:26:33: [2024-10-31 02:26:33] iter = 14580, loss = 4.6287
2024-10-31 02:26:35: [2024-10-31 02:26:35] iter = 14590, loss = 1.9780
2024-10-31 02:26:38: [2024-10-31 02:26:38] iter = 14600, loss = 2.3048
2024-10-31 02:26:40: [2024-10-31 02:26:40] iter = 14610, loss = 1.7981
2024-10-31 02:26:43: [2024-10-31 02:26:43] iter = 14620, loss = 2.2552
2024-10-31 02:26:47: [2024-10-31 02:26:47] iter = 14630, loss = 2.0392
2024-10-31 02:26:50: [2024-10-31 02:26:50] iter = 14640, loss = 1.8158
2024-10-31 02:26:53: [2024-10-31 02:26:53] iter = 14650, loss = 1.5714
2024-10-31 02:26:57: [2024-10-31 02:26:57] iter = 14660, loss = 1.6945
2024-10-31 02:27:00: [2024-10-31 02:27:00] iter = 14670, loss = 2.1702
2024-10-31 02:27:03: [2024-10-31 02:27:03] iter = 14680, loss = 2.1140
2024-10-31 02:27:06: [2024-10-31 02:27:06] iter = 14690, loss = 1.8744
2024-10-31 02:27:10: [2024-10-31 02:27:10] iter = 14700, loss = 1.8286
2024-10-31 02:27:13: [2024-10-31 02:27:13] iter = 14710, loss = 2.0646
2024-10-31 02:27:16: [2024-10-31 02:27:16] iter = 14720, loss = 1.9339
2024-10-31 02:27:18: [2024-10-31 02:27:18] iter = 14730, loss = 1.9170
2024-10-31 02:27:22: [2024-10-31 02:27:22] iter = 14740, loss = 2.1547
2024-10-31 02:27:24: [2024-10-31 02:27:24] iter = 14750, loss = 2.0187
2024-10-31 02:27:28: [2024-10-31 02:27:28] iter = 14760, loss = 1.6982
2024-10-31 02:27:31: [2024-10-31 02:27:31] iter = 14770, loss = 1.9045
2024-10-31 02:27:34: [2024-10-31 02:27:34] iter = 14780, loss = 2.4657
2024-10-31 02:27:37: [2024-10-31 02:27:37] iter = 14790, loss = 2.2752
2024-10-31 02:27:40: [2024-10-31 02:27:40] iter = 14800, loss = 1.7888
2024-10-31 02:27:43: [2024-10-31 02:27:43] iter = 14810, loss = 2.0773
2024-10-31 02:27:47: [2024-10-31 02:27:47] iter = 14820, loss = 2.5212
2024-10-31 02:27:50: [2024-10-31 02:27:50] iter = 14830, loss = 3.0709
2024-10-31 02:27:53: [2024-10-31 02:27:53] iter = 14840, loss = 1.6857
2024-10-31 02:27:56: [2024-10-31 02:27:56] iter = 14850, loss = 1.6566
2024-10-31 02:27:59: [2024-10-31 02:27:59] iter = 14860, loss = 2.9341
2024-10-31 02:28:03: [2024-10-31 02:28:03] iter = 14870, loss = 1.8325
2024-10-31 02:28:06: [2024-10-31 02:28:06] iter = 14880, loss = 2.6903
2024-10-31 02:28:08: [2024-10-31 02:28:08] iter = 14890, loss = 3.5688
2024-10-31 02:28:11: [2024-10-31 02:28:11] iter = 14900, loss = 2.1450
2024-10-31 02:28:15: [2024-10-31 02:28:15] iter = 14910, loss = 1.9897
2024-10-31 02:28:18: [2024-10-31 02:28:18] iter = 14920, loss = 2.1105
2024-10-31 02:28:21: [2024-10-31 02:28:21] iter = 14930, loss = 2.1903
2024-10-31 02:28:23: [2024-10-31 02:28:23] iter = 14940, loss = 3.8592
2024-10-31 02:28:26: [2024-10-31 02:28:26] iter = 14950, loss = 2.6760
2024-10-31 02:28:29: [2024-10-31 02:28:29] iter = 14960, loss = 1.7695
2024-10-31 02:28:32: [2024-10-31 02:28:32] iter = 14970, loss = 2.0875
2024-10-31 02:28:35: [2024-10-31 02:28:35] iter = 14980, loss = 2.8718
2024-10-31 02:28:39: [2024-10-31 02:28:39] iter = 14990, loss = 2.6686
2024-10-31 02:28:42: [2024-10-31 02:28:42] iter = 15000, loss = 3.3010
2024-10-31 02:28:46: [2024-10-31 02:28:46] iter = 15010, loss = 2.0383
2024-10-31 02:28:49: [2024-10-31 02:28:49] iter = 15020, loss = 3.4052
2024-10-31 02:28:51: [2024-10-31 02:28:51] iter = 15030, loss = 2.4091
2024-10-31 02:28:54: [2024-10-31 02:28:54] iter = 15040, loss = 2.6255
2024-10-31 02:28:57: [2024-10-31 02:28:57] iter = 15050, loss = 3.3060
2024-10-31 02:29:01: [2024-10-31 02:29:01] iter = 15060, loss = 2.2208
2024-10-31 02:29:04: [2024-10-31 02:29:04] iter = 15070, loss = 2.0576
2024-10-31 02:29:06: [2024-10-31 02:29:06] iter = 15080, loss = 1.6733
2024-10-31 02:29:09: [2024-10-31 02:29:09] iter = 15090, loss = 1.6592
2024-10-31 02:29:13: [2024-10-31 02:29:13] iter = 15100, loss = 1.7115
2024-10-31 02:29:16: [2024-10-31 02:29:16] iter = 15110, loss = 1.6793
2024-10-31 02:29:19: [2024-10-31 02:29:19] iter = 15120, loss = 1.6984
2024-10-31 02:29:22: [2024-10-31 02:29:22] iter = 15130, loss = 2.1568
2024-10-31 02:29:25: [2024-10-31 02:29:25] iter = 15140, loss = 1.8809
2024-10-31 02:29:28: [2024-10-31 02:29:28] iter = 15150, loss = 3.7170
2024-10-31 02:29:32: [2024-10-31 02:29:32] iter = 15160, loss = 2.9594
2024-10-31 02:29:35: [2024-10-31 02:29:34] iter = 15170, loss = 2.8219
2024-10-31 02:29:37: [2024-10-31 02:29:37] iter = 15180, loss = 1.8865
2024-10-31 02:29:40: [2024-10-31 02:29:40] iter = 15190, loss = 2.0720
2024-10-31 02:29:43: [2024-10-31 02:29:43] iter = 15200, loss = 2.1107
2024-10-31 02:29:47: [2024-10-31 02:29:47] iter = 15210, loss = 1.8734
2024-10-31 02:29:50: [2024-10-31 02:29:50] iter = 15220, loss = 1.8315
2024-10-31 02:29:53: [2024-10-31 02:29:53] iter = 15230, loss = 1.9769
2024-10-31 02:29:57: [2024-10-31 02:29:57] iter = 15240, loss = 2.6309
2024-10-31 02:29:59: [2024-10-31 02:29:59] iter = 15250, loss = 1.8839
2024-10-31 02:30:02: [2024-10-31 02:30:02] iter = 15260, loss = 2.1515
2024-10-31 02:30:05: [2024-10-31 02:30:05] iter = 15270, loss = 1.8974
2024-10-31 02:30:08: [2024-10-31 02:30:08] iter = 15280, loss = 2.2806
2024-10-31 02:30:11: [2024-10-31 02:30:11] iter = 15290, loss = 2.2215
2024-10-31 02:30:15: [2024-10-31 02:30:15] iter = 15300, loss = 1.9146
2024-10-31 02:30:17: [2024-10-31 02:30:17] iter = 15310, loss = 1.6142
2024-10-31 02:30:21: [2024-10-31 02:30:20] iter = 15320, loss = 3.3701
2024-10-31 02:30:23: [2024-10-31 02:30:23] iter = 15330, loss = 2.3154
2024-10-31 02:30:26: [2024-10-31 02:30:26] iter = 15340, loss = 2.1904
2024-10-31 02:30:29: [2024-10-31 02:30:29] iter = 15350, loss = 2.3202
2024-10-31 02:30:31: [2024-10-31 02:30:31] iter = 15360, loss = 1.8151
2024-10-31 02:30:34: [2024-10-31 02:30:34] iter = 15370, loss = 2.1240
2024-10-31 02:30:37: [2024-10-31 02:30:37] iter = 15380, loss = 2.0371
2024-10-31 02:30:40: [2024-10-31 02:30:40] iter = 15390, loss = 3.1113
2024-10-31 02:30:43: [2024-10-31 02:30:43] iter = 15400, loss = 2.1229
2024-10-31 02:30:46: [2024-10-31 02:30:46] iter = 15410, loss = 2.2297
2024-10-31 02:30:50: [2024-10-31 02:30:50] iter = 15420, loss = 2.1137
2024-10-31 02:30:53: [2024-10-31 02:30:53] iter = 15430, loss = 2.2968
2024-10-31 02:30:56: [2024-10-31 02:30:56] iter = 15440, loss = 1.8161
2024-10-31 02:30:59: [2024-10-31 02:30:59] iter = 15450, loss = 1.8699
2024-10-31 02:31:02: [2024-10-31 02:31:02] iter = 15460, loss = 2.1844
2024-10-31 02:31:06: [2024-10-31 02:31:06] iter = 15470, loss = 1.8254
2024-10-31 02:31:08: [2024-10-31 02:31:08] iter = 15480, loss = 2.7420
2024-10-31 02:31:12: [2024-10-31 02:31:12] iter = 15490, loss = 1.7531
2024-10-31 02:31:14: [2024-10-31 02:31:14] iter = 15500, loss = 2.2822
2024-10-31 02:31:18: [2024-10-31 02:31:18] iter = 15510, loss = 2.5299
2024-10-31 02:31:20: [2024-10-31 02:31:20] iter = 15520, loss = 1.8215
2024-10-31 02:31:23: [2024-10-31 02:31:23] iter = 15530, loss = 2.1422
2024-10-31 02:31:25: [2024-10-31 02:31:25] iter = 15540, loss = 2.9838
2024-10-31 02:31:28: [2024-10-31 02:31:28] iter = 15550, loss = 3.0507
2024-10-31 02:31:30: [2024-10-31 02:31:30] iter = 15560, loss = 2.0175
2024-10-31 02:31:33: [2024-10-31 02:31:33] iter = 15570, loss = 1.6586
2024-10-31 02:31:36: [2024-10-31 02:31:36] iter = 15580, loss = 1.9707
2024-10-31 02:31:38: [2024-10-31 02:31:38] iter = 15590, loss = 1.9799
2024-10-31 02:31:41: [2024-10-31 02:31:41] iter = 15600, loss = 2.3857
2024-10-31 02:31:43: [2024-10-31 02:31:43] iter = 15610, loss = 2.1296
2024-10-31 02:31:45: [2024-10-31 02:31:45] iter = 15620, loss = 2.3216
2024-10-31 02:31:48: [2024-10-31 02:31:48] iter = 15630, loss = 1.6829
2024-10-31 02:31:50: [2024-10-31 02:31:50] iter = 15640, loss = 5.9044
2024-10-31 02:31:52: [2024-10-31 02:31:52] iter = 15650, loss = 2.2250
2024-10-31 02:31:55: [2024-10-31 02:31:55] iter = 15660, loss = 2.3144
2024-10-31 02:31:58: [2024-10-31 02:31:58] iter = 15670, loss = 2.0079
2024-10-31 02:32:00: [2024-10-31 02:32:00] iter = 15680, loss = 1.9186
2024-10-31 02:32:02: [2024-10-31 02:32:02] iter = 15690, loss = 2.3455
2024-10-31 02:32:05: [2024-10-31 02:32:05] iter = 15700, loss = 2.0759
2024-10-31 02:32:07: [2024-10-31 02:32:07] iter = 15710, loss = 1.5648
2024-10-31 02:32:09: [2024-10-31 02:32:09] iter = 15720, loss = 2.9168
2024-10-31 02:32:12: [2024-10-31 02:32:12] iter = 15730, loss = 2.4950
2024-10-31 02:32:15: [2024-10-31 02:32:15] iter = 15740, loss = 2.4973
2024-10-31 02:32:19: [2024-10-31 02:32:19] iter = 15750, loss = 2.3443
2024-10-31 02:32:21: [2024-10-31 02:32:21] iter = 15760, loss = 2.3400
2024-10-31 02:32:24: [2024-10-31 02:32:24] iter = 15770, loss = 1.8701
2024-10-31 02:32:27: [2024-10-31 02:32:27] iter = 15780, loss = 2.1928
2024-10-31 02:32:30: [2024-10-31 02:32:30] iter = 15790, loss = 2.5007
2024-10-31 02:32:32: [2024-10-31 02:32:32] iter = 15800, loss = 2.1942
2024-10-31 02:32:35: [2024-10-31 02:32:35] iter = 15810, loss = 2.1653
2024-10-31 02:32:38: [2024-10-31 02:32:38] iter = 15820, loss = 2.2908
2024-10-31 02:32:41: [2024-10-31 02:32:41] iter = 15830, loss = 2.1445
2024-10-31 02:32:44: [2024-10-31 02:32:44] iter = 15840, loss = 2.6081
2024-10-31 02:32:47: [2024-10-31 02:32:47] iter = 15850, loss = 1.9330
2024-10-31 02:32:50: [2024-10-31 02:32:50] iter = 15860, loss = 1.9719
2024-10-31 02:32:52: [2024-10-31 02:32:52] iter = 15870, loss = 2.2204
2024-10-31 02:32:55: [2024-10-31 02:32:55] iter = 15880, loss = 2.3944
2024-10-31 02:32:58: [2024-10-31 02:32:58] iter = 15890, loss = 2.4362
2024-10-31 02:33:00: [2024-10-31 02:33:00] iter = 15900, loss = 2.1072
2024-10-31 02:33:03: [2024-10-31 02:33:03] iter = 15910, loss = 2.4723
2024-10-31 02:33:06: [2024-10-31 02:33:06] iter = 15920, loss = 2.0465
2024-10-31 02:33:09: [2024-10-31 02:33:09] iter = 15930, loss = 2.9171
2024-10-31 02:33:11: [2024-10-31 02:33:11] iter = 15940, loss = 1.9730
2024-10-31 02:33:13: [2024-10-31 02:33:13] iter = 15950, loss = 1.9909
2024-10-31 02:33:16: [2024-10-31 02:33:16] iter = 15960, loss = 2.5717
2024-10-31 02:33:19: [2024-10-31 02:33:19] iter = 15970, loss = 1.9773
2024-10-31 02:33:21: [2024-10-31 02:33:21] iter = 15980, loss = 2.9119
2024-10-31 02:33:24: [2024-10-31 02:33:24] iter = 15990, loss = 2.5048
2024-10-31 02:33:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-31 02:33:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:33:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 7234}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:35:09: Evaluate 5 random ConvNet, ACCmean = 0.7767 ACCstd = 0.0026
-------------------------
2024-10-31 02:35:09: Evaluate 5 random ConvNet, SENmean = 0.7734 SENstd = 0.0014
-------------------------
2024-10-31 02:35:09: Evaluate 5 random ConvNet, SPEmean = 0.9774 SPEstd = 0.0003
-------------------------
2024-10-31 02:35:09: Evaluate 5 random ConvNet, F!mean = 0.7651 F!std = 0.0016
-------------------------
2024-10-31 02:35:09: Evaluate 5 random ConvNet, mean = 0.7767 std = 0.0026
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:35:10: [2024-10-31 02:35:10] iter = 16000, loss = 1.8950
2024-10-31 02:35:13: [2024-10-31 02:35:13] iter = 16010, loss = 2.0043
2024-10-31 02:35:15: [2024-10-31 02:35:15] iter = 16020, loss = 3.2788
2024-10-31 02:35:18: [2024-10-31 02:35:18] iter = 16030, loss = 1.8253
2024-10-31 02:35:20: [2024-10-31 02:35:20] iter = 16040, loss = 1.7292
2024-10-31 02:35:23: [2024-10-31 02:35:23] iter = 16050, loss = 1.9390
2024-10-31 02:35:26: [2024-10-31 02:35:26] iter = 16060, loss = 1.7343
2024-10-31 02:35:29: [2024-10-31 02:35:29] iter = 16070, loss = 1.6435
2024-10-31 02:35:32: [2024-10-31 02:35:32] iter = 16080, loss = 1.9988
2024-10-31 02:35:35: [2024-10-31 02:35:35] iter = 16090, loss = 2.3119
2024-10-31 02:35:38: [2024-10-31 02:35:38] iter = 16100, loss = 1.9013
2024-10-31 02:35:41: [2024-10-31 02:35:41] iter = 16110, loss = 1.9800
2024-10-31 02:35:44: [2024-10-31 02:35:44] iter = 16120, loss = 1.8772
2024-10-31 02:35:46: [2024-10-31 02:35:46] iter = 16130, loss = 3.1767
2024-10-31 02:35:49: [2024-10-31 02:35:49] iter = 16140, loss = 1.9721
2024-10-31 02:35:52: [2024-10-31 02:35:52] iter = 16150, loss = 1.8002
2024-10-31 02:35:55: [2024-10-31 02:35:55] iter = 16160, loss = 4.0007
2024-10-31 02:35:58: [2024-10-31 02:35:58] iter = 16170, loss = 1.9815
2024-10-31 02:36:01: [2024-10-31 02:36:01] iter = 16180, loss = 1.7397
2024-10-31 02:36:04: [2024-10-31 02:36:04] iter = 16190, loss = 1.8348
2024-10-31 02:36:08: [2024-10-31 02:36:08] iter = 16200, loss = 2.0252
2024-10-31 02:36:11: [2024-10-31 02:36:11] iter = 16210, loss = 1.8005
2024-10-31 02:36:14: [2024-10-31 02:36:14] iter = 16220, loss = 2.6773
2024-10-31 02:36:17: [2024-10-31 02:36:17] iter = 16230, loss = 2.3938
2024-10-31 02:36:20: [2024-10-31 02:36:20] iter = 16240, loss = 3.1258
2024-10-31 02:36:23: [2024-10-31 02:36:23] iter = 16250, loss = 1.8077
2024-10-31 02:36:27: [2024-10-31 02:36:27] iter = 16260, loss = 2.1080
2024-10-31 02:36:29: [2024-10-31 02:36:29] iter = 16270, loss = 1.5285
2024-10-31 02:36:32: [2024-10-31 02:36:32] iter = 16280, loss = 2.1293
2024-10-31 02:36:34: [2024-10-31 02:36:34] iter = 16290, loss = 1.9975
2024-10-31 02:36:38: [2024-10-31 02:36:38] iter = 16300, loss = 2.0430
2024-10-31 02:36:41: [2024-10-31 02:36:41] iter = 16310, loss = 2.5740
2024-10-31 02:36:43: [2024-10-31 02:36:43] iter = 16320, loss = 1.8718
2024-10-31 02:36:46: [2024-10-31 02:36:46] iter = 16330, loss = 2.1446
2024-10-31 02:36:49: [2024-10-31 02:36:49] iter = 16340, loss = 2.8401
2024-10-31 02:36:52: [2024-10-31 02:36:52] iter = 16350, loss = 3.0163
2024-10-31 02:36:55: [2024-10-31 02:36:55] iter = 16360, loss = 3.0143
2024-10-31 02:36:57: [2024-10-31 02:36:57] iter = 16370, loss = 3.2614
2024-10-31 02:37:00: [2024-10-31 02:37:00] iter = 16380, loss = 2.0652
2024-10-31 02:37:02: [2024-10-31 02:37:02] iter = 16390, loss = 1.8184
2024-10-31 02:37:05: [2024-10-31 02:37:05] iter = 16400, loss = 2.3392
2024-10-31 02:37:07: [2024-10-31 02:37:07] iter = 16410, loss = 1.9626
2024-10-31 02:37:10: [2024-10-31 02:37:10] iter = 16420, loss = 1.7428
2024-10-31 02:37:13: [2024-10-31 02:37:13] iter = 16430, loss = 2.7666
2024-10-31 02:37:16: [2024-10-31 02:37:16] iter = 16440, loss = 2.4144
2024-10-31 02:37:18: [2024-10-31 02:37:18] iter = 16450, loss = 3.3192
2024-10-31 02:37:21: [2024-10-31 02:37:21] iter = 16460, loss = 2.7169
2024-10-31 02:37:24: [2024-10-31 02:37:24] iter = 16470, loss = 1.5541
2024-10-31 02:37:26: [2024-10-31 02:37:26] iter = 16480, loss = 1.8722
2024-10-31 02:37:29: [2024-10-31 02:37:29] iter = 16490, loss = 1.8626
2024-10-31 02:37:31: [2024-10-31 02:37:31] iter = 16500, loss = 1.8651
2024-10-31 02:37:34: [2024-10-31 02:37:34] iter = 16510, loss = 2.2223
2024-10-31 02:37:37: [2024-10-31 02:37:37] iter = 16520, loss = 3.0628
2024-10-31 02:37:40: [2024-10-31 02:37:40] iter = 16530, loss = 2.4976
2024-10-31 02:37:42: [2024-10-31 02:37:42] iter = 16540, loss = 1.8934
2024-10-31 02:37:46: [2024-10-31 02:37:46] iter = 16550, loss = 1.6739
2024-10-31 02:37:48: [2024-10-31 02:37:48] iter = 16560, loss = 1.6126
2024-10-31 02:37:51: [2024-10-31 02:37:51] iter = 16570, loss = 2.7987
2024-10-31 02:37:53: [2024-10-31 02:37:53] iter = 16580, loss = 1.7760
2024-10-31 02:37:55: [2024-10-31 02:37:55] iter = 16590, loss = 1.6942
2024-10-31 02:37:57: [2024-10-31 02:37:57] iter = 16600, loss = 7.0852
2024-10-31 02:38:00: [2024-10-31 02:38:00] iter = 16610, loss = 1.8157
2024-10-31 02:38:03: [2024-10-31 02:38:03] iter = 16620, loss = 2.1869
2024-10-31 02:38:05: [2024-10-31 02:38:05] iter = 16630, loss = 2.6199
2024-10-31 02:38:07: [2024-10-31 02:38:07] iter = 16640, loss = 1.9750
2024-10-31 02:38:10: [2024-10-31 02:38:10] iter = 16650, loss = 5.1848
2024-10-31 02:38:12: [2024-10-31 02:38:12] iter = 16660, loss = 3.0225
2024-10-31 02:38:15: [2024-10-31 02:38:15] iter = 16670, loss = 2.4789
2024-10-31 02:38:17: [2024-10-31 02:38:17] iter = 16680, loss = 2.1056
2024-10-31 02:38:20: [2024-10-31 02:38:20] iter = 16690, loss = 2.4240
2024-10-31 02:38:23: [2024-10-31 02:38:23] iter = 16700, loss = 2.1565
2024-10-31 02:38:25: [2024-10-31 02:38:25] iter = 16710, loss = 2.3712
2024-10-31 02:38:28: [2024-10-31 02:38:28] iter = 16720, loss = 2.3024
2024-10-31 02:38:30: [2024-10-31 02:38:30] iter = 16730, loss = 1.5962
2024-10-31 02:38:33: [2024-10-31 02:38:33] iter = 16740, loss = 2.5264
2024-10-31 02:38:35: [2024-10-31 02:38:35] iter = 16750, loss = 2.0245
2024-10-31 02:38:39: [2024-10-31 02:38:39] iter = 16760, loss = 2.3523
2024-10-31 02:38:41: [2024-10-31 02:38:41] iter = 16770, loss = 3.0301
2024-10-31 02:38:45: [2024-10-31 02:38:45] iter = 16780, loss = 3.0975
2024-10-31 02:38:47: [2024-10-31 02:38:47] iter = 16790, loss = 2.9686
2024-10-31 02:38:50: [2024-10-31 02:38:50] iter = 16800, loss = 2.0357
2024-10-31 02:38:52: [2024-10-31 02:38:52] iter = 16810, loss = 1.8685
2024-10-31 02:38:55: [2024-10-31 02:38:55] iter = 16820, loss = 1.9717
2024-10-31 02:38:58: [2024-10-31 02:38:58] iter = 16830, loss = 1.9750
2024-10-31 02:39:01: [2024-10-31 02:39:01] iter = 16840, loss = 1.7373
2024-10-31 02:39:04: [2024-10-31 02:39:04] iter = 16850, loss = 1.5275
2024-10-31 02:39:07: [2024-10-31 02:39:07] iter = 16860, loss = 6.9867
2024-10-31 02:39:10: [2024-10-31 02:39:10] iter = 16870, loss = 2.7580
2024-10-31 02:39:14: [2024-10-31 02:39:14] iter = 16880, loss = 2.3781
2024-10-31 02:39:17: [2024-10-31 02:39:17] iter = 16890, loss = 1.8807
2024-10-31 02:39:19: [2024-10-31 02:39:19] iter = 16900, loss = 2.5408
2024-10-31 02:39:21: [2024-10-31 02:39:21] iter = 16910, loss = 2.0213
2024-10-31 02:39:24: [2024-10-31 02:39:24] iter = 16920, loss = 2.1193
2024-10-31 02:39:26: [2024-10-31 02:39:26] iter = 16930, loss = 1.6381
2024-10-31 02:39:29: [2024-10-31 02:39:29] iter = 16940, loss = 1.7953
2024-10-31 02:39:32: [2024-10-31 02:39:32] iter = 16950, loss = 2.2495
2024-10-31 02:39:35: [2024-10-31 02:39:35] iter = 16960, loss = 1.8616
2024-10-31 02:39:37: [2024-10-31 02:39:37] iter = 16970, loss = 2.1854
2024-10-31 02:39:40: [2024-10-31 02:39:40] iter = 16980, loss = 2.4545
2024-10-31 02:39:43: [2024-10-31 02:39:43] iter = 16990, loss = 1.8776
2024-10-31 02:39:46: [2024-10-31 02:39:46] iter = 17000, loss = 2.2566
2024-10-31 02:39:49: [2024-10-31 02:39:49] iter = 17010, loss = 1.6935
2024-10-31 02:39:52: [2024-10-31 02:39:52] iter = 17020, loss = 2.0946
2024-10-31 02:39:55: [2024-10-31 02:39:55] iter = 17030, loss = 2.0644
2024-10-31 02:39:57: [2024-10-31 02:39:57] iter = 17040, loss = 2.6393
2024-10-31 02:40:00: [2024-10-31 02:40:00] iter = 17050, loss = 5.8904
2024-10-31 02:40:03: [2024-10-31 02:40:03] iter = 17060, loss = 2.6000
2024-10-31 02:40:06: [2024-10-31 02:40:06] iter = 17070, loss = 1.4997
2024-10-31 02:40:09: [2024-10-31 02:40:09] iter = 17080, loss = 1.7158
2024-10-31 02:40:12: [2024-10-31 02:40:12] iter = 17090, loss = 1.8877
2024-10-31 02:40:14: [2024-10-31 02:40:14] iter = 17100, loss = 1.6585
2024-10-31 02:40:17: [2024-10-31 02:40:17] iter = 17110, loss = 1.6853
2024-10-31 02:40:20: [2024-10-31 02:40:20] iter = 17120, loss = 1.9519
2024-10-31 02:40:22: [2024-10-31 02:40:22] iter = 17130, loss = 2.0026
2024-10-31 02:40:25: [2024-10-31 02:40:25] iter = 17140, loss = 2.9207
2024-10-31 02:40:28: [2024-10-31 02:40:28] iter = 17150, loss = 4.2437
2024-10-31 02:40:31: [2024-10-31 02:40:31] iter = 17160, loss = 1.5720
2024-10-31 02:40:34: [2024-10-31 02:40:34] iter = 17170, loss = 2.2610
2024-10-31 02:40:38: [2024-10-31 02:40:38] iter = 17180, loss = 1.6495
2024-10-31 02:40:40: [2024-10-31 02:40:40] iter = 17190, loss = 2.3545
2024-10-31 02:40:43: [2024-10-31 02:40:42] iter = 17200, loss = 2.2601
2024-10-31 02:40:45: [2024-10-31 02:40:45] iter = 17210, loss = 2.0388
2024-10-31 02:40:47: [2024-10-31 02:40:47] iter = 17220, loss = 1.9386
2024-10-31 02:40:49: [2024-10-31 02:40:49] iter = 17230, loss = 2.1982
2024-10-31 02:40:52: [2024-10-31 02:40:52] iter = 17240, loss = 1.9125
2024-10-31 02:40:55: [2024-10-31 02:40:55] iter = 17250, loss = 2.0463
2024-10-31 02:40:57: [2024-10-31 02:40:57] iter = 17260, loss = 2.0736
2024-10-31 02:41:00: [2024-10-31 02:41:00] iter = 17270, loss = 2.1911
2024-10-31 02:41:02: [2024-10-31 02:41:02] iter = 17280, loss = 2.0034
2024-10-31 02:41:04: [2024-10-31 02:41:04] iter = 17290, loss = 3.2434
2024-10-31 02:41:07: [2024-10-31 02:41:07] iter = 17300, loss = 2.1898
2024-10-31 02:41:10: [2024-10-31 02:41:10] iter = 17310, loss = 2.1962
2024-10-31 02:41:12: [2024-10-31 02:41:12] iter = 17320, loss = 4.4990
2024-10-31 02:41:15: [2024-10-31 02:41:15] iter = 17330, loss = 2.3119
2024-10-31 02:41:17: [2024-10-31 02:41:17] iter = 17340, loss = 2.1317
2024-10-31 02:41:20: [2024-10-31 02:41:20] iter = 17350, loss = 1.8752
2024-10-31 02:41:22: [2024-10-31 02:41:22] iter = 17360, loss = 2.5164
2024-10-31 02:41:25: [2024-10-31 02:41:25] iter = 17370, loss = 1.6832
2024-10-31 02:41:28: [2024-10-31 02:41:28] iter = 17380, loss = 1.8992
2024-10-31 02:41:31: [2024-10-31 02:41:31] iter = 17390, loss = 1.8512
2024-10-31 02:41:33: [2024-10-31 02:41:33] iter = 17400, loss = 3.1181
2024-10-31 02:41:36: [2024-10-31 02:41:36] iter = 17410, loss = 2.0449
2024-10-31 02:41:38: [2024-10-31 02:41:38] iter = 17420, loss = 1.8324
2024-10-31 02:41:40: [2024-10-31 02:41:40] iter = 17430, loss = 2.1687
2024-10-31 02:41:43: [2024-10-31 02:41:43] iter = 17440, loss = 2.2061
2024-10-31 02:41:45: [2024-10-31 02:41:45] iter = 17450, loss = 2.3379
2024-10-31 02:41:48: [2024-10-31 02:41:48] iter = 17460, loss = 2.9754
2024-10-31 02:41:50: [2024-10-31 02:41:50] iter = 17470, loss = 2.8279
2024-10-31 02:41:53: [2024-10-31 02:41:53] iter = 17480, loss = 3.1655
2024-10-31 02:41:55: [2024-10-31 02:41:55] iter = 17490, loss = 2.5704
2024-10-31 02:41:58: [2024-10-31 02:41:58] iter = 17500, loss = 2.5884
2024-10-31 02:42:01: [2024-10-31 02:42:01] iter = 17510, loss = 2.6646
2024-10-31 02:42:03: [2024-10-31 02:42:03] iter = 17520, loss = 2.3885
2024-10-31 02:42:05: [2024-10-31 02:42:05] iter = 17530, loss = 1.6519
2024-10-31 02:42:08: [2024-10-31 02:42:08] iter = 17540, loss = 1.7712
2024-10-31 02:42:10: [2024-10-31 02:42:10] iter = 17550, loss = 2.2881
2024-10-31 02:42:13: [2024-10-31 02:42:13] iter = 17560, loss = 2.8993
2024-10-31 02:42:15: [2024-10-31 02:42:15] iter = 17570, loss = 2.4692
2024-10-31 02:42:18: [2024-10-31 02:42:18] iter = 17580, loss = 1.8977
2024-10-31 02:42:21: [2024-10-31 02:42:21] iter = 17590, loss = 1.9694
2024-10-31 02:42:23: [2024-10-31 02:42:23] iter = 17600, loss = 1.9429
2024-10-31 02:42:26: [2024-10-31 02:42:26] iter = 17610, loss = 1.8789
2024-10-31 02:42:29: [2024-10-31 02:42:29] iter = 17620, loss = 2.1733
2024-10-31 02:42:31: [2024-10-31 02:42:31] iter = 17630, loss = 3.0005
2024-10-31 02:42:34: [2024-10-31 02:42:34] iter = 17640, loss = 1.6220
2024-10-31 02:42:37: [2024-10-31 02:42:37] iter = 17650, loss = 1.9510
2024-10-31 02:42:40: [2024-10-31 02:42:40] iter = 17660, loss = 2.0274
2024-10-31 02:42:42: [2024-10-31 02:42:42] iter = 17670, loss = 2.3669
2024-10-31 02:42:44: [2024-10-31 02:42:44] iter = 17680, loss = 1.7799
2024-10-31 02:42:47: [2024-10-31 02:42:47] iter = 17690, loss = 1.6769
2024-10-31 02:42:49: [2024-10-31 02:42:49] iter = 17700, loss = 1.9186
2024-10-31 02:42:52: [2024-10-31 02:42:52] iter = 17710, loss = 1.9643
2024-10-31 02:42:54: [2024-10-31 02:42:54] iter = 17720, loss = 1.7694
2024-10-31 02:42:57: [2024-10-31 02:42:57] iter = 17730, loss = 2.8164
2024-10-31 02:43:00: [2024-10-31 02:43:00] iter = 17740, loss = 2.0822
2024-10-31 02:43:02: [2024-10-31 02:43:02] iter = 17750, loss = 2.4301
2024-10-31 02:43:05: [2024-10-31 02:43:05] iter = 17760, loss = 1.7938
2024-10-31 02:43:08: [2024-10-31 02:43:08] iter = 17770, loss = 1.9178
2024-10-31 02:43:11: [2024-10-31 02:43:11] iter = 17780, loss = 2.6377
2024-10-31 02:43:13: [2024-10-31 02:43:13] iter = 17790, loss = 2.5256
2024-10-31 02:43:16: [2024-10-31 02:43:16] iter = 17800, loss = 3.8210
2024-10-31 02:43:18: [2024-10-31 02:43:18] iter = 17810, loss = 1.6933
2024-10-31 02:43:21: [2024-10-31 02:43:21] iter = 17820, loss = 2.3487
2024-10-31 02:43:23: [2024-10-31 02:43:23] iter = 17830, loss = 2.0691
2024-10-31 02:43:27: [2024-10-31 02:43:27] iter = 17840, loss = 2.0284
2024-10-31 02:43:29: [2024-10-31 02:43:29] iter = 17850, loss = 1.9009
2024-10-31 02:43:32: [2024-10-31 02:43:32] iter = 17860, loss = 1.9846
2024-10-31 02:43:34: [2024-10-31 02:43:34] iter = 17870, loss = 1.9101
2024-10-31 02:43:36: [2024-10-31 02:43:36] iter = 17880, loss = 1.9225
2024-10-31 02:43:39: [2024-10-31 02:43:39] iter = 17890, loss = 2.7997
2024-10-31 02:43:42: [2024-10-31 02:43:41] iter = 17900, loss = 2.3081
2024-10-31 02:43:44: [2024-10-31 02:43:44] iter = 17910, loss = 2.3019
2024-10-31 02:43:47: [2024-10-31 02:43:47] iter = 17920, loss = 1.9147
2024-10-31 02:43:50: [2024-10-31 02:43:50] iter = 17930, loss = 1.8479
2024-10-31 02:43:52: [2024-10-31 02:43:52] iter = 17940, loss = 1.9862
2024-10-31 02:43:55: [2024-10-31 02:43:55] iter = 17950, loss = 2.0876
2024-10-31 02:43:58: [2024-10-31 02:43:58] iter = 17960, loss = 2.0613
2024-10-31 02:44:01: [2024-10-31 02:44:01] iter = 17970, loss = 1.9165
2024-10-31 02:44:04: [2024-10-31 02:44:04] iter = 17980, loss = 2.0760
2024-10-31 02:44:06: [2024-10-31 02:44:06] iter = 17990, loss = 2.1318
2024-10-31 02:44:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-31 02:44:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:44:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49212}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:45:45: Evaluate 5 random ConvNet, ACCmean = 0.7746 ACCstd = 0.0012
-------------------------
2024-10-31 02:45:45: Evaluate 5 random ConvNet, SENmean = 0.7727 SENstd = 0.0018
-------------------------
2024-10-31 02:45:45: Evaluate 5 random ConvNet, SPEmean = 0.9772 SPEstd = 0.0001
-------------------------
2024-10-31 02:45:45: Evaluate 5 random ConvNet, F!mean = 0.7656 F!std = 0.0018
-------------------------
2024-10-31 02:45:45: Evaluate 5 random ConvNet, mean = 0.7746 std = 0.0012
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:45:45: [2024-10-31 02:45:45] iter = 18000, loss = 3.2632
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:45:48: [2024-10-31 02:45:48] iter = 18010, loss = 2.7748
2024-10-31 02:45:50: [2024-10-31 02:45:50] iter = 18020, loss = 2.0198
2024-10-31 02:45:52: [2024-10-31 02:45:52] iter = 18030, loss = 1.7720
2024-10-31 02:45:55: [2024-10-31 02:45:55] iter = 18040, loss = 2.5878
2024-10-31 02:45:57: [2024-10-31 02:45:57] iter = 18050, loss = 1.6533
2024-10-31 02:46:00: [2024-10-31 02:46:00] iter = 18060, loss = 1.8536
2024-10-31 02:46:02: [2024-10-31 02:46:02] iter = 18070, loss = 2.2486
2024-10-31 02:46:04: [2024-10-31 02:46:04] iter = 18080, loss = 1.9937
2024-10-31 02:46:06: [2024-10-31 02:46:06] iter = 18090, loss = 1.9128
2024-10-31 02:46:08: [2024-10-31 02:46:08] iter = 18100, loss = 1.9895
2024-10-31 02:46:11: [2024-10-31 02:46:11] iter = 18110, loss = 1.9429
2024-10-31 02:46:13: [2024-10-31 02:46:13] iter = 18120, loss = 2.3028
2024-10-31 02:46:15: [2024-10-31 02:46:15] iter = 18130, loss = 2.0994
2024-10-31 02:46:17: [2024-10-31 02:46:17] iter = 18140, loss = 2.1902
2024-10-31 02:46:19: [2024-10-31 02:46:19] iter = 18150, loss = 2.2486
2024-10-31 02:46:21: [2024-10-31 02:46:21] iter = 18160, loss = 2.5974
2024-10-31 02:46:24: [2024-10-31 02:46:24] iter = 18170, loss = 1.8209
2024-10-31 02:46:26: [2024-10-31 02:46:26] iter = 18180, loss = 2.3916
2024-10-31 02:46:29: [2024-10-31 02:46:29] iter = 18190, loss = 2.2329
2024-10-31 02:46:32: [2024-10-31 02:46:32] iter = 18200, loss = 1.9982
2024-10-31 02:46:34: [2024-10-31 02:46:34] iter = 18210, loss = 2.9212
2024-10-31 02:46:37: [2024-10-31 02:46:37] iter = 18220, loss = 2.7815
2024-10-31 02:46:39: [2024-10-31 02:46:39] iter = 18230, loss = 3.1245
2024-10-31 02:46:41: [2024-10-31 02:46:41] iter = 18240, loss = 2.1680
2024-10-31 02:46:44: [2024-10-31 02:46:44] iter = 18250, loss = 2.3055
2024-10-31 02:46:46: [2024-10-31 02:46:46] iter = 18260, loss = 1.7787
2024-10-31 02:46:48: [2024-10-31 02:46:48] iter = 18270, loss = 3.6999
2024-10-31 02:46:51: [2024-10-31 02:46:51] iter = 18280, loss = 3.2150
2024-10-31 02:46:53: [2024-10-31 02:46:53] iter = 18290, loss = 1.7032
2024-10-31 02:46:56: [2024-10-31 02:46:56] iter = 18300, loss = 1.9457
2024-10-31 02:46:58: [2024-10-31 02:46:58] iter = 18310, loss = 2.3275
2024-10-31 02:47:00: [2024-10-31 02:47:00] iter = 18320, loss = 1.8730
2024-10-31 02:47:02: [2024-10-31 02:47:02] iter = 18330, loss = 1.7256
2024-10-31 02:47:05: [2024-10-31 02:47:05] iter = 18340, loss = 2.9915
2024-10-31 02:47:07: [2024-10-31 02:47:07] iter = 18350, loss = 1.9860
2024-10-31 02:47:09: [2024-10-31 02:47:09] iter = 18360, loss = 1.8627
2024-10-31 02:47:11: [2024-10-31 02:47:11] iter = 18370, loss = 2.3246
2024-10-31 02:47:14: [2024-10-31 02:47:14] iter = 18380, loss = 1.8332
2024-10-31 02:47:16: [2024-10-31 02:47:16] iter = 18390, loss = 1.9017
2024-10-31 02:47:19: [2024-10-31 02:47:19] iter = 18400, loss = 2.3233
2024-10-31 02:47:21: [2024-10-31 02:47:21] iter = 18410, loss = 2.1179
2024-10-31 02:47:24: [2024-10-31 02:47:24] iter = 18420, loss = 1.8191
2024-10-31 02:47:26: [2024-10-31 02:47:26] iter = 18430, loss = 1.9236
2024-10-31 02:47:29: [2024-10-31 02:47:29] iter = 18440, loss = 1.6362
2024-10-31 02:47:31: [2024-10-31 02:47:31] iter = 18450, loss = 1.8059
2024-10-31 02:47:34: [2024-10-31 02:47:34] iter = 18460, loss = 2.1313
2024-10-31 02:47:36: [2024-10-31 02:47:36] iter = 18470, loss = 2.2814
2024-10-31 02:47:39: [2024-10-31 02:47:39] iter = 18480, loss = 1.9338
2024-10-31 02:47:41: [2024-10-31 02:47:41] iter = 18490, loss = 1.6038
2024-10-31 02:47:44: [2024-10-31 02:47:44] iter = 18500, loss = 1.8076
2024-10-31 02:47:47: [2024-10-31 02:47:47] iter = 18510, loss = 2.0114
2024-10-31 02:47:50: [2024-10-31 02:47:50] iter = 18520, loss = 3.4402
2024-10-31 02:47:52: [2024-10-31 02:47:52] iter = 18530, loss = 2.1164
2024-10-31 02:47:55: [2024-10-31 02:47:55] iter = 18540, loss = 1.6388
2024-10-31 02:47:58: [2024-10-31 02:47:58] iter = 18550, loss = 1.8732
2024-10-31 02:48:01: [2024-10-31 02:48:01] iter = 18560, loss = 2.5541
2024-10-31 02:48:03: [2024-10-31 02:48:03] iter = 18570, loss = 3.4288
2024-10-31 02:48:05: [2024-10-31 02:48:05] iter = 18580, loss = 2.2124
2024-10-31 02:48:07: [2024-10-31 02:48:07] iter = 18590, loss = 1.9807
2024-10-31 02:48:10: [2024-10-31 02:48:10] iter = 18600, loss = 1.7381
2024-10-31 02:48:12: [2024-10-31 02:48:12] iter = 18610, loss = 2.5056
2024-10-31 02:48:15: [2024-10-31 02:48:15] iter = 18620, loss = 1.9340
2024-10-31 02:48:17: [2024-10-31 02:48:17] iter = 18630, loss = 2.4418
2024-10-31 02:48:20: [2024-10-31 02:48:20] iter = 18640, loss = 1.7717
2024-10-31 02:48:22: [2024-10-31 02:48:22] iter = 18650, loss = 2.0419
2024-10-31 02:48:25: [2024-10-31 02:48:25] iter = 18660, loss = 1.8303
2024-10-31 02:48:28: [2024-10-31 02:48:28] iter = 18670, loss = 1.8210
2024-10-31 02:48:30: [2024-10-31 02:48:30] iter = 18680, loss = 1.7509
2024-10-31 02:48:33: [2024-10-31 02:48:33] iter = 18690, loss = 3.0773
2024-10-31 02:48:36: [2024-10-31 02:48:36] iter = 18700, loss = 2.0169
2024-10-31 02:48:38: [2024-10-31 02:48:38] iter = 18710, loss = 2.2540
2024-10-31 02:48:41: [2024-10-31 02:48:41] iter = 18720, loss = 2.5690
2024-10-31 02:48:44: [2024-10-31 02:48:44] iter = 18730, loss = 1.8331
2024-10-31 02:48:47: [2024-10-31 02:48:47] iter = 18740, loss = 2.5273
2024-10-31 02:48:49: [2024-10-31 02:48:49] iter = 18750, loss = 1.8806
2024-10-31 02:48:52: [2024-10-31 02:48:52] iter = 18760, loss = 3.5097
2024-10-31 02:48:54: [2024-10-31 02:48:54] iter = 18770, loss = 1.5633
2024-10-31 02:48:56: [2024-10-31 02:48:56] iter = 18780, loss = 1.8867
2024-10-31 02:48:59: [2024-10-31 02:48:59] iter = 18790, loss = 1.6408
2024-10-31 02:49:02: [2024-10-31 02:49:02] iter = 18800, loss = 2.2761
2024-10-31 02:49:04: [2024-10-31 02:49:04] iter = 18810, loss = 1.9348
2024-10-31 02:49:07: [2024-10-31 02:49:07] iter = 18820, loss = 2.1689
2024-10-31 02:49:10: [2024-10-31 02:49:10] iter = 18830, loss = 1.8764
2024-10-31 02:49:12: [2024-10-31 02:49:12] iter = 18840, loss = 3.0010
2024-10-31 02:49:15: [2024-10-31 02:49:15] iter = 18850, loss = 1.8000
2024-10-31 02:49:17: [2024-10-31 02:49:17] iter = 18860, loss = 1.6113
2024-10-31 02:49:20: [2024-10-31 02:49:20] iter = 18870, loss = 2.0830
2024-10-31 02:49:23: [2024-10-31 02:49:23] iter = 18880, loss = 1.8724
2024-10-31 02:49:26: [2024-10-31 02:49:26] iter = 18890, loss = 1.7090
2024-10-31 02:49:29: [2024-10-31 02:49:29] iter = 18900, loss = 4.0053
2024-10-31 02:49:32: [2024-10-31 02:49:32] iter = 18910, loss = 3.9183
2024-10-31 02:49:35: [2024-10-31 02:49:35] iter = 18920, loss = 1.9231
2024-10-31 02:49:37: [2024-10-31 02:49:37] iter = 18930, loss = 2.0001
2024-10-31 02:49:40: [2024-10-31 02:49:40] iter = 18940, loss = 2.2999
2024-10-31 02:49:43: [2024-10-31 02:49:43] iter = 18950, loss = 1.9984
2024-10-31 02:49:46: [2024-10-31 02:49:46] iter = 18960, loss = 2.5724
2024-10-31 02:49:48: [2024-10-31 02:49:48] iter = 18970, loss = 2.0725
2024-10-31 02:49:51: [2024-10-31 02:49:51] iter = 18980, loss = 3.0211
2024-10-31 02:49:54: [2024-10-31 02:49:54] iter = 18990, loss = 2.0682
2024-10-31 02:49:56: [2024-10-31 02:49:56] iter = 19000, loss = 6.4798
2024-10-31 02:49:59: [2024-10-31 02:49:59] iter = 19010, loss = 1.6758
2024-10-31 02:50:02: [2024-10-31 02:50:02] iter = 19020, loss = 2.0715
2024-10-31 02:50:05: [2024-10-31 02:50:05] iter = 19030, loss = 2.6117
2024-10-31 02:50:07: [2024-10-31 02:50:07] iter = 19040, loss = 2.3090
2024-10-31 02:50:10: [2024-10-31 02:50:10] iter = 19050, loss = 2.0793
2024-10-31 02:50:13: [2024-10-31 02:50:13] iter = 19060, loss = 1.8568
2024-10-31 02:50:16: [2024-10-31 02:50:16] iter = 19070, loss = 4.1403
2024-10-31 02:50:19: [2024-10-31 02:50:19] iter = 19080, loss = 1.8743
2024-10-31 02:50:21: [2024-10-31 02:50:21] iter = 19090, loss = 2.2092
2024-10-31 02:50:24: [2024-10-31 02:50:24] iter = 19100, loss = 2.6421
2024-10-31 02:50:27: [2024-10-31 02:50:27] iter = 19110, loss = 2.2729
2024-10-31 02:50:30: [2024-10-31 02:50:30] iter = 19120, loss = 1.8460
2024-10-31 02:50:32: [2024-10-31 02:50:32] iter = 19130, loss = 1.9219
2024-10-31 02:50:35: [2024-10-31 02:50:35] iter = 19140, loss = 2.5576
2024-10-31 02:50:38: [2024-10-31 02:50:38] iter = 19150, loss = 2.0771
2024-10-31 02:50:40: [2024-10-31 02:50:40] iter = 19160, loss = 1.9989
2024-10-31 02:50:43: [2024-10-31 02:50:43] iter = 19170, loss = 1.6623
2024-10-31 02:50:45: [2024-10-31 02:50:45] iter = 19180, loss = 2.1101
2024-10-31 02:50:48: [2024-10-31 02:50:48] iter = 19190, loss = 1.7667
2024-10-31 02:50:51: [2024-10-31 02:50:51] iter = 19200, loss = 2.1774
2024-10-31 02:50:54: [2024-10-31 02:50:54] iter = 19210, loss = 2.9380
2024-10-31 02:50:56: [2024-10-31 02:50:56] iter = 19220, loss = 2.1682
2024-10-31 02:50:59: [2024-10-31 02:50:59] iter = 19230, loss = 1.7102
2024-10-31 02:51:01: [2024-10-31 02:51:01] iter = 19240, loss = 2.6229
2024-10-31 02:51:04: [2024-10-31 02:51:04] iter = 19250, loss = 2.0379
2024-10-31 02:51:06: [2024-10-31 02:51:06] iter = 19260, loss = 1.5200
2024-10-31 02:51:09: [2024-10-31 02:51:09] iter = 19270, loss = 1.6573
2024-10-31 02:51:11: [2024-10-31 02:51:11] iter = 19280, loss = 2.1794
2024-10-31 02:51:13: [2024-10-31 02:51:13] iter = 19290, loss = 2.4078
2024-10-31 02:51:16: [2024-10-31 02:51:16] iter = 19300, loss = 1.8278
2024-10-31 02:51:19: [2024-10-31 02:51:19] iter = 19310, loss = 1.8501
2024-10-31 02:51:22: [2024-10-31 02:51:22] iter = 19320, loss = 1.8180
2024-10-31 02:51:24: [2024-10-31 02:51:24] iter = 19330, loss = 3.6509
2024-10-31 02:51:26: [2024-10-31 02:51:26] iter = 19340, loss = 2.0975
2024-10-31 02:51:28: [2024-10-31 02:51:28] iter = 19350, loss = 1.7829
2024-10-31 02:51:30: [2024-10-31 02:51:30] iter = 19360, loss = 1.9007
2024-10-31 02:51:33: [2024-10-31 02:51:33] iter = 19370, loss = 2.6423
2024-10-31 02:51:36: [2024-10-31 02:51:36] iter = 19380, loss = 2.0625
2024-10-31 02:51:38: [2024-10-31 02:51:38] iter = 19390, loss = 2.4320
2024-10-31 02:51:41: [2024-10-31 02:51:41] iter = 19400, loss = 3.4907
2024-10-31 02:51:43: [2024-10-31 02:51:43] iter = 19410, loss = 1.7611
2024-10-31 02:51:46: [2024-10-31 02:51:46] iter = 19420, loss = 2.2267
2024-10-31 02:51:49: [2024-10-31 02:51:49] iter = 19430, loss = 2.1515
2024-10-31 02:51:52: [2024-10-31 02:51:52] iter = 19440, loss = 4.4162
2024-10-31 02:51:54: [2024-10-31 02:51:54] iter = 19450, loss = 2.2700
2024-10-31 02:51:56: [2024-10-31 02:51:56] iter = 19460, loss = 1.7452
2024-10-31 02:51:59: [2024-10-31 02:51:59] iter = 19470, loss = 2.7273
2024-10-31 02:52:02: [2024-10-31 02:52:02] iter = 19480, loss = 1.6861
2024-10-31 02:52:05: [2024-10-31 02:52:05] iter = 19490, loss = 1.9294
2024-10-31 02:52:08: [2024-10-31 02:52:08] iter = 19500, loss = 2.0808
2024-10-31 02:52:11: [2024-10-31 02:52:11] iter = 19510, loss = 2.0782
2024-10-31 02:52:13: [2024-10-31 02:52:13] iter = 19520, loss = 2.3707
2024-10-31 02:52:16: [2024-10-31 02:52:16] iter = 19530, loss = 2.5176
2024-10-31 02:52:19: [2024-10-31 02:52:19] iter = 19540, loss = 2.4541
2024-10-31 02:52:22: [2024-10-31 02:52:22] iter = 19550, loss = 1.6814
2024-10-31 02:52:25: [2024-10-31 02:52:25] iter = 19560, loss = 1.9111
2024-10-31 02:52:28: [2024-10-31 02:52:28] iter = 19570, loss = 2.4553
2024-10-31 02:52:30: [2024-10-31 02:52:30] iter = 19580, loss = 2.4464
2024-10-31 02:52:33: [2024-10-31 02:52:33] iter = 19590, loss = 1.8989
2024-10-31 02:52:36: [2024-10-31 02:52:36] iter = 19600, loss = 1.9859
2024-10-31 02:52:40: [2024-10-31 02:52:40] iter = 19610, loss = 2.0520
2024-10-31 02:52:42: [2024-10-31 02:52:42] iter = 19620, loss = 2.4800
2024-10-31 02:52:45: [2024-10-31 02:52:45] iter = 19630, loss = 2.1547
2024-10-31 02:52:48: [2024-10-31 02:52:48] iter = 19640, loss = 1.6959
2024-10-31 02:52:51: [2024-10-31 02:52:51] iter = 19650, loss = 1.9925
2024-10-31 02:52:54: [2024-10-31 02:52:54] iter = 19660, loss = 2.4031
2024-10-31 02:52:57: [2024-10-31 02:52:57] iter = 19670, loss = 1.6537
2024-10-31 02:52:59: [2024-10-31 02:52:59] iter = 19680, loss = 5.0912
2024-10-31 02:53:01: [2024-10-31 02:53:01] iter = 19690, loss = 2.9559
2024-10-31 02:53:04: [2024-10-31 02:53:04] iter = 19700, loss = 2.0210
2024-10-31 02:53:07: [2024-10-31 02:53:07] iter = 19710, loss = 2.2066
2024-10-31 02:53:09: [2024-10-31 02:53:09] iter = 19720, loss = 1.8764
2024-10-31 02:53:12: [2024-10-31 02:53:12] iter = 19730, loss = 2.4746
2024-10-31 02:53:15: [2024-10-31 02:53:15] iter = 19740, loss = 2.5710
2024-10-31 02:53:17: [2024-10-31 02:53:17] iter = 19750, loss = 1.9653
2024-10-31 02:53:20: [2024-10-31 02:53:20] iter = 19760, loss = 2.0908
2024-10-31 02:53:23: [2024-10-31 02:53:23] iter = 19770, loss = 1.6786
2024-10-31 02:53:25: [2024-10-31 02:53:25] iter = 19780, loss = 1.9748
2024-10-31 02:53:27: [2024-10-31 02:53:27] iter = 19790, loss = 2.1650
2024-10-31 02:53:30: [2024-10-31 02:53:30] iter = 19800, loss = 1.7802
2024-10-31 02:53:33: [2024-10-31 02:53:33] iter = 19810, loss = 1.6485
2024-10-31 02:53:35: [2024-10-31 02:53:35] iter = 19820, loss = 1.9478
2024-10-31 02:53:38: [2024-10-31 02:53:38] iter = 19830, loss = 2.1942
2024-10-31 02:53:40: [2024-10-31 02:53:40] iter = 19840, loss = 2.0526
2024-10-31 02:53:43: [2024-10-31 02:53:43] iter = 19850, loss = 2.2621
2024-10-31 02:53:46: [2024-10-31 02:53:46] iter = 19860, loss = 2.0723
2024-10-31 02:53:49: [2024-10-31 02:53:49] iter = 19870, loss = 3.1615
2024-10-31 02:53:51: [2024-10-31 02:53:51] iter = 19880, loss = 1.9367
2024-10-31 02:53:54: [2024-10-31 02:53:54] iter = 19890, loss = 1.8197
2024-10-31 02:53:56: [2024-10-31 02:53:56] iter = 19900, loss = 1.7273
2024-10-31 02:53:59: [2024-10-31 02:53:59] iter = 19910, loss = 1.6251
2024-10-31 02:54:02: [2024-10-31 02:54:02] iter = 19920, loss = 1.7712
2024-10-31 02:54:04: [2024-10-31 02:54:04] iter = 19930, loss = 1.8215
2024-10-31 02:54:07: [2024-10-31 02:54:07] iter = 19940, loss = 2.8014
2024-10-31 02:54:10: [2024-10-31 02:54:10] iter = 19950, loss = 1.7834
2024-10-31 02:54:13: [2024-10-31 02:54:13] iter = 19960, loss = 2.3088
2024-10-31 02:54:15: [2024-10-31 02:54:15] iter = 19970, loss = 2.6638
2024-10-31 02:54:18: [2024-10-31 02:54:18] iter = 19980, loss = 2.5603
2024-10-31 02:54:20: [2024-10-31 02:54:20] iter = 19990, loss = 2.0099
2024-10-31 02:54:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-31 02:54:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:54:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62763}

[2024-10-31 01:07:40] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.012952 train acc = 1.0000, test acc = 0.7725, test_sen =0.7698, test_spe =0.9770, test_f1 =0.7609
[2024-10-31 01:19:27] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.003851 train acc = 1.0000, test acc = 0.7734, test_sen =0.7711, test_spe =0.9771, test_f1 =0.7622
[2024-10-31 01:19:54] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.027262 train acc = 1.0000, test acc = 0.7791, test_sen =0.7733, test_spe =0.9776, test_f1 =0.7674
[2024-10-31 01:20:20] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.016699 train acc = 1.0000, test acc = 0.7774, test_sen =0.7720, test_spe =0.9775, test_f1 =0.7652
[2024-10-31 01:20:41] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.009665 train acc = 1.0000, test acc = 0.7825, test_sen =0.7764, test_spe =0.9780, test_f1 =0.7694
[2024-10-31 01:21:08] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.010576 train acc = 1.0000, test acc = 0.7694, test_sen =0.7675, test_spe =0.9766, test_f1 =0.7594
[2024-10-31 01:32:53] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.004364 train acc = 1.0000, test acc = 0.7774, test_sen =0.7748, test_spe =0.9774, test_f1 =0.7677
[2024-10-31 01:33:17] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.010529 train acc = 1.0000, test acc = 0.7879, test_sen =0.7850, test_spe =0.9785, test_f1 =0.7779
[2024-10-31 01:33:40] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.003212 train acc = 1.0000, test acc = 0.7832, test_sen =0.7754, test_spe =0.9779, test_f1 =0.7718
[2024-10-31 01:34:00] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.003512 train acc = 1.0000, test acc = 0.7864, test_sen =0.7760, test_spe =0.9782, test_f1 =0.7734
[2024-10-31 01:34:22] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.009824 train acc = 1.0000, test acc = 0.7883, test_sen =0.7828, test_spe =0.9785, test_f1 =0.7757
[2024-10-31 01:45:36] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.030910 train acc = 1.0000, test acc = 0.7838, test_sen =0.7736, test_spe =0.9781, test_f1 =0.7705
[2024-10-31 01:45:58] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.010113 train acc = 1.0000, test acc = 0.7778, test_sen =0.7691, test_spe =0.9775, test_f1 =0.7643
[2024-10-31 01:46:23] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.009833 train acc = 1.0000, test acc = 0.7767, test_sen =0.7710, test_spe =0.9774, test_f1 =0.7651
[2024-10-31 01:46:47] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.004056 train acc = 1.0000, test acc = 0.7818, test_sen =0.7700, test_spe =0.9779, test_f1 =0.7665
[2024-10-31 01:47:10] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.003692 train acc = 1.0000, test acc = 0.7806, test_sen =0.7691, test_spe =0.9778, test_f1 =0.7651
[2024-10-31 01:58:13] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.003221 train acc = 1.0000, test acc = 0.7731, test_sen =0.7634, test_spe =0.9769, test_f1 =0.7588
[2024-10-31 01:58:36] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.003417 train acc = 1.0000, test acc = 0.7730, test_sen =0.7670, test_spe =0.9770, test_f1 =0.7590
[2024-10-31 01:59:03] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.011770 train acc = 1.0000, test acc = 0.7784, test_sen =0.7690, test_spe =0.9775, test_f1 =0.7648
[2024-10-31 01:59:27] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.003039 train acc = 1.0000, test acc = 0.7740, test_sen =0.7645, test_spe =0.9770, test_f1 =0.7589
[2024-10-31 01:59:51] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.003608 train acc = 1.0000, test acc = 0.7829, test_sen =0.7744, test_spe =0.9779, test_f1 =0.7698
[2024-10-31 02:11:10] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.022523 train acc = 1.0000, test acc = 0.7832, test_sen =0.7783, test_spe =0.9780, test_f1 =0.7718
[2024-10-31 02:11:32] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.008455 train acc = 1.0000, test acc = 0.7771, test_sen =0.7736, test_spe =0.9774, test_f1 =0.7656
[2024-10-31 02:11:53] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.020740 train acc = 1.0000, test acc = 0.7812, test_sen =0.7784, test_spe =0.9779, test_f1 =0.7695
[2024-10-31 02:12:14] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.011912 train acc = 1.0000, test acc = 0.7810, test_sen =0.7764, test_spe =0.9778, test_f1 =0.7697
[2024-10-31 02:12:38] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.011308 train acc = 1.0000, test acc = 0.7825, test_sen =0.7779, test_spe =0.9780, test_f1 =0.7701
[2024-10-31 02:22:30] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.004364 train acc = 1.0000, test acc = 0.7846, test_sen =0.7765, test_spe =0.9782, test_f1 =0.7716
[2024-10-31 02:22:52] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.006668 train acc = 1.0000, test acc = 0.7849, test_sen =0.7755, test_spe =0.9781, test_f1 =0.7697
[2024-10-31 02:23:14] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.004756 train acc = 1.0000, test acc = 0.7894, test_sen =0.7833, test_spe =0.9788, test_f1 =0.7736
[2024-10-31 02:23:36] Evaluate_03: epoch = 1000 train time = 21 s train loss = 0.031842 train acc = 1.0000, test acc = 0.7904, test_sen =0.7797, test_spe =0.9788, test_f1 =0.7742
[2024-10-31 02:23:57] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.010893 train acc = 1.0000, test acc = 0.7852, test_sen =0.7802, test_spe =0.9783, test_f1 =0.7716
[2024-10-31 02:33:48] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.020071 train acc = 1.0000, test acc = 0.7806, test_sen =0.7760, test_spe =0.9777, test_f1 =0.7676
[2024-10-31 02:34:08] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.004567 train acc = 1.0000, test acc = 0.7725, test_sen =0.7718, test_spe =0.9770, test_f1 =0.7627
[2024-10-31 02:34:28] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.009193 train acc = 1.0000, test acc = 0.7776, test_sen =0.7726, test_spe =0.9775, test_f1 =0.7649
[2024-10-31 02:34:46] Evaluate_03: epoch = 1000 train time = 16 s train loss = 0.027601 train acc = 0.9909, test acc = 0.7767, test_sen =0.7733, test_spe =0.9775, test_f1 =0.7647
[2024-10-31 02:35:09] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.002885 train acc = 1.0000, test acc = 0.7763, test_sen =0.7734, test_spe =0.9774, test_f1 =0.7656
[2024-10-31 02:44:29] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.004134 train acc = 1.0000, test acc = 0.7736, test_sen =0.7718, test_spe =0.9771, test_f1 =0.7643
[2024-10-31 02:44:49] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.012080 train acc = 1.0000, test acc = 0.7764, test_sen =0.7758, test_spe =0.9773, test_f1 =0.7690
[2024-10-31 02:45:09] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.013019 train acc = 1.0000, test acc = 0.7745, test_sen =0.7720, test_spe =0.9771, test_f1 =0.7644
[2024-10-31 02:45:27] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.009166 train acc = 1.0000, test acc = 0.7753, test_sen =0.7705, test_spe =0.9772, test_f1 =0.7659
[2024-10-31 02:45:45] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.015386 train acc = 1.0000, test acc = 0.7732, test_sen =0.7733, test_spe =0.9770, test_f1 =0.7646
[2024-10-31 02:54:40] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.020502 train acc = 1.0000, test acc = 0.7678, test_sen =0.7625, test_spe =0.9764, test_f1 =0.7575
[2024-10-31 02:55:01] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.002899 train acc = 1.0000, test acc = 0.7701, test_sen =0.7666, test_spe =0.9767, test_f1 =0.7588
[2024-10-31 02:55:21] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.013066 train acc = 1.0000, test acc = 0.7835, test_sen =0.7812, test_spe =0.9781, test_f1 =0.7734
[2024-10-31 02:55:40] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.005147 train acc = 1.0000, test acc = 0.7762, test_sen =0.7715, test_spe =0.9773, test_f1 =0.7657
[2024-10-31 02:55:57] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.003014 train acc = 1.0000, test acc = 0.7799, test_sen =0.7752, test_spe =0.9778, test_f1 =0.7675/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:55:57: Evaluate 5 random ConvNet, ACCmean = 0.7755 ACCstd = 0.0059
-------------------------
2024-10-31 02:55:57: Evaluate 5 random ConvNet, SENmean = 0.7714 SENstd = 0.0065
-------------------------
2024-10-31 02:55:57: Evaluate 5 random ConvNet, SPEmean = 0.9773 SPEstd = 0.0006
-------------------------
2024-10-31 02:55:57: Evaluate 5 random ConvNet, F!mean = 0.7646 F!std = 0.0058
-------------------------
2024-10-31 02:55:57: Evaluate 5 random ConvNet, mean = 0.7755 std = 0.0059
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:55:58: [2024-10-31 02:55:58] iter = 20000, loss = 1.8546
2024-10-31 02:55:58: 
==================== Final Results ====================

2024-10-31 02:55:58: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 77.84%  std = 0.65%

