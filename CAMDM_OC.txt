nohup: ignoring input
2024-11-21 10:34:02: eval_it_pool: [0, 500, 1000]
2024-11-21 10:34:05: 
================== Exp 0 ==================
 
2024-11-21 10:34:05: Hyper-parameters: 
{'method': 'DC', 'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faa221d7a60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_TissueMNIST (INFO)>}
2024-11-21 10:34:05: Evaluation model pool: ['ConvNet']
2024-11-21 10:34:13: class c = 0: 53075 real images
2024-11-21 10:34:13: class c = 1: 7814 real images
2024-11-21 10:34:13: class c = 2: 5866 real images
2024-11-21 10:34:13: class c = 3: 15406 real images
2024-11-21 10:34:13: class c = 4: 11789 real images
2024-11-21 10:34:13: class c = 5: 7705 real images
2024-11-21 10:34:13: class c = 6: 39203 real images
2024-11-21 10:34:13: class c = 7: 24608 real images
2024-11-21 10:34:13: real images channel 0, mean = 0.1020, std = 0.1000
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_base.py:125: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 10:34:13: initialize synthetic data from random noise
2024-11-21 10:34:13: [2024-11-21 10:34:13] training begins
2024-11-21 10:34:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 10:34:13: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 10:34:28: Evaluate 5 random ConvNet, ACCmean = 0.1200 ACCstd = 0.0260
-------------------------
2024-11-21 10:34:28: Evaluate 5 random ConvNet, F1mean = 0.0809 F!std = 0.0116
-------------------------
2024-11-21 10:34:32: [2024-11-21 10:34:32] iter = 0000, loss = 256.1619
2024-11-21 10:35:12: [2024-11-21 10:35:12] iter = 0010, loss = 136.1009
2024-11-21 10:35:52: [2024-11-21 10:35:52] iter = 0020, loss = 99.7150
2024-11-21 10:36:34: [2024-11-21 10:36:34] iter = 0030, loss = 78.7583
2024-11-21 10:37:14: [2024-11-21 10:37:14] iter = 0040, loss = 72.6890
2024-11-21 10:37:52: [2024-11-21 10:37:52] iter = 0050, loss = 66.6551
2024-11-21 10:38:31: [2024-11-21 10:38:31] iter = 0060, loss = 58.5222
2024-11-21 10:39:10: [2024-11-21 10:39:10] iter = 0070, loss = 59.4804
2024-11-21 10:39:49: [2024-11-21 10:39:49] iter = 0080, loss = 55.2385
2024-11-21 10:40:28: [2024-11-21 10:40:28] iter = 0090, loss = 54.3398
2024-11-21 10:41:07: [2024-11-21 10:41:07] iter = 0100, loss = 53.0566
2024-11-21 10:41:46: [2024-11-21 10:41:46] iter = 0110, loss = 51.2022
2024-11-21 10:42:24: [2024-11-21 10:42:24] iter = 0120, loss = 50.5751
2024-11-21 10:43:02: [2024-11-21 10:43:02] iter = 0130, loss = 48.5915
2024-11-21 10:43:40: [2024-11-21 10:43:40] iter = 0140, loss = 47.9493
2024-11-21 10:44:18: [2024-11-21 10:44:18] iter = 0150, loss = 48.6813
2024-11-21 10:44:57: [2024-11-21 10:44:57] iter = 0160, loss = 47.9109
2024-11-21 10:45:35: [2024-11-21 10:45:35] iter = 0170, loss = 45.6331
2024-11-21 10:46:13: [2024-11-21 10:46:13] iter = 0180, loss = 43.5867
2024-11-21 10:46:51: [2024-11-21 10:46:51] iter = 0190, loss = 43.2875
2024-11-21 10:47:29: [2024-11-21 10:47:29] iter = 0200, loss = 41.2337
2024-11-21 10:48:08: [2024-11-21 10:48:08] iter = 0210, loss = 43.9202
2024-11-21 10:48:46: [2024-11-21 10:48:46] iter = 0220, loss = 43.8728
2024-11-21 10:49:25: [2024-11-21 10:49:25] iter = 0230, loss = 44.8314
2024-11-21 10:50:04: [2024-11-21 10:50:04] iter = 0240, loss = 42.9977
2024-11-21 10:50:42: [2024-11-21 10:50:42] iter = 0250, loss = 45.1614
2024-11-21 10:51:21: [2024-11-21 10:51:21] iter = 0260, loss = 43.0015
2024-11-21 10:52:00: [2024-11-21 10:52:00] iter = 0270, loss = 42.2345
2024-11-21 10:52:38: [2024-11-21 10:52:38] iter = 0280, loss = 41.8112
2024-11-21 10:53:16: [2024-11-21 10:53:16] iter = 0290, loss = 43.9498
2024-11-21 10:53:55: [2024-11-21 10:53:55] iter = 0300, loss = 40.7709
2024-11-21 10:54:33: [2024-11-21 10:54:33] iter = 0310, loss = 43.2507
2024-11-21 10:55:12: [2024-11-21 10:55:12] iter = 0320, loss = 41.7561
2024-11-21 10:55:51: [2024-11-21 10:55:51] iter = 0330, loss = 42.2136
2024-11-21 10:56:29: [2024-11-21 10:56:29] iter = 0340, loss = 43.3169
2024-11-21 10:57:07: [2024-11-21 10:57:07] iter = 0350, loss = 43.3322
2024-11-21 10:57:45: [2024-11-21 10:57:45] iter = 0360, loss = 40.8257
2024-11-21 10:58:23: [2024-11-21 10:58:23] iter = 0370, loss = 42.6679
2024-11-21 10:59:02: [2024-11-21 10:59:02] iter = 0380, loss = 41.8698
2024-11-21 10:59:39: [2024-11-21 10:59:39] iter = 0390, loss = 41.3887
2024-11-21 11:00:17: [2024-11-21 11:00:17] iter = 0400, loss = 42.6136
2024-11-21 11:00:55: [2024-11-21 11:00:55] iter = 0410, loss = 43.4101
2024-11-21 11:01:35: [2024-11-21 11:01:35] iter = 0420, loss = 44.5482
2024-11-21 11:02:13: [2024-11-21 11:02:13] iter = 0430, loss = 44.3774
2024-11-21 11:02:52: [2024-11-21 11:02:52] iter = 0440, loss = 42.6923
2024-11-21 11:03:31: [2024-11-21 11:03:31] iter = 0450, loss = 43.6371
2024-11-21 11:04:09: [2024-11-21 11:04:09] iter = 0460, loss = 42.2021
2024-11-21 11:04:46: [2024-11-21 11:04:46] iter = 0470, loss = 42.9469
2024-11-21 11:05:25: [2024-11-21 11:05:25] iter = 0480, loss = 43.9242
2024-11-21 11:06:04: [2024-11-21 11:06:04] iter = 0490, loss = 43.7211
2024-11-21 11:06:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 11:06:39: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 11:06:51: Evaluate 5 random ConvNet, ACCmean = 0.3491 ACCstd = 0.0182
-------------------------
2024-11-21 11:06:51: Evaluate 5 random ConvNet, F1mean = 0.2830 F!std = 0.0072
-------------------------
2024-11-21 11:06:55: [2024-11-21 11:06:55] iter = 0500, loss = 41.1659
2024-11-21 11:07:34: [2024-11-21 11:07:34] iter = 0510, loss = 42.9639
2024-11-21 11:08:11: [2024-11-21 11:08:11] iter = 0520, loss = 44.1461
2024-11-21 11:08:50: [2024-11-21 11:08:50] iter = 0530, loss = 45.5813
2024-11-21 11:09:27: [2024-11-21 11:09:27] iter = 0540, loss = 43.1293
2024-11-21 11:10:05: [2024-11-21 11:10:05] iter = 0550, loss = 46.4172
2024-11-21 11:10:43: [2024-11-21 11:10:43] iter = 0560, loss = 42.7494
2024-11-21 11:11:21: [2024-11-21 11:11:21] iter = 0570, loss = 43.6181
2024-11-21 11:12:00: [2024-11-21 11:12:00] iter = 0580, loss = 43.9908
2024-11-21 11:12:37: [2024-11-21 11:12:37] iter = 0590, loss = 43.5966
2024-11-21 11:13:15: [2024-11-21 11:13:15] iter = 0600, loss = 42.4306
2024-11-21 11:13:54: [2024-11-21 11:13:54] iter = 0610, loss = 44.4631
2024-11-21 11:14:33: [2024-11-21 11:14:33] iter = 0620, loss = 39.0994
2024-11-21 11:15:11: [2024-11-21 11:15:11] iter = 0630, loss = 43.2692
2024-11-21 11:15:50: [2024-11-21 11:15:50] iter = 0640, loss = 42.3769
2024-11-21 11:16:27: [2024-11-21 11:16:27] iter = 0650, loss = 43.4238
2024-11-21 11:17:05: [2024-11-21 11:17:05] iter = 0660, loss = 45.1440
2024-11-21 11:17:43: [2024-11-21 11:17:43] iter = 0670, loss = 41.4528
2024-11-21 11:18:21: [2024-11-21 11:18:21] iter = 0680, loss = 41.4704
2024-11-21 11:19:00: [2024-11-21 11:19:00] iter = 0690, loss = 43.8218
2024-11-21 11:19:40: [2024-11-21 11:19:40] iter = 0700, loss = 44.4189
2024-11-21 11:20:19: [2024-11-21 11:20:19] iter = 0710, loss = 44.6267
2024-11-21 11:20:57: [2024-11-21 11:20:57] iter = 0720, loss = 43.9420
2024-11-21 11:21:33: [2024-11-21 11:21:33] iter = 0730, loss = 44.4850
2024-11-21 11:22:11: [2024-11-21 11:22:11] iter = 0740, loss = 44.4345
2024-11-21 11:22:49: [2024-11-21 11:22:49] iter = 0750, loss = 43.4765
2024-11-21 11:23:28: [2024-11-21 11:23:28] iter = 0760, loss = 42.2192
2024-11-21 11:24:05: [2024-11-21 11:24:05] iter = 0770, loss = 44.1177
2024-11-21 11:24:45: [2024-11-21 11:24:45] iter = 0780, loss = 42.1470
2024-11-21 11:25:22: [2024-11-21 11:25:22] iter = 0790, loss = 44.2221
2024-11-21 11:26:01: [2024-11-21 11:26:01] iter = 0800, loss = 43.1111
2024-11-21 11:26:40: [2024-11-21 11:26:40] iter = 0810, loss = 44.3829
2024-11-21 11:27:19: [2024-11-21 11:27:19] iter = 0820, loss = 42.0927
2024-11-21 11:27:57: [2024-11-21 11:27:57] iter = 0830, loss = 43.3475
2024-11-21 11:28:35: [2024-11-21 11:28:35] iter = 0840, loss = 42.7029
2024-11-21 11:29:13: [2024-11-21 11:29:13] iter = 0850, loss = 43.6853
2024-11-21 11:29:51: [2024-11-21 11:29:51] iter = 0860, loss = 43.0484
2024-11-21 11:30:29: [2024-11-21 11:30:29] iter = 0870, loss = 44.8478
2024-11-21 11:31:07: [2024-11-21 11:31:07] iter = 0880, loss = 41.9901
2024-11-21 11:31:45: [2024-11-21 11:31:45] iter = 0890, loss = 43.7735
2024-11-21 11:32:24: [2024-11-21 11:32:24] iter = 0900, loss = 43.2909
2024-11-21 11:33:03: [2024-11-21 11:33:03] iter = 0910, loss = 42.3023
2024-11-21 11:33:41: [2024-11-21 11:33:41] iter = 0920, loss = 44.4653
2024-11-21 11:34:19: [2024-11-21 11:34:19] iter = 0930, loss = 43.3534
2024-11-21 11:34:57: [2024-11-21 11:34:57] iter = 0940, loss = 42.5097
2024-11-21 11:35:35: [2024-11-21 11:35:35] iter = 0950, loss = 45.2675
2024-11-21 11:36:14: [2024-11-21 11:36:14] iter = 0960, loss = 44.5646
2024-11-21 11:36:52: [2024-11-21 11:36:52] iter = 0970, loss = 43.3211
2024-11-21 11:37:30: [2024-11-21 11:37:30] iter = 0980, loss = 42.5262
2024-11-21 11:38:08: [2024-11-21 11:38:08] iter = 0990, loss = 44.7403
2024-11-21 11:38:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 11:38:43: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 11:38:55: Evaluate 5 random ConvNet, ACCmean = 0.3645 ACCstd = 0.0129
-------------------------
2024-11-21 11:38:55: Evaluate 5 random ConvNet, F1mean = 0.2911 F!std = 0.0074
-------------------------
2024-11-21 11:38:59: [2024-11-21 11:38:59] iter = 1000, loss = 45.4094
2024-11-21 11:38:59: 
================== Exp 1 ==================
 
2024-11-21 11:38:59: Hyper-parameters: 
{'method': 'DC', 'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faa221d7a60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_TissueMNIST (INFO)>, 'dc_aug_param': None}
2024-11-21 11:38:59: Evaluation model pool: ['ConvNet']
2024-11-21 11:39:03: class c = 0: 53075 real images
2024-11-21 11:39:03: class c = 1: 7814 real images
2024-11-21 11:39:03: class c = 2: 5866 real images
2024-11-21 11:39:03: class c = 3: 15406 real images
2024-11-21 11:39:03: class c = 4: 11789 real images
2024-11-21 11:39:03: class c = 5: 7705 real images
2024-11-21 11:39:03: class c = 6: 39203 real images
2024-11-21 11:39:03: class c = 7: 24608 real images
2024-11-21 11:39:03: real images channel 0, mean = 0.1020, std = 0.1000
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 11:39:03: initialize synthetic data from random noise
2024-11-21 11:39:03: [2024-11-21 11:39:03] training begins
2024-11-21 11:39:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 11:39:03: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 11:39:15: Evaluate 5 random ConvNet, ACCmean = 0.1192 ACCstd = 0.0229
-------------------------
2024-11-21 11:39:15: Evaluate 5 random ConvNet, F1mean = 0.0864 F!std = 0.0075
-------------------------
2024-11-21 11:39:19: [2024-11-21 11:39:19] iter = 0000, loss = 259.7468
2024-11-21 11:39:57: [2024-11-21 11:39:57] iter = 0010, loss = 131.4218
2024-11-21 11:40:35: [2024-11-21 11:40:35] iter = 0020, loss = 93.5860
2024-11-21 11:41:12: [2024-11-21 11:41:12] iter = 0030, loss = 73.4700
2024-11-21 11:41:50: [2024-11-21 11:41:50] iter = 0040, loss = 65.8230
2024-11-21 11:42:28: [2024-11-21 11:42:28] iter = 0050, loss = 61.0287
2024-11-21 11:43:06: [2024-11-21 11:43:06] iter = 0060, loss = 59.0498
2024-11-21 11:43:44: [2024-11-21 11:43:44] iter = 0070, loss = 56.7865
2024-11-21 11:44:23: [2024-11-21 11:44:23] iter = 0080, loss = 55.2202
2024-11-21 11:45:02: [2024-11-21 11:45:02] iter = 0090, loss = 51.9305
2024-11-21 11:45:41: [2024-11-21 11:45:41] iter = 0100, loss = 51.2622
2024-11-21 11:46:17: [2024-11-21 11:46:17] iter = 0110, loss = 48.3490
2024-11-21 11:46:54: [2024-11-21 11:46:54] iter = 0120, loss = 52.5702
2024-11-21 11:47:30: [2024-11-21 11:47:30] iter = 0130, loss = 48.9460
2024-11-21 11:48:08: [2024-11-21 11:48:08] iter = 0140, loss = 47.6545
2024-11-21 11:48:45: [2024-11-21 11:48:45] iter = 0150, loss = 47.5709
2024-11-21 11:49:24: [2024-11-21 11:49:24] iter = 0160, loss = 45.3077
2024-11-21 11:50:02: [2024-11-21 11:50:02] iter = 0170, loss = 43.9298
2024-11-21 11:50:39: [2024-11-21 11:50:39] iter = 0180, loss = 45.2561
2024-11-21 11:51:16: [2024-11-21 11:51:16] iter = 0190, loss = 45.2217
2024-11-21 11:51:54: [2024-11-21 11:51:54] iter = 0200, loss = 44.1869
2024-11-21 11:52:32: [2024-11-21 11:52:32] iter = 0210, loss = 45.6999
2024-11-21 11:53:10: [2024-11-21 11:53:10] iter = 0220, loss = 44.2067
2024-11-21 11:53:48: [2024-11-21 11:53:48] iter = 0230, loss = 43.4047
2024-11-21 11:54:25: [2024-11-21 11:54:25] iter = 0240, loss = 43.5964
2024-11-21 11:55:03: [2024-11-21 11:55:03] iter = 0250, loss = 43.2186
2024-11-21 11:55:41: [2024-11-21 11:55:41] iter = 0260, loss = 45.2657
2024-11-21 11:56:19: [2024-11-21 11:56:19] iter = 0270, loss = 42.2931
2024-11-21 11:56:56: [2024-11-21 11:56:56] iter = 0280, loss = 41.4560
2024-11-21 11:57:34: [2024-11-21 11:57:34] iter = 0290, loss = 43.8500
2024-11-21 11:58:12: [2024-11-21 11:58:12] iter = 0300, loss = 43.3530
2024-11-21 11:58:50: [2024-11-21 11:58:50] iter = 0310, loss = 44.3372
2024-11-21 11:59:28: [2024-11-21 11:59:28] iter = 0320, loss = 41.3146
2024-11-21 12:00:05: [2024-11-21 12:00:05] iter = 0330, loss = 41.0212
2024-11-21 12:00:43: [2024-11-21 12:00:43] iter = 0340, loss = 43.6887
2024-11-21 12:01:21: [2024-11-21 12:01:21] iter = 0350, loss = 44.5059
2024-11-21 12:01:59: [2024-11-21 12:01:59] iter = 0360, loss = 40.9011
2024-11-21 12:02:36: [2024-11-21 12:02:36] iter = 0370, loss = 43.9440
2024-11-21 12:03:14: [2024-11-21 12:03:14] iter = 0380, loss = 40.5050
2024-11-21 12:03:52: [2024-11-21 12:03:52] iter = 0390, loss = 45.0330
2024-11-21 12:04:30: [2024-11-21 12:04:30] iter = 0400, loss = 42.0858
2024-11-21 12:05:08: [2024-11-21 12:05:08] iter = 0410, loss = 42.8085
2024-11-21 12:05:46: [2024-11-21 12:05:46] iter = 0420, loss = 42.8863
2024-11-21 12:06:23: [2024-11-21 12:06:23] iter = 0430, loss = 43.4595
2024-11-21 12:07:01: [2024-11-21 12:07:01] iter = 0440, loss = 43.3973
2024-11-21 12:07:39: [2024-11-21 12:07:39] iter = 0450, loss = 41.9658
2024-11-21 12:08:17: [2024-11-21 12:08:17] iter = 0460, loss = 43.7354
2024-11-21 12:08:55: [2024-11-21 12:08:55] iter = 0470, loss = 43.8571
2024-11-21 12:09:33: [2024-11-21 12:09:33] iter = 0480, loss = 38.7443
2024-11-21 12:10:10: [2024-11-21 12:10:10] iter = 0490, loss = 42.1973
2024-11-21 12:10:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 12:10:45: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 12:10:57: Evaluate 5 random ConvNet, ACCmean = 0.3775 ACCstd = 0.0164
-------------------------
2024-11-21 12:10:57: Evaluate 5 random ConvNet, F1mean = 0.2944 F!std = 0.0055
-------------------------
2024-11-21 12:11:01: [2024-11-21 12:11:01] iter = 0500, loss = 44.8274
2024-11-21 12:11:38: [2024-11-21 12:11:38] iter = 0510, loss = 42.9941
