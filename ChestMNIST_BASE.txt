nohup: ignoring input
2024-10-29 12:25:37: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
2024-10-29 12:25:38: 
================== Exp 0 ==================
 
2024-10-29 12:25:38: Hyper-parameters: 
{'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f20047a2730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_ChestMNIST (INFO)>}
2024-10-29 12:25:38: Evaluation model pool: ['ConvNet']
2024-10-29 12:25:42: class c = 0: 70472 real images
2024-10-29 12:25:42: class c = 1: 7996 real images
2024-10-29 12:25:42: real images channel 0, mean = 0.4936, std = 0.2380
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 12:25:42: initialize synthetic data from random real images
2024-10-29 12:25:42: [2024-10-29 12:25:42] training begins
2024-10-29 12:25:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 12:25:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:25:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:26:18: Evaluate 5 random ConvNet, ACCmean = 0.5647 ACCstd = 0.0099
-------------------------
2024-10-29 12:26:18: Evaluate 5 random ConvNet, SENmean = 0.5647 SENstd = 0.0020
-------------------------
2024-10-29 12:26:18: Evaluate 5 random ConvNet, SPEmean = 0.5647 SPEstd = 0.0020
-------------------------
2024-10-29 12:26:18: Evaluate 5 random ConvNet, F!mean = 0.4584 F!std = 0.0045
-------------------------
2024-10-29 12:26:18: Evaluate 5 random ConvNet, mean = 0.5647 std = 0.0099
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:26:18: [2024-10-29 12:26:18] iter = 00000, loss = 7.3565
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:26:19: [2024-10-29 12:26:19] iter = 00010, loss = 3.9044
2024-10-29 12:26:19: [2024-10-29 12:26:19] iter = 00020, loss = 1.4940
2024-10-29 12:26:19: [2024-10-29 12:26:19] iter = 00030, loss = 2.5710
2024-10-29 12:26:20: [2024-10-29 12:26:20] iter = 00040, loss = 3.9742
2024-10-29 12:26:20: [2024-10-29 12:26:20] iter = 00050, loss = 6.8829
2024-10-29 12:26:20: [2024-10-29 12:26:20] iter = 00060, loss = 1.4358
2024-10-29 12:26:21: [2024-10-29 12:26:21] iter = 00070, loss = 4.7447
2024-10-29 12:26:21: [2024-10-29 12:26:21] iter = 00080, loss = 1.8333
2024-10-29 12:26:21: [2024-10-29 12:26:21] iter = 00090, loss = 1.3561
2024-10-29 12:26:22: [2024-10-29 12:26:22] iter = 00100, loss = 1.4973
2024-10-29 12:26:22: [2024-10-29 12:26:22] iter = 00110, loss = 3.6985
2024-10-29 12:26:22: [2024-10-29 12:26:22] iter = 00120, loss = 2.5018
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 00130, loss = 1.3888
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 00140, loss = 1.7474
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 00150, loss = 1.8764
2024-10-29 12:26:24: [2024-10-29 12:26:24] iter = 00160, loss = 0.7825
2024-10-29 12:26:24: [2024-10-29 12:26:24] iter = 00170, loss = 1.0638
2024-10-29 12:26:25: [2024-10-29 12:26:25] iter = 00180, loss = 2.0172
2024-10-29 12:26:25: [2024-10-29 12:26:25] iter = 00190, loss = 1.5820
2024-10-29 12:26:25: [2024-10-29 12:26:25] iter = 00200, loss = 1.2706
2024-10-29 12:26:26: [2024-10-29 12:26:26] iter = 00210, loss = 1.2905
2024-10-29 12:26:26: [2024-10-29 12:26:26] iter = 00220, loss = 1.2380
2024-10-29 12:26:27: [2024-10-29 12:26:27] iter = 00230, loss = 1.2072
2024-10-29 12:26:27: [2024-10-29 12:26:27] iter = 00240, loss = 2.1385
2024-10-29 12:26:27: [2024-10-29 12:26:27] iter = 00250, loss = 1.4892
2024-10-29 12:26:28: [2024-10-29 12:26:28] iter = 00260, loss = 1.7812
2024-10-29 12:26:28: [2024-10-29 12:26:28] iter = 00270, loss = 1.0559
2024-10-29 12:26:29: [2024-10-29 12:26:29] iter = 00280, loss = 0.8358
2024-10-29 12:26:29: [2024-10-29 12:26:29] iter = 00290, loss = 1.3865
2024-10-29 12:26:29: [2024-10-29 12:26:29] iter = 00300, loss = 1.2272
2024-10-29 12:26:30: [2024-10-29 12:26:30] iter = 00310, loss = 0.9320
2024-10-29 12:26:30: [2024-10-29 12:26:30] iter = 00320, loss = 1.2692
2024-10-29 12:26:31: [2024-10-29 12:26:31] iter = 00330, loss = 1.4336
2024-10-29 12:26:31: [2024-10-29 12:26:31] iter = 00340, loss = 1.8103
2024-10-29 12:26:31: [2024-10-29 12:26:31] iter = 00350, loss = 3.0169
2024-10-29 12:26:32: [2024-10-29 12:26:32] iter = 00360, loss = 1.3557
2024-10-29 12:26:32: [2024-10-29 12:26:32] iter = 00370, loss = 1.0541
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 00380, loss = 1.0677
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 00390, loss = 1.0168
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 00400, loss = 1.1346
2024-10-29 12:26:34: [2024-10-29 12:26:34] iter = 00410, loss = 1.8930
2024-10-29 12:26:34: [2024-10-29 12:26:34] iter = 00420, loss = 1.3585
2024-10-29 12:26:35: [2024-10-29 12:26:35] iter = 00430, loss = 1.1062
2024-10-29 12:26:35: [2024-10-29 12:26:35] iter = 00440, loss = 0.7774
2024-10-29 12:26:35: [2024-10-29 12:26:35] iter = 00450, loss = 1.1348
2024-10-29 12:26:36: [2024-10-29 12:26:36] iter = 00460, loss = 1.0931
2024-10-29 12:26:36: [2024-10-29 12:26:36] iter = 00470, loss = 2.7608
2024-10-29 12:26:36: [2024-10-29 12:26:36] iter = 00480, loss = 2.0944
2024-10-29 12:26:37: [2024-10-29 12:26:37] iter = 00490, loss = 1.2730
2024-10-29 12:26:37: [2024-10-29 12:26:37] iter = 00500, loss = 1.5444
2024-10-29 12:26:38: [2024-10-29 12:26:38] iter = 00510, loss = 1.2295
2024-10-29 12:26:38: [2024-10-29 12:26:38] iter = 00520, loss = 6.5142
2024-10-29 12:26:38: [2024-10-29 12:26:38] iter = 00530, loss = 4.0608
2024-10-29 12:26:39: [2024-10-29 12:26:39] iter = 00540, loss = 2.2489
2024-10-29 12:26:39: [2024-10-29 12:26:39] iter = 00550, loss = 1.7932
2024-10-29 12:26:39: [2024-10-29 12:26:39] iter = 00560, loss = 2.5469
2024-10-29 12:26:40: [2024-10-29 12:26:40] iter = 00570, loss = 2.6230
2024-10-29 12:26:40: [2024-10-29 12:26:40] iter = 00580, loss = 0.8203
2024-10-29 12:26:40: [2024-10-29 12:26:40] iter = 00590, loss = 1.7658
2024-10-29 12:26:41: [2024-10-29 12:26:41] iter = 00600, loss = 2.6790
2024-10-29 12:26:41: [2024-10-29 12:26:41] iter = 00610, loss = 1.5673
2024-10-29 12:26:41: [2024-10-29 12:26:41] iter = 00620, loss = 1.2782
2024-10-29 12:26:42: [2024-10-29 12:26:42] iter = 00630, loss = 0.8587
2024-10-29 12:26:42: [2024-10-29 12:26:42] iter = 00640, loss = 1.2856
2024-10-29 12:26:43: [2024-10-29 12:26:43] iter = 00650, loss = 1.0055
2024-10-29 12:26:43: [2024-10-29 12:26:43] iter = 00660, loss = 0.8308
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 00670, loss = 1.8755
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 00680, loss = 3.0609
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 00690, loss = 1.1290
2024-10-29 12:26:45: [2024-10-29 12:26:45] iter = 00700, loss = 9.1408
2024-10-29 12:26:45: [2024-10-29 12:26:45] iter = 00710, loss = 1.5502
2024-10-29 12:26:46: [2024-10-29 12:26:46] iter = 00720, loss = 2.4072
2024-10-29 12:26:46: [2024-10-29 12:26:46] iter = 00730, loss = 1.4247
2024-10-29 12:26:47: [2024-10-29 12:26:47] iter = 00740, loss = 3.1824
2024-10-29 12:26:47: [2024-10-29 12:26:47] iter = 00750, loss = 1.2183
2024-10-29 12:26:47: [2024-10-29 12:26:47] iter = 00760, loss = 1.3143
2024-10-29 12:26:48: [2024-10-29 12:26:48] iter = 00770, loss = 2.1376
2024-10-29 12:26:48: [2024-10-29 12:26:48] iter = 00780, loss = 3.0170
2024-10-29 12:26:48: [2024-10-29 12:26:48] iter = 00790, loss = 1.2534
2024-10-29 12:26:49: [2024-10-29 12:26:49] iter = 00800, loss = 1.2992
2024-10-29 12:26:49: [2024-10-29 12:26:49] iter = 00810, loss = 2.0155
2024-10-29 12:26:50: [2024-10-29 12:26:50] iter = 00820, loss = 1.3597
2024-10-29 12:26:50: [2024-10-29 12:26:50] iter = 00830, loss = 1.6839
2024-10-29 12:26:50: [2024-10-29 12:26:50] iter = 00840, loss = 1.2228
2024-10-29 12:26:51: [2024-10-29 12:26:51] iter = 00850, loss = 1.4642
2024-10-29 12:26:51: [2024-10-29 12:26:51] iter = 00860, loss = 1.4453
2024-10-29 12:26:51: [2024-10-29 12:26:51] iter = 00870, loss = 1.2389
2024-10-29 12:26:52: [2024-10-29 12:26:52] iter = 00880, loss = 1.7795
2024-10-29 12:26:52: [2024-10-29 12:26:52] iter = 00890, loss = 1.5044
2024-10-29 12:26:53: [2024-10-29 12:26:53] iter = 00900, loss = 0.9865
2024-10-29 12:26:53: [2024-10-29 12:26:53] iter = 00910, loss = 1.3325
2024-10-29 12:26:54: [2024-10-29 12:26:54] iter = 00920, loss = 1.7938
2024-10-29 12:26:54: [2024-10-29 12:26:54] iter = 00930, loss = 1.3588
2024-10-29 12:26:54: [2024-10-29 12:26:54] iter = 00940, loss = 1.1885
2024-10-29 12:26:55: [2024-10-29 12:26:55] iter = 00950, loss = 4.2490
2024-10-29 12:26:55: [2024-10-29 12:26:55] iter = 00960, loss = 1.2046
2024-10-29 12:26:55: [2024-10-29 12:26:55] iter = 00970, loss = 1.4185
2024-10-29 12:26:56: [2024-10-29 12:26:56] iter = 00980, loss = 1.7894
2024-10-29 12:26:56: [2024-10-29 12:26:56] iter = 00990, loss = 4.0279
2024-10-29 12:26:57: [2024-10-29 12:26:57] iter = 01000, loss = 1.1933
2024-10-29 12:26:57: [2024-10-29 12:26:57] iter = 01010, loss = 2.6743
2024-10-29 12:26:57: [2024-10-29 12:26:57] iter = 01020, loss = 2.8563
2024-10-29 12:26:58: [2024-10-29 12:26:58] iter = 01030, loss = 1.0579
2024-10-29 12:26:58: [2024-10-29 12:26:58] iter = 01040, loss = 23.6106
2024-10-29 12:26:58: [2024-10-29 12:26:58] iter = 01050, loss = 3.1712
2024-10-29 12:26:59: [2024-10-29 12:26:59] iter = 01060, loss = 0.9230
2024-10-29 12:26:59: [2024-10-29 12:26:59] iter = 01070, loss = 1.8628
2024-10-29 12:26:59: [2024-10-29 12:26:59] iter = 01080, loss = 1.2138
2024-10-29 12:27:00: [2024-10-29 12:27:00] iter = 01090, loss = 1.4770
2024-10-29 12:27:00: [2024-10-29 12:27:00] iter = 01100, loss = 1.5944
2024-10-29 12:27:00: [2024-10-29 12:27:00] iter = 01110, loss = 3.4162
2024-10-29 12:27:01: [2024-10-29 12:27:01] iter = 01120, loss = 1.1042
2024-10-29 12:27:01: [2024-10-29 12:27:01] iter = 01130, loss = 1.8020
2024-10-29 12:27:02: [2024-10-29 12:27:02] iter = 01140, loss = 1.0374
2024-10-29 12:27:02: [2024-10-29 12:27:02] iter = 01150, loss = 2.1291
2024-10-29 12:27:03: [2024-10-29 12:27:03] iter = 01160, loss = 1.6907
2024-10-29 12:27:03: [2024-10-29 12:27:03] iter = 01170, loss = 2.6637
2024-10-29 12:27:04: [2024-10-29 12:27:04] iter = 01180, loss = 3.5384
2024-10-29 12:27:04: [2024-10-29 12:27:04] iter = 01190, loss = 1.4808
2024-10-29 12:27:05: [2024-10-29 12:27:05] iter = 01200, loss = 1.3209
2024-10-29 12:27:05: [2024-10-29 12:27:05] iter = 01210, loss = 2.2260
2024-10-29 12:27:05: [2024-10-29 12:27:05] iter = 01220, loss = 1.4552
2024-10-29 12:27:06: [2024-10-29 12:27:06] iter = 01230, loss = 0.8576
2024-10-29 12:27:06: [2024-10-29 12:27:06] iter = 01240, loss = 3.6271
2024-10-29 12:27:06: [2024-10-29 12:27:06] iter = 01250, loss = 1.4361
2024-10-29 12:27:07: [2024-10-29 12:27:07] iter = 01260, loss = 1.6873
2024-10-29 12:27:07: [2024-10-29 12:27:07] iter = 01270, loss = 1.5718
2024-10-29 12:27:08: [2024-10-29 12:27:08] iter = 01280, loss = 1.2283
2024-10-29 12:27:08: [2024-10-29 12:27:08] iter = 01290, loss = 1.0267
2024-10-29 12:27:08: [2024-10-29 12:27:08] iter = 01300, loss = 0.9391
2024-10-29 12:27:09: [2024-10-29 12:27:09] iter = 01310, loss = 2.1009
2024-10-29 12:27:09: [2024-10-29 12:27:09] iter = 01320, loss = 2.3795
2024-10-29 12:27:09: [2024-10-29 12:27:09] iter = 01330, loss = 3.8362
2024-10-29 12:27:10: [2024-10-29 12:27:10] iter = 01340, loss = 1.5799
2024-10-29 12:27:10: [2024-10-29 12:27:10] iter = 01350, loss = 4.1733
2024-10-29 12:27:11: [2024-10-29 12:27:11] iter = 01360, loss = 1.1018
2024-10-29 12:27:11: [2024-10-29 12:27:11] iter = 01370, loss = 0.9519
2024-10-29 12:27:11: [2024-10-29 12:27:11] iter = 01380, loss = 1.3195
2024-10-29 12:27:12: [2024-10-29 12:27:12] iter = 01390, loss = 1.5795
2024-10-29 12:27:12: [2024-10-29 12:27:12] iter = 01400, loss = 1.8314
2024-10-29 12:27:12: [2024-10-29 12:27:12] iter = 01410, loss = 0.7880
2024-10-29 12:27:13: [2024-10-29 12:27:13] iter = 01420, loss = 1.0817
2024-10-29 12:27:14: [2024-10-29 12:27:14] iter = 01430, loss = 1.2200
2024-10-29 12:27:14: [2024-10-29 12:27:14] iter = 01440, loss = 1.5409
2024-10-29 12:27:14: [2024-10-29 12:27:14] iter = 01450, loss = 3.4745
2024-10-29 12:27:15: [2024-10-29 12:27:15] iter = 01460, loss = 0.8469
2024-10-29 12:27:15: [2024-10-29 12:27:15] iter = 01470, loss = 1.0472
2024-10-29 12:27:15: [2024-10-29 12:27:15] iter = 01480, loss = 1.0489
2024-10-29 12:27:16: [2024-10-29 12:27:16] iter = 01490, loss = 4.0821
2024-10-29 12:27:16: [2024-10-29 12:27:16] iter = 01500, loss = 4.9688
2024-10-29 12:27:16: [2024-10-29 12:27:16] iter = 01510, loss = 1.2415
2024-10-29 12:27:17: [2024-10-29 12:27:17] iter = 01520, loss = 1.1157
2024-10-29 12:27:17: [2024-10-29 12:27:17] iter = 01530, loss = 1.3594
2024-10-29 12:27:17: [2024-10-29 12:27:17] iter = 01540, loss = 1.5123
2024-10-29 12:27:18: [2024-10-29 12:27:18] iter = 01550, loss = 2.0481
2024-10-29 12:27:18: [2024-10-29 12:27:18] iter = 01560, loss = 0.8191
2024-10-29 12:27:19: [2024-10-29 12:27:19] iter = 01570, loss = 1.3876
2024-10-29 12:27:19: [2024-10-29 12:27:19] iter = 01580, loss = 1.3212
2024-10-29 12:27:20: [2024-10-29 12:27:20] iter = 01590, loss = 1.1166
2024-10-29 12:27:20: [2024-10-29 12:27:20] iter = 01600, loss = 1.5353
2024-10-29 12:27:20: [2024-10-29 12:27:20] iter = 01610, loss = 1.4528
2024-10-29 12:27:21: [2024-10-29 12:27:21] iter = 01620, loss = 1.0406
2024-10-29 12:27:21: [2024-10-29 12:27:21] iter = 01630, loss = 1.0080
2024-10-29 12:27:22: [2024-10-29 12:27:22] iter = 01640, loss = 1.3127
2024-10-29 12:27:22: [2024-10-29 12:27:22] iter = 01650, loss = 1.0865
2024-10-29 12:27:23: [2024-10-29 12:27:23] iter = 01660, loss = 1.7394
2024-10-29 12:27:24: [2024-10-29 12:27:24] iter = 01670, loss = 1.8857
2024-10-29 12:27:24: [2024-10-29 12:27:24] iter = 01680, loss = 1.2271
2024-10-29 12:27:25: [2024-10-29 12:27:25] iter = 01690, loss = 1.7284
2024-10-29 12:27:25: [2024-10-29 12:27:25] iter = 01700, loss = 1.3804
2024-10-29 12:27:25: [2024-10-29 12:27:25] iter = 01710, loss = 3.4346
2024-10-29 12:27:26: [2024-10-29 12:27:26] iter = 01720, loss = 1.9152
2024-10-29 12:27:26: [2024-10-29 12:27:26] iter = 01730, loss = 1.4974
2024-10-29 12:27:27: [2024-10-29 12:27:27] iter = 01740, loss = 1.8617
2024-10-29 12:27:27: [2024-10-29 12:27:27] iter = 01750, loss = 1.0624
2024-10-29 12:27:28: [2024-10-29 12:27:28] iter = 01760, loss = 1.8575
2024-10-29 12:27:29: [2024-10-29 12:27:29] iter = 01770, loss = 1.7005
2024-10-29 12:27:29: [2024-10-29 12:27:29] iter = 01780, loss = 4.5656
2024-10-29 12:27:30: [2024-10-29 12:27:30] iter = 01790, loss = 1.3547
2024-10-29 12:27:31: [2024-10-29 12:27:31] iter = 01800, loss = 1.5014
2024-10-29 12:27:31: [2024-10-29 12:27:31] iter = 01810, loss = 2.2066
2024-10-29 12:27:32: [2024-10-29 12:27:32] iter = 01820, loss = 1.8280
2024-10-29 12:27:32: [2024-10-29 12:27:32] iter = 01830, loss = 1.3729
2024-10-29 12:27:32: [2024-10-29 12:27:32] iter = 01840, loss = 1.1717
2024-10-29 12:27:33: [2024-10-29 12:27:33] iter = 01850, loss = 1.5147
2024-10-29 12:27:33: [2024-10-29 12:27:33] iter = 01860, loss = 1.3817
2024-10-29 12:27:33: [2024-10-29 12:27:33] iter = 01870, loss = 1.4539
2024-10-29 12:27:34: [2024-10-29 12:27:34] iter = 01880, loss = 1.2013
2024-10-29 12:27:34: [2024-10-29 12:27:34] iter = 01890, loss = 1.9163
2024-10-29 12:27:35: [2024-10-29 12:27:35] iter = 01900, loss = 1.1693
2024-10-29 12:27:35: [2024-10-29 12:27:35] iter = 01910, loss = 1.0568
2024-10-29 12:27:35: [2024-10-29 12:27:35] iter = 01920, loss = 3.1237
2024-10-29 12:27:36: [2024-10-29 12:27:36] iter = 01930, loss = 1.4734
2024-10-29 12:27:36: [2024-10-29 12:27:36] iter = 01940, loss = 1.5846
2024-10-29 12:27:37: [2024-10-29 12:27:37] iter = 01950, loss = 1.8369
2024-10-29 12:27:37: [2024-10-29 12:27:37] iter = 01960, loss = 2.1968
2024-10-29 12:27:37: [2024-10-29 12:27:37] iter = 01970, loss = 2.4326
2024-10-29 12:27:38: [2024-10-29 12:27:38] iter = 01980, loss = 2.4883
2024-10-29 12:27:38: [2024-10-29 12:27:38] iter = 01990, loss = 1.4869
2024-10-29 12:27:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 12:27:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:27:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59032}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:28:11: Evaluate 5 random ConvNet, ACCmean = 0.5314 ACCstd = 0.0093
-------------------------
2024-10-29 12:28:11: Evaluate 5 random ConvNet, SENmean = 0.6073 SENstd = 0.0058
-------------------------
2024-10-29 12:28:11: Evaluate 5 random ConvNet, SPEmean = 0.6073 SPEstd = 0.0058
-------------------------
2024-10-29 12:28:11: Evaluate 5 random ConvNet, F!mean = 0.4525 F!std = 0.0064
-------------------------
2024-10-29 12:28:11: Evaluate 5 random ConvNet, mean = 0.5314 std = 0.0093
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:28:11: [2024-10-29 12:28:11] iter = 02000, loss = 1.3041
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:28:11: [2024-10-29 12:28:11] iter = 02010, loss = 1.4634
2024-10-29 12:28:12: [2024-10-29 12:28:12] iter = 02020, loss = 1.4892
2024-10-29 12:28:12: [2024-10-29 12:28:12] iter = 02030, loss = 1.6692
2024-10-29 12:28:13: [2024-10-29 12:28:13] iter = 02040, loss = 1.1853
2024-10-29 12:28:13: [2024-10-29 12:28:13] iter = 02050, loss = 5.7551
2024-10-29 12:28:14: [2024-10-29 12:28:14] iter = 02060, loss = 1.0676
2024-10-29 12:28:14: [2024-10-29 12:28:14] iter = 02070, loss = 1.2816
2024-10-29 12:28:15: [2024-10-29 12:28:15] iter = 02080, loss = 1.1422
2024-10-29 12:28:15: [2024-10-29 12:28:15] iter = 02090, loss = 1.3117
2024-10-29 12:28:16: [2024-10-29 12:28:16] iter = 02100, loss = 1.9329
2024-10-29 12:28:16: [2024-10-29 12:28:16] iter = 02110, loss = 2.4840
2024-10-29 12:28:17: [2024-10-29 12:28:17] iter = 02120, loss = 1.0741
2024-10-29 12:28:17: [2024-10-29 12:28:17] iter = 02130, loss = 1.7993
2024-10-29 12:28:17: [2024-10-29 12:28:17] iter = 02140, loss = 1.8426
2024-10-29 12:28:18: [2024-10-29 12:28:18] iter = 02150, loss = 4.8637
2024-10-29 12:28:18: [2024-10-29 12:28:18] iter = 02160, loss = 1.0734
2024-10-29 12:28:19: [2024-10-29 12:28:19] iter = 02170, loss = 1.3707
2024-10-29 12:28:19: [2024-10-29 12:28:19] iter = 02180, loss = 1.2213
2024-10-29 12:28:19: [2024-10-29 12:28:19] iter = 02190, loss = 0.9821
2024-10-29 12:28:20: [2024-10-29 12:28:19] iter = 02200, loss = 1.7695
2024-10-29 12:28:20: [2024-10-29 12:28:20] iter = 02210, loss = 1.0902
2024-10-29 12:28:20: [2024-10-29 12:28:20] iter = 02220, loss = 1.1327
2024-10-29 12:28:21: [2024-10-29 12:28:21] iter = 02230, loss = 2.3244
2024-10-29 12:28:21: [2024-10-29 12:28:21] iter = 02240, loss = 1.4581
2024-10-29 12:28:21: [2024-10-29 12:28:21] iter = 02250, loss = 1.3937
2024-10-29 12:28:22: [2024-10-29 12:28:22] iter = 02260, loss = 2.8219
2024-10-29 12:28:22: [2024-10-29 12:28:22] iter = 02270, loss = 1.1898
2024-10-29 12:28:23: [2024-10-29 12:28:23] iter = 02280, loss = 1.2924
2024-10-29 12:28:23: [2024-10-29 12:28:23] iter = 02290, loss = 2.2355
2024-10-29 12:28:23: [2024-10-29 12:28:23] iter = 02300, loss = 1.3965
2024-10-29 12:28:24: [2024-10-29 12:28:24] iter = 02310, loss = 0.9537
2024-10-29 12:28:24: [2024-10-29 12:28:24] iter = 02320, loss = 6.5432
2024-10-29 12:28:24: [2024-10-29 12:28:24] iter = 02330, loss = 1.3085
2024-10-29 12:28:25: [2024-10-29 12:28:25] iter = 02340, loss = 1.4993
2024-10-29 12:28:25: [2024-10-29 12:28:25] iter = 02350, loss = 2.8200
2024-10-29 12:28:25: [2024-10-29 12:28:25] iter = 02360, loss = 1.4485
2024-10-29 12:28:26: [2024-10-29 12:28:26] iter = 02370, loss = 1.3822
2024-10-29 12:28:26: [2024-10-29 12:28:26] iter = 02380, loss = 1.5680
2024-10-29 12:28:27: [2024-10-29 12:28:27] iter = 02390, loss = 1.7017
2024-10-29 12:28:27: [2024-10-29 12:28:27] iter = 02400, loss = 1.4405
2024-10-29 12:28:28: [2024-10-29 12:28:28] iter = 02410, loss = 1.1476
2024-10-29 12:28:28: [2024-10-29 12:28:28] iter = 02420, loss = 1.3756
2024-10-29 12:28:28: [2024-10-29 12:28:28] iter = 02430, loss = 0.9785
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 02440, loss = 3.5880
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 02450, loss = 0.9734
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 02460, loss = 1.2300
2024-10-29 12:28:30: [2024-10-29 12:28:30] iter = 02470, loss = 2.8042
2024-10-29 12:28:30: [2024-10-29 12:28:30] iter = 02480, loss = 1.2494
2024-10-29 12:28:30: [2024-10-29 12:28:30] iter = 02490, loss = 6.7649
2024-10-29 12:28:31: [2024-10-29 12:28:31] iter = 02500, loss = 1.7842
2024-10-29 12:28:31: [2024-10-29 12:28:31] iter = 02510, loss = 1.1665
2024-10-29 12:28:31: [2024-10-29 12:28:31] iter = 02520, loss = 1.5086
2024-10-29 12:28:32: [2024-10-29 12:28:32] iter = 02530, loss = 1.3508
2024-10-29 12:28:32: [2024-10-29 12:28:32] iter = 02540, loss = 0.8219
2024-10-29 12:28:32: [2024-10-29 12:28:32] iter = 02550, loss = 1.7929
2024-10-29 12:28:33: [2024-10-29 12:28:33] iter = 02560, loss = 1.2519
2024-10-29 12:28:33: [2024-10-29 12:28:33] iter = 02570, loss = 2.2702
2024-10-29 12:28:33: [2024-10-29 12:28:33] iter = 02580, loss = 1.2289
2024-10-29 12:28:34: [2024-10-29 12:28:34] iter = 02590, loss = 3.5111
2024-10-29 12:28:34: [2024-10-29 12:28:34] iter = 02600, loss = 3.2502
2024-10-29 12:28:35: [2024-10-29 12:28:35] iter = 02610, loss = 5.3817
2024-10-29 12:28:35: [2024-10-29 12:28:35] iter = 02620, loss = 2.0515
2024-10-29 12:28:35: [2024-10-29 12:28:35] iter = 02630, loss = 4.8268
2024-10-29 12:28:36: [2024-10-29 12:28:36] iter = 02640, loss = 1.1879
2024-10-29 12:28:36: [2024-10-29 12:28:36] iter = 02650, loss = 0.8717
2024-10-29 12:28:36: [2024-10-29 12:28:36] iter = 02660, loss = 1.7043
2024-10-29 12:28:37: [2024-10-29 12:28:37] iter = 02670, loss = 1.4367
2024-10-29 12:28:37: [2024-10-29 12:28:37] iter = 02680, loss = 1.5427
2024-10-29 12:28:37: [2024-10-29 12:28:37] iter = 02690, loss = 1.3085
2024-10-29 12:28:38: [2024-10-29 12:28:38] iter = 02700, loss = 3.1887
2024-10-29 12:28:38: [2024-10-29 12:28:38] iter = 02710, loss = 1.4376
2024-10-29 12:28:39: [2024-10-29 12:28:39] iter = 02720, loss = 1.4991
2024-10-29 12:28:39: [2024-10-29 12:28:39] iter = 02730, loss = 1.1420
2024-10-29 12:28:39: [2024-10-29 12:28:39] iter = 02740, loss = 1.0323
2024-10-29 12:28:40: [2024-10-29 12:28:40] iter = 02750, loss = 1.0911
2024-10-29 12:28:40: [2024-10-29 12:28:40] iter = 02760, loss = 1.1501
2024-10-29 12:28:40: [2024-10-29 12:28:40] iter = 02770, loss = 1.2609
2024-10-29 12:28:41: [2024-10-29 12:28:41] iter = 02780, loss = 1.9293
2024-10-29 12:28:41: [2024-10-29 12:28:41] iter = 02790, loss = 1.5779
2024-10-29 12:28:41: [2024-10-29 12:28:41] iter = 02800, loss = 0.8954
2024-10-29 12:28:42: [2024-10-29 12:28:42] iter = 02810, loss = 1.5164
2024-10-29 12:28:42: [2024-10-29 12:28:42] iter = 02820, loss = 1.1593
2024-10-29 12:28:43: [2024-10-29 12:28:43] iter = 02830, loss = 3.1342
2024-10-29 12:28:43: [2024-10-29 12:28:43] iter = 02840, loss = 1.6870
2024-10-29 12:28:44: [2024-10-29 12:28:44] iter = 02850, loss = 3.1190
2024-10-29 12:28:44: [2024-10-29 12:28:44] iter = 02860, loss = 4.3517
2024-10-29 12:28:45: [2024-10-29 12:28:44] iter = 02870, loss = 1.4715
2024-10-29 12:28:45: [2024-10-29 12:28:45] iter = 02880, loss = 1.3693
2024-10-29 12:28:45: [2024-10-29 12:28:45] iter = 02890, loss = 1.8191
2024-10-29 12:28:46: [2024-10-29 12:28:46] iter = 02900, loss = 1.1246
2024-10-29 12:28:46: [2024-10-29 12:28:46] iter = 02910, loss = 0.8744
2024-10-29 12:28:47: [2024-10-29 12:28:47] iter = 02920, loss = 2.3235
2024-10-29 12:28:47: [2024-10-29 12:28:47] iter = 02930, loss = 1.0949
2024-10-29 12:28:48: [2024-10-29 12:28:48] iter = 02940, loss = 3.0279
2024-10-29 12:28:48: [2024-10-29 12:28:48] iter = 02950, loss = 1.4108
2024-10-29 12:28:49: [2024-10-29 12:28:49] iter = 02960, loss = 6.3869
2024-10-29 12:28:49: [2024-10-29 12:28:49] iter = 02970, loss = 2.2240
2024-10-29 12:28:50: [2024-10-29 12:28:50] iter = 02980, loss = 1.7983
2024-10-29 12:28:50: [2024-10-29 12:28:50] iter = 02990, loss = 1.6697
2024-10-29 12:28:51: [2024-10-29 12:28:51] iter = 03000, loss = 1.3111
2024-10-29 12:28:51: [2024-10-29 12:28:51] iter = 03010, loss = 1.0053
2024-10-29 12:28:51: [2024-10-29 12:28:51] iter = 03020, loss = 0.8547
2024-10-29 12:28:52: [2024-10-29 12:28:52] iter = 03030, loss = 1.6415
2024-10-29 12:28:52: [2024-10-29 12:28:52] iter = 03040, loss = 1.1642
2024-10-29 12:28:53: [2024-10-29 12:28:53] iter = 03050, loss = 1.2946
2024-10-29 12:28:53: [2024-10-29 12:28:53] iter = 03060, loss = 1.4979
2024-10-29 12:28:53: [2024-10-29 12:28:53] iter = 03070, loss = 1.3364
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 03080, loss = 2.3241
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 03090, loss = 1.9266
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 03100, loss = 2.8937
2024-10-29 12:28:55: [2024-10-29 12:28:55] iter = 03110, loss = 4.0985
2024-10-29 12:28:55: [2024-10-29 12:28:55] iter = 03120, loss = 2.5216
2024-10-29 12:28:55: [2024-10-29 12:28:55] iter = 03130, loss = 1.4339
2024-10-29 12:28:56: [2024-10-29 12:28:56] iter = 03140, loss = 5.2881
2024-10-29 12:28:56: [2024-10-29 12:28:56] iter = 03150, loss = 1.5531
2024-10-29 12:28:57: [2024-10-29 12:28:57] iter = 03160, loss = 1.7111
2024-10-29 12:28:57: [2024-10-29 12:28:57] iter = 03170, loss = 2.9897
2024-10-29 12:28:57: [2024-10-29 12:28:57] iter = 03180, loss = 1.7530
2024-10-29 12:28:58: [2024-10-29 12:28:58] iter = 03190, loss = 1.3091
2024-10-29 12:28:58: [2024-10-29 12:28:58] iter = 03200, loss = 3.3115
2024-10-29 12:28:58: [2024-10-29 12:28:58] iter = 03210, loss = 6.3622
2024-10-29 12:28:59: [2024-10-29 12:28:59] iter = 03220, loss = 2.2554
2024-10-29 12:28:59: [2024-10-29 12:28:59] iter = 03230, loss = 1.2469
2024-10-29 12:29:00: [2024-10-29 12:28:59] iter = 03240, loss = 2.5889
2024-10-29 12:29:00: [2024-10-29 12:29:00] iter = 03250, loss = 1.4620
2024-10-29 12:29:01: [2024-10-29 12:29:01] iter = 03260, loss = 1.2720
2024-10-29 12:29:01: [2024-10-29 12:29:01] iter = 03270, loss = 5.6447
2024-10-29 12:29:01: [2024-10-29 12:29:01] iter = 03280, loss = 1.7492
2024-10-29 12:29:02: [2024-10-29 12:29:02] iter = 03290, loss = 1.6601
2024-10-29 12:29:02: [2024-10-29 12:29:02] iter = 03300, loss = 0.9578
2024-10-29 12:29:03: [2024-10-29 12:29:03] iter = 03310, loss = 1.1239
2024-10-29 12:29:03: [2024-10-29 12:29:03] iter = 03320, loss = 1.2572
2024-10-29 12:29:04: [2024-10-29 12:29:04] iter = 03330, loss = 1.1398
2024-10-29 12:29:04: [2024-10-29 12:29:04] iter = 03340, loss = 1.0430
2024-10-29 12:29:04: [2024-10-29 12:29:04] iter = 03350, loss = 1.9118
2024-10-29 12:29:05: [2024-10-29 12:29:05] iter = 03360, loss = 1.3386
2024-10-29 12:29:05: [2024-10-29 12:29:05] iter = 03370, loss = 1.4666
2024-10-29 12:29:06: [2024-10-29 12:29:06] iter = 03380, loss = 1.6592
2024-10-29 12:29:06: [2024-10-29 12:29:06] iter = 03390, loss = 1.0285
2024-10-29 12:29:06: [2024-10-29 12:29:06] iter = 03400, loss = 1.7039
2024-10-29 12:29:07: [2024-10-29 12:29:07] iter = 03410, loss = 0.8934
2024-10-29 12:29:07: [2024-10-29 12:29:07] iter = 03420, loss = 2.1767
2024-10-29 12:29:07: [2024-10-29 12:29:07] iter = 03430, loss = 2.1567
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 03440, loss = 2.8258
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 03450, loss = 1.4063
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 03460, loss = 1.0579
2024-10-29 12:29:09: [2024-10-29 12:29:09] iter = 03470, loss = 0.8998
2024-10-29 12:29:09: [2024-10-29 12:29:09] iter = 03480, loss = 1.1012
2024-10-29 12:29:10: [2024-10-29 12:29:10] iter = 03490, loss = 0.7359
2024-10-29 12:29:10: [2024-10-29 12:29:10] iter = 03500, loss = 1.9288
2024-10-29 12:29:10: [2024-10-29 12:29:10] iter = 03510, loss = 1.2727
2024-10-29 12:29:11: [2024-10-29 12:29:11] iter = 03520, loss = 1.2303
2024-10-29 12:29:11: [2024-10-29 12:29:11] iter = 03530, loss = 1.4169
2024-10-29 12:29:11: [2024-10-29 12:29:11] iter = 03540, loss = 3.7317
2024-10-29 12:29:12: [2024-10-29 12:29:12] iter = 03550, loss = 1.2498
2024-10-29 12:29:13: [2024-10-29 12:29:13] iter = 03560, loss = 2.7478
2024-10-29 12:29:13: [2024-10-29 12:29:13] iter = 03570, loss = 3.1631
2024-10-29 12:29:14: [2024-10-29 12:29:14] iter = 03580, loss = 1.2202
2024-10-29 12:29:14: [2024-10-29 12:29:14] iter = 03590, loss = 1.8489
2024-10-29 12:29:15: [2024-10-29 12:29:15] iter = 03600, loss = 1.2943
2024-10-29 12:29:15: [2024-10-29 12:29:15] iter = 03610, loss = 1.0342
2024-10-29 12:29:16: [2024-10-29 12:29:16] iter = 03620, loss = 1.3292
2024-10-29 12:29:16: [2024-10-29 12:29:16] iter = 03630, loss = 1.2151
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 03640, loss = 1.5595
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 03650, loss = 1.2919
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 03660, loss = 1.1944
2024-10-29 12:29:18: [2024-10-29 12:29:18] iter = 03670, loss = 1.5888
2024-10-29 12:29:18: [2024-10-29 12:29:18] iter = 03680, loss = 1.1596
2024-10-29 12:29:18: [2024-10-29 12:29:18] iter = 03690, loss = 1.7353
2024-10-29 12:29:19: [2024-10-29 12:29:19] iter = 03700, loss = 1.9292
2024-10-29 12:29:19: [2024-10-29 12:29:19] iter = 03710, loss = 1.8762
2024-10-29 12:29:20: [2024-10-29 12:29:20] iter = 03720, loss = 1.8767
2024-10-29 12:29:20: [2024-10-29 12:29:20] iter = 03730, loss = 1.5797
2024-10-29 12:29:20: [2024-10-29 12:29:20] iter = 03740, loss = 2.7583
2024-10-29 12:29:21: [2024-10-29 12:29:21] iter = 03750, loss = 0.8030
2024-10-29 12:29:21: [2024-10-29 12:29:21] iter = 03760, loss = 2.0487
2024-10-29 12:29:21: [2024-10-29 12:29:21] iter = 03770, loss = 1.9092
2024-10-29 12:29:22: [2024-10-29 12:29:22] iter = 03780, loss = 1.0605
2024-10-29 12:29:22: [2024-10-29 12:29:22] iter = 03790, loss = 3.2847
2024-10-29 12:29:22: [2024-10-29 12:29:22] iter = 03800, loss = 2.1890
2024-10-29 12:29:23: [2024-10-29 12:29:23] iter = 03810, loss = 1.8799
2024-10-29 12:29:23: [2024-10-29 12:29:23] iter = 03820, loss = 1.6502
2024-10-29 12:29:24: [2024-10-29 12:29:24] iter = 03830, loss = 1.4586
2024-10-29 12:29:24: [2024-10-29 12:29:24] iter = 03840, loss = 1.5652
2024-10-29 12:29:24: [2024-10-29 12:29:24] iter = 03850, loss = 2.1162
2024-10-29 12:29:25: [2024-10-29 12:29:25] iter = 03860, loss = 1.2189
2024-10-29 12:29:25: [2024-10-29 12:29:25] iter = 03870, loss = 2.4300
2024-10-29 12:29:25: [2024-10-29 12:29:25] iter = 03880, loss = 2.2784
2024-10-29 12:29:26: [2024-10-29 12:29:26] iter = 03890, loss = 0.8249
2024-10-29 12:29:26: [2024-10-29 12:29:26] iter = 03900, loss = 1.6547
2024-10-29 12:29:27: [2024-10-29 12:29:27] iter = 03910, loss = 1.6231
2024-10-29 12:29:27: [2024-10-29 12:29:27] iter = 03920, loss = 1.0749
2024-10-29 12:29:27: [2024-10-29 12:29:27] iter = 03930, loss = 1.1520
2024-10-29 12:29:28: [2024-10-29 12:29:28] iter = 03940, loss = 1.2388
2024-10-29 12:29:28: [2024-10-29 12:29:28] iter = 03950, loss = 0.8176
2024-10-29 12:29:28: [2024-10-29 12:29:28] iter = 03960, loss = 1.5111
2024-10-29 12:29:29: [2024-10-29 12:29:29] iter = 03970, loss = 1.3293
2024-10-29 12:29:29: [2024-10-29 12:29:29] iter = 03980, loss = 1.2555
2024-10-29 12:29:29: [2024-10-29 12:29:29] iter = 03990, loss = 2.1681
2024-10-29 12:29:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 12:29:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:29:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 70173}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:30:03: Evaluate 5 random ConvNet, ACCmean = 0.5789 ACCstd = 0.0081
-------------------------
2024-10-29 12:30:03: Evaluate 5 random ConvNet, SENmean = 0.6196 SENstd = 0.0019
-------------------------
2024-10-29 12:30:03: Evaluate 5 random ConvNet, SPEmean = 0.6196 SPEstd = 0.0019
-------------------------
2024-10-29 12:30:03: Evaluate 5 random ConvNet, F!mean = 0.4811 F!std = 0.0044
-------------------------
2024-10-29 12:30:03: Evaluate 5 random ConvNet, mean = 0.5789 std = 0.0081
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:30:03: [2024-10-29 12:30:03] iter = 04000, loss = 2.3875
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:30:04: [2024-10-29 12:30:04] iter = 04010, loss = 1.1635
2024-10-29 12:30:04: [2024-10-29 12:30:04] iter = 04020, loss = 3.0255
2024-10-29 12:30:05: [2024-10-29 12:30:05] iter = 04030, loss = 2.7641
2024-10-29 12:30:05: [2024-10-29 12:30:05] iter = 04040, loss = 1.5622
2024-10-29 12:30:06: [2024-10-29 12:30:06] iter = 04050, loss = 1.6822
2024-10-29 12:30:06: [2024-10-29 12:30:06] iter = 04060, loss = 1.4632
2024-10-29 12:30:07: [2024-10-29 12:30:07] iter = 04070, loss = 1.2694
2024-10-29 12:30:07: [2024-10-29 12:30:07] iter = 04080, loss = 1.8087
2024-10-29 12:30:07: [2024-10-29 12:30:07] iter = 04090, loss = 1.2618
2024-10-29 12:30:08: [2024-10-29 12:30:08] iter = 04100, loss = 5.6759
2024-10-29 12:30:08: [2024-10-29 12:30:08] iter = 04110, loss = 7.1823
2024-10-29 12:30:09: [2024-10-29 12:30:09] iter = 04120, loss = 2.3189
2024-10-29 12:30:10: [2024-10-29 12:30:10] iter = 04130, loss = 1.4860
2024-10-29 12:30:10: [2024-10-29 12:30:10] iter = 04140, loss = 3.7438
2024-10-29 12:30:10: [2024-10-29 12:30:10] iter = 04150, loss = 1.3575
2024-10-29 12:30:11: [2024-10-29 12:30:11] iter = 04160, loss = 0.9929
2024-10-29 12:30:11: [2024-10-29 12:30:11] iter = 04170, loss = 1.1632
2024-10-29 12:30:11: [2024-10-29 12:30:11] iter = 04180, loss = 1.2186
2024-10-29 12:30:12: [2024-10-29 12:30:12] iter = 04190, loss = 2.5124
2024-10-29 12:30:12: [2024-10-29 12:30:12] iter = 04200, loss = 1.5226
2024-10-29 12:30:12: [2024-10-29 12:30:12] iter = 04210, loss = 1.3972
2024-10-29 12:30:13: [2024-10-29 12:30:13] iter = 04220, loss = 1.1096
2024-10-29 12:30:13: [2024-10-29 12:30:13] iter = 04230, loss = 1.3244
2024-10-29 12:30:13: [2024-10-29 12:30:13] iter = 04240, loss = 1.7245
2024-10-29 12:30:14: [2024-10-29 12:30:14] iter = 04250, loss = 0.8948
2024-10-29 12:30:14: [2024-10-29 12:30:14] iter = 04260, loss = 0.6483
2024-10-29 12:30:14: [2024-10-29 12:30:14] iter = 04270, loss = 1.3669
2024-10-29 12:30:15: [2024-10-29 12:30:15] iter = 04280, loss = 2.3540
2024-10-29 12:30:15: [2024-10-29 12:30:15] iter = 04290, loss = 1.3436
2024-10-29 12:30:15: [2024-10-29 12:30:15] iter = 04300, loss = 1.5517
2024-10-29 12:30:16: [2024-10-29 12:30:16] iter = 04310, loss = 1.0777
2024-10-29 12:30:16: [2024-10-29 12:30:16] iter = 04320, loss = 5.6698
2024-10-29 12:30:16: [2024-10-29 12:30:16] iter = 04330, loss = 0.7355
2024-10-29 12:30:17: [2024-10-29 12:30:17] iter = 04340, loss = 1.0943
2024-10-29 12:30:17: [2024-10-29 12:30:17] iter = 04350, loss = 1.2178
2024-10-29 12:30:18: [2024-10-29 12:30:18] iter = 04360, loss = 1.1908
2024-10-29 12:30:18: [2024-10-29 12:30:18] iter = 04370, loss = 3.5177
2024-10-29 12:30:18: [2024-10-29 12:30:18] iter = 04380, loss = 1.7518
2024-10-29 12:30:19: [2024-10-29 12:30:19] iter = 04390, loss = 1.2584
2024-10-29 12:30:19: [2024-10-29 12:30:19] iter = 04400, loss = 1.3061
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 04410, loss = 0.8696
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 04420, loss = 1.3838
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 04430, loss = 2.6831
2024-10-29 12:30:21: [2024-10-29 12:30:21] iter = 04440, loss = 2.8962
2024-10-29 12:30:21: [2024-10-29 12:30:21] iter = 04450, loss = 1.9755
2024-10-29 12:30:21: [2024-10-29 12:30:21] iter = 04460, loss = 2.5800
2024-10-29 12:30:22: [2024-10-29 12:30:22] iter = 04470, loss = 9.0273
2024-10-29 12:30:22: [2024-10-29 12:30:22] iter = 04480, loss = 1.7179
2024-10-29 12:30:22: [2024-10-29 12:30:22] iter = 04490, loss = 0.9916
2024-10-29 12:30:23: [2024-10-29 12:30:23] iter = 04500, loss = 3.6584
2024-10-29 12:30:23: [2024-10-29 12:30:23] iter = 04510, loss = 1.5362
2024-10-29 12:30:23: [2024-10-29 12:30:23] iter = 04520, loss = 1.7058
2024-10-29 12:30:24: [2024-10-29 12:30:24] iter = 04530, loss = 3.3398
2024-10-29 12:30:24: [2024-10-29 12:30:24] iter = 04540, loss = 1.7075
2024-10-29 12:30:24: [2024-10-29 12:30:24] iter = 04550, loss = 1.5909
2024-10-29 12:30:25: [2024-10-29 12:30:25] iter = 04560, loss = 1.2354
2024-10-29 12:30:25: [2024-10-29 12:30:25] iter = 04570, loss = 1.0853
2024-10-29 12:30:25: [2024-10-29 12:30:25] iter = 04580, loss = 0.8993
2024-10-29 12:30:26: [2024-10-29 12:30:26] iter = 04590, loss = 1.6053
2024-10-29 12:30:26: [2024-10-29 12:30:26] iter = 04600, loss = 1.2501
2024-10-29 12:30:26: [2024-10-29 12:30:26] iter = 04610, loss = 0.7904
2024-10-29 12:30:27: [2024-10-29 12:30:27] iter = 04620, loss = 2.0229
2024-10-29 12:30:27: [2024-10-29 12:30:27] iter = 04630, loss = 1.6338
2024-10-29 12:30:27: [2024-10-29 12:30:27] iter = 04640, loss = 2.3714
2024-10-29 12:30:28: [2024-10-29 12:30:28] iter = 04650, loss = 1.5421
2024-10-29 12:30:28: [2024-10-29 12:30:28] iter = 04660, loss = 2.3836
2024-10-29 12:30:29: [2024-10-29 12:30:29] iter = 04670, loss = 1.2625
2024-10-29 12:30:29: [2024-10-29 12:30:29] iter = 04680, loss = 4.5842
2024-10-29 12:30:29: [2024-10-29 12:30:29] iter = 04690, loss = 3.7087
2024-10-29 12:30:30: [2024-10-29 12:30:30] iter = 04700, loss = 1.1864
2024-10-29 12:30:30: [2024-10-29 12:30:30] iter = 04710, loss = 1.3877
2024-10-29 12:30:30: [2024-10-29 12:30:30] iter = 04720, loss = 1.6469
2024-10-29 12:30:31: [2024-10-29 12:30:30] iter = 04730, loss = 1.4476
2024-10-29 12:30:31: [2024-10-29 12:30:31] iter = 04740, loss = 1.5501
2024-10-29 12:30:31: [2024-10-29 12:30:31] iter = 04750, loss = 1.7199
2024-10-29 12:30:32: [2024-10-29 12:30:32] iter = 04760, loss = 1.8787
2024-10-29 12:30:32: [2024-10-29 12:30:32] iter = 04770, loss = 1.0740
2024-10-29 12:30:32: [2024-10-29 12:30:32] iter = 04780, loss = 1.9752
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 04790, loss = 1.7050
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 04800, loss = 1.5474
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 04810, loss = 0.7216
2024-10-29 12:30:34: [2024-10-29 12:30:34] iter = 04820, loss = 3.0731
2024-10-29 12:30:34: [2024-10-29 12:30:34] iter = 04830, loss = 0.9395
2024-10-29 12:30:34: [2024-10-29 12:30:34] iter = 04840, loss = 1.2940
2024-10-29 12:30:35: [2024-10-29 12:30:35] iter = 04850, loss = 1.9215
2024-10-29 12:30:35: [2024-10-29 12:30:35] iter = 04860, loss = 0.9472
2024-10-29 12:30:35: [2024-10-29 12:30:35] iter = 04870, loss = 2.4848
2024-10-29 12:30:36: [2024-10-29 12:30:36] iter = 04880, loss = 1.1319
2024-10-29 12:30:36: [2024-10-29 12:30:36] iter = 04890, loss = 1.7865
2024-10-29 12:30:36: [2024-10-29 12:30:36] iter = 04900, loss = 0.9907
2024-10-29 12:30:37: [2024-10-29 12:30:37] iter = 04910, loss = 1.0329
2024-10-29 12:30:37: [2024-10-29 12:30:37] iter = 04920, loss = 1.0440
2024-10-29 12:30:38: [2024-10-29 12:30:38] iter = 04930, loss = 1.8951
2024-10-29 12:30:38: [2024-10-29 12:30:38] iter = 04940, loss = 1.3553
2024-10-29 12:30:38: [2024-10-29 12:30:38] iter = 04950, loss = 3.2398
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 04960, loss = 1.1450
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 04970, loss = 2.3178
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 04980, loss = 1.3054
2024-10-29 12:30:40: [2024-10-29 12:30:40] iter = 04990, loss = 2.2430
2024-10-29 12:30:40: [2024-10-29 12:30:40] iter = 05000, loss = 1.8907
2024-10-29 12:30:40: [2024-10-29 12:30:40] iter = 05010, loss = 1.1242
2024-10-29 12:30:41: [2024-10-29 12:30:41] iter = 05020, loss = 1.6700
2024-10-29 12:30:41: [2024-10-29 12:30:41] iter = 05030, loss = 0.8573
2024-10-29 12:30:42: [2024-10-29 12:30:42] iter = 05040, loss = 1.2893
2024-10-29 12:30:42: [2024-10-29 12:30:42] iter = 05050, loss = 1.5089
2024-10-29 12:30:42: [2024-10-29 12:30:42] iter = 05060, loss = 1.0518
2024-10-29 12:30:43: [2024-10-29 12:30:43] iter = 05070, loss = 1.6770
2024-10-29 12:30:43: [2024-10-29 12:30:43] iter = 05080, loss = 1.6232
2024-10-29 12:30:44: [2024-10-29 12:30:44] iter = 05090, loss = 1.0536
2024-10-29 12:30:44: [2024-10-29 12:30:44] iter = 05100, loss = 1.9614
2024-10-29 12:30:45: [2024-10-29 12:30:45] iter = 05110, loss = 1.0628
2024-10-29 12:30:45: [2024-10-29 12:30:45] iter = 05120, loss = 1.4815
2024-10-29 12:30:45: [2024-10-29 12:30:45] iter = 05130, loss = 1.5200
2024-10-29 12:30:46: [2024-10-29 12:30:46] iter = 05140, loss = 5.4637
2024-10-29 12:30:46: [2024-10-29 12:30:46] iter = 05150, loss = 1.0687
2024-10-29 12:30:47: [2024-10-29 12:30:47] iter = 05160, loss = 1.4594
2024-10-29 12:30:47: [2024-10-29 12:30:47] iter = 05170, loss = 2.7616
2024-10-29 12:30:48: [2024-10-29 12:30:48] iter = 05180, loss = 1.1614
2024-10-29 12:30:48: [2024-10-29 12:30:48] iter = 05190, loss = 1.4111
2024-10-29 12:30:49: [2024-10-29 12:30:49] iter = 05200, loss = 0.8744
2024-10-29 12:30:49: [2024-10-29 12:30:49] iter = 05210, loss = 1.3880
2024-10-29 12:30:49: [2024-10-29 12:30:49] iter = 05220, loss = 1.6908
2024-10-29 12:30:50: [2024-10-29 12:30:50] iter = 05230, loss = 2.4293
2024-10-29 12:30:50: [2024-10-29 12:30:50] iter = 05240, loss = 0.8109
2024-10-29 12:30:51: [2024-10-29 12:30:51] iter = 05250, loss = 1.4542
2024-10-29 12:30:51: [2024-10-29 12:30:51] iter = 05260, loss = 1.1676
2024-10-29 12:30:51: [2024-10-29 12:30:51] iter = 05270, loss = 0.9694
2024-10-29 12:30:52: [2024-10-29 12:30:52] iter = 05280, loss = 2.8223
2024-10-29 12:30:52: [2024-10-29 12:30:52] iter = 05290, loss = 1.5633
2024-10-29 12:30:52: [2024-10-29 12:30:52] iter = 05300, loss = 1.2194
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 05310, loss = 4.9951
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 05320, loss = 1.3209
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 05330, loss = 1.0437
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 05340, loss = 1.6237
2024-10-29 12:30:54: [2024-10-29 12:30:54] iter = 05350, loss = 1.3540
2024-10-29 12:30:54: [2024-10-29 12:30:54] iter = 05360, loss = 0.7847
2024-10-29 12:30:54: [2024-10-29 12:30:54] iter = 05370, loss = 1.2409
2024-10-29 12:30:55: [2024-10-29 12:30:55] iter = 05380, loss = 1.1718
2024-10-29 12:30:55: [2024-10-29 12:30:55] iter = 05390, loss = 0.9397
2024-10-29 12:30:55: [2024-10-29 12:30:55] iter = 05400, loss = 3.9290
2024-10-29 12:30:56: [2024-10-29 12:30:56] iter = 05410, loss = 1.1133
2024-10-29 12:30:56: [2024-10-29 12:30:56] iter = 05420, loss = 1.1849
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 05430, loss = 1.0642
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 05440, loss = 2.5627
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 05450, loss = 1.2583
2024-10-29 12:30:58: [2024-10-29 12:30:58] iter = 05460, loss = 2.6245
2024-10-29 12:30:58: [2024-10-29 12:30:58] iter = 05470, loss = 3.6978
2024-10-29 12:30:59: [2024-10-29 12:30:59] iter = 05480, loss = 1.9651
2024-10-29 12:30:59: [2024-10-29 12:30:59] iter = 05490, loss = 1.7281
2024-10-29 12:30:59: [2024-10-29 12:30:59] iter = 05500, loss = 1.8127
2024-10-29 12:31:00: [2024-10-29 12:31:00] iter = 05510, loss = 1.1503
2024-10-29 12:31:00: [2024-10-29 12:31:00] iter = 05520, loss = 2.5924
2024-10-29 12:31:00: [2024-10-29 12:31:00] iter = 05530, loss = 3.7943
2024-10-29 12:31:01: [2024-10-29 12:31:01] iter = 05540, loss = 1.1246
2024-10-29 12:31:01: [2024-10-29 12:31:01] iter = 05550, loss = 1.0285
2024-10-29 12:31:01: [2024-10-29 12:31:01] iter = 05560, loss = 1.2040
2024-10-29 12:31:02: [2024-10-29 12:31:02] iter = 05570, loss = 2.0057
2024-10-29 12:31:02: [2024-10-29 12:31:02] iter = 05580, loss = 2.4504
2024-10-29 12:31:02: [2024-10-29 12:31:02] iter = 05590, loss = 3.4990
2024-10-29 12:31:03: [2024-10-29 12:31:03] iter = 05600, loss = 1.5295
2024-10-29 12:31:03: [2024-10-29 12:31:03] iter = 05610, loss = 1.3818
2024-10-29 12:31:03: [2024-10-29 12:31:03] iter = 05620, loss = 1.9888
2024-10-29 12:31:04: [2024-10-29 12:31:04] iter = 05630, loss = 2.2457
2024-10-29 12:31:04: [2024-10-29 12:31:04] iter = 05640, loss = 2.2164
2024-10-29 12:31:05: [2024-10-29 12:31:05] iter = 05650, loss = 1.6606
2024-10-29 12:31:05: [2024-10-29 12:31:05] iter = 05660, loss = 2.6505
2024-10-29 12:31:05: [2024-10-29 12:31:05] iter = 05670, loss = 1.5091
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 05680, loss = 1.2273
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 05690, loss = 1.2818
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 05700, loss = 10.5244
2024-10-29 12:31:07: [2024-10-29 12:31:07] iter = 05710, loss = 4.4794
2024-10-29 12:31:07: [2024-10-29 12:31:07] iter = 05720, loss = 1.7383
2024-10-29 12:31:07: [2024-10-29 12:31:07] iter = 05730, loss = 1.1599
2024-10-29 12:31:08: [2024-10-29 12:31:08] iter = 05740, loss = 1.2125
2024-10-29 12:31:08: [2024-10-29 12:31:08] iter = 05750, loss = 1.0412
2024-10-29 12:31:08: [2024-10-29 12:31:08] iter = 05760, loss = 1.5668
2024-10-29 12:31:09: [2024-10-29 12:31:09] iter = 05770, loss = 2.0410
2024-10-29 12:31:09: [2024-10-29 12:31:09] iter = 05780, loss = 1.7445
2024-10-29 12:31:09: [2024-10-29 12:31:09] iter = 05790, loss = 2.5112
2024-10-29 12:31:10: [2024-10-29 12:31:10] iter = 05800, loss = 1.4517
2024-10-29 12:31:10: [2024-10-29 12:31:10] iter = 05810, loss = 0.9772
2024-10-29 12:31:11: [2024-10-29 12:31:11] iter = 05820, loss = 1.2500
2024-10-29 12:31:11: [2024-10-29 12:31:11] iter = 05830, loss = 1.2821
2024-10-29 12:31:11: [2024-10-29 12:31:11] iter = 05840, loss = 1.5929
2024-10-29 12:31:12: [2024-10-29 12:31:12] iter = 05850, loss = 1.3631
2024-10-29 12:31:12: [2024-10-29 12:31:12] iter = 05860, loss = 0.9169
2024-10-29 12:31:12: [2024-10-29 12:31:12] iter = 05870, loss = 1.1038
2024-10-29 12:31:13: [2024-10-29 12:31:13] iter = 05880, loss = 1.4573
2024-10-29 12:31:13: [2024-10-29 12:31:13] iter = 05890, loss = 2.3619
2024-10-29 12:31:13: [2024-10-29 12:31:13] iter = 05900, loss = 1.2478
2024-10-29 12:31:14: [2024-10-29 12:31:14] iter = 05910, loss = 1.1958
2024-10-29 12:31:14: [2024-10-29 12:31:14] iter = 05920, loss = 1.0429
2024-10-29 12:31:15: [2024-10-29 12:31:15] iter = 05930, loss = 1.1836
2024-10-29 12:31:15: [2024-10-29 12:31:15] iter = 05940, loss = 0.9833
2024-10-29 12:31:15: [2024-10-29 12:31:15] iter = 05950, loss = 2.2419
2024-10-29 12:31:16: [2024-10-29 12:31:16] iter = 05960, loss = 0.9855
2024-10-29 12:31:16: [2024-10-29 12:31:16] iter = 05970, loss = 1.8230
2024-10-29 12:31:16: [2024-10-29 12:31:16] iter = 05980, loss = 0.7971
2024-10-29 12:31:17: [2024-10-29 12:31:17] iter = 05990, loss = 1.1148
2024-10-29 12:31:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 12:31:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:31:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 77740}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:50: Evaluate 5 random ConvNet, ACCmean = 0.5455 ACCstd = 0.0054
-------------------------
2024-10-29 12:31:50: Evaluate 5 random ConvNet, SENmean = 0.6096 SENstd = 0.0029
-------------------------
2024-10-29 12:31:50: Evaluate 5 random ConvNet, SPEmean = 0.6096 SPEstd = 0.0029
-------------------------
2024-10-29 12:31:50: Evaluate 5 random ConvNet, F!mean = 0.4608 F!std = 0.0031
-------------------------
2024-10-29 12:31:50: Evaluate 5 random ConvNet, mean = 0.5455 std = 0.0054
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:50: [2024-10-29 12:31:50] iter = 06000, loss = 1.0098
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:51: [2024-10-29 12:31:51] iter = 06010, loss = 1.3225
2024-10-29 12:31:51: [2024-10-29 12:31:51] iter = 06020, loss = 1.5866
2024-10-29 12:31:51: [2024-10-29 12:31:51] iter = 06030, loss = 0.9222
2024-10-29 12:31:52: [2024-10-29 12:31:52] iter = 06040, loss = 0.9371
2024-10-29 12:31:52: [2024-10-29 12:31:52] iter = 06050, loss = 1.1110
2024-10-29 12:31:52: [2024-10-29 12:31:52] iter = 06060, loss = 1.0656
2024-10-29 12:31:53: [2024-10-29 12:31:53] iter = 06070, loss = 1.9641
2024-10-29 12:31:53: [2024-10-29 12:31:53] iter = 06080, loss = 1.6251
2024-10-29 12:31:53: [2024-10-29 12:31:53] iter = 06090, loss = 1.7298
2024-10-29 12:31:54: [2024-10-29 12:31:54] iter = 06100, loss = 1.4907
2024-10-29 12:31:54: [2024-10-29 12:31:54] iter = 06110, loss = 1.7643
2024-10-29 12:31:55: [2024-10-29 12:31:55] iter = 06120, loss = 0.9869
2024-10-29 12:31:55: [2024-10-29 12:31:55] iter = 06130, loss = 1.4113
2024-10-29 12:31:55: [2024-10-29 12:31:55] iter = 06140, loss = 1.1247
2024-10-29 12:31:56: [2024-10-29 12:31:56] iter = 06150, loss = 1.7395
2024-10-29 12:31:56: [2024-10-29 12:31:56] iter = 06160, loss = 1.7042
2024-10-29 12:31:56: [2024-10-29 12:31:56] iter = 06170, loss = 3.5426
2024-10-29 12:31:57: [2024-10-29 12:31:57] iter = 06180, loss = 0.9208
2024-10-29 12:31:57: [2024-10-29 12:31:57] iter = 06190, loss = 1.1272
2024-10-29 12:31:57: [2024-10-29 12:31:57] iter = 06200, loss = 2.3673
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 06210, loss = 1.4718
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 06220, loss = 3.5992
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 06230, loss = 1.1230
2024-10-29 12:31:59: [2024-10-29 12:31:59] iter = 06240, loss = 1.3145
2024-10-29 12:31:59: [2024-10-29 12:31:59] iter = 06250, loss = 1.0413
2024-10-29 12:31:59: [2024-10-29 12:31:59] iter = 06260, loss = 2.0985
2024-10-29 12:32:00: [2024-10-29 12:32:00] iter = 06270, loss = 1.6775
2024-10-29 12:32:00: [2024-10-29 12:32:00] iter = 06280, loss = 11.8778
2024-10-29 12:32:01: [2024-10-29 12:32:01] iter = 06290, loss = 1.2729
2024-10-29 12:32:01: [2024-10-29 12:32:01] iter = 06300, loss = 1.9287
2024-10-29 12:32:01: [2024-10-29 12:32:01] iter = 06310, loss = 1.2646
2024-10-29 12:32:02: [2024-10-29 12:32:02] iter = 06320, loss = 0.8138
2024-10-29 12:32:02: [2024-10-29 12:32:02] iter = 06330, loss = 0.9635
2024-10-29 12:32:03: [2024-10-29 12:32:03] iter = 06340, loss = 1.2754
2024-10-29 12:32:03: [2024-10-29 12:32:03] iter = 06350, loss = 5.1092
2024-10-29 12:32:04: [2024-10-29 12:32:04] iter = 06360, loss = 9.7272
2024-10-29 12:32:04: [2024-10-29 12:32:04] iter = 06370, loss = 2.1444
2024-10-29 12:32:04: [2024-10-29 12:32:04] iter = 06380, loss = 2.1641
2024-10-29 12:32:05: [2024-10-29 12:32:05] iter = 06390, loss = 1.7172
2024-10-29 12:32:05: [2024-10-29 12:32:05] iter = 06400, loss = 1.8734
2024-10-29 12:32:05: [2024-10-29 12:32:05] iter = 06410, loss = 1.2304
2024-10-29 12:32:06: [2024-10-29 12:32:06] iter = 06420, loss = 0.8463
2024-10-29 12:32:06: [2024-10-29 12:32:06] iter = 06430, loss = 0.8813
2024-10-29 12:32:06: [2024-10-29 12:32:06] iter = 06440, loss = 2.9841
2024-10-29 12:32:07: [2024-10-29 12:32:07] iter = 06450, loss = 1.6801
2024-10-29 12:32:07: [2024-10-29 12:32:07] iter = 06460, loss = 1.1941
2024-10-29 12:32:07: [2024-10-29 12:32:07] iter = 06470, loss = 2.4190
2024-10-29 12:32:08: [2024-10-29 12:32:08] iter = 06480, loss = 1.2346
2024-10-29 12:32:08: [2024-10-29 12:32:08] iter = 06490, loss = 1.2463
2024-10-29 12:32:08: [2024-10-29 12:32:08] iter = 06500, loss = 1.1763
2024-10-29 12:32:09: [2024-10-29 12:32:09] iter = 06510, loss = 6.0430
2024-10-29 12:32:09: [2024-10-29 12:32:09] iter = 06520, loss = 0.8918
2024-10-29 12:32:09: [2024-10-29 12:32:09] iter = 06530, loss = 1.2413
2024-10-29 12:32:10: [2024-10-29 12:32:10] iter = 06540, loss = 2.4259
2024-10-29 12:32:10: [2024-10-29 12:32:10] iter = 06550, loss = 3.6094
2024-10-29 12:32:10: [2024-10-29 12:32:10] iter = 06560, loss = 1.5444
2024-10-29 12:32:11: [2024-10-29 12:32:11] iter = 06570, loss = 8.3038
2024-10-29 12:32:11: [2024-10-29 12:32:11] iter = 06580, loss = 1.7715
2024-10-29 12:32:11: [2024-10-29 12:32:11] iter = 06590, loss = 1.2255
2024-10-29 12:32:12: [2024-10-29 12:32:12] iter = 06600, loss = 1.5090
2024-10-29 12:32:12: [2024-10-29 12:32:12] iter = 06610, loss = 1.1982
2024-10-29 12:32:12: [2024-10-29 12:32:12] iter = 06620, loss = 0.9816
2024-10-29 12:32:13: [2024-10-29 12:32:13] iter = 06630, loss = 1.2738
2024-10-29 12:32:13: [2024-10-29 12:32:13] iter = 06640, loss = 1.5678
2024-10-29 12:32:13: [2024-10-29 12:32:13] iter = 06650, loss = 1.2887
2024-10-29 12:32:14: [2024-10-29 12:32:14] iter = 06660, loss = 1.1113
2024-10-29 12:32:14: [2024-10-29 12:32:14] iter = 06670, loss = 0.9875
2024-10-29 12:32:14: [2024-10-29 12:32:14] iter = 06680, loss = 1.3880
2024-10-29 12:32:15: [2024-10-29 12:32:15] iter = 06690, loss = 1.0388
2024-10-29 12:32:15: [2024-10-29 12:32:15] iter = 06700, loss = 0.9339
2024-10-29 12:32:15: [2024-10-29 12:32:15] iter = 06710, loss = 0.8861
2024-10-29 12:32:16: [2024-10-29 12:32:16] iter = 06720, loss = 1.4182
2024-10-29 12:32:16: [2024-10-29 12:32:16] iter = 06730, loss = 1.0153
2024-10-29 12:32:17: [2024-10-29 12:32:17] iter = 06740, loss = 1.2221
2024-10-29 12:32:17: [2024-10-29 12:32:17] iter = 06750, loss = 1.8981
2024-10-29 12:32:17: [2024-10-29 12:32:17] iter = 06760, loss = 1.2501
2024-10-29 12:32:18: [2024-10-29 12:32:18] iter = 06770, loss = 1.5159
2024-10-29 12:32:18: [2024-10-29 12:32:18] iter = 06780, loss = 1.7905
2024-10-29 12:32:19: [2024-10-29 12:32:19] iter = 06790, loss = 1.3943
2024-10-29 12:32:19: [2024-10-29 12:32:19] iter = 06800, loss = 3.1177
2024-10-29 12:32:19: [2024-10-29 12:32:19] iter = 06810, loss = 1.3532
2024-10-29 12:32:20: [2024-10-29 12:32:20] iter = 06820, loss = 1.0443
2024-10-29 12:32:21: [2024-10-29 12:32:21] iter = 06830, loss = 2.9094
2024-10-29 12:32:21: [2024-10-29 12:32:21] iter = 06840, loss = 1.1284
2024-10-29 12:32:22: [2024-10-29 12:32:22] iter = 06850, loss = 1.5559
2024-10-29 12:32:22: [2024-10-29 12:32:22] iter = 06860, loss = 0.7764
2024-10-29 12:32:23: [2024-10-29 12:32:23] iter = 06870, loss = 1.4465
2024-10-29 12:32:23: [2024-10-29 12:32:23] iter = 06880, loss = 5.7890
2024-10-29 12:32:24: [2024-10-29 12:32:24] iter = 06890, loss = 1.2478
2024-10-29 12:32:24: [2024-10-29 12:32:24] iter = 06900, loss = 1.4839
2024-10-29 12:32:25: [2024-10-29 12:32:25] iter = 06910, loss = 1.4572
2024-10-29 12:32:25: [2024-10-29 12:32:25] iter = 06920, loss = 0.8617
2024-10-29 12:32:26: [2024-10-29 12:32:26] iter = 06930, loss = 1.0571
2024-10-29 12:32:26: [2024-10-29 12:32:26] iter = 06940, loss = 1.4265
2024-10-29 12:32:27: [2024-10-29 12:32:27] iter = 06950, loss = 4.6734
2024-10-29 12:32:27: [2024-10-29 12:32:27] iter = 06960, loss = 1.0842
2024-10-29 12:32:27: [2024-10-29 12:32:27] iter = 06970, loss = 1.7163
2024-10-29 12:32:28: [2024-10-29 12:32:28] iter = 06980, loss = 1.2274
2024-10-29 12:32:28: [2024-10-29 12:32:28] iter = 06990, loss = 0.9493
2024-10-29 12:32:28: [2024-10-29 12:32:28] iter = 07000, loss = 0.9209
2024-10-29 12:32:29: [2024-10-29 12:32:29] iter = 07010, loss = 2.1534
2024-10-29 12:32:29: [2024-10-29 12:32:29] iter = 07020, loss = 12.9074
2024-10-29 12:32:29: [2024-10-29 12:32:29] iter = 07030, loss = 3.6611
2024-10-29 12:32:30: [2024-10-29 12:32:30] iter = 07040, loss = 1.1330
2024-10-29 12:32:30: [2024-10-29 12:32:30] iter = 07050, loss = 1.3705
2024-10-29 12:32:31: [2024-10-29 12:32:31] iter = 07060, loss = 1.9737
2024-10-29 12:32:31: [2024-10-29 12:32:31] iter = 07070, loss = 8.2065
2024-10-29 12:32:31: [2024-10-29 12:32:31] iter = 07080, loss = 1.5459
2024-10-29 12:32:32: [2024-10-29 12:32:32] iter = 07090, loss = 1.3727
2024-10-29 12:32:32: [2024-10-29 12:32:32] iter = 07100, loss = 2.0799
2024-10-29 12:32:32: [2024-10-29 12:32:32] iter = 07110, loss = 1.1314
2024-10-29 12:32:33: [2024-10-29 12:32:33] iter = 07120, loss = 0.9578
2024-10-29 12:32:33: [2024-10-29 12:32:33] iter = 07130, loss = 1.4948
2024-10-29 12:32:34: [2024-10-29 12:32:34] iter = 07140, loss = 1.1671
2024-10-29 12:32:34: [2024-10-29 12:32:34] iter = 07150, loss = 0.8472
2024-10-29 12:32:34: [2024-10-29 12:32:34] iter = 07160, loss = 1.2034
2024-10-29 12:32:35: [2024-10-29 12:32:35] iter = 07170, loss = 1.1499
2024-10-29 12:32:35: [2024-10-29 12:32:35] iter = 07180, loss = 0.9822
2024-10-29 12:32:36: [2024-10-29 12:32:36] iter = 07190, loss = 1.1518
2024-10-29 12:32:36: [2024-10-29 12:32:36] iter = 07200, loss = 8.0658
2024-10-29 12:32:36: [2024-10-29 12:32:36] iter = 07210, loss = 3.5655
2024-10-29 12:32:37: [2024-10-29 12:32:37] iter = 07220, loss = 1.6212
2024-10-29 12:32:37: [2024-10-29 12:32:37] iter = 07230, loss = 0.8406
2024-10-29 12:32:37: [2024-10-29 12:32:37] iter = 07240, loss = 1.9387
2024-10-29 12:32:38: [2024-10-29 12:32:38] iter = 07250, loss = 1.5852
2024-10-29 12:32:38: [2024-10-29 12:32:38] iter = 07260, loss = 1.3575
2024-10-29 12:32:38: [2024-10-29 12:32:38] iter = 07270, loss = 1.6303
2024-10-29 12:32:39: [2024-10-29 12:32:39] iter = 07280, loss = 1.8999
2024-10-29 12:32:39: [2024-10-29 12:32:39] iter = 07290, loss = 1.6165
2024-10-29 12:32:39: [2024-10-29 12:32:39] iter = 07300, loss = 1.0751
2024-10-29 12:32:40: [2024-10-29 12:32:40] iter = 07310, loss = 1.4754
2024-10-29 12:32:40: [2024-10-29 12:32:40] iter = 07320, loss = 0.9352
2024-10-29 12:32:41: [2024-10-29 12:32:41] iter = 07330, loss = 6.1474
2024-10-29 12:32:41: [2024-10-29 12:32:41] iter = 07340, loss = 2.9203
2024-10-29 12:32:41: [2024-10-29 12:32:41] iter = 07350, loss = 1.5625
2024-10-29 12:32:42: [2024-10-29 12:32:42] iter = 07360, loss = 2.4743
2024-10-29 12:32:42: [2024-10-29 12:32:42] iter = 07370, loss = 2.6394
2024-10-29 12:32:42: [2024-10-29 12:32:42] iter = 07380, loss = 3.2357
2024-10-29 12:32:43: [2024-10-29 12:32:43] iter = 07390, loss = 1.5819
2024-10-29 12:32:43: [2024-10-29 12:32:43] iter = 07400, loss = 1.5411
2024-10-29 12:32:44: [2024-10-29 12:32:44] iter = 07410, loss = 1.5227
2024-10-29 12:32:44: [2024-10-29 12:32:44] iter = 07420, loss = 0.8153
2024-10-29 12:32:44: [2024-10-29 12:32:44] iter = 07430, loss = 1.0362
2024-10-29 12:32:45: [2024-10-29 12:32:45] iter = 07440, loss = 1.2951
2024-10-29 12:32:45: [2024-10-29 12:32:45] iter = 07450, loss = 1.5017
2024-10-29 12:32:45: [2024-10-29 12:32:45] iter = 07460, loss = 1.0703
2024-10-29 12:32:46: [2024-10-29 12:32:46] iter = 07470, loss = 1.1865
2024-10-29 12:32:46: [2024-10-29 12:32:46] iter = 07480, loss = 0.9799
2024-10-29 12:32:46: [2024-10-29 12:32:46] iter = 07490, loss = 1.5968
2024-10-29 12:32:47: [2024-10-29 12:32:47] iter = 07500, loss = 0.7488
2024-10-29 12:32:47: [2024-10-29 12:32:47] iter = 07510, loss = 1.7801
2024-10-29 12:32:47: [2024-10-29 12:32:47] iter = 07520, loss = 0.9840
2024-10-29 12:32:48: [2024-10-29 12:32:48] iter = 07530, loss = 1.9115
2024-10-29 12:32:48: [2024-10-29 12:32:48] iter = 07540, loss = 1.5641
2024-10-29 12:32:48: [2024-10-29 12:32:48] iter = 07550, loss = 1.3562
2024-10-29 12:32:49: [2024-10-29 12:32:49] iter = 07560, loss = 1.5611
2024-10-29 12:32:49: [2024-10-29 12:32:49] iter = 07570, loss = 1.4519
2024-10-29 12:32:49: [2024-10-29 12:32:49] iter = 07580, loss = 1.4171
2024-10-29 12:32:50: [2024-10-29 12:32:50] iter = 07590, loss = 1.2654
2024-10-29 12:32:50: [2024-10-29 12:32:50] iter = 07600, loss = 0.8943
2024-10-29 12:32:50: [2024-10-29 12:32:50] iter = 07610, loss = 2.0605
2024-10-29 12:32:51: [2024-10-29 12:32:51] iter = 07620, loss = 1.5996
2024-10-29 12:32:51: [2024-10-29 12:32:51] iter = 07630, loss = 2.5869
2024-10-29 12:32:51: [2024-10-29 12:32:51] iter = 07640, loss = 0.7940
2024-10-29 12:32:52: [2024-10-29 12:32:52] iter = 07650, loss = 1.5767
2024-10-29 12:32:52: [2024-10-29 12:32:52] iter = 07660, loss = 1.2674
2024-10-29 12:32:53: [2024-10-29 12:32:53] iter = 07670, loss = 1.0273
2024-10-29 12:32:53: [2024-10-29 12:32:53] iter = 07680, loss = 1.2994
2024-10-29 12:32:53: [2024-10-29 12:32:53] iter = 07690, loss = 2.3593
2024-10-29 12:32:54: [2024-10-29 12:32:54] iter = 07700, loss = 1.0323
2024-10-29 12:32:54: [2024-10-29 12:32:54] iter = 07710, loss = 1.5156
2024-10-29 12:32:54: [2024-10-29 12:32:54] iter = 07720, loss = 0.9951
2024-10-29 12:32:55: [2024-10-29 12:32:55] iter = 07730, loss = 0.9344
2024-10-29 12:32:55: [2024-10-29 12:32:55] iter = 07740, loss = 1.5551
2024-10-29 12:32:55: [2024-10-29 12:32:55] iter = 07750, loss = 1.7391
2024-10-29 12:32:56: [2024-10-29 12:32:56] iter = 07760, loss = 1.7976
2024-10-29 12:32:56: [2024-10-29 12:32:56] iter = 07770, loss = 1.0495
2024-10-29 12:32:56: [2024-10-29 12:32:56] iter = 07780, loss = 1.2691
2024-10-29 12:32:57: [2024-10-29 12:32:57] iter = 07790, loss = 0.5984
2024-10-29 12:32:57: [2024-10-29 12:32:57] iter = 07800, loss = 1.1362
2024-10-29 12:32:57: [2024-10-29 12:32:57] iter = 07810, loss = 4.7058
2024-10-29 12:32:58: [2024-10-29 12:32:58] iter = 07820, loss = 1.1741
2024-10-29 12:32:58: [2024-10-29 12:32:58] iter = 07830, loss = 2.4142
2024-10-29 12:32:58: [2024-10-29 12:32:58] iter = 07840, loss = 2.3825
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 07850, loss = 0.8596
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 07860, loss = 1.1520
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 07870, loss = 1.2498
2024-10-29 12:33:00: [2024-10-29 12:33:00] iter = 07880, loss = 2.0957
2024-10-29 12:33:00: [2024-10-29 12:33:00] iter = 07890, loss = 1.3484
2024-10-29 12:33:01: [2024-10-29 12:33:01] iter = 07900, loss = 1.1001
2024-10-29 12:33:01: [2024-10-29 12:33:01] iter = 07910, loss = 1.0410
2024-10-29 12:33:01: [2024-10-29 12:33:01] iter = 07920, loss = 3.0104
2024-10-29 12:33:02: [2024-10-29 12:33:02] iter = 07930, loss = 1.5009
2024-10-29 12:33:02: [2024-10-29 12:33:02] iter = 07940, loss = 4.6685
2024-10-29 12:33:02: [2024-10-29 12:33:02] iter = 07950, loss = 1.1500
2024-10-29 12:33:03: [2024-10-29 12:33:03] iter = 07960, loss = 1.1639
2024-10-29 12:33:03: [2024-10-29 12:33:03] iter = 07970, loss = 3.8345
2024-10-29 12:33:03: [2024-10-29 12:33:03] iter = 07980, loss = 1.0733
2024-10-29 12:33:04: [2024-10-29 12:33:04] iter = 07990, loss = 3.0058
2024-10-29 12:33:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 12:33:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:33:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 84605}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:33:37: Evaluate 5 random ConvNet, ACCmean = 0.6330 ACCstd = 0.0063
-------------------------
2024-10-29 12:33:37: Evaluate 5 random ConvNet, SENmean = 0.6071 SENstd = 0.0056
-------------------------
2024-10-29 12:33:37: Evaluate 5 random ConvNet, SPEmean = 0.6071 SPEstd = 0.0056
-------------------------
2024-10-29 12:33:37: Evaluate 5 random ConvNet, F!mean = 0.5045 F!std = 0.0026
-------------------------
2024-10-29 12:33:37: Evaluate 5 random ConvNet, mean = 0.6330 std = 0.0063
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:33:37: [2024-10-29 12:33:37] iter = 08000, loss = 0.8907
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:33:37: [2024-10-29 12:33:37] iter = 08010, loss = 1.6052
2024-10-29 12:33:38: [2024-10-29 12:33:38] iter = 08020, loss = 1.2246
2024-10-29 12:33:38: [2024-10-29 12:33:38] iter = 08030, loss = 1.1472
2024-10-29 12:33:38: [2024-10-29 12:33:38] iter = 08040, loss = 1.4653
2024-10-29 12:33:39: [2024-10-29 12:33:39] iter = 08050, loss = 1.0839
2024-10-29 12:33:39: [2024-10-29 12:33:39] iter = 08060, loss = 1.6090
2024-10-29 12:33:39: [2024-10-29 12:33:39] iter = 08070, loss = 1.6030
2024-10-29 12:33:40: [2024-10-29 12:33:40] iter = 08080, loss = 1.8131
2024-10-29 12:33:40: [2024-10-29 12:33:40] iter = 08090, loss = 2.3741
2024-10-29 12:33:40: [2024-10-29 12:33:40] iter = 08100, loss = 0.9467
2024-10-29 12:33:41: [2024-10-29 12:33:41] iter = 08110, loss = 4.2327
2024-10-29 12:33:41: [2024-10-29 12:33:41] iter = 08120, loss = 1.2517
2024-10-29 12:33:41: [2024-10-29 12:33:41] iter = 08130, loss = 1.4307
2024-10-29 12:33:42: [2024-10-29 12:33:42] iter = 08140, loss = 0.9659
2024-10-29 12:33:42: [2024-10-29 12:33:42] iter = 08150, loss = 1.3888
2024-10-29 12:33:42: [2024-10-29 12:33:42] iter = 08160, loss = 0.9483
2024-10-29 12:33:43: [2024-10-29 12:33:43] iter = 08170, loss = 1.2380
2024-10-29 12:33:43: [2024-10-29 12:33:43] iter = 08180, loss = 2.5089
2024-10-29 12:33:44: [2024-10-29 12:33:44] iter = 08190, loss = 2.4496
2024-10-29 12:33:44: [2024-10-29 12:33:44] iter = 08200, loss = 1.2807
2024-10-29 12:33:44: [2024-10-29 12:33:44] iter = 08210, loss = 1.1540
2024-10-29 12:33:45: [2024-10-29 12:33:45] iter = 08220, loss = 2.3160
2024-10-29 12:33:45: [2024-10-29 12:33:45] iter = 08230, loss = 3.4082
2024-10-29 12:33:45: [2024-10-29 12:33:45] iter = 08240, loss = 0.9140
2024-10-29 12:33:46: [2024-10-29 12:33:46] iter = 08250, loss = 1.0201
2024-10-29 12:33:46: [2024-10-29 12:33:46] iter = 08260, loss = 1.1149
2024-10-29 12:33:46: [2024-10-29 12:33:46] iter = 08270, loss = 0.9107
2024-10-29 12:33:47: [2024-10-29 12:33:47] iter = 08280, loss = 2.2454
2024-10-29 12:33:47: [2024-10-29 12:33:47] iter = 08290, loss = 1.1241
2024-10-29 12:33:47: [2024-10-29 12:33:47] iter = 08300, loss = 2.6841
2024-10-29 12:33:48: [2024-10-29 12:33:48] iter = 08310, loss = 3.7518
2024-10-29 12:33:48: [2024-10-29 12:33:48] iter = 08320, loss = 4.3669
2024-10-29 12:33:48: [2024-10-29 12:33:48] iter = 08330, loss = 0.8494
2024-10-29 12:33:49: [2024-10-29 12:33:49] iter = 08340, loss = 4.0284
2024-10-29 12:33:49: [2024-10-29 12:33:49] iter = 08350, loss = 1.2837
2024-10-29 12:33:49: [2024-10-29 12:33:49] iter = 08360, loss = 1.7262
2024-10-29 12:33:50: [2024-10-29 12:33:50] iter = 08370, loss = 1.8443
2024-10-29 12:33:50: [2024-10-29 12:33:50] iter = 08380, loss = 1.6358
2024-10-29 12:33:50: [2024-10-29 12:33:50] iter = 08390, loss = 2.4118
2024-10-29 12:33:51: [2024-10-29 12:33:51] iter = 08400, loss = 1.1767
2024-10-29 12:33:51: [2024-10-29 12:33:51] iter = 08410, loss = 4.5917
2024-10-29 12:33:52: [2024-10-29 12:33:52] iter = 08420, loss = 1.5237
2024-10-29 12:33:52: [2024-10-29 12:33:52] iter = 08430, loss = 2.5758
2024-10-29 12:33:52: [2024-10-29 12:33:52] iter = 08440, loss = 1.0478
2024-10-29 12:33:53: [2024-10-29 12:33:53] iter = 08450, loss = 4.5514
2024-10-29 12:33:53: [2024-10-29 12:33:53] iter = 08460, loss = 1.5533
2024-10-29 12:33:53: [2024-10-29 12:33:53] iter = 08470, loss = 2.6558
2024-10-29 12:33:54: [2024-10-29 12:33:54] iter = 08480, loss = 3.1127
2024-10-29 12:33:54: [2024-10-29 12:33:54] iter = 08490, loss = 2.7372
2024-10-29 12:33:54: [2024-10-29 12:33:54] iter = 08500, loss = 1.4896
2024-10-29 12:33:55: [2024-10-29 12:33:55] iter = 08510, loss = 1.2674
2024-10-29 12:33:55: [2024-10-29 12:33:55] iter = 08520, loss = 1.2930
2024-10-29 12:33:55: [2024-10-29 12:33:55] iter = 08530, loss = 1.2639
2024-10-29 12:33:56: [2024-10-29 12:33:56] iter = 08540, loss = 0.7887
2024-10-29 12:33:56: [2024-10-29 12:33:56] iter = 08550, loss = 1.3976
2024-10-29 12:33:57: [2024-10-29 12:33:57] iter = 08560, loss = 1.4634
2024-10-29 12:33:57: [2024-10-29 12:33:57] iter = 08570, loss = 1.1192
2024-10-29 12:33:57: [2024-10-29 12:33:57] iter = 08580, loss = 1.1772
2024-10-29 12:33:58: [2024-10-29 12:33:58] iter = 08590, loss = 1.0354
2024-10-29 12:33:58: [2024-10-29 12:33:58] iter = 08600, loss = 1.9748
2024-10-29 12:33:59: [2024-10-29 12:33:59] iter = 08610, loss = 0.7988
2024-10-29 12:33:59: [2024-10-29 12:33:59] iter = 08620, loss = 1.4350
2024-10-29 12:33:59: [2024-10-29 12:33:59] iter = 08630, loss = 0.9880
2024-10-29 12:34:00: [2024-10-29 12:34:00] iter = 08640, loss = 0.9692
2024-10-29 12:34:00: [2024-10-29 12:34:00] iter = 08650, loss = 1.2667
2024-10-29 12:34:01: [2024-10-29 12:34:01] iter = 08660, loss = 0.9805
2024-10-29 12:34:01: [2024-10-29 12:34:01] iter = 08670, loss = 1.2072
2024-10-29 12:34:02: [2024-10-29 12:34:02] iter = 08680, loss = 1.9533
2024-10-29 12:34:02: [2024-10-29 12:34:02] iter = 08690, loss = 1.0503
2024-10-29 12:34:03: [2024-10-29 12:34:03] iter = 08700, loss = 1.5774
2024-10-29 12:34:03: [2024-10-29 12:34:03] iter = 08710, loss = 1.2602
2024-10-29 12:34:03: [2024-10-29 12:34:03] iter = 08720, loss = 1.0646
2024-10-29 12:34:04: [2024-10-29 12:34:04] iter = 08730, loss = 2.4139
2024-10-29 12:34:04: [2024-10-29 12:34:04] iter = 08740, loss = 1.8326
2024-10-29 12:34:04: [2024-10-29 12:34:04] iter = 08750, loss = 1.3026
2024-10-29 12:34:05: [2024-10-29 12:34:05] iter = 08760, loss = 1.2453
2024-10-29 12:34:05: [2024-10-29 12:34:05] iter = 08770, loss = 1.2224
2024-10-29 12:34:05: [2024-10-29 12:34:05] iter = 08780, loss = 2.6470
2024-10-29 12:34:06: [2024-10-29 12:34:06] iter = 08790, loss = 2.3412
2024-10-29 12:34:06: [2024-10-29 12:34:06] iter = 08800, loss = 0.8756
2024-10-29 12:34:06: [2024-10-29 12:34:06] iter = 08810, loss = 2.4954
2024-10-29 12:34:07: [2024-10-29 12:34:07] iter = 08820, loss = 1.8831
2024-10-29 12:34:07: [2024-10-29 12:34:07] iter = 08830, loss = 1.1778
2024-10-29 12:34:07: [2024-10-29 12:34:07] iter = 08840, loss = 2.6667
2024-10-29 12:34:08: [2024-10-29 12:34:08] iter = 08850, loss = 4.0516
2024-10-29 12:34:08: [2024-10-29 12:34:08] iter = 08860, loss = 1.4602
2024-10-29 12:34:08: [2024-10-29 12:34:08] iter = 08870, loss = 2.5655
2024-10-29 12:34:09: [2024-10-29 12:34:09] iter = 08880, loss = 1.3886
2024-10-29 12:34:09: [2024-10-29 12:34:09] iter = 08890, loss = 2.3773
2024-10-29 12:34:09: [2024-10-29 12:34:09] iter = 08900, loss = 1.1018
2024-10-29 12:34:10: [2024-10-29 12:34:10] iter = 08910, loss = 1.6069
2024-10-29 12:34:10: [2024-10-29 12:34:10] iter = 08920, loss = 1.6853
2024-10-29 12:34:10: [2024-10-29 12:34:10] iter = 08930, loss = 1.8845
2024-10-29 12:34:11: [2024-10-29 12:34:11] iter = 08940, loss = 1.6129
2024-10-29 12:34:11: [2024-10-29 12:34:11] iter = 08950, loss = 1.7330
2024-10-29 12:34:11: [2024-10-29 12:34:11] iter = 08960, loss = 1.5177
2024-10-29 12:34:12: [2024-10-29 12:34:12] iter = 08970, loss = 2.0194
2024-10-29 12:34:12: [2024-10-29 12:34:12] iter = 08980, loss = 1.4394
2024-10-29 12:34:12: [2024-10-29 12:34:12] iter = 08990, loss = 0.8322
2024-10-29 12:34:13: [2024-10-29 12:34:13] iter = 09000, loss = 0.8513
2024-10-29 12:34:13: [2024-10-29 12:34:13] iter = 09010, loss = 1.9370
2024-10-29 12:34:13: [2024-10-29 12:34:13] iter = 09020, loss = 2.1626
2024-10-29 12:34:14: [2024-10-29 12:34:14] iter = 09030, loss = 0.7834
2024-10-29 12:34:14: [2024-10-29 12:34:14] iter = 09040, loss = 2.0410
2024-10-29 12:34:15: [2024-10-29 12:34:15] iter = 09050, loss = 1.0549
2024-10-29 12:34:15: [2024-10-29 12:34:15] iter = 09060, loss = 0.9541
2024-10-29 12:34:15: [2024-10-29 12:34:15] iter = 09070, loss = 1.2410
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 09080, loss = 1.3444
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 09090, loss = 0.6940
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 09100, loss = 2.8668
2024-10-29 12:34:17: [2024-10-29 12:34:17] iter = 09110, loss = 1.0885
2024-10-29 12:34:17: [2024-10-29 12:34:17] iter = 09120, loss = 1.0440
2024-10-29 12:34:17: [2024-10-29 12:34:17] iter = 09130, loss = 5.1373
2024-10-29 12:34:18: [2024-10-29 12:34:18] iter = 09140, loss = 1.1861
2024-10-29 12:34:18: [2024-10-29 12:34:18] iter = 09150, loss = 1.8745
2024-10-29 12:34:19: [2024-10-29 12:34:19] iter = 09160, loss = 3.0859
2024-10-29 12:34:19: [2024-10-29 12:34:19] iter = 09170, loss = 1.6503
2024-10-29 12:34:19: [2024-10-29 12:34:19] iter = 09180, loss = 0.9236
2024-10-29 12:34:20: [2024-10-29 12:34:20] iter = 09190, loss = 1.3642
2024-10-29 12:34:20: [2024-10-29 12:34:20] iter = 09200, loss = 0.8154
2024-10-29 12:34:20: [2024-10-29 12:34:20] iter = 09210, loss = 1.1044
2024-10-29 12:34:21: [2024-10-29 12:34:21] iter = 09220, loss = 1.7444
2024-10-29 12:34:21: [2024-10-29 12:34:21] iter = 09230, loss = 1.6741
2024-10-29 12:34:21: [2024-10-29 12:34:21] iter = 09240, loss = 0.7258
2024-10-29 12:34:22: [2024-10-29 12:34:22] iter = 09250, loss = 1.3075
2024-10-29 12:34:22: [2024-10-29 12:34:22] iter = 09260, loss = 1.2215
2024-10-29 12:34:22: [2024-10-29 12:34:22] iter = 09270, loss = 3.8473
2024-10-29 12:34:23: [2024-10-29 12:34:23] iter = 09280, loss = 1.2650
2024-10-29 12:34:23: [2024-10-29 12:34:23] iter = 09290, loss = 1.2431
2024-10-29 12:34:23: [2024-10-29 12:34:23] iter = 09300, loss = 1.5539
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 09310, loss = 1.2087
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 09320, loss = 2.0777
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 09330, loss = 1.8773
2024-10-29 12:34:25: [2024-10-29 12:34:24] iter = 09340, loss = 1.0983
2024-10-29 12:34:25: [2024-10-29 12:34:25] iter = 09350, loss = 1.3657
2024-10-29 12:34:25: [2024-10-29 12:34:25] iter = 09360, loss = 1.4339
2024-10-29 12:34:25: [2024-10-29 12:34:25] iter = 09370, loss = 0.9781
2024-10-29 12:34:26: [2024-10-29 12:34:26] iter = 09380, loss = 1.3359
2024-10-29 12:34:26: [2024-10-29 12:34:26] iter = 09390, loss = 1.0939
2024-10-29 12:34:26: [2024-10-29 12:34:26] iter = 09400, loss = 9.2919
2024-10-29 12:34:27: [2024-10-29 12:34:27] iter = 09410, loss = 0.9841
2024-10-29 12:34:27: [2024-10-29 12:34:27] iter = 09420, loss = 1.8579
2024-10-29 12:34:28: [2024-10-29 12:34:28] iter = 09430, loss = 1.9869
2024-10-29 12:34:28: [2024-10-29 12:34:28] iter = 09440, loss = 0.9912
2024-10-29 12:34:28: [2024-10-29 12:34:28] iter = 09450, loss = 1.0624
2024-10-29 12:34:29: [2024-10-29 12:34:29] iter = 09460, loss = 1.0310
2024-10-29 12:34:29: [2024-10-29 12:34:29] iter = 09470, loss = 0.8928
2024-10-29 12:34:29: [2024-10-29 12:34:29] iter = 09480, loss = 1.1389
2024-10-29 12:34:30: [2024-10-29 12:34:30] iter = 09490, loss = 1.2783
2024-10-29 12:34:30: [2024-10-29 12:34:30] iter = 09500, loss = 1.7242
2024-10-29 12:34:30: [2024-10-29 12:34:30] iter = 09510, loss = 1.7020
2024-10-29 12:34:31: [2024-10-29 12:34:31] iter = 09520, loss = 1.3997
2024-10-29 12:34:31: [2024-10-29 12:34:31] iter = 09530, loss = 0.7436
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 09540, loss = 1.7324
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 09550, loss = 4.1760
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 09560, loss = 0.9003
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 09570, loss = 1.8734
2024-10-29 12:34:33: [2024-10-29 12:34:33] iter = 09580, loss = 3.2113
2024-10-29 12:34:33: [2024-10-29 12:34:33] iter = 09590, loss = 3.0125
2024-10-29 12:34:33: [2024-10-29 12:34:33] iter = 09600, loss = 1.0699
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 09610, loss = 1.1921
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 09620, loss = 1.0393
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 09630, loss = 1.0558
2024-10-29 12:34:35: [2024-10-29 12:34:35] iter = 09640, loss = 3.7479
2024-10-29 12:34:35: [2024-10-29 12:34:35] iter = 09650, loss = 1.0664
2024-10-29 12:34:35: [2024-10-29 12:34:35] iter = 09660, loss = 0.8648
2024-10-29 12:34:36: [2024-10-29 12:34:36] iter = 09670, loss = 1.0867
2024-10-29 12:34:36: [2024-10-29 12:34:36] iter = 09680, loss = 1.6037
2024-10-29 12:34:36: [2024-10-29 12:34:36] iter = 09690, loss = 0.7403
2024-10-29 12:34:37: [2024-10-29 12:34:37] iter = 09700, loss = 0.8386
2024-10-29 12:34:37: [2024-10-29 12:34:37] iter = 09710, loss = 1.2035
2024-10-29 12:34:38: [2024-10-29 12:34:38] iter = 09720, loss = 1.2569
2024-10-29 12:34:38: [2024-10-29 12:34:38] iter = 09730, loss = 1.3930
2024-10-29 12:34:38: [2024-10-29 12:34:38] iter = 09740, loss = 1.6763
2024-10-29 12:34:39: [2024-10-29 12:34:39] iter = 09750, loss = 0.8854
2024-10-29 12:34:39: [2024-10-29 12:34:39] iter = 09760, loss = 1.5346
2024-10-29 12:34:39: [2024-10-29 12:34:39] iter = 09770, loss = 1.5208
2024-10-29 12:34:40: [2024-10-29 12:34:40] iter = 09780, loss = 0.9288
2024-10-29 12:34:40: [2024-10-29 12:34:40] iter = 09790, loss = 1.2072
2024-10-29 12:34:40: [2024-10-29 12:34:40] iter = 09800, loss = 1.3896
2024-10-29 12:34:41: [2024-10-29 12:34:41] iter = 09810, loss = 1.4088
2024-10-29 12:34:41: [2024-10-29 12:34:41] iter = 09820, loss = 1.4380
2024-10-29 12:34:42: [2024-10-29 12:34:42] iter = 09830, loss = 1.1120
2024-10-29 12:34:42: [2024-10-29 12:34:42] iter = 09840, loss = 1.2658
2024-10-29 12:34:43: [2024-10-29 12:34:43] iter = 09850, loss = 1.1017
2024-10-29 12:34:43: [2024-10-29 12:34:43] iter = 09860, loss = 0.9539
2024-10-29 12:34:44: [2024-10-29 12:34:44] iter = 09870, loss = 3.2899
2024-10-29 12:34:44: [2024-10-29 12:34:44] iter = 09880, loss = 1.2631
2024-10-29 12:34:45: [2024-10-29 12:34:45] iter = 09890, loss = 1.3230
2024-10-29 12:34:45: [2024-10-29 12:34:45] iter = 09900, loss = 3.1645
2024-10-29 12:34:46: [2024-10-29 12:34:46] iter = 09910, loss = 1.9623
2024-10-29 12:34:46: [2024-10-29 12:34:46] iter = 09920, loss = 2.2036
2024-10-29 12:34:46: [2024-10-29 12:34:46] iter = 09930, loss = 1.2079
2024-10-29 12:34:47: [2024-10-29 12:34:47] iter = 09940, loss = 2.0134
2024-10-29 12:34:47: [2024-10-29 12:34:47] iter = 09950, loss = 1.1294
2024-10-29 12:34:48: [2024-10-29 12:34:48] iter = 09960, loss = 0.8986
2024-10-29 12:34:48: [2024-10-29 12:34:48] iter = 09970, loss = 1.7498
2024-10-29 12:34:48: [2024-10-29 12:34:48] iter = 09980, loss = 4.4384
2024-10-29 12:34:49: [2024-10-29 12:34:49] iter = 09990, loss = 1.3988
2024-10-29 12:34:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 12:34:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:34:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 89752}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:35:18: Evaluate 5 random ConvNet, ACCmean = 0.6962 ACCstd = 0.0180
-------------------------
2024-10-29 12:35:18: Evaluate 5 random ConvNet, SENmean = 0.5890 SENstd = 0.0047
-------------------------
2024-10-29 12:35:18: Evaluate 5 random ConvNet, SPEmean = 0.5890 SPEstd = 0.0047
-------------------------
2024-10-29 12:35:18: Evaluate 5 random ConvNet, F!mean = 0.5264 F!std = 0.0067
-------------------------
2024-10-29 12:35:18: Evaluate 5 random ConvNet, mean = 0.6962 std = 0.0180
-------------------------
2024-10-29 12:35:18: [2024-10-29 12:35:18] iter = 10000, loss = 1.7664
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:35:19: [2024-10-29 12:35:19] iter = 10010, loss = 2.2755
2024-10-29 12:35:19: [2024-10-29 12:35:19] iter = 10020, loss = 1.4685
2024-10-29 12:35:19: [2024-10-29 12:35:19] iter = 10030, loss = 1.0866
2024-10-29 12:35:20: [2024-10-29 12:35:20] iter = 10040, loss = 1.6534
2024-10-29 12:35:20: [2024-10-29 12:35:20] iter = 10050, loss = 1.8647
2024-10-29 12:35:20: [2024-10-29 12:35:20] iter = 10060, loss = 0.8579
2024-10-29 12:35:21: [2024-10-29 12:35:21] iter = 10070, loss = 1.4950
2024-10-29 12:35:21: [2024-10-29 12:35:21] iter = 10080, loss = 0.9445
2024-10-29 12:35:22: [2024-10-29 12:35:22] iter = 10090, loss = 0.6123
2024-10-29 12:35:22: [2024-10-29 12:35:22] iter = 10100, loss = 0.7792
2024-10-29 12:35:22: [2024-10-29 12:35:22] iter = 10110, loss = 1.2524
2024-10-29 12:35:23: [2024-10-29 12:35:23] iter = 10120, loss = 0.7820
2024-10-29 12:35:23: [2024-10-29 12:35:23] iter = 10130, loss = 2.6234
2024-10-29 12:35:23: [2024-10-29 12:35:23] iter = 10140, loss = 1.1183
2024-10-29 12:35:24: [2024-10-29 12:35:24] iter = 10150, loss = 1.1444
2024-10-29 12:35:24: [2024-10-29 12:35:24] iter = 10160, loss = 1.3206
2024-10-29 12:35:24: [2024-10-29 12:35:24] iter = 10170, loss = 1.6529
2024-10-29 12:35:25: [2024-10-29 12:35:25] iter = 10180, loss = 2.1559
2024-10-29 12:35:25: [2024-10-29 12:35:25] iter = 10190, loss = 1.9463
2024-10-29 12:35:25: [2024-10-29 12:35:25] iter = 10200, loss = 1.0832
2024-10-29 12:35:26: [2024-10-29 12:35:26] iter = 10210, loss = 0.7693
2024-10-29 12:35:26: [2024-10-29 12:35:26] iter = 10220, loss = 4.1227
2024-10-29 12:35:26: [2024-10-29 12:35:26] iter = 10230, loss = 1.8630
2024-10-29 12:35:27: [2024-10-29 12:35:27] iter = 10240, loss = 1.5270
2024-10-29 12:35:27: [2024-10-29 12:35:27] iter = 10250, loss = 3.6804
2024-10-29 12:35:27: [2024-10-29 12:35:27] iter = 10260, loss = 4.1579
2024-10-29 12:35:28: [2024-10-29 12:35:28] iter = 10270, loss = 1.0940
2024-10-29 12:35:28: [2024-10-29 12:35:28] iter = 10280, loss = 1.4114
2024-10-29 12:35:28: [2024-10-29 12:35:28] iter = 10290, loss = 1.2962
2024-10-29 12:35:29: [2024-10-29 12:35:29] iter = 10300, loss = 1.8310
2024-10-29 12:35:29: [2024-10-29 12:35:29] iter = 10310, loss = 1.4761
2024-10-29 12:35:29: [2024-10-29 12:35:29] iter = 10320, loss = 3.6865
2024-10-29 12:35:30: [2024-10-29 12:35:30] iter = 10330, loss = 0.8588
2024-10-29 12:35:30: [2024-10-29 12:35:30] iter = 10340, loss = 1.1269
2024-10-29 12:35:31: [2024-10-29 12:35:31] iter = 10350, loss = 1.4041
2024-10-29 12:35:31: [2024-10-29 12:35:31] iter = 10360, loss = 1.4565
2024-10-29 12:35:31: [2024-10-29 12:35:31] iter = 10370, loss = 1.3239
2024-10-29 12:35:32: [2024-10-29 12:35:32] iter = 10380, loss = 1.2661
2024-10-29 12:35:32: [2024-10-29 12:35:32] iter = 10390, loss = 1.8508
2024-10-29 12:35:33: [2024-10-29 12:35:33] iter = 10400, loss = 1.4971
2024-10-29 12:35:34: [2024-10-29 12:35:34] iter = 10410, loss = 6.9995
2024-10-29 12:35:34: [2024-10-29 12:35:34] iter = 10420, loss = 1.9926
2024-10-29 12:35:35: [2024-10-29 12:35:35] iter = 10430, loss = 1.1841
2024-10-29 12:35:35: [2024-10-29 12:35:35] iter = 10440, loss = 1.0884
2024-10-29 12:35:35: [2024-10-29 12:35:35] iter = 10450, loss = 1.0754
2024-10-29 12:35:36: [2024-10-29 12:35:36] iter = 10460, loss = 7.0943
2024-10-29 12:35:36: [2024-10-29 12:35:36] iter = 10470, loss = 2.4597
2024-10-29 12:35:37: [2024-10-29 12:35:37] iter = 10480, loss = 5.1811
2024-10-29 12:35:37: [2024-10-29 12:35:37] iter = 10490, loss = 3.8938
2024-10-29 12:35:38: [2024-10-29 12:35:38] iter = 10500, loss = 2.7430
2024-10-29 12:35:38: [2024-10-29 12:35:38] iter = 10510, loss = 1.2688
2024-10-29 12:35:39: [2024-10-29 12:35:39] iter = 10520, loss = 0.7707
2024-10-29 12:35:39: [2024-10-29 12:35:39] iter = 10530, loss = 1.3332
2024-10-29 12:35:39: [2024-10-29 12:35:39] iter = 10540, loss = 1.6221
2024-10-29 12:35:40: [2024-10-29 12:35:40] iter = 10550, loss = 1.3645
2024-10-29 12:35:40: [2024-10-29 12:35:40] iter = 10560, loss = 2.5407
2024-10-29 12:35:40: [2024-10-29 12:35:40] iter = 10570, loss = 2.1640
2024-10-29 12:35:41: [2024-10-29 12:35:41] iter = 10580, loss = 1.4009
2024-10-29 12:35:41: [2024-10-29 12:35:41] iter = 10590, loss = 2.9257
2024-10-29 12:35:41: [2024-10-29 12:35:41] iter = 10600, loss = 1.2430
2024-10-29 12:35:42: [2024-10-29 12:35:42] iter = 10610, loss = 1.2066
2024-10-29 12:35:42: [2024-10-29 12:35:42] iter = 10620, loss = 1.5824
2024-10-29 12:35:42: [2024-10-29 12:35:42] iter = 10630, loss = 1.8273
2024-10-29 12:35:43: [2024-10-29 12:35:43] iter = 10640, loss = 1.2677
2024-10-29 12:35:43: [2024-10-29 12:35:43] iter = 10650, loss = 1.4155
2024-10-29 12:35:43: [2024-10-29 12:35:43] iter = 10660, loss = 0.8553
2024-10-29 12:35:44: [2024-10-29 12:35:44] iter = 10670, loss = 2.4034
2024-10-29 12:35:44: [2024-10-29 12:35:44] iter = 10680, loss = 1.4836
2024-10-29 12:35:45: [2024-10-29 12:35:45] iter = 10690, loss = 2.1623
2024-10-29 12:35:45: [2024-10-29 12:35:45] iter = 10700, loss = 1.4983
2024-10-29 12:35:46: [2024-10-29 12:35:46] iter = 10710, loss = 1.3442
2024-10-29 12:35:46: [2024-10-29 12:35:46] iter = 10720, loss = 1.8668
2024-10-29 12:35:46: [2024-10-29 12:35:46] iter = 10730, loss = 1.1175
2024-10-29 12:35:47: [2024-10-29 12:35:47] iter = 10740, loss = 1.5425
2024-10-29 12:35:47: [2024-10-29 12:35:47] iter = 10750, loss = 1.3056
2024-10-29 12:35:48: [2024-10-29 12:35:48] iter = 10760, loss = 2.5694
2024-10-29 12:35:48: [2024-10-29 12:35:48] iter = 10770, loss = 2.0317
2024-10-29 12:35:49: [2024-10-29 12:35:49] iter = 10780, loss = 5.7679
2024-10-29 12:35:49: [2024-10-29 12:35:49] iter = 10790, loss = 0.8550
2024-10-29 12:35:50: [2024-10-29 12:35:50] iter = 10800, loss = 3.4125
2024-10-29 12:35:50: [2024-10-29 12:35:50] iter = 10810, loss = 1.4310
2024-10-29 12:35:51: [2024-10-29 12:35:51] iter = 10820, loss = 0.9505
2024-10-29 12:35:51: [2024-10-29 12:35:51] iter = 10830, loss = 1.2015
2024-10-29 12:35:51: [2024-10-29 12:35:51] iter = 10840, loss = 1.0729
2024-10-29 12:35:52: [2024-10-29 12:35:52] iter = 10850, loss = 1.4309
2024-10-29 12:35:52: [2024-10-29 12:35:52] iter = 10860, loss = 1.4710
2024-10-29 12:35:52: [2024-10-29 12:35:52] iter = 10870, loss = 1.8454
2024-10-29 12:35:53: [2024-10-29 12:35:53] iter = 10880, loss = 3.0015
2024-10-29 12:35:53: [2024-10-29 12:35:53] iter = 10890, loss = 1.6467
2024-10-29 12:35:54: [2024-10-29 12:35:54] iter = 10900, loss = 1.0788
2024-10-29 12:35:54: [2024-10-29 12:35:54] iter = 10910, loss = 0.6003
2024-10-29 12:35:54: [2024-10-29 12:35:54] iter = 10920, loss = 1.0600
2024-10-29 12:35:55: [2024-10-29 12:35:55] iter = 10930, loss = 2.5360
2024-10-29 12:35:55: [2024-10-29 12:35:55] iter = 10940, loss = 1.3177
2024-10-29 12:35:55: [2024-10-29 12:35:55] iter = 10950, loss = 0.8869
2024-10-29 12:35:56: [2024-10-29 12:35:56] iter = 10960, loss = 1.2612
2024-10-29 12:35:56: [2024-10-29 12:35:56] iter = 10970, loss = 1.1600
2024-10-29 12:35:56: [2024-10-29 12:35:56] iter = 10980, loss = 1.5581
2024-10-29 12:35:57: [2024-10-29 12:35:57] iter = 10990, loss = 1.9307
2024-10-29 12:35:57: [2024-10-29 12:35:57] iter = 11000, loss = 1.4880
2024-10-29 12:35:57: [2024-10-29 12:35:57] iter = 11010, loss = 2.3502
2024-10-29 12:35:58: [2024-10-29 12:35:58] iter = 11020, loss = 1.0010
2024-10-29 12:35:58: [2024-10-29 12:35:58] iter = 11030, loss = 2.6879
2024-10-29 12:35:58: [2024-10-29 12:35:58] iter = 11040, loss = 2.8733
2024-10-29 12:35:59: [2024-10-29 12:35:59] iter = 11050, loss = 1.5789
2024-10-29 12:35:59: [2024-10-29 12:35:59] iter = 11060, loss = 1.4019
2024-10-29 12:35:59: [2024-10-29 12:35:59] iter = 11070, loss = 1.7123
2024-10-29 12:36:00: [2024-10-29 12:36:00] iter = 11080, loss = 1.0540
2024-10-29 12:36:00: [2024-10-29 12:36:00] iter = 11090, loss = 5.2180
2024-10-29 12:36:00: [2024-10-29 12:36:00] iter = 11100, loss = 0.9784
2024-10-29 12:36:01: [2024-10-29 12:36:01] iter = 11110, loss = 1.2498
2024-10-29 12:36:01: [2024-10-29 12:36:01] iter = 11120, loss = 2.0622
2024-10-29 12:36:01: [2024-10-29 12:36:01] iter = 11130, loss = 0.8174
2024-10-29 12:36:02: [2024-10-29 12:36:02] iter = 11140, loss = 1.4271
2024-10-29 12:36:02: [2024-10-29 12:36:02] iter = 11150, loss = 1.4577
2024-10-29 12:36:02: [2024-10-29 12:36:02] iter = 11160, loss = 2.0934
2024-10-29 12:36:03: [2024-10-29 12:36:03] iter = 11170, loss = 1.5522
2024-10-29 12:36:03: [2024-10-29 12:36:03] iter = 11180, loss = 2.6976
2024-10-29 12:36:03: [2024-10-29 12:36:03] iter = 11190, loss = 1.2211
2024-10-29 12:36:04: [2024-10-29 12:36:04] iter = 11200, loss = 0.9313
2024-10-29 12:36:04: [2024-10-29 12:36:04] iter = 11210, loss = 0.9670
2024-10-29 12:36:05: [2024-10-29 12:36:05] iter = 11220, loss = 1.0139
2024-10-29 12:36:05: [2024-10-29 12:36:05] iter = 11230, loss = 1.9756
2024-10-29 12:36:06: [2024-10-29 12:36:06] iter = 11240, loss = 1.0040
2024-10-29 12:36:06: [2024-10-29 12:36:06] iter = 11250, loss = 1.5403
2024-10-29 12:36:07: [2024-10-29 12:36:07] iter = 11260, loss = 0.8871
2024-10-29 12:36:07: [2024-10-29 12:36:07] iter = 11270, loss = 3.0265
2024-10-29 12:36:08: [2024-10-29 12:36:08] iter = 11280, loss = 0.7768
2024-10-29 12:36:08: [2024-10-29 12:36:08] iter = 11290, loss = 2.2115
2024-10-29 12:36:09: [2024-10-29 12:36:09] iter = 11300, loss = 1.1626
2024-10-29 12:36:09: [2024-10-29 12:36:09] iter = 11310, loss = 1.0270
2024-10-29 12:36:09: [2024-10-29 12:36:09] iter = 11320, loss = 1.8934
2024-10-29 12:36:10: [2024-10-29 12:36:10] iter = 11330, loss = 1.2683
2024-10-29 12:36:10: [2024-10-29 12:36:10] iter = 11340, loss = 2.7545
2024-10-29 12:36:11: [2024-10-29 12:36:11] iter = 11350, loss = 4.5292
2024-10-29 12:36:11: [2024-10-29 12:36:11] iter = 11360, loss = 1.0571
2024-10-29 12:36:11: [2024-10-29 12:36:11] iter = 11370, loss = 1.5916
2024-10-29 12:36:12: [2024-10-29 12:36:12] iter = 11380, loss = 1.1874
2024-10-29 12:36:12: [2024-10-29 12:36:12] iter = 11390, loss = 0.8845
2024-10-29 12:36:13: [2024-10-29 12:36:13] iter = 11400, loss = 0.8083
2024-10-29 12:36:13: [2024-10-29 12:36:13] iter = 11410, loss = 1.1182
2024-10-29 12:36:13: [2024-10-29 12:36:13] iter = 11420, loss = 4.2356
2024-10-29 12:36:14: [2024-10-29 12:36:14] iter = 11430, loss = 3.8376
2024-10-29 12:36:14: [2024-10-29 12:36:14] iter = 11440, loss = 1.4378
2024-10-29 12:36:14: [2024-10-29 12:36:14] iter = 11450, loss = 2.7283
2024-10-29 12:36:15: [2024-10-29 12:36:15] iter = 11460, loss = 4.4515
2024-10-29 12:36:15: [2024-10-29 12:36:15] iter = 11470, loss = 1.2413
2024-10-29 12:36:16: [2024-10-29 12:36:16] iter = 11480, loss = 7.8229
2024-10-29 12:36:16: [2024-10-29 12:36:16] iter = 11490, loss = 1.1655
2024-10-29 12:36:16: [2024-10-29 12:36:16] iter = 11500, loss = 0.9358
2024-10-29 12:36:17: [2024-10-29 12:36:17] iter = 11510, loss = 0.7934
2024-10-29 12:36:17: [2024-10-29 12:36:17] iter = 11520, loss = 11.6461
2024-10-29 12:36:18: [2024-10-29 12:36:18] iter = 11530, loss = 1.4792
2024-10-29 12:36:18: [2024-10-29 12:36:18] iter = 11540, loss = 1.6219
2024-10-29 12:36:19: [2024-10-29 12:36:19] iter = 11550, loss = 1.0839
2024-10-29 12:36:19: [2024-10-29 12:36:19] iter = 11560, loss = 5.8160
2024-10-29 12:36:20: [2024-10-29 12:36:20] iter = 11570, loss = 1.6006
2024-10-29 12:36:20: [2024-10-29 12:36:20] iter = 11580, loss = 1.9988
2024-10-29 12:36:20: [2024-10-29 12:36:20] iter = 11590, loss = 1.7350
2024-10-29 12:36:21: [2024-10-29 12:36:21] iter = 11600, loss = 1.7704
2024-10-29 12:36:21: [2024-10-29 12:36:21] iter = 11610, loss = 6.2552
2024-10-29 12:36:21: [2024-10-29 12:36:21] iter = 11620, loss = 0.9844
2024-10-29 12:36:22: [2024-10-29 12:36:22] iter = 11630, loss = 1.0202
2024-10-29 12:36:22: [2024-10-29 12:36:22] iter = 11640, loss = 1.3763
2024-10-29 12:36:23: [2024-10-29 12:36:23] iter = 11650, loss = 0.9322
2024-10-29 12:36:24: [2024-10-29 12:36:24] iter = 11660, loss = 1.1278
2024-10-29 12:36:24: [2024-10-29 12:36:24] iter = 11670, loss = 1.0019
2024-10-29 12:36:25: [2024-10-29 12:36:25] iter = 11680, loss = 1.4989
2024-10-29 12:36:25: [2024-10-29 12:36:25] iter = 11690, loss = 0.8295
2024-10-29 12:36:25: [2024-10-29 12:36:25] iter = 11700, loss = 1.1658
2024-10-29 12:36:26: [2024-10-29 12:36:26] iter = 11710, loss = 1.9825
2024-10-29 12:36:26: [2024-10-29 12:36:26] iter = 11720, loss = 1.5186
2024-10-29 12:36:27: [2024-10-29 12:36:27] iter = 11730, loss = 1.2017
2024-10-29 12:36:27: [2024-10-29 12:36:27] iter = 11740, loss = 1.0805
2024-10-29 12:36:28: [2024-10-29 12:36:28] iter = 11750, loss = 1.8583
2024-10-29 12:36:28: [2024-10-29 12:36:28] iter = 11760, loss = 4.6849
2024-10-29 12:36:29: [2024-10-29 12:36:29] iter = 11770, loss = 3.4104
2024-10-29 12:36:29: [2024-10-29 12:36:29] iter = 11780, loss = 1.1408
2024-10-29 12:36:29: [2024-10-29 12:36:29] iter = 11790, loss = 1.4345
2024-10-29 12:36:30: [2024-10-29 12:36:30] iter = 11800, loss = 1.3315
2024-10-29 12:36:30: [2024-10-29 12:36:30] iter = 11810, loss = 1.2639
2024-10-29 12:36:31: [2024-10-29 12:36:31] iter = 11820, loss = 1.7980
2024-10-29 12:36:31: [2024-10-29 12:36:31] iter = 11830, loss = 1.1352
2024-10-29 12:36:31: [2024-10-29 12:36:31] iter = 11840, loss = 1.4165
2024-10-29 12:36:32: [2024-10-29 12:36:32] iter = 11850, loss = 1.5004
2024-10-29 12:36:32: [2024-10-29 12:36:32] iter = 11860, loss = 1.2877
2024-10-29 12:36:32: [2024-10-29 12:36:32] iter = 11870, loss = 1.3062
2024-10-29 12:36:33: [2024-10-29 12:36:33] iter = 11880, loss = 1.5683
2024-10-29 12:36:33: [2024-10-29 12:36:33] iter = 11890, loss = 1.5616
2024-10-29 12:36:33: [2024-10-29 12:36:33] iter = 11900, loss = 2.4467
2024-10-29 12:36:34: [2024-10-29 12:36:34] iter = 11910, loss = 0.7990
2024-10-29 12:36:34: [2024-10-29 12:36:34] iter = 11920, loss = 2.2316
2024-10-29 12:36:34: [2024-10-29 12:36:34] iter = 11930, loss = 1.3339
2024-10-29 12:36:35: [2024-10-29 12:36:35] iter = 11940, loss = 1.3330
2024-10-29 12:36:35: [2024-10-29 12:36:35] iter = 11950, loss = 1.2022
2024-10-29 12:36:36: [2024-10-29 12:36:36] iter = 11960, loss = 1.3626
2024-10-29 12:36:36: [2024-10-29 12:36:36] iter = 11970, loss = 1.3456
2024-10-29 12:36:36: [2024-10-29 12:36:36] iter = 11980, loss = 1.2335
2024-10-29 12:36:37: [2024-10-29 12:36:37] iter = 11990, loss = 5.6291
2024-10-29 12:36:37: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 12:36:37: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:36:37: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97452}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:37:08: Evaluate 5 random ConvNet, ACCmean = 0.5827 ACCstd = 0.0144
-------------------------
2024-10-29 12:37:08: Evaluate 5 random ConvNet, SENmean = 0.6009 SENstd = 0.0056
-------------------------
2024-10-29 12:37:08: Evaluate 5 random ConvNet, SPEmean = 0.6009 SPEstd = 0.0056
-------------------------
2024-10-29 12:37:08: Evaluate 5 random ConvNet, F!mean = 0.4778 F!std = 0.0078
-------------------------
2024-10-29 12:37:08: Evaluate 5 random ConvNet, mean = 0.5827 std = 0.0144
-------------------------
2024-10-29 12:37:08: [2024-10-29 12:37:08] iter = 12000, loss = 1.4350
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:37:08: [2024-10-29 12:37:08] iter = 12010, loss = 3.6909
2024-10-29 12:37:08: [2024-10-29 12:37:08] iter = 12020, loss = 2.8341
2024-10-29 12:37:09: [2024-10-29 12:37:09] iter = 12030, loss = 1.1167
2024-10-29 12:37:09: [2024-10-29 12:37:09] iter = 12040, loss = 1.0414
2024-10-29 12:37:09: [2024-10-29 12:37:09] iter = 12050, loss = 1.2026
2024-10-29 12:37:10: [2024-10-29 12:37:10] iter = 12060, loss = 0.8443
2024-10-29 12:37:10: [2024-10-29 12:37:10] iter = 12070, loss = 1.6083
2024-10-29 12:37:10: [2024-10-29 12:37:10] iter = 12080, loss = 1.6551
2024-10-29 12:37:11: [2024-10-29 12:37:11] iter = 12090, loss = 1.5005
2024-10-29 12:37:11: [2024-10-29 12:37:11] iter = 12100, loss = 1.3618
2024-10-29 12:37:11: [2024-10-29 12:37:11] iter = 12110, loss = 5.2382
2024-10-29 12:37:12: [2024-10-29 12:37:12] iter = 12120, loss = 1.4205
2024-10-29 12:37:12: [2024-10-29 12:37:12] iter = 12130, loss = 2.6602
2024-10-29 12:37:13: [2024-10-29 12:37:13] iter = 12140, loss = 1.9507
2024-10-29 12:37:13: [2024-10-29 12:37:13] iter = 12150, loss = 1.6329
2024-10-29 12:37:14: [2024-10-29 12:37:14] iter = 12160, loss = 1.6580
2024-10-29 12:37:14: [2024-10-29 12:37:14] iter = 12170, loss = 4.4092
2024-10-29 12:37:15: [2024-10-29 12:37:15] iter = 12180, loss = 1.5886
2024-10-29 12:37:15: [2024-10-29 12:37:15] iter = 12190, loss = 0.9470
2024-10-29 12:37:16: [2024-10-29 12:37:16] iter = 12200, loss = 1.3597
2024-10-29 12:37:16: [2024-10-29 12:37:16] iter = 12210, loss = 2.2025
2024-10-29 12:37:16: [2024-10-29 12:37:16] iter = 12220, loss = 1.2562
2024-10-29 12:37:17: [2024-10-29 12:37:17] iter = 12230, loss = 3.0521
2024-10-29 12:37:17: [2024-10-29 12:37:17] iter = 12240, loss = 1.6677
2024-10-29 12:37:18: [2024-10-29 12:37:18] iter = 12250, loss = 1.2606
2024-10-29 12:37:18: [2024-10-29 12:37:18] iter = 12260, loss = 1.3390
2024-10-29 12:37:19: [2024-10-29 12:37:19] iter = 12270, loss = 1.5362
2024-10-29 12:37:19: [2024-10-29 12:37:19] iter = 12280, loss = 1.5461
2024-10-29 12:37:19: [2024-10-29 12:37:19] iter = 12290, loss = 1.0757
2024-10-29 12:37:20: [2024-10-29 12:37:20] iter = 12300, loss = 1.3155
2024-10-29 12:37:20: [2024-10-29 12:37:20] iter = 12310, loss = 6.3414
2024-10-29 12:37:20: [2024-10-29 12:37:20] iter = 12320, loss = 3.4828
2024-10-29 12:37:21: [2024-10-29 12:37:21] iter = 12330, loss = 2.1516
2024-10-29 12:37:21: [2024-10-29 12:37:21] iter = 12340, loss = 0.7758
2024-10-29 12:37:22: [2024-10-29 12:37:22] iter = 12350, loss = 1.2004
2024-10-29 12:37:22: [2024-10-29 12:37:22] iter = 12360, loss = 0.6352
2024-10-29 12:37:22: [2024-10-29 12:37:22] iter = 12370, loss = 1.6383
2024-10-29 12:37:23: [2024-10-29 12:37:23] iter = 12380, loss = 1.4022
2024-10-29 12:37:23: [2024-10-29 12:37:23] iter = 12390, loss = 1.3473
2024-10-29 12:37:23: [2024-10-29 12:37:23] iter = 12400, loss = 11.2085
2024-10-29 12:37:24: [2024-10-29 12:37:24] iter = 12410, loss = 1.9644
2024-10-29 12:37:24: [2024-10-29 12:37:24] iter = 12420, loss = 1.8569
2024-10-29 12:37:25: [2024-10-29 12:37:25] iter = 12430, loss = 1.1791
2024-10-29 12:37:25: [2024-10-29 12:37:25] iter = 12440, loss = 0.7849
2024-10-29 12:37:25: [2024-10-29 12:37:25] iter = 12450, loss = 1.3466
2024-10-29 12:37:26: [2024-10-29 12:37:26] iter = 12460, loss = 1.1997
2024-10-29 12:37:26: [2024-10-29 12:37:26] iter = 12470, loss = 1.4887
2024-10-29 12:37:26: [2024-10-29 12:37:26] iter = 12480, loss = 2.2548
2024-10-29 12:37:27: [2024-10-29 12:37:27] iter = 12490, loss = 1.9052
2024-10-29 12:37:27: [2024-10-29 12:37:27] iter = 12500, loss = 1.9109
2024-10-29 12:37:28: [2024-10-29 12:37:28] iter = 12510, loss = 4.4483
2024-10-29 12:37:28: [2024-10-29 12:37:28] iter = 12520, loss = 2.2880
2024-10-29 12:37:29: [2024-10-29 12:37:29] iter = 12530, loss = 2.0369
2024-10-29 12:37:29: [2024-10-29 12:37:29] iter = 12540, loss = 1.1901
2024-10-29 12:37:29: [2024-10-29 12:37:29] iter = 12550, loss = 7.1123
2024-10-29 12:37:30: [2024-10-29 12:37:30] iter = 12560, loss = 2.3998
2024-10-29 12:37:30: [2024-10-29 12:37:30] iter = 12570, loss = 1.1237
2024-10-29 12:37:31: [2024-10-29 12:37:31] iter = 12580, loss = 1.4741
2024-10-29 12:37:31: [2024-10-29 12:37:31] iter = 12590, loss = 2.1675
2024-10-29 12:37:31: [2024-10-29 12:37:31] iter = 12600, loss = 0.8790
2024-10-29 12:37:32: [2024-10-29 12:37:32] iter = 12610, loss = 1.5574
2024-10-29 12:37:32: [2024-10-29 12:37:32] iter = 12620, loss = 1.6571
2024-10-29 12:37:32: [2024-10-29 12:37:32] iter = 12630, loss = 1.7247
2024-10-29 12:37:33: [2024-10-29 12:37:33] iter = 12640, loss = 1.3992
2024-10-29 12:37:33: [2024-10-29 12:37:33] iter = 12650, loss = 2.6150
2024-10-29 12:37:33: [2024-10-29 12:37:33] iter = 12660, loss = 1.0320
2024-10-29 12:37:34: [2024-10-29 12:37:34] iter = 12670, loss = 1.3772
2024-10-29 12:37:34: [2024-10-29 12:37:34] iter = 12680, loss = 1.4629
2024-10-29 12:37:34: [2024-10-29 12:37:34] iter = 12690, loss = 1.2775
2024-10-29 12:37:35: [2024-10-29 12:37:35] iter = 12700, loss = 0.9903
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 12710, loss = 2.6608
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 12720, loss = 0.9559
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 12730, loss = 1.0184
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 12740, loss = 2.0300
2024-10-29 12:37:37: [2024-10-29 12:37:37] iter = 12750, loss = 1.0282
2024-10-29 12:37:37: [2024-10-29 12:37:37] iter = 12760, loss = 1.3023
2024-10-29 12:37:38: [2024-10-29 12:37:38] iter = 12770, loss = 1.2801
2024-10-29 12:37:38: [2024-10-29 12:37:38] iter = 12780, loss = 1.2796
2024-10-29 12:37:38: [2024-10-29 12:37:38] iter = 12790, loss = 2.2993
2024-10-29 12:37:39: [2024-10-29 12:37:39] iter = 12800, loss = 3.2024
2024-10-29 12:37:39: [2024-10-29 12:37:39] iter = 12810, loss = 1.4909
2024-10-29 12:37:39: [2024-10-29 12:37:39] iter = 12820, loss = 2.2596
2024-10-29 12:37:40: [2024-10-29 12:37:40] iter = 12830, loss = 1.0173
2024-10-29 12:37:40: [2024-10-29 12:37:40] iter = 12840, loss = 0.9488
2024-10-29 12:37:41: [2024-10-29 12:37:41] iter = 12850, loss = 1.4384
2024-10-29 12:37:41: [2024-10-29 12:37:41] iter = 12860, loss = 1.4940
2024-10-29 12:37:41: [2024-10-29 12:37:41] iter = 12870, loss = 0.9126
2024-10-29 12:37:42: [2024-10-29 12:37:42] iter = 12880, loss = 2.0956
2024-10-29 12:37:42: [2024-10-29 12:37:42] iter = 12890, loss = 1.6534
2024-10-29 12:37:42: [2024-10-29 12:37:42] iter = 12900, loss = 1.4140
2024-10-29 12:37:43: [2024-10-29 12:37:43] iter = 12910, loss = 0.7375
2024-10-29 12:37:43: [2024-10-29 12:37:43] iter = 12920, loss = 1.2181
2024-10-29 12:37:43: [2024-10-29 12:37:43] iter = 12930, loss = 1.4972
2024-10-29 12:37:44: [2024-10-29 12:37:44] iter = 12940, loss = 1.3345
2024-10-29 12:37:44: [2024-10-29 12:37:44] iter = 12950, loss = 7.5540
2024-10-29 12:37:44: [2024-10-29 12:37:44] iter = 12960, loss = 1.1845
2024-10-29 12:37:45: [2024-10-29 12:37:45] iter = 12970, loss = 1.3893
2024-10-29 12:37:45: [2024-10-29 12:37:45] iter = 12980, loss = 1.2554
2024-10-29 12:37:45: [2024-10-29 12:37:45] iter = 12990, loss = 1.2918
2024-10-29 12:37:46: [2024-10-29 12:37:46] iter = 13000, loss = 1.5981
2024-10-29 12:37:46: [2024-10-29 12:37:46] iter = 13010, loss = 1.5388
2024-10-29 12:37:46: [2024-10-29 12:37:46] iter = 13020, loss = 1.3103
2024-10-29 12:37:47: [2024-10-29 12:37:47] iter = 13030, loss = 3.5586
2024-10-29 12:37:47: [2024-10-29 12:37:47] iter = 13040, loss = 1.8712
2024-10-29 12:37:47: [2024-10-29 12:37:47] iter = 13050, loss = 1.0303
2024-10-29 12:37:48: [2024-10-29 12:37:48] iter = 13060, loss = 0.9894
2024-10-29 12:37:48: [2024-10-29 12:37:48] iter = 13070, loss = 1.7459
2024-10-29 12:37:49: [2024-10-29 12:37:49] iter = 13080, loss = 1.4932
2024-10-29 12:37:49: [2024-10-29 12:37:49] iter = 13090, loss = 1.7302
2024-10-29 12:37:49: [2024-10-29 12:37:49] iter = 13100, loss = 0.9405
2024-10-29 12:37:50: [2024-10-29 12:37:50] iter = 13110, loss = 1.3131
2024-10-29 12:37:50: [2024-10-29 12:37:50] iter = 13120, loss = 0.7412
2024-10-29 12:37:50: [2024-10-29 12:37:50] iter = 13130, loss = 0.9032
2024-10-29 12:37:51: [2024-10-29 12:37:51] iter = 13140, loss = 1.4006
2024-10-29 12:37:51: [2024-10-29 12:37:51] iter = 13150, loss = 1.1957
2024-10-29 12:37:51: [2024-10-29 12:37:51] iter = 13160, loss = 1.4703
2024-10-29 12:37:52: [2024-10-29 12:37:52] iter = 13170, loss = 5.9793
2024-10-29 12:37:52: [2024-10-29 12:37:52] iter = 13180, loss = 1.0809
2024-10-29 12:37:53: [2024-10-29 12:37:53] iter = 13190, loss = 1.3826
2024-10-29 12:37:53: [2024-10-29 12:37:53] iter = 13200, loss = 1.2686
2024-10-29 12:37:53: [2024-10-29 12:37:53] iter = 13210, loss = 1.5650
2024-10-29 12:37:54: [2024-10-29 12:37:54] iter = 13220, loss = 0.9785
2024-10-29 12:37:54: [2024-10-29 12:37:54] iter = 13230, loss = 1.6040
2024-10-29 12:37:55: [2024-10-29 12:37:55] iter = 13240, loss = 1.4247
2024-10-29 12:37:55: [2024-10-29 12:37:55] iter = 13250, loss = 1.3205
2024-10-29 12:37:55: [2024-10-29 12:37:55] iter = 13260, loss = 1.1850
2024-10-29 12:37:56: [2024-10-29 12:37:56] iter = 13270, loss = 1.5898
2024-10-29 12:37:56: [2024-10-29 12:37:56] iter = 13280, loss = 1.0143
2024-10-29 12:37:57: [2024-10-29 12:37:56] iter = 13290, loss = 6.3478
2024-10-29 12:37:57: [2024-10-29 12:37:57] iter = 13300, loss = 1.6486
2024-10-29 12:37:57: [2024-10-29 12:37:57] iter = 13310, loss = 2.1821
2024-10-29 12:37:58: [2024-10-29 12:37:58] iter = 13320, loss = 1.2422
2024-10-29 12:37:58: [2024-10-29 12:37:58] iter = 13330, loss = 1.4179
2024-10-29 12:37:58: [2024-10-29 12:37:58] iter = 13340, loss = 1.4049
2024-10-29 12:37:59: [2024-10-29 12:37:59] iter = 13350, loss = 6.6969
2024-10-29 12:37:59: [2024-10-29 12:37:59] iter = 13360, loss = 0.8136
2024-10-29 12:37:59: [2024-10-29 12:37:59] iter = 13370, loss = 1.4693
2024-10-29 12:38:00: [2024-10-29 12:38:00] iter = 13380, loss = 1.3582
2024-10-29 12:38:00: [2024-10-29 12:38:00] iter = 13390, loss = 2.3669
2024-10-29 12:38:01: [2024-10-29 12:38:01] iter = 13400, loss = 4.5693
2024-10-29 12:38:01: [2024-10-29 12:38:01] iter = 13410, loss = 0.7427
2024-10-29 12:38:01: [2024-10-29 12:38:01] iter = 13420, loss = 1.3830
2024-10-29 12:38:02: [2024-10-29 12:38:02] iter = 13430, loss = 1.8044
2024-10-29 12:38:02: [2024-10-29 12:38:02] iter = 13440, loss = 1.0814
2024-10-29 12:38:03: [2024-10-29 12:38:03] iter = 13450, loss = 2.9064
2024-10-29 12:38:03: [2024-10-29 12:38:03] iter = 13460, loss = 5.2840
2024-10-29 12:38:03: [2024-10-29 12:38:03] iter = 13470, loss = 1.9651
2024-10-29 12:38:04: [2024-10-29 12:38:04] iter = 13480, loss = 1.0025
2024-10-29 12:38:04: [2024-10-29 12:38:04] iter = 13490, loss = 1.4653
2024-10-29 12:38:04: [2024-10-29 12:38:04] iter = 13500, loss = 1.6097
2024-10-29 12:38:05: [2024-10-29 12:38:05] iter = 13510, loss = 1.4354
2024-10-29 12:38:05: [2024-10-29 12:38:05] iter = 13520, loss = 1.1709
2024-10-29 12:38:06: [2024-10-29 12:38:06] iter = 13530, loss = 1.5993
2024-10-29 12:38:06: [2024-10-29 12:38:06] iter = 13540, loss = 1.3646
2024-10-29 12:38:07: [2024-10-29 12:38:07] iter = 13550, loss = 9.6723
2024-10-29 12:38:07: [2024-10-29 12:38:07] iter = 13560, loss = 1.9222
2024-10-29 12:38:07: [2024-10-29 12:38:07] iter = 13570, loss = 2.0819
2024-10-29 12:38:08: [2024-10-29 12:38:08] iter = 13580, loss = 2.0745
2024-10-29 12:38:08: [2024-10-29 12:38:08] iter = 13590, loss = 1.0030
2024-10-29 12:38:08: [2024-10-29 12:38:08] iter = 13600, loss = 1.0868
2024-10-29 12:38:09: [2024-10-29 12:38:09] iter = 13610, loss = 1.0403
2024-10-29 12:38:09: [2024-10-29 12:38:09] iter = 13620, loss = 1.6355
2024-10-29 12:38:09: [2024-10-29 12:38:09] iter = 13630, loss = 1.2700
2024-10-29 12:38:10: [2024-10-29 12:38:10] iter = 13640, loss = 1.8509
2024-10-29 12:38:10: [2024-10-29 12:38:10] iter = 13650, loss = 0.9912
2024-10-29 12:38:10: [2024-10-29 12:38:10] iter = 13660, loss = 1.1315
2024-10-29 12:38:11: [2024-10-29 12:38:11] iter = 13670, loss = 0.9839
2024-10-29 12:38:11: [2024-10-29 12:38:11] iter = 13680, loss = 5.2419
2024-10-29 12:38:11: [2024-10-29 12:38:11] iter = 13690, loss = 1.4098
2024-10-29 12:38:12: [2024-10-29 12:38:12] iter = 13700, loss = 1.0433
2024-10-29 12:38:12: [2024-10-29 12:38:12] iter = 13710, loss = 0.8873
2024-10-29 12:38:13: [2024-10-29 12:38:13] iter = 13720, loss = 1.6264
2024-10-29 12:38:13: [2024-10-29 12:38:13] iter = 13730, loss = 2.3930
2024-10-29 12:38:13: [2024-10-29 12:38:13] iter = 13740, loss = 0.9485
2024-10-29 12:38:14: [2024-10-29 12:38:14] iter = 13750, loss = 2.2250
2024-10-29 12:38:14: [2024-10-29 12:38:14] iter = 13760, loss = 2.7730
2024-10-29 12:38:14: [2024-10-29 12:38:14] iter = 13770, loss = 1.5923
2024-10-29 12:38:15: [2024-10-29 12:38:15] iter = 13780, loss = 0.8094
2024-10-29 12:38:15: [2024-10-29 12:38:15] iter = 13790, loss = 1.6131
2024-10-29 12:38:16: [2024-10-29 12:38:16] iter = 13800, loss = 0.8279
2024-10-29 12:38:16: [2024-10-29 12:38:16] iter = 13810, loss = 3.4630
2024-10-29 12:38:16: [2024-10-29 12:38:16] iter = 13820, loss = 1.4955
2024-10-29 12:38:17: [2024-10-29 12:38:17] iter = 13830, loss = 0.9884
2024-10-29 12:38:17: [2024-10-29 12:38:17] iter = 13840, loss = 2.4886
2024-10-29 12:38:17: [2024-10-29 12:38:17] iter = 13850, loss = 1.0437
2024-10-29 12:38:18: [2024-10-29 12:38:18] iter = 13860, loss = 0.9189
2024-10-29 12:38:18: [2024-10-29 12:38:18] iter = 13870, loss = 2.1745
2024-10-29 12:38:18: [2024-10-29 12:38:18] iter = 13880, loss = 1.1417
2024-10-29 12:38:19: [2024-10-29 12:38:19] iter = 13890, loss = 0.9184
2024-10-29 12:38:19: [2024-10-29 12:38:19] iter = 13900, loss = 1.0212
2024-10-29 12:38:19: [2024-10-29 12:38:19] iter = 13910, loss = 1.3985
2024-10-29 12:38:20: [2024-10-29 12:38:20] iter = 13920, loss = 1.6090
2024-10-29 12:38:20: [2024-10-29 12:38:20] iter = 13930, loss = 1.3447
2024-10-29 12:38:20: [2024-10-29 12:38:20] iter = 13940, loss = 1.4204
2024-10-29 12:38:21: [2024-10-29 12:38:21] iter = 13950, loss = 4.4665
2024-10-29 12:38:21: [2024-10-29 12:38:21] iter = 13960, loss = 1.0782
2024-10-29 12:38:22: [2024-10-29 12:38:21] iter = 13970, loss = 6.0534
2024-10-29 12:38:22: [2024-10-29 12:38:22] iter = 13980, loss = 2.0694
2024-10-29 12:38:22: [2024-10-29 12:38:22] iter = 13990, loss = 1.1219
2024-10-29 12:38:23: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 12:38:23: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:38:23: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 3164}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:38:54: Evaluate 5 random ConvNet, ACCmean = 0.5161 ACCstd = 0.0205
-------------------------
2024-10-29 12:38:54: Evaluate 5 random ConvNet, SENmean = 0.6089 SENstd = 0.0048
-------------------------
2024-10-29 12:38:54: Evaluate 5 random ConvNet, SPEmean = 0.6089 SPEstd = 0.0048
-------------------------
2024-10-29 12:38:54: Evaluate 5 random ConvNet, F!mean = 0.4443 F!std = 0.0124
-------------------------
2024-10-29 12:38:54: Evaluate 5 random ConvNet, mean = 0.5161 std = 0.0205
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:38:54: [2024-10-29 12:38:54] iter = 14000, loss = 1.7210
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:38:54: [2024-10-29 12:38:54] iter = 14010, loss = 1.9745
2024-10-29 12:38:54: [2024-10-29 12:38:54] iter = 14020, loss = 2.0268
2024-10-29 12:38:55: [2024-10-29 12:38:55] iter = 14030, loss = 1.8816
2024-10-29 12:38:55: [2024-10-29 12:38:55] iter = 14040, loss = 0.9133
2024-10-29 12:38:55: [2024-10-29 12:38:55] iter = 14050, loss = 1.5120
2024-10-29 12:38:56: [2024-10-29 12:38:56] iter = 14060, loss = 1.1602
2024-10-29 12:38:56: [2024-10-29 12:38:56] iter = 14070, loss = 2.7783
2024-10-29 12:38:56: [2024-10-29 12:38:56] iter = 14080, loss = 2.9462
2024-10-29 12:38:57: [2024-10-29 12:38:57] iter = 14090, loss = 7.9111
2024-10-29 12:38:57: [2024-10-29 12:38:57] iter = 14100, loss = 3.9187
2024-10-29 12:38:58: [2024-10-29 12:38:58] iter = 14110, loss = 1.7977
2024-10-29 12:38:58: [2024-10-29 12:38:58] iter = 14120, loss = 1.4228
2024-10-29 12:38:58: [2024-10-29 12:38:58] iter = 14130, loss = 1.4771
2024-10-29 12:38:59: [2024-10-29 12:38:59] iter = 14140, loss = 3.3235
2024-10-29 12:38:59: [2024-10-29 12:38:59] iter = 14150, loss = 1.8850
2024-10-29 12:38:59: [2024-10-29 12:38:59] iter = 14160, loss = 3.7076
2024-10-29 12:39:00: [2024-10-29 12:39:00] iter = 14170, loss = 1.2261
2024-10-29 12:39:00: [2024-10-29 12:39:00] iter = 14180, loss = 1.2493
2024-10-29 12:39:01: [2024-10-29 12:39:01] iter = 14190, loss = 0.9821
2024-10-29 12:39:01: [2024-10-29 12:39:01] iter = 14200, loss = 3.6402
2024-10-29 12:39:01: [2024-10-29 12:39:01] iter = 14210, loss = 1.4774
2024-10-29 12:39:02: [2024-10-29 12:39:02] iter = 14220, loss = 1.0319
2024-10-29 12:39:02: [2024-10-29 12:39:02] iter = 14230, loss = 1.1057
2024-10-29 12:39:02: [2024-10-29 12:39:02] iter = 14240, loss = 1.7998
2024-10-29 12:39:03: [2024-10-29 12:39:03] iter = 14250, loss = 1.0460
2024-10-29 12:39:03: [2024-10-29 12:39:03] iter = 14260, loss = 0.7761
2024-10-29 12:39:03: [2024-10-29 12:39:03] iter = 14270, loss = 1.2117
2024-10-29 12:39:04: [2024-10-29 12:39:04] iter = 14280, loss = 1.1515
2024-10-29 12:39:04: [2024-10-29 12:39:04] iter = 14290, loss = 1.2060
2024-10-29 12:39:04: [2024-10-29 12:39:04] iter = 14300, loss = 1.1746
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 14310, loss = 1.4017
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 14320, loss = 1.3784
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 14330, loss = 1.7364
2024-10-29 12:39:06: [2024-10-29 12:39:06] iter = 14340, loss = 2.7909
2024-10-29 12:39:06: [2024-10-29 12:39:06] iter = 14350, loss = 3.5880
2024-10-29 12:39:06: [2024-10-29 12:39:06] iter = 14360, loss = 1.2920
2024-10-29 12:39:07: [2024-10-29 12:39:07] iter = 14370, loss = 1.0599
2024-10-29 12:39:07: [2024-10-29 12:39:07] iter = 14380, loss = 1.0915
2024-10-29 12:39:07: [2024-10-29 12:39:07] iter = 14390, loss = 1.8939
2024-10-29 12:39:08: [2024-10-29 12:39:08] iter = 14400, loss = 2.0428
2024-10-29 12:39:08: [2024-10-29 12:39:08] iter = 14410, loss = 1.2043
2024-10-29 12:39:08: [2024-10-29 12:39:08] iter = 14420, loss = 2.9965
2024-10-29 12:39:09: [2024-10-29 12:39:09] iter = 14430, loss = 1.1935
2024-10-29 12:39:09: [2024-10-29 12:39:09] iter = 14440, loss = 1.2630
2024-10-29 12:39:09: [2024-10-29 12:39:09] iter = 14450, loss = 2.1356
2024-10-29 12:39:10: [2024-10-29 12:39:10] iter = 14460, loss = 2.0748
2024-10-29 12:39:10: [2024-10-29 12:39:10] iter = 14470, loss = 1.1623
2024-10-29 12:39:10: [2024-10-29 12:39:10] iter = 14480, loss = 1.5134
2024-10-29 12:39:11: [2024-10-29 12:39:11] iter = 14490, loss = 1.2133
2024-10-29 12:39:11: [2024-10-29 12:39:11] iter = 14500, loss = 1.0093
2024-10-29 12:39:11: [2024-10-29 12:39:11] iter = 14510, loss = 1.3316
2024-10-29 12:39:12: [2024-10-29 12:39:12] iter = 14520, loss = 0.8667
2024-10-29 12:39:13: [2024-10-29 12:39:13] iter = 14530, loss = 1.4762
2024-10-29 12:39:13: [2024-10-29 12:39:13] iter = 14540, loss = 0.8532
2024-10-29 12:39:13: [2024-10-29 12:39:13] iter = 14550, loss = 2.1365
2024-10-29 12:39:14: [2024-10-29 12:39:14] iter = 14560, loss = 1.3585
2024-10-29 12:39:14: [2024-10-29 12:39:14] iter = 14570, loss = 1.9066
2024-10-29 12:39:14: [2024-10-29 12:39:14] iter = 14580, loss = 1.8399
2024-10-29 12:39:15: [2024-10-29 12:39:15] iter = 14590, loss = 1.1715
2024-10-29 12:39:15: [2024-10-29 12:39:15] iter = 14600, loss = 1.5169
2024-10-29 12:39:15: [2024-10-29 12:39:15] iter = 14610, loss = 1.0952
2024-10-29 12:39:15: [2024-10-29 12:39:15] iter = 14620, loss = 4.2502
2024-10-29 12:39:16: [2024-10-29 12:39:16] iter = 14630, loss = 1.6411
2024-10-29 12:39:16: [2024-10-29 12:39:16] iter = 14640, loss = 2.0795
2024-10-29 12:39:17: [2024-10-29 12:39:17] iter = 14650, loss = 0.8977
2024-10-29 12:39:17: [2024-10-29 12:39:17] iter = 14660, loss = 1.6255
2024-10-29 12:39:17: [2024-10-29 12:39:17] iter = 14670, loss = 4.2568
2024-10-29 12:39:18: [2024-10-29 12:39:18] iter = 14680, loss = 1.1573
2024-10-29 12:39:18: [2024-10-29 12:39:18] iter = 14690, loss = 1.2655
2024-10-29 12:39:18: [2024-10-29 12:39:18] iter = 14700, loss = 2.6378
2024-10-29 12:39:19: [2024-10-29 12:39:19] iter = 14710, loss = 1.4774
2024-10-29 12:39:19: [2024-10-29 12:39:19] iter = 14720, loss = 1.6690
2024-10-29 12:39:20: [2024-10-29 12:39:20] iter = 14730, loss = 3.1091
2024-10-29 12:39:20: [2024-10-29 12:39:20] iter = 14740, loss = 1.6465
2024-10-29 12:39:21: [2024-10-29 12:39:21] iter = 14750, loss = 1.9229
2024-10-29 12:39:21: [2024-10-29 12:39:21] iter = 14760, loss = 1.2320
2024-10-29 12:39:21: [2024-10-29 12:39:21] iter = 14770, loss = 1.2148
2024-10-29 12:39:22: [2024-10-29 12:39:22] iter = 14780, loss = 2.4582
2024-10-29 12:39:22: [2024-10-29 12:39:22] iter = 14790, loss = 1.9480
2024-10-29 12:39:22: [2024-10-29 12:39:22] iter = 14800, loss = 1.7050
2024-10-29 12:39:23: [2024-10-29 12:39:23] iter = 14810, loss = 0.9193
2024-10-29 12:39:23: [2024-10-29 12:39:23] iter = 14820, loss = 2.2432
2024-10-29 12:39:23: [2024-10-29 12:39:23] iter = 14830, loss = 1.0146
2024-10-29 12:39:24: [2024-10-29 12:39:24] iter = 14840, loss = 2.1818
2024-10-29 12:39:24: [2024-10-29 12:39:24] iter = 14850, loss = 1.1895
2024-10-29 12:39:24: [2024-10-29 12:39:24] iter = 14860, loss = 1.6148
2024-10-29 12:39:25: [2024-10-29 12:39:25] iter = 14870, loss = 1.5667
2024-10-29 12:39:25: [2024-10-29 12:39:25] iter = 14880, loss = 1.5670
2024-10-29 12:39:25: [2024-10-29 12:39:25] iter = 14890, loss = 2.1144
2024-10-29 12:39:26: [2024-10-29 12:39:26] iter = 14900, loss = 1.8310
2024-10-29 12:39:26: [2024-10-29 12:39:26] iter = 14910, loss = 1.4506
2024-10-29 12:39:26: [2024-10-29 12:39:26] iter = 14920, loss = 2.0241
2024-10-29 12:39:27: [2024-10-29 12:39:27] iter = 14930, loss = 1.5372
2024-10-29 12:39:27: [2024-10-29 12:39:27] iter = 14940, loss = 1.3418
2024-10-29 12:39:27: [2024-10-29 12:39:27] iter = 14950, loss = 1.7030
2024-10-29 12:39:28: [2024-10-29 12:39:28] iter = 14960, loss = 1.4153
2024-10-29 12:39:28: [2024-10-29 12:39:28] iter = 14970, loss = 6.3541
2024-10-29 12:39:29: [2024-10-29 12:39:29] iter = 14980, loss = 3.2109
2024-10-29 12:39:29: [2024-10-29 12:39:29] iter = 14990, loss = 1.3034
2024-10-29 12:39:29: [2024-10-29 12:39:29] iter = 15000, loss = 1.8719
2024-10-29 12:39:30: [2024-10-29 12:39:30] iter = 15010, loss = 1.3049
2024-10-29 12:39:30: [2024-10-29 12:39:30] iter = 15020, loss = 1.7858
2024-10-29 12:39:30: [2024-10-29 12:39:30] iter = 15030, loss = 0.8826
2024-10-29 12:39:31: [2024-10-29 12:39:31] iter = 15040, loss = 1.6457
2024-10-29 12:39:31: [2024-10-29 12:39:31] iter = 15050, loss = 1.3426
2024-10-29 12:39:32: [2024-10-29 12:39:32] iter = 15060, loss = 1.3703
2024-10-29 12:39:32: [2024-10-29 12:39:32] iter = 15070, loss = 3.1388
2024-10-29 12:39:32: [2024-10-29 12:39:32] iter = 15080, loss = 1.1362
2024-10-29 12:39:33: [2024-10-29 12:39:33] iter = 15090, loss = 2.8484
2024-10-29 12:39:33: [2024-10-29 12:39:33] iter = 15100, loss = 1.1383
2024-10-29 12:39:33: [2024-10-29 12:39:33] iter = 15110, loss = 1.1129
2024-10-29 12:39:34: [2024-10-29 12:39:34] iter = 15120, loss = 1.4984
2024-10-29 12:39:34: [2024-10-29 12:39:34] iter = 15130, loss = 1.1954
2024-10-29 12:39:35: [2024-10-29 12:39:35] iter = 15140, loss = 1.2754
2024-10-29 12:39:35: [2024-10-29 12:39:35] iter = 15150, loss = 1.0972
2024-10-29 12:39:36: [2024-10-29 12:39:36] iter = 15160, loss = 5.8443
2024-10-29 12:39:36: [2024-10-29 12:39:36] iter = 15170, loss = 1.4364
2024-10-29 12:39:37: [2024-10-29 12:39:37] iter = 15180, loss = 2.3171
2024-10-29 12:39:37: [2024-10-29 12:39:37] iter = 15190, loss = 1.4877
2024-10-29 12:39:38: [2024-10-29 12:39:38] iter = 15200, loss = 1.4582
2024-10-29 12:39:38: [2024-10-29 12:39:38] iter = 15210, loss = 0.9477
2024-10-29 12:39:38: [2024-10-29 12:39:38] iter = 15220, loss = 1.6060
2024-10-29 12:39:39: [2024-10-29 12:39:39] iter = 15230, loss = 1.2290
2024-10-29 12:39:39: [2024-10-29 12:39:39] iter = 15240, loss = 1.1730
2024-10-29 12:39:40: [2024-10-29 12:39:40] iter = 15250, loss = 1.5102
2024-10-29 12:39:40: [2024-10-29 12:39:40] iter = 15260, loss = 1.3266
2024-10-29 12:39:40: [2024-10-29 12:39:40] iter = 15270, loss = 4.9010
2024-10-29 12:39:41: [2024-10-29 12:39:41] iter = 15280, loss = 1.7837
2024-10-29 12:39:41: [2024-10-29 12:39:41] iter = 15290, loss = 9.1548
2024-10-29 12:39:42: [2024-10-29 12:39:42] iter = 15300, loss = 1.9570
2024-10-29 12:39:42: [2024-10-29 12:39:42] iter = 15310, loss = 1.3061
2024-10-29 12:39:42: [2024-10-29 12:39:42] iter = 15320, loss = 0.7082
2024-10-29 12:39:43: [2024-10-29 12:39:43] iter = 15330, loss = 1.5529
2024-10-29 12:39:43: [2024-10-29 12:39:43] iter = 15340, loss = 1.9346
2024-10-29 12:39:43: [2024-10-29 12:39:43] iter = 15350, loss = 1.0181
2024-10-29 12:39:44: [2024-10-29 12:39:44] iter = 15360, loss = 3.0368
2024-10-29 12:39:44: [2024-10-29 12:39:44] iter = 15370, loss = 1.4329
2024-10-29 12:39:44: [2024-10-29 12:39:44] iter = 15380, loss = 2.5702
2024-10-29 12:39:45: [2024-10-29 12:39:45] iter = 15390, loss = 2.0137
2024-10-29 12:39:45: [2024-10-29 12:39:45] iter = 15400, loss = 1.4263
2024-10-29 12:39:45: [2024-10-29 12:39:45] iter = 15410, loss = 1.0657
2024-10-29 12:39:46: [2024-10-29 12:39:46] iter = 15420, loss = 1.3885
2024-10-29 12:39:46: [2024-10-29 12:39:46] iter = 15430, loss = 2.5165
2024-10-29 12:39:47: [2024-10-29 12:39:47] iter = 15440, loss = 0.9803
2024-10-29 12:39:47: [2024-10-29 12:39:47] iter = 15450, loss = 1.3874
2024-10-29 12:39:47: [2024-10-29 12:39:47] iter = 15460, loss = 1.6552
2024-10-29 12:39:48: [2024-10-29 12:39:48] iter = 15470, loss = 1.4059
2024-10-29 12:39:48: [2024-10-29 12:39:48] iter = 15480, loss = 2.3030
2024-10-29 12:39:48: [2024-10-29 12:39:48] iter = 15490, loss = 1.7219
2024-10-29 12:39:49: [2024-10-29 12:39:49] iter = 15500, loss = 1.1746
2024-10-29 12:39:49: [2024-10-29 12:39:49] iter = 15510, loss = 1.2822
2024-10-29 12:39:49: [2024-10-29 12:39:49] iter = 15520, loss = 1.8190
2024-10-29 12:39:50: [2024-10-29 12:39:50] iter = 15530, loss = 0.9609
2024-10-29 12:39:50: [2024-10-29 12:39:50] iter = 15540, loss = 1.8160
2024-10-29 12:39:51: [2024-10-29 12:39:51] iter = 15550, loss = 1.3330
2024-10-29 12:39:51: [2024-10-29 12:39:51] iter = 15560, loss = 1.1133
2024-10-29 12:39:51: [2024-10-29 12:39:51] iter = 15570, loss = 0.9790
2024-10-29 12:39:52: [2024-10-29 12:39:52] iter = 15580, loss = 0.8651
2024-10-29 12:39:52: [2024-10-29 12:39:52] iter = 15590, loss = 1.4481
2024-10-29 12:39:52: [2024-10-29 12:39:52] iter = 15600, loss = 1.8907
2024-10-29 12:39:53: [2024-10-29 12:39:53] iter = 15610, loss = 1.3891
2024-10-29 12:39:53: [2024-10-29 12:39:53] iter = 15620, loss = 8.3943
2024-10-29 12:39:53: [2024-10-29 12:39:53] iter = 15630, loss = 8.1544
2024-10-29 12:39:54: [2024-10-29 12:39:54] iter = 15640, loss = 1.8473
2024-10-29 12:39:54: [2024-10-29 12:39:54] iter = 15650, loss = 1.8750
2024-10-29 12:39:55: [2024-10-29 12:39:55] iter = 15660, loss = 4.5571
2024-10-29 12:39:55: [2024-10-29 12:39:55] iter = 15670, loss = 1.2722
2024-10-29 12:39:56: [2024-10-29 12:39:56] iter = 15680, loss = 1.5676
2024-10-29 12:39:56: [2024-10-29 12:39:56] iter = 15690, loss = 1.9870
2024-10-29 12:39:57: [2024-10-29 12:39:57] iter = 15700, loss = 1.1078
2024-10-29 12:39:57: [2024-10-29 12:39:57] iter = 15710, loss = 1.3929
2024-10-29 12:39:57: [2024-10-29 12:39:57] iter = 15720, loss = 1.2956
2024-10-29 12:39:58: [2024-10-29 12:39:58] iter = 15730, loss = 1.1738
2024-10-29 12:39:58: [2024-10-29 12:39:58] iter = 15740, loss = 0.9607
2024-10-29 12:39:59: [2024-10-29 12:39:59] iter = 15750, loss = 1.7776
2024-10-29 12:39:59: [2024-10-29 12:39:59] iter = 15760, loss = 1.5257
2024-10-29 12:40:00: [2024-10-29 12:40:00] iter = 15770, loss = 0.6927
2024-10-29 12:40:00: [2024-10-29 12:40:00] iter = 15780, loss = 1.3538
2024-10-29 12:40:00: [2024-10-29 12:40:00] iter = 15790, loss = 1.3480
2024-10-29 12:40:01: [2024-10-29 12:40:01] iter = 15800, loss = 2.4757
2024-10-29 12:40:01: [2024-10-29 12:40:01] iter = 15810, loss = 1.1481
2024-10-29 12:40:02: [2024-10-29 12:40:02] iter = 15820, loss = 5.7836
2024-10-29 12:40:02: [2024-10-29 12:40:02] iter = 15830, loss = 1.1789
2024-10-29 12:40:02: [2024-10-29 12:40:02] iter = 15840, loss = 0.8440
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 15850, loss = 1.0818
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 15860, loss = 3.0878
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 15870, loss = 1.4226
2024-10-29 12:40:04: [2024-10-29 12:40:04] iter = 15880, loss = 1.0710
2024-10-29 12:40:04: [2024-10-29 12:40:04] iter = 15890, loss = 2.3715
2024-10-29 12:40:04: [2024-10-29 12:40:04] iter = 15900, loss = 1.8881
2024-10-29 12:40:05: [2024-10-29 12:40:05] iter = 15910, loss = 1.2692
2024-10-29 12:40:05: [2024-10-29 12:40:05] iter = 15920, loss = 3.4692
2024-10-29 12:40:06: [2024-10-29 12:40:06] iter = 15930, loss = 1.1869
2024-10-29 12:40:06: [2024-10-29 12:40:06] iter = 15940, loss = 1.3472
2024-10-29 12:40:06: [2024-10-29 12:40:06] iter = 15950, loss = 1.0344
2024-10-29 12:40:07: [2024-10-29 12:40:07] iter = 15960, loss = 0.9410
2024-10-29 12:40:07: [2024-10-29 12:40:07] iter = 15970, loss = 1.7245
2024-10-29 12:40:07: [2024-10-29 12:40:07] iter = 15980, loss = 1.2466
2024-10-29 12:40:08: [2024-10-29 12:40:08] iter = 15990, loss = 0.9866
2024-10-29 12:40:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 12:40:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:40:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 8337}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/chestmnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/chestmnist.npz
Loaded the dataset:ChestMNIST
[2024-10-29 12:25:51] Evaluate_00: epoch = 1000 train time = 7 s train loss = 0.001374 train acc = 1.0000, test acc = 0.5619, test_sen =0.5679, test_spe =0.5679, test_f1 =0.4581
[2024-10-29 12:25:57] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.005336 train acc = 1.0000, test acc = 0.5576, test_sen =0.5630, test_spe =0.5630, test_f1 =0.4546
[2024-10-29 12:26:03] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.010205 train acc = 1.0000, test acc = 0.5795, test_sen =0.5634, test_spe =0.5634, test_f1 =0.4652
[2024-10-29 12:26:10] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.006017 train acc = 1.0000, test acc = 0.5522, test_sen =0.5663, test_spe =0.5663, test_f1 =0.4529
[2024-10-29 12:26:18] Evaluate_04: epoch = 1000 train time = 7 s train loss = 0.013895 train acc = 1.0000, test acc = 0.5721, test_sen =0.5630, test_spe =0.5630, test_f1 =0.4615
[2024-10-29 12:27:45] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.015316 train acc = 1.0000, test acc = 0.5435, test_sen =0.6126, test_spe =0.6126, test_f1 =0.4605
[2024-10-29 12:27:51] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.014445 train acc = 1.0000, test acc = 0.5204, test_sen =0.6035, test_spe =0.6035, test_f1 =0.4456
[2024-10-29 12:27:58] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.010983 train acc = 1.0000, test acc = 0.5322, test_sen =0.6061, test_spe =0.6061, test_f1 =0.4527
[2024-10-29 12:28:04] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.091793 train acc = 0.9500, test acc = 0.5393, test_sen =0.6149, test_spe =0.6149, test_f1 =0.4587
[2024-10-29 12:28:11] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.007139 train acc = 1.0000, test acc = 0.5213, test_sen =0.5991, test_spe =0.5991, test_f1 =0.4451
[2024-10-29 12:29:35] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.003505 train acc = 1.0000, test acc = 0.5765, test_sen =0.6195, test_spe =0.6195, test_f1 =0.4799
[2024-10-29 12:29:42] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.059389 train acc = 1.0000, test acc = 0.5795, test_sen =0.6216, test_spe =0.6216, test_f1 =0.4820
[2024-10-29 12:29:48] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.003062 train acc = 1.0000, test acc = 0.5680, test_sen =0.6164, test_spe =0.6164, test_f1 =0.4745
[2024-10-29 12:29:55] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.003613 train acc = 1.0000, test acc = 0.5775, test_sen =0.6216, test_spe =0.6216, test_f1 =0.4810
[2024-10-29 12:30:03] Evaluate_04: epoch = 1000 train time = 7 s train loss = 0.006878 train acc = 1.0000, test acc = 0.5930, test_sen =0.6188, test_spe =0.6188, test_f1 =0.4882
[2024-10-29 12:31:25] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.105259 train acc = 1.0000, test acc = 0.5540, test_sen =0.6125, test_spe =0.6125, test_f1 =0.4661
[2024-10-29 12:31:30] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.029987 train acc = 1.0000, test acc = 0.5381, test_sen =0.6114, test_spe =0.6114, test_f1 =0.4572
[2024-10-29 12:31:38] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.295415 train acc = 0.8500, test acc = 0.5419, test_sen =0.6103, test_spe =0.6103, test_f1 =0.4590
[2024-10-29 12:31:44] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.157443 train acc = 0.9500, test acc = 0.5454, test_sen =0.6043, test_spe =0.6043, test_f1 =0.4594
[2024-10-29 12:31:50] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.016082 train acc = 1.0000, test acc = 0.5482, test_sen =0.6095, test_spe =0.6095, test_f1 =0.4622
[2024-10-29 12:33:12] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.023705 train acc = 1.0000, test acc = 0.6373, test_sen =0.6120, test_spe =0.6120, test_f1 =0.5083
[2024-10-29 12:33:18] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.003137 train acc = 1.0000, test acc = 0.6276, test_sen =0.6140, test_spe =0.6140, test_f1 =0.5042
[2024-10-29 12:33:25] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.147094 train acc = 0.9500, test acc = 0.6234, test_sen =0.6082, test_spe =0.6082, test_f1 =0.5003
[2024-10-29 12:33:31] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.008814 train acc = 1.0000, test acc = 0.6367, test_sen =0.5999, test_spe =0.5999, test_f1 =0.5039
[2024-10-29 12:33:37] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001623 train acc = 1.0000, test acc = 0.6398, test_sen =0.6014, test_spe =0.6014, test_f1 =0.5059
[2024-10-29 12:34:55] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.065112 train acc = 1.0000, test acc = 0.7009, test_sen =0.5885, test_spe =0.5885, test_f1 =0.5283
[2024-10-29 12:35:01] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.003716 train acc = 1.0000, test acc = 0.6687, test_sen =0.5893, test_spe =0.5893, test_f1 =0.5146
[2024-10-29 12:35:07] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000816 train acc = 1.0000, test acc = 0.6873, test_sen =0.5975, test_spe =0.5975, test_f1 =0.5262
[2024-10-29 12:35:13] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.010406 train acc = 1.0000, test acc = 0.7008, test_sen =0.5860, test_spe =0.5860, test_f1 =0.5272
[2024-10-29 12:35:18] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001392 train acc = 1.0000, test acc = 0.7233, test_sen =0.5837, test_spe =0.5837, test_f1 =0.5356
[2024-10-29 12:36:44] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.007311 train acc = 1.0000, test acc = 0.5826, test_sen =0.5953, test_spe =0.5953, test_f1 =0.4762
[2024-10-29 12:36:50] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.003628 train acc = 1.0000, test acc = 0.5948, test_sen =0.6087, test_spe =0.6087, test_f1 =0.4863
[2024-10-29 12:36:56] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.008824 train acc = 1.0000, test acc = 0.5624, test_sen =0.6049, test_spe =0.6049, test_f1 =0.4686
[2024-10-29 12:37:02] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.044265 train acc = 1.0000, test acc = 0.5721, test_sen =0.5938, test_spe =0.5938, test_f1 =0.4705
[2024-10-29 12:37:08] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.070493 train acc = 0.9500, test acc = 0.6017, test_sen =0.6015, test_spe =0.6015, test_f1 =0.4876
[2024-10-29 12:38:28] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.006548 train acc = 1.0000, test acc = 0.5372, test_sen =0.6184, test_spe =0.6184, test_f1 =0.4584
[2024-10-29 12:38:34] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.000383 train acc = 1.0000, test acc = 0.5192, test_sen =0.6054, test_spe =0.6054, test_f1 =0.4454
[2024-10-29 12:38:40] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.003355 train acc = 1.0000, test acc = 0.4773, test_sen =0.6061, test_spe =0.6061, test_f1 =0.4213
[2024-10-29 12:38:46] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.003150 train acc = 1.0000, test acc = 0.5198, test_sen =0.6077, test_spe =0.6077, test_f1 =0.4462
[2024-10-29 12:38:54] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.000354 train acc = 1.0000, test acc = 0.5272, test_sen =0.6068, test_spe =0.6068, test_f1 =0.4501
[2024-10-29 12:40:13] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001951 train acc = 1.0000, test acc = 0.6358, test_sen =0.5574, test_spe =0.5574, test_f1 =0.4881
[2024-10-29 12:40:19] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.006211 train acc = 1.0000, test acc = 0.6712, test_sen =0.5547, test_spe =0.5547, test_f1 =0.5014
[2024-10-29 12:40:25] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000868 train acc = 1.0000, test acc = 0.6722, test_sen =0.5420, test_spe =0.5420, test_f1 =0.4962
[2024-10-29 12:40:31] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.067723 train acc = 1.0000, test acc = 0.6267, test_sen =0.5685, test_spe =0.5685, test_f1 =0.4883
[2024-10-29 12:40:37] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.050780 train acc = 1.0000, test acc = 0.6955, test_sen =0.5517, test_spe =0.5517, test_f1 =0.5093/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:37: Evaluate 5 random ConvNet, ACCmean = 0.6603 ACCstd = 0.0254
-------------------------
2024-10-29 12:40:37: Evaluate 5 random ConvNet, SENmean = 0.5549 SENstd = 0.0086
-------------------------
2024-10-29 12:40:37: Evaluate 5 random ConvNet, SPEmean = 0.5549 SPEstd = 0.0086
-------------------------
2024-10-29 12:40:37: Evaluate 5 random ConvNet, F!mean = 0.4967 F!std = 0.0081
-------------------------
2024-10-29 12:40:37: Evaluate 5 random ConvNet, mean = 0.6603 std = 0.0254
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:37: [2024-10-29 12:40:37] iter = 16000, loss = 3.3930
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:37: [2024-10-29 12:40:37] iter = 16010, loss = 2.2677
2024-10-29 12:40:38: [2024-10-29 12:40:38] iter = 16020, loss = 1.5407
2024-10-29 12:40:38: [2024-10-29 12:40:38] iter = 16030, loss = 1.4102
2024-10-29 12:40:39: [2024-10-29 12:40:39] iter = 16040, loss = 6.2637
2024-10-29 12:40:39: [2024-10-29 12:40:39] iter = 16050, loss = 1.5965
2024-10-29 12:40:40: [2024-10-29 12:40:40] iter = 16060, loss = 3.6706
2024-10-29 12:40:40: [2024-10-29 12:40:40] iter = 16070, loss = 2.2843
2024-10-29 12:40:40: [2024-10-29 12:40:40] iter = 16080, loss = 1.8507
2024-10-29 12:40:41: [2024-10-29 12:40:41] iter = 16090, loss = 1.0145
2024-10-29 12:40:41: [2024-10-29 12:40:41] iter = 16100, loss = 1.1311
2024-10-29 12:40:41: [2024-10-29 12:40:41] iter = 16110, loss = 1.4638
2024-10-29 12:40:42: [2024-10-29 12:40:42] iter = 16120, loss = 1.6069
2024-10-29 12:40:42: [2024-10-29 12:40:42] iter = 16130, loss = 1.1909
2024-10-29 12:40:43: [2024-10-29 12:40:43] iter = 16140, loss = 2.3444
2024-10-29 12:40:43: [2024-10-29 12:40:43] iter = 16150, loss = 1.9050
2024-10-29 12:40:43: [2024-10-29 12:40:43] iter = 16160, loss = 0.9132
2024-10-29 12:40:44: [2024-10-29 12:40:44] iter = 16170, loss = 1.2751
2024-10-29 12:40:44: [2024-10-29 12:40:44] iter = 16180, loss = 2.7493
2024-10-29 12:40:44: [2024-10-29 12:40:44] iter = 16190, loss = 1.4142
2024-10-29 12:40:45: [2024-10-29 12:40:45] iter = 16200, loss = 0.9000
2024-10-29 12:40:45: [2024-10-29 12:40:45] iter = 16210, loss = 1.2339
2024-10-29 12:40:46: [2024-10-29 12:40:46] iter = 16220, loss = 1.8070
2024-10-29 12:40:46: [2024-10-29 12:40:46] iter = 16230, loss = 1.3492
2024-10-29 12:40:46: [2024-10-29 12:40:46] iter = 16240, loss = 0.8376
2024-10-29 12:40:47: [2024-10-29 12:40:47] iter = 16250, loss = 0.9749
2024-10-29 12:40:47: [2024-10-29 12:40:47] iter = 16260, loss = 0.9110
2024-10-29 12:40:47: [2024-10-29 12:40:47] iter = 16270, loss = 1.6798
2024-10-29 12:40:48: [2024-10-29 12:40:48] iter = 16280, loss = 2.0548
2024-10-29 12:40:48: [2024-10-29 12:40:48] iter = 16290, loss = 1.7354
2024-10-29 12:40:48: [2024-10-29 12:40:48] iter = 16300, loss = 3.4784
2024-10-29 12:40:49: [2024-10-29 12:40:49] iter = 16310, loss = 2.1106
2024-10-29 12:40:49: [2024-10-29 12:40:49] iter = 16320, loss = 1.8169
2024-10-29 12:40:49: [2024-10-29 12:40:49] iter = 16330, loss = 1.5618
2024-10-29 12:40:50: [2024-10-29 12:40:50] iter = 16340, loss = 7.1602
2024-10-29 12:40:50: [2024-10-29 12:40:50] iter = 16350, loss = 1.1595
2024-10-29 12:40:50: [2024-10-29 12:40:50] iter = 16360, loss = 3.5736
2024-10-29 12:40:51: [2024-10-29 12:40:51] iter = 16370, loss = 1.0196
2024-10-29 12:40:51: [2024-10-29 12:40:51] iter = 16380, loss = 1.3788
2024-10-29 12:40:52: [2024-10-29 12:40:52] iter = 16390, loss = 3.8123
2024-10-29 12:40:52: [2024-10-29 12:40:52] iter = 16400, loss = 4.2389
2024-10-29 12:40:53: [2024-10-29 12:40:53] iter = 16410, loss = 1.5232
2024-10-29 12:40:53: [2024-10-29 12:40:53] iter = 16420, loss = 1.5090
2024-10-29 12:40:53: [2024-10-29 12:40:53] iter = 16430, loss = 1.4784
2024-10-29 12:40:54: [2024-10-29 12:40:54] iter = 16440, loss = 1.1374
2024-10-29 12:40:54: [2024-10-29 12:40:54] iter = 16450, loss = 4.1571
2024-10-29 12:40:54: [2024-10-29 12:40:54] iter = 16460, loss = 1.3795
2024-10-29 12:40:55: [2024-10-29 12:40:55] iter = 16470, loss = 1.1849
2024-10-29 12:40:55: [2024-10-29 12:40:55] iter = 16480, loss = 1.2244
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 16490, loss = 2.0366
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 16500, loss = 1.7353
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 16510, loss = 1.4010
2024-10-29 12:40:57: [2024-10-29 12:40:57] iter = 16520, loss = 2.8279
2024-10-29 12:40:57: [2024-10-29 12:40:57] iter = 16530, loss = 1.2235
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 16540, loss = 0.8336
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 16550, loss = 0.9248
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 16560, loss = 1.6390
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 16570, loss = 0.7898
2024-10-29 12:40:59: [2024-10-29 12:40:59] iter = 16580, loss = 1.3127
2024-10-29 12:40:59: [2024-10-29 12:40:59] iter = 16590, loss = 1.0723
2024-10-29 12:40:59: [2024-10-29 12:40:59] iter = 16600, loss = 0.6956
2024-10-29 12:41:00: [2024-10-29 12:41:00] iter = 16610, loss = 0.8982
2024-10-29 12:41:00: [2024-10-29 12:41:00] iter = 16620, loss = 1.3257
2024-10-29 12:41:01: [2024-10-29 12:41:01] iter = 16630, loss = 1.8658
2024-10-29 12:41:01: [2024-10-29 12:41:01] iter = 16640, loss = 3.6361
2024-10-29 12:41:01: [2024-10-29 12:41:01] iter = 16650, loss = 1.8156
2024-10-29 12:41:02: [2024-10-29 12:41:02] iter = 16660, loss = 1.5905
2024-10-29 12:41:02: [2024-10-29 12:41:02] iter = 16670, loss = 1.5531
2024-10-29 12:41:02: [2024-10-29 12:41:02] iter = 16680, loss = 1.0159
2024-10-29 12:41:03: [2024-10-29 12:41:03] iter = 16690, loss = 2.7669
2024-10-29 12:41:03: [2024-10-29 12:41:03] iter = 16700, loss = 1.0158
2024-10-29 12:41:03: [2024-10-29 12:41:03] iter = 16710, loss = 3.1904
2024-10-29 12:41:04: [2024-10-29 12:41:04] iter = 16720, loss = 0.9454
2024-10-29 12:41:04: [2024-10-29 12:41:04] iter = 16730, loss = 1.3149
2024-10-29 12:41:04: [2024-10-29 12:41:04] iter = 16740, loss = 4.6686
2024-10-29 12:41:05: [2024-10-29 12:41:05] iter = 16750, loss = 2.0928
2024-10-29 12:41:05: [2024-10-29 12:41:05] iter = 16760, loss = 1.7340
2024-10-29 12:41:06: [2024-10-29 12:41:06] iter = 16770, loss = 1.1795
2024-10-29 12:41:06: [2024-10-29 12:41:06] iter = 16780, loss = 1.4306
2024-10-29 12:41:06: [2024-10-29 12:41:06] iter = 16790, loss = 1.4146
2024-10-29 12:41:07: [2024-10-29 12:41:07] iter = 16800, loss = 2.9230
2024-10-29 12:41:07: [2024-10-29 12:41:07] iter = 16810, loss = 1.2709
2024-10-29 12:41:07: [2024-10-29 12:41:07] iter = 16820, loss = 1.5473
2024-10-29 12:41:08: [2024-10-29 12:41:08] iter = 16830, loss = 1.4758
2024-10-29 12:41:08: [2024-10-29 12:41:08] iter = 16840, loss = 1.7890
2024-10-29 12:41:08: [2024-10-29 12:41:08] iter = 16850, loss = 1.3701
2024-10-29 12:41:09: [2024-10-29 12:41:09] iter = 16860, loss = 3.6908
2024-10-29 12:41:09: [2024-10-29 12:41:09] iter = 16870, loss = 1.8280
2024-10-29 12:41:10: [2024-10-29 12:41:10] iter = 16880, loss = 2.0736
2024-10-29 12:41:10: [2024-10-29 12:41:10] iter = 16890, loss = 1.6093
2024-10-29 12:41:10: [2024-10-29 12:41:10] iter = 16900, loss = 1.5444
2024-10-29 12:41:11: [2024-10-29 12:41:11] iter = 16910, loss = 0.7797
2024-10-29 12:41:11: [2024-10-29 12:41:11] iter = 16920, loss = 1.8044
2024-10-29 12:41:11: [2024-10-29 12:41:11] iter = 16930, loss = 2.3935
2024-10-29 12:41:12: [2024-10-29 12:41:12] iter = 16940, loss = 1.5340
2024-10-29 12:41:12: [2024-10-29 12:41:12] iter = 16950, loss = 1.0039
2024-10-29 12:41:13: [2024-10-29 12:41:13] iter = 16960, loss = 1.5670
2024-10-29 12:41:13: [2024-10-29 12:41:13] iter = 16970, loss = 1.0972
2024-10-29 12:41:14: [2024-10-29 12:41:14] iter = 16980, loss = 1.5101
2024-10-29 12:41:14: [2024-10-29 12:41:14] iter = 16990, loss = 1.6567
2024-10-29 12:41:15: [2024-10-29 12:41:15] iter = 17000, loss = 1.2341
2024-10-29 12:41:15: [2024-10-29 12:41:15] iter = 17010, loss = 2.8804
2024-10-29 12:41:15: [2024-10-29 12:41:15] iter = 17020, loss = 0.9064
2024-10-29 12:41:16: [2024-10-29 12:41:16] iter = 17030, loss = 2.4113
2024-10-29 12:41:16: [2024-10-29 12:41:16] iter = 17040, loss = 1.1298
2024-10-29 12:41:16: [2024-10-29 12:41:16] iter = 17050, loss = 0.8445
2024-10-29 12:41:17: [2024-10-29 12:41:17] iter = 17060, loss = 1.3488
2024-10-29 12:41:17: [2024-10-29 12:41:17] iter = 17070, loss = 0.9344
2024-10-29 12:41:18: [2024-10-29 12:41:18] iter = 17080, loss = 1.5091
2024-10-29 12:41:18: [2024-10-29 12:41:18] iter = 17090, loss = 1.3485
2024-10-29 12:41:19: [2024-10-29 12:41:19] iter = 17100, loss = 1.1059
2024-10-29 12:41:19: [2024-10-29 12:41:19] iter = 17110, loss = 1.3227
2024-10-29 12:41:20: [2024-10-29 12:41:20] iter = 17120, loss = 1.0281
2024-10-29 12:41:20: [2024-10-29 12:41:20] iter = 17130, loss = 1.4644
2024-10-29 12:41:20: [2024-10-29 12:41:20] iter = 17140, loss = 1.1620
2024-10-29 12:41:21: [2024-10-29 12:41:21] iter = 17150, loss = 1.6299
2024-10-29 12:41:21: [2024-10-29 12:41:21] iter = 17160, loss = 1.7302
2024-10-29 12:41:21: [2024-10-29 12:41:21] iter = 17170, loss = 1.1838
2024-10-29 12:41:22: [2024-10-29 12:41:22] iter = 17180, loss = 1.8278
2024-10-29 12:41:22: [2024-10-29 12:41:22] iter = 17190, loss = 1.6384
2024-10-29 12:41:22: [2024-10-29 12:41:22] iter = 17200, loss = 1.4179
2024-10-29 12:41:23: [2024-10-29 12:41:23] iter = 17210, loss = 1.0384
2024-10-29 12:41:23: [2024-10-29 12:41:23] iter = 17220, loss = 1.4798
2024-10-29 12:41:24: [2024-10-29 12:41:24] iter = 17230, loss = 1.2810
2024-10-29 12:41:24: [2024-10-29 12:41:24] iter = 17240, loss = 1.2558
2024-10-29 12:41:24: [2024-10-29 12:41:24] iter = 17250, loss = 0.8689
2024-10-29 12:41:25: [2024-10-29 12:41:25] iter = 17260, loss = 0.7215
2024-10-29 12:41:25: [2024-10-29 12:41:25] iter = 17270, loss = 1.1813
2024-10-29 12:41:25: [2024-10-29 12:41:25] iter = 17280, loss = 1.3944
2024-10-29 12:41:26: [2024-10-29 12:41:26] iter = 17290, loss = 1.2438
2024-10-29 12:41:26: [2024-10-29 12:41:26] iter = 17300, loss = 1.4426
2024-10-29 12:41:26: [2024-10-29 12:41:26] iter = 17310, loss = 5.1106
2024-10-29 12:41:27: [2024-10-29 12:41:27] iter = 17320, loss = 5.9994
2024-10-29 12:41:27: [2024-10-29 12:41:27] iter = 17330, loss = 2.9043
2024-10-29 12:41:28: [2024-10-29 12:41:28] iter = 17340, loss = 7.1800
2024-10-29 12:41:28: [2024-10-29 12:41:28] iter = 17350, loss = 1.0232
2024-10-29 12:41:29: [2024-10-29 12:41:28] iter = 17360, loss = 2.7798
2024-10-29 12:41:29: [2024-10-29 12:41:29] iter = 17370, loss = 2.2941
2024-10-29 12:41:30: [2024-10-29 12:41:30] iter = 17380, loss = 1.2989
2024-10-29 12:41:30: [2024-10-29 12:41:30] iter = 17390, loss = 1.5369
2024-10-29 12:41:30: [2024-10-29 12:41:30] iter = 17400, loss = 1.4213
2024-10-29 12:41:31: [2024-10-29 12:41:31] iter = 17410, loss = 1.2231
2024-10-29 12:41:31: [2024-10-29 12:41:31] iter = 17420, loss = 1.0985
2024-10-29 12:41:31: [2024-10-29 12:41:31] iter = 17430, loss = 4.4586
2024-10-29 12:41:32: [2024-10-29 12:41:32] iter = 17440, loss = 5.0516
2024-10-29 12:41:32: [2024-10-29 12:41:32] iter = 17450, loss = 1.4631
2024-10-29 12:41:32: [2024-10-29 12:41:32] iter = 17460, loss = 1.9463
2024-10-29 12:41:33: [2024-10-29 12:41:33] iter = 17470, loss = 1.5384
2024-10-29 12:41:33: [2024-10-29 12:41:33] iter = 17480, loss = 1.1328
2024-10-29 12:41:33: [2024-10-29 12:41:33] iter = 17490, loss = 1.4151
2024-10-29 12:41:34: [2024-10-29 12:41:34] iter = 17500, loss = 1.3044
2024-10-29 12:41:34: [2024-10-29 12:41:34] iter = 17510, loss = 2.0283
2024-10-29 12:41:34: [2024-10-29 12:41:34] iter = 17520, loss = 2.2292
2024-10-29 12:41:35: [2024-10-29 12:41:35] iter = 17530, loss = 0.7277
2024-10-29 12:41:35: [2024-10-29 12:41:35] iter = 17540, loss = 1.1373
2024-10-29 12:41:36: [2024-10-29 12:41:36] iter = 17550, loss = 0.8726
2024-10-29 12:41:36: [2024-10-29 12:41:36] iter = 17560, loss = 1.3369
2024-10-29 12:41:36: [2024-10-29 12:41:36] iter = 17570, loss = 1.1189
2024-10-29 12:41:37: [2024-10-29 12:41:37] iter = 17580, loss = 1.1279
2024-10-29 12:41:37: [2024-10-29 12:41:37] iter = 17590, loss = 1.1522
2024-10-29 12:41:37: [2024-10-29 12:41:37] iter = 17600, loss = 3.0057
2024-10-29 12:41:38: [2024-10-29 12:41:38] iter = 17610, loss = 2.8154
2024-10-29 12:41:38: [2024-10-29 12:41:38] iter = 17620, loss = 1.5794
2024-10-29 12:41:38: [2024-10-29 12:41:38] iter = 17630, loss = 2.2932
2024-10-29 12:41:39: [2024-10-29 12:41:39] iter = 17640, loss = 1.7659
2024-10-29 12:41:39: [2024-10-29 12:41:39] iter = 17650, loss = 0.8782
2024-10-29 12:41:39: [2024-10-29 12:41:39] iter = 17660, loss = 1.1310
2024-10-29 12:41:40: [2024-10-29 12:41:40] iter = 17670, loss = 0.8739
2024-10-29 12:41:40: [2024-10-29 12:41:40] iter = 17680, loss = 1.1047
2024-10-29 12:41:40: [2024-10-29 12:41:40] iter = 17690, loss = 1.7720
2024-10-29 12:41:41: [2024-10-29 12:41:41] iter = 17700, loss = 1.1539
2024-10-29 12:41:41: [2024-10-29 12:41:41] iter = 17710, loss = 1.1069
2024-10-29 12:41:41: [2024-10-29 12:41:41] iter = 17720, loss = 1.8709
2024-10-29 12:41:42: [2024-10-29 12:41:42] iter = 17730, loss = 2.6618
2024-10-29 12:41:42: [2024-10-29 12:41:42] iter = 17740, loss = 0.4516
2024-10-29 12:41:42: [2024-10-29 12:41:42] iter = 17750, loss = 2.5348
2024-10-29 12:41:43: [2024-10-29 12:41:43] iter = 17760, loss = 0.8634
2024-10-29 12:41:43: [2024-10-29 12:41:43] iter = 17770, loss = 0.9147
2024-10-29 12:41:43: [2024-10-29 12:41:43] iter = 17780, loss = 1.4289
2024-10-29 12:41:44: [2024-10-29 12:41:44] iter = 17790, loss = 0.9324
2024-10-29 12:41:44: [2024-10-29 12:41:44] iter = 17800, loss = 1.0102
2024-10-29 12:41:44: [2024-10-29 12:41:44] iter = 17810, loss = 1.2000
2024-10-29 12:41:45: [2024-10-29 12:41:45] iter = 17820, loss = 2.9526
2024-10-29 12:41:45: [2024-10-29 12:41:45] iter = 17830, loss = 1.6347
2024-10-29 12:41:45: [2024-10-29 12:41:45] iter = 17840, loss = 0.9260
2024-10-29 12:41:46: [2024-10-29 12:41:46] iter = 17850, loss = 1.6042
2024-10-29 12:41:46: [2024-10-29 12:41:46] iter = 17860, loss = 3.1158
2024-10-29 12:41:46: [2024-10-29 12:41:46] iter = 17870, loss = 2.2082
2024-10-29 12:41:47: [2024-10-29 12:41:47] iter = 17880, loss = 1.2436
2024-10-29 12:41:47: [2024-10-29 12:41:47] iter = 17890, loss = 1.3336
2024-10-29 12:41:47: [2024-10-29 12:41:47] iter = 17900, loss = 0.9933
2024-10-29 12:41:48: [2024-10-29 12:41:48] iter = 17910, loss = 1.4018
2024-10-29 12:41:48: [2024-10-29 12:41:48] iter = 17920, loss = 3.9480
2024-10-29 12:41:48: [2024-10-29 12:41:48] iter = 17930, loss = 1.0167
2024-10-29 12:41:49: [2024-10-29 12:41:49] iter = 17940, loss = 2.4091
2024-10-29 12:41:49: [2024-10-29 12:41:49] iter = 17950, loss = 2.4717
2024-10-29 12:41:49: [2024-10-29 12:41:49] iter = 17960, loss = 1.2102
2024-10-29 12:41:50: [2024-10-29 12:41:50] iter = 17970, loss = 1.5771
2024-10-29 12:41:50: [2024-10-29 12:41:50] iter = 17980, loss = 1.1127
2024-10-29 12:41:50: [2024-10-29 12:41:50] iter = 17990, loss = 1.0442
2024-10-29 12:41:51: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 12:41:51: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:41:51: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 11265}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:42:20: Evaluate 5 random ConvNet, ACCmean = 0.6387 ACCstd = 0.0058
-------------------------
2024-10-29 12:42:20: Evaluate 5 random ConvNet, SENmean = 0.6144 SENstd = 0.0035
-------------------------
2024-10-29 12:42:20: Evaluate 5 random ConvNet, SPEmean = 0.6144 SPEstd = 0.0035
-------------------------
2024-10-29 12:42:20: Evaluate 5 random ConvNet, F!mean = 0.5098 F!std = 0.0037
-------------------------
2024-10-29 12:42:20: Evaluate 5 random ConvNet, mean = 0.6387 std = 0.0058
-------------------------
2024-10-29 12:42:20: [2024-10-29 12:42:20] iter = 18000, loss = 0.7874
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:42:20: [2024-10-29 12:42:20] iter = 18010, loss = 1.5202
2024-10-29 12:42:21: [2024-10-29 12:42:21] iter = 18020, loss = 1.0668
2024-10-29 12:42:21: [2024-10-29 12:42:21] iter = 18030, loss = 1.6688
2024-10-29 12:42:21: [2024-10-29 12:42:21] iter = 18040, loss = 1.7914
2024-10-29 12:42:22: [2024-10-29 12:42:22] iter = 18050, loss = 1.0801
2024-10-29 12:42:22: [2024-10-29 12:42:22] iter = 18060, loss = 0.9789
2024-10-29 12:42:23: [2024-10-29 12:42:23] iter = 18070, loss = 0.8952
2024-10-29 12:42:23: [2024-10-29 12:42:23] iter = 18080, loss = 1.4456
2024-10-29 12:42:24: [2024-10-29 12:42:24] iter = 18090, loss = 0.8933
2024-10-29 12:42:24: [2024-10-29 12:42:24] iter = 18100, loss = 0.8007
2024-10-29 12:42:24: [2024-10-29 12:42:24] iter = 18110, loss = 1.2484
2024-10-29 12:42:25: [2024-10-29 12:42:25] iter = 18120, loss = 4.2738
2024-10-29 12:42:25: [2024-10-29 12:42:25] iter = 18130, loss = 3.0573
2024-10-29 12:42:25: [2024-10-29 12:42:25] iter = 18140, loss = 3.3073
2024-10-29 12:42:26: [2024-10-29 12:42:26] iter = 18150, loss = 1.8105
2024-10-29 12:42:26: [2024-10-29 12:42:26] iter = 18160, loss = 3.1324
2024-10-29 12:42:26: [2024-10-29 12:42:26] iter = 18170, loss = 1.9421
2024-10-29 12:42:27: [2024-10-29 12:42:27] iter = 18180, loss = 1.3404
2024-10-29 12:42:27: [2024-10-29 12:42:27] iter = 18190, loss = 1.7028
2024-10-29 12:42:27: [2024-10-29 12:42:27] iter = 18200, loss = 1.1349
2024-10-29 12:42:28: [2024-10-29 12:42:28] iter = 18210, loss = 3.4548
2024-10-29 12:42:28: [2024-10-29 12:42:28] iter = 18220, loss = 1.3625
2024-10-29 12:42:29: [2024-10-29 12:42:29] iter = 18230, loss = 1.8260
2024-10-29 12:42:29: [2024-10-29 12:42:29] iter = 18240, loss = 0.8238
2024-10-29 12:42:29: [2024-10-29 12:42:29] iter = 18250, loss = 1.4189
2024-10-29 12:42:30: [2024-10-29 12:42:30] iter = 18260, loss = 0.8232
2024-10-29 12:42:30: [2024-10-29 12:42:30] iter = 18270, loss = 1.2282
2024-10-29 12:42:30: [2024-10-29 12:42:30] iter = 18280, loss = 2.1049
2024-10-29 12:42:31: [2024-10-29 12:42:31] iter = 18290, loss = 1.7642
2024-10-29 12:42:31: [2024-10-29 12:42:31] iter = 18300, loss = 1.0266
2024-10-29 12:42:31: [2024-10-29 12:42:31] iter = 18310, loss = 1.4260
2024-10-29 12:42:32: [2024-10-29 12:42:32] iter = 18320, loss = 1.5132
2024-10-29 12:42:32: [2024-10-29 12:42:32] iter = 18330, loss = 1.0442
2024-10-29 12:42:32: [2024-10-29 12:42:32] iter = 18340, loss = 1.1293
2024-10-29 12:42:33: [2024-10-29 12:42:33] iter = 18350, loss = 0.9924
2024-10-29 12:42:33: [2024-10-29 12:42:33] iter = 18360, loss = 11.4106
2024-10-29 12:42:34: [2024-10-29 12:42:34] iter = 18370, loss = 1.9372
2024-10-29 12:42:34: [2024-10-29 12:42:34] iter = 18380, loss = 1.2841
2024-10-29 12:42:34: [2024-10-29 12:42:34] iter = 18390, loss = 3.0281
2024-10-29 12:42:35: [2024-10-29 12:42:35] iter = 18400, loss = 1.0278
2024-10-29 12:42:35: [2024-10-29 12:42:35] iter = 18410, loss = 1.4597
2024-10-29 12:42:35: [2024-10-29 12:42:35] iter = 18420, loss = 1.7941
2024-10-29 12:42:36: [2024-10-29 12:42:36] iter = 18430, loss = 1.2525
2024-10-29 12:42:36: [2024-10-29 12:42:36] iter = 18440, loss = 1.2809
2024-10-29 12:42:36: [2024-10-29 12:42:36] iter = 18450, loss = 1.7139
2024-10-29 12:42:37: [2024-10-29 12:42:37] iter = 18460, loss = 1.3598
2024-10-29 12:42:37: [2024-10-29 12:42:37] iter = 18470, loss = 1.2952
2024-10-29 12:42:37: [2024-10-29 12:42:37] iter = 18480, loss = 1.0362
2024-10-29 12:42:38: [2024-10-29 12:42:38] iter = 18490, loss = 0.9683
2024-10-29 12:42:38: [2024-10-29 12:42:38] iter = 18500, loss = 1.1004
2024-10-29 12:42:38: [2024-10-29 12:42:38] iter = 18510, loss = 1.2069
2024-10-29 12:42:39: [2024-10-29 12:42:39] iter = 18520, loss = 1.7929
2024-10-29 12:42:39: [2024-10-29 12:42:39] iter = 18530, loss = 1.1483
2024-10-29 12:42:39: [2024-10-29 12:42:39] iter = 18540, loss = 4.1682
2024-10-29 12:42:40: [2024-10-29 12:42:40] iter = 18550, loss = 1.8227
2024-10-29 12:42:40: [2024-10-29 12:42:40] iter = 18560, loss = 3.5987
2024-10-29 12:42:41: [2024-10-29 12:42:41] iter = 18570, loss = 1.1051
2024-10-29 12:42:41: [2024-10-29 12:42:41] iter = 18580, loss = 5.0486
2024-10-29 12:42:41: [2024-10-29 12:42:41] iter = 18590, loss = 1.5446
2024-10-29 12:42:42: [2024-10-29 12:42:42] iter = 18600, loss = 1.5961
2024-10-29 12:42:42: [2024-10-29 12:42:42] iter = 18610, loss = 1.1869
2024-10-29 12:42:42: [2024-10-29 12:42:42] iter = 18620, loss = 0.9532
2024-10-29 12:42:43: [2024-10-29 12:42:43] iter = 18630, loss = 0.8316
2024-10-29 12:42:43: [2024-10-29 12:42:43] iter = 18640, loss = 0.8759
2024-10-29 12:42:43: [2024-10-29 12:42:43] iter = 18650, loss = 1.6325
2024-10-29 12:42:44: [2024-10-29 12:42:44] iter = 18660, loss = 1.1927
2024-10-29 12:42:44: [2024-10-29 12:42:44] iter = 18670, loss = 2.1555
2024-10-29 12:42:44: [2024-10-29 12:42:44] iter = 18680, loss = 1.5325
2024-10-29 12:42:45: [2024-10-29 12:42:45] iter = 18690, loss = 4.6291
2024-10-29 12:42:45: [2024-10-29 12:42:45] iter = 18700, loss = 1.3847
2024-10-29 12:42:46: [2024-10-29 12:42:46] iter = 18710, loss = 1.7157
2024-10-29 12:42:46: [2024-10-29 12:42:46] iter = 18720, loss = 1.1720
2024-10-29 12:42:46: [2024-10-29 12:42:46] iter = 18730, loss = 7.4373
2024-10-29 12:42:47: [2024-10-29 12:42:47] iter = 18740, loss = 0.8387
2024-10-29 12:42:47: [2024-10-29 12:42:47] iter = 18750, loss = 4.5947
2024-10-29 12:42:47: [2024-10-29 12:42:47] iter = 18760, loss = 1.3650
2024-10-29 12:42:48: [2024-10-29 12:42:48] iter = 18770, loss = 0.9387
2024-10-29 12:42:48: [2024-10-29 12:42:48] iter = 18780, loss = 1.2261
2024-10-29 12:42:49: [2024-10-29 12:42:49] iter = 18790, loss = 1.5606
2024-10-29 12:42:49: [2024-10-29 12:42:49] iter = 18800, loss = 2.3519
2024-10-29 12:42:50: [2024-10-29 12:42:50] iter = 18810, loss = 0.7929
2024-10-29 12:42:50: [2024-10-29 12:42:50] iter = 18820, loss = 1.2047
2024-10-29 12:42:51: [2024-10-29 12:42:51] iter = 18830, loss = 1.2829
2024-10-29 12:42:51: [2024-10-29 12:42:51] iter = 18840, loss = 1.5505
2024-10-29 12:42:52: [2024-10-29 12:42:52] iter = 18850, loss = 1.9890
2024-10-29 12:42:52: [2024-10-29 12:42:52] iter = 18860, loss = 1.3234
2024-10-29 12:42:53: [2024-10-29 12:42:53] iter = 18870, loss = 1.1063
2024-10-29 12:42:53: [2024-10-29 12:42:53] iter = 18880, loss = 1.4495
2024-10-29 12:42:54: [2024-10-29 12:42:54] iter = 18890, loss = 0.8844
2024-10-29 12:42:54: [2024-10-29 12:42:54] iter = 18900, loss = 1.0579
2024-10-29 12:42:54: [2024-10-29 12:42:54] iter = 18910, loss = 4.3881
2024-10-29 12:42:55: [2024-10-29 12:42:55] iter = 18920, loss = 1.7841
2024-10-29 12:42:55: [2024-10-29 12:42:55] iter = 18930, loss = 1.4929
2024-10-29 12:42:55: [2024-10-29 12:42:55] iter = 18940, loss = 3.0414
2024-10-29 12:42:56: [2024-10-29 12:42:56] iter = 18950, loss = 1.6100
2024-10-29 12:42:56: [2024-10-29 12:42:56] iter = 18960, loss = 0.8783
2024-10-29 12:42:57: [2024-10-29 12:42:57] iter = 18970, loss = 0.8246
2024-10-29 12:42:57: [2024-10-29 12:42:57] iter = 18980, loss = 1.0754
2024-10-29 12:42:57: [2024-10-29 12:42:57] iter = 18990, loss = 1.5178
2024-10-29 12:42:58: [2024-10-29 12:42:58] iter = 19000, loss = 1.4414
2024-10-29 12:42:58: [2024-10-29 12:42:58] iter = 19010, loss = 3.9543
2024-10-29 12:42:58: [2024-10-29 12:42:58] iter = 19020, loss = 1.0922
2024-10-29 12:42:59: [2024-10-29 12:42:59] iter = 19030, loss = 1.9562
2024-10-29 12:42:59: [2024-10-29 12:42:59] iter = 19040, loss = 0.9186
2024-10-29 12:42:59: [2024-10-29 12:42:59] iter = 19050, loss = 1.3811
2024-10-29 12:43:00: [2024-10-29 12:43:00] iter = 19060, loss = 1.5988
2024-10-29 12:43:00: [2024-10-29 12:43:00] iter = 19070, loss = 1.5382
2024-10-29 12:43:00: [2024-10-29 12:43:00] iter = 19080, loss = 0.8537
2024-10-29 12:43:01: [2024-10-29 12:43:01] iter = 19090, loss = 1.0780
2024-10-29 12:43:01: [2024-10-29 12:43:01] iter = 19100, loss = 1.3489
2024-10-29 12:43:02: [2024-10-29 12:43:02] iter = 19110, loss = 0.9692
2024-10-29 12:43:02: [2024-10-29 12:43:02] iter = 19120, loss = 1.4783
2024-10-29 12:43:03: [2024-10-29 12:43:03] iter = 19130, loss = 0.7605
2024-10-29 12:43:03: [2024-10-29 12:43:03] iter = 19140, loss = 3.4140
2024-10-29 12:43:03: [2024-10-29 12:43:03] iter = 19150, loss = 1.7875
2024-10-29 12:43:04: [2024-10-29 12:43:04] iter = 19160, loss = 1.4624
2024-10-29 12:43:04: [2024-10-29 12:43:04] iter = 19170, loss = 1.4770
2024-10-29 12:43:04: [2024-10-29 12:43:04] iter = 19180, loss = 2.1725
2024-10-29 12:43:05: [2024-10-29 12:43:05] iter = 19190, loss = 2.3493
2024-10-29 12:43:05: [2024-10-29 12:43:05] iter = 19200, loss = 2.2611
2024-10-29 12:43:05: [2024-10-29 12:43:05] iter = 19210, loss = 0.9466
2024-10-29 12:43:06: [2024-10-29 12:43:06] iter = 19220, loss = 1.1276
2024-10-29 12:43:06: [2024-10-29 12:43:06] iter = 19230, loss = 1.3818
2024-10-29 12:43:06: [2024-10-29 12:43:06] iter = 19240, loss = 5.7354
2024-10-29 12:43:07: [2024-10-29 12:43:07] iter = 19250, loss = 1.1247
2024-10-29 12:43:07: [2024-10-29 12:43:07] iter = 19260, loss = 1.1117
2024-10-29 12:43:07: [2024-10-29 12:43:07] iter = 19270, loss = 1.6438
2024-10-29 12:43:08: [2024-10-29 12:43:08] iter = 19280, loss = 8.3270
2024-10-29 12:43:08: [2024-10-29 12:43:08] iter = 19290, loss = 1.4351
2024-10-29 12:43:09: [2024-10-29 12:43:09] iter = 19300, loss = 1.3017
2024-10-29 12:43:09: [2024-10-29 12:43:09] iter = 19310, loss = 3.3750
2024-10-29 12:43:10: [2024-10-29 12:43:10] iter = 19320, loss = 2.7477
2024-10-29 12:43:10: [2024-10-29 12:43:10] iter = 19330, loss = 1.8325
2024-10-29 12:43:10: [2024-10-29 12:43:10] iter = 19340, loss = 3.9636
2024-10-29 12:43:11: [2024-10-29 12:43:11] iter = 19350, loss = 1.6903
2024-10-29 12:43:11: [2024-10-29 12:43:11] iter = 19360, loss = 0.9637
2024-10-29 12:43:11: [2024-10-29 12:43:11] iter = 19370, loss = 0.7828
2024-10-29 12:43:12: [2024-10-29 12:43:12] iter = 19380, loss = 0.9406
2024-10-29 12:43:12: [2024-10-29 12:43:12] iter = 19390, loss = 1.4272
2024-10-29 12:43:12: [2024-10-29 12:43:12] iter = 19400, loss = 1.0858
2024-10-29 12:43:13: [2024-10-29 12:43:13] iter = 19410, loss = 1.9209
2024-10-29 12:43:13: [2024-10-29 12:43:13] iter = 19420, loss = 0.9858
2024-10-29 12:43:13: [2024-10-29 12:43:13] iter = 19430, loss = 2.0051
2024-10-29 12:43:14: [2024-10-29 12:43:14] iter = 19440, loss = 1.7489
2024-10-29 12:43:14: [2024-10-29 12:43:14] iter = 19450, loss = 1.6107
2024-10-29 12:43:14: [2024-10-29 12:43:14] iter = 19460, loss = 1.5687
2024-10-29 12:43:15: [2024-10-29 12:43:15] iter = 19470, loss = 2.0209
2024-10-29 12:43:15: [2024-10-29 12:43:15] iter = 19480, loss = 1.8140
2024-10-29 12:43:15: [2024-10-29 12:43:15] iter = 19490, loss = 1.0796
2024-10-29 12:43:16: [2024-10-29 12:43:16] iter = 19500, loss = 0.8345
2024-10-29 12:43:16: [2024-10-29 12:43:16] iter = 19510, loss = 1.6453
2024-10-29 12:43:16: [2024-10-29 12:43:16] iter = 19520, loss = 1.2165
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 19530, loss = 1.4992
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 19540, loss = 1.4591
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 19550, loss = 1.3295
2024-10-29 12:43:18: [2024-10-29 12:43:18] iter = 19560, loss = 1.4109
2024-10-29 12:43:18: [2024-10-29 12:43:18] iter = 19570, loss = 1.6162
2024-10-29 12:43:18: [2024-10-29 12:43:18] iter = 19580, loss = 1.6547
2024-10-29 12:43:19: [2024-10-29 12:43:19] iter = 19590, loss = 1.0203
2024-10-29 12:43:19: [2024-10-29 12:43:19] iter = 19600, loss = 1.2167
2024-10-29 12:43:19: [2024-10-29 12:43:19] iter = 19610, loss = 4.3565
2024-10-29 12:43:20: [2024-10-29 12:43:20] iter = 19620, loss = 1.1953
2024-10-29 12:43:20: [2024-10-29 12:43:20] iter = 19630, loss = 1.0899
2024-10-29 12:43:20: [2024-10-29 12:43:20] iter = 19640, loss = 3.1972
2024-10-29 12:43:21: [2024-10-29 12:43:21] iter = 19650, loss = 1.6589
2024-10-29 12:43:21: [2024-10-29 12:43:21] iter = 19660, loss = 1.6511
2024-10-29 12:43:21: [2024-10-29 12:43:21] iter = 19670, loss = 1.0818
2024-10-29 12:43:22: [2024-10-29 12:43:22] iter = 19680, loss = 1.0624
2024-10-29 12:43:22: [2024-10-29 12:43:22] iter = 19690, loss = 1.0153
2024-10-29 12:43:22: [2024-10-29 12:43:22] iter = 19700, loss = 0.9428
2024-10-29 12:43:23: [2024-10-29 12:43:23] iter = 19710, loss = 2.6524
2024-10-29 12:43:23: [2024-10-29 12:43:23] iter = 19720, loss = 1.0410
2024-10-29 12:43:23: [2024-10-29 12:43:23] iter = 19730, loss = 2.2640
2024-10-29 12:43:24: [2024-10-29 12:43:24] iter = 19740, loss = 1.5882
2024-10-29 12:43:24: [2024-10-29 12:43:24] iter = 19750, loss = 0.7373
2024-10-29 12:43:24: [2024-10-29 12:43:24] iter = 19760, loss = 2.2637
2024-10-29 12:43:25: [2024-10-29 12:43:25] iter = 19770, loss = 0.9989
2024-10-29 12:43:25: [2024-10-29 12:43:25] iter = 19780, loss = 1.5689
2024-10-29 12:43:25: [2024-10-29 12:43:25] iter = 19790, loss = 1.7393
2024-10-29 12:43:26: [2024-10-29 12:43:26] iter = 19800, loss = 1.1944
2024-10-29 12:43:26: [2024-10-29 12:43:26] iter = 19810, loss = 1.1147
2024-10-29 12:43:26: [2024-10-29 12:43:26] iter = 19820, loss = 1.7349
2024-10-29 12:43:27: [2024-10-29 12:43:27] iter = 19830, loss = 1.2114
2024-10-29 12:43:27: [2024-10-29 12:43:27] iter = 19840, loss = 1.1737
2024-10-29 12:43:28: [2024-10-29 12:43:28] iter = 19850, loss = 0.9046
2024-10-29 12:43:28: [2024-10-29 12:43:28] iter = 19860, loss = 0.9972
2024-10-29 12:43:28: [2024-10-29 12:43:28] iter = 19870, loss = 2.6496
2024-10-29 12:43:29: [2024-10-29 12:43:29] iter = 19880, loss = 1.2222
2024-10-29 12:43:29: [2024-10-29 12:43:29] iter = 19890, loss = 1.1447
2024-10-29 12:43:29: [2024-10-29 12:43:29] iter = 19900, loss = 2.4084
2024-10-29 12:43:30: [2024-10-29 12:43:30] iter = 19910, loss = 1.1390
2024-10-29 12:43:30: [2024-10-29 12:43:30] iter = 19920, loss = 1.9271
2024-10-29 12:43:30: [2024-10-29 12:43:30] iter = 19930, loss = 1.1269
2024-10-29 12:43:31: [2024-10-29 12:43:31] iter = 19940, loss = 1.0501
2024-10-29 12:43:31: [2024-10-29 12:43:31] iter = 19950, loss = 1.5569
2024-10-29 12:43:31: [2024-10-29 12:43:31] iter = 19960, loss = 1.3267
2024-10-29 12:43:32: [2024-10-29 12:43:32] iter = 19970, loss = 0.9346
2024-10-29 12:43:32: [2024-10-29 12:43:32] iter = 19980, loss = 1.8360
2024-10-29 12:43:33: [2024-10-29 12:43:33] iter = 19990, loss = 1.0157
2024-10-29 12:43:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 12:43:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:43:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 13343}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:44:04: Evaluate 5 random ConvNet, ACCmean = 0.6314 ACCstd = 0.0124
-------------------------
2024-10-29 12:44:04: Evaluate 5 random ConvNet, SENmean = 0.5998 SENstd = 0.0017
-------------------------
2024-10-29 12:44:04: Evaluate 5 random ConvNet, SPEmean = 0.5998 SPEstd = 0.0017
-------------------------
2024-10-29 12:44:04: Evaluate 5 random ConvNet, F!mean = 0.5013 F!std = 0.0058
-------------------------
2024-10-29 12:44:04: Evaluate 5 random ConvNet, mean = 0.6314 std = 0.0124
-------------------------
2024-10-29 12:44:04: [2024-10-29 12:44:04] iter = 20000, loss = 3.6706
2024-10-29 12:44:04: 
================== Exp 1 ==================
 
2024-10-29 12:44:04: Hyper-parameters: 
{'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f20047a2730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_ChestMNIST (INFO)>}
2024-10-29 12:44:04: Evaluation model pool: ['ConvNet']
2024-10-29 12:44:06: class c = 0: 70472 real images
2024-10-29 12:44:06: class c = 1: 7996 real images
2024-10-29 12:44:06: real images channel 0, mean = 0.4936, std = 0.2380
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 12:44:06: initialize synthetic data from random real images
2024-10-29 12:44:06: [2024-10-29 12:44:06] training begins
2024-10-29 12:44:06: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 12:44:06: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:44:06: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 44776}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:44:37: Evaluate 5 random ConvNet, ACCmean = 0.6015 ACCstd = 0.0205
-------------------------
2024-10-29 12:44:37: Evaluate 5 random ConvNet, SENmean = 0.5391 SENstd = 0.0056
-------------------------
2024-10-29 12:44:37: Evaluate 5 random ConvNet, SPEmean = 0.5391 SPEstd = 0.0056
-------------------------
2024-10-29 12:44:37: Evaluate 5 random ConvNet, F!mean = 0.4668 F!std = 0.0097
-------------------------
2024-10-29 12:44:37: Evaluate 5 random ConvNet, mean = 0.6015 std = 0.0205
-------------------------
2024-10-29 12:44:37: [2024-10-29 12:44:37] iter = 00000, loss = 4.6875
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:44:37: [2024-10-29 12:44:37] iter = 00010, loss = 6.2413
2024-10-29 12:44:37: [2024-10-29 12:44:37] iter = 00020, loss = 2.1893
2024-10-29 12:44:38: [2024-10-29 12:44:38] iter = 00030, loss = 2.2094
2024-10-29 12:44:38: [2024-10-29 12:44:38] iter = 00040, loss = 1.3880
2024-10-29 12:44:38: [2024-10-29 12:44:38] iter = 00050, loss = 1.4449
2024-10-29 12:44:39: [2024-10-29 12:44:39] iter = 00060, loss = 2.0848
2024-10-29 12:44:39: [2024-10-29 12:44:39] iter = 00070, loss = 1.4299
2024-10-29 12:44:40: [2024-10-29 12:44:40] iter = 00080, loss = 1.9453
2024-10-29 12:44:40: [2024-10-29 12:44:40] iter = 00090, loss = 2.2085
2024-10-29 12:44:40: [2024-10-29 12:44:40] iter = 00100, loss = 2.7292
2024-10-29 12:44:41: [2024-10-29 12:44:41] iter = 00110, loss = 1.2799
2024-10-29 12:44:41: [2024-10-29 12:44:41] iter = 00120, loss = 1.4462
2024-10-29 12:44:41: [2024-10-29 12:44:41] iter = 00130, loss = 4.3790
2024-10-29 12:44:42: [2024-10-29 12:44:42] iter = 00140, loss = 2.2144
2024-10-29 12:44:42: [2024-10-29 12:44:42] iter = 00150, loss = 1.4041
2024-10-29 12:44:42: [2024-10-29 12:44:42] iter = 00160, loss = 1.7392
2024-10-29 12:44:42: [2024-10-29 12:44:42] iter = 00170, loss = 1.7961
2024-10-29 12:44:43: [2024-10-29 12:44:43] iter = 00180, loss = 5.3624
2024-10-29 12:44:43: [2024-10-29 12:44:43] iter = 00190, loss = 1.1877
2024-10-29 12:44:44: [2024-10-29 12:44:44] iter = 00200, loss = 1.5368
2024-10-29 12:44:44: [2024-10-29 12:44:44] iter = 00210, loss = 0.9852
2024-10-29 12:44:44: [2024-10-29 12:44:44] iter = 00220, loss = 1.3922
2024-10-29 12:44:45: [2024-10-29 12:44:45] iter = 00230, loss = 0.8261
2024-10-29 12:44:45: [2024-10-29 12:44:45] iter = 00240, loss = 2.5515
2024-10-29 12:44:45: [2024-10-29 12:44:45] iter = 00250, loss = 1.1269
2024-10-29 12:44:45: [2024-10-29 12:44:45] iter = 00260, loss = 3.1652
2024-10-29 12:44:46: [2024-10-29 12:44:46] iter = 00270, loss = 1.4636
2024-10-29 12:44:46: [2024-10-29 12:44:46] iter = 00280, loss = 2.0076
2024-10-29 12:44:47: [2024-10-29 12:44:47] iter = 00290, loss = 1.0710
2024-10-29 12:44:47: [2024-10-29 12:44:47] iter = 00300, loss = 2.7886
2024-10-29 12:44:47: [2024-10-29 12:44:47] iter = 00310, loss = 1.7040
2024-10-29 12:44:48: [2024-10-29 12:44:48] iter = 00320, loss = 1.5575
2024-10-29 12:44:48: [2024-10-29 12:44:48] iter = 00330, loss = 2.2345
2024-10-29 12:44:48: [2024-10-29 12:44:48] iter = 00340, loss = 0.9855
2024-10-29 12:44:49: [2024-10-29 12:44:49] iter = 00350, loss = 1.1172
2024-10-29 12:44:49: [2024-10-29 12:44:49] iter = 00360, loss = 1.0889
2024-10-29 12:44:49: [2024-10-29 12:44:49] iter = 00370, loss = 1.1511
2024-10-29 12:44:50: [2024-10-29 12:44:49] iter = 00380, loss = 4.2161
2024-10-29 12:44:50: [2024-10-29 12:44:50] iter = 00390, loss = 1.1754
2024-10-29 12:44:50: [2024-10-29 12:44:50] iter = 00400, loss = 1.1321
2024-10-29 12:44:51: [2024-10-29 12:44:51] iter = 00410, loss = 1.1664
2024-10-29 12:44:51: [2024-10-29 12:44:51] iter = 00420, loss = 1.9635
2024-10-29 12:44:51: [2024-10-29 12:44:51] iter = 00430, loss = 1.8868
2024-10-29 12:44:51: [2024-10-29 12:44:51] iter = 00440, loss = 15.3277
2024-10-29 12:44:52: [2024-10-29 12:44:52] iter = 00450, loss = 2.4903
2024-10-29 12:44:52: [2024-10-29 12:44:52] iter = 00460, loss = 1.8146
2024-10-29 12:44:52: [2024-10-29 12:44:52] iter = 00470, loss = 1.7543
2024-10-29 12:44:53: [2024-10-29 12:44:53] iter = 00480, loss = 3.4833
2024-10-29 12:44:53: [2024-10-29 12:44:53] iter = 00490, loss = 3.1612
2024-10-29 12:44:53: [2024-10-29 12:44:53] iter = 00500, loss = 1.6959
2024-10-29 12:44:54: [2024-10-29 12:44:54] iter = 00510, loss = 5.5166
2024-10-29 12:44:54: [2024-10-29 12:44:54] iter = 00520, loss = 1.3832
2024-10-29 12:44:55: [2024-10-29 12:44:55] iter = 00530, loss = 1.5565
2024-10-29 12:44:55: [2024-10-29 12:44:55] iter = 00540, loss = 1.3434
2024-10-29 12:44:56: [2024-10-29 12:44:56] iter = 00550, loss = 1.3066
2024-10-29 12:44:56: [2024-10-29 12:44:56] iter = 00560, loss = 1.7124
2024-10-29 12:44:57: [2024-10-29 12:44:57] iter = 00570, loss = 1.6121
2024-10-29 12:44:57: [2024-10-29 12:44:57] iter = 00580, loss = 1.0836
2024-10-29 12:44:57: [2024-10-29 12:44:57] iter = 00590, loss = 1.9670
2024-10-29 12:44:58: [2024-10-29 12:44:58] iter = 00600, loss = 1.8171
2024-10-29 12:44:58: [2024-10-29 12:44:58] iter = 00610, loss = 0.7704
2024-10-29 12:44:58: [2024-10-29 12:44:58] iter = 00620, loss = 1.8628
2024-10-29 12:44:59: [2024-10-29 12:44:59] iter = 00630, loss = 1.3826
2024-10-29 12:44:59: [2024-10-29 12:44:59] iter = 00640, loss = 1.6515
2024-10-29 12:44:59: [2024-10-29 12:44:59] iter = 00650, loss = 1.1733
2024-10-29 12:45:00: [2024-10-29 12:45:00] iter = 00660, loss = 1.2113
2024-10-29 12:45:00: [2024-10-29 12:45:00] iter = 00670, loss = 1.4176
2024-10-29 12:45:01: [2024-10-29 12:45:01] iter = 00680, loss = 1.1774
2024-10-29 12:45:01: [2024-10-29 12:45:01] iter = 00690, loss = 1.3764
2024-10-29 12:45:01: [2024-10-29 12:45:01] iter = 00700, loss = 1.1692
2024-10-29 12:45:02: [2024-10-29 12:45:02] iter = 00710, loss = 1.5334
2024-10-29 12:45:02: [2024-10-29 12:45:02] iter = 00720, loss = 0.9816
2024-10-29 12:45:02: [2024-10-29 12:45:02] iter = 00730, loss = 1.0630
2024-10-29 12:45:03: [2024-10-29 12:45:03] iter = 00740, loss = 1.5149
2024-10-29 12:45:03: [2024-10-29 12:45:03] iter = 00750, loss = 8.2517
2024-10-29 12:45:03: [2024-10-29 12:45:03] iter = 00760, loss = 1.4167
2024-10-29 12:45:04: [2024-10-29 12:45:04] iter = 00770, loss = 1.0024
2024-10-29 12:45:04: [2024-10-29 12:45:04] iter = 00780, loss = 1.1003
2024-10-29 12:45:05: [2024-10-29 12:45:05] iter = 00790, loss = 0.9686
2024-10-29 12:45:05: [2024-10-29 12:45:05] iter = 00800, loss = 1.2893
2024-10-29 12:45:05: [2024-10-29 12:45:05] iter = 00810, loss = 3.9842
2024-10-29 12:45:06: [2024-10-29 12:45:05] iter = 00820, loss = 1.3490
2024-10-29 12:45:06: [2024-10-29 12:45:06] iter = 00830, loss = 0.8384
2024-10-29 12:45:06: [2024-10-29 12:45:06] iter = 00840, loss = 2.2409
2024-10-29 12:45:07: [2024-10-29 12:45:07] iter = 00850, loss = 3.4595
2024-10-29 12:45:07: [2024-10-29 12:45:07] iter = 00860, loss = 1.3597
2024-10-29 12:45:07: [2024-10-29 12:45:07] iter = 00870, loss = 1.1812
2024-10-29 12:45:08: [2024-10-29 12:45:08] iter = 00880, loss = 1.2103
2024-10-29 12:45:08: [2024-10-29 12:45:08] iter = 00890, loss = 1.4632
2024-10-29 12:45:09: [2024-10-29 12:45:09] iter = 00900, loss = 1.9444
2024-10-29 12:45:09: [2024-10-29 12:45:09] iter = 00910, loss = 1.3998
2024-10-29 12:45:10: [2024-10-29 12:45:10] iter = 00920, loss = 1.4371
2024-10-29 12:45:10: [2024-10-29 12:45:10] iter = 00930, loss = 2.2454
2024-10-29 12:45:10: [2024-10-29 12:45:10] iter = 00940, loss = 2.0918
2024-10-29 12:45:11: [2024-10-29 12:45:11] iter = 00950, loss = 1.3446
2024-10-29 12:45:11: [2024-10-29 12:45:11] iter = 00960, loss = 1.1701
2024-10-29 12:45:11: [2024-10-29 12:45:11] iter = 00970, loss = 1.5332
2024-10-29 12:45:12: [2024-10-29 12:45:12] iter = 00980, loss = 4.0890
2024-10-29 12:45:12: [2024-10-29 12:45:12] iter = 00990, loss = 1.1154
2024-10-29 12:45:13: [2024-10-29 12:45:13] iter = 01000, loss = 1.8742
2024-10-29 12:45:13: [2024-10-29 12:45:13] iter = 01010, loss = 1.4677
2024-10-29 12:45:13: [2024-10-29 12:45:13] iter = 01020, loss = 1.5838
2024-10-29 12:45:14: [2024-10-29 12:45:14] iter = 01030, loss = 2.6082
2024-10-29 12:45:14: [2024-10-29 12:45:14] iter = 01040, loss = 3.0224
2024-10-29 12:45:15: [2024-10-29 12:45:15] iter = 01050, loss = 1.0189
2024-10-29 12:45:15: [2024-10-29 12:45:15] iter = 01060, loss = 1.0077
2024-10-29 12:45:16: [2024-10-29 12:45:16] iter = 01070, loss = 1.5835
2024-10-29 12:45:16: [2024-10-29 12:45:16] iter = 01080, loss = 3.5006
2024-10-29 12:45:17: [2024-10-29 12:45:17] iter = 01090, loss = 3.3400
2024-10-29 12:45:17: [2024-10-29 12:45:17] iter = 01100, loss = 1.1652
2024-10-29 12:45:18: [2024-10-29 12:45:18] iter = 01110, loss = 2.4277
2024-10-29 12:45:18: [2024-10-29 12:45:18] iter = 01120, loss = 3.0981
2024-10-29 12:45:18: [2024-10-29 12:45:18] iter = 01130, loss = 1.0590
2024-10-29 12:45:19: [2024-10-29 12:45:19] iter = 01140, loss = 1.3927
2024-10-29 12:45:19: [2024-10-29 12:45:19] iter = 01150, loss = 2.3212
2024-10-29 12:45:19: [2024-10-29 12:45:19] iter = 01160, loss = 1.1566
2024-10-29 12:45:20: [2024-10-29 12:45:20] iter = 01170, loss = 1.0403
2024-10-29 12:45:20: [2024-10-29 12:45:20] iter = 01180, loss = 1.1031
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 01190, loss = 1.2518
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 01200, loss = 1.1829
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 01210, loss = 2.2624
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 01220, loss = 1.8645
2024-10-29 12:45:22: [2024-10-29 12:45:22] iter = 01230, loss = 1.1266
2024-10-29 12:45:22: [2024-10-29 12:45:22] iter = 01240, loss = 1.2030
2024-10-29 12:45:23: [2024-10-29 12:45:23] iter = 01250, loss = 2.4411
2024-10-29 12:45:23: [2024-10-29 12:45:23] iter = 01260, loss = 3.1070
2024-10-29 12:45:23: [2024-10-29 12:45:23] iter = 01270, loss = 1.8213
2024-10-29 12:45:24: [2024-10-29 12:45:24] iter = 01280, loss = 0.8619
2024-10-29 12:45:24: [2024-10-29 12:45:24] iter = 01290, loss = 2.0107
2024-10-29 12:45:24: [2024-10-29 12:45:24] iter = 01300, loss = 1.6754
2024-10-29 12:45:25: [2024-10-29 12:45:25] iter = 01310, loss = 1.1555
2024-10-29 12:45:25: [2024-10-29 12:45:25] iter = 01320, loss = 0.9816
2024-10-29 12:45:26: [2024-10-29 12:45:26] iter = 01330, loss = 1.3055
2024-10-29 12:45:26: [2024-10-29 12:45:26] iter = 01340, loss = 6.3761
2024-10-29 12:45:26: [2024-10-29 12:45:26] iter = 01350, loss = 1.1304
2024-10-29 12:45:27: [2024-10-29 12:45:27] iter = 01360, loss = 1.3779
2024-10-29 12:45:27: [2024-10-29 12:45:27] iter = 01370, loss = 1.6489
2024-10-29 12:45:27: [2024-10-29 12:45:27] iter = 01380, loss = 0.9829
2024-10-29 12:45:28: [2024-10-29 12:45:28] iter = 01390, loss = 1.4069
2024-10-29 12:45:28: [2024-10-29 12:45:28] iter = 01400, loss = 1.1087
2024-10-29 12:45:28: [2024-10-29 12:45:28] iter = 01410, loss = 3.2363
2024-10-29 12:45:29: [2024-10-29 12:45:29] iter = 01420, loss = 1.6876
2024-10-29 12:45:29: [2024-10-29 12:45:29] iter = 01430, loss = 0.9408
2024-10-29 12:45:29: [2024-10-29 12:45:29] iter = 01440, loss = 1.4858
2024-10-29 12:45:30: [2024-10-29 12:45:30] iter = 01450, loss = 0.8391
2024-10-29 12:45:30: [2024-10-29 12:45:30] iter = 01460, loss = 2.8766
2024-10-29 12:45:31: [2024-10-29 12:45:31] iter = 01470, loss = 1.2097
2024-10-29 12:45:31: [2024-10-29 12:45:31] iter = 01480, loss = 1.6627
2024-10-29 12:45:31: [2024-10-29 12:45:31] iter = 01490, loss = 1.6357
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 01500, loss = 0.9011
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 01510, loss = 3.7511
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 01520, loss = 1.1199
2024-10-29 12:45:33: [2024-10-29 12:45:33] iter = 01530, loss = 1.1652
2024-10-29 12:45:33: [2024-10-29 12:45:33] iter = 01540, loss = 1.3656
2024-10-29 12:45:33: [2024-10-29 12:45:33] iter = 01550, loss = 1.1848
2024-10-29 12:45:34: [2024-10-29 12:45:34] iter = 01560, loss = 1.7671
2024-10-29 12:45:34: [2024-10-29 12:45:34] iter = 01570, loss = 1.7232
2024-10-29 12:45:34: [2024-10-29 12:45:34] iter = 01580, loss = 1.2000
2024-10-29 12:45:35: [2024-10-29 12:45:35] iter = 01590, loss = 2.1262
2024-10-29 12:45:35: [2024-10-29 12:45:35] iter = 01600, loss = 1.2990
2024-10-29 12:45:35: [2024-10-29 12:45:35] iter = 01610, loss = 1.1070
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 01620, loss = 2.3318
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 01630, loss = 1.6494
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 01640, loss = 1.6827
2024-10-29 12:45:37: [2024-10-29 12:45:37] iter = 01650, loss = 0.9032
2024-10-29 12:45:37: [2024-10-29 12:45:37] iter = 01660, loss = 1.0093
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 01670, loss = 1.9829
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 01680, loss = 3.0660
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 01690, loss = 5.4323
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 01700, loss = 3.9523
2024-10-29 12:45:39: [2024-10-29 12:45:39] iter = 01710, loss = 1.2985
2024-10-29 12:45:39: [2024-10-29 12:45:39] iter = 01720, loss = 2.1143
2024-10-29 12:45:39: [2024-10-29 12:45:39] iter = 01730, loss = 1.2334
2024-10-29 12:45:40: [2024-10-29 12:45:40] iter = 01740, loss = 1.6921
2024-10-29 12:45:40: [2024-10-29 12:45:40] iter = 01750, loss = 1.1761
2024-10-29 12:45:40: [2024-10-29 12:45:40] iter = 01760, loss = 3.2038
2024-10-29 12:45:41: [2024-10-29 12:45:41] iter = 01770, loss = 1.7761
2024-10-29 12:45:41: [2024-10-29 12:45:41] iter = 01780, loss = 4.2902
2024-10-29 12:45:42: [2024-10-29 12:45:42] iter = 01790, loss = 1.8414
2024-10-29 12:45:42: [2024-10-29 12:45:42] iter = 01800, loss = 3.9153
2024-10-29 12:45:42: [2024-10-29 12:45:42] iter = 01810, loss = 1.0894
2024-10-29 12:45:43: [2024-10-29 12:45:43] iter = 01820, loss = 0.9642
2024-10-29 12:45:43: [2024-10-29 12:45:43] iter = 01830, loss = 1.0464
2024-10-29 12:45:43: [2024-10-29 12:45:43] iter = 01840, loss = 1.2276
2024-10-29 12:45:44: [2024-10-29 12:45:44] iter = 01850, loss = 2.3225
2024-10-29 12:45:44: [2024-10-29 12:45:44] iter = 01860, loss = 1.7956
2024-10-29 12:45:44: [2024-10-29 12:45:44] iter = 01870, loss = 1.4509
2024-10-29 12:45:45: [2024-10-29 12:45:45] iter = 01880, loss = 3.4350
2024-10-29 12:45:45: [2024-10-29 12:45:45] iter = 01890, loss = 2.3992
2024-10-29 12:45:45: [2024-10-29 12:45:45] iter = 01900, loss = 1.7127
2024-10-29 12:45:46: [2024-10-29 12:45:46] iter = 01910, loss = 0.8799
2024-10-29 12:45:46: [2024-10-29 12:45:46] iter = 01920, loss = 1.2306
2024-10-29 12:45:46: [2024-10-29 12:45:46] iter = 01930, loss = 1.4225
2024-10-29 12:45:47: [2024-10-29 12:45:47] iter = 01940, loss = 1.9398
2024-10-29 12:45:47: [2024-10-29 12:45:47] iter = 01950, loss = 1.2820
2024-10-29 12:45:47: [2024-10-29 12:45:47] iter = 01960, loss = 5.6620
2024-10-29 12:45:48: [2024-10-29 12:45:48] iter = 01970, loss = 1.6894
2024-10-29 12:45:48: [2024-10-29 12:45:48] iter = 01980, loss = 1.0350
2024-10-29 12:45:48: [2024-10-29 12:45:48] iter = 01990, loss = 2.5658
2024-10-29 12:45:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 12:45:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:45:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49167}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:46:20: Evaluate 5 random ConvNet, ACCmean = 0.6217 ACCstd = 0.0292
-------------------------
2024-10-29 12:46:20: Evaluate 5 random ConvNet, SENmean = 0.6189 SENstd = 0.0021
-------------------------
2024-10-29 12:46:20: Evaluate 5 random ConvNet, SPEmean = 0.6189 SPEstd = 0.0021
-------------------------
2024-10-29 12:46:20: Evaluate 5 random ConvNet, F!mean = 0.5026 F!std = 0.0143
-------------------------
2024-10-29 12:46:20: Evaluate 5 random ConvNet, mean = 0.6217 std = 0.0292
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:46:20: [2024-10-29 12:46:20] iter = 02000, loss = 0.9657
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:46:20: [2024-10-29 12:46:20] iter = 02010, loss = 1.6966
2024-10-29 12:46:21: [2024-10-29 12:46:21] iter = 02020, loss = 1.3343
2024-10-29 12:46:21: [2024-10-29 12:46:21] iter = 02030, loss = 1.0791
2024-10-29 12:46:21: [2024-10-29 12:46:21] iter = 02040, loss = 2.1025
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 02050, loss = 1.4591
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 02060, loss = 5.0875
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 02070, loss = 1.2398
2024-10-29 12:46:23: [2024-10-29 12:46:23] iter = 02080, loss = 2.2265
2024-10-29 12:46:23: [2024-10-29 12:46:23] iter = 02090, loss = 3.1981
2024-10-29 12:46:23: [2024-10-29 12:46:23] iter = 02100, loss = 1.9855
2024-10-29 12:46:24: [2024-10-29 12:46:24] iter = 02110, loss = 3.2866
2024-10-29 12:46:24: [2024-10-29 12:46:24] iter = 02120, loss = 1.7552
2024-10-29 12:46:24: [2024-10-29 12:46:24] iter = 02130, loss = 2.0802
2024-10-29 12:46:25: [2024-10-29 12:46:25] iter = 02140, loss = 1.9013
2024-10-29 12:46:25: [2024-10-29 12:46:25] iter = 02150, loss = 1.0746
2024-10-29 12:46:25: [2024-10-29 12:46:25] iter = 02160, loss = 2.2272
2024-10-29 12:46:26: [2024-10-29 12:46:26] iter = 02170, loss = 6.8719
2024-10-29 12:46:26: [2024-10-29 12:46:26] iter = 02180, loss = 1.1969
2024-10-29 12:46:26: [2024-10-29 12:46:26] iter = 02190, loss = 1.4742
2024-10-29 12:46:27: [2024-10-29 12:46:27] iter = 02200, loss = 1.1104
2024-10-29 12:46:27: [2024-10-29 12:46:27] iter = 02210, loss = 1.5289
2024-10-29 12:46:28: [2024-10-29 12:46:28] iter = 02220, loss = 1.9141
2024-10-29 12:46:28: [2024-10-29 12:46:28] iter = 02230, loss = 1.1746
2024-10-29 12:46:28: [2024-10-29 12:46:28] iter = 02240, loss = 1.3423
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 02250, loss = 2.0263
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 02260, loss = 1.2633
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 02270, loss = 1.3262
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 02280, loss = 1.2315
2024-10-29 12:46:30: [2024-10-29 12:46:30] iter = 02290, loss = 1.3758
2024-10-29 12:46:30: [2024-10-29 12:46:30] iter = 02300, loss = 0.9858
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 02310, loss = 1.0406
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 02320, loss = 1.6124
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 02330, loss = 1.3720
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 02340, loss = 1.4466
2024-10-29 12:46:32: [2024-10-29 12:46:32] iter = 02350, loss = 1.2564
2024-10-29 12:46:32: [2024-10-29 12:46:32] iter = 02360, loss = 1.3420
2024-10-29 12:46:32: [2024-10-29 12:46:32] iter = 02370, loss = 1.0906
2024-10-29 12:46:33: [2024-10-29 12:46:33] iter = 02380, loss = 2.7693
2024-10-29 12:46:33: [2024-10-29 12:46:33] iter = 02390, loss = 2.4953
2024-10-29 12:46:33: [2024-10-29 12:46:33] iter = 02400, loss = 1.4907
2024-10-29 12:46:34: [2024-10-29 12:46:34] iter = 02410, loss = 1.8175
2024-10-29 12:46:34: [2024-10-29 12:46:34] iter = 02420, loss = 1.7333
2024-10-29 12:46:34: [2024-10-29 12:46:34] iter = 02430, loss = 1.0756
2024-10-29 12:46:35: [2024-10-29 12:46:35] iter = 02440, loss = 0.9834
2024-10-29 12:46:35: [2024-10-29 12:46:35] iter = 02450, loss = 0.8291
2024-10-29 12:46:36: [2024-10-29 12:46:36] iter = 02460, loss = 2.3594
2024-10-29 12:46:36: [2024-10-29 12:46:36] iter = 02470, loss = 1.6085
2024-10-29 12:46:36: [2024-10-29 12:46:36] iter = 02480, loss = 1.6004
2024-10-29 12:46:37: [2024-10-29 12:46:37] iter = 02490, loss = 2.9353
2024-10-29 12:46:37: [2024-10-29 12:46:37] iter = 02500, loss = 1.1325
2024-10-29 12:46:37: [2024-10-29 12:46:37] iter = 02510, loss = 1.1955
2024-10-29 12:46:38: [2024-10-29 12:46:38] iter = 02520, loss = 0.9774
2024-10-29 12:46:38: [2024-10-29 12:46:38] iter = 02530, loss = 1.1639
2024-10-29 12:46:38: [2024-10-29 12:46:38] iter = 02540, loss = 2.0909
2024-10-29 12:46:39: [2024-10-29 12:46:39] iter = 02550, loss = 1.0118
2024-10-29 12:46:39: [2024-10-29 12:46:39] iter = 02560, loss = 0.8601
2024-10-29 12:46:39: [2024-10-29 12:46:39] iter = 02570, loss = 1.5828
2024-10-29 12:46:40: [2024-10-29 12:46:40] iter = 02580, loss = 1.5226
2024-10-29 12:46:40: [2024-10-29 12:46:40] iter = 02590, loss = 1.1911
2024-10-29 12:46:40: [2024-10-29 12:46:40] iter = 02600, loss = 3.0390
2024-10-29 12:46:41: [2024-10-29 12:46:41] iter = 02610, loss = 1.4884
2024-10-29 12:46:41: [2024-10-29 12:46:41] iter = 02620, loss = 1.2638
2024-10-29 12:46:41: [2024-10-29 12:46:41] iter = 02630, loss = 1.1415
2024-10-29 12:46:42: [2024-10-29 12:46:42] iter = 02640, loss = 1.0273
2024-10-29 12:46:42: [2024-10-29 12:46:42] iter = 02650, loss = 1.4596
2024-10-29 12:46:42: [2024-10-29 12:46:42] iter = 02660, loss = 1.0015
2024-10-29 12:46:43: [2024-10-29 12:46:43] iter = 02670, loss = 1.2296
2024-10-29 12:46:43: [2024-10-29 12:46:43] iter = 02680, loss = 1.4409
2024-10-29 12:46:44: [2024-10-29 12:46:43] iter = 02690, loss = 1.7593
2024-10-29 12:46:44: [2024-10-29 12:46:44] iter = 02700, loss = 1.7797
2024-10-29 12:46:44: [2024-10-29 12:46:44] iter = 02710, loss = 2.6461
2024-10-29 12:46:44: [2024-10-29 12:46:44] iter = 02720, loss = 6.1720
2024-10-29 12:46:45: [2024-10-29 12:46:45] iter = 02730, loss = 1.0111
2024-10-29 12:46:46: [2024-10-29 12:46:46] iter = 02740, loss = 1.3502
2024-10-29 12:46:46: [2024-10-29 12:46:46] iter = 02750, loss = 2.0627
2024-10-29 12:46:47: [2024-10-29 12:46:47] iter = 02760, loss = 0.9323
2024-10-29 12:46:47: [2024-10-29 12:46:47] iter = 02770, loss = 1.4287
2024-10-29 12:46:48: [2024-10-29 12:46:48] iter = 02780, loss = 1.7158
2024-10-29 12:46:48: [2024-10-29 12:46:48] iter = 02790, loss = 0.9911
2024-10-29 12:46:48: [2024-10-29 12:46:48] iter = 02800, loss = 1.1672
2024-10-29 12:46:49: [2024-10-29 12:46:49] iter = 02810, loss = 1.7753
2024-10-29 12:46:49: [2024-10-29 12:46:49] iter = 02820, loss = 1.5430
2024-10-29 12:46:50: [2024-10-29 12:46:50] iter = 02830, loss = 5.8933
2024-10-29 12:46:50: [2024-10-29 12:46:50] iter = 02840, loss = 2.0652
2024-10-29 12:46:50: [2024-10-29 12:46:50] iter = 02850, loss = 1.3481
2024-10-29 12:46:51: [2024-10-29 12:46:51] iter = 02860, loss = 4.8612
2024-10-29 12:46:51: [2024-10-29 12:46:51] iter = 02870, loss = 1.6228
2024-10-29 12:46:51: [2024-10-29 12:46:51] iter = 02880, loss = 1.9651
2024-10-29 12:46:52: [2024-10-29 12:46:52] iter = 02890, loss = 1.3237
2024-10-29 12:46:52: [2024-10-29 12:46:52] iter = 02900, loss = 1.1629
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 02910, loss = 1.8816
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 02920, loss = 1.2949
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 02930, loss = 1.8672
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 02940, loss = 1.6458
2024-10-29 12:46:54: [2024-10-29 12:46:54] iter = 02950, loss = 1.6679
2024-10-29 12:46:54: [2024-10-29 12:46:54] iter = 02960, loss = 1.7206
2024-10-29 12:46:55: [2024-10-29 12:46:55] iter = 02970, loss = 2.0593
2024-10-29 12:46:55: [2024-10-29 12:46:55] iter = 02980, loss = 1.8597
2024-10-29 12:46:55: [2024-10-29 12:46:55] iter = 02990, loss = 0.8615
2024-10-29 12:46:56: [2024-10-29 12:46:56] iter = 03000, loss = 1.8819
2024-10-29 12:46:56: [2024-10-29 12:46:56] iter = 03010, loss = 1.8915
2024-10-29 12:46:56: [2024-10-29 12:46:56] iter = 03020, loss = 1.8028
2024-10-29 12:46:57: [2024-10-29 12:46:57] iter = 03030, loss = 1.0604
2024-10-29 12:46:57: [2024-10-29 12:46:57] iter = 03040, loss = 1.1028
2024-10-29 12:46:57: [2024-10-29 12:46:57] iter = 03050, loss = 1.4681
2024-10-29 12:46:58: [2024-10-29 12:46:58] iter = 03060, loss = 1.2604
2024-10-29 12:46:58: [2024-10-29 12:46:58] iter = 03070, loss = 2.3694
2024-10-29 12:46:59: [2024-10-29 12:46:58] iter = 03080, loss = 1.0162
2024-10-29 12:46:59: [2024-10-29 12:46:59] iter = 03090, loss = 1.2379
2024-10-29 12:47:00: [2024-10-29 12:47:00] iter = 03100, loss = 0.8754
2024-10-29 12:47:00: [2024-10-29 12:47:00] iter = 03110, loss = 1.6381
2024-10-29 12:47:00: [2024-10-29 12:47:00] iter = 03120, loss = 1.5533
2024-10-29 12:47:01: [2024-10-29 12:47:01] iter = 03130, loss = 1.2177
2024-10-29 12:47:01: [2024-10-29 12:47:01] iter = 03140, loss = 1.4515
2024-10-29 12:47:01: [2024-10-29 12:47:01] iter = 03150, loss = 1.1304
2024-10-29 12:47:02: [2024-10-29 12:47:02] iter = 03160, loss = 1.7535
2024-10-29 12:47:02: [2024-10-29 12:47:02] iter = 03170, loss = 1.0495
2024-10-29 12:47:03: [2024-10-29 12:47:02] iter = 03180, loss = 0.8696
2024-10-29 12:47:03: [2024-10-29 12:47:03] iter = 03190, loss = 1.9418
2024-10-29 12:47:03: [2024-10-29 12:47:03] iter = 03200, loss = 2.3193
2024-10-29 12:47:03: [2024-10-29 12:47:03] iter = 03210, loss = 2.0238
2024-10-29 12:47:04: [2024-10-29 12:47:04] iter = 03220, loss = 2.0074
2024-10-29 12:47:04: [2024-10-29 12:47:04] iter = 03230, loss = 1.0463
2024-10-29 12:47:04: [2024-10-29 12:47:04] iter = 03240, loss = 1.1995
2024-10-29 12:47:05: [2024-10-29 12:47:05] iter = 03250, loss = 3.1970
2024-10-29 12:47:05: [2024-10-29 12:47:05] iter = 03260, loss = 1.6459
2024-10-29 12:47:05: [2024-10-29 12:47:05] iter = 03270, loss = 0.8296
2024-10-29 12:47:06: [2024-10-29 12:47:06] iter = 03280, loss = 3.1569
2024-10-29 12:47:06: [2024-10-29 12:47:06] iter = 03290, loss = 2.0309
2024-10-29 12:47:06: [2024-10-29 12:47:06] iter = 03300, loss = 1.1698
2024-10-29 12:47:07: [2024-10-29 12:47:07] iter = 03310, loss = 1.3359
2024-10-29 12:47:07: [2024-10-29 12:47:07] iter = 03320, loss = 1.5510
2024-10-29 12:47:07: [2024-10-29 12:47:07] iter = 03330, loss = 1.4315
2024-10-29 12:47:08: [2024-10-29 12:47:08] iter = 03340, loss = 3.7562
2024-10-29 12:47:08: [2024-10-29 12:47:08] iter = 03350, loss = 3.5388
2024-10-29 12:47:09: [2024-10-29 12:47:09] iter = 03360, loss = 0.9783
2024-10-29 12:47:09: [2024-10-29 12:47:09] iter = 03370, loss = 1.6981
2024-10-29 12:47:09: [2024-10-29 12:47:09] iter = 03380, loss = 1.3288
2024-10-29 12:47:10: [2024-10-29 12:47:10] iter = 03390, loss = 1.2639
2024-10-29 12:47:10: [2024-10-29 12:47:10] iter = 03400, loss = 1.7385
2024-10-29 12:47:10: [2024-10-29 12:47:10] iter = 03410, loss = 2.3573
2024-10-29 12:47:11: [2024-10-29 12:47:11] iter = 03420, loss = 2.0124
2024-10-29 12:47:11: [2024-10-29 12:47:11] iter = 03430, loss = 1.2754
2024-10-29 12:47:11: [2024-10-29 12:47:11] iter = 03440, loss = 1.0206
2024-10-29 12:47:12: [2024-10-29 12:47:12] iter = 03450, loss = 1.3288
2024-10-29 12:47:12: [2024-10-29 12:47:12] iter = 03460, loss = 1.6441
2024-10-29 12:47:13: [2024-10-29 12:47:13] iter = 03470, loss = 2.0412
2024-10-29 12:47:13: [2024-10-29 12:47:13] iter = 03480, loss = 0.8855
2024-10-29 12:47:13: [2024-10-29 12:47:13] iter = 03490, loss = 1.0022
2024-10-29 12:47:14: [2024-10-29 12:47:14] iter = 03500, loss = 1.7642
2024-10-29 12:47:14: [2024-10-29 12:47:14] iter = 03510, loss = 1.5467
2024-10-29 12:47:14: [2024-10-29 12:47:14] iter = 03520, loss = 1.4075
2024-10-29 12:47:15: [2024-10-29 12:47:15] iter = 03530, loss = 2.0975
2024-10-29 12:47:15: [2024-10-29 12:47:15] iter = 03540, loss = 1.7463
2024-10-29 12:47:15: [2024-10-29 12:47:15] iter = 03550, loss = 1.5257
2024-10-29 12:47:16: [2024-10-29 12:47:16] iter = 03560, loss = 1.1311
2024-10-29 12:47:16: [2024-10-29 12:47:16] iter = 03570, loss = 1.5565
2024-10-29 12:47:16: [2024-10-29 12:47:16] iter = 03580, loss = 1.1085
2024-10-29 12:47:17: [2024-10-29 12:47:17] iter = 03590, loss = 1.2828
2024-10-29 12:47:17: [2024-10-29 12:47:17] iter = 03600, loss = 2.3109
2024-10-29 12:47:17: [2024-10-29 12:47:17] iter = 03610, loss = 1.2898
2024-10-29 12:47:18: [2024-10-29 12:47:18] iter = 03620, loss = 1.3062
2024-10-29 12:47:18: [2024-10-29 12:47:18] iter = 03630, loss = 0.9957
2024-10-29 12:47:19: [2024-10-29 12:47:18] iter = 03640, loss = 2.2878
2024-10-29 12:47:19: [2024-10-29 12:47:19] iter = 03650, loss = 0.8942
2024-10-29 12:47:19: [2024-10-29 12:47:19] iter = 03660, loss = 1.8468
2024-10-29 12:47:20: [2024-10-29 12:47:20] iter = 03670, loss = 1.5566
2024-10-29 12:47:20: [2024-10-29 12:47:20] iter = 03680, loss = 1.6317
2024-10-29 12:47:20: [2024-10-29 12:47:20] iter = 03690, loss = 2.1389
2024-10-29 12:47:21: [2024-10-29 12:47:21] iter = 03700, loss = 1.2687
2024-10-29 12:47:21: [2024-10-29 12:47:21] iter = 03710, loss = 1.0801
2024-10-29 12:47:21: [2024-10-29 12:47:21] iter = 03720, loss = 4.4057
2024-10-29 12:47:22: [2024-10-29 12:47:22] iter = 03730, loss = 1.8821
2024-10-29 12:47:22: [2024-10-29 12:47:22] iter = 03740, loss = 1.0395
2024-10-29 12:47:22: [2024-10-29 12:47:22] iter = 03750, loss = 1.1538
2024-10-29 12:47:23: [2024-10-29 12:47:23] iter = 03760, loss = 1.1187
2024-10-29 12:47:23: [2024-10-29 12:47:23] iter = 03770, loss = 1.2112
2024-10-29 12:47:23: [2024-10-29 12:47:23] iter = 03780, loss = 0.9372
2024-10-29 12:47:24: [2024-10-29 12:47:24] iter = 03790, loss = 1.3988
2024-10-29 12:47:24: [2024-10-29 12:47:24] iter = 03800, loss = 0.8145
2024-10-29 12:47:24: [2024-10-29 12:47:24] iter = 03810, loss = 1.1032
2024-10-29 12:47:25: [2024-10-29 12:47:25] iter = 03820, loss = 1.6684
2024-10-29 12:47:25: [2024-10-29 12:47:25] iter = 03830, loss = 3.4076
2024-10-29 12:47:25: [2024-10-29 12:47:25] iter = 03840, loss = 2.3918
2024-10-29 12:47:26: [2024-10-29 12:47:26] iter = 03850, loss = 2.3324
2024-10-29 12:47:26: [2024-10-29 12:47:26] iter = 03860, loss = 4.2064
2024-10-29 12:47:26: [2024-10-29 12:47:26] iter = 03870, loss = 1.3878
2024-10-29 12:47:27: [2024-10-29 12:47:27] iter = 03880, loss = 1.0920
2024-10-29 12:47:27: [2024-10-29 12:47:27] iter = 03890, loss = 1.1201
2024-10-29 12:47:27: [2024-10-29 12:47:27] iter = 03900, loss = 1.4852
2024-10-29 12:47:28: [2024-10-29 12:47:28] iter = 03910, loss = 2.4227
2024-10-29 12:47:28: [2024-10-29 12:47:28] iter = 03920, loss = 1.1412
2024-10-29 12:47:28: [2024-10-29 12:47:28] iter = 03930, loss = 1.2331
2024-10-29 12:47:29: [2024-10-29 12:47:29] iter = 03940, loss = 1.0947
2024-10-29 12:47:29: [2024-10-29 12:47:29] iter = 03950, loss = 1.5888
2024-10-29 12:47:30: [2024-10-29 12:47:30] iter = 03960, loss = 1.6705
2024-10-29 12:47:30: [2024-10-29 12:47:30] iter = 03970, loss = 1.0083
2024-10-29 12:47:31: [2024-10-29 12:47:31] iter = 03980, loss = 0.6755
2024-10-29 12:47:31: [2024-10-29 12:47:31] iter = 03990, loss = 8.8369
2024-10-29 12:47:31: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 12:47:31: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:47:31: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 51799}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:48:02: Evaluate 5 random ConvNet, ACCmean = 0.6818 ACCstd = 0.0083
-------------------------
2024-10-29 12:48:02: Evaluate 5 random ConvNet, SENmean = 0.5900 SENstd = 0.0038
-------------------------
2024-10-29 12:48:02: Evaluate 5 random ConvNet, SPEmean = 0.5900 SPEstd = 0.0038
-------------------------
2024-10-29 12:48:02: Evaluate 5 random ConvNet, F!mean = 0.5207 F!std = 0.0040
-------------------------
2024-10-29 12:48:02: Evaluate 5 random ConvNet, mean = 0.6818 std = 0.0083
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:48:02: [2024-10-29 12:48:02] iter = 04000, loss = 1.1843
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:48:02: [2024-10-29 12:48:02] iter = 04010, loss = 1.3011
2024-10-29 12:48:03: [2024-10-29 12:48:03] iter = 04020, loss = 0.7615
2024-10-29 12:48:03: [2024-10-29 12:48:03] iter = 04030, loss = 1.1089
2024-10-29 12:48:03: [2024-10-29 12:48:03] iter = 04040, loss = 2.3382
2024-10-29 12:48:04: [2024-10-29 12:48:04] iter = 04050, loss = 3.3369
2024-10-29 12:48:04: [2024-10-29 12:48:04] iter = 04060, loss = 1.5675
2024-10-29 12:48:04: [2024-10-29 12:48:04] iter = 04070, loss = 0.9040
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 04080, loss = 1.1584
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 04090, loss = 2.7426
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 04100, loss = 2.4643
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 04110, loss = 1.7832
2024-10-29 12:48:06: [2024-10-29 12:48:06] iter = 04120, loss = 1.8705
2024-10-29 12:48:06: [2024-10-29 12:48:06] iter = 04130, loss = 1.1019
2024-10-29 12:48:07: [2024-10-29 12:48:07] iter = 04140, loss = 3.4335
2024-10-29 12:48:07: [2024-10-29 12:48:07] iter = 04150, loss = 0.9565
2024-10-29 12:48:08: [2024-10-29 12:48:08] iter = 04160, loss = 1.4522
2024-10-29 12:48:08: [2024-10-29 12:48:08] iter = 04170, loss = 1.9689
2024-10-29 12:48:09: [2024-10-29 12:48:09] iter = 04180, loss = 2.3771
2024-10-29 12:48:09: [2024-10-29 12:48:09] iter = 04190, loss = 1.5998
2024-10-29 12:48:09: [2024-10-29 12:48:09] iter = 04200, loss = 2.3574
2024-10-29 12:48:10: [2024-10-29 12:48:10] iter = 04210, loss = 2.0634
2024-10-29 12:48:10: [2024-10-29 12:48:10] iter = 04220, loss = 1.6153
2024-10-29 12:48:10: [2024-10-29 12:48:10] iter = 04230, loss = 1.0924
2024-10-29 12:48:11: [2024-10-29 12:48:11] iter = 04240, loss = 1.3582
2024-10-29 12:48:11: [2024-10-29 12:48:11] iter = 04250, loss = 1.3172
2024-10-29 12:48:11: [2024-10-29 12:48:11] iter = 04260, loss = 2.4125
2024-10-29 12:48:12: [2024-10-29 12:48:12] iter = 04270, loss = 1.1477
2024-10-29 12:48:12: [2024-10-29 12:48:12] iter = 04280, loss = 2.6669
2024-10-29 12:48:12: [2024-10-29 12:48:12] iter = 04290, loss = 1.2070
2024-10-29 12:48:13: [2024-10-29 12:48:13] iter = 04300, loss = 6.6747
2024-10-29 12:48:13: [2024-10-29 12:48:13] iter = 04310, loss = 3.8205
2024-10-29 12:48:13: [2024-10-29 12:48:13] iter = 04320, loss = 1.5063
2024-10-29 12:48:14: [2024-10-29 12:48:14] iter = 04330, loss = 1.3706
2024-10-29 12:48:14: [2024-10-29 12:48:14] iter = 04340, loss = 3.0889
2024-10-29 12:48:14: [2024-10-29 12:48:14] iter = 04350, loss = 2.1547
2024-10-29 12:48:15: [2024-10-29 12:48:15] iter = 04360, loss = 2.2749
2024-10-29 12:48:15: [2024-10-29 12:48:15] iter = 04370, loss = 0.8522
2024-10-29 12:48:16: [2024-10-29 12:48:16] iter = 04380, loss = 1.8520
2024-10-29 12:48:16: [2024-10-29 12:48:16] iter = 04390, loss = 1.3674
2024-10-29 12:48:17: [2024-10-29 12:48:17] iter = 04400, loss = 1.3993
2024-10-29 12:48:17: [2024-10-29 12:48:17] iter = 04410, loss = 1.4216
2024-10-29 12:48:17: [2024-10-29 12:48:17] iter = 04420, loss = 2.6803
2024-10-29 12:48:18: [2024-10-29 12:48:18] iter = 04430, loss = 0.8058
2024-10-29 12:48:18: [2024-10-29 12:48:18] iter = 04440, loss = 2.5592
2024-10-29 12:48:18: [2024-10-29 12:48:18] iter = 04450, loss = 4.9629
2024-10-29 12:48:19: [2024-10-29 12:48:19] iter = 04460, loss = 2.1829
2024-10-29 12:48:19: [2024-10-29 12:48:19] iter = 04470, loss = 1.2413
2024-10-29 12:48:20: [2024-10-29 12:48:20] iter = 04480, loss = 1.2840
2024-10-29 12:48:20: [2024-10-29 12:48:20] iter = 04490, loss = 1.1875
2024-10-29 12:48:21: [2024-10-29 12:48:21] iter = 04500, loss = 1.4736
2024-10-29 12:48:21: [2024-10-29 12:48:21] iter = 04510, loss = 1.6947
2024-10-29 12:48:22: [2024-10-29 12:48:22] iter = 04520, loss = 1.4176
2024-10-29 12:48:22: [2024-10-29 12:48:22] iter = 04530, loss = 2.3814
2024-10-29 12:48:23: [2024-10-29 12:48:23] iter = 04540, loss = 1.6808
2024-10-29 12:48:23: [2024-10-29 12:48:23] iter = 04550, loss = 1.2462
2024-10-29 12:48:23: [2024-10-29 12:48:23] iter = 04560, loss = 3.2787
2024-10-29 12:48:24: [2024-10-29 12:48:24] iter = 04570, loss = 1.2304
2024-10-29 12:48:24: [2024-10-29 12:48:24] iter = 04580, loss = 1.5903
2024-10-29 12:48:24: [2024-10-29 12:48:24] iter = 04590, loss = 1.2092
2024-10-29 12:48:25: [2024-10-29 12:48:25] iter = 04600, loss = 1.4639
2024-10-29 12:48:25: [2024-10-29 12:48:25] iter = 04610, loss = 1.2775
2024-10-29 12:48:25: [2024-10-29 12:48:25] iter = 04620, loss = 2.7646
2024-10-29 12:48:26: [2024-10-29 12:48:26] iter = 04630, loss = 1.3944
2024-10-29 12:48:26: [2024-10-29 12:48:26] iter = 04640, loss = 1.5495
2024-10-29 12:48:26: [2024-10-29 12:48:26] iter = 04650, loss = 0.8271
2024-10-29 12:48:27: [2024-10-29 12:48:27] iter = 04660, loss = 1.0320
2024-10-29 12:48:27: [2024-10-29 12:48:27] iter = 04670, loss = 1.4145
2024-10-29 12:48:27: [2024-10-29 12:48:27] iter = 04680, loss = 1.1178
2024-10-29 12:48:28: [2024-10-29 12:48:28] iter = 04690, loss = 1.4190
2024-10-29 12:48:28: [2024-10-29 12:48:28] iter = 04700, loss = 1.8148
2024-10-29 12:48:28: [2024-10-29 12:48:28] iter = 04710, loss = 2.9536
2024-10-29 12:48:29: [2024-10-29 12:48:29] iter = 04720, loss = 1.6217
2024-10-29 12:48:29: [2024-10-29 12:48:29] iter = 04730, loss = 0.7757
2024-10-29 12:48:29: [2024-10-29 12:48:29] iter = 04740, loss = 1.0397
2024-10-29 12:48:30: [2024-10-29 12:48:30] iter = 04750, loss = 2.1403
2024-10-29 12:48:30: [2024-10-29 12:48:30] iter = 04760, loss = 1.8721
2024-10-29 12:48:31: [2024-10-29 12:48:31] iter = 04770, loss = 1.4534
2024-10-29 12:48:31: [2024-10-29 12:48:31] iter = 04780, loss = 1.4155
2024-10-29 12:48:32: [2024-10-29 12:48:32] iter = 04790, loss = 1.8112
2024-10-29 12:48:32: [2024-10-29 12:48:32] iter = 04800, loss = 9.9636
2024-10-29 12:48:33: [2024-10-29 12:48:33] iter = 04810, loss = 1.4481
2024-10-29 12:48:33: [2024-10-29 12:48:33] iter = 04820, loss = 0.9472
2024-10-29 12:48:33: [2024-10-29 12:48:33] iter = 04830, loss = 3.2740
2024-10-29 12:48:34: [2024-10-29 12:48:34] iter = 04840, loss = 1.4931
2024-10-29 12:48:34: [2024-10-29 12:48:34] iter = 04850, loss = 1.1525
2024-10-29 12:48:34: [2024-10-29 12:48:34] iter = 04860, loss = 1.1106
2024-10-29 12:48:35: [2024-10-29 12:48:35] iter = 04870, loss = 0.9823
2024-10-29 12:48:35: [2024-10-29 12:48:35] iter = 04880, loss = 1.0629
2024-10-29 12:48:35: [2024-10-29 12:48:35] iter = 04890, loss = 1.2289
2024-10-29 12:48:36: [2024-10-29 12:48:36] iter = 04900, loss = 1.2187
2024-10-29 12:48:36: [2024-10-29 12:48:36] iter = 04910, loss = 1.3730
2024-10-29 12:48:36: [2024-10-29 12:48:36] iter = 04920, loss = 1.2421
2024-10-29 12:48:37: [2024-10-29 12:48:37] iter = 04930, loss = 1.5391
2024-10-29 12:48:37: [2024-10-29 12:48:37] iter = 04940, loss = 1.8587
2024-10-29 12:48:37: [2024-10-29 12:48:37] iter = 04950, loss = 2.4210
2024-10-29 12:48:38: [2024-10-29 12:48:38] iter = 04960, loss = 1.4600
2024-10-29 12:48:38: [2024-10-29 12:48:38] iter = 04970, loss = 1.5387
2024-10-29 12:48:38: [2024-10-29 12:48:38] iter = 04980, loss = 1.4216
2024-10-29 12:48:38: [2024-10-29 12:48:38] iter = 04990, loss = 1.2814
2024-10-29 12:48:39: [2024-10-29 12:48:39] iter = 05000, loss = 1.3121
2024-10-29 12:48:39: [2024-10-29 12:48:39] iter = 05010, loss = 1.0068
2024-10-29 12:48:40: [2024-10-29 12:48:40] iter = 05020, loss = 1.4082
2024-10-29 12:48:40: [2024-10-29 12:48:40] iter = 05030, loss = 0.8630
2024-10-29 12:48:40: [2024-10-29 12:48:40] iter = 05040, loss = 1.3527
2024-10-29 12:48:41: [2024-10-29 12:48:41] iter = 05050, loss = 0.9031
2024-10-29 12:48:41: [2024-10-29 12:48:41] iter = 05060, loss = 1.5237
2024-10-29 12:48:41: [2024-10-29 12:48:41] iter = 05070, loss = 1.6795
2024-10-29 12:48:42: [2024-10-29 12:48:42] iter = 05080, loss = 1.3002
2024-10-29 12:48:42: [2024-10-29 12:48:42] iter = 05090, loss = 0.9154
2024-10-29 12:48:43: [2024-10-29 12:48:43] iter = 05100, loss = 1.5843
2024-10-29 12:48:43: [2024-10-29 12:48:43] iter = 05110, loss = 2.2833
2024-10-29 12:48:43: [2024-10-29 12:48:43] iter = 05120, loss = 1.2008
2024-10-29 12:48:43: [2024-10-29 12:48:43] iter = 05130, loss = 2.7105
2024-10-29 12:48:44: [2024-10-29 12:48:44] iter = 05140, loss = 1.8983
2024-10-29 12:48:44: [2024-10-29 12:48:44] iter = 05150, loss = 1.5926
2024-10-29 12:48:45: [2024-10-29 12:48:45] iter = 05160, loss = 2.9735
2024-10-29 12:48:45: [2024-10-29 12:48:45] iter = 05170, loss = 1.5292
2024-10-29 12:48:45: [2024-10-29 12:48:45] iter = 05180, loss = 0.6758
2024-10-29 12:48:46: [2024-10-29 12:48:46] iter = 05190, loss = 1.0570
2024-10-29 12:48:46: [2024-10-29 12:48:46] iter = 05200, loss = 1.7301
2024-10-29 12:48:46: [2024-10-29 12:48:46] iter = 05210, loss = 0.9296
2024-10-29 12:48:47: [2024-10-29 12:48:47] iter = 05220, loss = 1.2855
2024-10-29 12:48:47: [2024-10-29 12:48:47] iter = 05230, loss = 4.8264
2024-10-29 12:48:48: [2024-10-29 12:48:48] iter = 05240, loss = 1.3443
2024-10-29 12:48:48: [2024-10-29 12:48:48] iter = 05250, loss = 1.6598
2024-10-29 12:48:48: [2024-10-29 12:48:48] iter = 05260, loss = 3.3209
2024-10-29 12:48:49: [2024-10-29 12:48:49] iter = 05270, loss = 0.8366
2024-10-29 12:48:49: [2024-10-29 12:48:49] iter = 05280, loss = 1.8236
2024-10-29 12:48:49: [2024-10-29 12:48:49] iter = 05290, loss = 1.3243
2024-10-29 12:48:50: [2024-10-29 12:48:50] iter = 05300, loss = 1.0800
2024-10-29 12:48:50: [2024-10-29 12:48:50] iter = 05310, loss = 8.9790
2024-10-29 12:48:50: [2024-10-29 12:48:50] iter = 05320, loss = 1.9349
2024-10-29 12:48:51: [2024-10-29 12:48:51] iter = 05330, loss = 1.3708
2024-10-29 12:48:51: [2024-10-29 12:48:51] iter = 05340, loss = 1.0721
2024-10-29 12:48:51: [2024-10-29 12:48:51] iter = 05350, loss = 1.4149
2024-10-29 12:48:52: [2024-10-29 12:48:52] iter = 05360, loss = 1.2974
2024-10-29 12:48:52: [2024-10-29 12:48:52] iter = 05370, loss = 1.3797
2024-10-29 12:48:52: [2024-10-29 12:48:52] iter = 05380, loss = 1.6100
2024-10-29 12:48:53: [2024-10-29 12:48:53] iter = 05390, loss = 2.2986
2024-10-29 12:48:53: [2024-10-29 12:48:53] iter = 05400, loss = 1.0872
2024-10-29 12:48:53: [2024-10-29 12:48:53] iter = 05410, loss = 1.1454
2024-10-29 12:48:54: [2024-10-29 12:48:54] iter = 05420, loss = 1.7483
2024-10-29 12:48:54: [2024-10-29 12:48:54] iter = 05430, loss = 2.0045
2024-10-29 12:48:54: [2024-10-29 12:48:54] iter = 05440, loss = 1.2076
2024-10-29 12:48:55: [2024-10-29 12:48:55] iter = 05450, loss = 1.1029
2024-10-29 12:48:55: [2024-10-29 12:48:55] iter = 05460, loss = 0.8833
2024-10-29 12:48:55: [2024-10-29 12:48:55] iter = 05470, loss = 1.7188
2024-10-29 12:48:56: [2024-10-29 12:48:56] iter = 05480, loss = 1.3050
2024-10-29 12:48:56: [2024-10-29 12:48:56] iter = 05490, loss = 1.5291
2024-10-29 12:48:56: [2024-10-29 12:48:56] iter = 05500, loss = 0.8755
2024-10-29 12:48:57: [2024-10-29 12:48:57] iter = 05510, loss = 3.0192
2024-10-29 12:48:57: [2024-10-29 12:48:57] iter = 05520, loss = 1.0182
2024-10-29 12:48:57: [2024-10-29 12:48:57] iter = 05530, loss = 0.9011
2024-10-29 12:48:58: [2024-10-29 12:48:58] iter = 05540, loss = 0.7496
2024-10-29 12:48:58: [2024-10-29 12:48:58] iter = 05550, loss = 1.4408
2024-10-29 12:48:58: [2024-10-29 12:48:58] iter = 05560, loss = 1.3005
2024-10-29 12:48:59: [2024-10-29 12:48:59] iter = 05570, loss = 4.4855
2024-10-29 12:48:59: [2024-10-29 12:48:59] iter = 05580, loss = 1.1305
2024-10-29 12:49:00: [2024-10-29 12:49:00] iter = 05590, loss = 7.0934
2024-10-29 12:49:00: [2024-10-29 12:49:00] iter = 05600, loss = 3.2977
2024-10-29 12:49:00: [2024-10-29 12:49:00] iter = 05610, loss = 5.5978
2024-10-29 12:49:01: [2024-10-29 12:49:01] iter = 05620, loss = 0.9971
2024-10-29 12:49:01: [2024-10-29 12:49:01] iter = 05630, loss = 1.2603
2024-10-29 12:49:02: [2024-10-29 12:49:02] iter = 05640, loss = 1.8099
2024-10-29 12:49:02: [2024-10-29 12:49:02] iter = 05650, loss = 1.2373
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 05660, loss = 3.8290
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 05670, loss = 1.4616
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 05680, loss = 0.9310
2024-10-29 12:49:04: [2024-10-29 12:49:04] iter = 05690, loss = 1.4954
2024-10-29 12:49:04: [2024-10-29 12:49:04] iter = 05700, loss = 6.0170
2024-10-29 12:49:05: [2024-10-29 12:49:05] iter = 05710, loss = 1.2528
2024-10-29 12:49:05: [2024-10-29 12:49:05] iter = 05720, loss = 0.9151
2024-10-29 12:49:06: [2024-10-29 12:49:06] iter = 05730, loss = 1.2740
2024-10-29 12:49:06: [2024-10-29 12:49:06] iter = 05740, loss = 1.2708
2024-10-29 12:49:06: [2024-10-29 12:49:06] iter = 05750, loss = 1.3757
2024-10-29 12:49:07: [2024-10-29 12:49:07] iter = 05760, loss = 10.8006
2024-10-29 12:49:08: [2024-10-29 12:49:08] iter = 05770, loss = 1.5028
2024-10-29 12:49:08: [2024-10-29 12:49:08] iter = 05780, loss = 4.1556
2024-10-29 12:49:08: [2024-10-29 12:49:08] iter = 05790, loss = 1.0046
2024-10-29 12:49:09: [2024-10-29 12:49:09] iter = 05800, loss = 0.8030
2024-10-29 12:49:09: [2024-10-29 12:49:09] iter = 05810, loss = 1.2160
2024-10-29 12:49:09: [2024-10-29 12:49:09] iter = 05820, loss = 6.9406
2024-10-29 12:49:10: [2024-10-29 12:49:10] iter = 05830, loss = 1.5328
2024-10-29 12:49:10: [2024-10-29 12:49:10] iter = 05840, loss = 1.3337
2024-10-29 12:49:10: [2024-10-29 12:49:10] iter = 05850, loss = 1.7640
2024-10-29 12:49:11: [2024-10-29 12:49:11] iter = 05860, loss = 1.6470
2024-10-29 12:49:11: [2024-10-29 12:49:11] iter = 05870, loss = 0.8793
2024-10-29 12:49:11: [2024-10-29 12:49:11] iter = 05880, loss = 1.2600
2024-10-29 12:49:12: [2024-10-29 12:49:12] iter = 05890, loss = 1.5804
2024-10-29 12:49:12: [2024-10-29 12:49:12] iter = 05900, loss = 2.7552
2024-10-29 12:49:12: [2024-10-29 12:49:12] iter = 05910, loss = 0.9844
2024-10-29 12:49:13: [2024-10-29 12:49:13] iter = 05920, loss = 8.6025
2024-10-29 12:49:13: [2024-10-29 12:49:13] iter = 05930, loss = 4.0061
2024-10-29 12:49:13: [2024-10-29 12:49:13] iter = 05940, loss = 2.4205
2024-10-29 12:49:14: [2024-10-29 12:49:14] iter = 05950, loss = 1.9422
2024-10-29 12:49:14: [2024-10-29 12:49:14] iter = 05960, loss = 1.2119
2024-10-29 12:49:14: [2024-10-29 12:49:14] iter = 05970, loss = 3.6934
2024-10-29 12:49:15: [2024-10-29 12:49:15] iter = 05980, loss = 1.0413
2024-10-29 12:49:15: [2024-10-29 12:49:15] iter = 05990, loss = 1.0331
2024-10-29 12:49:15: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 12:49:15: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:49:15: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 55805}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:49:44: Evaluate 5 random ConvNet, ACCmean = 0.6022 ACCstd = 0.0133
-------------------------
2024-10-29 12:49:44: Evaluate 5 random ConvNet, SENmean = 0.6260 SENstd = 0.0048
-------------------------
2024-10-29 12:49:44: Evaluate 5 random ConvNet, SPEmean = 0.6260 SPEstd = 0.0048
-------------------------
2024-10-29 12:49:44: Evaluate 5 random ConvNet, F!mean = 0.4950 F!std = 0.0071
-------------------------
2024-10-29 12:49:44: Evaluate 5 random ConvNet, mean = 0.6022 std = 0.0133
-------------------------
2024-10-29 12:49:44: [2024-10-29 12:49:44] iter = 06000, loss = 1.3863
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:49:44: [2024-10-29 12:49:44] iter = 06010, loss = 2.2128
2024-10-29 12:49:45: [2024-10-29 12:49:45] iter = 06020, loss = 1.8010
2024-10-29 12:49:45: [2024-10-29 12:49:45] iter = 06030, loss = 1.2821
2024-10-29 12:49:46: [2024-10-29 12:49:46] iter = 06040, loss = 0.8810
2024-10-29 12:49:46: [2024-10-29 12:49:46] iter = 06050, loss = 5.9753
2024-10-29 12:49:46: [2024-10-29 12:49:46] iter = 06060, loss = 1.5591
2024-10-29 12:49:47: [2024-10-29 12:49:47] iter = 06070, loss = 1.0957
2024-10-29 12:49:47: [2024-10-29 12:49:47] iter = 06080, loss = 2.1603
2024-10-29 12:49:47: [2024-10-29 12:49:47] iter = 06090, loss = 1.3690
2024-10-29 12:49:48: [2024-10-29 12:49:48] iter = 06100, loss = 1.4199
2024-10-29 12:49:48: [2024-10-29 12:49:48] iter = 06110, loss = 1.0293
2024-10-29 12:49:49: [2024-10-29 12:49:49] iter = 06120, loss = 1.9035
2024-10-29 12:49:49: [2024-10-29 12:49:49] iter = 06130, loss = 4.4773
2024-10-29 12:49:49: [2024-10-29 12:49:49] iter = 06140, loss = 1.5514
2024-10-29 12:49:50: [2024-10-29 12:49:50] iter = 06150, loss = 1.6437
2024-10-29 12:49:50: [2024-10-29 12:49:50] iter = 06160, loss = 0.8979
2024-10-29 12:49:51: [2024-10-29 12:49:51] iter = 06170, loss = 0.9413
2024-10-29 12:49:51: [2024-10-29 12:49:51] iter = 06180, loss = 3.0205
2024-10-29 12:49:51: [2024-10-29 12:49:51] iter = 06190, loss = 1.2686
2024-10-29 12:49:52: [2024-10-29 12:49:52] iter = 06200, loss = 2.7821
2024-10-29 12:49:52: [2024-10-29 12:49:52] iter = 06210, loss = 1.9128
2024-10-29 12:49:53: [2024-10-29 12:49:53] iter = 06220, loss = 1.2037
2024-10-29 12:49:53: [2024-10-29 12:49:53] iter = 06230, loss = 0.9806
2024-10-29 12:49:54: [2024-10-29 12:49:54] iter = 06240, loss = 2.3522
2024-10-29 12:49:54: [2024-10-29 12:49:54] iter = 06250, loss = 1.2690
2024-10-29 12:49:54: [2024-10-29 12:49:54] iter = 06260, loss = 1.5370
2024-10-29 12:49:55: [2024-10-29 12:49:55] iter = 06270, loss = 0.9127
2024-10-29 12:49:55: [2024-10-29 12:49:55] iter = 06280, loss = 2.0114
2024-10-29 12:49:55: [2024-10-29 12:49:55] iter = 06290, loss = 1.2372
2024-10-29 12:49:56: [2024-10-29 12:49:56] iter = 06300, loss = 1.8873
2024-10-29 12:49:56: [2024-10-29 12:49:56] iter = 06310, loss = 2.1868
2024-10-29 12:49:57: [2024-10-29 12:49:57] iter = 06320, loss = 1.0269
2024-10-29 12:49:57: [2024-10-29 12:49:57] iter = 06330, loss = 1.2357
2024-10-29 12:49:57: [2024-10-29 12:49:57] iter = 06340, loss = 1.5545
2024-10-29 12:49:58: [2024-10-29 12:49:58] iter = 06350, loss = 1.7957
2024-10-29 12:49:58: [2024-10-29 12:49:58] iter = 06360, loss = 2.0268
2024-10-29 12:49:58: [2024-10-29 12:49:58] iter = 06370, loss = 1.3874
2024-10-29 12:49:59: [2024-10-29 12:49:59] iter = 06380, loss = 3.9126
2024-10-29 12:49:59: [2024-10-29 12:49:59] iter = 06390, loss = 2.0377
2024-10-29 12:49:59: [2024-10-29 12:49:59] iter = 06400, loss = 2.1792
2024-10-29 12:50:00: [2024-10-29 12:50:00] iter = 06410, loss = 3.0321
2024-10-29 12:50:00: [2024-10-29 12:50:00] iter = 06420, loss = 1.1236
2024-10-29 12:50:00: [2024-10-29 12:50:00] iter = 06430, loss = 0.8977
2024-10-29 12:50:01: [2024-10-29 12:50:01] iter = 06440, loss = 2.2442
2024-10-29 12:50:01: [2024-10-29 12:50:01] iter = 06450, loss = 2.1713
2024-10-29 12:50:02: [2024-10-29 12:50:01] iter = 06460, loss = 0.7535
2024-10-29 12:50:02: [2024-10-29 12:50:02] iter = 06470, loss = 1.3597
2024-10-29 12:50:02: [2024-10-29 12:50:02] iter = 06480, loss = 1.0926
2024-10-29 12:50:03: [2024-10-29 12:50:03] iter = 06490, loss = 1.0877
2024-10-29 12:50:03: [2024-10-29 12:50:03] iter = 06500, loss = 2.0654
2024-10-29 12:50:04: [2024-10-29 12:50:04] iter = 06510, loss = 1.1204
2024-10-29 12:50:04: [2024-10-29 12:50:04] iter = 06520, loss = 1.6772
2024-10-29 12:50:04: [2024-10-29 12:50:04] iter = 06530, loss = 1.2010
2024-10-29 12:50:05: [2024-10-29 12:50:05] iter = 06540, loss = 3.8443
2024-10-29 12:50:05: [2024-10-29 12:50:05] iter = 06550, loss = 2.2238
2024-10-29 12:50:05: [2024-10-29 12:50:05] iter = 06560, loss = 1.7565
2024-10-29 12:50:06: [2024-10-29 12:50:06] iter = 06570, loss = 1.5950
2024-10-29 12:50:06: [2024-10-29 12:50:06] iter = 06580, loss = 0.9769
2024-10-29 12:50:06: [2024-10-29 12:50:06] iter = 06590, loss = 1.0207
2024-10-29 12:50:07: [2024-10-29 12:50:07] iter = 06600, loss = 1.1271
2024-10-29 12:50:07: [2024-10-29 12:50:07] iter = 06610, loss = 4.7706
2024-10-29 12:50:07: [2024-10-29 12:50:07] iter = 06620, loss = 0.9663
2024-10-29 12:50:08: [2024-10-29 12:50:08] iter = 06630, loss = 1.6564
2024-10-29 12:50:08: [2024-10-29 12:50:08] iter = 06640, loss = 1.8024
2024-10-29 12:50:08: [2024-10-29 12:50:08] iter = 06650, loss = 1.3029
2024-10-29 12:50:09: [2024-10-29 12:50:09] iter = 06660, loss = 1.5454
2024-10-29 12:50:09: [2024-10-29 12:50:09] iter = 06670, loss = 1.3983
2024-10-29 12:50:09: [2024-10-29 12:50:09] iter = 06680, loss = 1.3757
2024-10-29 12:50:10: [2024-10-29 12:50:10] iter = 06690, loss = 1.2851
2024-10-29 12:50:10: [2024-10-29 12:50:10] iter = 06700, loss = 3.3259
2024-10-29 12:50:10: [2024-10-29 12:50:10] iter = 06710, loss = 1.7197
2024-10-29 12:50:11: [2024-10-29 12:50:11] iter = 06720, loss = 1.8668
2024-10-29 12:50:11: [2024-10-29 12:50:11] iter = 06730, loss = 1.4813
2024-10-29 12:50:11: [2024-10-29 12:50:11] iter = 06740, loss = 1.2762
2024-10-29 12:50:12: [2024-10-29 12:50:12] iter = 06750, loss = 1.9751
2024-10-29 12:50:12: [2024-10-29 12:50:12] iter = 06760, loss = 0.8126
2024-10-29 12:50:12: [2024-10-29 12:50:12] iter = 06770, loss = 2.4470
2024-10-29 12:50:13: [2024-10-29 12:50:13] iter = 06780, loss = 1.3475
2024-10-29 12:50:13: [2024-10-29 12:50:13] iter = 06790, loss = 1.0549
2024-10-29 12:50:13: [2024-10-29 12:50:13] iter = 06800, loss = 1.1373
2024-10-29 12:50:14: [2024-10-29 12:50:14] iter = 06810, loss = 0.7975
2024-10-29 12:50:14: [2024-10-29 12:50:14] iter = 06820, loss = 1.1237
2024-10-29 12:50:14: [2024-10-29 12:50:14] iter = 06830, loss = 1.4436
2024-10-29 12:50:15: [2024-10-29 12:50:15] iter = 06840, loss = 1.3657
2024-10-29 12:50:15: [2024-10-29 12:50:15] iter = 06850, loss = 1.7300
2024-10-29 12:50:15: [2024-10-29 12:50:15] iter = 06860, loss = 4.5135
2024-10-29 12:50:16: [2024-10-29 12:50:16] iter = 06870, loss = 2.1090
2024-10-29 12:50:16: [2024-10-29 12:50:16] iter = 06880, loss = 2.9739
2024-10-29 12:50:16: [2024-10-29 12:50:16] iter = 06890, loss = 0.9964
2024-10-29 12:50:17: [2024-10-29 12:50:17] iter = 06900, loss = 1.1982
2024-10-29 12:50:17: [2024-10-29 12:50:17] iter = 06910, loss = 2.2923
2024-10-29 12:50:17: [2024-10-29 12:50:17] iter = 06920, loss = 1.2540
2024-10-29 12:50:18: [2024-10-29 12:50:18] iter = 06930, loss = 0.8801
2024-10-29 12:50:18: [2024-10-29 12:50:18] iter = 06940, loss = 1.7488
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 06950, loss = 8.2114
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 06960, loss = 1.7814
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 06970, loss = 1.3355
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 06980, loss = 3.1156
2024-10-29 12:50:20: [2024-10-29 12:50:20] iter = 06990, loss = 1.4588
2024-10-29 12:50:20: [2024-10-29 12:50:20] iter = 07000, loss = 1.4603
2024-10-29 12:50:20: [2024-10-29 12:50:20] iter = 07010, loss = 4.2907
2024-10-29 12:50:21: [2024-10-29 12:50:21] iter = 07020, loss = 1.2780
2024-10-29 12:50:21: [2024-10-29 12:50:21] iter = 07030, loss = 0.6335
2024-10-29 12:50:21: [2024-10-29 12:50:21] iter = 07040, loss = 0.7024
2024-10-29 12:50:22: [2024-10-29 12:50:22] iter = 07050, loss = 1.1882
2024-10-29 12:50:22: [2024-10-29 12:50:22] iter = 07060, loss = 1.3696
2024-10-29 12:50:23: [2024-10-29 12:50:23] iter = 07070, loss = 1.4843
2024-10-29 12:50:23: [2024-10-29 12:50:23] iter = 07080, loss = 1.4985
2024-10-29 12:50:23: [2024-10-29 12:50:23] iter = 07090, loss = 1.3248
2024-10-29 12:50:24: [2024-10-29 12:50:24] iter = 07100, loss = 4.1477
2024-10-29 12:50:24: [2024-10-29 12:50:24] iter = 07110, loss = 1.0166
2024-10-29 12:50:24: [2024-10-29 12:50:24] iter = 07120, loss = 1.7288
2024-10-29 12:50:25: [2024-10-29 12:50:25] iter = 07130, loss = 0.7845
2024-10-29 12:50:25: [2024-10-29 12:50:25] iter = 07140, loss = 1.7262
2024-10-29 12:50:26: [2024-10-29 12:50:25] iter = 07150, loss = 1.0273
2024-10-29 12:50:26: [2024-10-29 12:50:26] iter = 07160, loss = 2.7632
2024-10-29 12:50:26: [2024-10-29 12:50:26] iter = 07170, loss = 3.6112
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 07180, loss = 4.3212
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 07190, loss = 1.5484
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 07200, loss = 2.8531
2024-10-29 12:50:28: [2024-10-29 12:50:28] iter = 07210, loss = 2.3779
2024-10-29 12:50:28: [2024-10-29 12:50:28] iter = 07220, loss = 1.4162
2024-10-29 12:50:28: [2024-10-29 12:50:28] iter = 07230, loss = 1.8447
2024-10-29 12:50:29: [2024-10-29 12:50:29] iter = 07240, loss = 1.1084
2024-10-29 12:50:29: [2024-10-29 12:50:29] iter = 07250, loss = 2.3647
2024-10-29 12:50:29: [2024-10-29 12:50:29] iter = 07260, loss = 3.3793
2024-10-29 12:50:30: [2024-10-29 12:50:30] iter = 07270, loss = 1.7032
2024-10-29 12:50:30: [2024-10-29 12:50:30] iter = 07280, loss = 1.1220
2024-10-29 12:50:31: [2024-10-29 12:50:31] iter = 07290, loss = 1.0803
2024-10-29 12:50:31: [2024-10-29 12:50:31] iter = 07300, loss = 1.3325
2024-10-29 12:50:31: [2024-10-29 12:50:31] iter = 07310, loss = 3.8719
2024-10-29 12:50:32: [2024-10-29 12:50:32] iter = 07320, loss = 1.0711
2024-10-29 12:50:32: [2024-10-29 12:50:32] iter = 07330, loss = 1.3616
2024-10-29 12:50:32: [2024-10-29 12:50:32] iter = 07340, loss = 0.9292
2024-10-29 12:50:33: [2024-10-29 12:50:33] iter = 07350, loss = 4.9989
2024-10-29 12:50:33: [2024-10-29 12:50:33] iter = 07360, loss = 1.1144
2024-10-29 12:50:33: [2024-10-29 12:50:33] iter = 07370, loss = 1.9376
2024-10-29 12:50:34: [2024-10-29 12:50:34] iter = 07380, loss = 1.3650
2024-10-29 12:50:34: [2024-10-29 12:50:34] iter = 07390, loss = 5.0770
2024-10-29 12:50:35: [2024-10-29 12:50:35] iter = 07400, loss = 1.7887
2024-10-29 12:50:35: [2024-10-29 12:50:35] iter = 07410, loss = 2.1205
2024-10-29 12:50:35: [2024-10-29 12:50:35] iter = 07420, loss = 1.0737
2024-10-29 12:50:36: [2024-10-29 12:50:36] iter = 07430, loss = 0.9124
2024-10-29 12:50:36: [2024-10-29 12:50:36] iter = 07440, loss = 1.0074
2024-10-29 12:50:36: [2024-10-29 12:50:36] iter = 07450, loss = 2.2279
2024-10-29 12:50:37: [2024-10-29 12:50:37] iter = 07460, loss = 0.9518
2024-10-29 12:50:37: [2024-10-29 12:50:37] iter = 07470, loss = 2.2263
2024-10-29 12:50:38: [2024-10-29 12:50:38] iter = 07480, loss = 1.7172
2024-10-29 12:50:38: [2024-10-29 12:50:38] iter = 07490, loss = 2.0698
2024-10-29 12:50:39: [2024-10-29 12:50:39] iter = 07500, loss = 1.3560
2024-10-29 12:50:39: [2024-10-29 12:50:39] iter = 07510, loss = 0.9058
2024-10-29 12:50:40: [2024-10-29 12:50:40] iter = 07520, loss = 0.9675
2024-10-29 12:50:40: [2024-10-29 12:50:40] iter = 07530, loss = 1.2548
2024-10-29 12:50:41: [2024-10-29 12:50:41] iter = 07540, loss = 3.3046
2024-10-29 12:50:41: [2024-10-29 12:50:41] iter = 07550, loss = 1.0005
2024-10-29 12:50:41: [2024-10-29 12:50:41] iter = 07560, loss = 1.3969
2024-10-29 12:50:42: [2024-10-29 12:50:42] iter = 07570, loss = 0.8598
2024-10-29 12:50:42: [2024-10-29 12:50:42] iter = 07580, loss = 1.3781
2024-10-29 12:50:42: [2024-10-29 12:50:42] iter = 07590, loss = 1.0222
2024-10-29 12:50:43: [2024-10-29 12:50:43] iter = 07600, loss = 2.3515
2024-10-29 12:50:43: [2024-10-29 12:50:43] iter = 07610, loss = 1.5487
2024-10-29 12:50:44: [2024-10-29 12:50:44] iter = 07620, loss = 1.7421
2024-10-29 12:50:44: [2024-10-29 12:50:44] iter = 07630, loss = 1.8485
2024-10-29 12:50:44: [2024-10-29 12:50:44] iter = 07640, loss = 0.8320
2024-10-29 12:50:45: [2024-10-29 12:50:45] iter = 07650, loss = 0.8832
2024-10-29 12:50:45: [2024-10-29 12:50:45] iter = 07660, loss = 1.0333
2024-10-29 12:50:45: [2024-10-29 12:50:45] iter = 07670, loss = 4.7162
2024-10-29 12:50:46: [2024-10-29 12:50:46] iter = 07680, loss = 1.2358
2024-10-29 12:50:46: [2024-10-29 12:50:46] iter = 07690, loss = 2.6971
2024-10-29 12:50:46: [2024-10-29 12:50:46] iter = 07700, loss = 1.4487
2024-10-29 12:50:47: [2024-10-29 12:50:47] iter = 07710, loss = 0.9560
2024-10-29 12:50:47: [2024-10-29 12:50:47] iter = 07720, loss = 2.2531
2024-10-29 12:50:47: [2024-10-29 12:50:47] iter = 07730, loss = 1.4966
2024-10-29 12:50:48: [2024-10-29 12:50:48] iter = 07740, loss = 4.4274
2024-10-29 12:50:48: [2024-10-29 12:50:48] iter = 07750, loss = 1.1469
2024-10-29 12:50:48: [2024-10-29 12:50:48] iter = 07760, loss = 0.9494
2024-10-29 12:50:49: [2024-10-29 12:50:49] iter = 07770, loss = 1.4796
2024-10-29 12:50:50: [2024-10-29 12:50:49] iter = 07780, loss = 0.8277
2024-10-29 12:50:50: [2024-10-29 12:50:50] iter = 07790, loss = 1.4871
2024-10-29 12:50:50: [2024-10-29 12:50:50] iter = 07800, loss = 1.6388
2024-10-29 12:50:51: [2024-10-29 12:50:51] iter = 07810, loss = 0.8631
2024-10-29 12:50:51: [2024-10-29 12:50:51] iter = 07820, loss = 1.1836
2024-10-29 12:50:51: [2024-10-29 12:50:51] iter = 07830, loss = 1.0971
2024-10-29 12:50:52: [2024-10-29 12:50:52] iter = 07840, loss = 1.0814
2024-10-29 12:50:52: [2024-10-29 12:50:52] iter = 07850, loss = 0.9068
2024-10-29 12:50:52: [2024-10-29 12:50:52] iter = 07860, loss = 1.1418
2024-10-29 12:50:53: [2024-10-29 12:50:53] iter = 07870, loss = 3.2835
2024-10-29 12:50:53: [2024-10-29 12:50:53] iter = 07880, loss = 1.6172
2024-10-29 12:50:53: [2024-10-29 12:50:53] iter = 07890, loss = 1.3099
2024-10-29 12:50:54: [2024-10-29 12:50:54] iter = 07900, loss = 5.2725
2024-10-29 12:50:54: [2024-10-29 12:50:54] iter = 07910, loss = 1.2707
2024-10-29 12:50:54: [2024-10-29 12:50:54] iter = 07920, loss = 1.7605
2024-10-29 12:50:55: [2024-10-29 12:50:55] iter = 07930, loss = 5.6019
2024-10-29 12:50:55: [2024-10-29 12:50:55] iter = 07940, loss = 1.3605
2024-10-29 12:50:55: [2024-10-29 12:50:55] iter = 07950, loss = 2.7544
2024-10-29 12:50:56: [2024-10-29 12:50:56] iter = 07960, loss = 1.4746
2024-10-29 12:50:56: [2024-10-29 12:50:56] iter = 07970, loss = 4.5809
2024-10-29 12:50:57: [2024-10-29 12:50:57] iter = 07980, loss = 5.5217
2024-10-29 12:50:57: [2024-10-29 12:50:57] iter = 07990, loss = 2.8515
2024-10-29 12:50:57: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 12:50:57: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:50:57: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57850}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:51:26: Evaluate 5 random ConvNet, ACCmean = 0.4704 ACCstd = 0.0280
-------------------------
2024-10-29 12:51:26: Evaluate 5 random ConvNet, SENmean = 0.5672 SENstd = 0.0057
-------------------------
2024-10-29 12:51:26: Evaluate 5 random ConvNet, SPEmean = 0.5672 SPEstd = 0.0057
-------------------------
2024-10-29 12:51:26: Evaluate 5 random ConvNet, F!mean = 0.4091 F!std = 0.0175
-------------------------
2024-10-29 12:51:26: Evaluate 5 random ConvNet, mean = 0.4704 std = 0.0280
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:51:26: [2024-10-29 12:51:26] iter = 08000, loss = 2.1746
2024-10-29 12:51:27: [2024-10-29 12:51:27] iter = 08010, loss = 1.7293
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:51:27: [2024-10-29 12:51:27] iter = 08020, loss = 1.3026
2024-10-29 12:51:27: [2024-10-29 12:51:27] iter = 08030, loss = 1.4281
2024-10-29 12:51:28: [2024-10-29 12:51:28] iter = 08040, loss = 1.2243
2024-10-29 12:51:29: [2024-10-29 12:51:28] iter = 08050, loss = 0.8511
2024-10-29 12:51:29: [2024-10-29 12:51:29] iter = 08060, loss = 3.3176
2024-10-29 12:51:29: [2024-10-29 12:51:29] iter = 08070, loss = 0.8465
2024-10-29 12:51:30: [2024-10-29 12:51:30] iter = 08080, loss = 2.1702
2024-10-29 12:51:30: [2024-10-29 12:51:30] iter = 08090, loss = 1.4008
2024-10-29 12:51:30: [2024-10-29 12:51:30] iter = 08100, loss = 0.9335
2024-10-29 12:51:31: [2024-10-29 12:51:31] iter = 08110, loss = 0.9839
2024-10-29 12:51:31: [2024-10-29 12:51:31] iter = 08120, loss = 2.3165
2024-10-29 12:51:31: [2024-10-29 12:51:31] iter = 08130, loss = 2.2903
2024-10-29 12:51:32: [2024-10-29 12:51:32] iter = 08140, loss = 7.9255
2024-10-29 12:51:32: [2024-10-29 12:51:32] iter = 08150, loss = 1.0663
2024-10-29 12:51:32: [2024-10-29 12:51:32] iter = 08160, loss = 1.4133
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 08170, loss = 0.9506
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 08180, loss = 3.3187
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 08190, loss = 2.1615
2024-10-29 12:51:34: [2024-10-29 12:51:34] iter = 08200, loss = 1.1110
2024-10-29 12:51:34: [2024-10-29 12:51:34] iter = 08210, loss = 1.1744
2024-10-29 12:51:34: [2024-10-29 12:51:34] iter = 08220, loss = 1.8628
2024-10-29 12:51:35: [2024-10-29 12:51:35] iter = 08230, loss = 1.4474
2024-10-29 12:51:35: [2024-10-29 12:51:35] iter = 08240, loss = 0.9538
2024-10-29 12:51:35: [2024-10-29 12:51:35] iter = 08250, loss = 1.2754
2024-10-29 12:51:36: [2024-10-29 12:51:36] iter = 08260, loss = 4.6809
2024-10-29 12:51:36: [2024-10-29 12:51:36] iter = 08270, loss = 2.2906
2024-10-29 12:51:37: [2024-10-29 12:51:37] iter = 08280, loss = 1.0606
2024-10-29 12:51:37: [2024-10-29 12:51:37] iter = 08290, loss = 1.0378
2024-10-29 12:51:37: [2024-10-29 12:51:37] iter = 08300, loss = 0.9758
2024-10-29 12:51:38: [2024-10-29 12:51:38] iter = 08310, loss = 1.4615
2024-10-29 12:51:38: [2024-10-29 12:51:38] iter = 08320, loss = 2.0769
2024-10-29 12:51:38: [2024-10-29 12:51:38] iter = 08330, loss = 4.5173
2024-10-29 12:51:39: [2024-10-29 12:51:39] iter = 08340, loss = 2.2159
2024-10-29 12:51:39: [2024-10-29 12:51:39] iter = 08350, loss = 1.4420
2024-10-29 12:51:39: [2024-10-29 12:51:39] iter = 08360, loss = 1.0110
2024-10-29 12:51:40: [2024-10-29 12:51:40] iter = 08370, loss = 1.4855
2024-10-29 12:51:40: [2024-10-29 12:51:40] iter = 08380, loss = 4.7821
2024-10-29 12:51:40: [2024-10-29 12:51:40] iter = 08390, loss = 1.1208
2024-10-29 12:51:41: [2024-10-29 12:51:41] iter = 08400, loss = 0.7977
2024-10-29 12:51:41: [2024-10-29 12:51:41] iter = 08410, loss = 1.6558
2024-10-29 12:51:42: [2024-10-29 12:51:42] iter = 08420, loss = 0.7908
2024-10-29 12:51:42: [2024-10-29 12:51:42] iter = 08430, loss = 0.8945
2024-10-29 12:51:42: [2024-10-29 12:51:42] iter = 08440, loss = 1.5139
2024-10-29 12:51:43: [2024-10-29 12:51:43] iter = 08450, loss = 2.1439
2024-10-29 12:51:43: [2024-10-29 12:51:43] iter = 08460, loss = 1.3760
2024-10-29 12:51:43: [2024-10-29 12:51:43] iter = 08470, loss = 2.2207
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 08480, loss = 1.4182
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 08490, loss = 1.3874
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 08500, loss = 1.9178
2024-10-29 12:51:45: [2024-10-29 12:51:45] iter = 08510, loss = 2.4154
2024-10-29 12:51:45: [2024-10-29 12:51:45] iter = 08520, loss = 2.7802
2024-10-29 12:51:45: [2024-10-29 12:51:45] iter = 08530, loss = 1.1595
2024-10-29 12:51:46: [2024-10-29 12:51:46] iter = 08540, loss = 0.7326
2024-10-29 12:51:46: [2024-10-29 12:51:46] iter = 08550, loss = 1.6594
2024-10-29 12:51:46: [2024-10-29 12:51:46] iter = 08560, loss = 0.6678
2024-10-29 12:51:47: [2024-10-29 12:51:47] iter = 08570, loss = 0.9033
2024-10-29 12:51:47: [2024-10-29 12:51:47] iter = 08580, loss = 1.1569
2024-10-29 12:51:47: [2024-10-29 12:51:47] iter = 08590, loss = 1.2472
2024-10-29 12:51:48: [2024-10-29 12:51:48] iter = 08600, loss = 1.6310
2024-10-29 12:51:48: [2024-10-29 12:51:48] iter = 08610, loss = 1.3987
2024-10-29 12:51:48: [2024-10-29 12:51:48] iter = 08620, loss = 1.1368
2024-10-29 12:51:49: [2024-10-29 12:51:49] iter = 08630, loss = 1.6677
2024-10-29 12:51:49: [2024-10-29 12:51:49] iter = 08640, loss = 1.8367
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 08650, loss = 1.6942
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 08660, loss = 1.3309
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 08670, loss = 1.5686
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 08680, loss = 2.1041
2024-10-29 12:51:51: [2024-10-29 12:51:51] iter = 08690, loss = 0.8591
2024-10-29 12:51:51: [2024-10-29 12:51:51] iter = 08700, loss = 1.2681
2024-10-29 12:51:51: [2024-10-29 12:51:51] iter = 08710, loss = 1.1460
2024-10-29 12:51:52: [2024-10-29 12:51:52] iter = 08720, loss = 1.5166
2024-10-29 12:51:52: [2024-10-29 12:51:52] iter = 08730, loss = 0.8194
2024-10-29 12:51:52: [2024-10-29 12:51:52] iter = 08740, loss = 1.0269
2024-10-29 12:51:53: [2024-10-29 12:51:53] iter = 08750, loss = 1.1615
2024-10-29 12:51:53: [2024-10-29 12:51:53] iter = 08760, loss = 0.9342
2024-10-29 12:51:53: [2024-10-29 12:51:53] iter = 08770, loss = 1.2407
2024-10-29 12:51:54: [2024-10-29 12:51:54] iter = 08780, loss = 1.1309
2024-10-29 12:51:54: [2024-10-29 12:51:54] iter = 08790, loss = 6.4406
2024-10-29 12:51:54: [2024-10-29 12:51:54] iter = 08800, loss = 1.0897
2024-10-29 12:51:55: [2024-10-29 12:51:55] iter = 08810, loss = 1.0475
2024-10-29 12:51:55: [2024-10-29 12:51:55] iter = 08820, loss = 1.3000
2024-10-29 12:51:55: [2024-10-29 12:51:55] iter = 08830, loss = 1.5718
2024-10-29 12:51:56: [2024-10-29 12:51:56] iter = 08840, loss = 2.3735
2024-10-29 12:51:56: [2024-10-29 12:51:56] iter = 08850, loss = 1.5732
2024-10-29 12:51:56: [2024-10-29 12:51:56] iter = 08860, loss = 1.7930
2024-10-29 12:51:57: [2024-10-29 12:51:57] iter = 08870, loss = 1.2968
2024-10-29 12:51:57: [2024-10-29 12:51:57] iter = 08880, loss = 1.4036
2024-10-29 12:51:57: [2024-10-29 12:51:57] iter = 08890, loss = 1.3025
2024-10-29 12:51:58: [2024-10-29 12:51:58] iter = 08900, loss = 1.0369
2024-10-29 12:51:58: [2024-10-29 12:51:58] iter = 08910, loss = 1.7426
2024-10-29 12:51:59: [2024-10-29 12:51:58] iter = 08920, loss = 1.0276
2024-10-29 12:51:59: [2024-10-29 12:51:59] iter = 08930, loss = 1.4545
2024-10-29 12:51:59: [2024-10-29 12:51:59] iter = 08940, loss = 8.8939
2024-10-29 12:51:59: [2024-10-29 12:51:59] iter = 08950, loss = 3.1578
2024-10-29 12:52:00: [2024-10-29 12:52:00] iter = 08960, loss = 0.9568
2024-10-29 12:52:00: [2024-10-29 12:52:00] iter = 08970, loss = 2.2804
2024-10-29 12:52:00: [2024-10-29 12:52:00] iter = 08980, loss = 1.7679
2024-10-29 12:52:01: [2024-10-29 12:52:01] iter = 08990, loss = 5.0926
2024-10-29 12:52:01: [2024-10-29 12:52:01] iter = 09000, loss = 1.4830
2024-10-29 12:52:02: [2024-10-29 12:52:02] iter = 09010, loss = 1.2972
2024-10-29 12:52:02: [2024-10-29 12:52:02] iter = 09020, loss = 0.6662
2024-10-29 12:52:02: [2024-10-29 12:52:02] iter = 09030, loss = 1.1961
2024-10-29 12:52:03: [2024-10-29 12:52:03] iter = 09040, loss = 1.0207
2024-10-29 12:52:03: [2024-10-29 12:52:03] iter = 09050, loss = 1.0105
2024-10-29 12:52:03: [2024-10-29 12:52:03] iter = 09060, loss = 3.1418
2024-10-29 12:52:04: [2024-10-29 12:52:04] iter = 09070, loss = 0.9229
2024-10-29 12:52:04: [2024-10-29 12:52:04] iter = 09080, loss = 0.9664
2024-10-29 12:52:04: [2024-10-29 12:52:04] iter = 09090, loss = 1.6375
2024-10-29 12:52:05: [2024-10-29 12:52:05] iter = 09100, loss = 1.2332
2024-10-29 12:52:05: [2024-10-29 12:52:05] iter = 09110, loss = 1.2898
2024-10-29 12:52:05: [2024-10-29 12:52:05] iter = 09120, loss = 1.0052
2024-10-29 12:52:06: [2024-10-29 12:52:06] iter = 09130, loss = 1.0526
2024-10-29 12:52:06: [2024-10-29 12:52:06] iter = 09140, loss = 0.6432
2024-10-29 12:52:06: [2024-10-29 12:52:06] iter = 09150, loss = 1.0050
2024-10-29 12:52:07: [2024-10-29 12:52:07] iter = 09160, loss = 1.3296
2024-10-29 12:52:07: [2024-10-29 12:52:07] iter = 09170, loss = 1.8915
2024-10-29 12:52:07: [2024-10-29 12:52:07] iter = 09180, loss = 0.8110
2024-10-29 12:52:08: [2024-10-29 12:52:08] iter = 09190, loss = 1.5305
2024-10-29 12:52:08: [2024-10-29 12:52:08] iter = 09200, loss = 2.6449
2024-10-29 12:52:08: [2024-10-29 12:52:08] iter = 09210, loss = 2.0250
2024-10-29 12:52:09: [2024-10-29 12:52:09] iter = 09220, loss = 1.3196
2024-10-29 12:52:09: [2024-10-29 12:52:09] iter = 09230, loss = 1.6658
2024-10-29 12:52:10: [2024-10-29 12:52:10] iter = 09240, loss = 1.7021
2024-10-29 12:52:10: [2024-10-29 12:52:10] iter = 09250, loss = 1.2129
2024-10-29 12:52:10: [2024-10-29 12:52:10] iter = 09260, loss = 1.1118
2024-10-29 12:52:11: [2024-10-29 12:52:11] iter = 09270, loss = 1.2605
2024-10-29 12:52:11: [2024-10-29 12:52:11] iter = 09280, loss = 1.1200
2024-10-29 12:52:12: [2024-10-29 12:52:12] iter = 09290, loss = 1.1524
2024-10-29 12:52:12: [2024-10-29 12:52:12] iter = 09300, loss = 1.8897
2024-10-29 12:52:13: [2024-10-29 12:52:13] iter = 09310, loss = 1.7369
2024-10-29 12:52:13: [2024-10-29 12:52:13] iter = 09320, loss = 0.7480
2024-10-29 12:52:14: [2024-10-29 12:52:14] iter = 09330, loss = 2.2725
2024-10-29 12:52:14: [2024-10-29 12:52:14] iter = 09340, loss = 1.0055
2024-10-29 12:52:14: [2024-10-29 12:52:14] iter = 09350, loss = 0.8565
2024-10-29 12:52:15: [2024-10-29 12:52:15] iter = 09360, loss = 1.6744
2024-10-29 12:52:15: [2024-10-29 12:52:15] iter = 09370, loss = 2.4016
2024-10-29 12:52:15: [2024-10-29 12:52:15] iter = 09380, loss = 2.9340
2024-10-29 12:52:16: [2024-10-29 12:52:16] iter = 09390, loss = 1.8180
2024-10-29 12:52:16: [2024-10-29 12:52:16] iter = 09400, loss = 2.2664
2024-10-29 12:52:16: [2024-10-29 12:52:16] iter = 09410, loss = 1.1535
2024-10-29 12:52:17: [2024-10-29 12:52:17] iter = 09420, loss = 1.7276
2024-10-29 12:52:17: [2024-10-29 12:52:17] iter = 09430, loss = 1.9475
2024-10-29 12:52:17: [2024-10-29 12:52:17] iter = 09440, loss = 1.5610
2024-10-29 12:52:18: [2024-10-29 12:52:18] iter = 09450, loss = 1.3366
2024-10-29 12:52:18: [2024-10-29 12:52:18] iter = 09460, loss = 0.9141
2024-10-29 12:52:19: [2024-10-29 12:52:18] iter = 09470, loss = 1.3286
2024-10-29 12:52:19: [2024-10-29 12:52:19] iter = 09480, loss = 1.6802
2024-10-29 12:52:19: [2024-10-29 12:52:19] iter = 09490, loss = 1.6333
2024-10-29 12:52:20: [2024-10-29 12:52:20] iter = 09500, loss = 1.3431
2024-10-29 12:52:20: [2024-10-29 12:52:20] iter = 09510, loss = 1.9753
2024-10-29 12:52:20: [2024-10-29 12:52:20] iter = 09520, loss = 1.4503
2024-10-29 12:52:21: [2024-10-29 12:52:21] iter = 09530, loss = 2.9591
2024-10-29 12:52:21: [2024-10-29 12:52:21] iter = 09540, loss = 2.6774
2024-10-29 12:52:21: [2024-10-29 12:52:21] iter = 09550, loss = 2.1011
2024-10-29 12:52:22: [2024-10-29 12:52:22] iter = 09560, loss = 1.5812
2024-10-29 12:52:22: [2024-10-29 12:52:22] iter = 09570, loss = 1.3907
2024-10-29 12:52:22: [2024-10-29 12:52:22] iter = 09580, loss = 3.9882
2024-10-29 12:52:23: [2024-10-29 12:52:23] iter = 09590, loss = 1.4450
2024-10-29 12:52:23: [2024-10-29 12:52:23] iter = 09600, loss = 2.0436
2024-10-29 12:52:24: [2024-10-29 12:52:24] iter = 09610, loss = 1.2104
2024-10-29 12:52:24: [2024-10-29 12:52:24] iter = 09620, loss = 1.3796
2024-10-29 12:52:24: [2024-10-29 12:52:24] iter = 09630, loss = 1.9285
2024-10-29 12:52:25: [2024-10-29 12:52:25] iter = 09640, loss = 2.1991
2024-10-29 12:52:25: [2024-10-29 12:52:25] iter = 09650, loss = 2.9225
2024-10-29 12:52:25: [2024-10-29 12:52:25] iter = 09660, loss = 2.1064
2024-10-29 12:52:26: [2024-10-29 12:52:26] iter = 09670, loss = 2.9655
2024-10-29 12:52:26: [2024-10-29 12:52:26] iter = 09680, loss = 1.1788
2024-10-29 12:52:26: [2024-10-29 12:52:26] iter = 09690, loss = 1.2872
2024-10-29 12:52:27: [2024-10-29 12:52:27] iter = 09700, loss = 1.2294
2024-10-29 12:52:27: [2024-10-29 12:52:27] iter = 09710, loss = 3.1143
2024-10-29 12:52:27: [2024-10-29 12:52:27] iter = 09720, loss = 1.4902
2024-10-29 12:52:28: [2024-10-29 12:52:28] iter = 09730, loss = 1.0428
2024-10-29 12:52:28: [2024-10-29 12:52:28] iter = 09740, loss = 3.3231
2024-10-29 12:52:29: [2024-10-29 12:52:29] iter = 09750, loss = 1.3030
2024-10-29 12:52:29: [2024-10-29 12:52:29] iter = 09760, loss = 1.0592
2024-10-29 12:52:29: [2024-10-29 12:52:29] iter = 09770, loss = 1.0776
2024-10-29 12:52:30: [2024-10-29 12:52:30] iter = 09780, loss = 0.8765
2024-10-29 12:52:30: [2024-10-29 12:52:30] iter = 09790, loss = 1.5827
2024-10-29 12:52:31: [2024-10-29 12:52:31] iter = 09800, loss = 1.6441
2024-10-29 12:52:31: [2024-10-29 12:52:31] iter = 09810, loss = 1.3068
2024-10-29 12:52:31: [2024-10-29 12:52:31] iter = 09820, loss = 1.2833
2024-10-29 12:52:32: [2024-10-29 12:52:32] iter = 09830, loss = 1.2544
2024-10-29 12:52:32: [2024-10-29 12:52:32] iter = 09840, loss = 3.6308
2024-10-29 12:52:32: [2024-10-29 12:52:32] iter = 09850, loss = 1.0775
2024-10-29 12:52:33: [2024-10-29 12:52:33] iter = 09860, loss = 2.7527
2024-10-29 12:52:33: [2024-10-29 12:52:33] iter = 09870, loss = 0.9059
2024-10-29 12:52:34: [2024-10-29 12:52:34] iter = 09880, loss = 0.8008
2024-10-29 12:52:34: [2024-10-29 12:52:34] iter = 09890, loss = 1.6530
2024-10-29 12:52:34: [2024-10-29 12:52:34] iter = 09900, loss = 1.2476
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 09910, loss = 1.3882
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 09920, loss = 1.2905
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 09930, loss = 1.1320
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 09940, loss = 1.1361
2024-10-29 12:52:36: [2024-10-29 12:52:36] iter = 09950, loss = 1.0394
2024-10-29 12:52:36: [2024-10-29 12:52:36] iter = 09960, loss = 1.9159
2024-10-29 12:52:37: [2024-10-29 12:52:37] iter = 09970, loss = 1.1940
2024-10-29 12:52:37: [2024-10-29 12:52:37] iter = 09980, loss = 1.5570
2024-10-29 12:52:37: [2024-10-29 12:52:37] iter = 09990, loss = 1.8348
2024-10-29 12:52:38: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 12:52:38: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:52:38: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 58009}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:53:06: Evaluate 5 random ConvNet, ACCmean = 0.6583 ACCstd = 0.0148
-------------------------
2024-10-29 12:53:06: Evaluate 5 random ConvNet, SENmean = 0.6150 SENstd = 0.0050
-------------------------
2024-10-29 12:53:06: Evaluate 5 random ConvNet, SPEmean = 0.6150 SPEstd = 0.0050
-------------------------
2024-10-29 12:53:06: Evaluate 5 random ConvNet, F!mean = 0.5193 F!std = 0.0067
-------------------------
2024-10-29 12:53:06: Evaluate 5 random ConvNet, mean = 0.6583 std = 0.0148
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:53:06: [2024-10-29 12:53:06] iter = 10000, loss = 1.2839
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:53:06: [2024-10-29 12:53:06] iter = 10010, loss = 1.8527
2024-10-29 12:53:07: [2024-10-29 12:53:07] iter = 10020, loss = 1.2808
2024-10-29 12:53:07: [2024-10-29 12:53:07] iter = 10030, loss = 1.6403
2024-10-29 12:53:07: [2024-10-29 12:53:07] iter = 10040, loss = 1.6199
2024-10-29 12:53:08: [2024-10-29 12:53:08] iter = 10050, loss = 1.4171
2024-10-29 12:53:08: [2024-10-29 12:53:08] iter = 10060, loss = 1.6572
2024-10-29 12:53:09: [2024-10-29 12:53:09] iter = 10070, loss = 1.9462
2024-10-29 12:53:09: [2024-10-29 12:53:09] iter = 10080, loss = 2.6915
2024-10-29 12:53:09: [2024-10-29 12:53:09] iter = 10090, loss = 1.0584
2024-10-29 12:53:10: [2024-10-29 12:53:10] iter = 10100, loss = 1.0745
2024-10-29 12:53:10: [2024-10-29 12:53:10] iter = 10110, loss = 1.6616
2024-10-29 12:53:11: [2024-10-29 12:53:11] iter = 10120, loss = 2.1786
2024-10-29 12:53:11: [2024-10-29 12:53:11] iter = 10130, loss = 3.3094
2024-10-29 12:53:11: [2024-10-29 12:53:11] iter = 10140, loss = 1.2995
2024-10-29 12:53:12: [2024-10-29 12:53:12] iter = 10150, loss = 1.3631
2024-10-29 12:53:12: [2024-10-29 12:53:12] iter = 10160, loss = 1.0134
2024-10-29 12:53:12: [2024-10-29 12:53:12] iter = 10170, loss = 1.1794
2024-10-29 12:53:13: [2024-10-29 12:53:13] iter = 10180, loss = 1.5445
2024-10-29 12:53:13: [2024-10-29 12:53:13] iter = 10190, loss = 2.5049
2024-10-29 12:53:13: [2024-10-29 12:53:13] iter = 10200, loss = 2.3465
2024-10-29 12:53:14: [2024-10-29 12:53:14] iter = 10210, loss = 1.6453
2024-10-29 12:53:14: [2024-10-29 12:53:14] iter = 10220, loss = 1.0433
2024-10-29 12:53:14: [2024-10-29 12:53:14] iter = 10230, loss = 1.6946
2024-10-29 12:53:15: [2024-10-29 12:53:15] iter = 10240, loss = 1.7337
2024-10-29 12:53:15: [2024-10-29 12:53:15] iter = 10250, loss = 1.1337
2024-10-29 12:53:15: [2024-10-29 12:53:15] iter = 10260, loss = 1.0842
2024-10-29 12:53:16: [2024-10-29 12:53:16] iter = 10270, loss = 2.9977
2024-10-29 12:53:16: [2024-10-29 12:53:16] iter = 10280, loss = 1.5243
2024-10-29 12:53:17: [2024-10-29 12:53:17] iter = 10290, loss = 1.5562
2024-10-29 12:53:17: [2024-10-29 12:53:17] iter = 10300, loss = 0.8070
2024-10-29 12:53:17: [2024-10-29 12:53:17] iter = 10310, loss = 1.5257
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 10320, loss = 1.3018
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 10330, loss = 0.7216
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 10340, loss = 2.1107
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 10350, loss = 2.0371
2024-10-29 12:53:19: [2024-10-29 12:53:19] iter = 10360, loss = 1.8387
2024-10-29 12:53:19: [2024-10-29 12:53:19] iter = 10370, loss = 0.7778
2024-10-29 12:53:20: [2024-10-29 12:53:20] iter = 10380, loss = 0.7697
2024-10-29 12:53:20: [2024-10-29 12:53:20] iter = 10390, loss = 1.4405
2024-10-29 12:53:20: [2024-10-29 12:53:20] iter = 10400, loss = 1.4444
2024-10-29 12:53:21: [2024-10-29 12:53:21] iter = 10410, loss = 0.8342
2024-10-29 12:53:21: [2024-10-29 12:53:21] iter = 10420, loss = 2.0037
2024-10-29 12:53:21: [2024-10-29 12:53:21] iter = 10430, loss = 1.3485
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 10440, loss = 0.9819
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 10450, loss = 1.7851
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 10460, loss = 1.2036
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 10470, loss = 0.8224
2024-10-29 12:53:23: [2024-10-29 12:53:23] iter = 10480, loss = 2.2788
2024-10-29 12:53:23: [2024-10-29 12:53:23] iter = 10490, loss = 1.0085
2024-10-29 12:53:24: [2024-10-29 12:53:24] iter = 10500, loss = 4.5659
2024-10-29 12:53:24: [2024-10-29 12:53:24] iter = 10510, loss = 0.9715
2024-10-29 12:53:24: [2024-10-29 12:53:24] iter = 10520, loss = 1.1291
2024-10-29 12:53:25: [2024-10-29 12:53:25] iter = 10530, loss = 1.0063
2024-10-29 12:53:25: [2024-10-29 12:53:25] iter = 10540, loss = 2.8250
2024-10-29 12:53:25: [2024-10-29 12:53:25] iter = 10550, loss = 1.2052
2024-10-29 12:53:26: [2024-10-29 12:53:26] iter = 10560, loss = 0.8111
2024-10-29 12:53:26: [2024-10-29 12:53:26] iter = 10570, loss = 1.1908
2024-10-29 12:53:26: [2024-10-29 12:53:26] iter = 10580, loss = 1.2570
2024-10-29 12:53:27: [2024-10-29 12:53:27] iter = 10590, loss = 3.3006
2024-10-29 12:53:27: [2024-10-29 12:53:27] iter = 10600, loss = 1.3547
2024-10-29 12:53:27: [2024-10-29 12:53:27] iter = 10610, loss = 0.9329
2024-10-29 12:53:28: [2024-10-29 12:53:28] iter = 10620, loss = 1.1825
2024-10-29 12:53:28: [2024-10-29 12:53:28] iter = 10630, loss = 5.5772
2024-10-29 12:53:28: [2024-10-29 12:53:28] iter = 10640, loss = 1.5737
2024-10-29 12:53:29: [2024-10-29 12:53:29] iter = 10650, loss = 1.8610
2024-10-29 12:53:29: [2024-10-29 12:53:29] iter = 10660, loss = 1.2588
2024-10-29 12:53:29: [2024-10-29 12:53:29] iter = 10670, loss = 1.6844
2024-10-29 12:53:30: [2024-10-29 12:53:30] iter = 10680, loss = 0.7974
2024-10-29 12:53:30: [2024-10-29 12:53:30] iter = 10690, loss = 1.4979
2024-10-29 12:53:30: [2024-10-29 12:53:30] iter = 10700, loss = 0.9098
2024-10-29 12:53:31: [2024-10-29 12:53:31] iter = 10710, loss = 1.2134
2024-10-29 12:53:31: [2024-10-29 12:53:31] iter = 10720, loss = 1.3832
2024-10-29 12:53:31: [2024-10-29 12:53:31] iter = 10730, loss = 1.3147
2024-10-29 12:53:32: [2024-10-29 12:53:32] iter = 10740, loss = 0.7579
2024-10-29 12:53:32: [2024-10-29 12:53:32] iter = 10750, loss = 1.7282
2024-10-29 12:53:32: [2024-10-29 12:53:32] iter = 10760, loss = 2.4442
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 10770, loss = 1.1130
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 10780, loss = 4.0692
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 10790, loss = 1.4494
2024-10-29 12:53:34: [2024-10-29 12:53:34] iter = 10800, loss = 1.5732
2024-10-29 12:53:34: [2024-10-29 12:53:34] iter = 10810, loss = 1.3807
2024-10-29 12:53:34: [2024-10-29 12:53:34] iter = 10820, loss = 1.4850
2024-10-29 12:53:35: [2024-10-29 12:53:35] iter = 10830, loss = 2.0727
2024-10-29 12:53:35: [2024-10-29 12:53:35] iter = 10840, loss = 1.4218
2024-10-29 12:53:35: [2024-10-29 12:53:35] iter = 10850, loss = 1.8206
2024-10-29 12:53:36: [2024-10-29 12:53:36] iter = 10860, loss = 2.3410
2024-10-29 12:53:36: [2024-10-29 12:53:36] iter = 10870, loss = 1.4512
2024-10-29 12:53:36: [2024-10-29 12:53:36] iter = 10880, loss = 0.7327
2024-10-29 12:53:37: [2024-10-29 12:53:37] iter = 10890, loss = 1.3350
2024-10-29 12:53:37: [2024-10-29 12:53:37] iter = 10900, loss = 1.6480
2024-10-29 12:53:37: [2024-10-29 12:53:37] iter = 10910, loss = 1.4008
2024-10-29 12:53:38: [2024-10-29 12:53:38] iter = 10920, loss = 1.9758
2024-10-29 12:53:38: [2024-10-29 12:53:38] iter = 10930, loss = 1.3866
2024-10-29 12:53:39: [2024-10-29 12:53:39] iter = 10940, loss = 1.4096
2024-10-29 12:53:39: [2024-10-29 12:53:39] iter = 10950, loss = 1.2435
2024-10-29 12:53:39: [2024-10-29 12:53:39] iter = 10960, loss = 1.1674
2024-10-29 12:53:40: [2024-10-29 12:53:40] iter = 10970, loss = 1.4111
2024-10-29 12:53:40: [2024-10-29 12:53:40] iter = 10980, loss = 0.9121
2024-10-29 12:53:41: [2024-10-29 12:53:41] iter = 10990, loss = 2.4042
2024-10-29 12:53:42: [2024-10-29 12:53:42] iter = 11000, loss = 1.1122
2024-10-29 12:53:42: [2024-10-29 12:53:42] iter = 11010, loss = 2.7601
2024-10-29 12:53:43: [2024-10-29 12:53:43] iter = 11020, loss = 5.0283
2024-10-29 12:53:43: [2024-10-29 12:53:43] iter = 11030, loss = 1.5784
2024-10-29 12:53:44: [2024-10-29 12:53:44] iter = 11040, loss = 1.0636
2024-10-29 12:53:44: [2024-10-29 12:53:44] iter = 11050, loss = 1.1726
2024-10-29 12:53:44: [2024-10-29 12:53:44] iter = 11060, loss = 1.3722
2024-10-29 12:53:45: [2024-10-29 12:53:45] iter = 11070, loss = 1.8444
2024-10-29 12:53:45: [2024-10-29 12:53:45] iter = 11080, loss = 1.5439
2024-10-29 12:53:46: [2024-10-29 12:53:46] iter = 11090, loss = 1.2058
2024-10-29 12:53:46: [2024-10-29 12:53:46] iter = 11100, loss = 1.4864
2024-10-29 12:53:47: [2024-10-29 12:53:47] iter = 11110, loss = 1.2271
2024-10-29 12:53:47: [2024-10-29 12:53:47] iter = 11120, loss = 1.2830
2024-10-29 12:53:47: [2024-10-29 12:53:47] iter = 11130, loss = 4.2739
2024-10-29 12:53:48: [2024-10-29 12:53:48] iter = 11140, loss = 1.0865
2024-10-29 12:53:48: [2024-10-29 12:53:48] iter = 11150, loss = 2.0992
2024-10-29 12:53:48: [2024-10-29 12:53:48] iter = 11160, loss = 1.2356
2024-10-29 12:53:49: [2024-10-29 12:53:49] iter = 11170, loss = 1.7952
2024-10-29 12:53:49: [2024-10-29 12:53:49] iter = 11180, loss = 1.4663
2024-10-29 12:53:49: [2024-10-29 12:53:49] iter = 11190, loss = 6.5712
2024-10-29 12:53:50: [2024-10-29 12:53:50] iter = 11200, loss = 1.3537
2024-10-29 12:53:50: [2024-10-29 12:53:50] iter = 11210, loss = 0.8176
2024-10-29 12:53:50: [2024-10-29 12:53:50] iter = 11220, loss = 2.5702
2024-10-29 12:53:51: [2024-10-29 12:53:51] iter = 11230, loss = 2.6435
2024-10-29 12:53:51: [2024-10-29 12:53:51] iter = 11240, loss = 1.2697
2024-10-29 12:53:52: [2024-10-29 12:53:52] iter = 11250, loss = 0.9724
2024-10-29 12:53:52: [2024-10-29 12:53:52] iter = 11260, loss = 1.5556
2024-10-29 12:53:52: [2024-10-29 12:53:52] iter = 11270, loss = 6.2104
2024-10-29 12:53:53: [2024-10-29 12:53:53] iter = 11280, loss = 1.6098
2024-10-29 12:53:53: [2024-10-29 12:53:53] iter = 11290, loss = 0.8525
2024-10-29 12:53:54: [2024-10-29 12:53:54] iter = 11300, loss = 1.0640
2024-10-29 12:53:54: [2024-10-29 12:53:54] iter = 11310, loss = 1.6520
2024-10-29 12:53:54: [2024-10-29 12:53:54] iter = 11320, loss = 1.3607
2024-10-29 12:53:55: [2024-10-29 12:53:55] iter = 11330, loss = 1.1108
2024-10-29 12:53:55: [2024-10-29 12:53:55] iter = 11340, loss = 1.2819
2024-10-29 12:53:55: [2024-10-29 12:53:55] iter = 11350, loss = 1.9378
2024-10-29 12:53:56: [2024-10-29 12:53:56] iter = 11360, loss = 2.7007
2024-10-29 12:53:56: [2024-10-29 12:53:56] iter = 11370, loss = 1.6604
2024-10-29 12:53:56: [2024-10-29 12:53:56] iter = 11380, loss = 1.3320
2024-10-29 12:53:57: [2024-10-29 12:53:57] iter = 11390, loss = 1.6310
2024-10-29 12:53:57: [2024-10-29 12:53:57] iter = 11400, loss = 1.2025
2024-10-29 12:53:57: [2024-10-29 12:53:57] iter = 11410, loss = 1.2385
2024-10-29 12:53:58: [2024-10-29 12:53:58] iter = 11420, loss = 1.3346
2024-10-29 12:53:58: [2024-10-29 12:53:58] iter = 11430, loss = 1.4210
2024-10-29 12:53:58: [2024-10-29 12:53:58] iter = 11440, loss = 1.4662
2024-10-29 12:53:59: [2024-10-29 12:53:59] iter = 11450, loss = 10.8875
2024-10-29 12:53:59: [2024-10-29 12:53:59] iter = 11460, loss = 0.7057
2024-10-29 12:53:59: [2024-10-29 12:53:59] iter = 11470, loss = 1.3042
2024-10-29 12:54:00: [2024-10-29 12:54:00] iter = 11480, loss = 2.3251
2024-10-29 12:54:00: [2024-10-29 12:54:00] iter = 11490, loss = 1.1207
2024-10-29 12:54:00: [2024-10-29 12:54:00] iter = 11500, loss = 1.9416
2024-10-29 12:54:01: [2024-10-29 12:54:01] iter = 11510, loss = 3.2915
2024-10-29 12:54:01: [2024-10-29 12:54:01] iter = 11520, loss = 3.0195
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 11530, loss = 1.6337
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 11540, loss = 1.6099
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 11550, loss = 1.0863
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 11560, loss = 9.6827
2024-10-29 12:54:03: [2024-10-29 12:54:03] iter = 11570, loss = 2.2230
2024-10-29 12:54:03: [2024-10-29 12:54:03] iter = 11580, loss = 1.2440
2024-10-29 12:54:03: [2024-10-29 12:54:03] iter = 11590, loss = 1.3310
2024-10-29 12:54:04: [2024-10-29 12:54:04] iter = 11600, loss = 1.3464
2024-10-29 12:54:04: [2024-10-29 12:54:04] iter = 11610, loss = 0.9528
2024-10-29 12:54:05: [2024-10-29 12:54:05] iter = 11620, loss = 1.5010
2024-10-29 12:54:05: [2024-10-29 12:54:05] iter = 11630, loss = 0.7598
2024-10-29 12:54:05: [2024-10-29 12:54:05] iter = 11640, loss = 1.6009
2024-10-29 12:54:06: [2024-10-29 12:54:06] iter = 11650, loss = 1.2476
2024-10-29 12:54:06: [2024-10-29 12:54:06] iter = 11660, loss = 2.8540
2024-10-29 12:54:06: [2024-10-29 12:54:06] iter = 11670, loss = 1.6589
2024-10-29 12:54:06: [2024-10-29 12:54:06] iter = 11680, loss = 1.0138
2024-10-29 12:54:07: [2024-10-29 12:54:07] iter = 11690, loss = 1.0111
2024-10-29 12:54:07: [2024-10-29 12:54:07] iter = 11700, loss = 1.1557
2024-10-29 12:54:07: [2024-10-29 12:54:07] iter = 11710, loss = 6.5001
2024-10-29 12:54:08: [2024-10-29 12:54:08] iter = 11720, loss = 2.2652
2024-10-29 12:54:08: [2024-10-29 12:54:08] iter = 11730, loss = 4.9296
2024-10-29 12:54:08: [2024-10-29 12:54:08] iter = 11740, loss = 3.7226
2024-10-29 12:54:09: [2024-10-29 12:54:09] iter = 11750, loss = 2.0796
2024-10-29 12:54:09: [2024-10-29 12:54:09] iter = 11760, loss = 1.3195
2024-10-29 12:54:09: [2024-10-29 12:54:09] iter = 11770, loss = 0.8632
2024-10-29 12:54:10: [2024-10-29 12:54:10] iter = 11780, loss = 6.4991
2024-10-29 12:54:10: [2024-10-29 12:54:10] iter = 11790, loss = 1.6835
2024-10-29 12:54:10: [2024-10-29 12:54:10] iter = 11800, loss = 1.4051
2024-10-29 12:54:11: [2024-10-29 12:54:11] iter = 11810, loss = 1.5204
2024-10-29 12:54:11: [2024-10-29 12:54:11] iter = 11820, loss = 0.9758
2024-10-29 12:54:11: [2024-10-29 12:54:11] iter = 11830, loss = 1.8948
2024-10-29 12:54:12: [2024-10-29 12:54:12] iter = 11840, loss = 1.5698
2024-10-29 12:54:12: [2024-10-29 12:54:12] iter = 11850, loss = 1.4098
2024-10-29 12:54:12: [2024-10-29 12:54:12] iter = 11860, loss = 1.3789
2024-10-29 12:54:13: [2024-10-29 12:54:13] iter = 11870, loss = 1.3061
2024-10-29 12:54:13: [2024-10-29 12:54:13] iter = 11880, loss = 1.3830
2024-10-29 12:54:13: [2024-10-29 12:54:13] iter = 11890, loss = 0.9804
2024-10-29 12:54:14: [2024-10-29 12:54:14] iter = 11900, loss = 0.9431
2024-10-29 12:54:14: [2024-10-29 12:54:14] iter = 11910, loss = 1.1515
2024-10-29 12:54:14: [2024-10-29 12:54:14] iter = 11920, loss = 2.2313
2024-10-29 12:54:15: [2024-10-29 12:54:15] iter = 11930, loss = 3.1165
2024-10-29 12:54:15: [2024-10-29 12:54:15] iter = 11940, loss = 1.6407
2024-10-29 12:54:15: [2024-10-29 12:54:15] iter = 11950, loss = 1.2682
2024-10-29 12:54:16: [2024-10-29 12:54:16] iter = 11960, loss = 2.4455
2024-10-29 12:54:16: [2024-10-29 12:54:16] iter = 11970, loss = 1.6661
2024-10-29 12:54:16: [2024-10-29 12:54:16] iter = 11980, loss = 1.2145
2024-10-29 12:54:17: [2024-10-29 12:54:17] iter = 11990, loss = 1.5567
2024-10-29 12:54:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 12:54:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:54:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57590}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:54:46: Evaluate 5 random ConvNet, ACCmean = 0.5280 ACCstd = 0.0111
-------------------------
2024-10-29 12:54:46: Evaluate 5 random ConvNet, SENmean = 0.6291 SENstd = 0.0023
-------------------------
2024-10-29 12:54:46: Evaluate 5 random ConvNet, SPEmean = 0.6291 SPEstd = 0.0023
-------------------------
2024-10-29 12:54:46: Evaluate 5 random ConvNet, F!mean = 0.4557 F!std = 0.0065
-------------------------
2024-10-29 12:54:46: Evaluate 5 random ConvNet, mean = 0.5280 std = 0.0111
-------------------------
2024-10-29 12:54:46: [2024-10-29 12:54:46] iter = 12000, loss = 1.5236
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:54:46: [2024-10-29 12:54:46] iter = 12010, loss = 1.0407
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 12020, loss = 0.7330
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 12030, loss = 1.7179
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 12040, loss = 1.4662
2024-10-29 12:54:48: [2024-10-29 12:54:48] iter = 12050, loss = 1.9028
2024-10-29 12:54:48: [2024-10-29 12:54:48] iter = 12060, loss = 1.6568
2024-10-29 12:54:48: [2024-10-29 12:54:48] iter = 12070, loss = 2.7761
2024-10-29 12:54:49: [2024-10-29 12:54:49] iter = 12080, loss = 1.1309
2024-10-29 12:54:49: [2024-10-29 12:54:49] iter = 12090, loss = 1.0613
2024-10-29 12:54:50: [2024-10-29 12:54:50] iter = 12100, loss = 1.0439
2024-10-29 12:54:50: [2024-10-29 12:54:50] iter = 12110, loss = 9.6504
2024-10-29 12:54:50: [2024-10-29 12:54:50] iter = 12120, loss = 2.4943
2024-10-29 12:54:51: [2024-10-29 12:54:51] iter = 12130, loss = 1.5801
2024-10-29 12:54:51: [2024-10-29 12:54:51] iter = 12140, loss = 1.2332
2024-10-29 12:54:51: [2024-10-29 12:54:51] iter = 12150, loss = 1.0133
2024-10-29 12:54:52: [2024-10-29 12:54:52] iter = 12160, loss = 1.4262
2024-10-29 12:54:52: [2024-10-29 12:54:52] iter = 12170, loss = 1.0854
2024-10-29 12:54:53: [2024-10-29 12:54:53] iter = 12180, loss = 1.5098
2024-10-29 12:54:53: [2024-10-29 12:54:53] iter = 12190, loss = 1.2415
2024-10-29 12:54:53: [2024-10-29 12:54:53] iter = 12200, loss = 0.9574
2024-10-29 12:54:54: [2024-10-29 12:54:54] iter = 12210, loss = 2.7880
2024-10-29 12:54:54: [2024-10-29 12:54:54] iter = 12220, loss = 1.6872
2024-10-29 12:54:54: [2024-10-29 12:54:54] iter = 12230, loss = 0.8986
2024-10-29 12:54:55: [2024-10-29 12:54:55] iter = 12240, loss = 1.0904
2024-10-29 12:54:55: [2024-10-29 12:54:55] iter = 12250, loss = 2.7090
2024-10-29 12:54:56: [2024-10-29 12:54:56] iter = 12260, loss = 1.6143
2024-10-29 12:54:56: [2024-10-29 12:54:56] iter = 12270, loss = 2.7254
2024-10-29 12:54:57: [2024-10-29 12:54:57] iter = 12280, loss = 1.3820
2024-10-29 12:54:58: [2024-10-29 12:54:58] iter = 12290, loss = 1.3313
2024-10-29 12:54:58: [2024-10-29 12:54:58] iter = 12300, loss = 2.1293
2024-10-29 12:54:59: [2024-10-29 12:54:59] iter = 12310, loss = 1.3860
2024-10-29 12:54:59: [2024-10-29 12:54:59] iter = 12320, loss = 0.9493
2024-10-29 12:55:00: [2024-10-29 12:55:00] iter = 12330, loss = 1.7258
2024-10-29 12:55:00: [2024-10-29 12:55:00] iter = 12340, loss = 0.8843
2024-10-29 12:55:01: [2024-10-29 12:55:01] iter = 12350, loss = 2.2711
2024-10-29 12:55:01: [2024-10-29 12:55:01] iter = 12360, loss = 1.1258
2024-10-29 12:55:01: [2024-10-29 12:55:01] iter = 12370, loss = 1.3541
2024-10-29 12:55:02: [2024-10-29 12:55:02] iter = 12380, loss = 1.4395
2024-10-29 12:55:02: [2024-10-29 12:55:02] iter = 12390, loss = 2.8373
2024-10-29 12:55:03: [2024-10-29 12:55:03] iter = 12400, loss = 1.3430
2024-10-29 12:55:03: [2024-10-29 12:55:03] iter = 12410, loss = 1.2364
2024-10-29 12:55:03: [2024-10-29 12:55:03] iter = 12420, loss = 1.3866
2024-10-29 12:55:04: [2024-10-29 12:55:04] iter = 12430, loss = 1.1968
2024-10-29 12:55:04: [2024-10-29 12:55:04] iter = 12440, loss = 1.6540
2024-10-29 12:55:05: [2024-10-29 12:55:05] iter = 12450, loss = 1.3234
2024-10-29 12:55:05: [2024-10-29 12:55:05] iter = 12460, loss = 0.9643
2024-10-29 12:55:06: [2024-10-29 12:55:06] iter = 12470, loss = 1.5463
2024-10-29 12:55:06: [2024-10-29 12:55:06] iter = 12480, loss = 1.1207
2024-10-29 12:55:06: [2024-10-29 12:55:06] iter = 12490, loss = 1.0983
2024-10-29 12:55:07: [2024-10-29 12:55:07] iter = 12500, loss = 1.3768
2024-10-29 12:55:07: [2024-10-29 12:55:07] iter = 12510, loss = 1.2461
2024-10-29 12:55:07: [2024-10-29 12:55:07] iter = 12520, loss = 3.5915
2024-10-29 12:55:08: [2024-10-29 12:55:08] iter = 12530, loss = 1.3462
2024-10-29 12:55:08: [2024-10-29 12:55:08] iter = 12540, loss = 3.6880
2024-10-29 12:55:08: [2024-10-29 12:55:08] iter = 12550, loss = 0.8905
2024-10-29 12:55:09: [2024-10-29 12:55:09] iter = 12560, loss = 1.3696
2024-10-29 12:55:09: [2024-10-29 12:55:09] iter = 12570, loss = 1.3492
2024-10-29 12:55:10: [2024-10-29 12:55:10] iter = 12580, loss = 4.1498
2024-10-29 12:55:10: [2024-10-29 12:55:10] iter = 12590, loss = 1.5679
2024-10-29 12:55:10: [2024-10-29 12:55:10] iter = 12600, loss = 0.8314
2024-10-29 12:55:11: [2024-10-29 12:55:11] iter = 12610, loss = 1.5678
2024-10-29 12:55:11: [2024-10-29 12:55:11] iter = 12620, loss = 1.2281
2024-10-29 12:55:12: [2024-10-29 12:55:12] iter = 12630, loss = 1.1817
2024-10-29 12:55:12: [2024-10-29 12:55:12] iter = 12640, loss = 1.2018
2024-10-29 12:55:12: [2024-10-29 12:55:12] iter = 12650, loss = 1.2361
2024-10-29 12:55:13: [2024-10-29 12:55:13] iter = 12660, loss = 0.8619
2024-10-29 12:55:14: [2024-10-29 12:55:14] iter = 12670, loss = 0.9420
2024-10-29 12:55:14: [2024-10-29 12:55:14] iter = 12680, loss = 0.8141
2024-10-29 12:55:15: [2024-10-29 12:55:15] iter = 12690, loss = 0.7994
2024-10-29 12:55:15: [2024-10-29 12:55:15] iter = 12700, loss = 1.3294
2024-10-29 12:55:15: [2024-10-29 12:55:15] iter = 12710, loss = 2.8035
2024-10-29 12:55:16: [2024-10-29 12:55:16] iter = 12720, loss = 1.7209
2024-10-29 12:55:16: [2024-10-29 12:55:16] iter = 12730, loss = 1.3860
2024-10-29 12:55:17: [2024-10-29 12:55:17] iter = 12740, loss = 1.2060
2024-10-29 12:55:17: [2024-10-29 12:55:17] iter = 12750, loss = 0.7423
2024-10-29 12:55:17: [2024-10-29 12:55:17] iter = 12760, loss = 1.3734
2024-10-29 12:55:18: [2024-10-29 12:55:18] iter = 12770, loss = 7.4298
2024-10-29 12:55:18: [2024-10-29 12:55:18] iter = 12780, loss = 1.0487
2024-10-29 12:55:18: [2024-10-29 12:55:18] iter = 12790, loss = 1.3614
2024-10-29 12:55:19: [2024-10-29 12:55:19] iter = 12800, loss = 4.5545
2024-10-29 12:55:19: [2024-10-29 12:55:19] iter = 12810, loss = 2.1042
2024-10-29 12:55:19: [2024-10-29 12:55:19] iter = 12820, loss = 1.4217
2024-10-29 12:55:20: [2024-10-29 12:55:20] iter = 12830, loss = 1.7951
2024-10-29 12:55:20: [2024-10-29 12:55:20] iter = 12840, loss = 1.2569
2024-10-29 12:55:20: [2024-10-29 12:55:20] iter = 12850, loss = 1.0999
2024-10-29 12:55:21: [2024-10-29 12:55:21] iter = 12860, loss = 2.3509
2024-10-29 12:55:21: [2024-10-29 12:55:21] iter = 12870, loss = 1.6016
2024-10-29 12:55:21: [2024-10-29 12:55:21] iter = 12880, loss = 1.1193
2024-10-29 12:55:22: [2024-10-29 12:55:22] iter = 12890, loss = 1.3284
2024-10-29 12:55:22: [2024-10-29 12:55:22] iter = 12900, loss = 0.9887
2024-10-29 12:55:22: [2024-10-29 12:55:22] iter = 12910, loss = 1.1984
2024-10-29 12:55:23: [2024-10-29 12:55:23] iter = 12920, loss = 1.6019
2024-10-29 12:55:23: [2024-10-29 12:55:23] iter = 12930, loss = 1.0862
2024-10-29 12:55:23: [2024-10-29 12:55:23] iter = 12940, loss = 1.0238
2024-10-29 12:55:24: [2024-10-29 12:55:24] iter = 12950, loss = 1.7190
2024-10-29 12:55:24: [2024-10-29 12:55:24] iter = 12960, loss = 3.6712
2024-10-29 12:55:24: [2024-10-29 12:55:24] iter = 12970, loss = 1.1574
2024-10-29 12:55:25: [2024-10-29 12:55:25] iter = 12980, loss = 2.9442
2024-10-29 12:55:25: [2024-10-29 12:55:25] iter = 12990, loss = 1.5649
2024-10-29 12:55:25: [2024-10-29 12:55:25] iter = 13000, loss = 1.8374
2024-10-29 12:55:26: [2024-10-29 12:55:26] iter = 13010, loss = 1.0188
2024-10-29 12:55:26: [2024-10-29 12:55:26] iter = 13020, loss = 1.2749
2024-10-29 12:55:26: [2024-10-29 12:55:26] iter = 13030, loss = 0.9821
2024-10-29 12:55:27: [2024-10-29 12:55:27] iter = 13040, loss = 1.1956
2024-10-29 12:55:27: [2024-10-29 12:55:27] iter = 13050, loss = 1.2841
2024-10-29 12:55:27: [2024-10-29 12:55:27] iter = 13060, loss = 0.8865
2024-10-29 12:55:28: [2024-10-29 12:55:28] iter = 13070, loss = 0.9704
2024-10-29 12:55:28: [2024-10-29 12:55:28] iter = 13080, loss = 1.3100
2024-10-29 12:55:28: [2024-10-29 12:55:28] iter = 13090, loss = 0.7400
2024-10-29 12:55:29: [2024-10-29 12:55:29] iter = 13100, loss = 7.5328
2024-10-29 12:55:29: [2024-10-29 12:55:29] iter = 13110, loss = 1.0364
2024-10-29 12:55:29: [2024-10-29 12:55:29] iter = 13120, loss = 0.9529
2024-10-29 12:55:30: [2024-10-29 12:55:30] iter = 13130, loss = 1.0901
2024-10-29 12:55:30: [2024-10-29 12:55:30] iter = 13140, loss = 0.8244
2024-10-29 12:55:30: [2024-10-29 12:55:30] iter = 13150, loss = 0.8457
2024-10-29 12:55:31: [2024-10-29 12:55:31] iter = 13160, loss = 1.4413
2024-10-29 12:55:31: [2024-10-29 12:55:31] iter = 13170, loss = 0.9514
2024-10-29 12:55:31: [2024-10-29 12:55:31] iter = 13180, loss = 1.4467
2024-10-29 12:55:32: [2024-10-29 12:55:32] iter = 13190, loss = 1.5879
2024-10-29 12:55:32: [2024-10-29 12:55:32] iter = 13200, loss = 1.0146
2024-10-29 12:55:32: [2024-10-29 12:55:32] iter = 13210, loss = 0.9715
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 13220, loss = 6.3394
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 13230, loss = 1.2272
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 13240, loss = 3.8388
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 13250, loss = 1.4617
2024-10-29 12:55:34: [2024-10-29 12:55:34] iter = 13260, loss = 1.5907
2024-10-29 12:55:34: [2024-10-29 12:55:34] iter = 13270, loss = 1.0936
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 13280, loss = 1.0160
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 13290, loss = 0.8897
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 13300, loss = 1.2274
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 13310, loss = 1.7033
2024-10-29 12:55:36: [2024-10-29 12:55:36] iter = 13320, loss = 1.2449
2024-10-29 12:55:36: [2024-10-29 12:55:36] iter = 13330, loss = 2.2565
2024-10-29 12:55:36: [2024-10-29 12:55:36] iter = 13340, loss = 3.1950
2024-10-29 12:55:37: [2024-10-29 12:55:37] iter = 13350, loss = 2.4804
2024-10-29 12:55:37: [2024-10-29 12:55:37] iter = 13360, loss = 0.8328
2024-10-29 12:55:38: [2024-10-29 12:55:38] iter = 13370, loss = 1.0979
2024-10-29 12:55:38: [2024-10-29 12:55:38] iter = 13380, loss = 1.0866
2024-10-29 12:55:38: [2024-10-29 12:55:38] iter = 13390, loss = 2.2243
2024-10-29 12:55:39: [2024-10-29 12:55:39] iter = 13400, loss = 1.4022
2024-10-29 12:55:39: [2024-10-29 12:55:39] iter = 13410, loss = 1.1830
2024-10-29 12:55:39: [2024-10-29 12:55:39] iter = 13420, loss = 1.1845
2024-10-29 12:55:40: [2024-10-29 12:55:40] iter = 13430, loss = 1.1964
2024-10-29 12:55:40: [2024-10-29 12:55:40] iter = 13440, loss = 1.3425
2024-10-29 12:55:40: [2024-10-29 12:55:40] iter = 13450, loss = 1.2004
2024-10-29 12:55:41: [2024-10-29 12:55:41] iter = 13460, loss = 0.9151
2024-10-29 12:55:41: [2024-10-29 12:55:41] iter = 13470, loss = 10.5165
2024-10-29 12:55:41: [2024-10-29 12:55:41] iter = 13480, loss = 1.6562
2024-10-29 12:55:42: [2024-10-29 12:55:42] iter = 13490, loss = 1.1923
2024-10-29 12:55:42: [2024-10-29 12:55:42] iter = 13500, loss = 2.1517
2024-10-29 12:55:42: [2024-10-29 12:55:42] iter = 13510, loss = 1.6562
2024-10-29 12:55:43: [2024-10-29 12:55:43] iter = 13520, loss = 1.9316
2024-10-29 12:55:43: [2024-10-29 12:55:43] iter = 13530, loss = 1.3852
2024-10-29 12:55:43: [2024-10-29 12:55:43] iter = 13540, loss = 2.0854
2024-10-29 12:55:44: [2024-10-29 12:55:44] iter = 13550, loss = 1.2060
2024-10-29 12:55:44: [2024-10-29 12:55:44] iter = 13560, loss = 2.3037
2024-10-29 12:55:44: [2024-10-29 12:55:44] iter = 13570, loss = 1.5465
2024-10-29 12:55:45: [2024-10-29 12:55:45] iter = 13580, loss = 2.7232
2024-10-29 12:55:45: [2024-10-29 12:55:45] iter = 13590, loss = 1.5938
2024-10-29 12:55:45: [2024-10-29 12:55:45] iter = 13600, loss = 1.3766
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 13610, loss = 1.6299
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 13620, loss = 1.8967
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 13630, loss = 1.7442
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 13640, loss = 2.4915
2024-10-29 12:55:47: [2024-10-29 12:55:47] iter = 13650, loss = 1.1984
2024-10-29 12:55:47: [2024-10-29 12:55:47] iter = 13660, loss = 1.8908
2024-10-29 12:55:47: [2024-10-29 12:55:47] iter = 13670, loss = 4.1531
2024-10-29 12:55:48: [2024-10-29 12:55:48] iter = 13680, loss = 1.7159
2024-10-29 12:55:48: [2024-10-29 12:55:48] iter = 13690, loss = 2.9423
2024-10-29 12:55:48: [2024-10-29 12:55:48] iter = 13700, loss = 1.5786
2024-10-29 12:55:49: [2024-10-29 12:55:49] iter = 13710, loss = 1.1874
2024-10-29 12:55:49: [2024-10-29 12:55:49] iter = 13720, loss = 1.7342
2024-10-29 12:55:49: [2024-10-29 12:55:49] iter = 13730, loss = 0.8011
2024-10-29 12:55:50: [2024-10-29 12:55:50] iter = 13740, loss = 1.5597
2024-10-29 12:55:50: [2024-10-29 12:55:50] iter = 13750, loss = 1.3425
2024-10-29 12:55:51: [2024-10-29 12:55:51] iter = 13760, loss = 3.5410
2024-10-29 12:55:51: [2024-10-29 12:55:51] iter = 13770, loss = 1.3359
2024-10-29 12:55:51: [2024-10-29 12:55:51] iter = 13780, loss = 1.2370
2024-10-29 12:55:52: [2024-10-29 12:55:52] iter = 13790, loss = 1.1270
2024-10-29 12:55:52: [2024-10-29 12:55:52] iter = 13800, loss = 1.6186
2024-10-29 12:55:52: [2024-10-29 12:55:52] iter = 13810, loss = 1.2546
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 13820, loss = 1.5383
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 13830, loss = 1.0656
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 13840, loss = 1.6131
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 13850, loss = 1.0355
2024-10-29 12:55:54: [2024-10-29 12:55:54] iter = 13860, loss = 1.1606
2024-10-29 12:55:54: [2024-10-29 12:55:54] iter = 13870, loss = 3.1986
2024-10-29 12:55:54: [2024-10-29 12:55:54] iter = 13880, loss = 1.2710
2024-10-29 12:55:55: [2024-10-29 12:55:55] iter = 13890, loss = 1.3424
2024-10-29 12:55:55: [2024-10-29 12:55:55] iter = 13900, loss = 2.2589
2024-10-29 12:55:55: [2024-10-29 12:55:55] iter = 13910, loss = 1.6348
2024-10-29 12:55:56: [2024-10-29 12:55:56] iter = 13920, loss = 1.2327
2024-10-29 12:55:56: [2024-10-29 12:55:56] iter = 13930, loss = 1.3128
2024-10-29 12:55:57: [2024-10-29 12:55:57] iter = 13940, loss = 1.7149
2024-10-29 12:55:57: [2024-10-29 12:55:57] iter = 13950, loss = 1.1961
2024-10-29 12:55:57: [2024-10-29 12:55:57] iter = 13960, loss = 1.3289
2024-10-29 12:55:58: [2024-10-29 12:55:58] iter = 13970, loss = 1.3793
2024-10-29 12:55:58: [2024-10-29 12:55:58] iter = 13980, loss = 1.1056
2024-10-29 12:55:59: [2024-10-29 12:55:59] iter = 13990, loss = 2.7136
2024-10-29 12:55:59: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 12:55:59: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:55:59: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59643}

[2024-10-29 12:41:56] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.009210 train acc = 1.0000, test acc = 0.6384, test_sen =0.6150, test_spe =0.6150, test_f1 =0.5098
[2024-10-29 12:42:02] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.093843 train acc = 1.0000, test acc = 0.6317, test_sen =0.6128, test_spe =0.6128, test_f1 =0.5058
[2024-10-29 12:42:09] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.008862 train acc = 1.0000, test acc = 0.6395, test_sen =0.6098, test_spe =0.6098, test_f1 =0.5086
[2024-10-29 12:42:14] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.008263 train acc = 1.0000, test acc = 0.6350, test_sen =0.6140, test_spe =0.6140, test_f1 =0.5078
[2024-10-29 12:42:20] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.038047 train acc = 1.0000, test acc = 0.6489, test_sen =0.6205, test_spe =0.6205, test_f1 =0.5168
[2024-10-29 12:43:40] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.100450 train acc = 0.9500, test acc = 0.6236, test_sen =0.6031, test_spe =0.6031, test_f1 =0.4987
[2024-10-29 12:43:46] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.005617 train acc = 1.0000, test acc = 0.6323, test_sen =0.5990, test_spe =0.5990, test_f1 =0.5015
[2024-10-29 12:43:52] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.006558 train acc = 1.0000, test acc = 0.6147, test_sen =0.5981, test_spe =0.5981, test_f1 =0.4928
[2024-10-29 12:43:58] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.103240 train acc = 0.9500, test acc = 0.6344, test_sen =0.5997, test_spe =0.5997, test_f1 =0.5027
[2024-10-29 12:44:04] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.003879 train acc = 1.0000, test acc = 0.6518, test_sen =0.5992, test_spe =0.5992, test_f1 =0.5107
[2024-10-29 12:44:12] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.046261 train acc = 1.0000, test acc = 0.5652, test_sen =0.5400, test_spe =0.5400, test_f1 =0.4513
[2024-10-29 12:44:18] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.001740 train acc = 1.0000, test acc = 0.6016, test_sen =0.5379, test_spe =0.5379, test_f1 =0.4666
[2024-10-29 12:44:23] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.005105 train acc = 1.0000, test acc = 0.6110, test_sen =0.5413, test_spe =0.5413, test_f1 =0.4718
[2024-10-29 12:44:30] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.003932 train acc = 1.0000, test acc = 0.6017, test_sen =0.5294, test_spe =0.5294, test_f1 =0.4636
[2024-10-29 12:44:37] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.002415 train acc = 1.0000, test acc = 0.6278, test_sen =0.5467, test_spe =0.5467, test_f1 =0.4808
[2024-10-29 12:45:54] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.009926 train acc = 1.0000, test acc = 0.5775, test_sen =0.6190, test_spe =0.6190, test_f1 =0.4802
[2024-10-29 12:46:02] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.002614 train acc = 1.0000, test acc = 0.6240, test_sen =0.6184, test_spe =0.6184, test_f1 =0.5038
[2024-10-29 12:46:08] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.008617 train acc = 1.0000, test acc = 0.6564, test_sen =0.6161, test_spe =0.6161, test_f1 =0.5189
[2024-10-29 12:46:14] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.024200 train acc = 1.0000, test acc = 0.6486, test_sen =0.6183, test_spe =0.6183, test_f1 =0.5159
[2024-10-29 12:46:20] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.005923 train acc = 1.0000, test acc = 0.6020, test_sen =0.6227, test_spe =0.6227, test_f1 =0.4940
[2024-10-29 12:47:39] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.001124 train acc = 1.0000, test acc = 0.6756, test_sen =0.5881, test_spe =0.5881, test_f1 =0.5172
[2024-10-29 12:47:44] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.003738 train acc = 1.0000, test acc = 0.6805, test_sen =0.5975, test_spe =0.5975, test_f1 =0.5232
[2024-10-29 12:47:50] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000862 train acc = 1.0000, test acc = 0.6830, test_sen =0.5889, test_spe =0.5889, test_f1 =0.5208
[2024-10-29 12:47:56] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.007094 train acc = 1.0000, test acc = 0.6730, test_sen =0.5872, test_spe =0.5872, test_f1 =0.5157
[2024-10-29 12:48:02] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.004303 train acc = 1.0000, test acc = 0.6968, test_sen =0.5885, test_spe =0.5885, test_f1 =0.5266
[2024-10-29 12:49:21] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001992 train acc = 1.0000, test acc = 0.5935, test_sen =0.6291, test_spe =0.6291, test_f1 =0.4915
[2024-10-29 12:49:27] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.004815 train acc = 1.0000, test acc = 0.6170, test_sen =0.6188, test_spe =0.6188, test_f1 =0.5005
[2024-10-29 12:49:33] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.114221 train acc = 1.0000, test acc = 0.5996, test_sen =0.6295, test_spe =0.6295, test_f1 =0.4947
[2024-10-29 12:49:39] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.095157 train acc = 1.0000, test acc = 0.6173, test_sen =0.6308, test_spe =0.6308, test_f1 =0.5043
[2024-10-29 12:49:44] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002020 train acc = 1.0000, test acc = 0.5834, test_sen =0.6216, test_spe =0.6216, test_f1 =0.4840
[2024-10-29 12:51:03] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.005709 train acc = 1.0000, test acc = 0.4860, test_sen =0.5670, test_spe =0.5670, test_f1 =0.4182
[2024-10-29 12:51:09] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.020350 train acc = 1.0000, test acc = 0.4817, test_sen =0.5720, test_spe =0.5720, test_f1 =0.4169
[2024-10-29 12:51:14] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003496 train acc = 1.0000, test acc = 0.4194, test_sen =0.5595, test_spe =0.5595, test_f1 =0.3773
[2024-10-29 12:51:20] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002218 train acc = 1.0000, test acc = 0.4643, test_sen =0.5628, test_spe =0.5628, test_f1 =0.4049
[2024-10-29 12:51:26] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001877 train acc = 1.0000, test acc = 0.5008, test_sen =0.5749, test_spe =0.5749, test_f1 =0.4282
[2024-10-29 12:52:43] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.035532 train acc = 1.0000, test acc = 0.6315, test_sen =0.6159, test_spe =0.6159, test_f1 =0.5067
[2024-10-29 12:52:48] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.003041 train acc = 1.0000, test acc = 0.6629, test_sen =0.6089, test_spe =0.6089, test_f1 =0.5194
[2024-10-29 12:52:54] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.004138 train acc = 1.0000, test acc = 0.6757, test_sen =0.6096, test_spe =0.6096, test_f1 =0.5257
[2024-10-29 12:53:01] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.004187 train acc = 1.0000, test acc = 0.6650, test_sen =0.6188, test_spe =0.6188, test_f1 =0.5240
[2024-10-29 12:53:06] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.005062 train acc = 1.0000, test acc = 0.6562, test_sen =0.6217, test_spe =0.6217, test_f1 =0.5208
[2024-10-29 12:54:23] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000756 train acc = 1.0000, test acc = 0.5441, test_sen =0.6280, test_spe =0.6280, test_f1 =0.4645
[2024-10-29 12:54:30] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002447 train acc = 1.0000, test acc = 0.5377, test_sen =0.6327, test_spe =0.6327, test_f1 =0.4620
[2024-10-29 12:54:35] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.005211 train acc = 1.0000, test acc = 0.5243, test_sen =0.6293, test_spe =0.6293, test_f1 =0.4536
[2024-10-29 12:54:41] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.013131 train acc = 1.0000, test acc = 0.5171, test_sen =0.6256, test_spe =0.6256, test_f1 =0.4487
[2024-10-29 12:54:46] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002757 train acc = 1.0000, test acc = 0.5168, test_sen =0.6300, test_spe =0.6300, test_f1 =0.4495
[2024-10-29 12:56:06] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000868 train acc = 1.0000, test acc = 0.6038, test_sen =0.6022, test_spe =0.6022, test_f1 =0.4888
[2024-10-29 12:56:12] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002208 train acc = 1.0000, test acc = 0.6344, test_sen =0.6011, test_spe =0.6011, test_f1 =0.5032/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:56:30: Evaluate 5 random ConvNet, ACCmean = 0.6233 ACCstd = 0.0179
-------------------------
2024-10-29 12:56:30: Evaluate 5 random ConvNet, SENmean = 0.6029 SENstd = 0.0023
-------------------------
2024-10-29 12:56:30: Evaluate 5 random ConvNet, SPEmean = 0.6029 SPEstd = 0.0023
-------------------------
2024-10-29 12:56:30: Evaluate 5 random ConvNet, F!mean = 0.4984 F!std = 0.0082
-------------------------
2024-10-29 12:56:30: Evaluate 5 random ConvNet, mean = 0.6233 std = 0.0179
-------------------------
2024-10-29 12:56:30: [2024-10-29 12:56:30] iter = 14000, loss = 1.2350
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:56:31: [2024-10-29 12:56:31] iter = 14010, loss = 0.7818
2024-10-29 12:56:31: [2024-10-29 12:56:31] iter = 14020, loss = 3.2401
2024-10-29 12:56:31: [2024-10-29 12:56:31] iter = 14030, loss = 1.4602
2024-10-29 12:56:32: [2024-10-29 12:56:32] iter = 14040, loss = 1.3144
2024-10-29 12:56:32: [2024-10-29 12:56:32] iter = 14050, loss = 5.9704
2024-10-29 12:56:32: [2024-10-29 12:56:32] iter = 14060, loss = 1.2100
2024-10-29 12:56:33: [2024-10-29 12:56:33] iter = 14070, loss = 1.3982
2024-10-29 12:56:33: [2024-10-29 12:56:33] iter = 14080, loss = 3.0698
2024-10-29 12:56:33: [2024-10-29 12:56:33] iter = 14090, loss = 1.5808
2024-10-29 12:56:34: [2024-10-29 12:56:34] iter = 14100, loss = 1.3416
2024-10-29 12:56:34: [2024-10-29 12:56:34] iter = 14110, loss = 4.5136
2024-10-29 12:56:34: [2024-10-29 12:56:34] iter = 14120, loss = 1.7145
2024-10-29 12:56:35: [2024-10-29 12:56:35] iter = 14130, loss = 1.1647
2024-10-29 12:56:35: [2024-10-29 12:56:35] iter = 14140, loss = 1.0541
2024-10-29 12:56:35: [2024-10-29 12:56:35] iter = 14150, loss = 2.0031
2024-10-29 12:56:36: [2024-10-29 12:56:35] iter = 14160, loss = 3.1204
2024-10-29 12:56:36: [2024-10-29 12:56:36] iter = 14170, loss = 1.4507
2024-10-29 12:56:36: [2024-10-29 12:56:36] iter = 14180, loss = 1.5868
2024-10-29 12:56:36: [2024-10-29 12:56:36] iter = 14190, loss = 6.1542
2024-10-29 12:56:37: [2024-10-29 12:56:37] iter = 14200, loss = 3.2970
2024-10-29 12:56:37: [2024-10-29 12:56:37] iter = 14210, loss = 1.7697
2024-10-29 12:56:37: [2024-10-29 12:56:37] iter = 14220, loss = 0.8677
2024-10-29 12:56:38: [2024-10-29 12:56:38] iter = 14230, loss = 3.8366
2024-10-29 12:56:38: [2024-10-29 12:56:38] iter = 14240, loss = 1.5473
2024-10-29 12:56:38: [2024-10-29 12:56:38] iter = 14250, loss = 0.8497
2024-10-29 12:56:39: [2024-10-29 12:56:39] iter = 14260, loss = 1.7674
2024-10-29 12:56:39: [2024-10-29 12:56:39] iter = 14270, loss = 1.5644
2024-10-29 12:56:39: [2024-10-29 12:56:39] iter = 14280, loss = 0.8029
2024-10-29 12:56:40: [2024-10-29 12:56:40] iter = 14290, loss = 0.9561
2024-10-29 12:56:40: [2024-10-29 12:56:40] iter = 14300, loss = 1.2221
2024-10-29 12:56:40: [2024-10-29 12:56:40] iter = 14310, loss = 1.6778
2024-10-29 12:56:41: [2024-10-29 12:56:41] iter = 14320, loss = 0.9730
2024-10-29 12:56:41: [2024-10-29 12:56:41] iter = 14330, loss = 1.5590
2024-10-29 12:56:41: [2024-10-29 12:56:41] iter = 14340, loss = 1.6888
2024-10-29 12:56:42: [2024-10-29 12:56:42] iter = 14350, loss = 1.6326
2024-10-29 12:56:42: [2024-10-29 12:56:42] iter = 14360, loss = 1.1136
2024-10-29 12:56:42: [2024-10-29 12:56:42] iter = 14370, loss = 0.9206
2024-10-29 12:56:43: [2024-10-29 12:56:43] iter = 14380, loss = 1.4937
2024-10-29 12:56:43: [2024-10-29 12:56:43] iter = 14390, loss = 0.9177
2024-10-29 12:56:43: [2024-10-29 12:56:43] iter = 14400, loss = 1.5519
2024-10-29 12:56:44: [2024-10-29 12:56:44] iter = 14410, loss = 2.2459
2024-10-29 12:56:44: [2024-10-29 12:56:44] iter = 14420, loss = 1.6410
2024-10-29 12:56:44: [2024-10-29 12:56:44] iter = 14430, loss = 1.1696
2024-10-29 12:56:45: [2024-10-29 12:56:45] iter = 14440, loss = 1.8906
2024-10-29 12:56:45: [2024-10-29 12:56:45] iter = 14450, loss = 1.3189
2024-10-29 12:56:46: [2024-10-29 12:56:46] iter = 14460, loss = 1.0344
2024-10-29 12:56:46: [2024-10-29 12:56:46] iter = 14470, loss = 1.2743
2024-10-29 12:56:47: [2024-10-29 12:56:47] iter = 14480, loss = 1.3710
2024-10-29 12:56:47: [2024-10-29 12:56:47] iter = 14490, loss = 1.2049
2024-10-29 12:56:48: [2024-10-29 12:56:48] iter = 14500, loss = 0.9005
2024-10-29 12:56:48: [2024-10-29 12:56:48] iter = 14510, loss = 1.2177
2024-10-29 12:56:48: [2024-10-29 12:56:48] iter = 14520, loss = 2.2669
2024-10-29 12:56:49: [2024-10-29 12:56:49] iter = 14530, loss = 1.1858
2024-10-29 12:56:49: [2024-10-29 12:56:49] iter = 14540, loss = 1.2924
2024-10-29 12:56:50: [2024-10-29 12:56:50] iter = 14550, loss = 1.8324
2024-10-29 12:56:50: [2024-10-29 12:56:50] iter = 14560, loss = 1.5776
2024-10-29 12:56:51: [2024-10-29 12:56:51] iter = 14570, loss = 0.7764
2024-10-29 12:56:51: [2024-10-29 12:56:51] iter = 14580, loss = 1.5656
2024-10-29 12:56:51: [2024-10-29 12:56:51] iter = 14590, loss = 1.0293
2024-10-29 12:56:52: [2024-10-29 12:56:52] iter = 14600, loss = 2.9041
2024-10-29 12:56:52: [2024-10-29 12:56:52] iter = 14610, loss = 1.0921
2024-10-29 12:56:52: [2024-10-29 12:56:52] iter = 14620, loss = 1.4509
2024-10-29 12:56:53: [2024-10-29 12:56:53] iter = 14630, loss = 2.2104
2024-10-29 12:56:53: [2024-10-29 12:56:53] iter = 14640, loss = 1.9182
2024-10-29 12:56:53: [2024-10-29 12:56:53] iter = 14650, loss = 0.9696
2024-10-29 12:56:54: [2024-10-29 12:56:54] iter = 14660, loss = 1.4252
2024-10-29 12:56:54: [2024-10-29 12:56:54] iter = 14670, loss = 1.2455
2024-10-29 12:56:54: [2024-10-29 12:56:54] iter = 14680, loss = 0.9293
2024-10-29 12:56:55: [2024-10-29 12:56:55] iter = 14690, loss = 1.2331
2024-10-29 12:56:55: [2024-10-29 12:56:55] iter = 14700, loss = 1.1503
2024-10-29 12:56:55: [2024-10-29 12:56:55] iter = 14710, loss = 1.2521
2024-10-29 12:56:56: [2024-10-29 12:56:56] iter = 14720, loss = 1.7516
2024-10-29 12:56:56: [2024-10-29 12:56:56] iter = 14730, loss = 1.7868
2024-10-29 12:56:56: [2024-10-29 12:56:56] iter = 14740, loss = 1.7733
2024-10-29 12:56:57: [2024-10-29 12:56:57] iter = 14750, loss = 0.7775
2024-10-29 12:56:57: [2024-10-29 12:56:57] iter = 14760, loss = 1.0643
2024-10-29 12:56:57: [2024-10-29 12:56:57] iter = 14770, loss = 1.6946
2024-10-29 12:56:58: [2024-10-29 12:56:58] iter = 14780, loss = 1.7789
2024-10-29 12:56:58: [2024-10-29 12:56:58] iter = 14790, loss = 1.1160
2024-10-29 12:56:58: [2024-10-29 12:56:58] iter = 14800, loss = 1.4917
2024-10-29 12:56:59: [2024-10-29 12:56:59] iter = 14810, loss = 1.1036
2024-10-29 12:56:59: [2024-10-29 12:56:59] iter = 14820, loss = 1.2094
2024-10-29 12:56:59: [2024-10-29 12:56:59] iter = 14830, loss = 1.3737
2024-10-29 12:57:00: [2024-10-29 12:57:00] iter = 14840, loss = 0.7713
2024-10-29 12:57:00: [2024-10-29 12:57:00] iter = 14850, loss = 1.1959
2024-10-29 12:57:00: [2024-10-29 12:57:00] iter = 14860, loss = 1.2915
2024-10-29 12:57:01: [2024-10-29 12:57:01] iter = 14870, loss = 4.6703
2024-10-29 12:57:01: [2024-10-29 12:57:01] iter = 14880, loss = 1.1030
2024-10-29 12:57:02: [2024-10-29 12:57:02] iter = 14890, loss = 0.8844
2024-10-29 12:57:02: [2024-10-29 12:57:02] iter = 14900, loss = 1.1511
2024-10-29 12:57:02: [2024-10-29 12:57:02] iter = 14910, loss = 1.6259
2024-10-29 12:57:03: [2024-10-29 12:57:03] iter = 14920, loss = 2.2871
2024-10-29 12:57:03: [2024-10-29 12:57:03] iter = 14930, loss = 3.7949
2024-10-29 12:57:03: [2024-10-29 12:57:03] iter = 14940, loss = 3.8682
2024-10-29 12:57:04: [2024-10-29 12:57:04] iter = 14950, loss = 1.2788
2024-10-29 12:57:04: [2024-10-29 12:57:04] iter = 14960, loss = 1.0087
2024-10-29 12:57:04: [2024-10-29 12:57:04] iter = 14970, loss = 6.6491
2024-10-29 12:57:05: [2024-10-29 12:57:05] iter = 14980, loss = 8.0421
2024-10-29 12:57:05: [2024-10-29 12:57:05] iter = 14990, loss = 1.6965
2024-10-29 12:57:05: [2024-10-29 12:57:05] iter = 15000, loss = 1.0186
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 15010, loss = 1.6917
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 15020, loss = 1.6028
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 15030, loss = 1.0672
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 15040, loss = 0.8229
2024-10-29 12:57:07: [2024-10-29 12:57:07] iter = 15050, loss = 1.2914
2024-10-29 12:57:07: [2024-10-29 12:57:07] iter = 15060, loss = 3.0523
2024-10-29 12:57:07: [2024-10-29 12:57:07] iter = 15070, loss = 1.4674
2024-10-29 12:57:08: [2024-10-29 12:57:08] iter = 15080, loss = 1.4805
2024-10-29 12:57:08: [2024-10-29 12:57:08] iter = 15090, loss = 0.9514
2024-10-29 12:57:08: [2024-10-29 12:57:08] iter = 15100, loss = 1.3682
2024-10-29 12:57:09: [2024-10-29 12:57:09] iter = 15110, loss = 1.7243
2024-10-29 12:57:09: [2024-10-29 12:57:09] iter = 15120, loss = 1.4011
2024-10-29 12:57:09: [2024-10-29 12:57:09] iter = 15130, loss = 1.7983
2024-10-29 12:57:10: [2024-10-29 12:57:10] iter = 15140, loss = 2.2893
2024-10-29 12:57:10: [2024-10-29 12:57:10] iter = 15150, loss = 1.2319
2024-10-29 12:57:10: [2024-10-29 12:57:10] iter = 15160, loss = 1.1553
2024-10-29 12:57:11: [2024-10-29 12:57:11] iter = 15170, loss = 4.4371
2024-10-29 12:57:11: [2024-10-29 12:57:11] iter = 15180, loss = 1.6233
2024-10-29 12:57:11: [2024-10-29 12:57:11] iter = 15190, loss = 1.5755
2024-10-29 12:57:12: [2024-10-29 12:57:12] iter = 15200, loss = 2.4876
2024-10-29 12:57:12: [2024-10-29 12:57:12] iter = 15210, loss = 1.1869
2024-10-29 12:57:12: [2024-10-29 12:57:12] iter = 15220, loss = 1.5511
2024-10-29 12:57:13: [2024-10-29 12:57:13] iter = 15230, loss = 1.4911
2024-10-29 12:57:13: [2024-10-29 12:57:13] iter = 15240, loss = 1.6116
2024-10-29 12:57:13: [2024-10-29 12:57:13] iter = 15250, loss = 1.3078
2024-10-29 12:57:14: [2024-10-29 12:57:14] iter = 15260, loss = 2.0515
2024-10-29 12:57:14: [2024-10-29 12:57:14] iter = 15270, loss = 1.9296
2024-10-29 12:57:14: [2024-10-29 12:57:14] iter = 15280, loss = 1.3943
2024-10-29 12:57:15: [2024-10-29 12:57:15] iter = 15290, loss = 1.3812
2024-10-29 12:57:15: [2024-10-29 12:57:15] iter = 15300, loss = 1.5616
2024-10-29 12:57:15: [2024-10-29 12:57:15] iter = 15310, loss = 1.0147
2024-10-29 12:57:16: [2024-10-29 12:57:16] iter = 15320, loss = 1.7383
2024-10-29 12:57:16: [2024-10-29 12:57:16] iter = 15330, loss = 1.7891
2024-10-29 12:57:16: [2024-10-29 12:57:16] iter = 15340, loss = 0.7726
2024-10-29 12:57:17: [2024-10-29 12:57:17] iter = 15350, loss = 1.5277
2024-10-29 12:57:17: [2024-10-29 12:57:17] iter = 15360, loss = 1.3354
2024-10-29 12:57:17: [2024-10-29 12:57:17] iter = 15370, loss = 1.0858
2024-10-29 12:57:18: [2024-10-29 12:57:18] iter = 15380, loss = 1.1570
2024-10-29 12:57:18: [2024-10-29 12:57:18] iter = 15390, loss = 2.0782
2024-10-29 12:57:18: [2024-10-29 12:57:18] iter = 15400, loss = 1.9087
2024-10-29 12:57:19: [2024-10-29 12:57:19] iter = 15410, loss = 1.1558
2024-10-29 12:57:19: [2024-10-29 12:57:19] iter = 15420, loss = 6.1536
2024-10-29 12:57:19: [2024-10-29 12:57:19] iter = 15430, loss = 0.9333
2024-10-29 12:57:20: [2024-10-29 12:57:20] iter = 15440, loss = 1.0037
2024-10-29 12:57:20: [2024-10-29 12:57:20] iter = 15450, loss = 0.9129
2024-10-29 12:57:20: [2024-10-29 12:57:20] iter = 15460, loss = 4.0890
2024-10-29 12:57:21: [2024-10-29 12:57:21] iter = 15470, loss = 1.1881
2024-10-29 12:57:21: [2024-10-29 12:57:21] iter = 15480, loss = 1.3808
2024-10-29 12:57:21: [2024-10-29 12:57:21] iter = 15490, loss = 1.3729
2024-10-29 12:57:22: [2024-10-29 12:57:22] iter = 15500, loss = 0.8697
2024-10-29 12:57:22: [2024-10-29 12:57:22] iter = 15510, loss = 2.7230
2024-10-29 12:57:22: [2024-10-29 12:57:22] iter = 15520, loss = 1.2215
2024-10-29 12:57:23: [2024-10-29 12:57:23] iter = 15530, loss = 1.4886
2024-10-29 12:57:23: [2024-10-29 12:57:23] iter = 15540, loss = 1.2947
2024-10-29 12:57:23: [2024-10-29 12:57:23] iter = 15550, loss = 0.9366
2024-10-29 12:57:24: [2024-10-29 12:57:24] iter = 15560, loss = 1.5622
2024-10-29 12:57:24: [2024-10-29 12:57:24] iter = 15570, loss = 1.4993
2024-10-29 12:57:24: [2024-10-29 12:57:24] iter = 15580, loss = 1.1443
2024-10-29 12:57:25: [2024-10-29 12:57:25] iter = 15590, loss = 1.6971
2024-10-29 12:57:25: [2024-10-29 12:57:25] iter = 15600, loss = 1.6189
2024-10-29 12:57:25: [2024-10-29 12:57:25] iter = 15610, loss = 3.6173
2024-10-29 12:57:26: [2024-10-29 12:57:26] iter = 15620, loss = 1.5849
2024-10-29 12:57:26: [2024-10-29 12:57:26] iter = 15630, loss = 1.3677
2024-10-29 12:57:27: [2024-10-29 12:57:27] iter = 15640, loss = 1.0142
2024-10-29 12:57:27: [2024-10-29 12:57:27] iter = 15650, loss = 0.9226
2024-10-29 12:57:28: [2024-10-29 12:57:28] iter = 15660, loss = 1.7127
2024-10-29 12:57:28: [2024-10-29 12:57:28] iter = 15670, loss = 1.3279
2024-10-29 12:57:28: [2024-10-29 12:57:28] iter = 15680, loss = 2.2541
2024-10-29 12:57:29: [2024-10-29 12:57:29] iter = 15690, loss = 1.0314
2024-10-29 12:57:29: [2024-10-29 12:57:29] iter = 15700, loss = 2.2890
2024-10-29 12:57:29: [2024-10-29 12:57:29] iter = 15710, loss = 1.2387
2024-10-29 12:57:30: [2024-10-29 12:57:30] iter = 15720, loss = 0.9308
2024-10-29 12:57:30: [2024-10-29 12:57:30] iter = 15730, loss = 1.1564
2024-10-29 12:57:30: [2024-10-29 12:57:30] iter = 15740, loss = 1.5102
2024-10-29 12:57:31: [2024-10-29 12:57:31] iter = 15750, loss = 1.1127
2024-10-29 12:57:31: [2024-10-29 12:57:31] iter = 15760, loss = 1.6464
2024-10-29 12:57:32: [2024-10-29 12:57:32] iter = 15770, loss = 1.0848
2024-10-29 12:57:32: [2024-10-29 12:57:32] iter = 15780, loss = 1.2646
2024-10-29 12:57:33: [2024-10-29 12:57:33] iter = 15790, loss = 0.9363
2024-10-29 12:57:34: [2024-10-29 12:57:34] iter = 15800, loss = 1.2043
2024-10-29 12:57:34: [2024-10-29 12:57:34] iter = 15810, loss = 1.0633
2024-10-29 12:57:35: [2024-10-29 12:57:35] iter = 15820, loss = 1.1719
2024-10-29 12:57:35: [2024-10-29 12:57:35] iter = 15830, loss = 1.5559
2024-10-29 12:57:36: [2024-10-29 12:57:36] iter = 15840, loss = 0.9580
2024-10-29 12:57:36: [2024-10-29 12:57:36] iter = 15850, loss = 1.7751
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 15860, loss = 4.9069
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 15870, loss = 3.3433
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 15880, loss = 1.2097
2024-10-29 12:57:38: [2024-10-29 12:57:38] iter = 15890, loss = 1.3898
2024-10-29 12:57:38: [2024-10-29 12:57:38] iter = 15900, loss = 2.8243
2024-10-29 12:57:38: [2024-10-29 12:57:38] iter = 15910, loss = 1.7808
2024-10-29 12:57:39: [2024-10-29 12:57:39] iter = 15920, loss = 1.4820
2024-10-29 12:57:39: [2024-10-29 12:57:39] iter = 15930, loss = 1.2791
2024-10-29 12:57:39: [2024-10-29 12:57:39] iter = 15940, loss = 1.1913
2024-10-29 12:57:40: [2024-10-29 12:57:40] iter = 15950, loss = 1.0753
2024-10-29 12:57:40: [2024-10-29 12:57:40] iter = 15960, loss = 1.3973
2024-10-29 12:57:41: [2024-10-29 12:57:41] iter = 15970, loss = 1.3900
2024-10-29 12:57:41: [2024-10-29 12:57:41] iter = 15980, loss = 1.0743
2024-10-29 12:57:41: [2024-10-29 12:57:41] iter = 15990, loss = 2.3120
2024-10-29 12:57:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 12:57:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:57:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62064}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:58:09: Evaluate 5 random ConvNet, ACCmean = 0.6092 ACCstd = 0.0272
-------------------------
2024-10-29 12:58:09: Evaluate 5 random ConvNet, SENmean = 0.6248 SENstd = 0.0053
-------------------------
2024-10-29 12:58:09: Evaluate 5 random ConvNet, SPEmean = 0.6248 SPEstd = 0.0053
-------------------------
2024-10-29 12:58:09: Evaluate 5 random ConvNet, F!mean = 0.4980 F!std = 0.0131
-------------------------
2024-10-29 12:58:09: Evaluate 5 random ConvNet, mean = 0.6092 std = 0.0272
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:58:09: [2024-10-29 12:58:09] iter = 16000, loss = 1.4539
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:58:10: [2024-10-29 12:58:10] iter = 16010, loss = 1.0824
2024-10-29 12:58:10: [2024-10-29 12:58:10] iter = 16020, loss = 1.1888
2024-10-29 12:58:10: [2024-10-29 12:58:10] iter = 16030, loss = 0.9389
2024-10-29 12:58:11: [2024-10-29 12:58:11] iter = 16040, loss = 1.3601
2024-10-29 12:58:11: [2024-10-29 12:58:11] iter = 16050, loss = 0.9929
2024-10-29 12:58:11: [2024-10-29 12:58:11] iter = 16060, loss = 1.6916
2024-10-29 12:58:12: [2024-10-29 12:58:12] iter = 16070, loss = 1.3203
2024-10-29 12:58:12: [2024-10-29 12:58:12] iter = 16080, loss = 2.0118
2024-10-29 12:58:12: [2024-10-29 12:58:12] iter = 16090, loss = 2.4899
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 16100, loss = 1.1017
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 16110, loss = 2.2884
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 16120, loss = 2.1874
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 16130, loss = 1.2407
2024-10-29 12:58:14: [2024-10-29 12:58:14] iter = 16140, loss = 0.9925
2024-10-29 12:58:14: [2024-10-29 12:58:14] iter = 16150, loss = 1.5987
2024-10-29 12:58:14: [2024-10-29 12:58:14] iter = 16160, loss = 1.0710
2024-10-29 12:58:15: [2024-10-29 12:58:15] iter = 16170, loss = 2.1763
2024-10-29 12:58:15: [2024-10-29 12:58:15] iter = 16180, loss = 1.4128
2024-10-29 12:58:15: [2024-10-29 12:58:15] iter = 16190, loss = 1.1849
2024-10-29 12:58:16: [2024-10-29 12:58:16] iter = 16200, loss = 1.4225
2024-10-29 12:58:16: [2024-10-29 12:58:16] iter = 16210, loss = 0.6788
2024-10-29 12:58:16: [2024-10-29 12:58:16] iter = 16220, loss = 0.9417
2024-10-29 12:58:17: [2024-10-29 12:58:17] iter = 16230, loss = 0.7877
2024-10-29 12:58:17: [2024-10-29 12:58:17] iter = 16240, loss = 1.5337
2024-10-29 12:58:17: [2024-10-29 12:58:17] iter = 16250, loss = 1.2708
2024-10-29 12:58:18: [2024-10-29 12:58:18] iter = 16260, loss = 11.1588
2024-10-29 12:58:18: [2024-10-29 12:58:18] iter = 16270, loss = 2.8389
2024-10-29 12:58:18: [2024-10-29 12:58:18] iter = 16280, loss = 1.0478
2024-10-29 12:58:19: [2024-10-29 12:58:19] iter = 16290, loss = 4.4611
2024-10-29 12:58:19: [2024-10-29 12:58:19] iter = 16300, loss = 3.0801
2024-10-29 12:58:20: [2024-10-29 12:58:20] iter = 16310, loss = 1.2248
2024-10-29 12:58:20: [2024-10-29 12:58:20] iter = 16320, loss = 1.0928
2024-10-29 12:58:20: [2024-10-29 12:58:20] iter = 16330, loss = 1.0999
2024-10-29 12:58:21: [2024-10-29 12:58:21] iter = 16340, loss = 1.2456
2024-10-29 12:58:21: [2024-10-29 12:58:21] iter = 16350, loss = 0.9152
2024-10-29 12:58:22: [2024-10-29 12:58:22] iter = 16360, loss = 1.0001
2024-10-29 12:58:22: [2024-10-29 12:58:22] iter = 16370, loss = 0.7929
2024-10-29 12:58:23: [2024-10-29 12:58:23] iter = 16380, loss = 1.1312
2024-10-29 12:58:23: [2024-10-29 12:58:23] iter = 16390, loss = 1.2563
2024-10-29 12:58:24: [2024-10-29 12:58:24] iter = 16400, loss = 1.6460
2024-10-29 12:58:24: [2024-10-29 12:58:24] iter = 16410, loss = 2.1575
2024-10-29 12:58:25: [2024-10-29 12:58:25] iter = 16420, loss = 1.0144
2024-10-29 12:58:25: [2024-10-29 12:58:25] iter = 16430, loss = 1.9496
2024-10-29 12:58:25: [2024-10-29 12:58:25] iter = 16440, loss = 1.1127
2024-10-29 12:58:26: [2024-10-29 12:58:26] iter = 16450, loss = 1.0645
2024-10-29 12:58:26: [2024-10-29 12:58:26] iter = 16460, loss = 3.3786
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 16470, loss = 1.8916
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 16480, loss = 1.7548
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 16490, loss = 1.7482
2024-10-29 12:58:28: [2024-10-29 12:58:28] iter = 16500, loss = 1.3089
2024-10-29 12:58:28: [2024-10-29 12:58:28] iter = 16510, loss = 1.2572
2024-10-29 12:58:28: [2024-10-29 12:58:28] iter = 16520, loss = 1.1909
2024-10-29 12:58:29: [2024-10-29 12:58:29] iter = 16530, loss = 1.1789
2024-10-29 12:58:29: [2024-10-29 12:58:29] iter = 16540, loss = 1.7062
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 16550, loss = 1.2216
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 16560, loss = 1.0737
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 16570, loss = 1.5643
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 16580, loss = 1.5717
2024-10-29 12:58:31: [2024-10-29 12:58:31] iter = 16590, loss = 1.0130
2024-10-29 12:58:31: [2024-10-29 12:58:31] iter = 16600, loss = 1.9312
2024-10-29 12:58:31: [2024-10-29 12:58:31] iter = 16610, loss = 4.9664
2024-10-29 12:58:32: [2024-10-29 12:58:32] iter = 16620, loss = 2.0491
2024-10-29 12:58:32: [2024-10-29 12:58:32] iter = 16630, loss = 2.0958
2024-10-29 12:58:32: [2024-10-29 12:58:32] iter = 16640, loss = 1.4758
2024-10-29 12:58:33: [2024-10-29 12:58:33] iter = 16650, loss = 1.2272
2024-10-29 12:58:33: [2024-10-29 12:58:33] iter = 16660, loss = 1.6940
2024-10-29 12:58:33: [2024-10-29 12:58:33] iter = 16670, loss = 1.2065
2024-10-29 12:58:34: [2024-10-29 12:58:34] iter = 16680, loss = 1.4487
2024-10-29 12:58:34: [2024-10-29 12:58:34] iter = 16690, loss = 2.1296
2024-10-29 12:58:34: [2024-10-29 12:58:34] iter = 16700, loss = 1.1538
2024-10-29 12:58:35: [2024-10-29 12:58:35] iter = 16710, loss = 1.8444
2024-10-29 12:58:35: [2024-10-29 12:58:35] iter = 16720, loss = 0.8041
2024-10-29 12:58:35: [2024-10-29 12:58:35] iter = 16730, loss = 0.9015
2024-10-29 12:58:36: [2024-10-29 12:58:36] iter = 16740, loss = 2.6353
2024-10-29 12:58:36: [2024-10-29 12:58:36] iter = 16750, loss = 1.0866
2024-10-29 12:58:36: [2024-10-29 12:58:36] iter = 16760, loss = 1.0591
2024-10-29 12:58:37: [2024-10-29 12:58:37] iter = 16770, loss = 2.0186
2024-10-29 12:58:37: [2024-10-29 12:58:37] iter = 16780, loss = 1.1167
2024-10-29 12:58:38: [2024-10-29 12:58:38] iter = 16790, loss = 0.9626
2024-10-29 12:58:38: [2024-10-29 12:58:38] iter = 16800, loss = 1.5459
2024-10-29 12:58:38: [2024-10-29 12:58:38] iter = 16810, loss = 5.9259
2024-10-29 12:58:39: [2024-10-29 12:58:38] iter = 16820, loss = 1.1726
2024-10-29 12:58:39: [2024-10-29 12:58:39] iter = 16830, loss = 1.6114
2024-10-29 12:58:39: [2024-10-29 12:58:39] iter = 16840, loss = 0.8313
2024-10-29 12:58:40: [2024-10-29 12:58:39] iter = 16850, loss = 1.0380
2024-10-29 12:58:40: [2024-10-29 12:58:40] iter = 16860, loss = 6.0256
2024-10-29 12:58:40: [2024-10-29 12:58:40] iter = 16870, loss = 1.3584
2024-10-29 12:58:41: [2024-10-29 12:58:41] iter = 16880, loss = 4.5648
2024-10-29 12:58:41: [2024-10-29 12:58:41] iter = 16890, loss = 1.4190
2024-10-29 12:58:41: [2024-10-29 12:58:41] iter = 16900, loss = 0.9187
2024-10-29 12:58:42: [2024-10-29 12:58:42] iter = 16910, loss = 0.7863
2024-10-29 12:58:42: [2024-10-29 12:58:42] iter = 16920, loss = 0.8553
2024-10-29 12:58:42: [2024-10-29 12:58:42] iter = 16930, loss = 0.9295
2024-10-29 12:58:43: [2024-10-29 12:58:43] iter = 16940, loss = 1.4858
2024-10-29 12:58:43: [2024-10-29 12:58:43] iter = 16950, loss = 0.9934
2024-10-29 12:58:44: [2024-10-29 12:58:44] iter = 16960, loss = 3.1954
2024-10-29 12:58:44: [2024-10-29 12:58:44] iter = 16970, loss = 2.7637
2024-10-29 12:58:45: [2024-10-29 12:58:45] iter = 16980, loss = 1.1775
2024-10-29 12:58:45: [2024-10-29 12:58:45] iter = 16990, loss = 1.7126
2024-10-29 12:58:45: [2024-10-29 12:58:45] iter = 17000, loss = 1.5130
2024-10-29 12:58:46: [2024-10-29 12:58:46] iter = 17010, loss = 1.1437
2024-10-29 12:58:46: [2024-10-29 12:58:46] iter = 17020, loss = 2.4272
2024-10-29 12:58:47: [2024-10-29 12:58:47] iter = 17030, loss = 2.2021
2024-10-29 12:58:47: [2024-10-29 12:58:47] iter = 17040, loss = 1.3302
2024-10-29 12:58:48: [2024-10-29 12:58:48] iter = 17050, loss = 1.6166
2024-10-29 12:58:48: [2024-10-29 12:58:48] iter = 17060, loss = 1.2962
2024-10-29 12:58:49: [2024-10-29 12:58:49] iter = 17070, loss = 0.8899
2024-10-29 12:58:49: [2024-10-29 12:58:49] iter = 17080, loss = 2.1361
2024-10-29 12:58:50: [2024-10-29 12:58:50] iter = 17090, loss = 5.0953
2024-10-29 12:58:50: [2024-10-29 12:58:50] iter = 17100, loss = 1.4405
2024-10-29 12:58:51: [2024-10-29 12:58:51] iter = 17110, loss = 1.2643
2024-10-29 12:58:51: [2024-10-29 12:58:51] iter = 17120, loss = 1.6084
2024-10-29 12:58:51: [2024-10-29 12:58:51] iter = 17130, loss = 0.9914
2024-10-29 12:58:52: [2024-10-29 12:58:52] iter = 17140, loss = 1.7319
2024-10-29 12:58:52: [2024-10-29 12:58:52] iter = 17150, loss = 1.5903
2024-10-29 12:58:52: [2024-10-29 12:58:52] iter = 17160, loss = 2.3044
2024-10-29 12:58:53: [2024-10-29 12:58:53] iter = 17170, loss = 1.8599
2024-10-29 12:58:53: [2024-10-29 12:58:53] iter = 17180, loss = 1.3090
2024-10-29 12:58:53: [2024-10-29 12:58:53] iter = 17190, loss = 1.2991
2024-10-29 12:58:54: [2024-10-29 12:58:54] iter = 17200, loss = 0.8894
2024-10-29 12:58:54: [2024-10-29 12:58:54] iter = 17210, loss = 2.6130
2024-10-29 12:58:54: [2024-10-29 12:58:54] iter = 17220, loss = 1.4120
2024-10-29 12:58:55: [2024-10-29 12:58:55] iter = 17230, loss = 2.5278
2024-10-29 12:58:55: [2024-10-29 12:58:55] iter = 17240, loss = 5.8199
2024-10-29 12:58:55: [2024-10-29 12:58:55] iter = 17250, loss = 1.2842
2024-10-29 12:58:56: [2024-10-29 12:58:56] iter = 17260, loss = 2.0389
2024-10-29 12:58:56: [2024-10-29 12:58:56] iter = 17270, loss = 2.4537
2024-10-29 12:58:56: [2024-10-29 12:58:56] iter = 17280, loss = 1.8222
2024-10-29 12:58:57: [2024-10-29 12:58:57] iter = 17290, loss = 1.6943
2024-10-29 12:58:57: [2024-10-29 12:58:57] iter = 17300, loss = 0.8602
2024-10-29 12:58:57: [2024-10-29 12:58:57] iter = 17310, loss = 1.7025
2024-10-29 12:58:58: [2024-10-29 12:58:58] iter = 17320, loss = 1.5122
2024-10-29 12:58:58: [2024-10-29 12:58:58] iter = 17330, loss = 1.8323
2024-10-29 12:58:59: [2024-10-29 12:58:59] iter = 17340, loss = 1.5171
2024-10-29 12:58:59: [2024-10-29 12:58:59] iter = 17350, loss = 0.8569
2024-10-29 12:58:59: [2024-10-29 12:58:59] iter = 17360, loss = 1.0951
2024-10-29 12:59:00: [2024-10-29 12:59:00] iter = 17370, loss = 1.8129
2024-10-29 12:59:00: [2024-10-29 12:59:00] iter = 17380, loss = 1.5516
2024-10-29 12:59:00: [2024-10-29 12:59:00] iter = 17390, loss = 1.3643
2024-10-29 12:59:01: [2024-10-29 12:59:01] iter = 17400, loss = 1.0410
2024-10-29 12:59:01: [2024-10-29 12:59:01] iter = 17410, loss = 1.3430
2024-10-29 12:59:01: [2024-10-29 12:59:01] iter = 17420, loss = 2.1183
2024-10-29 12:59:02: [2024-10-29 12:59:02] iter = 17430, loss = 1.3150
2024-10-29 12:59:02: [2024-10-29 12:59:02] iter = 17440, loss = 1.8127
2024-10-29 12:59:02: [2024-10-29 12:59:02] iter = 17450, loss = 1.2250
2024-10-29 12:59:03: [2024-10-29 12:59:03] iter = 17460, loss = 0.8633
2024-10-29 12:59:03: [2024-10-29 12:59:03] iter = 17470, loss = 3.6395
2024-10-29 12:59:03: [2024-10-29 12:59:03] iter = 17480, loss = 3.1736
2024-10-29 12:59:04: [2024-10-29 12:59:04] iter = 17490, loss = 1.3112
2024-10-29 12:59:04: [2024-10-29 12:59:04] iter = 17500, loss = 1.6923
2024-10-29 12:59:04: [2024-10-29 12:59:04] iter = 17510, loss = 1.5262
2024-10-29 12:59:05: [2024-10-29 12:59:05] iter = 17520, loss = 1.6392
2024-10-29 12:59:05: [2024-10-29 12:59:05] iter = 17530, loss = 0.9531
2024-10-29 12:59:05: [2024-10-29 12:59:05] iter = 17540, loss = 1.2471
2024-10-29 12:59:06: [2024-10-29 12:59:06] iter = 17550, loss = 1.2712
2024-10-29 12:59:06: [2024-10-29 12:59:06] iter = 17560, loss = 1.4514
2024-10-29 12:59:06: [2024-10-29 12:59:06] iter = 17570, loss = 1.1051
2024-10-29 12:59:07: [2024-10-29 12:59:07] iter = 17580, loss = 0.7179
2024-10-29 12:59:07: [2024-10-29 12:59:07] iter = 17590, loss = 4.0860
2024-10-29 12:59:07: [2024-10-29 12:59:07] iter = 17600, loss = 1.3989
2024-10-29 12:59:08: [2024-10-29 12:59:08] iter = 17610, loss = 1.0255
2024-10-29 12:59:08: [2024-10-29 12:59:08] iter = 17620, loss = 1.9805
2024-10-29 12:59:09: [2024-10-29 12:59:09] iter = 17630, loss = 1.4801
2024-10-29 12:59:09: [2024-10-29 12:59:09] iter = 17640, loss = 0.9955
2024-10-29 12:59:10: [2024-10-29 12:59:10] iter = 17650, loss = 1.0590
2024-10-29 12:59:10: [2024-10-29 12:59:10] iter = 17660, loss = 1.2878
2024-10-29 12:59:11: [2024-10-29 12:59:11] iter = 17670, loss = 1.3013
2024-10-29 12:59:11: [2024-10-29 12:59:11] iter = 17680, loss = 8.1560
2024-10-29 12:59:11: [2024-10-29 12:59:11] iter = 17690, loss = 2.0333
2024-10-29 12:59:12: [2024-10-29 12:59:12] iter = 17700, loss = 1.5233
2024-10-29 12:59:12: [2024-10-29 12:59:12] iter = 17710, loss = 3.3456
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 17720, loss = 3.8555
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 17730, loss = 0.9200
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 17740, loss = 1.0798
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 17750, loss = 2.6026
2024-10-29 12:59:14: [2024-10-29 12:59:14] iter = 17760, loss = 1.6195
2024-10-29 12:59:14: [2024-10-29 12:59:14] iter = 17770, loss = 2.9852
2024-10-29 12:59:14: [2024-10-29 12:59:14] iter = 17780, loss = 1.4346
2024-10-29 12:59:15: [2024-10-29 12:59:15] iter = 17790, loss = 1.3884
2024-10-29 12:59:15: [2024-10-29 12:59:15] iter = 17800, loss = 1.5563
2024-10-29 12:59:15: [2024-10-29 12:59:15] iter = 17810, loss = 1.4819
2024-10-29 12:59:16: [2024-10-29 12:59:16] iter = 17820, loss = 1.3107
2024-10-29 12:59:16: [2024-10-29 12:59:16] iter = 17830, loss = 1.1965
2024-10-29 12:59:16: [2024-10-29 12:59:16] iter = 17840, loss = 2.0639
2024-10-29 12:59:17: [2024-10-29 12:59:17] iter = 17850, loss = 0.6690
2024-10-29 12:59:17: [2024-10-29 12:59:17] iter = 17860, loss = 1.1781
2024-10-29 12:59:17: [2024-10-29 12:59:17] iter = 17870, loss = 1.1983
2024-10-29 12:59:18: [2024-10-29 12:59:18] iter = 17880, loss = 1.5016
2024-10-29 12:59:18: [2024-10-29 12:59:18] iter = 17890, loss = 4.9504
2024-10-29 12:59:18: [2024-10-29 12:59:18] iter = 17900, loss = 1.3079
2024-10-29 12:59:19: [2024-10-29 12:59:19] iter = 17910, loss = 0.9478
2024-10-29 12:59:19: [2024-10-29 12:59:19] iter = 17920, loss = 1.6177
2024-10-29 12:59:19: [2024-10-29 12:59:19] iter = 17930, loss = 2.4643
2024-10-29 12:59:20: [2024-10-29 12:59:20] iter = 17940, loss = 0.8012
2024-10-29 12:59:20: [2024-10-29 12:59:20] iter = 17950, loss = 1.3980
2024-10-29 12:59:21: [2024-10-29 12:59:21] iter = 17960, loss = 1.1799
2024-10-29 12:59:21: [2024-10-29 12:59:21] iter = 17970, loss = 0.7761
2024-10-29 12:59:21: [2024-10-29 12:59:21] iter = 17980, loss = 1.6816
2024-10-29 12:59:22: [2024-10-29 12:59:22] iter = 17990, loss = 2.3372
2024-10-29 12:59:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 12:59:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:59:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62374}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:59:49: Evaluate 5 random ConvNet, ACCmean = 0.4589 ACCstd = 0.0108
-------------------------
2024-10-29 12:59:49: Evaluate 5 random ConvNet, SENmean = 0.5940 SENstd = 0.0063
-------------------------
2024-10-29 12:59:49: Evaluate 5 random ConvNet, SPEmean = 0.5940 SPEstd = 0.0063
-------------------------
2024-10-29 12:59:49: Evaluate 5 random ConvNet, F!mean = 0.4078 F!std = 0.0077
-------------------------
2024-10-29 12:59:49: Evaluate 5 random ConvNet, mean = 0.4589 std = 0.0108
-------------------------
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 18000, loss = 1.5025
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 18010, loss = 1.7392
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 18020, loss = 1.2502
2024-10-29 12:59:50: [2024-10-29 12:59:50] iter = 18030, loss = 4.4695
2024-10-29 12:59:50: [2024-10-29 12:59:50] iter = 18040, loss = 4.2487
2024-10-29 12:59:50: [2024-10-29 12:59:50] iter = 18050, loss = 1.6189
2024-10-29 12:59:51: [2024-10-29 12:59:51] iter = 18060, loss = 0.9203
2024-10-29 12:59:51: [2024-10-29 12:59:51] iter = 18070, loss = 1.7642
2024-10-29 12:59:52: [2024-10-29 12:59:52] iter = 18080, loss = 0.9826
2024-10-29 12:59:52: [2024-10-29 12:59:52] iter = 18090, loss = 1.5365
2024-10-29 12:59:52: [2024-10-29 12:59:52] iter = 18100, loss = 1.2531
2024-10-29 12:59:53: [2024-10-29 12:59:53] iter = 18110, loss = 1.2454
2024-10-29 12:59:53: [2024-10-29 12:59:53] iter = 18120, loss = 0.9716
2024-10-29 12:59:53: [2024-10-29 12:59:53] iter = 18130, loss = 1.4087
2024-10-29 12:59:54: [2024-10-29 12:59:54] iter = 18140, loss = 1.6638
2024-10-29 12:59:54: [2024-10-29 12:59:54] iter = 18150, loss = 1.3591
2024-10-29 12:59:54: [2024-10-29 12:59:54] iter = 18160, loss = 1.6395
2024-10-29 12:59:55: [2024-10-29 12:59:55] iter = 18170, loss = 1.5312
2024-10-29 12:59:55: [2024-10-29 12:59:55] iter = 18180, loss = 1.2692
2024-10-29 12:59:55: [2024-10-29 12:59:55] iter = 18190, loss = 2.9565
2024-10-29 12:59:56: [2024-10-29 12:59:56] iter = 18200, loss = 0.9231
2024-10-29 12:59:56: [2024-10-29 12:59:56] iter = 18210, loss = 0.8110
2024-10-29 12:59:57: [2024-10-29 12:59:57] iter = 18220, loss = 1.5848
2024-10-29 12:59:57: [2024-10-29 12:59:57] iter = 18230, loss = 1.3104
2024-10-29 12:59:58: [2024-10-29 12:59:58] iter = 18240, loss = 1.0364
2024-10-29 12:59:58: [2024-10-29 12:59:58] iter = 18250, loss = 1.0297
2024-10-29 12:59:58: [2024-10-29 12:59:58] iter = 18260, loss = 1.0023
2024-10-29 12:59:59: [2024-10-29 12:59:59] iter = 18270, loss = 1.1282
2024-10-29 13:00:00: [2024-10-29 13:00:00] iter = 18280, loss = 0.9287
2024-10-29 13:00:00: [2024-10-29 13:00:00] iter = 18290, loss = 1.2665
2024-10-29 13:00:01: [2024-10-29 13:00:01] iter = 18300, loss = 0.8915
2024-10-29 13:00:01: [2024-10-29 13:00:01] iter = 18310, loss = 0.8911
2024-10-29 13:00:01: [2024-10-29 13:00:01] iter = 18320, loss = 0.8933
2024-10-29 13:00:02: [2024-10-29 13:00:02] iter = 18330, loss = 3.2327
2024-10-29 13:00:02: [2024-10-29 13:00:02] iter = 18340, loss = 4.8728
2024-10-29 13:00:03: [2024-10-29 13:00:03] iter = 18350, loss = 1.6843
2024-10-29 13:00:03: [2024-10-29 13:00:03] iter = 18360, loss = 0.7117
2024-10-29 13:00:03: [2024-10-29 13:00:03] iter = 18370, loss = 1.8403
2024-10-29 13:00:04: [2024-10-29 13:00:04] iter = 18380, loss = 1.0757
2024-10-29 13:00:04: [2024-10-29 13:00:04] iter = 18390, loss = 9.1182
2024-10-29 13:00:04: [2024-10-29 13:00:04] iter = 18400, loss = 0.9768
2024-10-29 13:00:05: [2024-10-29 13:00:05] iter = 18410, loss = 1.2590
2024-10-29 13:00:05: [2024-10-29 13:00:05] iter = 18420, loss = 0.8500
2024-10-29 13:00:05: [2024-10-29 13:00:05] iter = 18430, loss = 0.8858
2024-10-29 13:00:06: [2024-10-29 13:00:06] iter = 18440, loss = 2.0491
2024-10-29 13:00:07: [2024-10-29 13:00:07] iter = 18450, loss = 3.9891
2024-10-29 13:00:07: [2024-10-29 13:00:07] iter = 18460, loss = 1.0808
2024-10-29 13:00:07: [2024-10-29 13:00:07] iter = 18470, loss = 1.2341
2024-10-29 13:00:08: [2024-10-29 13:00:08] iter = 18480, loss = 1.8913
2024-10-29 13:00:08: [2024-10-29 13:00:08] iter = 18490, loss = 1.0584
2024-10-29 13:00:08: [2024-10-29 13:00:08] iter = 18500, loss = 1.2777
2024-10-29 13:00:09: [2024-10-29 13:00:09] iter = 18510, loss = 1.5052
2024-10-29 13:00:09: [2024-10-29 13:00:09] iter = 18520, loss = 0.9476
2024-10-29 13:00:10: [2024-10-29 13:00:10] iter = 18530, loss = 1.3598
2024-10-29 13:00:10: [2024-10-29 13:00:10] iter = 18540, loss = 0.8540
2024-10-29 13:00:11: [2024-10-29 13:00:11] iter = 18550, loss = 1.1655
2024-10-29 13:00:11: [2024-10-29 13:00:11] iter = 18560, loss = 1.1550
2024-10-29 13:00:11: [2024-10-29 13:00:11] iter = 18570, loss = 1.0679
2024-10-29 13:00:12: [2024-10-29 13:00:12] iter = 18580, loss = 5.2118
2024-10-29 13:00:12: [2024-10-29 13:00:12] iter = 18590, loss = 1.5670
2024-10-29 13:00:12: [2024-10-29 13:00:12] iter = 18600, loss = 0.7196
2024-10-29 13:00:13: [2024-10-29 13:00:13] iter = 18610, loss = 2.2440
2024-10-29 13:00:13: [2024-10-29 13:00:13] iter = 18620, loss = 1.2715
2024-10-29 13:00:13: [2024-10-29 13:00:13] iter = 18630, loss = 2.8227
2024-10-29 13:00:14: [2024-10-29 13:00:14] iter = 18640, loss = 0.7490
2024-10-29 13:00:14: [2024-10-29 13:00:14] iter = 18650, loss = 0.9570
2024-10-29 13:00:14: [2024-10-29 13:00:14] iter = 18660, loss = 1.2879
2024-10-29 13:00:15: [2024-10-29 13:00:15] iter = 18670, loss = 1.3582
2024-10-29 13:00:15: [2024-10-29 13:00:15] iter = 18680, loss = 1.1779
2024-10-29 13:00:16: [2024-10-29 13:00:16] iter = 18690, loss = 1.7420
2024-10-29 13:00:16: [2024-10-29 13:00:16] iter = 18700, loss = 1.1731
2024-10-29 13:00:16: [2024-10-29 13:00:16] iter = 18710, loss = 0.6642
2024-10-29 13:00:17: [2024-10-29 13:00:17] iter = 18720, loss = 0.7498
2024-10-29 13:00:17: [2024-10-29 13:00:17] iter = 18730, loss = 1.3295
2024-10-29 13:00:18: [2024-10-29 13:00:18] iter = 18740, loss = 1.1749
2024-10-29 13:00:18: [2024-10-29 13:00:18] iter = 18750, loss = 1.6930
2024-10-29 13:00:18: [2024-10-29 13:00:18] iter = 18760, loss = 1.0964
2024-10-29 13:00:19: [2024-10-29 13:00:19] iter = 18770, loss = 1.4017
2024-10-29 13:00:19: [2024-10-29 13:00:19] iter = 18780, loss = 0.7879
2024-10-29 13:00:19: [2024-10-29 13:00:19] iter = 18790, loss = 1.2104
2024-10-29 13:00:20: [2024-10-29 13:00:20] iter = 18800, loss = 0.9958
2024-10-29 13:00:20: [2024-10-29 13:00:20] iter = 18810, loss = 1.2123
2024-10-29 13:00:20: [2024-10-29 13:00:20] iter = 18820, loss = 0.9286
2024-10-29 13:00:21: [2024-10-29 13:00:21] iter = 18830, loss = 1.3334
2024-10-29 13:00:21: [2024-10-29 13:00:21] iter = 18840, loss = 1.2448
2024-10-29 13:00:21: [2024-10-29 13:00:21] iter = 18850, loss = 2.0737
2024-10-29 13:00:22: [2024-10-29 13:00:22] iter = 18860, loss = 1.1125
2024-10-29 13:00:22: [2024-10-29 13:00:22] iter = 18870, loss = 0.6534
2024-10-29 13:00:22: [2024-10-29 13:00:22] iter = 18880, loss = 2.3307
2024-10-29 13:00:23: [2024-10-29 13:00:23] iter = 18890, loss = 1.3584
2024-10-29 13:00:23: [2024-10-29 13:00:23] iter = 18900, loss = 1.1117
2024-10-29 13:00:23: [2024-10-29 13:00:23] iter = 18910, loss = 0.9672
2024-10-29 13:00:24: [2024-10-29 13:00:24] iter = 18920, loss = 1.1470
2024-10-29 13:00:24: [2024-10-29 13:00:24] iter = 18930, loss = 1.5786
2024-10-29 13:00:24: [2024-10-29 13:00:24] iter = 18940, loss = 1.2279
2024-10-29 13:00:25: [2024-10-29 13:00:25] iter = 18950, loss = 1.6082
2024-10-29 13:00:25: [2024-10-29 13:00:25] iter = 18960, loss = 1.0949
2024-10-29 13:00:25: [2024-10-29 13:00:25] iter = 18970, loss = 2.0186
2024-10-29 13:00:26: [2024-10-29 13:00:26] iter = 18980, loss = 1.0462
2024-10-29 13:00:26: [2024-10-29 13:00:26] iter = 18990, loss = 1.0656
2024-10-29 13:00:27: [2024-10-29 13:00:27] iter = 19000, loss = 1.2308
2024-10-29 13:00:27: [2024-10-29 13:00:27] iter = 19010, loss = 1.4160
2024-10-29 13:00:28: [2024-10-29 13:00:28] iter = 19020, loss = 1.7128
2024-10-29 13:00:28: [2024-10-29 13:00:28] iter = 19030, loss = 1.2826
2024-10-29 13:00:28: [2024-10-29 13:00:28] iter = 19040, loss = 1.1021
2024-10-29 13:00:29: [2024-10-29 13:00:29] iter = 19050, loss = 0.9603
2024-10-29 13:00:29: [2024-10-29 13:00:29] iter = 19060, loss = 4.1397
2024-10-29 13:00:29: [2024-10-29 13:00:29] iter = 19070, loss = 4.5208
2024-10-29 13:00:30: [2024-10-29 13:00:30] iter = 19080, loss = 1.7962
2024-10-29 13:00:30: [2024-10-29 13:00:30] iter = 19090, loss = 4.2709
2024-10-29 13:00:30: [2024-10-29 13:00:30] iter = 19100, loss = 1.3253
2024-10-29 13:00:31: [2024-10-29 13:00:31] iter = 19110, loss = 0.7020
2024-10-29 13:00:31: [2024-10-29 13:00:31] iter = 19120, loss = 2.4491
2024-10-29 13:00:31: [2024-10-29 13:00:31] iter = 19130, loss = 1.2506
2024-10-29 13:00:32: [2024-10-29 13:00:32] iter = 19140, loss = 0.9678
2024-10-29 13:00:32: [2024-10-29 13:00:32] iter = 19150, loss = 1.0077
2024-10-29 13:00:32: [2024-10-29 13:00:32] iter = 19160, loss = 0.6546
2024-10-29 13:00:33: [2024-10-29 13:00:33] iter = 19170, loss = 2.0083
2024-10-29 13:00:33: [2024-10-29 13:00:33] iter = 19180, loss = 3.6235
2024-10-29 13:00:33: [2024-10-29 13:00:33] iter = 19190, loss = 4.8627
2024-10-29 13:00:34: [2024-10-29 13:00:34] iter = 19200, loss = 1.5603
2024-10-29 13:00:34: [2024-10-29 13:00:34] iter = 19210, loss = 0.7538
2024-10-29 13:00:34: [2024-10-29 13:00:34] iter = 19220, loss = 0.7774
2024-10-29 13:00:35: [2024-10-29 13:00:35] iter = 19230, loss = 0.6397
2024-10-29 13:00:35: [2024-10-29 13:00:35] iter = 19240, loss = 1.1148
2024-10-29 13:00:35: [2024-10-29 13:00:35] iter = 19250, loss = 0.9121
2024-10-29 13:00:36: [2024-10-29 13:00:36] iter = 19260, loss = 0.9519
2024-10-29 13:00:36: [2024-10-29 13:00:36] iter = 19270, loss = 2.5954
2024-10-29 13:00:36: [2024-10-29 13:00:36] iter = 19280, loss = 1.1159
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 19290, loss = 1.9062
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 19300, loss = 2.1537
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 19310, loss = 1.6870
2024-10-29 13:00:38: [2024-10-29 13:00:38] iter = 19320, loss = 1.2504
2024-10-29 13:00:38: [2024-10-29 13:00:38] iter = 19330, loss = 1.3987
2024-10-29 13:00:38: [2024-10-29 13:00:38] iter = 19340, loss = 1.1803
2024-10-29 13:00:39: [2024-10-29 13:00:39] iter = 19350, loss = 2.1729
2024-10-29 13:00:39: [2024-10-29 13:00:39] iter = 19360, loss = 1.7180
2024-10-29 13:00:39: [2024-10-29 13:00:39] iter = 19370, loss = 1.4176
2024-10-29 13:00:40: [2024-10-29 13:00:40] iter = 19380, loss = 1.4517
2024-10-29 13:00:40: [2024-10-29 13:00:40] iter = 19390, loss = 0.8775
2024-10-29 13:00:40: [2024-10-29 13:00:40] iter = 19400, loss = 1.2816
2024-10-29 13:00:41: [2024-10-29 13:00:41] iter = 19410, loss = 1.4226
2024-10-29 13:00:41: [2024-10-29 13:00:41] iter = 19420, loss = 8.5987
2024-10-29 13:00:41: [2024-10-29 13:00:41] iter = 19430, loss = 1.6856
2024-10-29 13:00:42: [2024-10-29 13:00:42] iter = 19440, loss = 1.4109
2024-10-29 13:00:42: [2024-10-29 13:00:42] iter = 19450, loss = 1.4799
2024-10-29 13:00:43: [2024-10-29 13:00:43] iter = 19460, loss = 2.0741
2024-10-29 13:00:43: [2024-10-29 13:00:43] iter = 19470, loss = 1.4095
2024-10-29 13:00:44: [2024-10-29 13:00:44] iter = 19480, loss = 0.8886
2024-10-29 13:00:44: [2024-10-29 13:00:44] iter = 19490, loss = 1.0391
2024-10-29 13:00:44: [2024-10-29 13:00:44] iter = 19500, loss = 0.8431
2024-10-29 13:00:45: [2024-10-29 13:00:45] iter = 19510, loss = 1.8177
2024-10-29 13:00:46: [2024-10-29 13:00:46] iter = 19520, loss = 1.4959
2024-10-29 13:00:46: [2024-10-29 13:00:46] iter = 19530, loss = 0.7988
2024-10-29 13:00:47: [2024-10-29 13:00:47] iter = 19540, loss = 1.0126
2024-10-29 13:00:47: [2024-10-29 13:00:47] iter = 19550, loss = 2.2250
2024-10-29 13:00:48: [2024-10-29 13:00:48] iter = 19560, loss = 1.3058
2024-10-29 13:00:48: [2024-10-29 13:00:48] iter = 19570, loss = 1.4606
2024-10-29 13:00:48: [2024-10-29 13:00:48] iter = 19580, loss = 1.6543
2024-10-29 13:00:49: [2024-10-29 13:00:49] iter = 19590, loss = 1.0648
2024-10-29 13:00:49: [2024-10-29 13:00:49] iter = 19600, loss = 1.3417
2024-10-29 13:00:49: [2024-10-29 13:00:49] iter = 19610, loss = 1.2414
2024-10-29 13:00:50: [2024-10-29 13:00:50] iter = 19620, loss = 1.4394
2024-10-29 13:00:50: [2024-10-29 13:00:50] iter = 19630, loss = 2.3971
2024-10-29 13:00:50: [2024-10-29 13:00:50] iter = 19640, loss = 2.5467
2024-10-29 13:00:51: [2024-10-29 13:00:51] iter = 19650, loss = 1.7783
2024-10-29 13:00:51: [2024-10-29 13:00:51] iter = 19660, loss = 1.1443
2024-10-29 13:00:51: [2024-10-29 13:00:51] iter = 19670, loss = 1.3130
2024-10-29 13:00:52: [2024-10-29 13:00:52] iter = 19680, loss = 1.0012
2024-10-29 13:00:52: [2024-10-29 13:00:52] iter = 19690, loss = 1.1193
2024-10-29 13:00:52: [2024-10-29 13:00:52] iter = 19700, loss = 1.8829
2024-10-29 13:00:53: [2024-10-29 13:00:53] iter = 19710, loss = 0.7748
2024-10-29 13:00:53: [2024-10-29 13:00:53] iter = 19720, loss = 4.2248
2024-10-29 13:00:53: [2024-10-29 13:00:53] iter = 19730, loss = 0.6692
2024-10-29 13:00:54: [2024-10-29 13:00:54] iter = 19740, loss = 1.1117
2024-10-29 13:00:54: [2024-10-29 13:00:54] iter = 19750, loss = 0.8660
2024-10-29 13:00:54: [2024-10-29 13:00:54] iter = 19760, loss = 0.7179
2024-10-29 13:00:55: [2024-10-29 13:00:55] iter = 19770, loss = 0.7850
2024-10-29 13:00:55: [2024-10-29 13:00:55] iter = 19780, loss = 1.4694
2024-10-29 13:00:55: [2024-10-29 13:00:55] iter = 19790, loss = 0.8941
2024-10-29 13:00:55: [2024-10-29 13:00:55] iter = 19800, loss = 2.0991
2024-10-29 13:00:56: [2024-10-29 13:00:56] iter = 19810, loss = 1.1647
2024-10-29 13:00:56: [2024-10-29 13:00:56] iter = 19820, loss = 1.1948
2024-10-29 13:00:57: [2024-10-29 13:00:57] iter = 19830, loss = 2.2499
2024-10-29 13:00:57: [2024-10-29 13:00:57] iter = 19840, loss = 1.1096
2024-10-29 13:00:58: [2024-10-29 13:00:58] iter = 19850, loss = 1.2049
2024-10-29 13:00:58: [2024-10-29 13:00:58] iter = 19860, loss = 1.1629
2024-10-29 13:00:58: [2024-10-29 13:00:58] iter = 19870, loss = 2.4773
2024-10-29 13:00:59: [2024-10-29 13:00:59] iter = 19880, loss = 0.6756
2024-10-29 13:00:59: [2024-10-29 13:00:59] iter = 19890, loss = 2.3906
2024-10-29 13:00:59: [2024-10-29 13:00:59] iter = 19900, loss = 1.3079
2024-10-29 13:01:00: [2024-10-29 13:01:00] iter = 19910, loss = 3.3841
2024-10-29 13:01:00: [2024-10-29 13:01:00] iter = 19920, loss = 1.3949
2024-10-29 13:01:00: [2024-10-29 13:01:00] iter = 19930, loss = 1.3683
2024-10-29 13:01:01: [2024-10-29 13:01:01] iter = 19940, loss = 1.5703
2024-10-29 13:01:01: [2024-10-29 13:01:01] iter = 19950, loss = 6.3616
2024-10-29 13:01:01: [2024-10-29 13:01:01] iter = 19960, loss = 1.3643
2024-10-29 13:01:02: [2024-10-29 13:01:02] iter = 19970, loss = 1.0767
2024-10-29 13:01:02: [2024-10-29 13:01:02] iter = 19980, loss = 0.9138
2024-10-29 13:01:02: [2024-10-29 13:01:02] iter = 19990, loss = 1.2100
2024-10-29 13:01:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:01:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:01:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63152}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:01:33: Evaluate 5 random ConvNet, ACCmean = 0.6228 ACCstd = 0.0249
-------------------------
2024-10-29 13:01:33: Evaluate 5 random ConvNet, SENmean = 0.6065 SENstd = 0.0044
-------------------------
2024-10-29 13:01:33: Evaluate 5 random ConvNet, SPEmean = 0.6065 SPEstd = 0.0044
-------------------------
2024-10-29 13:01:33: Evaluate 5 random ConvNet, F!mean = 0.4992 F!std = 0.0110
-------------------------
2024-10-29 13:01:33: Evaluate 5 random ConvNet, mean = 0.6228 std = 0.0249
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:01:33: [2024-10-29 13:01:33] iter = 20000, loss = 0.8618
2024-10-29 13:01:33: 
================== Exp 2 ==================
 
2024-10-29 13:01:33: Hyper-parameters: 
{'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f20047a2730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_ChestMNIST (INFO)>}
2024-10-29 13:01:33: Evaluation model pool: ['ConvNet']
2024-10-29 13:01:36: class c = 0: 70472 real images
2024-10-29 13:01:36: class c = 1: 7996 real images
2024-10-29 13:01:36: real images channel 0, mean = 0.4936, std = 0.2380
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 13:01:36: initialize synthetic data from random real images
2024-10-29 13:01:36: [2024-10-29 13:01:36] training begins
2024-10-29 13:01:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 13:01:36: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:01:36: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 93298}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:02:03: Evaluate 5 random ConvNet, ACCmean = 0.3989 ACCstd = 0.0137
-------------------------
2024-10-29 13:02:03: Evaluate 5 random ConvNet, SENmean = 0.5184 SENstd = 0.0018
-------------------------
2024-10-29 13:02:03: Evaluate 5 random ConvNet, SPEmean = 0.5184 SPEstd = 0.0018
-------------------------
2024-10-29 13:02:03: Evaluate 5 random ConvNet, F!mean = 0.3573 F!std = 0.0087
-------------------------
2024-10-29 13:02:03: Evaluate 5 random ConvNet, mean = 0.3989 std = 0.0137
-------------------------
2024-10-29 13:02:03: [2024-10-29 13:02:03] iter = 00000, loss = 7.2465
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:02:03: [2024-10-29 13:02:03] iter = 00010, loss = 2.9984
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:02:04: [2024-10-29 13:02:04] iter = 00020, loss = 1.4015
2024-10-29 13:02:04: [2024-10-29 13:02:04] iter = 00030, loss = 6.9794
2024-10-29 13:02:04: [2024-10-29 13:02:04] iter = 00040, loss = 2.9750
2024-10-29 13:02:05: [2024-10-29 13:02:05] iter = 00050, loss = 1.5965
2024-10-29 13:02:05: [2024-10-29 13:02:05] iter = 00060, loss = 1.1859
2024-10-29 13:02:05: [2024-10-29 13:02:05] iter = 00070, loss = 2.1722
2024-10-29 13:02:06: [2024-10-29 13:02:06] iter = 00080, loss = 1.2832
2024-10-29 13:02:06: [2024-10-29 13:02:06] iter = 00090, loss = 1.0961
2024-10-29 13:02:06: [2024-10-29 13:02:06] iter = 00100, loss = 1.5562
2024-10-29 13:02:07: [2024-10-29 13:02:07] iter = 00110, loss = 1.0895
2024-10-29 13:02:07: [2024-10-29 13:02:07] iter = 00120, loss = 1.5813
2024-10-29 13:02:07: [2024-10-29 13:02:07] iter = 00130, loss = 1.7359
2024-10-29 13:02:08: [2024-10-29 13:02:08] iter = 00140, loss = 1.6959
2024-10-29 13:02:08: [2024-10-29 13:02:08] iter = 00150, loss = 1.1312
2024-10-29 13:02:08: [2024-10-29 13:02:08] iter = 00160, loss = 1.5304
2024-10-29 13:02:09: [2024-10-29 13:02:09] iter = 00170, loss = 1.9780
2024-10-29 13:02:09: [2024-10-29 13:02:09] iter = 00180, loss = 1.5679
2024-10-29 13:02:09: [2024-10-29 13:02:09] iter = 00190, loss = 1.3027
2024-10-29 13:02:10: [2024-10-29 13:02:10] iter = 00200, loss = 1.5514
2024-10-29 13:02:10: [2024-10-29 13:02:10] iter = 00210, loss = 2.1580
2024-10-29 13:02:10: [2024-10-29 13:02:10] iter = 00220, loss = 2.4409
2024-10-29 13:02:11: [2024-10-29 13:02:11] iter = 00230, loss = 3.4879
2024-10-29 13:02:11: [2024-10-29 13:02:11] iter = 00240, loss = 1.5393
2024-10-29 13:02:11: [2024-10-29 13:02:11] iter = 00250, loss = 1.3484
2024-10-29 13:02:12: [2024-10-29 13:02:12] iter = 00260, loss = 2.3333
2024-10-29 13:02:12: [2024-10-29 13:02:12] iter = 00270, loss = 1.8337
2024-10-29 13:02:12: [2024-10-29 13:02:12] iter = 00280, loss = 2.1997
2024-10-29 13:02:13: [2024-10-29 13:02:13] iter = 00290, loss = 1.6110
2024-10-29 13:02:13: [2024-10-29 13:02:13] iter = 00300, loss = 5.1192
2024-10-29 13:02:13: [2024-10-29 13:02:13] iter = 00310, loss = 2.6656
2024-10-29 13:02:14: [2024-10-29 13:02:14] iter = 00320, loss = 1.2141
2024-10-29 13:02:14: [2024-10-29 13:02:14] iter = 00330, loss = 5.0624
2024-10-29 13:02:14: [2024-10-29 13:02:14] iter = 00340, loss = 2.5590
2024-10-29 13:02:15: [2024-10-29 13:02:15] iter = 00350, loss = 5.2567
2024-10-29 13:02:15: [2024-10-29 13:02:15] iter = 00360, loss = 1.0426
2024-10-29 13:02:15: [2024-10-29 13:02:15] iter = 00370, loss = 2.2395
2024-10-29 13:02:16: [2024-10-29 13:02:16] iter = 00380, loss = 2.3994
2024-10-29 13:02:17: [2024-10-29 13:02:17] iter = 00390, loss = 2.3745
2024-10-29 13:02:17: [2024-10-29 13:02:17] iter = 00400, loss = 1.7595
2024-10-29 13:02:18: [2024-10-29 13:02:18] iter = 00410, loss = 2.3075
2024-10-29 13:02:18: [2024-10-29 13:02:18] iter = 00420, loss = 1.3525
2024-10-29 13:02:18: [2024-10-29 13:02:18] iter = 00430, loss = 0.8891
2024-10-29 13:02:19: [2024-10-29 13:02:19] iter = 00440, loss = 2.3813
2024-10-29 13:02:19: [2024-10-29 13:02:19] iter = 00450, loss = 1.2972
2024-10-29 13:02:20: [2024-10-29 13:02:20] iter = 00460, loss = 1.6284
2024-10-29 13:02:20: [2024-10-29 13:02:20] iter = 00470, loss = 1.2447
2024-10-29 13:02:20: [2024-10-29 13:02:20] iter = 00480, loss = 2.2508
2024-10-29 13:02:21: [2024-10-29 13:02:21] iter = 00490, loss = 1.0020
2024-10-29 13:02:21: [2024-10-29 13:02:21] iter = 00500, loss = 1.2587
2024-10-29 13:02:21: [2024-10-29 13:02:21] iter = 00510, loss = 7.0796
2024-10-29 13:02:22: [2024-10-29 13:02:22] iter = 00520, loss = 1.3491
2024-10-29 13:02:22: [2024-10-29 13:02:22] iter = 00530, loss = 1.4096
2024-10-29 13:02:22: [2024-10-29 13:02:22] iter = 00540, loss = 1.2657
2024-10-29 13:02:23: [2024-10-29 13:02:23] iter = 00550, loss = 1.3853
2024-10-29 13:02:23: [2024-10-29 13:02:23] iter = 00560, loss = 4.2368
2024-10-29 13:02:23: [2024-10-29 13:02:23] iter = 00570, loss = 0.9981
2024-10-29 13:02:24: [2024-10-29 13:02:24] iter = 00580, loss = 2.7918
2024-10-29 13:02:24: [2024-10-29 13:02:24] iter = 00590, loss = 0.7848
2024-10-29 13:02:24: [2024-10-29 13:02:24] iter = 00600, loss = 1.3275
2024-10-29 13:02:25: [2024-10-29 13:02:25] iter = 00610, loss = 8.1010
2024-10-29 13:02:25: [2024-10-29 13:02:25] iter = 00620, loss = 1.2984
2024-10-29 13:02:26: [2024-10-29 13:02:26] iter = 00630, loss = 1.9921
2024-10-29 13:02:26: [2024-10-29 13:02:26] iter = 00640, loss = 1.4503
2024-10-29 13:02:26: [2024-10-29 13:02:26] iter = 00650, loss = 1.3176
2024-10-29 13:02:27: [2024-10-29 13:02:27] iter = 00660, loss = 2.2278
2024-10-29 13:02:27: [2024-10-29 13:02:27] iter = 00670, loss = 2.9104
2024-10-29 13:02:27: [2024-10-29 13:02:27] iter = 00680, loss = 1.5766
2024-10-29 13:02:28: [2024-10-29 13:02:28] iter = 00690, loss = 1.3050
2024-10-29 13:02:28: [2024-10-29 13:02:28] iter = 00700, loss = 1.3948
2024-10-29 13:02:29: [2024-10-29 13:02:29] iter = 00710, loss = 1.4175
2024-10-29 13:02:30: [2024-10-29 13:02:30] iter = 00720, loss = 3.1041
2024-10-29 13:02:30: [2024-10-29 13:02:30] iter = 00730, loss = 1.7572
2024-10-29 13:02:31: [2024-10-29 13:02:31] iter = 00740, loss = 1.0410
2024-10-29 13:02:31: [2024-10-29 13:02:31] iter = 00750, loss = 1.4484
2024-10-29 13:02:32: [2024-10-29 13:02:32] iter = 00760, loss = 0.9197
2024-10-29 13:02:32: [2024-10-29 13:02:32] iter = 00770, loss = 1.2389
2024-10-29 13:02:33: [2024-10-29 13:02:33] iter = 00780, loss = 1.1486
2024-10-29 13:02:33: [2024-10-29 13:02:33] iter = 00790, loss = 1.8590
2024-10-29 13:02:34: [2024-10-29 13:02:34] iter = 00800, loss = 1.6948
2024-10-29 13:02:34: [2024-10-29 13:02:34] iter = 00810, loss = 1.0665
2024-10-29 13:02:35: [2024-10-29 13:02:35] iter = 00820, loss = 1.9933
2024-10-29 13:02:35: [2024-10-29 13:02:35] iter = 00830, loss = 0.9775
2024-10-29 13:02:36: [2024-10-29 13:02:36] iter = 00840, loss = 0.6856
2024-10-29 13:02:36: [2024-10-29 13:02:36] iter = 00850, loss = 1.5493
2024-10-29 13:02:36: [2024-10-29 13:02:36] iter = 00860, loss = 1.9601
2024-10-29 13:02:37: [2024-10-29 13:02:37] iter = 00870, loss = 2.8141
2024-10-29 13:02:37: [2024-10-29 13:02:37] iter = 00880, loss = 0.9043
2024-10-29 13:02:37: [2024-10-29 13:02:37] iter = 00890, loss = 1.0718
2024-10-29 13:02:38: [2024-10-29 13:02:38] iter = 00900, loss = 1.5931
2024-10-29 13:02:38: [2024-10-29 13:02:38] iter = 00910, loss = 1.7655
2024-10-29 13:02:38: [2024-10-29 13:02:38] iter = 00920, loss = 1.5903
2024-10-29 13:02:39: [2024-10-29 13:02:39] iter = 00930, loss = 1.7993
2024-10-29 13:02:39: [2024-10-29 13:02:39] iter = 00940, loss = 1.0799
2024-10-29 13:02:39: [2024-10-29 13:02:39] iter = 00950, loss = 1.0686
2024-10-29 13:02:40: [2024-10-29 13:02:40] iter = 00960, loss = 1.1293
2024-10-29 13:02:40: [2024-10-29 13:02:40] iter = 00970, loss = 1.2377
2024-10-29 13:02:40: [2024-10-29 13:02:40] iter = 00980, loss = 8.1557
2024-10-29 13:02:41: [2024-10-29 13:02:41] iter = 00990, loss = 1.1391
2024-10-29 13:02:41: [2024-10-29 13:02:41] iter = 01000, loss = 1.6068
2024-10-29 13:02:41: [2024-10-29 13:02:41] iter = 01010, loss = 1.2184
2024-10-29 13:02:42: [2024-10-29 13:02:42] iter = 01020, loss = 1.5043
2024-10-29 13:02:42: [2024-10-29 13:02:42] iter = 01030, loss = 2.3075
2024-10-29 13:02:42: [2024-10-29 13:02:42] iter = 01040, loss = 1.7916
2024-10-29 13:02:43: [2024-10-29 13:02:43] iter = 01050, loss = 2.6132
2024-10-29 13:02:43: [2024-10-29 13:02:43] iter = 01060, loss = 1.2144
2024-10-29 13:02:44: [2024-10-29 13:02:44] iter = 01070, loss = 2.9312
2024-10-29 13:02:44: [2024-10-29 13:02:44] iter = 01080, loss = 2.5685
2024-10-29 13:02:44: [2024-10-29 13:02:44] iter = 01090, loss = 1.6008
2024-10-29 13:02:45: [2024-10-29 13:02:45] iter = 01100, loss = 4.1871
2024-10-29 13:02:45: [2024-10-29 13:02:45] iter = 01110, loss = 1.0290
2024-10-29 13:02:45: [2024-10-29 13:02:45] iter = 01120, loss = 1.1746
2024-10-29 13:02:46: [2024-10-29 13:02:46] iter = 01130, loss = 1.4814
2024-10-29 13:02:46: [2024-10-29 13:02:46] iter = 01140, loss = 0.7684
2024-10-29 13:02:46: [2024-10-29 13:02:46] iter = 01150, loss = 1.1237
2024-10-29 13:02:47: [2024-10-29 13:02:47] iter = 01160, loss = 1.4207
2024-10-29 13:02:47: [2024-10-29 13:02:47] iter = 01170, loss = 1.0033
2024-10-29 13:02:47: [2024-10-29 13:02:47] iter = 01180, loss = 1.3042
2024-10-29 13:02:48: [2024-10-29 13:02:48] iter = 01190, loss = 1.9732
2024-10-29 13:02:48: [2024-10-29 13:02:48] iter = 01200, loss = 1.6620
2024-10-29 13:02:48: [2024-10-29 13:02:48] iter = 01210, loss = 1.2486
2024-10-29 13:02:49: [2024-10-29 13:02:48] iter = 01220, loss = 1.3588
2024-10-29 13:02:49: [2024-10-29 13:02:49] iter = 01230, loss = 1.7197
2024-10-29 13:02:49: [2024-10-29 13:02:49] iter = 01240, loss = 0.9937
2024-10-29 13:02:49: [2024-10-29 13:02:49] iter = 01250, loss = 1.3709
2024-10-29 13:02:50: [2024-10-29 13:02:50] iter = 01260, loss = 0.7889
2024-10-29 13:02:50: [2024-10-29 13:02:50] iter = 01270, loss = 1.0002
2024-10-29 13:02:51: [2024-10-29 13:02:50] iter = 01280, loss = 0.9360
2024-10-29 13:02:51: [2024-10-29 13:02:51] iter = 01290, loss = 1.8632
2024-10-29 13:02:51: [2024-10-29 13:02:51] iter = 01300, loss = 1.4563
2024-10-29 13:02:51: [2024-10-29 13:02:51] iter = 01310, loss = 1.9120
2024-10-29 13:02:52: [2024-10-29 13:02:52] iter = 01320, loss = 1.2111
2024-10-29 13:02:52: [2024-10-29 13:02:52] iter = 01330, loss = 1.2687
2024-10-29 13:02:52: [2024-10-29 13:02:52] iter = 01340, loss = 3.1789
2024-10-29 13:02:53: [2024-10-29 13:02:53] iter = 01350, loss = 0.9095
2024-10-29 13:02:53: [2024-10-29 13:02:53] iter = 01360, loss = 1.6078
2024-10-29 13:02:53: [2024-10-29 13:02:53] iter = 01370, loss = 2.4441
2024-10-29 13:02:54: [2024-10-29 13:02:54] iter = 01380, loss = 2.0534
2024-10-29 13:02:54: [2024-10-29 13:02:54] iter = 01390, loss = 2.0806
2024-10-29 13:02:54: [2024-10-29 13:02:54] iter = 01400, loss = 3.0519
2024-10-29 13:02:55: [2024-10-29 13:02:55] iter = 01410, loss = 1.6589
2024-10-29 13:02:55: [2024-10-29 13:02:55] iter = 01420, loss = 2.1615
2024-10-29 13:02:55: [2024-10-29 13:02:55] iter = 01430, loss = 1.8879
2024-10-29 13:02:56: [2024-10-29 13:02:56] iter = 01440, loss = 2.5637
2024-10-29 13:02:56: [2024-10-29 13:02:56] iter = 01450, loss = 2.3274
2024-10-29 13:02:56: [2024-10-29 13:02:56] iter = 01460, loss = 1.8756
2024-10-29 13:02:57: [2024-10-29 13:02:57] iter = 01470, loss = 1.5291
2024-10-29 13:02:57: [2024-10-29 13:02:57] iter = 01480, loss = 3.5318
2024-10-29 13:02:57: [2024-10-29 13:02:57] iter = 01490, loss = 1.3439
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 01500, loss = 3.2393
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 01510, loss = 1.1045
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 01520, loss = 1.3750
2024-10-29 13:02:59: [2024-10-29 13:02:59] iter = 01530, loss = 1.2104
2024-10-29 13:02:59: [2024-10-29 13:02:59] iter = 01540, loss = 1.3319
2024-10-29 13:02:59: [2024-10-29 13:02:59] iter = 01550, loss = 2.8602
2024-10-29 13:03:00: [2024-10-29 13:03:00] iter = 01560, loss = 0.9378
2024-10-29 13:03:00: [2024-10-29 13:03:00] iter = 01570, loss = 0.7342
2024-10-29 13:03:00: [2024-10-29 13:03:00] iter = 01580, loss = 1.4714
2024-10-29 13:03:01: [2024-10-29 13:03:01] iter = 01590, loss = 1.1558
2024-10-29 13:03:01: [2024-10-29 13:03:01] iter = 01600, loss = 1.1702
2024-10-29 13:03:01: [2024-10-29 13:03:01] iter = 01610, loss = 1.0790
2024-10-29 13:03:02: [2024-10-29 13:03:02] iter = 01620, loss = 0.7195
2024-10-29 13:03:02: [2024-10-29 13:03:02] iter = 01630, loss = 1.5123
2024-10-29 13:03:02: [2024-10-29 13:03:02] iter = 01640, loss = 1.3436
2024-10-29 13:03:03: [2024-10-29 13:03:03] iter = 01650, loss = 2.4374
2024-10-29 13:03:03: [2024-10-29 13:03:03] iter = 01660, loss = 1.0822
2024-10-29 13:03:04: [2024-10-29 13:03:04] iter = 01670, loss = 1.3401
2024-10-29 13:03:04: [2024-10-29 13:03:04] iter = 01680, loss = 1.7172
2024-10-29 13:03:05: [2024-10-29 13:03:05] iter = 01690, loss = 1.6131
2024-10-29 13:03:05: [2024-10-29 13:03:05] iter = 01700, loss = 1.3022
2024-10-29 13:03:06: [2024-10-29 13:03:06] iter = 01710, loss = 1.5817
2024-10-29 13:03:06: [2024-10-29 13:03:06] iter = 01720, loss = 1.2174
2024-10-29 13:03:06: [2024-10-29 13:03:06] iter = 01730, loss = 1.1511
2024-10-29 13:03:07: [2024-10-29 13:03:07] iter = 01740, loss = 2.1435
2024-10-29 13:03:08: [2024-10-29 13:03:08] iter = 01750, loss = 1.2287
2024-10-29 13:03:08: [2024-10-29 13:03:08] iter = 01760, loss = 1.2866
2024-10-29 13:03:08: [2024-10-29 13:03:08] iter = 01770, loss = 2.0760
2024-10-29 13:03:09: [2024-10-29 13:03:09] iter = 01780, loss = 1.1070
2024-10-29 13:03:09: [2024-10-29 13:03:09] iter = 01790, loss = 0.8628
2024-10-29 13:03:09: [2024-10-29 13:03:09] iter = 01800, loss = 1.3675
2024-10-29 13:03:10: [2024-10-29 13:03:10] iter = 01810, loss = 0.9283
2024-10-29 13:03:10: [2024-10-29 13:03:10] iter = 01820, loss = 2.9716
2024-10-29 13:03:10: [2024-10-29 13:03:10] iter = 01830, loss = 1.3939
2024-10-29 13:03:11: [2024-10-29 13:03:11] iter = 01840, loss = 1.7446
2024-10-29 13:03:11: [2024-10-29 13:03:11] iter = 01850, loss = 1.8570
2024-10-29 13:03:11: [2024-10-29 13:03:11] iter = 01860, loss = 1.6087
2024-10-29 13:03:12: [2024-10-29 13:03:12] iter = 01870, loss = 1.2334
2024-10-29 13:03:12: [2024-10-29 13:03:12] iter = 01880, loss = 1.4638
2024-10-29 13:03:12: [2024-10-29 13:03:12] iter = 01890, loss = 0.8779
2024-10-29 13:03:13: [2024-10-29 13:03:13] iter = 01900, loss = 1.7443
2024-10-29 13:03:13: [2024-10-29 13:03:13] iter = 01910, loss = 1.2934
2024-10-29 13:03:13: [2024-10-29 13:03:13] iter = 01920, loss = 1.9981
2024-10-29 13:03:14: [2024-10-29 13:03:14] iter = 01930, loss = 1.1944
2024-10-29 13:03:14: [2024-10-29 13:03:14] iter = 01940, loss = 1.4874
2024-10-29 13:03:14: [2024-10-29 13:03:14] iter = 01950, loss = 0.9876
2024-10-29 13:03:15: [2024-10-29 13:03:15] iter = 01960, loss = 1.2902
2024-10-29 13:03:15: [2024-10-29 13:03:15] iter = 01970, loss = 2.3582
2024-10-29 13:03:16: [2024-10-29 13:03:16] iter = 01980, loss = 1.1153
2024-10-29 13:03:16: [2024-10-29 13:03:16] iter = 01990, loss = 1.0483
2024-10-29 13:03:16: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 13:03:16: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:03:16: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 96900}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:03:44: Evaluate 5 random ConvNet, ACCmean = 0.5816 ACCstd = 0.0284
-------------------------
2024-10-29 13:03:44: Evaluate 5 random ConvNet, SENmean = 0.6108 SENstd = 0.0017
-------------------------
2024-10-29 13:03:44: Evaluate 5 random ConvNet, SPEmean = 0.6108 SPEstd = 0.0017
-------------------------
2024-10-29 13:03:44: Evaluate 5 random ConvNet, F!mean = 0.4799 F!std = 0.0154
-------------------------
2024-10-29 13:03:44: Evaluate 5 random ConvNet, mean = 0.5816 std = 0.0284
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:03:44: [2024-10-29 13:03:44] iter = 02000, loss = 0.9604
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:03:45: [2024-10-29 13:03:45] iter = 02010, loss = 1.1043
2024-10-29 13:03:45: [2024-10-29 13:03:45] iter = 02020, loss = 1.7949
2024-10-29 13:03:46: [2024-10-29 13:03:46] iter = 02030, loss = 3.0138
2024-10-29 13:03:46: [2024-10-29 13:03:46] iter = 02040, loss = 0.7720
2024-10-29 13:03:47: [2024-10-29 13:03:47] iter = 02050, loss = 1.3477
2024-10-29 13:03:47: [2024-10-29 13:03:47] iter = 02060, loss = 3.3735
2024-10-29 13:03:48: [2024-10-29 13:03:48] iter = 02070, loss = 1.1822
2024-10-29 13:03:49: [2024-10-29 13:03:49] iter = 02080, loss = 1.4336
2024-10-29 13:03:49: [2024-10-29 13:03:49] iter = 02090, loss = 1.4447
2024-10-29 13:03:50: [2024-10-29 13:03:50] iter = 02100, loss = 1.2079
2024-10-29 13:03:50: [2024-10-29 13:03:50] iter = 02110, loss = 1.3301
2024-10-29 13:03:51: [2024-10-29 13:03:51] iter = 02120, loss = 0.8170
2024-10-29 13:03:51: [2024-10-29 13:03:51] iter = 02130, loss = 6.2099
2024-10-29 13:03:51: [2024-10-29 13:03:51] iter = 02140, loss = 4.0767
2024-10-29 13:03:52: [2024-10-29 13:03:52] iter = 02150, loss = 3.2720
2024-10-29 13:03:52: [2024-10-29 13:03:52] iter = 02160, loss = 1.2113
2024-10-29 13:03:53: [2024-10-29 13:03:53] iter = 02170, loss = 1.3342
2024-10-29 13:03:53: [2024-10-29 13:03:53] iter = 02180, loss = 3.1299
2024-10-29 13:03:54: [2024-10-29 13:03:54] iter = 02190, loss = 2.5419
2024-10-29 13:03:54: [2024-10-29 13:03:54] iter = 02200, loss = 1.8887
2024-10-29 13:03:54: [2024-10-29 13:03:54] iter = 02210, loss = 0.8993
2024-10-29 13:03:55: [2024-10-29 13:03:55] iter = 02220, loss = 0.8629
2024-10-29 13:03:55: [2024-10-29 13:03:55] iter = 02230, loss = 1.5420
2024-10-29 13:03:55: [2024-10-29 13:03:55] iter = 02240, loss = 4.2794
2024-10-29 13:03:56: [2024-10-29 13:03:56] iter = 02250, loss = 2.6945
2024-10-29 13:03:56: [2024-10-29 13:03:56] iter = 02260, loss = 1.9392
2024-10-29 13:03:57: [2024-10-29 13:03:57] iter = 02270, loss = 1.0932
2024-10-29 13:03:57: [2024-10-29 13:03:57] iter = 02280, loss = 1.0988
2024-10-29 13:03:57: [2024-10-29 13:03:57] iter = 02290, loss = 1.3228
2024-10-29 13:03:58: [2024-10-29 13:03:58] iter = 02300, loss = 3.7447
2024-10-29 13:03:58: [2024-10-29 13:03:58] iter = 02310, loss = 1.5041
2024-10-29 13:03:58: [2024-10-29 13:03:58] iter = 02320, loss = 1.4708
2024-10-29 13:03:59: [2024-10-29 13:03:59] iter = 02330, loss = 0.9550
2024-10-29 13:03:59: [2024-10-29 13:03:59] iter = 02340, loss = 2.7928
2024-10-29 13:04:00: [2024-10-29 13:04:00] iter = 02350, loss = 1.2179
2024-10-29 13:04:00: [2024-10-29 13:04:00] iter = 02360, loss = 2.7793
2024-10-29 13:04:00: [2024-10-29 13:04:00] iter = 02370, loss = 1.9794
2024-10-29 13:04:01: [2024-10-29 13:04:01] iter = 02380, loss = 1.7154
2024-10-29 13:04:01: [2024-10-29 13:04:01] iter = 02390, loss = 1.4344
2024-10-29 13:04:01: [2024-10-29 13:04:01] iter = 02400, loss = 1.6235
2024-10-29 13:04:02: [2024-10-29 13:04:02] iter = 02410, loss = 2.1466
2024-10-29 13:04:02: [2024-10-29 13:04:02] iter = 02420, loss = 2.0706
2024-10-29 13:04:03: [2024-10-29 13:04:03] iter = 02430, loss = 1.5733
2024-10-29 13:04:03: [2024-10-29 13:04:03] iter = 02440, loss = 1.5255
2024-10-29 13:04:03: [2024-10-29 13:04:03] iter = 02450, loss = 1.3651
2024-10-29 13:04:04: [2024-10-29 13:04:04] iter = 02460, loss = 1.0440
2024-10-29 13:04:04: [2024-10-29 13:04:04] iter = 02470, loss = 1.2269
2024-10-29 13:04:04: [2024-10-29 13:04:04] iter = 02480, loss = 1.2720
2024-10-29 13:04:05: [2024-10-29 13:04:05] iter = 02490, loss = 1.3939
2024-10-29 13:04:05: [2024-10-29 13:04:05] iter = 02500, loss = 1.9734
2024-10-29 13:04:05: [2024-10-29 13:04:05] iter = 02510, loss = 0.9785
2024-10-29 13:04:06: [2024-10-29 13:04:06] iter = 02520, loss = 1.5015
2024-10-29 13:04:06: [2024-10-29 13:04:06] iter = 02530, loss = 1.7182
2024-10-29 13:04:06: [2024-10-29 13:04:06] iter = 02540, loss = 1.1025
2024-10-29 13:04:07: [2024-10-29 13:04:07] iter = 02550, loss = 1.0351
2024-10-29 13:04:07: [2024-10-29 13:04:07] iter = 02560, loss = 0.7561
2024-10-29 13:04:07: [2024-10-29 13:04:07] iter = 02570, loss = 2.6888
2024-10-29 13:04:08: [2024-10-29 13:04:08] iter = 02580, loss = 1.5119
2024-10-29 13:04:08: [2024-10-29 13:04:08] iter = 02590, loss = 1.9001
2024-10-29 13:04:08: [2024-10-29 13:04:08] iter = 02600, loss = 3.0292
2024-10-29 13:04:09: [2024-10-29 13:04:09] iter = 02610, loss = 3.8046
2024-10-29 13:04:09: [2024-10-29 13:04:09] iter = 02620, loss = 3.2887
2024-10-29 13:04:09: [2024-10-29 13:04:09] iter = 02630, loss = 1.0559
2024-10-29 13:04:10: [2024-10-29 13:04:10] iter = 02640, loss = 0.8776
2024-10-29 13:04:10: [2024-10-29 13:04:10] iter = 02650, loss = 1.1666
2024-10-29 13:04:10: [2024-10-29 13:04:10] iter = 02660, loss = 1.1306
2024-10-29 13:04:11: [2024-10-29 13:04:11] iter = 02670, loss = 1.3401
2024-10-29 13:04:11: [2024-10-29 13:04:11] iter = 02680, loss = 1.4178
2024-10-29 13:04:11: [2024-10-29 13:04:11] iter = 02690, loss = 0.7258
2024-10-29 13:04:12: [2024-10-29 13:04:12] iter = 02700, loss = 2.6411
2024-10-29 13:04:12: [2024-10-29 13:04:12] iter = 02710, loss = 1.5534
2024-10-29 13:04:12: [2024-10-29 13:04:12] iter = 02720, loss = 1.1231
2024-10-29 13:04:13: [2024-10-29 13:04:13] iter = 02730, loss = 0.8582
2024-10-29 13:04:13: [2024-10-29 13:04:13] iter = 02740, loss = 1.4968
2024-10-29 13:04:13: [2024-10-29 13:04:13] iter = 02750, loss = 1.0175
2024-10-29 13:04:14: [2024-10-29 13:04:14] iter = 02760, loss = 2.1722
2024-10-29 13:04:14: [2024-10-29 13:04:14] iter = 02770, loss = 1.4161
2024-10-29 13:04:14: [2024-10-29 13:04:14] iter = 02780, loss = 1.1837
2024-10-29 13:04:15: [2024-10-29 13:04:15] iter = 02790, loss = 0.9421
2024-10-29 13:04:15: [2024-10-29 13:04:15] iter = 02800, loss = 1.8863
2024-10-29 13:04:16: [2024-10-29 13:04:16] iter = 02810, loss = 0.7258
2024-10-29 13:04:16: [2024-10-29 13:04:16] iter = 02820, loss = 1.0577
2024-10-29 13:04:16: [2024-10-29 13:04:16] iter = 02830, loss = 0.8849
2024-10-29 13:04:17: [2024-10-29 13:04:17] iter = 02840, loss = 2.4633
2024-10-29 13:04:17: [2024-10-29 13:04:17] iter = 02850, loss = 1.3028
2024-10-29 13:04:17: [2024-10-29 13:04:17] iter = 02860, loss = 1.1742
2024-10-29 13:04:18: [2024-10-29 13:04:18] iter = 02870, loss = 1.6644
2024-10-29 13:04:18: [2024-10-29 13:04:18] iter = 02880, loss = 0.9393
2024-10-29 13:04:18: [2024-10-29 13:04:18] iter = 02890, loss = 0.9455
2024-10-29 13:04:19: [2024-10-29 13:04:19] iter = 02900, loss = 1.1292
2024-10-29 13:04:19: [2024-10-29 13:04:19] iter = 02910, loss = 1.2601
2024-10-29 13:04:19: [2024-10-29 13:04:19] iter = 02920, loss = 0.9889
2024-10-29 13:04:20: [2024-10-29 13:04:20] iter = 02930, loss = 1.6176
2024-10-29 13:04:20: [2024-10-29 13:04:20] iter = 02940, loss = 2.7018
2024-10-29 13:04:20: [2024-10-29 13:04:20] iter = 02950, loss = 2.9465
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 02960, loss = 2.5542
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 02970, loss = 3.3474
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 02980, loss = 1.8835
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 02990, loss = 1.6297
2024-10-29 13:04:22: [2024-10-29 13:04:22] iter = 03000, loss = 0.9310
2024-10-29 13:04:22: [2024-10-29 13:04:22] iter = 03010, loss = 0.9972
2024-10-29 13:04:22: [2024-10-29 13:04:22] iter = 03020, loss = 0.7668
2024-10-29 13:04:23: [2024-10-29 13:04:23] iter = 03030, loss = 2.3029
2024-10-29 13:04:23: [2024-10-29 13:04:23] iter = 03040, loss = 0.7388
2024-10-29 13:04:23: [2024-10-29 13:04:23] iter = 03050, loss = 1.6115
2024-10-29 13:04:24: [2024-10-29 13:04:24] iter = 03060, loss = 1.1789
2024-10-29 13:04:24: [2024-10-29 13:04:24] iter = 03070, loss = 1.0487
2024-10-29 13:04:24: [2024-10-29 13:04:24] iter = 03080, loss = 1.8026
2024-10-29 13:04:25: [2024-10-29 13:04:25] iter = 03090, loss = 1.3421
2024-10-29 13:04:25: [2024-10-29 13:04:25] iter = 03100, loss = 7.3902
2024-10-29 13:04:25: [2024-10-29 13:04:25] iter = 03110, loss = 1.0858
2024-10-29 13:04:26: [2024-10-29 13:04:26] iter = 03120, loss = 1.4361
2024-10-29 13:04:26: [2024-10-29 13:04:26] iter = 03130, loss = 1.2219
2024-10-29 13:04:27: [2024-10-29 13:04:27] iter = 03140, loss = 2.3454
2024-10-29 13:04:27: [2024-10-29 13:04:27] iter = 03150, loss = 1.6006
2024-10-29 13:04:27: [2024-10-29 13:04:27] iter = 03160, loss = 1.6739
2024-10-29 13:04:28: [2024-10-29 13:04:28] iter = 03170, loss = 1.4535
2024-10-29 13:04:28: [2024-10-29 13:04:28] iter = 03180, loss = 1.6203
2024-10-29 13:04:28: [2024-10-29 13:04:28] iter = 03190, loss = 1.4722
2024-10-29 13:04:29: [2024-10-29 13:04:29] iter = 03200, loss = 1.0055
2024-10-29 13:04:29: [2024-10-29 13:04:29] iter = 03210, loss = 1.1552
2024-10-29 13:04:29: [2024-10-29 13:04:29] iter = 03220, loss = 3.2658
2024-10-29 13:04:30: [2024-10-29 13:04:30] iter = 03230, loss = 1.7456
2024-10-29 13:04:30: [2024-10-29 13:04:30] iter = 03240, loss = 1.8990
2024-10-29 13:04:30: [2024-10-29 13:04:30] iter = 03250, loss = 0.9312
2024-10-29 13:04:31: [2024-10-29 13:04:31] iter = 03260, loss = 1.7627
2024-10-29 13:04:31: [2024-10-29 13:04:31] iter = 03270, loss = 2.2182
2024-10-29 13:04:31: [2024-10-29 13:04:31] iter = 03280, loss = 1.5570
2024-10-29 13:04:32: [2024-10-29 13:04:32] iter = 03290, loss = 6.2144
2024-10-29 13:04:32: [2024-10-29 13:04:32] iter = 03300, loss = 1.5123
2024-10-29 13:04:33: [2024-10-29 13:04:33] iter = 03310, loss = 2.2153
2024-10-29 13:04:33: [2024-10-29 13:04:33] iter = 03320, loss = 1.1308
2024-10-29 13:04:33: [2024-10-29 13:04:33] iter = 03330, loss = 2.4958
2024-10-29 13:04:34: [2024-10-29 13:04:34] iter = 03340, loss = 1.4501
2024-10-29 13:04:34: [2024-10-29 13:04:34] iter = 03350, loss = 1.6640
2024-10-29 13:04:35: [2024-10-29 13:04:35] iter = 03360, loss = 2.7614
2024-10-29 13:04:35: [2024-10-29 13:04:35] iter = 03370, loss = 1.1787
2024-10-29 13:04:36: [2024-10-29 13:04:36] iter = 03380, loss = 1.2569
2024-10-29 13:04:36: [2024-10-29 13:04:36] iter = 03390, loss = 1.0028
2024-10-29 13:04:36: [2024-10-29 13:04:36] iter = 03400, loss = 1.6150
2024-10-29 13:04:37: [2024-10-29 13:04:37] iter = 03410, loss = 1.8098
2024-10-29 13:04:37: [2024-10-29 13:04:37] iter = 03420, loss = 1.5727
2024-10-29 13:04:38: [2024-10-29 13:04:38] iter = 03430, loss = 0.9828
2024-10-29 13:04:38: [2024-10-29 13:04:38] iter = 03440, loss = 1.1211
2024-10-29 13:04:38: [2024-10-29 13:04:38] iter = 03450, loss = 0.8653
2024-10-29 13:04:39: [2024-10-29 13:04:39] iter = 03460, loss = 1.1091
2024-10-29 13:04:39: [2024-10-29 13:04:39] iter = 03470, loss = 2.1664
2024-10-29 13:04:40: [2024-10-29 13:04:40] iter = 03480, loss = 1.2292
2024-10-29 13:04:40: [2024-10-29 13:04:40] iter = 03490, loss = 1.7458
2024-10-29 13:04:40: [2024-10-29 13:04:40] iter = 03500, loss = 2.9226
2024-10-29 13:04:41: [2024-10-29 13:04:41] iter = 03510, loss = 1.3433
2024-10-29 13:04:41: [2024-10-29 13:04:41] iter = 03520, loss = 1.4629
2024-10-29 13:04:41: [2024-10-29 13:04:41] iter = 03530, loss = 1.6642
2024-10-29 13:04:42: [2024-10-29 13:04:42] iter = 03540, loss = 1.6473
2024-10-29 13:04:42: [2024-10-29 13:04:42] iter = 03550, loss = 1.1955
2024-10-29 13:04:42: [2024-10-29 13:04:42] iter = 03560, loss = 1.1717
2024-10-29 13:04:43: [2024-10-29 13:04:43] iter = 03570, loss = 1.1702
2024-10-29 13:04:43: [2024-10-29 13:04:43] iter = 03580, loss = 0.7426
2024-10-29 13:04:43: [2024-10-29 13:04:43] iter = 03590, loss = 1.2447
2024-10-29 13:04:44: [2024-10-29 13:04:44] iter = 03600, loss = 1.1784
2024-10-29 13:04:44: [2024-10-29 13:04:44] iter = 03610, loss = 0.9733
2024-10-29 13:04:44: [2024-10-29 13:04:44] iter = 03620, loss = 0.9019
2024-10-29 13:04:45: [2024-10-29 13:04:45] iter = 03630, loss = 1.0323
2024-10-29 13:04:45: [2024-10-29 13:04:45] iter = 03640, loss = 4.0591
2024-10-29 13:04:46: [2024-10-29 13:04:46] iter = 03650, loss = 2.5107
2024-10-29 13:04:46: [2024-10-29 13:04:46] iter = 03660, loss = 1.7598
2024-10-29 13:04:46: [2024-10-29 13:04:46] iter = 03670, loss = 2.3617
2024-10-29 13:04:47: [2024-10-29 13:04:47] iter = 03680, loss = 1.7247
2024-10-29 13:04:47: [2024-10-29 13:04:47] iter = 03690, loss = 1.9143
2024-10-29 13:04:47: [2024-10-29 13:04:47] iter = 03700, loss = 1.1974
2024-10-29 13:04:48: [2024-10-29 13:04:48] iter = 03710, loss = 2.3641
2024-10-29 13:04:48: [2024-10-29 13:04:48] iter = 03720, loss = 1.0930
2024-10-29 13:04:48: [2024-10-29 13:04:48] iter = 03730, loss = 1.7171
2024-10-29 13:04:49: [2024-10-29 13:04:49] iter = 03740, loss = 0.8812
2024-10-29 13:04:49: [2024-10-29 13:04:49] iter = 03750, loss = 1.2838
2024-10-29 13:04:49: [2024-10-29 13:04:49] iter = 03760, loss = 1.2506
2024-10-29 13:04:50: [2024-10-29 13:04:50] iter = 03770, loss = 1.7953
2024-10-29 13:04:50: [2024-10-29 13:04:50] iter = 03780, loss = 1.1217
2024-10-29 13:04:50: [2024-10-29 13:04:50] iter = 03790, loss = 1.8749
2024-10-29 13:04:51: [2024-10-29 13:04:51] iter = 03800, loss = 1.4495
2024-10-29 13:04:51: [2024-10-29 13:04:51] iter = 03810, loss = 0.9137
2024-10-29 13:04:51: [2024-10-29 13:04:51] iter = 03820, loss = 0.9473
2024-10-29 13:04:52: [2024-10-29 13:04:52] iter = 03830, loss = 1.3404
2024-10-29 13:04:52: [2024-10-29 13:04:52] iter = 03840, loss = 5.8054
2024-10-29 13:04:52: [2024-10-29 13:04:52] iter = 03850, loss = 1.0089
2024-10-29 13:04:53: [2024-10-29 13:04:53] iter = 03860, loss = 0.9554
2024-10-29 13:04:53: [2024-10-29 13:04:53] iter = 03870, loss = 1.3260
2024-10-29 13:04:53: [2024-10-29 13:04:53] iter = 03880, loss = 1.4076
2024-10-29 13:04:54: [2024-10-29 13:04:54] iter = 03890, loss = 1.8482
2024-10-29 13:04:54: [2024-10-29 13:04:54] iter = 03900, loss = 1.5851
2024-10-29 13:04:54: [2024-10-29 13:04:54] iter = 03910, loss = 1.0641
2024-10-29 13:04:55: [2024-10-29 13:04:55] iter = 03920, loss = 1.1055
2024-10-29 13:04:55: [2024-10-29 13:04:55] iter = 03930, loss = 0.7363
2024-10-29 13:04:55: [2024-10-29 13:04:55] iter = 03940, loss = 6.1703
2024-10-29 13:04:56: [2024-10-29 13:04:56] iter = 03950, loss = 1.3701
2024-10-29 13:04:56: [2024-10-29 13:04:56] iter = 03960, loss = 1.2288
2024-10-29 13:04:57: [2024-10-29 13:04:57] iter = 03970, loss = 1.0112
2024-10-29 13:04:57: [2024-10-29 13:04:57] iter = 03980, loss = 1.1813
2024-10-29 13:04:58: [2024-10-29 13:04:58] iter = 03990, loss = 1.9601
2024-10-29 13:04:58: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 13:04:58: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:04:58: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 98824}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:05:28: Evaluate 5 random ConvNet, ACCmean = 0.3910 ACCstd = 0.0136
-------------------------
2024-10-29 13:05:28: Evaluate 5 random ConvNet, SENmean = 0.5758 SENstd = 0.0029
-------------------------
2024-10-29 13:05:28: Evaluate 5 random ConvNet, SPEmean = 0.5758 SPEstd = 0.0029
-------------------------
2024-10-29 13:05:28: Evaluate 5 random ConvNet, F!mean = 0.3611 F!std = 0.0095
-------------------------
2024-10-29 13:05:28: Evaluate 5 random ConvNet, mean = 0.3910 std = 0.0136
-------------------------
2024-10-29 13:05:28: [2024-10-29 13:05:28] iter = 04000, loss = 7.0427
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:05:28: [2024-10-29 13:05:28] iter = 04010, loss = 1.3077
2024-10-29 13:05:29: [2024-10-29 13:05:29] iter = 04020, loss = 4.0453
2024-10-29 13:05:29: [2024-10-29 13:05:29] iter = 04030, loss = 1.4433
2024-10-29 13:05:29: [2024-10-29 13:05:29] iter = 04040, loss = 1.1360
2024-10-29 13:05:30: [2024-10-29 13:05:30] iter = 04050, loss = 1.5107
2024-10-29 13:05:30: [2024-10-29 13:05:30] iter = 04060, loss = 2.5674
2024-10-29 13:05:30: [2024-10-29 13:05:30] iter = 04070, loss = 1.4694
2024-10-29 13:05:31: [2024-10-29 13:05:31] iter = 04080, loss = 1.7593
2024-10-29 13:05:31: [2024-10-29 13:05:31] iter = 04090, loss = 1.0146
2024-10-29 13:05:32: [2024-10-29 13:05:32] iter = 04100, loss = 0.9809
2024-10-29 13:05:32: [2024-10-29 13:05:32] iter = 04110, loss = 0.9911
2024-10-29 13:05:32: [2024-10-29 13:05:32] iter = 04120, loss = 3.5475
2024-10-29 13:05:32: [2024-10-29 13:05:32] iter = 04130, loss = 1.4775
2024-10-29 13:05:33: [2024-10-29 13:05:33] iter = 04140, loss = 1.1137
2024-10-29 13:05:33: [2024-10-29 13:05:33] iter = 04150, loss = 2.8036
2024-10-29 13:05:34: [2024-10-29 13:05:34] iter = 04160, loss = 1.3658
2024-10-29 13:05:34: [2024-10-29 13:05:34] iter = 04170, loss = 1.0155
2024-10-29 13:05:35: [2024-10-29 13:05:35] iter = 04180, loss = 0.9829
2024-10-29 13:05:35: [2024-10-29 13:05:35] iter = 04190, loss = 5.1534
2024-10-29 13:05:35: [2024-10-29 13:05:35] iter = 04200, loss = 1.5786
2024-10-29 13:05:36: [2024-10-29 13:05:36] iter = 04210, loss = 1.2760
2024-10-29 13:05:36: [2024-10-29 13:05:36] iter = 04220, loss = 1.3636
2024-10-29 13:05:36: [2024-10-29 13:05:36] iter = 04230, loss = 2.5418
2024-10-29 13:05:37: [2024-10-29 13:05:37] iter = 04240, loss = 2.4108
2024-10-29 13:05:37: [2024-10-29 13:05:37] iter = 04250, loss = 1.6454
2024-10-29 13:05:37: [2024-10-29 13:05:37] iter = 04260, loss = 1.1458
2024-10-29 13:05:38: [2024-10-29 13:05:38] iter = 04270, loss = 1.2567
2024-10-29 13:05:38: [2024-10-29 13:05:38] iter = 04280, loss = 1.2643
2024-10-29 13:05:38: [2024-10-29 13:05:38] iter = 04290, loss = 0.8608
2024-10-29 13:05:39: [2024-10-29 13:05:39] iter = 04300, loss = 1.3229
2024-10-29 13:05:39: [2024-10-29 13:05:39] iter = 04310, loss = 1.3799
2024-10-29 13:05:39: [2024-10-29 13:05:39] iter = 04320, loss = 1.9681
2024-10-29 13:05:40: [2024-10-29 13:05:40] iter = 04330, loss = 1.4863
2024-10-29 13:05:40: [2024-10-29 13:05:40] iter = 04340, loss = 2.5575
2024-10-29 13:05:40: [2024-10-29 13:05:40] iter = 04350, loss = 1.0202
2024-10-29 13:05:40: [2024-10-29 13:05:40] iter = 04360, loss = 1.5523
2024-10-29 13:05:41: [2024-10-29 13:05:41] iter = 04370, loss = 1.1489
2024-10-29 13:05:41: [2024-10-29 13:05:41] iter = 04380, loss = 1.6819
2024-10-29 13:05:41: [2024-10-29 13:05:41] iter = 04390, loss = 1.3498
2024-10-29 13:05:42: [2024-10-29 13:05:42] iter = 04400, loss = 0.9928
2024-10-29 13:05:42: [2024-10-29 13:05:42] iter = 04410, loss = 1.1399
2024-10-29 13:05:43: [2024-10-29 13:05:43] iter = 04420, loss = 1.8750
2024-10-29 13:05:43: [2024-10-29 13:05:43] iter = 04430, loss = 1.1805
2024-10-29 13:05:43: [2024-10-29 13:05:43] iter = 04440, loss = 1.3419
2024-10-29 13:05:44: [2024-10-29 13:05:44] iter = 04450, loss = 1.3977
2024-10-29 13:05:44: [2024-10-29 13:05:44] iter = 04460, loss = 1.0819
2024-10-29 13:05:45: [2024-10-29 13:05:45] iter = 04470, loss = 7.6622
2024-10-29 13:05:45: [2024-10-29 13:05:45] iter = 04480, loss = 1.4834
2024-10-29 13:05:45: [2024-10-29 13:05:45] iter = 04490, loss = 0.8874
2024-10-29 13:05:46: [2024-10-29 13:05:46] iter = 04500, loss = 2.8518
2024-10-29 13:05:46: [2024-10-29 13:05:46] iter = 04510, loss = 0.9436
2024-10-29 13:05:46: [2024-10-29 13:05:46] iter = 04520, loss = 4.0886
2024-10-29 13:05:47: [2024-10-29 13:05:47] iter = 04530, loss = 0.9235
2024-10-29 13:05:47: [2024-10-29 13:05:47] iter = 04540, loss = 3.2658
2024-10-29 13:05:47: [2024-10-29 13:05:47] iter = 04550, loss = 0.7867
2024-10-29 13:05:48: [2024-10-29 13:05:48] iter = 04560, loss = 2.0884
2024-10-29 13:05:48: [2024-10-29 13:05:48] iter = 04570, loss = 1.3536
2024-10-29 13:05:48: [2024-10-29 13:05:48] iter = 04580, loss = 1.5966
2024-10-29 13:05:49: [2024-10-29 13:05:49] iter = 04590, loss = 1.5407
2024-10-29 13:05:49: [2024-10-29 13:05:49] iter = 04600, loss = 1.9255
2024-10-29 13:05:49: [2024-10-29 13:05:49] iter = 04610, loss = 2.0277
2024-10-29 13:05:50: [2024-10-29 13:05:50] iter = 04620, loss = 1.7435
2024-10-29 13:05:50: [2024-10-29 13:05:50] iter = 04630, loss = 1.2864
2024-10-29 13:05:50: [2024-10-29 13:05:50] iter = 04640, loss = 3.8662
2024-10-29 13:05:51: [2024-10-29 13:05:51] iter = 04650, loss = 1.6314
2024-10-29 13:05:51: [2024-10-29 13:05:51] iter = 04660, loss = 1.2373
2024-10-29 13:05:51: [2024-10-29 13:05:51] iter = 04670, loss = 0.8992
2024-10-29 13:05:52: [2024-10-29 13:05:52] iter = 04680, loss = 1.0857
2024-10-29 13:05:52: [2024-10-29 13:05:52] iter = 04690, loss = 1.0805
2024-10-29 13:05:52: [2024-10-29 13:05:52] iter = 04700, loss = 1.1875
2024-10-29 13:05:53: [2024-10-29 13:05:53] iter = 04710, loss = 0.9518
2024-10-29 13:05:53: [2024-10-29 13:05:53] iter = 04720, loss = 1.2267
2024-10-29 13:05:53: [2024-10-29 13:05:53] iter = 04730, loss = 1.3959
2024-10-29 13:05:54: [2024-10-29 13:05:54] iter = 04740, loss = 1.0275
2024-10-29 13:05:54: [2024-10-29 13:05:54] iter = 04750, loss = 0.7053
2024-10-29 13:05:54: [2024-10-29 13:05:54] iter = 04760, loss = 0.8647
2024-10-29 13:05:55: [2024-10-29 13:05:55] iter = 04770, loss = 1.0615
2024-10-29 13:05:55: [2024-10-29 13:05:55] iter = 04780, loss = 0.8245
2024-10-29 13:05:55: [2024-10-29 13:05:55] iter = 04790, loss = 0.7771
2024-10-29 13:05:56: [2024-10-29 13:05:56] iter = 04800, loss = 1.3885
2024-10-29 13:05:56: [2024-10-29 13:05:56] iter = 04810, loss = 2.0463
2024-10-29 13:05:56: [2024-10-29 13:05:56] iter = 04820, loss = 1.6843
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 04830, loss = 0.9476
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 04840, loss = 0.6893
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 04850, loss = 1.2264
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 04860, loss = 2.2746
2024-10-29 13:05:58: [2024-10-29 13:05:58] iter = 04870, loss = 1.4562
2024-10-29 13:05:58: [2024-10-29 13:05:58] iter = 04880, loss = 1.4501
2024-10-29 13:05:58: [2024-10-29 13:05:58] iter = 04890, loss = 1.3518
2024-10-29 13:05:59: [2024-10-29 13:05:59] iter = 04900, loss = 1.2548
2024-10-29 13:05:59: [2024-10-29 13:05:59] iter = 04910, loss = 1.5446
2024-10-29 13:05:59: [2024-10-29 13:05:59] iter = 04920, loss = 1.1134
2024-10-29 13:06:00: [2024-10-29 13:06:00] iter = 04930, loss = 0.9944
2024-10-29 13:06:00: [2024-10-29 13:06:00] iter = 04940, loss = 2.1226
2024-10-29 13:06:00: [2024-10-29 13:06:00] iter = 04950, loss = 1.0678
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 04960, loss = 1.7773
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 04970, loss = 1.2668
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 04980, loss = 2.0452
2024-10-29 13:06:02: [2024-10-29 13:06:02] iter = 04990, loss = 1.6732
2024-10-29 13:06:02: [2024-10-29 13:06:02] iter = 05000, loss = 2.3981
2024-10-29 13:06:02: [2024-10-29 13:06:02] iter = 05010, loss = 1.2173
2024-10-29 13:06:03: [2024-10-29 13:06:03] iter = 05020, loss = 0.8516
2024-10-29 13:06:03: [2024-10-29 13:06:03] iter = 05030, loss = 2.3425
2024-10-29 13:06:04: [2024-10-29 13:06:04] iter = 05040, loss = 2.1586
2024-10-29 13:06:04: [2024-10-29 13:06:04] iter = 05050, loss = 2.1558
2024-10-29 13:06:04: [2024-10-29 13:06:04] iter = 05060, loss = 1.1466
2024-10-29 13:06:05: [2024-10-29 13:06:05] iter = 05070, loss = 1.9897
2024-10-29 13:06:05: [2024-10-29 13:06:05] iter = 05080, loss = 3.2279
2024-10-29 13:06:05: [2024-10-29 13:06:05] iter = 05090, loss = 1.9560
2024-10-29 13:06:06: [2024-10-29 13:06:06] iter = 05100, loss = 2.6440
2024-10-29 13:06:06: [2024-10-29 13:06:06] iter = 05110, loss = 1.2897
2024-10-29 13:06:07: [2024-10-29 13:06:07] iter = 05120, loss = 1.1662
2024-10-29 13:06:07: [2024-10-29 13:06:07] iter = 05130, loss = 1.2941
2024-10-29 13:06:08: [2024-10-29 13:06:08] iter = 05140, loss = 1.7353
2024-10-29 13:06:08: [2024-10-29 13:06:08] iter = 05150, loss = 1.6787
2024-10-29 13:06:09: [2024-10-29 13:06:09] iter = 05160, loss = 1.6916
2024-10-29 13:06:09: [2024-10-29 13:06:09] iter = 05170, loss = 1.6285
2024-10-29 13:06:10: [2024-10-29 13:06:10] iter = 05180, loss = 1.2032
2024-10-29 13:06:10: [2024-10-29 13:06:10] iter = 05190, loss = 1.0909
2024-10-29 13:06:11: [2024-10-29 13:06:11] iter = 05200, loss = 1.4278
2024-10-29 13:06:11: [2024-10-29 13:06:11] iter = 05210, loss = 5.2213
2024-10-29 13:06:12: [2024-10-29 13:06:12] iter = 05220, loss = 1.7804
2024-10-29 13:06:12: [2024-10-29 13:06:12] iter = 05230, loss = 1.3083
2024-10-29 13:06:12: [2024-10-29 13:06:12] iter = 05240, loss = 1.9748
2024-10-29 13:06:13: [2024-10-29 13:06:13] iter = 05250, loss = 2.0490
2024-10-29 13:06:13: [2024-10-29 13:06:13] iter = 05260, loss = 0.9858
2024-10-29 13:06:14: [2024-10-29 13:06:14] iter = 05270, loss = 1.2151
2024-10-29 13:06:14: [2024-10-29 13:06:14] iter = 05280, loss = 2.1499
2024-10-29 13:06:15: [2024-10-29 13:06:15] iter = 05290, loss = 4.4611
2024-10-29 13:06:15: [2024-10-29 13:06:15] iter = 05300, loss = 1.5130
2024-10-29 13:06:16: [2024-10-29 13:06:16] iter = 05310, loss = 1.2647
2024-10-29 13:06:16: [2024-10-29 13:06:16] iter = 05320, loss = 1.4123
2024-10-29 13:06:16: [2024-10-29 13:06:16] iter = 05330, loss = 1.3057
2024-10-29 13:06:17: [2024-10-29 13:06:17] iter = 05340, loss = 1.0402
2024-10-29 13:06:17: [2024-10-29 13:06:17] iter = 05350, loss = 0.8720
2024-10-29 13:06:18: [2024-10-29 13:06:18] iter = 05360, loss = 4.0202
2024-10-29 13:06:18: [2024-10-29 13:06:18] iter = 05370, loss = 2.2775
2024-10-29 13:06:19: [2024-10-29 13:06:19] iter = 05380, loss = 1.3798
2024-10-29 13:06:19: [2024-10-29 13:06:19] iter = 05390, loss = 1.0434
2024-10-29 13:06:19: [2024-10-29 13:06:19] iter = 05400, loss = 5.8928
2024-10-29 13:06:20: [2024-10-29 13:06:20] iter = 05410, loss = 1.3098
2024-10-29 13:06:20: [2024-10-29 13:06:20] iter = 05420, loss = 1.0636
2024-10-29 13:06:21: [2024-10-29 13:06:21] iter = 05430, loss = 0.9854
2024-10-29 13:06:21: [2024-10-29 13:06:21] iter = 05440, loss = 1.3267
2024-10-29 13:06:22: [2024-10-29 13:06:22] iter = 05450, loss = 0.9819
2024-10-29 13:06:22: [2024-10-29 13:06:22] iter = 05460, loss = 2.5442
2024-10-29 13:06:23: [2024-10-29 13:06:23] iter = 05470, loss = 0.9469
2024-10-29 13:06:23: [2024-10-29 13:06:23] iter = 05480, loss = 0.9865
2024-10-29 13:06:23: [2024-10-29 13:06:23] iter = 05490, loss = 1.7822
2024-10-29 13:06:24: [2024-10-29 13:06:24] iter = 05500, loss = 1.5860
2024-10-29 13:06:24: [2024-10-29 13:06:24] iter = 05510, loss = 0.8088
2024-10-29 13:06:24: [2024-10-29 13:06:24] iter = 05520, loss = 11.9921
2024-10-29 13:06:25: [2024-10-29 13:06:25] iter = 05530, loss = 2.4297
2024-10-29 13:06:25: [2024-10-29 13:06:25] iter = 05540, loss = 1.1851
2024-10-29 13:06:25: [2024-10-29 13:06:25] iter = 05550, loss = 3.9073
2024-10-29 13:06:26: [2024-10-29 13:06:26] iter = 05560, loss = 2.3539
2024-10-29 13:06:26: [2024-10-29 13:06:26] iter = 05570, loss = 1.4643
2024-10-29 13:06:26: [2024-10-29 13:06:26] iter = 05580, loss = 1.7435
2024-10-29 13:06:27: [2024-10-29 13:06:27] iter = 05590, loss = 3.0988
2024-10-29 13:06:27: [2024-10-29 13:06:27] iter = 05600, loss = 1.3054
2024-10-29 13:06:27: [2024-10-29 13:06:27] iter = 05610, loss = 0.9860
2024-10-29 13:06:28: [2024-10-29 13:06:28] iter = 05620, loss = 1.5956
2024-10-29 13:06:28: [2024-10-29 13:06:28] iter = 05630, loss = 2.3236
2024-10-29 13:06:29: [2024-10-29 13:06:29] iter = 05640, loss = 1.6035
2024-10-29 13:06:29: [2024-10-29 13:06:29] iter = 05650, loss = 2.1168
2024-10-29 13:06:29: [2024-10-29 13:06:29] iter = 05660, loss = 0.9520
2024-10-29 13:06:30: [2024-10-29 13:06:30] iter = 05670, loss = 0.8301
2024-10-29 13:06:30: [2024-10-29 13:06:30] iter = 05680, loss = 0.9790
2024-10-29 13:06:30: [2024-10-29 13:06:30] iter = 05690, loss = 1.3490
2024-10-29 13:06:31: [2024-10-29 13:06:31] iter = 05700, loss = 1.6820
2024-10-29 13:06:31: [2024-10-29 13:06:31] iter = 05710, loss = 1.2805
2024-10-29 13:06:32: [2024-10-29 13:06:32] iter = 05720, loss = 1.8711
2024-10-29 13:06:32: [2024-10-29 13:06:32] iter = 05730, loss = 1.8558
2024-10-29 13:06:32: [2024-10-29 13:06:32] iter = 05740, loss = 1.7853
2024-10-29 13:06:33: [2024-10-29 13:06:33] iter = 05750, loss = 1.8634
2024-10-29 13:06:33: [2024-10-29 13:06:33] iter = 05760, loss = 1.6766
2024-10-29 13:06:33: [2024-10-29 13:06:33] iter = 05770, loss = 1.7382
2024-10-29 13:06:34: [2024-10-29 13:06:34] iter = 05780, loss = 1.5295
2024-10-29 13:06:34: [2024-10-29 13:06:34] iter = 05790, loss = 1.1988
2024-10-29 13:06:34: [2024-10-29 13:06:34] iter = 05800, loss = 2.4251
2024-10-29 13:06:35: [2024-10-29 13:06:35] iter = 05810, loss = 1.2342
2024-10-29 13:06:35: [2024-10-29 13:06:35] iter = 05820, loss = 0.9384
2024-10-29 13:06:35: [2024-10-29 13:06:35] iter = 05830, loss = 1.5261
2024-10-29 13:06:36: [2024-10-29 13:06:36] iter = 05840, loss = 1.8086
2024-10-29 13:06:36: [2024-10-29 13:06:36] iter = 05850, loss = 2.3037
2024-10-29 13:06:36: [2024-10-29 13:06:36] iter = 05860, loss = 1.4633
2024-10-29 13:06:37: [2024-10-29 13:06:37] iter = 05870, loss = 4.1522
2024-10-29 13:06:37: [2024-10-29 13:06:37] iter = 05880, loss = 1.1951
2024-10-29 13:06:37: [2024-10-29 13:06:37] iter = 05890, loss = 1.0491
2024-10-29 13:06:38: [2024-10-29 13:06:38] iter = 05900, loss = 1.3538
2024-10-29 13:06:38: [2024-10-29 13:06:38] iter = 05910, loss = 1.8198
2024-10-29 13:06:38: [2024-10-29 13:06:38] iter = 05920, loss = 1.2247
2024-10-29 13:06:39: [2024-10-29 13:06:39] iter = 05930, loss = 2.9777
2024-10-29 13:06:39: [2024-10-29 13:06:39] iter = 05940, loss = 2.4371
2024-10-29 13:06:39: [2024-10-29 13:06:39] iter = 05950, loss = 5.8818
2024-10-29 13:06:40: [2024-10-29 13:06:40] iter = 05960, loss = 1.0451
2024-10-29 13:06:40: [2024-10-29 13:06:40] iter = 05970, loss = 2.3263
2024-10-29 13:06:40: [2024-10-29 13:06:40] iter = 05980, loss = 1.3172
2024-10-29 13:06:41: [2024-10-29 13:06:41] iter = 05990, loss = 2.9044
2024-10-29 13:06:41: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 13:06:41: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:06:41: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 1376}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:07:10: Evaluate 5 random ConvNet, ACCmean = 0.5947 ACCstd = 0.0159
-------------------------
2024-10-29 13:07:10: Evaluate 5 random ConvNet, SENmean = 0.6371 SENstd = 0.0043
-------------------------
2024-10-29 13:07:10: Evaluate 5 random ConvNet, SPEmean = 0.6371 SPEstd = 0.0043
-------------------------
2024-10-29 13:07:10: Evaluate 5 random ConvNet, F!mean = 0.4942 F!std = 0.0086
-------------------------
2024-10-29 13:07:10: Evaluate 5 random ConvNet, mean = 0.5947 std = 0.0159
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:07:10: [2024-10-29 13:07:10] iter = 06000, loss = 1.1534
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:07:10: [2024-10-29 13:07:10] iter = 06010, loss = 2.9458
2024-10-29 13:07:10: [2024-10-29 13:07:10] iter = 06020, loss = 3.3739
2024-10-29 13:07:11: [2024-10-29 13:07:11] iter = 06030, loss = 2.4361
2024-10-29 13:07:11: [2024-10-29 13:07:11] iter = 06040, loss = 1.1701
2024-10-29 13:07:11: [2024-10-29 13:07:11] iter = 06050, loss = 1.3319
2024-10-29 13:07:12: [2024-10-29 13:07:12] iter = 06060, loss = 0.9953
2024-10-29 13:07:12: [2024-10-29 13:07:12] iter = 06070, loss = 1.9115
2024-10-29 13:07:12: [2024-10-29 13:07:12] iter = 06080, loss = 1.4947
2024-10-29 13:07:13: [2024-10-29 13:07:13] iter = 06090, loss = 0.8335
2024-10-29 13:07:13: [2024-10-29 13:07:13] iter = 06100, loss = 10.8528
2024-10-29 13:07:13: [2024-10-29 13:07:13] iter = 06110, loss = 1.8229
2024-10-29 13:07:14: [2024-10-29 13:07:14] iter = 06120, loss = 1.4137
2024-10-29 13:07:14: [2024-10-29 13:07:14] iter = 06130, loss = 2.7817
2024-10-29 13:07:15: [2024-10-29 13:07:15] iter = 06140, loss = 1.2070
2024-10-29 13:07:15: [2024-10-29 13:07:15] iter = 06150, loss = 1.3570
2024-10-29 13:07:15: [2024-10-29 13:07:15] iter = 06160, loss = 2.1618
2024-10-29 13:07:16: [2024-10-29 13:07:16] iter = 06170, loss = 0.8203
2024-10-29 13:07:16: [2024-10-29 13:07:16] iter = 06180, loss = 4.2618
2024-10-29 13:07:16: [2024-10-29 13:07:16] iter = 06190, loss = 1.5452
2024-10-29 13:07:17: [2024-10-29 13:07:17] iter = 06200, loss = 1.0433
2024-10-29 13:07:17: [2024-10-29 13:07:17] iter = 06210, loss = 2.6435
2024-10-29 13:07:17: [2024-10-29 13:07:17] iter = 06220, loss = 2.0857
2024-10-29 13:07:18: [2024-10-29 13:07:18] iter = 06230, loss = 6.9866
2024-10-29 13:07:18: [2024-10-29 13:07:18] iter = 06240, loss = 1.3444
2024-10-29 13:07:18: [2024-10-29 13:07:18] iter = 06250, loss = 1.2770
2024-10-29 13:07:19: [2024-10-29 13:07:19] iter = 06260, loss = 1.5683
2024-10-29 13:07:19: [2024-10-29 13:07:19] iter = 06270, loss = 1.5807
2024-10-29 13:07:19: [2024-10-29 13:07:19] iter = 06280, loss = 1.7840
2024-10-29 13:07:20: [2024-10-29 13:07:19] iter = 06290, loss = 1.3360
2024-10-29 13:07:20: [2024-10-29 13:07:20] iter = 06300, loss = 1.3970
2024-10-29 13:07:20: [2024-10-29 13:07:20] iter = 06310, loss = 2.1009
2024-10-29 13:07:20: [2024-10-29 13:07:20] iter = 06320, loss = 1.8758
2024-10-29 13:07:21: [2024-10-29 13:07:21] iter = 06330, loss = 1.8418
2024-10-29 13:07:21: [2024-10-29 13:07:21] iter = 06340, loss = 1.6808
2024-10-29 13:07:21: [2024-10-29 13:07:21] iter = 06350, loss = 1.0069
2024-10-29 13:07:22: [2024-10-29 13:07:22] iter = 06360, loss = 1.2427
2024-10-29 13:07:22: [2024-10-29 13:07:22] iter = 06370, loss = 1.3810
2024-10-29 13:07:22: [2024-10-29 13:07:22] iter = 06380, loss = 1.2154
2024-10-29 13:07:23: [2024-10-29 13:07:23] iter = 06390, loss = 1.1628
2024-10-29 13:07:23: [2024-10-29 13:07:23] iter = 06400, loss = 1.1521
2024-10-29 13:07:23: [2024-10-29 13:07:23] iter = 06410, loss = 1.4977
2024-10-29 13:07:24: [2024-10-29 13:07:24] iter = 06420, loss = 0.8254
2024-10-29 13:07:24: [2024-10-29 13:07:24] iter = 06430, loss = 1.0330
2024-10-29 13:07:24: [2024-10-29 13:07:24] iter = 06440, loss = 1.5338
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 06450, loss = 1.1570
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 06460, loss = 0.9901
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 06470, loss = 1.0431
2024-10-29 13:07:26: [2024-10-29 13:07:26] iter = 06480, loss = 1.2297
2024-10-29 13:07:26: [2024-10-29 13:07:26] iter = 06490, loss = 1.2585
2024-10-29 13:07:26: [2024-10-29 13:07:26] iter = 06500, loss = 1.0646
2024-10-29 13:07:27: [2024-10-29 13:07:27] iter = 06510, loss = 1.5887
2024-10-29 13:07:27: [2024-10-29 13:07:27] iter = 06520, loss = 1.0468
2024-10-29 13:07:27: [2024-10-29 13:07:27] iter = 06530, loss = 1.4717
2024-10-29 13:07:28: [2024-10-29 13:07:28] iter = 06540, loss = 1.6535
2024-10-29 13:07:28: [2024-10-29 13:07:28] iter = 06550, loss = 0.9026
2024-10-29 13:07:29: [2024-10-29 13:07:29] iter = 06560, loss = 1.5723
2024-10-29 13:07:29: [2024-10-29 13:07:29] iter = 06570, loss = 1.1864
2024-10-29 13:07:29: [2024-10-29 13:07:29] iter = 06580, loss = 1.2745
2024-10-29 13:07:30: [2024-10-29 13:07:30] iter = 06590, loss = 0.9294
2024-10-29 13:07:30: [2024-10-29 13:07:30] iter = 06600, loss = 1.3658
2024-10-29 13:07:31: [2024-10-29 13:07:31] iter = 06610, loss = 1.0396
2024-10-29 13:07:31: [2024-10-29 13:07:31] iter = 06620, loss = 1.1608
2024-10-29 13:07:32: [2024-10-29 13:07:32] iter = 06630, loss = 0.9317
2024-10-29 13:07:32: [2024-10-29 13:07:32] iter = 06640, loss = 1.5167
2024-10-29 13:07:32: [2024-10-29 13:07:32] iter = 06650, loss = 0.9264
2024-10-29 13:07:33: [2024-10-29 13:07:33] iter = 06660, loss = 0.8237
2024-10-29 13:07:33: [2024-10-29 13:07:33] iter = 06670, loss = 1.4989
2024-10-29 13:07:34: [2024-10-29 13:07:33] iter = 06680, loss = 1.0436
2024-10-29 13:07:34: [2024-10-29 13:07:34] iter = 06690, loss = 2.0793
2024-10-29 13:07:34: [2024-10-29 13:07:34] iter = 06700, loss = 1.5233
2024-10-29 13:07:35: [2024-10-29 13:07:35] iter = 06710, loss = 2.4357
2024-10-29 13:07:36: [2024-10-29 13:07:36] iter = 06720, loss = 1.3288
2024-10-29 13:07:36: [2024-10-29 13:07:36] iter = 06730, loss = 0.8525
2024-10-29 13:07:36: [2024-10-29 13:07:36] iter = 06740, loss = 1.3152
2024-10-29 13:07:37: [2024-10-29 13:07:37] iter = 06750, loss = 0.9789
2024-10-29 13:07:37: [2024-10-29 13:07:37] iter = 06760, loss = 0.7805
2024-10-29 13:07:38: [2024-10-29 13:07:38] iter = 06770, loss = 15.5502
2024-10-29 13:07:38: [2024-10-29 13:07:38] iter = 06780, loss = 2.1654
2024-10-29 13:07:39: [2024-10-29 13:07:39] iter = 06790, loss = 1.6080
2024-10-29 13:07:39: [2024-10-29 13:07:39] iter = 06800, loss = 1.1242
2024-10-29 13:07:39: [2024-10-29 13:07:39] iter = 06810, loss = 1.1444
2024-10-29 13:07:40: [2024-10-29 13:07:40] iter = 06820, loss = 1.3435
2024-10-29 13:07:40: [2024-10-29 13:07:40] iter = 06830, loss = 1.3072
2024-10-29 13:07:40: [2024-10-29 13:07:40] iter = 06840, loss = 2.3782
2024-10-29 13:07:41: [2024-10-29 13:07:41] iter = 06850, loss = 1.6392
2024-10-29 13:07:41: [2024-10-29 13:07:41] iter = 06860, loss = 2.2366
2024-10-29 13:07:42: [2024-10-29 13:07:42] iter = 06870, loss = 1.0640
2024-10-29 13:07:42: [2024-10-29 13:07:42] iter = 06880, loss = 1.0423
2024-10-29 13:07:43: [2024-10-29 13:07:43] iter = 06890, loss = 1.0291
2024-10-29 13:07:43: [2024-10-29 13:07:43] iter = 06900, loss = 1.8195
2024-10-29 13:07:43: [2024-10-29 13:07:43] iter = 06910, loss = 1.6867
2024-10-29 13:07:44: [2024-10-29 13:07:44] iter = 06920, loss = 1.5214
2024-10-29 13:07:44: [2024-10-29 13:07:44] iter = 06930, loss = 1.1586
2024-10-29 13:07:45: [2024-10-29 13:07:45] iter = 06940, loss = 1.2510
2024-10-29 13:07:45: [2024-10-29 13:07:45] iter = 06950, loss = 1.2102
2024-10-29 13:07:46: [2024-10-29 13:07:46] iter = 06960, loss = 0.9911
2024-10-29 13:07:46: [2024-10-29 13:07:46] iter = 06970, loss = 0.8890
2024-10-29 13:07:46: [2024-10-29 13:07:46] iter = 06980, loss = 2.7057
2024-10-29 13:07:47: [2024-10-29 13:07:47] iter = 06990, loss = 2.2787
2024-10-29 13:07:47: [2024-10-29 13:07:47] iter = 07000, loss = 2.6317
2024-10-29 13:07:48: [2024-10-29 13:07:48] iter = 07010, loss = 1.2994
2024-10-29 13:07:48: [2024-10-29 13:07:48] iter = 07020, loss = 1.4111
2024-10-29 13:07:48: [2024-10-29 13:07:48] iter = 07030, loss = 3.1591
2024-10-29 13:07:49: [2024-10-29 13:07:49] iter = 07040, loss = 1.3363
2024-10-29 13:07:49: [2024-10-29 13:07:49] iter = 07050, loss = 2.5850
2024-10-29 13:07:50: [2024-10-29 13:07:49] iter = 07060, loss = 0.9097
2024-10-29 13:07:50: [2024-10-29 13:07:50] iter = 07070, loss = 1.0007
2024-10-29 13:07:50: [2024-10-29 13:07:50] iter = 07080, loss = 3.1753
2024-10-29 13:07:51: [2024-10-29 13:07:51] iter = 07090, loss = 1.0149
2024-10-29 13:07:51: [2024-10-29 13:07:51] iter = 07100, loss = 1.0820
2024-10-29 13:07:51: [2024-10-29 13:07:51] iter = 07110, loss = 2.3585
2024-10-29 13:07:52: [2024-10-29 13:07:52] iter = 07120, loss = 0.9881
2024-10-29 13:07:52: [2024-10-29 13:07:52] iter = 07130, loss = 0.8938
2024-10-29 13:07:52: [2024-10-29 13:07:52] iter = 07140, loss = 1.5962
2024-10-29 13:07:53: [2024-10-29 13:07:53] iter = 07150, loss = 2.0110
2024-10-29 13:07:53: [2024-10-29 13:07:53] iter = 07160, loss = 0.7691
2024-10-29 13:07:54: [2024-10-29 13:07:54] iter = 07170, loss = 1.1118
2024-10-29 13:07:54: [2024-10-29 13:07:54] iter = 07180, loss = 1.3900
2024-10-29 13:07:54: [2024-10-29 13:07:54] iter = 07190, loss = 1.6410
2024-10-29 13:07:55: [2024-10-29 13:07:55] iter = 07200, loss = 1.7965
2024-10-29 13:07:55: [2024-10-29 13:07:55] iter = 07210, loss = 1.0974
2024-10-29 13:07:56: [2024-10-29 13:07:56] iter = 07220, loss = 1.4730
2024-10-29 13:07:56: [2024-10-29 13:07:56] iter = 07230, loss = 1.8775
2024-10-29 13:07:56: [2024-10-29 13:07:56] iter = 07240, loss = 0.9056
2024-10-29 13:07:57: [2024-10-29 13:07:57] iter = 07250, loss = 3.4833
2024-10-29 13:07:57: [2024-10-29 13:07:57] iter = 07260, loss = 1.5761
2024-10-29 13:07:57: [2024-10-29 13:07:57] iter = 07270, loss = 1.6133
2024-10-29 13:07:58: [2024-10-29 13:07:58] iter = 07280, loss = 1.7774
2024-10-29 13:07:58: [2024-10-29 13:07:58] iter = 07290, loss = 1.1173
2024-10-29 13:07:58: [2024-10-29 13:07:58] iter = 07300, loss = 1.7053
2024-10-29 13:07:59: [2024-10-29 13:07:59] iter = 07310, loss = 1.3369
2024-10-29 13:07:59: [2024-10-29 13:07:59] iter = 07320, loss = 1.2300
2024-10-29 13:07:59: [2024-10-29 13:07:59] iter = 07330, loss = 2.3351
2024-10-29 13:08:00: [2024-10-29 13:08:00] iter = 07340, loss = 4.2646
2024-10-29 13:08:00: [2024-10-29 13:08:00] iter = 07350, loss = 2.0129
2024-10-29 13:08:00: [2024-10-29 13:08:00] iter = 07360, loss = 1.6091
2024-10-29 13:08:01: [2024-10-29 13:08:01] iter = 07370, loss = 1.3620
2024-10-29 13:08:01: [2024-10-29 13:08:01] iter = 07380, loss = 1.8173
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 07390, loss = 1.3105
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 07400, loss = 0.9553
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 07410, loss = 1.4801
2024-10-29 13:08:03: [2024-10-29 13:08:03] iter = 07420, loss = 1.3848
2024-10-29 13:08:03: [2024-10-29 13:08:03] iter = 07430, loss = 1.4563
2024-10-29 13:08:03: [2024-10-29 13:08:03] iter = 07440, loss = 0.9355
2024-10-29 13:08:04: [2024-10-29 13:08:04] iter = 07450, loss = 2.0280
2024-10-29 13:08:04: [2024-10-29 13:08:04] iter = 07460, loss = 1.3072
2024-10-29 13:08:04: [2024-10-29 13:08:04] iter = 07470, loss = 1.0278
2024-10-29 13:08:05: [2024-10-29 13:08:05] iter = 07480, loss = 0.9894
2024-10-29 13:08:05: [2024-10-29 13:08:05] iter = 07490, loss = 0.6562
2024-10-29 13:08:05: [2024-10-29 13:08:05] iter = 07500, loss = 3.4252
2024-10-29 13:08:06: [2024-10-29 13:08:06] iter = 07510, loss = 1.2597
2024-10-29 13:08:06: [2024-10-29 13:08:06] iter = 07520, loss = 6.7282
2024-10-29 13:08:06: [2024-10-29 13:08:06] iter = 07530, loss = 1.2731
2024-10-29 13:08:07: [2024-10-29 13:08:07] iter = 07540, loss = 3.1356
2024-10-29 13:08:07: [2024-10-29 13:08:07] iter = 07550, loss = 1.4716
2024-10-29 13:08:08: [2024-10-29 13:08:08] iter = 07560, loss = 1.4521
2024-10-29 13:08:08: [2024-10-29 13:08:08] iter = 07570, loss = 1.3831
2024-10-29 13:08:08: [2024-10-29 13:08:08] iter = 07580, loss = 0.8169
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 07590, loss = 1.2468
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 07600, loss = 1.0357
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 07610, loss = 1.7615
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 07620, loss = 0.9544
2024-10-29 13:08:10: [2024-10-29 13:08:10] iter = 07630, loss = 1.1029
2024-10-29 13:08:10: [2024-10-29 13:08:10] iter = 07640, loss = 3.5610
2024-10-29 13:08:10: [2024-10-29 13:08:10] iter = 07650, loss = 1.3648
2024-10-29 13:08:11: [2024-10-29 13:08:11] iter = 07660, loss = 1.1302
2024-10-29 13:08:11: [2024-10-29 13:08:11] iter = 07670, loss = 1.8358
2024-10-29 13:08:11: [2024-10-29 13:08:11] iter = 07680, loss = 0.9383
2024-10-29 13:08:12: [2024-10-29 13:08:12] iter = 07690, loss = 1.2763
2024-10-29 13:08:12: [2024-10-29 13:08:12] iter = 07700, loss = 1.4236
2024-10-29 13:08:12: [2024-10-29 13:08:12] iter = 07710, loss = 0.9119
2024-10-29 13:08:13: [2024-10-29 13:08:13] iter = 07720, loss = 1.6710
2024-10-29 13:08:13: [2024-10-29 13:08:13] iter = 07730, loss = 4.7006
2024-10-29 13:08:13: [2024-10-29 13:08:13] iter = 07740, loss = 1.7405
2024-10-29 13:08:14: [2024-10-29 13:08:14] iter = 07750, loss = 1.7144
2024-10-29 13:08:14: [2024-10-29 13:08:14] iter = 07760, loss = 3.9443
2024-10-29 13:08:14: [2024-10-29 13:08:14] iter = 07770, loss = 1.4639
2024-10-29 13:08:15: [2024-10-29 13:08:15] iter = 07780, loss = 1.4609
2024-10-29 13:08:15: [2024-10-29 13:08:15] iter = 07790, loss = 1.4690
2024-10-29 13:08:15: [2024-10-29 13:08:15] iter = 07800, loss = 3.7623
2024-10-29 13:08:16: [2024-10-29 13:08:16] iter = 07810, loss = 2.9382
2024-10-29 13:08:16: [2024-10-29 13:08:16] iter = 07820, loss = 1.3890
2024-10-29 13:08:16: [2024-10-29 13:08:16] iter = 07830, loss = 2.0119
2024-10-29 13:08:17: [2024-10-29 13:08:17] iter = 07840, loss = 11.7768
2024-10-29 13:08:17: [2024-10-29 13:08:17] iter = 07850, loss = 1.6861
2024-10-29 13:08:17: [2024-10-29 13:08:17] iter = 07860, loss = 1.6463
2024-10-29 13:08:18: [2024-10-29 13:08:18] iter = 07870, loss = 0.8116
2024-10-29 13:08:18: [2024-10-29 13:08:18] iter = 07880, loss = 1.0774
2024-10-29 13:08:18: [2024-10-29 13:08:18] iter = 07890, loss = 1.2594
2024-10-29 13:08:19: [2024-10-29 13:08:19] iter = 07900, loss = 1.2421
2024-10-29 13:08:19: [2024-10-29 13:08:19] iter = 07910, loss = 1.6092
2024-10-29 13:08:19: [2024-10-29 13:08:19] iter = 07920, loss = 1.3375
2024-10-29 13:08:20: [2024-10-29 13:08:20] iter = 07930, loss = 0.9038
2024-10-29 13:08:20: [2024-10-29 13:08:20] iter = 07940, loss = 1.2182
2024-10-29 13:08:20: [2024-10-29 13:08:20] iter = 07950, loss = 1.3347
2024-10-29 13:08:21: [2024-10-29 13:08:21] iter = 07960, loss = 3.7765
2024-10-29 13:08:21: [2024-10-29 13:08:21] iter = 07970, loss = 7.7356
2024-10-29 13:08:21: [2024-10-29 13:08:21] iter = 07980, loss = 1.3915
2024-10-29 13:08:22: [2024-10-29 13:08:22] iter = 07990, loss = 2.3606
2024-10-29 13:08:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 13:08:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:08:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 2599}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:08:53: Evaluate 5 random ConvNet, ACCmean = 0.6109 ACCstd = 0.0096
-------------------------
2024-10-29 13:08:53: Evaluate 5 random ConvNet, SENmean = 0.6183 SENstd = 0.0033
-------------------------
2024-10-29 13:08:53: Evaluate 5 random ConvNet, SPEmean = 0.6183 SPEstd = 0.0033
-------------------------
2024-10-29 13:08:53: Evaluate 5 random ConvNet, F!mean = 0.4972 F!std = 0.0042
-------------------------
2024-10-29 13:08:53: Evaluate 5 random ConvNet, mean = 0.6109 std = 0.0096
-------------------------
2024-10-29 13:08:53: [2024-10-29 13:08:53] iter = 08000, loss = 1.2456
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:08:53: [2024-10-29 13:08:53] iter = 08010, loss = 3.9755
2024-10-29 13:08:54: [2024-10-29 13:08:54] iter = 08020, loss = 1.1394
2024-10-29 13:08:54: [2024-10-29 13:08:54] iter = 08030, loss = 1.0746
2024-10-29 13:08:55: [2024-10-29 13:08:55] iter = 08040, loss = 0.9573
2024-10-29 13:08:55: [2024-10-29 13:08:55] iter = 08050, loss = 2.1815
2024-10-29 13:08:56: [2024-10-29 13:08:56] iter = 08060, loss = 1.6501
2024-10-29 13:08:56: [2024-10-29 13:08:56] iter = 08070, loss = 1.4903
2024-10-29 13:08:56: [2024-10-29 13:08:56] iter = 08080, loss = 2.0299
2024-10-29 13:08:57: [2024-10-29 13:08:57] iter = 08090, loss = 1.1599
2024-10-29 13:08:57: [2024-10-29 13:08:57] iter = 08100, loss = 1.2556
2024-10-29 13:08:57: [2024-10-29 13:08:57] iter = 08110, loss = 1.0565
2024-10-29 13:08:58: [2024-10-29 13:08:58] iter = 08120, loss = 1.4090
2024-10-29 13:08:58: [2024-10-29 13:08:58] iter = 08130, loss = 0.8860
2024-10-29 13:08:58: [2024-10-29 13:08:58] iter = 08140, loss = 5.1787
2024-10-29 13:08:59: [2024-10-29 13:08:59] iter = 08150, loss = 1.2955
2024-10-29 13:08:59: [2024-10-29 13:08:59] iter = 08160, loss = 2.3182
2024-10-29 13:08:59: [2024-10-29 13:08:59] iter = 08170, loss = 1.6741
2024-10-29 13:09:00: [2024-10-29 13:09:00] iter = 08180, loss = 2.2517
2024-10-29 13:09:00: [2024-10-29 13:09:00] iter = 08190, loss = 1.2988
2024-10-29 13:09:00: [2024-10-29 13:09:00] iter = 08200, loss = 1.0973
2024-10-29 13:09:01: [2024-10-29 13:09:01] iter = 08210, loss = 0.8868
2024-10-29 13:09:01: [2024-10-29 13:09:01] iter = 08220, loss = 1.7911
2024-10-29 13:09:01: [2024-10-29 13:09:01] iter = 08230, loss = 8.3460
2024-10-29 13:09:02: [2024-10-29 13:09:02] iter = 08240, loss = 2.3665
2024-10-29 13:09:02: [2024-10-29 13:09:02] iter = 08250, loss = 1.0938
2024-10-29 13:09:02: [2024-10-29 13:09:02] iter = 08260, loss = 1.6066
2024-10-29 13:09:03: [2024-10-29 13:09:03] iter = 08270, loss = 0.7767
2024-10-29 13:09:03: [2024-10-29 13:09:03] iter = 08280, loss = 1.2427
2024-10-29 13:09:03: [2024-10-29 13:09:03] iter = 08290, loss = 1.1759
2024-10-29 13:09:04: [2024-10-29 13:09:04] iter = 08300, loss = 2.0535
2024-10-29 13:09:04: [2024-10-29 13:09:04] iter = 08310, loss = 1.0229
2024-10-29 13:09:05: [2024-10-29 13:09:05] iter = 08320, loss = 2.1368
2024-10-29 13:09:05: [2024-10-29 13:09:05] iter = 08330, loss = 0.9406
2024-10-29 13:09:05: [2024-10-29 13:09:05] iter = 08340, loss = 0.8938
2024-10-29 13:09:06: [2024-10-29 13:09:06] iter = 08350, loss = 7.1215
2024-10-29 13:09:06: [2024-10-29 13:09:06] iter = 08360, loss = 1.0405
2024-10-29 13:09:06: [2024-10-29 13:09:06] iter = 08370, loss = 1.4968
2024-10-29 13:09:07: [2024-10-29 13:09:07] iter = 08380, loss = 1.3233
2024-10-29 13:09:07: [2024-10-29 13:09:07] iter = 08390, loss = 1.2700
2024-10-29 13:09:07: [2024-10-29 13:09:07] iter = 08400, loss = 1.4756
2024-10-29 13:09:08: [2024-10-29 13:09:08] iter = 08410, loss = 1.3683
2024-10-29 13:09:08: [2024-10-29 13:09:08] iter = 08420, loss = 1.2619
2024-10-29 13:09:08: [2024-10-29 13:09:08] iter = 08430, loss = 0.7436
2024-10-29 13:09:09: [2024-10-29 13:09:09] iter = 08440, loss = 0.9908
2024-10-29 13:09:09: [2024-10-29 13:09:09] iter = 08450, loss = 1.3741
2024-10-29 13:09:09: [2024-10-29 13:09:09] iter = 08460, loss = 1.1997
2024-10-29 13:09:10: [2024-10-29 13:09:10] iter = 08470, loss = 0.6439
2024-10-29 13:09:10: [2024-10-29 13:09:10] iter = 08480, loss = 2.4552
2024-10-29 13:09:10: [2024-10-29 13:09:10] iter = 08490, loss = 0.9804
2024-10-29 13:09:11: [2024-10-29 13:09:11] iter = 08500, loss = 2.3104
2024-10-29 13:09:11: [2024-10-29 13:09:11] iter = 08510, loss = 1.2819
2024-10-29 13:09:11: [2024-10-29 13:09:11] iter = 08520, loss = 1.3025
2024-10-29 13:09:12: [2024-10-29 13:09:12] iter = 08530, loss = 1.4187
2024-10-29 13:09:12: [2024-10-29 13:09:12] iter = 08540, loss = 1.0919
2024-10-29 13:09:12: [2024-10-29 13:09:12] iter = 08550, loss = 1.1033
2024-10-29 13:09:13: [2024-10-29 13:09:13] iter = 08560, loss = 1.3740
2024-10-29 13:09:13: [2024-10-29 13:09:13] iter = 08570, loss = 1.0026
2024-10-29 13:09:14: [2024-10-29 13:09:14] iter = 08580, loss = 1.5410
2024-10-29 13:09:14: [2024-10-29 13:09:14] iter = 08590, loss = 1.5195
2024-10-29 13:09:14: [2024-10-29 13:09:14] iter = 08600, loss = 3.0096
2024-10-29 13:09:15: [2024-10-29 13:09:15] iter = 08610, loss = 0.9024
2024-10-29 13:09:15: [2024-10-29 13:09:15] iter = 08620, loss = 5.3391
2024-10-29 13:09:16: [2024-10-29 13:09:16] iter = 08630, loss = 1.2251
2024-10-29 13:09:16: [2024-10-29 13:09:16] iter = 08640, loss = 1.3658
2024-10-29 13:09:16: [2024-10-29 13:09:16] iter = 08650, loss = 1.5050
2024-10-29 13:09:17: [2024-10-29 13:09:17] iter = 08660, loss = 1.5424
2024-10-29 13:09:17: [2024-10-29 13:09:17] iter = 08670, loss = 1.6626
2024-10-29 13:09:17: [2024-10-29 13:09:17] iter = 08680, loss = 3.9066
2024-10-29 13:09:18: [2024-10-29 13:09:18] iter = 08690, loss = 1.7141
2024-10-29 13:09:18: [2024-10-29 13:09:18] iter = 08700, loss = 2.4035
2024-10-29 13:09:19: [2024-10-29 13:09:19] iter = 08710, loss = 1.7105
2024-10-29 13:09:19: [2024-10-29 13:09:19] iter = 08720, loss = 1.7321
2024-10-29 13:09:19: [2024-10-29 13:09:19] iter = 08730, loss = 0.8697
2024-10-29 13:09:20: [2024-10-29 13:09:20] iter = 08740, loss = 0.9928
2024-10-29 13:09:20: [2024-10-29 13:09:20] iter = 08750, loss = 1.3114
2024-10-29 13:09:21: [2024-10-29 13:09:21] iter = 08760, loss = 0.6894
2024-10-29 13:09:21: [2024-10-29 13:09:21] iter = 08770, loss = 2.1868
2024-10-29 13:09:21: [2024-10-29 13:09:21] iter = 08780, loss = 1.1661
2024-10-29 13:09:22: [2024-10-29 13:09:22] iter = 08790, loss = 1.3209
2024-10-29 13:09:22: [2024-10-29 13:09:22] iter = 08800, loss = 0.6842
2024-10-29 13:09:23: [2024-10-29 13:09:23] iter = 08810, loss = 2.2591
2024-10-29 13:09:23: [2024-10-29 13:09:23] iter = 08820, loss = 1.6476
2024-10-29 13:09:23: [2024-10-29 13:09:23] iter = 08830, loss = 1.1690
2024-10-29 13:09:24: [2024-10-29 13:09:24] iter = 08840, loss = 1.1669
2024-10-29 13:09:24: [2024-10-29 13:09:24] iter = 08850, loss = 4.6635
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 08860, loss = 2.1888
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 08870, loss = 1.7611
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 08880, loss = 1.0192
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 08890, loss = 2.0949
2024-10-29 13:09:26: [2024-10-29 13:09:26] iter = 08900, loss = 1.3655
2024-10-29 13:09:26: [2024-10-29 13:09:26] iter = 08910, loss = 0.9333
2024-10-29 13:09:27: [2024-10-29 13:09:27] iter = 08920, loss = 1.4555
2024-10-29 13:09:27: [2024-10-29 13:09:27] iter = 08930, loss = 1.2565
2024-10-29 13:09:27: [2024-10-29 13:09:27] iter = 08940, loss = 1.1898
2024-10-29 13:09:28: [2024-10-29 13:09:28] iter = 08950, loss = 1.0554
2024-10-29 13:09:28: [2024-10-29 13:09:28] iter = 08960, loss = 1.0929
2024-10-29 13:09:28: [2024-10-29 13:09:28] iter = 08970, loss = 2.1257
2024-10-29 13:09:29: [2024-10-29 13:09:28] iter = 08980, loss = 1.5573
2024-10-29 13:09:29: [2024-10-29 13:09:29] iter = 08990, loss = 0.9605
2024-10-29 13:09:29: [2024-10-29 13:09:29] iter = 09000, loss = 2.9808
2024-10-29 13:09:30: [2024-10-29 13:09:30] iter = 09010, loss = 1.6934
2024-10-29 13:09:30: [2024-10-29 13:09:30] iter = 09020, loss = 0.9414
2024-10-29 13:09:30: [2024-10-29 13:09:30] iter = 09030, loss = 1.2658
2024-10-29 13:09:31: [2024-10-29 13:09:31] iter = 09040, loss = 3.8251
2024-10-29 13:09:31: [2024-10-29 13:09:31] iter = 09050, loss = 1.0319
2024-10-29 13:09:31: [2024-10-29 13:09:31] iter = 09060, loss = 2.9611
2024-10-29 13:09:32: [2024-10-29 13:09:32] iter = 09070, loss = 1.0295
2024-10-29 13:09:32: [2024-10-29 13:09:32] iter = 09080, loss = 1.2405
2024-10-29 13:09:33: [2024-10-29 13:09:33] iter = 09090, loss = 1.5537
2024-10-29 13:09:33: [2024-10-29 13:09:33] iter = 09100, loss = 0.9779
2024-10-29 13:09:33: [2024-10-29 13:09:33] iter = 09110, loss = 1.1999
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 09120, loss = 3.1534
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 09130, loss = 1.2138
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 09140, loss = 1.9640
2024-10-29 13:09:35: [2024-10-29 13:09:35] iter = 09150, loss = 1.0316
2024-10-29 13:09:35: [2024-10-29 13:09:35] iter = 09160, loss = 1.1508
2024-10-29 13:09:35: [2024-10-29 13:09:35] iter = 09170, loss = 0.8060
2024-10-29 13:09:36: [2024-10-29 13:09:36] iter = 09180, loss = 1.1308
2024-10-29 13:09:36: [2024-10-29 13:09:36] iter = 09190, loss = 1.1580
2024-10-29 13:09:36: [2024-10-29 13:09:36] iter = 09200, loss = 0.8839
2024-10-29 13:09:37: [2024-10-29 13:09:37] iter = 09210, loss = 1.2904
2024-10-29 13:09:37: [2024-10-29 13:09:37] iter = 09220, loss = 1.2597
2024-10-29 13:09:37: [2024-10-29 13:09:37] iter = 09230, loss = 0.8966
2024-10-29 13:09:38: [2024-10-29 13:09:38] iter = 09240, loss = 0.7995
2024-10-29 13:09:38: [2024-10-29 13:09:38] iter = 09250, loss = 1.2881
2024-10-29 13:09:38: [2024-10-29 13:09:38] iter = 09260, loss = 2.4585
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 09270, loss = 1.2831
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 09280, loss = 0.8318
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 09290, loss = 1.6012
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 09300, loss = 1.0715
2024-10-29 13:09:40: [2024-10-29 13:09:40] iter = 09310, loss = 1.2928
2024-10-29 13:09:40: [2024-10-29 13:09:40] iter = 09320, loss = 1.8001
2024-10-29 13:09:41: [2024-10-29 13:09:41] iter = 09330, loss = 1.7222
2024-10-29 13:09:41: [2024-10-29 13:09:41] iter = 09340, loss = 0.8902
2024-10-29 13:09:41: [2024-10-29 13:09:41] iter = 09350, loss = 1.0915
2024-10-29 13:09:42: [2024-10-29 13:09:42] iter = 09360, loss = 0.6876
2024-10-29 13:09:42: [2024-10-29 13:09:42] iter = 09370, loss = 1.5585
2024-10-29 13:09:42: [2024-10-29 13:09:42] iter = 09380, loss = 1.9081
2024-10-29 13:09:43: [2024-10-29 13:09:43] iter = 09390, loss = 0.8764
2024-10-29 13:09:43: [2024-10-29 13:09:43] iter = 09400, loss = 1.8682
2024-10-29 13:09:43: [2024-10-29 13:09:43] iter = 09410, loss = 0.8919
2024-10-29 13:09:44: [2024-10-29 13:09:44] iter = 09420, loss = 2.0984
2024-10-29 13:09:44: [2024-10-29 13:09:44] iter = 09430, loss = 1.0780
2024-10-29 13:09:44: [2024-10-29 13:09:44] iter = 09440, loss = 0.8262
2024-10-29 13:09:45: [2024-10-29 13:09:45] iter = 09450, loss = 1.6049
2024-10-29 13:09:45: [2024-10-29 13:09:45] iter = 09460, loss = 3.0307
2024-10-29 13:09:45: [2024-10-29 13:09:45] iter = 09470, loss = 1.3636
2024-10-29 13:09:46: [2024-10-29 13:09:46] iter = 09480, loss = 0.6917
2024-10-29 13:09:46: [2024-10-29 13:09:46] iter = 09490, loss = 1.2716
2024-10-29 13:09:46: [2024-10-29 13:09:46] iter = 09500, loss = 1.2943
2024-10-29 13:09:47: [2024-10-29 13:09:47] iter = 09510, loss = 0.9055
2024-10-29 13:09:47: [2024-10-29 13:09:47] iter = 09520, loss = 1.6657
2024-10-29 13:09:47: [2024-10-29 13:09:47] iter = 09530, loss = 1.6695
2024-10-29 13:09:48: [2024-10-29 13:09:48] iter = 09540, loss = 1.1315
2024-10-29 13:09:48: [2024-10-29 13:09:48] iter = 09550, loss = 1.0140
2024-10-29 13:09:48: [2024-10-29 13:09:48] iter = 09560, loss = 1.2003
2024-10-29 13:09:49: [2024-10-29 13:09:49] iter = 09570, loss = 4.1177
2024-10-29 13:09:49: [2024-10-29 13:09:49] iter = 09580, loss = 1.1552
2024-10-29 13:09:49: [2024-10-29 13:09:49] iter = 09590, loss = 0.7703
2024-10-29 13:09:50: [2024-10-29 13:09:50] iter = 09600, loss = 2.1803
2024-10-29 13:09:50: [2024-10-29 13:09:50] iter = 09610, loss = 1.2775
2024-10-29 13:09:50: [2024-10-29 13:09:50] iter = 09620, loss = 1.1699
2024-10-29 13:09:51: [2024-10-29 13:09:51] iter = 09630, loss = 1.6585
2024-10-29 13:09:51: [2024-10-29 13:09:51] iter = 09640, loss = 1.4369
2024-10-29 13:09:51: [2024-10-29 13:09:51] iter = 09650, loss = 1.8264
2024-10-29 13:09:51: [2024-10-29 13:09:51] iter = 09660, loss = 1.1656
2024-10-29 13:09:52: [2024-10-29 13:09:52] iter = 09670, loss = 0.9910
2024-10-29 13:09:52: [2024-10-29 13:09:52] iter = 09680, loss = 1.1177
2024-10-29 13:09:52: [2024-10-29 13:09:52] iter = 09690, loss = 1.0112
2024-10-29 13:09:53: [2024-10-29 13:09:53] iter = 09700, loss = 2.1566
2024-10-29 13:09:53: [2024-10-29 13:09:53] iter = 09710, loss = 1.2606
2024-10-29 13:09:53: [2024-10-29 13:09:53] iter = 09720, loss = 0.8846
2024-10-29 13:09:54: [2024-10-29 13:09:54] iter = 09730, loss = 1.3700
2024-10-29 13:09:54: [2024-10-29 13:09:54] iter = 09740, loss = 0.7462
2024-10-29 13:09:54: [2024-10-29 13:09:54] iter = 09750, loss = 1.0379
2024-10-29 13:09:55: [2024-10-29 13:09:55] iter = 09760, loss = 0.9870
2024-10-29 13:09:55: [2024-10-29 13:09:55] iter = 09770, loss = 1.0607
2024-10-29 13:09:55: [2024-10-29 13:09:55] iter = 09780, loss = 0.7106
2024-10-29 13:09:56: [2024-10-29 13:09:56] iter = 09790, loss = 2.0232
2024-10-29 13:09:56: [2024-10-29 13:09:56] iter = 09800, loss = 2.0521
2024-10-29 13:09:56: [2024-10-29 13:09:56] iter = 09810, loss = 0.9144
2024-10-29 13:09:57: [2024-10-29 13:09:57] iter = 09820, loss = 1.8873
2024-10-29 13:09:57: [2024-10-29 13:09:57] iter = 09830, loss = 1.2615
2024-10-29 13:09:57: [2024-10-29 13:09:57] iter = 09840, loss = 1.9513
2024-10-29 13:09:58: [2024-10-29 13:09:58] iter = 09850, loss = 1.3770
2024-10-29 13:09:58: [2024-10-29 13:09:58] iter = 09860, loss = 0.9770
2024-10-29 13:09:58: [2024-10-29 13:09:58] iter = 09870, loss = 2.1614
2024-10-29 13:09:59: [2024-10-29 13:09:59] iter = 09880, loss = 1.0728
2024-10-29 13:09:59: [2024-10-29 13:09:59] iter = 09890, loss = 1.2192
2024-10-29 13:09:59: [2024-10-29 13:09:59] iter = 09900, loss = 1.2654
2024-10-29 13:10:00: [2024-10-29 13:10:00] iter = 09910, loss = 1.7460
2024-10-29 13:10:00: [2024-10-29 13:10:00] iter = 09920, loss = 4.7840
2024-10-29 13:10:00: [2024-10-29 13:10:00] iter = 09930, loss = 1.9090
2024-10-29 13:10:01: [2024-10-29 13:10:01] iter = 09940, loss = 1.6407
2024-10-29 13:10:01: [2024-10-29 13:10:01] iter = 09950, loss = 1.3578
2024-10-29 13:10:02: [2024-10-29 13:10:02] iter = 09960, loss = 1.2647
2024-10-29 13:10:02: [2024-10-29 13:10:02] iter = 09970, loss = 1.1155
2024-10-29 13:10:02: [2024-10-29 13:10:02] iter = 09980, loss = 0.9440
2024-10-29 13:10:03: [2024-10-29 13:10:03] iter = 09990, loss = 1.0236
2024-10-29 13:10:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 13:10:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:10:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 3570}

[2024-10-29 12:56:19] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.018901 train acc = 1.0000, test acc = 0.6463, test_sen =0.6022, test_spe =0.6022, test_f1 =0.5092
[2024-10-29 12:56:24] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.003971 train acc = 1.0000, test acc = 0.6006, test_sen =0.6074, test_spe =0.6074, test_f1 =0.4888
[2024-10-29 12:56:30] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.006736 train acc = 1.0000, test acc = 0.6311, test_sen =0.6018, test_spe =0.6018, test_f1 =0.5019
[2024-10-29 12:57:47] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.007019 train acc = 1.0000, test acc = 0.5803, test_sen =0.6273, test_spe =0.6273, test_f1 =0.4840
[2024-10-29 12:57:53] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.008771 train acc = 1.0000, test acc = 0.6321, test_sen =0.6149, test_spe =0.6149, test_f1 =0.5067
[2024-10-29 12:57:58] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.066755 train acc = 1.0000, test acc = 0.6275, test_sen =0.6283, test_spe =0.6283, test_f1 =0.5087
[2024-10-29 12:58:04] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.004125 train acc = 1.0000, test acc = 0.5720, test_sen =0.6297, test_spe =0.6297, test_f1 =0.4802
[2024-10-29 12:58:09] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.003123 train acc = 1.0000, test acc = 0.6338, test_sen =0.6237, test_spe =0.6237, test_f1 =0.5104
[2024-10-29 12:59:27] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.012338 train acc = 1.0000, test acc = 0.4676, test_sen =0.5999, test_spe =0.5999, test_f1 =0.4143
[2024-10-29 12:59:33] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.301355 train acc = 0.9000, test acc = 0.4599, test_sen =0.5916, test_spe =0.5916, test_f1 =0.4080
[2024-10-29 12:59:38] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.047286 train acc = 1.0000, test acc = 0.4379, test_sen =0.5845, test_spe =0.5845, test_f1 =0.3932
[2024-10-29 12:59:43] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.050279 train acc = 0.9500, test acc = 0.4656, test_sen =0.6020, test_spe =0.6020, test_f1 =0.4134
[2024-10-29 12:59:49] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.034442 train acc = 1.0000, test acc = 0.4636, test_sen =0.5922, test_spe =0.5922, test_f1 =0.4103
[2024-10-29 13:01:08] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.014786 train acc = 1.0000, test acc = 0.6114, test_sen =0.6080, test_spe =0.6080, test_f1 =0.4944
[2024-10-29 13:01:14] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.014568 train acc = 1.0000, test acc = 0.6162, test_sen =0.6013, test_spe =0.6013, test_f1 =0.4945
[2024-10-29 13:01:21] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.012725 train acc = 1.0000, test acc = 0.6212, test_sen =0.6077, test_spe =0.6077, test_f1 =0.4990
[2024-10-29 13:01:26] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.061211 train acc = 1.0000, test acc = 0.6695, test_sen =0.6021, test_spe =0.6021, test_f1 =0.5200
[2024-10-29 13:01:33] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.003336 train acc = 1.0000, test acc = 0.5956, test_sen =0.6132, test_spe =0.6132, test_f1 =0.4880
[2024-10-29 13:01:41] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.059312 train acc = 1.0000, test acc = 0.4198, test_sen =0.5197, test_spe =0.5197, test_f1 =0.3704
[2024-10-29 13:01:47] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002202 train acc = 1.0000, test acc = 0.3835, test_sen =0.5159, test_spe =0.5159, test_f1 =0.3472
[2024-10-29 13:01:52] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.007033 train acc = 1.0000, test acc = 0.4090, test_sen =0.5204, test_spe =0.5204, test_f1 =0.3640
[2024-10-29 13:01:58] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.000748 train acc = 1.0000, test acc = 0.3863, test_sen =0.5193, test_spe =0.5193, test_f1 =0.3496
[2024-10-29 13:02:03] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001589 train acc = 1.0000, test acc = 0.3958, test_sen =0.5166, test_spe =0.5166, test_f1 =0.3551
[2024-10-29 13:03:22] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001957 train acc = 1.0000, test acc = 0.6117, test_sen =0.6140, test_spe =0.6140, test_f1 =0.4963
[2024-10-29 13:03:27] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.015764 train acc = 1.0000, test acc = 0.5859, test_sen =0.6099, test_spe =0.6099, test_f1 =0.4821
[2024-10-29 13:03:33] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.015995 train acc = 1.0000, test acc = 0.5900, test_sen =0.6109, test_spe =0.6109, test_f1 =0.4845
[2024-10-29 13:03:38] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.003704 train acc = 1.0000, test acc = 0.5929, test_sen =0.6106, test_spe =0.6106, test_f1 =0.4859
[2024-10-29 13:03:44] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.002622 train acc = 1.0000, test acc = 0.5275, test_sen =0.6088, test_spe =0.6088, test_f1 =0.4508
[2024-10-29 13:05:05] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.004185 train acc = 1.0000, test acc = 0.4124, test_sen =0.5780, test_spe =0.5780, test_f1 =0.3758
[2024-10-29 13:05:10] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004578 train acc = 1.0000, test acc = 0.3889, test_sen =0.5759, test_spe =0.5759, test_f1 =0.3598
[2024-10-29 13:05:16] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.002464 train acc = 1.0000, test acc = 0.3882, test_sen =0.5795, test_spe =0.5795, test_f1 =0.3598
[2024-10-29 13:05:23] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.000191 train acc = 1.0000, test acc = 0.3955, test_sen =0.5742, test_spe =0.5742, test_f1 =0.3640
[2024-10-29 13:05:28] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.008641 train acc = 1.0000, test acc = 0.3700, test_sen =0.5713, test_spe =0.5713, test_f1 =0.3461
[2024-10-29 13:06:46] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.095622 train acc = 1.0000, test acc = 0.6002, test_sen =0.6297, test_spe =0.6297, test_f1 =0.4951
[2024-10-29 13:06:51] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.010275 train acc = 1.0000, test acc = 0.6185, test_sen =0.6383, test_spe =0.6383, test_f1 =0.5072
[2024-10-29 13:06:58] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.003866 train acc = 1.0000, test acc = 0.5855, test_sen =0.6398, test_spe =0.6398, test_f1 =0.4901
[2024-10-29 13:07:04] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001628 train acc = 1.0000, test acc = 0.5709, test_sen =0.6355, test_spe =0.6355, test_f1 =0.4811
[2024-10-29 13:07:10] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.009225 train acc = 1.0000, test acc = 0.5984, test_sen =0.6422, test_spe =0.6422, test_f1 =0.4977
[2024-10-29 13:08:28] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.012757 train acc = 1.0000, test acc = 0.6257, test_sen =0.6124, test_spe =0.6124, test_f1 =0.5028
[2024-10-29 13:08:34] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.007666 train acc = 1.0000, test acc = 0.6161, test_sen =0.6206, test_spe =0.6206, test_f1 =0.5006
[2024-10-29 13:08:39] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.004016 train acc = 1.0000, test acc = 0.6010, test_sen =0.6222, test_spe =0.6222, test_f1 =0.4934
[2024-10-29 13:08:45] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.005691 train acc = 1.0000, test acc = 0.5999, test_sen =0.6185, test_spe =0.6185, test_f1 =0.4917
[2024-10-29 13:08:53] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.116358 train acc = 1.0000, test acc = 0.6120, test_sen =0.6180, test_spe =0.6180, test_f1 =0.4977
[2024-10-29 13:10:10] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.004452 train acc = 1.0000, test acc = 0.5925, test_sen =0.6369, test_spe =0.6369, test_f1 =0.4931
[2024-10-29 13:10:17] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.004622 train acc = 1.0000, test acc = 0.5871, test_sen =0.6333, test_spe =0.6333, test_f1 =0.4892
[2024-10-29 13:10:22] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001184 train acc = 1.0000, test acc = 0.5860, test_sen =0.6270, test_spe =0.6270, test_f1 =0.4869
[2024-10-29 13:10:28] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.077686 train acc = 1.0000, test acc = 0.5515, test_sen =0.6338, test_spe =0.6338, test_f1 =0.4700/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:10:33: Evaluate 5 random ConvNet, ACCmean = 0.5796 ACCstd = 0.0145
-------------------------
2024-10-29 13:10:33: Evaluate 5 random ConvNet, SENmean = 0.6329 SENstd = 0.0032
-------------------------
2024-10-29 13:10:33: Evaluate 5 random ConvNet, SPEmean = 0.6329 SPEstd = 0.0032
-------------------------
2024-10-29 13:10:33: Evaluate 5 random ConvNet, F!mean = 0.4850 F!std = 0.0079
-------------------------
2024-10-29 13:10:33: Evaluate 5 random ConvNet, mean = 0.5796 std = 0.0145
-------------------------
2024-10-29 13:10:33: [2024-10-29 13:10:33] iter = 10000, loss = 0.9437
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:10:33: [2024-10-29 13:10:33] iter = 10010, loss = 0.9698
2024-10-29 13:10:34: [2024-10-29 13:10:34] iter = 10020, loss = 1.1486
2024-10-29 13:10:34: [2024-10-29 13:10:34] iter = 10030, loss = 7.1219
2024-10-29 13:10:34: [2024-10-29 13:10:34] iter = 10040, loss = 1.0554
2024-10-29 13:10:35: [2024-10-29 13:10:35] iter = 10050, loss = 2.8946
2024-10-29 13:10:35: [2024-10-29 13:10:35] iter = 10060, loss = 1.9845
2024-10-29 13:10:35: [2024-10-29 13:10:35] iter = 10070, loss = 1.1870
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 10080, loss = 1.1307
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 10090, loss = 3.6352
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 10100, loss = 2.2117
2024-10-29 13:10:37: [2024-10-29 13:10:37] iter = 10110, loss = 1.0424
2024-10-29 13:10:37: [2024-10-29 13:10:37] iter = 10120, loss = 0.9413
2024-10-29 13:10:37: [2024-10-29 13:10:37] iter = 10130, loss = 1.6869
2024-10-29 13:10:38: [2024-10-29 13:10:38] iter = 10140, loss = 1.4139
2024-10-29 13:10:38: [2024-10-29 13:10:38] iter = 10150, loss = 1.4484
2024-10-29 13:10:38: [2024-10-29 13:10:38] iter = 10160, loss = 1.5367
2024-10-29 13:10:39: [2024-10-29 13:10:39] iter = 10170, loss = 1.2638
2024-10-29 13:10:39: [2024-10-29 13:10:39] iter = 10180, loss = 1.0518
2024-10-29 13:10:39: [2024-10-29 13:10:39] iter = 10190, loss = 1.2018
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 10200, loss = 1.3333
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 10210, loss = 1.2225
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 10220, loss = 1.3869
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 10230, loss = 1.5365
2024-10-29 13:10:41: [2024-10-29 13:10:41] iter = 10240, loss = 6.2450
2024-10-29 13:10:41: [2024-10-29 13:10:41] iter = 10250, loss = 1.9614
2024-10-29 13:10:41: [2024-10-29 13:10:41] iter = 10260, loss = 1.5085
2024-10-29 13:10:42: [2024-10-29 13:10:42] iter = 10270, loss = 1.4338
2024-10-29 13:10:42: [2024-10-29 13:10:42] iter = 10280, loss = 4.3520
2024-10-29 13:10:42: [2024-10-29 13:10:42] iter = 10290, loss = 1.0497
2024-10-29 13:10:43: [2024-10-29 13:10:43] iter = 10300, loss = 1.7409
2024-10-29 13:10:43: [2024-10-29 13:10:43] iter = 10310, loss = 1.4139
2024-10-29 13:10:43: [2024-10-29 13:10:43] iter = 10320, loss = 1.8287
2024-10-29 13:10:44: [2024-10-29 13:10:44] iter = 10330, loss = 1.1666
2024-10-29 13:10:44: [2024-10-29 13:10:44] iter = 10340, loss = 1.0016
2024-10-29 13:10:44: [2024-10-29 13:10:44] iter = 10350, loss = 1.1110
2024-10-29 13:10:45: [2024-10-29 13:10:45] iter = 10360, loss = 1.2752
2024-10-29 13:10:45: [2024-10-29 13:10:45] iter = 10370, loss = 0.8628
2024-10-29 13:10:45: [2024-10-29 13:10:45] iter = 10380, loss = 0.6969
2024-10-29 13:10:46: [2024-10-29 13:10:46] iter = 10390, loss = 1.1585
2024-10-29 13:10:46: [2024-10-29 13:10:46] iter = 10400, loss = 4.4136
2024-10-29 13:10:46: [2024-10-29 13:10:46] iter = 10410, loss = 0.9035
2024-10-29 13:10:47: [2024-10-29 13:10:47] iter = 10420, loss = 1.0907
2024-10-29 13:10:47: [2024-10-29 13:10:47] iter = 10430, loss = 2.3233
2024-10-29 13:10:47: [2024-10-29 13:10:47] iter = 10440, loss = 1.3226
2024-10-29 13:10:48: [2024-10-29 13:10:48] iter = 10450, loss = 0.8951
2024-10-29 13:10:48: [2024-10-29 13:10:48] iter = 10460, loss = 0.8558
2024-10-29 13:10:48: [2024-10-29 13:10:48] iter = 10470, loss = 0.9801
2024-10-29 13:10:49: [2024-10-29 13:10:49] iter = 10480, loss = 1.1205
2024-10-29 13:10:49: [2024-10-29 13:10:49] iter = 10490, loss = 2.7837
2024-10-29 13:10:50: [2024-10-29 13:10:50] iter = 10500, loss = 1.5063
2024-10-29 13:10:50: [2024-10-29 13:10:50] iter = 10510, loss = 1.0835
2024-10-29 13:10:50: [2024-10-29 13:10:50] iter = 10520, loss = 1.3227
2024-10-29 13:10:51: [2024-10-29 13:10:51] iter = 10530, loss = 1.4759
2024-10-29 13:10:51: [2024-10-29 13:10:51] iter = 10540, loss = 0.8091
2024-10-29 13:10:51: [2024-10-29 13:10:51] iter = 10550, loss = 1.3630
2024-10-29 13:10:52: [2024-10-29 13:10:52] iter = 10560, loss = 1.1334
2024-10-29 13:10:52: [2024-10-29 13:10:52] iter = 10570, loss = 1.1992
2024-10-29 13:10:52: [2024-10-29 13:10:52] iter = 10580, loss = 1.2092
2024-10-29 13:10:53: [2024-10-29 13:10:53] iter = 10590, loss = 0.9966
2024-10-29 13:10:53: [2024-10-29 13:10:53] iter = 10600, loss = 0.6855
2024-10-29 13:10:53: [2024-10-29 13:10:53] iter = 10610, loss = 1.0656
2024-10-29 13:10:54: [2024-10-29 13:10:54] iter = 10620, loss = 0.8723
2024-10-29 13:10:54: [2024-10-29 13:10:54] iter = 10630, loss = 0.7087
2024-10-29 13:10:55: [2024-10-29 13:10:55] iter = 10640, loss = 1.1314
2024-10-29 13:10:55: [2024-10-29 13:10:55] iter = 10650, loss = 2.0616
2024-10-29 13:10:55: [2024-10-29 13:10:55] iter = 10660, loss = 0.8165
2024-10-29 13:10:56: [2024-10-29 13:10:56] iter = 10670, loss = 1.5994
2024-10-29 13:10:56: [2024-10-29 13:10:56] iter = 10680, loss = 0.8896
2024-10-29 13:10:57: [2024-10-29 13:10:57] iter = 10690, loss = 1.8538
2024-10-29 13:10:57: [2024-10-29 13:10:57] iter = 10700, loss = 2.4886
2024-10-29 13:10:58: [2024-10-29 13:10:58] iter = 10710, loss = 0.9672
2024-10-29 13:10:58: [2024-10-29 13:10:58] iter = 10720, loss = 2.2028
2024-10-29 13:10:59: [2024-10-29 13:10:59] iter = 10730, loss = 1.0007
2024-10-29 13:10:59: [2024-10-29 13:10:59] iter = 10740, loss = 1.4144
2024-10-29 13:10:59: [2024-10-29 13:10:59] iter = 10750, loss = 1.3481
2024-10-29 13:11:00: [2024-10-29 13:11:00] iter = 10760, loss = 0.8772
2024-10-29 13:11:00: [2024-10-29 13:11:00] iter = 10770, loss = 0.9560
2024-10-29 13:11:00: [2024-10-29 13:11:00] iter = 10780, loss = 2.9986
2024-10-29 13:11:01: [2024-10-29 13:11:01] iter = 10790, loss = 1.5920
2024-10-29 13:11:01: [2024-10-29 13:11:01] iter = 10800, loss = 0.9963
2024-10-29 13:11:01: [2024-10-29 13:11:01] iter = 10810, loss = 1.2343
2024-10-29 13:11:02: [2024-10-29 13:11:02] iter = 10820, loss = 1.2354
2024-10-29 13:11:02: [2024-10-29 13:11:02] iter = 10830, loss = 1.0381
2024-10-29 13:11:02: [2024-10-29 13:11:02] iter = 10840, loss = 2.1141
2024-10-29 13:11:03: [2024-10-29 13:11:03] iter = 10850, loss = 1.4241
2024-10-29 13:11:03: [2024-10-29 13:11:03] iter = 10860, loss = 1.3857
2024-10-29 13:11:03: [2024-10-29 13:11:03] iter = 10870, loss = 0.9962
2024-10-29 13:11:04: [2024-10-29 13:11:04] iter = 10880, loss = 0.9818
2024-10-29 13:11:04: [2024-10-29 13:11:04] iter = 10890, loss = 1.7845
2024-10-29 13:11:04: [2024-10-29 13:11:04] iter = 10900, loss = 1.4763
2024-10-29 13:11:05: [2024-10-29 13:11:05] iter = 10910, loss = 0.7665
2024-10-29 13:11:05: [2024-10-29 13:11:05] iter = 10920, loss = 1.2312
2024-10-29 13:11:05: [2024-10-29 13:11:05] iter = 10930, loss = 1.3410
2024-10-29 13:11:06: [2024-10-29 13:11:06] iter = 10940, loss = 1.3194
2024-10-29 13:11:06: [2024-10-29 13:11:06] iter = 10950, loss = 1.9530
2024-10-29 13:11:06: [2024-10-29 13:11:06] iter = 10960, loss = 1.2822
2024-10-29 13:11:07: [2024-10-29 13:11:07] iter = 10970, loss = 1.3570
2024-10-29 13:11:07: [2024-10-29 13:11:07] iter = 10980, loss = 1.6557
2024-10-29 13:11:08: [2024-10-29 13:11:08] iter = 10990, loss = 1.1348
2024-10-29 13:11:08: [2024-10-29 13:11:08] iter = 11000, loss = 1.9599
2024-10-29 13:11:08: [2024-10-29 13:11:08] iter = 11010, loss = 0.9923
2024-10-29 13:11:09: [2024-10-29 13:11:09] iter = 11020, loss = 1.2618
2024-10-29 13:11:09: [2024-10-29 13:11:09] iter = 11030, loss = 1.0490
2024-10-29 13:11:09: [2024-10-29 13:11:09] iter = 11040, loss = 1.0861
2024-10-29 13:11:10: [2024-10-29 13:11:10] iter = 11050, loss = 0.8544
2024-10-29 13:11:10: [2024-10-29 13:11:10] iter = 11060, loss = 1.3820
2024-10-29 13:11:10: [2024-10-29 13:11:10] iter = 11070, loss = 1.0686
2024-10-29 13:11:11: [2024-10-29 13:11:11] iter = 11080, loss = 1.1394
2024-10-29 13:11:11: [2024-10-29 13:11:11] iter = 11090, loss = 1.1187
2024-10-29 13:11:11: [2024-10-29 13:11:11] iter = 11100, loss = 1.2346
2024-10-29 13:11:12: [2024-10-29 13:11:12] iter = 11110, loss = 2.8235
2024-10-29 13:11:12: [2024-10-29 13:11:12] iter = 11120, loss = 1.4570
2024-10-29 13:11:12: [2024-10-29 13:11:12] iter = 11130, loss = 0.8913
2024-10-29 13:11:13: [2024-10-29 13:11:13] iter = 11140, loss = 1.2646
2024-10-29 13:11:13: [2024-10-29 13:11:13] iter = 11150, loss = 1.1756
2024-10-29 13:11:13: [2024-10-29 13:11:13] iter = 11160, loss = 1.0144
2024-10-29 13:11:14: [2024-10-29 13:11:14] iter = 11170, loss = 0.9920
2024-10-29 13:11:14: [2024-10-29 13:11:14] iter = 11180, loss = 1.0815
2024-10-29 13:11:14: [2024-10-29 13:11:14] iter = 11190, loss = 2.1282
2024-10-29 13:11:15: [2024-10-29 13:11:15] iter = 11200, loss = 2.4561
2024-10-29 13:11:15: [2024-10-29 13:11:15] iter = 11210, loss = 4.9971
2024-10-29 13:11:16: [2024-10-29 13:11:15] iter = 11220, loss = 1.6043
2024-10-29 13:11:16: [2024-10-29 13:11:16] iter = 11230, loss = 1.7303
2024-10-29 13:11:16: [2024-10-29 13:11:16] iter = 11240, loss = 0.6994
2024-10-29 13:11:17: [2024-10-29 13:11:16] iter = 11250, loss = 1.0271
2024-10-29 13:11:17: [2024-10-29 13:11:17] iter = 11260, loss = 0.8311
2024-10-29 13:11:17: [2024-10-29 13:11:17] iter = 11270, loss = 3.3039
2024-10-29 13:11:18: [2024-10-29 13:11:18] iter = 11280, loss = 1.6661
2024-10-29 13:11:18: [2024-10-29 13:11:18] iter = 11290, loss = 1.0564
2024-10-29 13:11:18: [2024-10-29 13:11:18] iter = 11300, loss = 0.7887
2024-10-29 13:11:19: [2024-10-29 13:11:19] iter = 11310, loss = 2.2251
2024-10-29 13:11:19: [2024-10-29 13:11:19] iter = 11320, loss = 1.0311
2024-10-29 13:11:19: [2024-10-29 13:11:19] iter = 11330, loss = 2.0282
2024-10-29 13:11:20: [2024-10-29 13:11:20] iter = 11340, loss = 5.1900
2024-10-29 13:11:20: [2024-10-29 13:11:20] iter = 11350, loss = 2.8250
2024-10-29 13:11:20: [2024-10-29 13:11:20] iter = 11360, loss = 1.4389
2024-10-29 13:11:21: [2024-10-29 13:11:21] iter = 11370, loss = 0.8521
2024-10-29 13:11:21: [2024-10-29 13:11:21] iter = 11380, loss = 2.1832
2024-10-29 13:11:22: [2024-10-29 13:11:22] iter = 11390, loss = 1.0118
2024-10-29 13:11:22: [2024-10-29 13:11:22] iter = 11400, loss = 0.8998
2024-10-29 13:11:22: [2024-10-29 13:11:22] iter = 11410, loss = 1.5848
2024-10-29 13:11:23: [2024-10-29 13:11:23] iter = 11420, loss = 0.9077
2024-10-29 13:11:23: [2024-10-29 13:11:23] iter = 11430, loss = 1.1269
2024-10-29 13:11:24: [2024-10-29 13:11:24] iter = 11440, loss = 0.9784
2024-10-29 13:11:24: [2024-10-29 13:11:24] iter = 11450, loss = 1.1166
2024-10-29 13:11:25: [2024-10-29 13:11:25] iter = 11460, loss = 1.0328
2024-10-29 13:11:25: [2024-10-29 13:11:25] iter = 11470, loss = 1.3520
2024-10-29 13:11:25: [2024-10-29 13:11:25] iter = 11480, loss = 1.2626
2024-10-29 13:11:26: [2024-10-29 13:11:26] iter = 11490, loss = 0.8796
2024-10-29 13:11:26: [2024-10-29 13:11:26] iter = 11500, loss = 1.0936
2024-10-29 13:11:27: [2024-10-29 13:11:27] iter = 11510, loss = 1.0736
2024-10-29 13:11:27: [2024-10-29 13:11:27] iter = 11520, loss = 1.1865
2024-10-29 13:11:27: [2024-10-29 13:11:27] iter = 11530, loss = 0.9470
2024-10-29 13:11:28: [2024-10-29 13:11:28] iter = 11540, loss = 1.4233
2024-10-29 13:11:28: [2024-10-29 13:11:28] iter = 11550, loss = 1.2325
2024-10-29 13:11:29: [2024-10-29 13:11:29] iter = 11560, loss = 1.3557
2024-10-29 13:11:29: [2024-10-29 13:11:29] iter = 11570, loss = 1.0329
2024-10-29 13:11:29: [2024-10-29 13:11:29] iter = 11580, loss = 1.5497
2024-10-29 13:11:30: [2024-10-29 13:11:30] iter = 11590, loss = 0.8826
2024-10-29 13:11:30: [2024-10-29 13:11:30] iter = 11600, loss = 8.5492
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 11610, loss = 1.2780
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 11620, loss = 3.3124
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 11630, loss = 6.6471
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 11640, loss = 1.3567
2024-10-29 13:11:32: [2024-10-29 13:11:32] iter = 11650, loss = 1.4176
2024-10-29 13:11:32: [2024-10-29 13:11:32] iter = 11660, loss = 0.9142
2024-10-29 13:11:32: [2024-10-29 13:11:32] iter = 11670, loss = 1.2934
2024-10-29 13:11:33: [2024-10-29 13:11:33] iter = 11680, loss = 1.3987
2024-10-29 13:11:33: [2024-10-29 13:11:33] iter = 11690, loss = 1.7522
2024-10-29 13:11:33: [2024-10-29 13:11:33] iter = 11700, loss = 1.8731
2024-10-29 13:11:34: [2024-10-29 13:11:34] iter = 11710, loss = 1.2774
2024-10-29 13:11:34: [2024-10-29 13:11:34] iter = 11720, loss = 1.0591
2024-10-29 13:11:34: [2024-10-29 13:11:34] iter = 11730, loss = 0.9376
2024-10-29 13:11:35: [2024-10-29 13:11:35] iter = 11740, loss = 2.4141
2024-10-29 13:11:35: [2024-10-29 13:11:35] iter = 11750, loss = 4.7132
2024-10-29 13:11:35: [2024-10-29 13:11:35] iter = 11760, loss = 1.1455
2024-10-29 13:11:36: [2024-10-29 13:11:36] iter = 11770, loss = 1.7729
2024-10-29 13:11:36: [2024-10-29 13:11:36] iter = 11780, loss = 1.6733
2024-10-29 13:11:37: [2024-10-29 13:11:37] iter = 11790, loss = 1.9681
2024-10-29 13:11:37: [2024-10-29 13:11:37] iter = 11800, loss = 0.7681
2024-10-29 13:11:37: [2024-10-29 13:11:37] iter = 11810, loss = 0.8260
2024-10-29 13:11:38: [2024-10-29 13:11:38] iter = 11820, loss = 0.8426
2024-10-29 13:11:38: [2024-10-29 13:11:38] iter = 11830, loss = 1.6640
2024-10-29 13:11:38: [2024-10-29 13:11:38] iter = 11840, loss = 1.8550
2024-10-29 13:11:39: [2024-10-29 13:11:39] iter = 11850, loss = 1.1718
2024-10-29 13:11:39: [2024-10-29 13:11:39] iter = 11860, loss = 1.3501
2024-10-29 13:11:39: [2024-10-29 13:11:39] iter = 11870, loss = 3.0487
2024-10-29 13:11:40: [2024-10-29 13:11:40] iter = 11880, loss = 1.9653
2024-10-29 13:11:40: [2024-10-29 13:11:40] iter = 11890, loss = 2.3172
2024-10-29 13:11:41: [2024-10-29 13:11:41] iter = 11900, loss = 1.6575
2024-10-29 13:11:41: [2024-10-29 13:11:41] iter = 11910, loss = 0.9799
2024-10-29 13:11:42: [2024-10-29 13:11:42] iter = 11920, loss = 1.8118
2024-10-29 13:11:42: [2024-10-29 13:11:42] iter = 11930, loss = 2.6049
2024-10-29 13:11:43: [2024-10-29 13:11:43] iter = 11940, loss = 6.1630
2024-10-29 13:11:43: [2024-10-29 13:11:43] iter = 11950, loss = 1.8228
2024-10-29 13:11:43: [2024-10-29 13:11:43] iter = 11960, loss = 5.9466
2024-10-29 13:11:44: [2024-10-29 13:11:44] iter = 11970, loss = 1.3880
2024-10-29 13:11:44: [2024-10-29 13:11:44] iter = 11980, loss = 2.9495
2024-10-29 13:11:45: [2024-10-29 13:11:45] iter = 11990, loss = 1.2315
2024-10-29 13:11:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 13:11:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:11:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 5548}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:12:13: Evaluate 5 random ConvNet, ACCmean = 0.6721 ACCstd = 0.0204
-------------------------
2024-10-29 13:12:13: Evaluate 5 random ConvNet, SENmean = 0.6246 SENstd = 0.0058
-------------------------
2024-10-29 13:12:13: Evaluate 5 random ConvNet, SPEmean = 0.6246 SPEstd = 0.0058
-------------------------
2024-10-29 13:12:13: Evaluate 5 random ConvNet, F!mean = 0.5294 F!std = 0.0085
-------------------------
2024-10-29 13:12:13: Evaluate 5 random ConvNet, mean = 0.6721 std = 0.0204
-------------------------
2024-10-29 13:12:13: [2024-10-29 13:12:13] iter = 12000, loss = 1.6952
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:12:13: [2024-10-29 13:12:13] iter = 12010, loss = 2.2044
2024-10-29 13:12:13: [2024-10-29 13:12:13] iter = 12020, loss = 1.5759
2024-10-29 13:12:14: [2024-10-29 13:12:14] iter = 12030, loss = 1.5661
2024-10-29 13:12:14: [2024-10-29 13:12:14] iter = 12040, loss = 1.0416
2024-10-29 13:12:14: [2024-10-29 13:12:14] iter = 12050, loss = 1.3561
2024-10-29 13:12:15: [2024-10-29 13:12:15] iter = 12060, loss = 1.6238
2024-10-29 13:12:15: [2024-10-29 13:12:15] iter = 12070, loss = 1.4486
2024-10-29 13:12:15: [2024-10-29 13:12:15] iter = 12080, loss = 1.6440
2024-10-29 13:12:16: [2024-10-29 13:12:16] iter = 12090, loss = 1.5551
2024-10-29 13:12:16: [2024-10-29 13:12:16] iter = 12100, loss = 1.1658
2024-10-29 13:12:16: [2024-10-29 13:12:16] iter = 12110, loss = 1.3419
2024-10-29 13:12:17: [2024-10-29 13:12:17] iter = 12120, loss = 2.1008
2024-10-29 13:12:17: [2024-10-29 13:12:17] iter = 12130, loss = 1.2140
2024-10-29 13:12:17: [2024-10-29 13:12:17] iter = 12140, loss = 1.4959
2024-10-29 13:12:17: [2024-10-29 13:12:17] iter = 12150, loss = 3.3752
2024-10-29 13:12:18: [2024-10-29 13:12:18] iter = 12160, loss = 1.2641
2024-10-29 13:12:18: [2024-10-29 13:12:18] iter = 12170, loss = 1.3233
2024-10-29 13:12:18: [2024-10-29 13:12:18] iter = 12180, loss = 1.1599
2024-10-29 13:12:19: [2024-10-29 13:12:19] iter = 12190, loss = 2.2218
2024-10-29 13:12:19: [2024-10-29 13:12:19] iter = 12200, loss = 3.0583
2024-10-29 13:12:19: [2024-10-29 13:12:19] iter = 12210, loss = 2.4201
2024-10-29 13:12:20: [2024-10-29 13:12:20] iter = 12220, loss = 1.7417
2024-10-29 13:12:20: [2024-10-29 13:12:20] iter = 12230, loss = 1.2497
2024-10-29 13:12:20: [2024-10-29 13:12:20] iter = 12240, loss = 1.3632
2024-10-29 13:12:21: [2024-10-29 13:12:21] iter = 12250, loss = 1.3425
2024-10-29 13:12:21: [2024-10-29 13:12:21] iter = 12260, loss = 1.4574
2024-10-29 13:12:21: [2024-10-29 13:12:21] iter = 12270, loss = 2.3587
2024-10-29 13:12:22: [2024-10-29 13:12:22] iter = 12280, loss = 1.5612
2024-10-29 13:12:22: [2024-10-29 13:12:22] iter = 12290, loss = 1.5212
2024-10-29 13:12:22: [2024-10-29 13:12:22] iter = 12300, loss = 1.0098
2024-10-29 13:12:23: [2024-10-29 13:12:23] iter = 12310, loss = 1.3953
2024-10-29 13:12:23: [2024-10-29 13:12:23] iter = 12320, loss = 0.9262
2024-10-29 13:12:23: [2024-10-29 13:12:23] iter = 12330, loss = 1.1678
2024-10-29 13:12:24: [2024-10-29 13:12:24] iter = 12340, loss = 1.2651
2024-10-29 13:12:24: [2024-10-29 13:12:24] iter = 12350, loss = 0.8715
2024-10-29 13:12:25: [2024-10-29 13:12:25] iter = 12360, loss = 1.4222
2024-10-29 13:12:25: [2024-10-29 13:12:25] iter = 12370, loss = 1.0479
2024-10-29 13:12:25: [2024-10-29 13:12:25] iter = 12380, loss = 1.5681
2024-10-29 13:12:26: [2024-10-29 13:12:26] iter = 12390, loss = 3.6248
2024-10-29 13:12:26: [2024-10-29 13:12:26] iter = 12400, loss = 2.2257
2024-10-29 13:12:26: [2024-10-29 13:12:26] iter = 12410, loss = 1.2278
2024-10-29 13:12:27: [2024-10-29 13:12:27] iter = 12420, loss = 1.0123
2024-10-29 13:12:27: [2024-10-29 13:12:27] iter = 12430, loss = 1.0375
2024-10-29 13:12:27: [2024-10-29 13:12:27] iter = 12440, loss = 8.9052
2024-10-29 13:12:28: [2024-10-29 13:12:28] iter = 12450, loss = 4.2092
2024-10-29 13:12:28: [2024-10-29 13:12:28] iter = 12460, loss = 1.7735
2024-10-29 13:12:29: [2024-10-29 13:12:29] iter = 12470, loss = 1.0646
2024-10-29 13:12:30: [2024-10-29 13:12:30] iter = 12480, loss = 0.8064
2024-10-29 13:12:30: [2024-10-29 13:12:30] iter = 12490, loss = 2.2285
2024-10-29 13:12:31: [2024-10-29 13:12:31] iter = 12500, loss = 1.1052
2024-10-29 13:12:31: [2024-10-29 13:12:31] iter = 12510, loss = 1.2557
2024-10-29 13:12:32: [2024-10-29 13:12:32] iter = 12520, loss = 6.6831
2024-10-29 13:12:32: [2024-10-29 13:12:32] iter = 12530, loss = 1.4824
2024-10-29 13:12:32: [2024-10-29 13:12:32] iter = 12540, loss = 0.8670
2024-10-29 13:12:33: [2024-10-29 13:12:33] iter = 12550, loss = 4.1965
2024-10-29 13:12:33: [2024-10-29 13:12:33] iter = 12560, loss = 1.5190
2024-10-29 13:12:33: [2024-10-29 13:12:33] iter = 12570, loss = 1.3904
2024-10-29 13:12:34: [2024-10-29 13:12:34] iter = 12580, loss = 1.2811
2024-10-29 13:12:34: [2024-10-29 13:12:34] iter = 12590, loss = 1.1677
2024-10-29 13:12:34: [2024-10-29 13:12:34] iter = 12600, loss = 1.6087
2024-10-29 13:12:34: [2024-10-29 13:12:34] iter = 12610, loss = 1.6795
2024-10-29 13:12:35: [2024-10-29 13:12:35] iter = 12620, loss = 1.1179
2024-10-29 13:12:35: [2024-10-29 13:12:35] iter = 12630, loss = 0.8862
2024-10-29 13:12:35: [2024-10-29 13:12:35] iter = 12640, loss = 2.9589
2024-10-29 13:12:35: [2024-10-29 13:12:35] iter = 12650, loss = 1.1564
2024-10-29 13:12:36: [2024-10-29 13:12:36] iter = 12660, loss = 1.4304
2024-10-29 13:12:36: [2024-10-29 13:12:36] iter = 12670, loss = 0.8776
2024-10-29 13:12:37: [2024-10-29 13:12:37] iter = 12680, loss = 0.9818
2024-10-29 13:12:37: [2024-10-29 13:12:37] iter = 12690, loss = 4.8779
2024-10-29 13:12:37: [2024-10-29 13:12:37] iter = 12700, loss = 1.2805
2024-10-29 13:12:38: [2024-10-29 13:12:38] iter = 12710, loss = 1.0743
2024-10-29 13:12:38: [2024-10-29 13:12:38] iter = 12720, loss = 1.5113
2024-10-29 13:12:39: [2024-10-29 13:12:39] iter = 12730, loss = 0.9885
2024-10-29 13:12:39: [2024-10-29 13:12:39] iter = 12740, loss = 2.1679
2024-10-29 13:12:39: [2024-10-29 13:12:39] iter = 12750, loss = 1.9503
2024-10-29 13:12:40: [2024-10-29 13:12:40] iter = 12760, loss = 1.4030
2024-10-29 13:12:40: [2024-10-29 13:12:40] iter = 12770, loss = 2.9360
2024-10-29 13:12:41: [2024-10-29 13:12:41] iter = 12780, loss = 2.2526
2024-10-29 13:12:41: [2024-10-29 13:12:41] iter = 12790, loss = 0.9627
2024-10-29 13:12:41: [2024-10-29 13:12:41] iter = 12800, loss = 1.3013
2024-10-29 13:12:42: [2024-10-29 13:12:42] iter = 12810, loss = 1.8392
2024-10-29 13:12:42: [2024-10-29 13:12:42] iter = 12820, loss = 2.2373
2024-10-29 13:12:43: [2024-10-29 13:12:43] iter = 12830, loss = 0.8063
2024-10-29 13:12:44: [2024-10-29 13:12:44] iter = 12840, loss = 1.5199
2024-10-29 13:12:44: [2024-10-29 13:12:44] iter = 12850, loss = 2.4865
2024-10-29 13:12:45: [2024-10-29 13:12:45] iter = 12860, loss = 1.5120
2024-10-29 13:12:45: [2024-10-29 13:12:45] iter = 12870, loss = 1.1432
2024-10-29 13:12:45: [2024-10-29 13:12:45] iter = 12880, loss = 1.0565
2024-10-29 13:12:46: [2024-10-29 13:12:46] iter = 12890, loss = 0.6542
2024-10-29 13:12:46: [2024-10-29 13:12:46] iter = 12900, loss = 0.9297
2024-10-29 13:12:46: [2024-10-29 13:12:46] iter = 12910, loss = 1.2920
2024-10-29 13:12:47: [2024-10-29 13:12:47] iter = 12920, loss = 1.3463
2024-10-29 13:12:47: [2024-10-29 13:12:47] iter = 12930, loss = 1.4347
2024-10-29 13:12:47: [2024-10-29 13:12:47] iter = 12940, loss = 1.5633
2024-10-29 13:12:48: [2024-10-29 13:12:48] iter = 12950, loss = 2.1635
2024-10-29 13:12:48: [2024-10-29 13:12:48] iter = 12960, loss = 0.7230
2024-10-29 13:12:48: [2024-10-29 13:12:48] iter = 12970, loss = 1.0132
2024-10-29 13:12:49: [2024-10-29 13:12:49] iter = 12980, loss = 1.5043
2024-10-29 13:12:49: [2024-10-29 13:12:49] iter = 12990, loss = 3.3750
2024-10-29 13:12:50: [2024-10-29 13:12:50] iter = 13000, loss = 1.2488
2024-10-29 13:12:50: [2024-10-29 13:12:50] iter = 13010, loss = 1.1739
2024-10-29 13:12:50: [2024-10-29 13:12:50] iter = 13020, loss = 1.3630
2024-10-29 13:12:51: [2024-10-29 13:12:51] iter = 13030, loss = 1.1103
2024-10-29 13:12:51: [2024-10-29 13:12:51] iter = 13040, loss = 1.1624
2024-10-29 13:12:51: [2024-10-29 13:12:51] iter = 13050, loss = 1.2180
2024-10-29 13:12:52: [2024-10-29 13:12:52] iter = 13060, loss = 1.1779
2024-10-29 13:12:52: [2024-10-29 13:12:52] iter = 13070, loss = 1.6574
2024-10-29 13:12:52: [2024-10-29 13:12:52] iter = 13080, loss = 2.5555
2024-10-29 13:12:53: [2024-10-29 13:12:53] iter = 13090, loss = 1.1724
2024-10-29 13:12:53: [2024-10-29 13:12:53] iter = 13100, loss = 1.3594
2024-10-29 13:12:53: [2024-10-29 13:12:53] iter = 13110, loss = 1.0712
2024-10-29 13:12:54: [2024-10-29 13:12:54] iter = 13120, loss = 2.3114
2024-10-29 13:12:54: [2024-10-29 13:12:54] iter = 13130, loss = 1.9929
2024-10-29 13:12:55: [2024-10-29 13:12:55] iter = 13140, loss = 1.4558
2024-10-29 13:12:55: [2024-10-29 13:12:55] iter = 13150, loss = 2.1676
2024-10-29 13:12:55: [2024-10-29 13:12:55] iter = 13160, loss = 1.1203
2024-10-29 13:12:56: [2024-10-29 13:12:56] iter = 13170, loss = 1.3765
2024-10-29 13:12:56: [2024-10-29 13:12:56] iter = 13180, loss = 1.2628
2024-10-29 13:12:56: [2024-10-29 13:12:56] iter = 13190, loss = 1.2520
2024-10-29 13:12:57: [2024-10-29 13:12:57] iter = 13200, loss = 2.5247
2024-10-29 13:12:57: [2024-10-29 13:12:57] iter = 13210, loss = 1.5729
2024-10-29 13:12:57: [2024-10-29 13:12:57] iter = 13220, loss = 1.9913
2024-10-29 13:12:58: [2024-10-29 13:12:58] iter = 13230, loss = 1.0052
2024-10-29 13:12:58: [2024-10-29 13:12:58] iter = 13240, loss = 2.8422
2024-10-29 13:12:58: [2024-10-29 13:12:58] iter = 13250, loss = 1.3712
2024-10-29 13:12:59: [2024-10-29 13:12:59] iter = 13260, loss = 2.4302
2024-10-29 13:12:59: [2024-10-29 13:12:59] iter = 13270, loss = 1.1715
2024-10-29 13:12:59: [2024-10-29 13:12:59] iter = 13280, loss = 1.6078
2024-10-29 13:13:00: [2024-10-29 13:13:00] iter = 13290, loss = 1.4185
2024-10-29 13:13:00: [2024-10-29 13:13:00] iter = 13300, loss = 1.2082
2024-10-29 13:13:00: [2024-10-29 13:13:00] iter = 13310, loss = 1.8118
2024-10-29 13:13:01: [2024-10-29 13:13:01] iter = 13320, loss = 6.5836
2024-10-29 13:13:01: [2024-10-29 13:13:01] iter = 13330, loss = 2.1275
2024-10-29 13:13:01: [2024-10-29 13:13:01] iter = 13340, loss = 1.7586
2024-10-29 13:13:02: [2024-10-29 13:13:02] iter = 13350, loss = 0.7705
2024-10-29 13:13:02: [2024-10-29 13:13:02] iter = 13360, loss = 1.2148
2024-10-29 13:13:02: [2024-10-29 13:13:02] iter = 13370, loss = 2.0671
2024-10-29 13:13:03: [2024-10-29 13:13:03] iter = 13380, loss = 1.1419
2024-10-29 13:13:03: [2024-10-29 13:13:03] iter = 13390, loss = 3.7786
2024-10-29 13:13:03: [2024-10-29 13:13:03] iter = 13400, loss = 1.5785
2024-10-29 13:13:04: [2024-10-29 13:13:04] iter = 13410, loss = 0.9398
2024-10-29 13:13:04: [2024-10-29 13:13:04] iter = 13420, loss = 1.0981
2024-10-29 13:13:04: [2024-10-29 13:13:04] iter = 13430, loss = 2.0657
2024-10-29 13:13:05: [2024-10-29 13:13:05] iter = 13440, loss = 1.1365
2024-10-29 13:13:05: [2024-10-29 13:13:05] iter = 13450, loss = 9.9948
2024-10-29 13:13:05: [2024-10-29 13:13:05] iter = 13460, loss = 1.4286
2024-10-29 13:13:06: [2024-10-29 13:13:06] iter = 13470, loss = 1.5306
2024-10-29 13:13:06: [2024-10-29 13:13:06] iter = 13480, loss = 0.7913
2024-10-29 13:13:06: [2024-10-29 13:13:06] iter = 13490, loss = 1.1649
2024-10-29 13:13:07: [2024-10-29 13:13:07] iter = 13500, loss = 2.0873
2024-10-29 13:13:07: [2024-10-29 13:13:07] iter = 13510, loss = 1.3133
2024-10-29 13:13:07: [2024-10-29 13:13:07] iter = 13520, loss = 1.8121
2024-10-29 13:13:08: [2024-10-29 13:13:08] iter = 13530, loss = 2.1296
2024-10-29 13:13:08: [2024-10-29 13:13:08] iter = 13540, loss = 2.0349
2024-10-29 13:13:08: [2024-10-29 13:13:08] iter = 13550, loss = 2.8032
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 13560, loss = 1.3072
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 13570, loss = 1.6752
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 13580, loss = 1.7811
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 13590, loss = 1.3356
2024-10-29 13:13:10: [2024-10-29 13:13:10] iter = 13600, loss = 1.2415
2024-10-29 13:13:10: [2024-10-29 13:13:10] iter = 13610, loss = 1.3737
2024-10-29 13:13:10: [2024-10-29 13:13:10] iter = 13620, loss = 1.0708
2024-10-29 13:13:11: [2024-10-29 13:13:11] iter = 13630, loss = 1.0890
2024-10-29 13:13:11: [2024-10-29 13:13:11] iter = 13640, loss = 1.5240
2024-10-29 13:13:11: [2024-10-29 13:13:11] iter = 13650, loss = 1.2051
2024-10-29 13:13:12: [2024-10-29 13:13:12] iter = 13660, loss = 0.8354
2024-10-29 13:13:12: [2024-10-29 13:13:12] iter = 13670, loss = 1.2484
2024-10-29 13:13:13: [2024-10-29 13:13:13] iter = 13680, loss = 1.1504
2024-10-29 13:13:13: [2024-10-29 13:13:13] iter = 13690, loss = 1.3070
2024-10-29 13:13:13: [2024-10-29 13:13:13] iter = 13700, loss = 1.0459
2024-10-29 13:13:14: [2024-10-29 13:13:14] iter = 13710, loss = 0.9459
2024-10-29 13:13:14: [2024-10-29 13:13:14] iter = 13720, loss = 1.8309
2024-10-29 13:13:14: [2024-10-29 13:13:14] iter = 13730, loss = 2.4807
2024-10-29 13:13:15: [2024-10-29 13:13:15] iter = 13740, loss = 2.1661
2024-10-29 13:13:15: [2024-10-29 13:13:15] iter = 13750, loss = 0.9433
2024-10-29 13:13:15: [2024-10-29 13:13:15] iter = 13760, loss = 1.4286
2024-10-29 13:13:16: [2024-10-29 13:13:16] iter = 13770, loss = 1.0250
2024-10-29 13:13:16: [2024-10-29 13:13:16] iter = 13780, loss = 0.9987
2024-10-29 13:13:17: [2024-10-29 13:13:17] iter = 13790, loss = 1.5178
2024-10-29 13:13:17: [2024-10-29 13:13:17] iter = 13800, loss = 1.4752
2024-10-29 13:13:17: [2024-10-29 13:13:17] iter = 13810, loss = 1.4045
2024-10-29 13:13:18: [2024-10-29 13:13:18] iter = 13820, loss = 1.2300
2024-10-29 13:13:18: [2024-10-29 13:13:18] iter = 13830, loss = 3.3185
2024-10-29 13:13:19: [2024-10-29 13:13:19] iter = 13840, loss = 1.1760
2024-10-29 13:13:19: [2024-10-29 13:13:19] iter = 13850, loss = 1.4014
2024-10-29 13:13:19: [2024-10-29 13:13:19] iter = 13860, loss = 1.1120
2024-10-29 13:13:20: [2024-10-29 13:13:20] iter = 13870, loss = 0.9823
2024-10-29 13:13:20: [2024-10-29 13:13:20] iter = 13880, loss = 1.4905
2024-10-29 13:13:21: [2024-10-29 13:13:21] iter = 13890, loss = 0.9991
2024-10-29 13:13:21: [2024-10-29 13:13:21] iter = 13900, loss = 5.9780
2024-10-29 13:13:22: [2024-10-29 13:13:22] iter = 13910, loss = 1.5989
2024-10-29 13:13:22: [2024-10-29 13:13:22] iter = 13920, loss = 1.0986
2024-10-29 13:13:23: [2024-10-29 13:13:23] iter = 13930, loss = 0.7762
2024-10-29 13:13:23: [2024-10-29 13:13:23] iter = 13940, loss = 1.0563
2024-10-29 13:13:23: [2024-10-29 13:13:23] iter = 13950, loss = 1.6841
2024-10-29 13:13:24: [2024-10-29 13:13:24] iter = 13960, loss = 1.0209
2024-10-29 13:13:24: [2024-10-29 13:13:24] iter = 13970, loss = 1.1096
2024-10-29 13:13:24: [2024-10-29 13:13:24] iter = 13980, loss = 0.7860
2024-10-29 13:13:25: [2024-10-29 13:13:25] iter = 13990, loss = 2.1483
2024-10-29 13:13:25: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 13:13:25: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:13:25: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 5427}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:51: Evaluate 5 random ConvNet, ACCmean = 0.5913 ACCstd = 0.0293
-------------------------
2024-10-29 13:13:51: Evaluate 5 random ConvNet, SENmean = 0.6079 SENstd = 0.0017
-------------------------
2024-10-29 13:13:51: Evaluate 5 random ConvNet, SPEmean = 0.6079 SPEstd = 0.0017
-------------------------
2024-10-29 13:13:51: Evaluate 5 random ConvNet, F!mean = 0.4840 F!std = 0.0150
-------------------------
2024-10-29 13:13:51: Evaluate 5 random ConvNet, mean = 0.5913 std = 0.0293
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:51: [2024-10-29 13:13:51] iter = 14000, loss = 1.1969
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:52: [2024-10-29 13:13:52] iter = 14010, loss = 1.8603
2024-10-29 13:13:52: [2024-10-29 13:13:52] iter = 14020, loss = 1.0009
2024-10-29 13:13:52: [2024-10-29 13:13:52] iter = 14030, loss = 0.8821
2024-10-29 13:13:53: [2024-10-29 13:13:53] iter = 14040, loss = 1.4430
2024-10-29 13:13:53: [2024-10-29 13:13:53] iter = 14050, loss = 1.8604
2024-10-29 13:13:54: [2024-10-29 13:13:54] iter = 14060, loss = 1.0694
2024-10-29 13:13:54: [2024-10-29 13:13:54] iter = 14070, loss = 1.6763
2024-10-29 13:13:55: [2024-10-29 13:13:55] iter = 14080, loss = 1.3236
2024-10-29 13:13:55: [2024-10-29 13:13:55] iter = 14090, loss = 1.3970
2024-10-29 13:13:55: [2024-10-29 13:13:55] iter = 14100, loss = 3.7240
2024-10-29 13:13:56: [2024-10-29 13:13:56] iter = 14110, loss = 1.2326
2024-10-29 13:13:56: [2024-10-29 13:13:56] iter = 14120, loss = 1.0359
2024-10-29 13:13:57: [2024-10-29 13:13:57] iter = 14130, loss = 9.9362
2024-10-29 13:13:57: [2024-10-29 13:13:57] iter = 14140, loss = 1.4913
2024-10-29 13:13:58: [2024-10-29 13:13:58] iter = 14150, loss = 1.2755
2024-10-29 13:13:58: [2024-10-29 13:13:58] iter = 14160, loss = 3.0226
2024-10-29 13:13:58: [2024-10-29 13:13:58] iter = 14170, loss = 1.5037
2024-10-29 13:13:59: [2024-10-29 13:13:59] iter = 14180, loss = 1.4277
2024-10-29 13:13:59: [2024-10-29 13:13:59] iter = 14190, loss = 1.1974
2024-10-29 13:14:00: [2024-10-29 13:14:00] iter = 14200, loss = 2.7260
2024-10-29 13:14:00: [2024-10-29 13:14:00] iter = 14210, loss = 1.5211
2024-10-29 13:14:01: [2024-10-29 13:14:01] iter = 14220, loss = 2.7445
2024-10-29 13:14:01: [2024-10-29 13:14:01] iter = 14230, loss = 1.7726
2024-10-29 13:14:01: [2024-10-29 13:14:01] iter = 14240, loss = 2.0372
2024-10-29 13:14:02: [2024-10-29 13:14:02] iter = 14250, loss = 2.6528
2024-10-29 13:14:02: [2024-10-29 13:14:02] iter = 14260, loss = 0.9703
2024-10-29 13:14:02: [2024-10-29 13:14:02] iter = 14270, loss = 1.0774
2024-10-29 13:14:03: [2024-10-29 13:14:03] iter = 14280, loss = 1.3666
2024-10-29 13:14:03: [2024-10-29 13:14:03] iter = 14290, loss = 1.1089
2024-10-29 13:14:03: [2024-10-29 13:14:03] iter = 14300, loss = 1.1756
2024-10-29 13:14:04: [2024-10-29 13:14:04] iter = 14310, loss = 1.3411
2024-10-29 13:14:04: [2024-10-29 13:14:04] iter = 14320, loss = 1.2311
2024-10-29 13:14:05: [2024-10-29 13:14:05] iter = 14330, loss = 1.2042
2024-10-29 13:14:05: [2024-10-29 13:14:05] iter = 14340, loss = 1.2980
2024-10-29 13:14:05: [2024-10-29 13:14:05] iter = 14350, loss = 3.1104
2024-10-29 13:14:06: [2024-10-29 13:14:06] iter = 14360, loss = 1.6159
2024-10-29 13:14:06: [2024-10-29 13:14:06] iter = 14370, loss = 1.7341
2024-10-29 13:14:06: [2024-10-29 13:14:06] iter = 14380, loss = 1.9474
2024-10-29 13:14:07: [2024-10-29 13:14:07] iter = 14390, loss = 2.4352
2024-10-29 13:14:07: [2024-10-29 13:14:07] iter = 14400, loss = 1.2361
2024-10-29 13:14:08: [2024-10-29 13:14:08] iter = 14410, loss = 1.5548
2024-10-29 13:14:08: [2024-10-29 13:14:08] iter = 14420, loss = 1.2641
2024-10-29 13:14:09: [2024-10-29 13:14:09] iter = 14430, loss = 2.3023
2024-10-29 13:14:09: [2024-10-29 13:14:09] iter = 14440, loss = 2.0240
2024-10-29 13:14:10: [2024-10-29 13:14:10] iter = 14450, loss = 1.2490
2024-10-29 13:14:10: [2024-10-29 13:14:10] iter = 14460, loss = 0.9339
2024-10-29 13:14:11: [2024-10-29 13:14:11] iter = 14470, loss = 1.1281
2024-10-29 13:14:11: [2024-10-29 13:14:11] iter = 14480, loss = 1.5868
2024-10-29 13:14:12: [2024-10-29 13:14:12] iter = 14490, loss = 1.0708
2024-10-29 13:14:12: [2024-10-29 13:14:12] iter = 14500, loss = 1.5375
2024-10-29 13:14:13: [2024-10-29 13:14:13] iter = 14510, loss = 1.1072
2024-10-29 13:14:13: [2024-10-29 13:14:13] iter = 14520, loss = 0.7631
2024-10-29 13:14:13: [2024-10-29 13:14:13] iter = 14530, loss = 1.8732
2024-10-29 13:14:14: [2024-10-29 13:14:14] iter = 14540, loss = 1.3807
2024-10-29 13:14:14: [2024-10-29 13:14:14] iter = 14550, loss = 3.5872
2024-10-29 13:14:14: [2024-10-29 13:14:14] iter = 14560, loss = 2.5199
2024-10-29 13:14:15: [2024-10-29 13:14:15] iter = 14570, loss = 1.7921
2024-10-29 13:14:15: [2024-10-29 13:14:15] iter = 14580, loss = 0.9867
2024-10-29 13:14:15: [2024-10-29 13:14:15] iter = 14590, loss = 1.3143
2024-10-29 13:14:16: [2024-10-29 13:14:16] iter = 14600, loss = 0.9942
2024-10-29 13:14:16: [2024-10-29 13:14:16] iter = 14610, loss = 0.8512
2024-10-29 13:14:16: [2024-10-29 13:14:16] iter = 14620, loss = 1.4294
2024-10-29 13:14:17: [2024-10-29 13:14:17] iter = 14630, loss = 1.6490
2024-10-29 13:14:17: [2024-10-29 13:14:17] iter = 14640, loss = 1.0275
2024-10-29 13:14:17: [2024-10-29 13:14:17] iter = 14650, loss = 1.5851
2024-10-29 13:14:18: [2024-10-29 13:14:18] iter = 14660, loss = 1.1819
2024-10-29 13:14:18: [2024-10-29 13:14:18] iter = 14670, loss = 2.2022
2024-10-29 13:14:18: [2024-10-29 13:14:18] iter = 14680, loss = 2.0204
2024-10-29 13:14:19: [2024-10-29 13:14:19] iter = 14690, loss = 1.0678
2024-10-29 13:14:19: [2024-10-29 13:14:19] iter = 14700, loss = 1.2318
2024-10-29 13:14:19: [2024-10-29 13:14:19] iter = 14710, loss = 1.1372
2024-10-29 13:14:20: [2024-10-29 13:14:20] iter = 14720, loss = 1.2968
2024-10-29 13:14:20: [2024-10-29 13:14:20] iter = 14730, loss = 2.1106
2024-10-29 13:14:20: [2024-10-29 13:14:20] iter = 14740, loss = 1.3466
2024-10-29 13:14:21: [2024-10-29 13:14:21] iter = 14750, loss = 2.2343
2024-10-29 13:14:21: [2024-10-29 13:14:21] iter = 14760, loss = 1.3598
2024-10-29 13:14:21: [2024-10-29 13:14:21] iter = 14770, loss = 1.1046
2024-10-29 13:14:22: [2024-10-29 13:14:22] iter = 14780, loss = 1.0220
2024-10-29 13:14:22: [2024-10-29 13:14:22] iter = 14790, loss = 1.5038
2024-10-29 13:14:22: [2024-10-29 13:14:22] iter = 14800, loss = 1.0187
2024-10-29 13:14:23: [2024-10-29 13:14:23] iter = 14810, loss = 1.0910
2024-10-29 13:14:23: [2024-10-29 13:14:23] iter = 14820, loss = 1.4005
2024-10-29 13:14:23: [2024-10-29 13:14:23] iter = 14830, loss = 1.7621
2024-10-29 13:14:24: [2024-10-29 13:14:24] iter = 14840, loss = 1.1169
2024-10-29 13:14:24: [2024-10-29 13:14:24] iter = 14850, loss = 1.0294
2024-10-29 13:14:24: [2024-10-29 13:14:24] iter = 14860, loss = 1.1043
2024-10-29 13:14:25: [2024-10-29 13:14:25] iter = 14870, loss = 1.4313
2024-10-29 13:14:25: [2024-10-29 13:14:25] iter = 14880, loss = 1.2119
2024-10-29 13:14:25: [2024-10-29 13:14:25] iter = 14890, loss = 1.2951
2024-10-29 13:14:26: [2024-10-29 13:14:26] iter = 14900, loss = 1.1590
2024-10-29 13:14:26: [2024-10-29 13:14:26] iter = 14910, loss = 1.0202
2024-10-29 13:14:26: [2024-10-29 13:14:26] iter = 14920, loss = 1.1162
2024-10-29 13:14:27: [2024-10-29 13:14:27] iter = 14930, loss = 1.2400
2024-10-29 13:14:27: [2024-10-29 13:14:27] iter = 14940, loss = 1.0367
2024-10-29 13:14:27: [2024-10-29 13:14:27] iter = 14950, loss = 1.4587
2024-10-29 13:14:28: [2024-10-29 13:14:28] iter = 14960, loss = 1.0391
2024-10-29 13:14:28: [2024-10-29 13:14:28] iter = 14970, loss = 1.6420
2024-10-29 13:14:28: [2024-10-29 13:14:28] iter = 14980, loss = 1.5716
2024-10-29 13:14:29: [2024-10-29 13:14:29] iter = 14990, loss = 4.9024
2024-10-29 13:14:29: [2024-10-29 13:14:29] iter = 15000, loss = 1.7484
2024-10-29 13:14:29: [2024-10-29 13:14:29] iter = 15010, loss = 1.6754
2024-10-29 13:14:30: [2024-10-29 13:14:30] iter = 15020, loss = 1.0884
2024-10-29 13:14:30: [2024-10-29 13:14:30] iter = 15030, loss = 2.4744
2024-10-29 13:14:30: [2024-10-29 13:14:30] iter = 15040, loss = 0.8607
2024-10-29 13:14:30: [2024-10-29 13:14:30] iter = 15050, loss = 0.9077
2024-10-29 13:14:31: [2024-10-29 13:14:31] iter = 15060, loss = 2.5535
2024-10-29 13:14:31: [2024-10-29 13:14:31] iter = 15070, loss = 0.9798
2024-10-29 13:14:32: [2024-10-29 13:14:32] iter = 15080, loss = 2.5272
2024-10-29 13:14:32: [2024-10-29 13:14:32] iter = 15090, loss = 1.2559
2024-10-29 13:14:32: [2024-10-29 13:14:32] iter = 15100, loss = 0.9868
2024-10-29 13:14:33: [2024-10-29 13:14:33] iter = 15110, loss = 1.8444
2024-10-29 13:14:33: [2024-10-29 13:14:33] iter = 15120, loss = 0.9544
2024-10-29 13:14:33: [2024-10-29 13:14:33] iter = 15130, loss = 1.3216
2024-10-29 13:14:34: [2024-10-29 13:14:34] iter = 15140, loss = 2.9469
2024-10-29 13:14:34: [2024-10-29 13:14:34] iter = 15150, loss = 0.7722
2024-10-29 13:14:34: [2024-10-29 13:14:34] iter = 15160, loss = 1.2238
2024-10-29 13:14:35: [2024-10-29 13:14:35] iter = 15170, loss = 1.2831
2024-10-29 13:14:35: [2024-10-29 13:14:35] iter = 15180, loss = 2.6032
2024-10-29 13:14:36: [2024-10-29 13:14:36] iter = 15190, loss = 1.2623
2024-10-29 13:14:36: [2024-10-29 13:14:36] iter = 15200, loss = 1.1620
2024-10-29 13:14:36: [2024-10-29 13:14:36] iter = 15210, loss = 2.1115
2024-10-29 13:14:37: [2024-10-29 13:14:37] iter = 15220, loss = 1.1017
2024-10-29 13:14:37: [2024-10-29 13:14:37] iter = 15230, loss = 1.5372
2024-10-29 13:14:37: [2024-10-29 13:14:37] iter = 15240, loss = 0.9083
2024-10-29 13:14:38: [2024-10-29 13:14:38] iter = 15250, loss = 1.0838
2024-10-29 13:14:38: [2024-10-29 13:14:38] iter = 15260, loss = 0.8273
2024-10-29 13:14:38: [2024-10-29 13:14:38] iter = 15270, loss = 1.0314
2024-10-29 13:14:39: [2024-10-29 13:14:39] iter = 15280, loss = 4.8375
2024-10-29 13:14:39: [2024-10-29 13:14:39] iter = 15290, loss = 1.1652
2024-10-29 13:14:39: [2024-10-29 13:14:39] iter = 15300, loss = 1.3574
2024-10-29 13:14:40: [2024-10-29 13:14:40] iter = 15310, loss = 1.9439
2024-10-29 13:14:40: [2024-10-29 13:14:40] iter = 15320, loss = 1.6888
2024-10-29 13:14:40: [2024-10-29 13:14:40] iter = 15330, loss = 0.8417
2024-10-29 13:14:41: [2024-10-29 13:14:41] iter = 15340, loss = 1.0515
2024-10-29 13:14:41: [2024-10-29 13:14:41] iter = 15350, loss = 0.6987
2024-10-29 13:14:41: [2024-10-29 13:14:41] iter = 15360, loss = 0.6919
2024-10-29 13:14:42: [2024-10-29 13:14:42] iter = 15370, loss = 1.0683
2024-10-29 13:14:42: [2024-10-29 13:14:42] iter = 15380, loss = 5.8283
2024-10-29 13:14:42: [2024-10-29 13:14:42] iter = 15390, loss = 0.8852
2024-10-29 13:14:43: [2024-10-29 13:14:43] iter = 15400, loss = 1.0313
2024-10-29 13:14:43: [2024-10-29 13:14:43] iter = 15410, loss = 1.2655
2024-10-29 13:14:43: [2024-10-29 13:14:43] iter = 15420, loss = 1.1621
2024-10-29 13:14:44: [2024-10-29 13:14:44] iter = 15430, loss = 2.8675
2024-10-29 13:14:44: [2024-10-29 13:14:44] iter = 15440, loss = 1.0051
2024-10-29 13:14:44: [2024-10-29 13:14:44] iter = 15450, loss = 1.0342
2024-10-29 13:14:45: [2024-10-29 13:14:45] iter = 15460, loss = 1.1108
2024-10-29 13:14:45: [2024-10-29 13:14:45] iter = 15470, loss = 1.2809
2024-10-29 13:14:45: [2024-10-29 13:14:45] iter = 15480, loss = 3.2435
2024-10-29 13:14:46: [2024-10-29 13:14:46] iter = 15490, loss = 1.6873
2024-10-29 13:14:46: [2024-10-29 13:14:46] iter = 15500, loss = 0.9092
2024-10-29 13:14:46: [2024-10-29 13:14:46] iter = 15510, loss = 3.8611
2024-10-29 13:14:47: [2024-10-29 13:14:47] iter = 15520, loss = 14.7244
2024-10-29 13:14:47: [2024-10-29 13:14:47] iter = 15530, loss = 1.4349
2024-10-29 13:14:47: [2024-10-29 13:14:47] iter = 15540, loss = 1.3151
2024-10-29 13:14:48: [2024-10-29 13:14:48] iter = 15550, loss = 4.7889
2024-10-29 13:14:48: [2024-10-29 13:14:48] iter = 15560, loss = 1.5002
2024-10-29 13:14:48: [2024-10-29 13:14:48] iter = 15570, loss = 1.0800
2024-10-29 13:14:49: [2024-10-29 13:14:49] iter = 15580, loss = 1.1422
2024-10-29 13:14:49: [2024-10-29 13:14:49] iter = 15590, loss = 1.2340
2024-10-29 13:14:49: [2024-10-29 13:14:49] iter = 15600, loss = 1.1138
2024-10-29 13:14:50: [2024-10-29 13:14:50] iter = 15610, loss = 1.5521
2024-10-29 13:14:50: [2024-10-29 13:14:50] iter = 15620, loss = 1.1459
2024-10-29 13:14:50: [2024-10-29 13:14:50] iter = 15630, loss = 1.2746
2024-10-29 13:14:51: [2024-10-29 13:14:51] iter = 15640, loss = 3.0808
2024-10-29 13:14:51: [2024-10-29 13:14:51] iter = 15650, loss = 1.9356
2024-10-29 13:14:51: [2024-10-29 13:14:51] iter = 15660, loss = 1.5522
2024-10-29 13:14:52: [2024-10-29 13:14:52] iter = 15670, loss = 2.1828
2024-10-29 13:14:52: [2024-10-29 13:14:52] iter = 15680, loss = 1.4604
2024-10-29 13:14:52: [2024-10-29 13:14:52] iter = 15690, loss = 1.3893
2024-10-29 13:14:53: [2024-10-29 13:14:53] iter = 15700, loss = 2.1925
2024-10-29 13:14:53: [2024-10-29 13:14:53] iter = 15710, loss = 1.3515
2024-10-29 13:14:53: [2024-10-29 13:14:53] iter = 15720, loss = 0.9290
2024-10-29 13:14:54: [2024-10-29 13:14:54] iter = 15730, loss = 1.4654
2024-10-29 13:14:54: [2024-10-29 13:14:54] iter = 15740, loss = 1.2448
2024-10-29 13:14:55: [2024-10-29 13:14:55] iter = 15750, loss = 1.0613
2024-10-29 13:14:55: [2024-10-29 13:14:55] iter = 15760, loss = 1.8145
2024-10-29 13:14:56: [2024-10-29 13:14:56] iter = 15770, loss = 0.7896
2024-10-29 13:14:56: [2024-10-29 13:14:56] iter = 15780, loss = 0.8873
2024-10-29 13:14:56: [2024-10-29 13:14:56] iter = 15790, loss = 0.8358
2024-10-29 13:14:57: [2024-10-29 13:14:57] iter = 15800, loss = 0.7835
2024-10-29 13:14:57: [2024-10-29 13:14:57] iter = 15810, loss = 1.1069
2024-10-29 13:14:58: [2024-10-29 13:14:58] iter = 15820, loss = 1.9338
2024-10-29 13:14:58: [2024-10-29 13:14:58] iter = 15830, loss = 1.0290
2024-10-29 13:14:58: [2024-10-29 13:14:58] iter = 15840, loss = 5.2457
2024-10-29 13:14:59: [2024-10-29 13:14:59] iter = 15850, loss = 1.6393
2024-10-29 13:14:59: [2024-10-29 13:14:59] iter = 15860, loss = 1.3184
2024-10-29 13:14:59: [2024-10-29 13:14:59] iter = 15870, loss = 1.6212
2024-10-29 13:15:00: [2024-10-29 13:15:00] iter = 15880, loss = 0.9659
2024-10-29 13:15:00: [2024-10-29 13:15:00] iter = 15890, loss = 0.8096
2024-10-29 13:15:00: [2024-10-29 13:15:00] iter = 15900, loss = 0.8510
2024-10-29 13:15:01: [2024-10-29 13:15:01] iter = 15910, loss = 4.9004
2024-10-29 13:15:01: [2024-10-29 13:15:01] iter = 15920, loss = 0.8322
2024-10-29 13:15:01: [2024-10-29 13:15:01] iter = 15930, loss = 1.4695
2024-10-29 13:15:02: [2024-10-29 13:15:02] iter = 15940, loss = 1.1987
2024-10-29 13:15:02: [2024-10-29 13:15:02] iter = 15950, loss = 1.2978
2024-10-29 13:15:02: [2024-10-29 13:15:02] iter = 15960, loss = 0.9598
2024-10-29 13:15:03: [2024-10-29 13:15:03] iter = 15970, loss = 1.2715
2024-10-29 13:15:03: [2024-10-29 13:15:03] iter = 15980, loss = 1.1199
2024-10-29 13:15:03: [2024-10-29 13:15:03] iter = 15990, loss = 1.2940
2024-10-29 13:15:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 13:15:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:15:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 4108}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:15:33: Evaluate 5 random ConvNet, ACCmean = 0.5378 ACCstd = 0.0171
-------------------------
2024-10-29 13:15:33: Evaluate 5 random ConvNet, SENmean = 0.6185 SENstd = 0.0025
-------------------------
2024-10-29 13:15:33: Evaluate 5 random ConvNet, SPEmean = 0.6185 SPEstd = 0.0025
-------------------------
2024-10-29 13:15:33: Evaluate 5 random ConvNet, F!mean = 0.4586 F!std = 0.0092
-------------------------
2024-10-29 13:15:33: Evaluate 5 random ConvNet, mean = 0.5378 std = 0.0171
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:15:33: [2024-10-29 13:15:33] iter = 16000, loss = 0.8428
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:15:34: [2024-10-29 13:15:34] iter = 16010, loss = 1.0208
2024-10-29 13:15:34: [2024-10-29 13:15:34] iter = 16020, loss = 0.8649
2024-10-29 13:15:34: [2024-10-29 13:15:34] iter = 16030, loss = 1.4700
2024-10-29 13:15:35: [2024-10-29 13:15:35] iter = 16040, loss = 2.0791
2024-10-29 13:15:35: [2024-10-29 13:15:35] iter = 16050, loss = 0.7869
2024-10-29 13:15:35: [2024-10-29 13:15:35] iter = 16060, loss = 1.2138
2024-10-29 13:15:36: [2024-10-29 13:15:36] iter = 16070, loss = 1.1756
2024-10-29 13:15:36: [2024-10-29 13:15:36] iter = 16080, loss = 1.1193
2024-10-29 13:15:36: [2024-10-29 13:15:36] iter = 16090, loss = 1.2055
2024-10-29 13:15:37: [2024-10-29 13:15:37] iter = 16100, loss = 1.2379
2024-10-29 13:15:37: [2024-10-29 13:15:37] iter = 16110, loss = 2.1229
2024-10-29 13:15:37: [2024-10-29 13:15:37] iter = 16120, loss = 1.5580
2024-10-29 13:15:38: [2024-10-29 13:15:38] iter = 16130, loss = 0.9742
2024-10-29 13:15:38: [2024-10-29 13:15:38] iter = 16140, loss = 1.2496
2024-10-29 13:15:39: [2024-10-29 13:15:39] iter = 16150, loss = 1.6755
2024-10-29 13:15:39: [2024-10-29 13:15:39] iter = 16160, loss = 1.4497
2024-10-29 13:15:39: [2024-10-29 13:15:39] iter = 16170, loss = 1.0119
2024-10-29 13:15:40: [2024-10-29 13:15:40] iter = 16180, loss = 1.6903
2024-10-29 13:15:40: [2024-10-29 13:15:40] iter = 16190, loss = 1.0045
2024-10-29 13:15:40: [2024-10-29 13:15:40] iter = 16200, loss = 1.2805
2024-10-29 13:15:41: [2024-10-29 13:15:41] iter = 16210, loss = 2.5286
2024-10-29 13:15:41: [2024-10-29 13:15:41] iter = 16220, loss = 2.4180
2024-10-29 13:15:42: [2024-10-29 13:15:42] iter = 16230, loss = 1.4351
2024-10-29 13:15:42: [2024-10-29 13:15:42] iter = 16240, loss = 1.1294
2024-10-29 13:15:43: [2024-10-29 13:15:43] iter = 16250, loss = 1.1134
2024-10-29 13:15:44: [2024-10-29 13:15:44] iter = 16260, loss = 1.0190
2024-10-29 13:15:44: [2024-10-29 13:15:44] iter = 16270, loss = 0.9610
2024-10-29 13:15:45: [2024-10-29 13:15:45] iter = 16280, loss = 1.4239
2024-10-29 13:15:45: [2024-10-29 13:15:45] iter = 16290, loss = 1.0935
2024-10-29 13:15:46: [2024-10-29 13:15:46] iter = 16300, loss = 0.8688
2024-10-29 13:15:46: [2024-10-29 13:15:46] iter = 16310, loss = 1.3143
2024-10-29 13:15:46: [2024-10-29 13:15:46] iter = 16320, loss = 0.9767
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 16330, loss = 1.0021
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 16340, loss = 1.4499
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 16350, loss = 3.4555
2024-10-29 13:15:48: [2024-10-29 13:15:48] iter = 16360, loss = 7.7765
2024-10-29 13:15:48: [2024-10-29 13:15:48] iter = 16370, loss = 1.5178
2024-10-29 13:15:48: [2024-10-29 13:15:48] iter = 16380, loss = 1.2445
2024-10-29 13:15:49: [2024-10-29 13:15:49] iter = 16390, loss = 0.8393
2024-10-29 13:15:49: [2024-10-29 13:15:49] iter = 16400, loss = 1.7285
2024-10-29 13:15:49: [2024-10-29 13:15:49] iter = 16410, loss = 0.9598
2024-10-29 13:15:50: [2024-10-29 13:15:50] iter = 16420, loss = 3.4385
2024-10-29 13:15:50: [2024-10-29 13:15:50] iter = 16430, loss = 1.1320
2024-10-29 13:15:50: [2024-10-29 13:15:50] iter = 16440, loss = 1.3328
2024-10-29 13:15:51: [2024-10-29 13:15:51] iter = 16450, loss = 1.0109
2024-10-29 13:15:51: [2024-10-29 13:15:51] iter = 16460, loss = 1.0372
2024-10-29 13:15:51: [2024-10-29 13:15:51] iter = 16470, loss = 1.0764
2024-10-29 13:15:52: [2024-10-29 13:15:52] iter = 16480, loss = 1.5089
2024-10-29 13:15:52: [2024-10-29 13:15:52] iter = 16490, loss = 1.5278
2024-10-29 13:15:52: [2024-10-29 13:15:52] iter = 16500, loss = 2.0914
2024-10-29 13:15:53: [2024-10-29 13:15:53] iter = 16510, loss = 0.9636
2024-10-29 13:15:53: [2024-10-29 13:15:53] iter = 16520, loss = 3.9667
2024-10-29 13:15:53: [2024-10-29 13:15:53] iter = 16530, loss = 1.2516
2024-10-29 13:15:54: [2024-10-29 13:15:54] iter = 16540, loss = 0.7614
2024-10-29 13:15:54: [2024-10-29 13:15:54] iter = 16550, loss = 1.7628
2024-10-29 13:15:55: [2024-10-29 13:15:55] iter = 16560, loss = 1.1863
2024-10-29 13:15:55: [2024-10-29 13:15:55] iter = 16570, loss = 1.2339
2024-10-29 13:15:56: [2024-10-29 13:15:55] iter = 16580, loss = 2.0795
2024-10-29 13:15:56: [2024-10-29 13:15:56] iter = 16590, loss = 1.0816
2024-10-29 13:15:56: [2024-10-29 13:15:56] iter = 16600, loss = 0.8254
2024-10-29 13:15:57: [2024-10-29 13:15:57] iter = 16610, loss = 1.8391
2024-10-29 13:15:57: [2024-10-29 13:15:57] iter = 16620, loss = 1.7231
2024-10-29 13:15:57: [2024-10-29 13:15:57] iter = 16630, loss = 4.6656
2024-10-29 13:15:58: [2024-10-29 13:15:58] iter = 16640, loss = 1.7679
2024-10-29 13:15:58: [2024-10-29 13:15:58] iter = 16650, loss = 1.5002
2024-10-29 13:15:58: [2024-10-29 13:15:58] iter = 16660, loss = 1.3110
2024-10-29 13:15:59: [2024-10-29 13:15:59] iter = 16670, loss = 1.5589
2024-10-29 13:15:59: [2024-10-29 13:15:59] iter = 16680, loss = 1.2714
2024-10-29 13:15:59: [2024-10-29 13:15:59] iter = 16690, loss = 0.7637
2024-10-29 13:16:00: [2024-10-29 13:16:00] iter = 16700, loss = 1.5220
2024-10-29 13:16:00: [2024-10-29 13:16:00] iter = 16710, loss = 8.6946
2024-10-29 13:16:00: [2024-10-29 13:16:00] iter = 16720, loss = 2.2417
2024-10-29 13:16:01: [2024-10-29 13:16:01] iter = 16730, loss = 0.8465
2024-10-29 13:16:01: [2024-10-29 13:16:01] iter = 16740, loss = 1.5777
2024-10-29 13:16:01: [2024-10-29 13:16:01] iter = 16750, loss = 1.5840
2024-10-29 13:16:02: [2024-10-29 13:16:02] iter = 16760, loss = 2.3127
2024-10-29 13:16:02: [2024-10-29 13:16:02] iter = 16770, loss = 1.6257
2024-10-29 13:16:02: [2024-10-29 13:16:02] iter = 16780, loss = 1.1270
2024-10-29 13:16:03: [2024-10-29 13:16:03] iter = 16790, loss = 1.0289
2024-10-29 13:16:03: [2024-10-29 13:16:03] iter = 16800, loss = 1.0195
2024-10-29 13:16:03: [2024-10-29 13:16:03] iter = 16810, loss = 1.1416
2024-10-29 13:16:04: [2024-10-29 13:16:04] iter = 16820, loss = 1.0526
2024-10-29 13:16:04: [2024-10-29 13:16:04] iter = 16830, loss = 1.2592
2024-10-29 13:16:04: [2024-10-29 13:16:04] iter = 16840, loss = 1.1355
2024-10-29 13:16:05: [2024-10-29 13:16:05] iter = 16850, loss = 2.7685
2024-10-29 13:16:05: [2024-10-29 13:16:05] iter = 16860, loss = 0.7886
2024-10-29 13:16:05: [2024-10-29 13:16:05] iter = 16870, loss = 1.9382
2024-10-29 13:16:06: [2024-10-29 13:16:06] iter = 16880, loss = 1.1031
2024-10-29 13:16:06: [2024-10-29 13:16:06] iter = 16890, loss = 1.6196
2024-10-29 13:16:06: [2024-10-29 13:16:06] iter = 16900, loss = 1.2264
2024-10-29 13:16:07: [2024-10-29 13:16:07] iter = 16910, loss = 1.7834
2024-10-29 13:16:07: [2024-10-29 13:16:07] iter = 16920, loss = 1.1967
2024-10-29 13:16:07: [2024-10-29 13:16:07] iter = 16930, loss = 1.0641
2024-10-29 13:16:08: [2024-10-29 13:16:08] iter = 16940, loss = 1.5689
2024-10-29 13:16:08: [2024-10-29 13:16:08] iter = 16950, loss = 0.8775
2024-10-29 13:16:08: [2024-10-29 13:16:08] iter = 16960, loss = 0.6754
2024-10-29 13:16:09: [2024-10-29 13:16:09] iter = 16970, loss = 1.1702
2024-10-29 13:16:09: [2024-10-29 13:16:09] iter = 16980, loss = 1.2713
2024-10-29 13:16:09: [2024-10-29 13:16:09] iter = 16990, loss = 0.9775
2024-10-29 13:16:10: [2024-10-29 13:16:10] iter = 17000, loss = 1.2979
2024-10-29 13:16:10: [2024-10-29 13:16:10] iter = 17010, loss = 0.9467
2024-10-29 13:16:10: [2024-10-29 13:16:10] iter = 17020, loss = 0.8624
2024-10-29 13:16:11: [2024-10-29 13:16:11] iter = 17030, loss = 0.7822
2024-10-29 13:16:11: [2024-10-29 13:16:11] iter = 17040, loss = 0.7572
2024-10-29 13:16:11: [2024-10-29 13:16:11] iter = 17050, loss = 1.1731
2024-10-29 13:16:12: [2024-10-29 13:16:12] iter = 17060, loss = 1.2577
2024-10-29 13:16:12: [2024-10-29 13:16:12] iter = 17070, loss = 3.6754
2024-10-29 13:16:12: [2024-10-29 13:16:12] iter = 17080, loss = 2.7659
2024-10-29 13:16:13: [2024-10-29 13:16:13] iter = 17090, loss = 1.3847
2024-10-29 13:16:13: [2024-10-29 13:16:13] iter = 17100, loss = 1.5401
2024-10-29 13:16:14: [2024-10-29 13:16:14] iter = 17110, loss = 1.3483
2024-10-29 13:16:14: [2024-10-29 13:16:14] iter = 17120, loss = 2.6488
2024-10-29 13:16:14: [2024-10-29 13:16:14] iter = 17130, loss = 1.8664
2024-10-29 13:16:15: [2024-10-29 13:16:15] iter = 17140, loss = 2.1193
2024-10-29 13:16:15: [2024-10-29 13:16:15] iter = 17150, loss = 0.9804
2024-10-29 13:16:15: [2024-10-29 13:16:15] iter = 17160, loss = 1.4293
2024-10-29 13:16:16: [2024-10-29 13:16:16] iter = 17170, loss = 1.2912
2024-10-29 13:16:16: [2024-10-29 13:16:16] iter = 17180, loss = 0.8215
2024-10-29 13:16:16: [2024-10-29 13:16:16] iter = 17190, loss = 1.1637
2024-10-29 13:16:17: [2024-10-29 13:16:17] iter = 17200, loss = 0.7602
2024-10-29 13:16:17: [2024-10-29 13:16:17] iter = 17210, loss = 2.2297
2024-10-29 13:16:17: [2024-10-29 13:16:17] iter = 17220, loss = 1.3352
2024-10-29 13:16:18: [2024-10-29 13:16:18] iter = 17230, loss = 0.9414
2024-10-29 13:16:18: [2024-10-29 13:16:18] iter = 17240, loss = 1.1779
2024-10-29 13:16:18: [2024-10-29 13:16:18] iter = 17250, loss = 1.0221
2024-10-29 13:16:19: [2024-10-29 13:16:19] iter = 17260, loss = 2.3815
2024-10-29 13:16:19: [2024-10-29 13:16:19] iter = 17270, loss = 1.3302
2024-10-29 13:16:19: [2024-10-29 13:16:19] iter = 17280, loss = 1.2611
2024-10-29 13:16:20: [2024-10-29 13:16:20] iter = 17290, loss = 1.3241
2024-10-29 13:16:20: [2024-10-29 13:16:20] iter = 17300, loss = 1.4922
2024-10-29 13:16:20: [2024-10-29 13:16:20] iter = 17310, loss = 1.6457
2024-10-29 13:16:21: [2024-10-29 13:16:21] iter = 17320, loss = 1.0988
2024-10-29 13:16:21: [2024-10-29 13:16:21] iter = 17330, loss = 1.1736
2024-10-29 13:16:21: [2024-10-29 13:16:21] iter = 17340, loss = 2.9119
2024-10-29 13:16:22: [2024-10-29 13:16:22] iter = 17350, loss = 4.6976
2024-10-29 13:16:22: [2024-10-29 13:16:22] iter = 17360, loss = 0.9879
2024-10-29 13:16:22: [2024-10-29 13:16:22] iter = 17370, loss = 2.0323
2024-10-29 13:16:23: [2024-10-29 13:16:23] iter = 17380, loss = 1.3104
2024-10-29 13:16:23: [2024-10-29 13:16:23] iter = 17390, loss = 3.2979
2024-10-29 13:16:23: [2024-10-29 13:16:23] iter = 17400, loss = 1.5287
2024-10-29 13:16:24: [2024-10-29 13:16:24] iter = 17410, loss = 1.2061
2024-10-29 13:16:24: [2024-10-29 13:16:24] iter = 17420, loss = 1.0882
2024-10-29 13:16:24: [2024-10-29 13:16:24] iter = 17430, loss = 1.2290
2024-10-29 13:16:25: [2024-10-29 13:16:25] iter = 17440, loss = 1.0386
2024-10-29 13:16:25: [2024-10-29 13:16:25] iter = 17450, loss = 1.6584
2024-10-29 13:16:26: [2024-10-29 13:16:26] iter = 17460, loss = 3.2966
2024-10-29 13:16:26: [2024-10-29 13:16:26] iter = 17470, loss = 1.2699
2024-10-29 13:16:27: [2024-10-29 13:16:27] iter = 17480, loss = 1.4465
2024-10-29 13:16:27: [2024-10-29 13:16:27] iter = 17490, loss = 3.3419
2024-10-29 13:16:28: [2024-10-29 13:16:28] iter = 17500, loss = 1.2276
2024-10-29 13:16:28: [2024-10-29 13:16:28] iter = 17510, loss = 1.1025
2024-10-29 13:16:29: [2024-10-29 13:16:29] iter = 17520, loss = 1.2699
2024-10-29 13:16:29: [2024-10-29 13:16:29] iter = 17530, loss = 1.2819
2024-10-29 13:16:30: [2024-10-29 13:16:30] iter = 17540, loss = 1.1529
2024-10-29 13:16:31: [2024-10-29 13:16:31] iter = 17550, loss = 1.2892
2024-10-29 13:16:31: [2024-10-29 13:16:31] iter = 17560, loss = 2.0816
2024-10-29 13:16:32: [2024-10-29 13:16:32] iter = 17570, loss = 2.5517
2024-10-29 13:16:33: [2024-10-29 13:16:33] iter = 17580, loss = 1.2696
2024-10-29 13:16:34: [2024-10-29 13:16:34] iter = 17590, loss = 1.6393
2024-10-29 13:16:34: [2024-10-29 13:16:34] iter = 17600, loss = 1.5810
2024-10-29 13:16:35: [2024-10-29 13:16:35] iter = 17610, loss = 0.7835
2024-10-29 13:16:35: [2024-10-29 13:16:35] iter = 17620, loss = 0.9913
2024-10-29 13:16:36: [2024-10-29 13:16:36] iter = 17630, loss = 1.2324
2024-10-29 13:16:36: [2024-10-29 13:16:36] iter = 17640, loss = 1.0945
2024-10-29 13:16:37: [2024-10-29 13:16:37] iter = 17650, loss = 1.3030
2024-10-29 13:16:37: [2024-10-29 13:16:37] iter = 17660, loss = 1.1532
2024-10-29 13:16:37: [2024-10-29 13:16:37] iter = 17670, loss = 0.9008
2024-10-29 13:16:38: [2024-10-29 13:16:38] iter = 17680, loss = 0.7147
2024-10-29 13:16:38: [2024-10-29 13:16:38] iter = 17690, loss = 1.0465
2024-10-29 13:16:38: [2024-10-29 13:16:38] iter = 17700, loss = 1.4288
2024-10-29 13:16:39: [2024-10-29 13:16:39] iter = 17710, loss = 1.2555
2024-10-29 13:16:39: [2024-10-29 13:16:39] iter = 17720, loss = 2.8233
2024-10-29 13:16:39: [2024-10-29 13:16:39] iter = 17730, loss = 1.2849
2024-10-29 13:16:40: [2024-10-29 13:16:40] iter = 17740, loss = 1.2060
2024-10-29 13:16:40: [2024-10-29 13:16:40] iter = 17750, loss = 0.8935
2024-10-29 13:16:40: [2024-10-29 13:16:40] iter = 17760, loss = 0.8701
2024-10-29 13:16:41: [2024-10-29 13:16:41] iter = 17770, loss = 1.3936
2024-10-29 13:16:41: [2024-10-29 13:16:41] iter = 17780, loss = 12.5027
2024-10-29 13:16:41: [2024-10-29 13:16:41] iter = 17790, loss = 1.2075
2024-10-29 13:16:42: [2024-10-29 13:16:42] iter = 17800, loss = 3.1137
2024-10-29 13:16:42: [2024-10-29 13:16:42] iter = 17810, loss = 1.4143
2024-10-29 13:16:42: [2024-10-29 13:16:42] iter = 17820, loss = 1.5830
2024-10-29 13:16:43: [2024-10-29 13:16:43] iter = 17830, loss = 3.0894
2024-10-29 13:16:43: [2024-10-29 13:16:43] iter = 17840, loss = 1.5846
2024-10-29 13:16:43: [2024-10-29 13:16:43] iter = 17850, loss = 5.9737
2024-10-29 13:16:44: [2024-10-29 13:16:44] iter = 17860, loss = 1.3782
2024-10-29 13:16:44: [2024-10-29 13:16:44] iter = 17870, loss = 2.0426
2024-10-29 13:16:45: [2024-10-29 13:16:45] iter = 17880, loss = 1.3222
2024-10-29 13:16:45: [2024-10-29 13:16:45] iter = 17890, loss = 1.2538
2024-10-29 13:16:46: [2024-10-29 13:16:46] iter = 17900, loss = 1.3343
2024-10-29 13:16:46: [2024-10-29 13:16:46] iter = 17910, loss = 1.1232
2024-10-29 13:16:46: [2024-10-29 13:16:46] iter = 17920, loss = 1.9589
2024-10-29 13:16:47: [2024-10-29 13:16:47] iter = 17930, loss = 1.2356
2024-10-29 13:16:47: [2024-10-29 13:16:47] iter = 17940, loss = 1.9029
2024-10-29 13:16:47: [2024-10-29 13:16:47] iter = 17950, loss = 3.1542
2024-10-29 13:16:48: [2024-10-29 13:16:48] iter = 17960, loss = 1.3628
2024-10-29 13:16:48: [2024-10-29 13:16:48] iter = 17970, loss = 2.1738
2024-10-29 13:16:48: [2024-10-29 13:16:48] iter = 17980, loss = 1.3260
2024-10-29 13:16:49: [2024-10-29 13:16:49] iter = 17990, loss = 2.0085
2024-10-29 13:16:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 13:16:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:16:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 9494}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:17:16: Evaluate 5 random ConvNet, ACCmean = 0.5797 ACCstd = 0.0175
-------------------------
2024-10-29 13:17:16: Evaluate 5 random ConvNet, SENmean = 0.6098 SENstd = 0.0045
-------------------------
2024-10-29 13:17:16: Evaluate 5 random ConvNet, SPEmean = 0.6098 SPEstd = 0.0045
-------------------------
2024-10-29 13:17:16: Evaluate 5 random ConvNet, F!mean = 0.4788 F!std = 0.0100
-------------------------
2024-10-29 13:17:16: Evaluate 5 random ConvNet, mean = 0.5797 std = 0.0175
-------------------------
2024-10-29 13:17:16: [2024-10-29 13:17:16] iter = 18000, loss = 1.2496
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:17:16: [2024-10-29 13:17:16] iter = 18010, loss = 1.2587
2024-10-29 13:17:16: [2024-10-29 13:17:16] iter = 18020, loss = 1.5913
2024-10-29 13:17:17: [2024-10-29 13:17:17] iter = 18030, loss = 1.8530
2024-10-29 13:17:17: [2024-10-29 13:17:17] iter = 18040, loss = 2.0135
2024-10-29 13:17:17: [2024-10-29 13:17:17] iter = 18050, loss = 2.2395
2024-10-29 13:17:18: [2024-10-29 13:17:18] iter = 18060, loss = 1.3479
2024-10-29 13:17:18: [2024-10-29 13:17:18] iter = 18070, loss = 1.4008
2024-10-29 13:17:19: [2024-10-29 13:17:19] iter = 18080, loss = 1.1457
2024-10-29 13:17:19: [2024-10-29 13:17:19] iter = 18090, loss = 0.7189
2024-10-29 13:17:20: [2024-10-29 13:17:20] iter = 18100, loss = 1.6536
2024-10-29 13:17:20: [2024-10-29 13:17:20] iter = 18110, loss = 1.5928
2024-10-29 13:17:21: [2024-10-29 13:17:21] iter = 18120, loss = 2.1776
2024-10-29 13:17:21: [2024-10-29 13:17:21] iter = 18130, loss = 2.4739
2024-10-29 13:17:21: [2024-10-29 13:17:21] iter = 18140, loss = 3.5469
2024-10-29 13:17:22: [2024-10-29 13:17:22] iter = 18150, loss = 1.9235
2024-10-29 13:17:22: [2024-10-29 13:17:22] iter = 18160, loss = 2.4706
2024-10-29 13:17:22: [2024-10-29 13:17:22] iter = 18170, loss = 1.4408
2024-10-29 13:17:23: [2024-10-29 13:17:23] iter = 18180, loss = 1.5884
2024-10-29 13:17:23: [2024-10-29 13:17:23] iter = 18190, loss = 2.2030
2024-10-29 13:17:23: [2024-10-29 13:17:23] iter = 18200, loss = 5.4010
2024-10-29 13:17:24: [2024-10-29 13:17:24] iter = 18210, loss = 1.2550
2024-10-29 13:17:24: [2024-10-29 13:17:24] iter = 18220, loss = 1.0096
2024-10-29 13:17:24: [2024-10-29 13:17:24] iter = 18230, loss = 2.1843
2024-10-29 13:17:25: [2024-10-29 13:17:25] iter = 18240, loss = 1.1925
2024-10-29 13:17:25: [2024-10-29 13:17:25] iter = 18250, loss = 1.4693
2024-10-29 13:17:25: [2024-10-29 13:17:25] iter = 18260, loss = 1.8728
2024-10-29 13:17:26: [2024-10-29 13:17:26] iter = 18270, loss = 1.2025
2024-10-29 13:17:26: [2024-10-29 13:17:26] iter = 18280, loss = 1.6341
2024-10-29 13:17:26: [2024-10-29 13:17:26] iter = 18290, loss = 1.3726
2024-10-29 13:17:27: [2024-10-29 13:17:27] iter = 18300, loss = 1.2410
2024-10-29 13:17:27: [2024-10-29 13:17:27] iter = 18310, loss = 1.6240
2024-10-29 13:17:27: [2024-10-29 13:17:27] iter = 18320, loss = 2.8204
2024-10-29 13:17:28: [2024-10-29 13:17:28] iter = 18330, loss = 1.7057
2024-10-29 13:17:28: [2024-10-29 13:17:28] iter = 18340, loss = 1.0795
2024-10-29 13:17:28: [2024-10-29 13:17:28] iter = 18350, loss = 1.5670
2024-10-29 13:17:29: [2024-10-29 13:17:29] iter = 18360, loss = 0.8180
2024-10-29 13:17:29: [2024-10-29 13:17:29] iter = 18370, loss = 1.2772
2024-10-29 13:17:29: [2024-10-29 13:17:29] iter = 18380, loss = 0.8011
2024-10-29 13:17:30: [2024-10-29 13:17:30] iter = 18390, loss = 2.6524
2024-10-29 13:17:30: [2024-10-29 13:17:30] iter = 18400, loss = 1.5486
2024-10-29 13:17:30: [2024-10-29 13:17:30] iter = 18410, loss = 0.8138
2024-10-29 13:17:31: [2024-10-29 13:17:31] iter = 18420, loss = 3.8493
2024-10-29 13:17:31: [2024-10-29 13:17:31] iter = 18430, loss = 1.1575
2024-10-29 13:17:32: [2024-10-29 13:17:32] iter = 18440, loss = 1.3302
2024-10-29 13:17:32: [2024-10-29 13:17:32] iter = 18450, loss = 1.1169
2024-10-29 13:17:32: [2024-10-29 13:17:32] iter = 18460, loss = 1.1759
2024-10-29 13:17:33: [2024-10-29 13:17:33] iter = 18470, loss = 1.2013
2024-10-29 13:17:33: [2024-10-29 13:17:33] iter = 18480, loss = 1.1167
2024-10-29 13:17:33: [2024-10-29 13:17:33] iter = 18490, loss = 1.3584
2024-10-29 13:17:34: [2024-10-29 13:17:34] iter = 18500, loss = 1.1637
2024-10-29 13:17:34: [2024-10-29 13:17:34] iter = 18510, loss = 1.2107
2024-10-29 13:17:34: [2024-10-29 13:17:34] iter = 18520, loss = 2.5109
2024-10-29 13:17:35: [2024-10-29 13:17:35] iter = 18530, loss = 1.0947
2024-10-29 13:17:35: [2024-10-29 13:17:35] iter = 18540, loss = 1.2768
2024-10-29 13:17:35: [2024-10-29 13:17:35] iter = 18550, loss = 1.0906
2024-10-29 13:17:36: [2024-10-29 13:17:36] iter = 18560, loss = 0.8368
2024-10-29 13:17:36: [2024-10-29 13:17:36] iter = 18570, loss = 0.8805
2024-10-29 13:17:37: [2024-10-29 13:17:37] iter = 18580, loss = 0.8163
2024-10-29 13:17:37: [2024-10-29 13:17:37] iter = 18590, loss = 1.5647
2024-10-29 13:17:37: [2024-10-29 13:17:37] iter = 18600, loss = 2.0718
2024-10-29 13:17:38: [2024-10-29 13:17:38] iter = 18610, loss = 1.5687
2024-10-29 13:17:38: [2024-10-29 13:17:38] iter = 18620, loss = 4.7670
2024-10-29 13:17:38: [2024-10-29 13:17:38] iter = 18630, loss = 1.0443
2024-10-29 13:17:39: [2024-10-29 13:17:39] iter = 18640, loss = 2.3164
2024-10-29 13:17:39: [2024-10-29 13:17:39] iter = 18650, loss = 4.1412
2024-10-29 13:17:39: [2024-10-29 13:17:39] iter = 18660, loss = 1.3500
2024-10-29 13:17:40: [2024-10-29 13:17:40] iter = 18670, loss = 2.2108
2024-10-29 13:17:40: [2024-10-29 13:17:40] iter = 18680, loss = 4.1887
2024-10-29 13:17:40: [2024-10-29 13:17:40] iter = 18690, loss = 3.0687
2024-10-29 13:17:41: [2024-10-29 13:17:41] iter = 18700, loss = 1.3089
2024-10-29 13:17:41: [2024-10-29 13:17:41] iter = 18710, loss = 1.0849
2024-10-29 13:17:41: [2024-10-29 13:17:41] iter = 18720, loss = 2.5629
2024-10-29 13:17:42: [2024-10-29 13:17:42] iter = 18730, loss = 2.0432
2024-10-29 13:17:42: [2024-10-29 13:17:42] iter = 18740, loss = 1.2737
2024-10-29 13:17:43: [2024-10-29 13:17:43] iter = 18750, loss = 1.5518
2024-10-29 13:17:43: [2024-10-29 13:17:43] iter = 18760, loss = 1.3247
2024-10-29 13:17:44: [2024-10-29 13:17:44] iter = 18770, loss = 1.0796
2024-10-29 13:17:44: [2024-10-29 13:17:44] iter = 18780, loss = 1.3464
2024-10-29 13:17:44: [2024-10-29 13:17:44] iter = 18790, loss = 1.3923
2024-10-29 13:17:45: [2024-10-29 13:17:45] iter = 18800, loss = 17.2448
2024-10-29 13:17:45: [2024-10-29 13:17:45] iter = 18810, loss = 2.3581
2024-10-29 13:17:46: [2024-10-29 13:17:46] iter = 18820, loss = 1.1622
2024-10-29 13:17:46: [2024-10-29 13:17:46] iter = 18830, loss = 0.9956
2024-10-29 13:17:47: [2024-10-29 13:17:47] iter = 18840, loss = 1.3058
2024-10-29 13:17:47: [2024-10-29 13:17:47] iter = 18850, loss = 1.5839
2024-10-29 13:17:47: [2024-10-29 13:17:47] iter = 18860, loss = 1.0979
2024-10-29 13:17:48: [2024-10-29 13:17:48] iter = 18870, loss = 1.4601
2024-10-29 13:17:48: [2024-10-29 13:17:48] iter = 18880, loss = 1.0703
2024-10-29 13:17:48: [2024-10-29 13:17:48] iter = 18890, loss = 0.7700
2024-10-29 13:17:49: [2024-10-29 13:17:49] iter = 18900, loss = 1.5419
2024-10-29 13:17:49: [2024-10-29 13:17:49] iter = 18910, loss = 1.8414
2024-10-29 13:17:50: [2024-10-29 13:17:50] iter = 18920, loss = 0.9767
2024-10-29 13:17:50: [2024-10-29 13:17:50] iter = 18930, loss = 2.3392
2024-10-29 13:17:50: [2024-10-29 13:17:50] iter = 18940, loss = 0.8984
2024-10-29 13:17:51: [2024-10-29 13:17:51] iter = 18950, loss = 6.6446
2024-10-29 13:17:51: [2024-10-29 13:17:51] iter = 18960, loss = 0.7665
2024-10-29 13:17:51: [2024-10-29 13:17:51] iter = 18970, loss = 0.8010
2024-10-29 13:17:52: [2024-10-29 13:17:52] iter = 18980, loss = 0.7470
2024-10-29 13:17:52: [2024-10-29 13:17:52] iter = 18990, loss = 2.9350
2024-10-29 13:17:53: [2024-10-29 13:17:53] iter = 19000, loss = 1.1171
2024-10-29 13:17:53: [2024-10-29 13:17:53] iter = 19010, loss = 1.0362
2024-10-29 13:17:53: [2024-10-29 13:17:53] iter = 19020, loss = 1.7894
2024-10-29 13:17:54: [2024-10-29 13:17:54] iter = 19030, loss = 4.8816
2024-10-29 13:17:54: [2024-10-29 13:17:54] iter = 19040, loss = 0.6408
2024-10-29 13:17:54: [2024-10-29 13:17:54] iter = 19050, loss = 1.3604
2024-10-29 13:17:55: [2024-10-29 13:17:55] iter = 19060, loss = 1.1738
2024-10-29 13:17:55: [2024-10-29 13:17:55] iter = 19070, loss = 2.0631
2024-10-29 13:17:55: [2024-10-29 13:17:55] iter = 19080, loss = 1.5694
2024-10-29 13:17:56: [2024-10-29 13:17:56] iter = 19090, loss = 1.3681
2024-10-29 13:17:56: [2024-10-29 13:17:56] iter = 19100, loss = 0.9226
2024-10-29 13:17:56: [2024-10-29 13:17:56] iter = 19110, loss = 2.3525
2024-10-29 13:17:57: [2024-10-29 13:17:57] iter = 19120, loss = 1.1975
2024-10-29 13:17:57: [2024-10-29 13:17:57] iter = 19130, loss = 0.7839
2024-10-29 13:17:57: [2024-10-29 13:17:57] iter = 19140, loss = 0.9771
2024-10-29 13:17:58: [2024-10-29 13:17:58] iter = 19150, loss = 0.8866
2024-10-29 13:17:58: [2024-10-29 13:17:58] iter = 19160, loss = 1.7306
2024-10-29 13:17:58: [2024-10-29 13:17:58] iter = 19170, loss = 1.3750
2024-10-29 13:17:59: [2024-10-29 13:17:59] iter = 19180, loss = 2.7781
2024-10-29 13:17:59: [2024-10-29 13:17:59] iter = 19190, loss = 1.0477
2024-10-29 13:17:59: [2024-10-29 13:17:59] iter = 19200, loss = 0.7655
2024-10-29 13:18:00: [2024-10-29 13:18:00] iter = 19210, loss = 1.4330
2024-10-29 13:18:00: [2024-10-29 13:18:00] iter = 19220, loss = 3.1298
2024-10-29 13:18:00: [2024-10-29 13:18:00] iter = 19230, loss = 0.8763
2024-10-29 13:18:01: [2024-10-29 13:18:01] iter = 19240, loss = 1.3000
2024-10-29 13:18:01: [2024-10-29 13:18:01] iter = 19250, loss = 0.7124
2024-10-29 13:18:01: [2024-10-29 13:18:01] iter = 19260, loss = 1.1829
2024-10-29 13:18:02: [2024-10-29 13:18:02] iter = 19270, loss = 1.1223
2024-10-29 13:18:03: [2024-10-29 13:18:03] iter = 19280, loss = 3.3376
2024-10-29 13:18:03: [2024-10-29 13:18:03] iter = 19290, loss = 1.1460
2024-10-29 13:18:03: [2024-10-29 13:18:03] iter = 19300, loss = 1.5423
2024-10-29 13:18:04: [2024-10-29 13:18:04] iter = 19310, loss = 1.5332
2024-10-29 13:18:04: [2024-10-29 13:18:04] iter = 19320, loss = 3.2228
2024-10-29 13:18:04: [2024-10-29 13:18:04] iter = 19330, loss = 2.8709
2024-10-29 13:18:05: [2024-10-29 13:18:05] iter = 19340, loss = 1.0436
2024-10-29 13:18:05: [2024-10-29 13:18:05] iter = 19350, loss = 5.9715
2024-10-29 13:18:05: [2024-10-29 13:18:05] iter = 19360, loss = 0.8669
2024-10-29 13:18:06: [2024-10-29 13:18:06] iter = 19370, loss = 2.1860
2024-10-29 13:18:06: [2024-10-29 13:18:06] iter = 19380, loss = 1.1140
2024-10-29 13:18:07: [2024-10-29 13:18:07] iter = 19390, loss = 2.8200
2024-10-29 13:18:07: [2024-10-29 13:18:07] iter = 19400, loss = 1.3701
2024-10-29 13:18:08: [2024-10-29 13:18:08] iter = 19410, loss = 1.1431
2024-10-29 13:18:08: [2024-10-29 13:18:08] iter = 19420, loss = 2.1478
2024-10-29 13:18:08: [2024-10-29 13:18:08] iter = 19430, loss = 1.8669
2024-10-29 13:18:09: [2024-10-29 13:18:09] iter = 19440, loss = 1.1754
2024-10-29 13:18:09: [2024-10-29 13:18:09] iter = 19450, loss = 1.8507
2024-10-29 13:18:10: [2024-10-29 13:18:10] iter = 19460, loss = 1.0844
2024-10-29 13:18:10: [2024-10-29 13:18:10] iter = 19470, loss = 1.2664
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 19480, loss = 0.9440
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 19490, loss = 1.3544
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 19500, loss = 1.8050
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 19510, loss = 3.2692
2024-10-29 13:18:12: [2024-10-29 13:18:12] iter = 19520, loss = 1.8541
2024-10-29 13:18:12: [2024-10-29 13:18:12] iter = 19530, loss = 1.5712
2024-10-29 13:18:12: [2024-10-29 13:18:12] iter = 19540, loss = 1.0133
2024-10-29 13:18:13: [2024-10-29 13:18:13] iter = 19550, loss = 1.5490
2024-10-29 13:18:13: [2024-10-29 13:18:13] iter = 19560, loss = 2.2971
2024-10-29 13:18:14: [2024-10-29 13:18:14] iter = 19570, loss = 1.8141
2024-10-29 13:18:14: [2024-10-29 13:18:14] iter = 19580, loss = 1.0525
2024-10-29 13:18:14: [2024-10-29 13:18:14] iter = 19590, loss = 1.3661
2024-10-29 13:18:15: [2024-10-29 13:18:15] iter = 19600, loss = 4.6374
2024-10-29 13:18:15: [2024-10-29 13:18:15] iter = 19610, loss = 0.8343
2024-10-29 13:18:15: [2024-10-29 13:18:15] iter = 19620, loss = 1.6647
2024-10-29 13:18:16: [2024-10-29 13:18:16] iter = 19630, loss = 1.4820
2024-10-29 13:18:16: [2024-10-29 13:18:16] iter = 19640, loss = 1.0644
2024-10-29 13:18:16: [2024-10-29 13:18:16] iter = 19650, loss = 2.2265
2024-10-29 13:18:17: [2024-10-29 13:18:17] iter = 19660, loss = 1.5136
2024-10-29 13:18:17: [2024-10-29 13:18:17] iter = 19670, loss = 3.9721
2024-10-29 13:18:17: [2024-10-29 13:18:17] iter = 19680, loss = 0.9961
2024-10-29 13:18:18: [2024-10-29 13:18:18] iter = 19690, loss = 1.9905
2024-10-29 13:18:18: [2024-10-29 13:18:18] iter = 19700, loss = 2.3376
2024-10-29 13:18:18: [2024-10-29 13:18:18] iter = 19710, loss = 1.4349
2024-10-29 13:18:19: [2024-10-29 13:18:19] iter = 19720, loss = 1.5481
2024-10-29 13:18:19: [2024-10-29 13:18:19] iter = 19730, loss = 1.0185
2024-10-29 13:18:20: [2024-10-29 13:18:20] iter = 19740, loss = 1.0601
2024-10-29 13:18:20: [2024-10-29 13:18:20] iter = 19750, loss = 1.5946
2024-10-29 13:18:21: [2024-10-29 13:18:21] iter = 19760, loss = 1.2172
2024-10-29 13:18:21: [2024-10-29 13:18:21] iter = 19770, loss = 1.3090
2024-10-29 13:18:21: [2024-10-29 13:18:21] iter = 19780, loss = 1.0399
2024-10-29 13:18:22: [2024-10-29 13:18:22] iter = 19790, loss = 1.1628
2024-10-29 13:18:22: [2024-10-29 13:18:22] iter = 19800, loss = 2.4343
2024-10-29 13:18:22: [2024-10-29 13:18:22] iter = 19810, loss = 1.5134
2024-10-29 13:18:23: [2024-10-29 13:18:23] iter = 19820, loss = 1.1520
2024-10-29 13:18:23: [2024-10-29 13:18:23] iter = 19830, loss = 2.6083
2024-10-29 13:18:23: [2024-10-29 13:18:23] iter = 19840, loss = 2.1305
2024-10-29 13:18:24: [2024-10-29 13:18:24] iter = 19850, loss = 0.9314
2024-10-29 13:18:24: [2024-10-29 13:18:24] iter = 19860, loss = 1.3264
2024-10-29 13:18:24: [2024-10-29 13:18:24] iter = 19870, loss = 0.9697
2024-10-29 13:18:25: [2024-10-29 13:18:25] iter = 19880, loss = 1.2669
2024-10-29 13:18:25: [2024-10-29 13:18:25] iter = 19890, loss = 2.1252
2024-10-29 13:18:25: [2024-10-29 13:18:25] iter = 19900, loss = 0.9206
2024-10-29 13:18:26: [2024-10-29 13:18:26] iter = 19910, loss = 0.9182
2024-10-29 13:18:26: [2024-10-29 13:18:26] iter = 19920, loss = 0.9229
2024-10-29 13:18:26: [2024-10-29 13:18:26] iter = 19930, loss = 0.9653
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 19940, loss = 1.1810
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 19950, loss = 1.7288
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 19960, loss = 1.6910
2024-10-29 13:18:28: [2024-10-29 13:18:28] iter = 19970, loss = 2.1118
2024-10-29 13:18:28: [2024-10-29 13:18:28] iter = 19980, loss = 2.7388
2024-10-29 13:18:28: [2024-10-29 13:18:28] iter = 19990, loss = 2.3226
2024-10-29 13:18:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:18:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:18:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 9270}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:18:59: Evaluate 5 random ConvNet, ACCmean = 0.5801 ACCstd = 0.0220
-------------------------
2024-10-29 13:18:59: Evaluate 5 random ConvNet, SENmean = 0.6203 SENstd = 0.0034
-------------------------
2024-10-29 13:18:59: Evaluate 5 random ConvNet, SPEmean = 0.6203 SPEstd = 0.0034
-------------------------
2024-10-29 13:18:59: Evaluate 5 random ConvNet, F!mean = 0.4818 F!std = 0.0117
-------------------------
2024-10-29 13:18:59: Evaluate 5 random ConvNet, mean = 0.5801 std = 0.0220
-------------------------
2024-10-29 13:18:59: [2024-10-29 13:18:59] iter = 20000, loss = 0.9077
2024-10-29 13:18:59: 
================== Exp 3 ==================
 
2024-10-29 13:18:59: Hyper-parameters: 
{'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f20047a2730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_ChestMNIST (INFO)>}
2024-10-29 13:18:59: Evaluation model pool: ['ConvNet']
2024-10-29 13:19:01: class c = 0: 70472 real images
2024-10-29 13:19:01: class c = 1: 7996 real images
2024-10-29 13:19:01: real images channel 0, mean = 0.4936, std = 0.2380
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 13:19:01: initialize synthetic data from random real images
2024-10-29 13:19:01: [2024-10-29 13:19:01] training begins
2024-10-29 13:19:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 13:19:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:19:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 39451}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:31: Evaluate 5 random ConvNet, ACCmean = 0.6760 ACCstd = 0.0133
-------------------------
2024-10-29 13:19:31: Evaluate 5 random ConvNet, SENmean = 0.6121 SENstd = 0.0074
-------------------------
2024-10-29 13:19:31: Evaluate 5 random ConvNet, SPEmean = 0.6121 SPEstd = 0.0074
-------------------------
2024-10-29 13:19:31: Evaluate 5 random ConvNet, F!mean = 0.5266 F!std = 0.0036
-------------------------
2024-10-29 13:19:31: Evaluate 5 random ConvNet, mean = 0.6760 std = 0.0133
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:31: [2024-10-29 13:19:31] iter = 00000, loss = 5.3747
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:31: [2024-10-29 13:19:31] iter = 00010, loss = 4.8344
2024-10-29 13:19:32: [2024-10-29 13:19:32] iter = 00020, loss = 1.7498
2024-10-29 13:19:32: [2024-10-29 13:19:32] iter = 00030, loss = 1.7878
2024-10-29 13:19:32: [2024-10-29 13:19:32] iter = 00040, loss = 2.4673
2024-10-29 13:19:33: [2024-10-29 13:19:33] iter = 00050, loss = 1.9075
2024-10-29 13:19:33: [2024-10-29 13:19:33] iter = 00060, loss = 2.2646
2024-10-29 13:19:33: [2024-10-29 13:19:33] iter = 00070, loss = 1.7164
2024-10-29 13:19:34: [2024-10-29 13:19:34] iter = 00080, loss = 1.2899
2024-10-29 13:19:34: [2024-10-29 13:19:34] iter = 00090, loss = 1.3097
2024-10-29 13:19:34: [2024-10-29 13:19:34] iter = 00100, loss = 1.2478
2024-10-29 13:19:35: [2024-10-29 13:19:35] iter = 00110, loss = 1.4850
2024-10-29 13:19:35: [2024-10-29 13:19:35] iter = 00120, loss = 2.7665
2024-10-29 13:19:35: [2024-10-29 13:19:35] iter = 00130, loss = 1.4507
2024-10-29 13:19:36: [2024-10-29 13:19:36] iter = 00140, loss = 1.4367
2024-10-29 13:19:36: [2024-10-29 13:19:36] iter = 00150, loss = 1.9156
2024-10-29 13:19:36: [2024-10-29 13:19:36] iter = 00160, loss = 1.4472
2024-10-29 13:19:37: [2024-10-29 13:19:37] iter = 00170, loss = 1.3677
2024-10-29 13:19:37: [2024-10-29 13:19:37] iter = 00180, loss = 2.2431
2024-10-29 13:19:38: [2024-10-29 13:19:38] iter = 00190, loss = 1.3094
2024-10-29 13:19:38: [2024-10-29 13:19:38] iter = 00200, loss = 1.5442
2024-10-29 13:19:38: [2024-10-29 13:19:38] iter = 00210, loss = 1.0012
2024-10-29 13:19:39: [2024-10-29 13:19:39] iter = 00220, loss = 2.1256
2024-10-29 13:19:39: [2024-10-29 13:19:39] iter = 00230, loss = 11.4184
2024-10-29 13:19:39: [2024-10-29 13:19:39] iter = 00240, loss = 3.6720
2024-10-29 13:19:40: [2024-10-29 13:19:40] iter = 00250, loss = 1.4475
2024-10-29 13:19:40: [2024-10-29 13:19:40] iter = 00260, loss = 1.5407
2024-10-29 13:19:41: [2024-10-29 13:19:41] iter = 00270, loss = 1.5291
2024-10-29 13:19:41: [2024-10-29 13:19:41] iter = 00280, loss = 2.1305
2024-10-29 13:19:41: [2024-10-29 13:19:41] iter = 00290, loss = 1.5838
2024-10-29 13:19:42: [2024-10-29 13:19:42] iter = 00300, loss = 1.0337
2024-10-29 13:19:42: [2024-10-29 13:19:42] iter = 00310, loss = 1.8133
2024-10-29 13:19:43: [2024-10-29 13:19:43] iter = 00320, loss = 4.1588
2024-10-29 13:19:43: [2024-10-29 13:19:43] iter = 00330, loss = 2.4140
2024-10-29 13:19:43: [2024-10-29 13:19:43] iter = 00340, loss = 1.3453
2024-10-29 13:19:44: [2024-10-29 13:19:44] iter = 00350, loss = 1.2738
2024-10-29 13:19:44: [2024-10-29 13:19:44] iter = 00360, loss = 2.1792
2024-10-29 13:19:44: [2024-10-29 13:19:44] iter = 00370, loss = 1.1182
2024-10-29 13:19:45: [2024-10-29 13:19:45] iter = 00380, loss = 1.8379
2024-10-29 13:19:45: [2024-10-29 13:19:45] iter = 00390, loss = 0.9069
2024-10-29 13:19:45: [2024-10-29 13:19:45] iter = 00400, loss = 1.0823
2024-10-29 13:19:46: [2024-10-29 13:19:46] iter = 00410, loss = 1.1785
2024-10-29 13:19:46: [2024-10-29 13:19:46] iter = 00420, loss = 0.8520
2024-10-29 13:19:46: [2024-10-29 13:19:46] iter = 00430, loss = 2.2821
2024-10-29 13:19:47: [2024-10-29 13:19:47] iter = 00440, loss = 1.5875
2024-10-29 13:19:47: [2024-10-29 13:19:47] iter = 00450, loss = 1.2588
2024-10-29 13:19:47: [2024-10-29 13:19:47] iter = 00460, loss = 1.3508
2024-10-29 13:19:48: [2024-10-29 13:19:48] iter = 00470, loss = 1.3570
2024-10-29 13:19:48: [2024-10-29 13:19:48] iter = 00480, loss = 1.1222
2024-10-29 13:19:48: [2024-10-29 13:19:48] iter = 00490, loss = 1.1595
2024-10-29 13:19:49: [2024-10-29 13:19:49] iter = 00500, loss = 1.2002
2024-10-29 13:19:49: [2024-10-29 13:19:49] iter = 00510, loss = 1.4573
2024-10-29 13:19:49: [2024-10-29 13:19:49] iter = 00520, loss = 2.2771
2024-10-29 13:19:50: [2024-10-29 13:19:50] iter = 00530, loss = 1.5278
2024-10-29 13:19:50: [2024-10-29 13:19:50] iter = 00540, loss = 1.3037
2024-10-29 13:19:50: [2024-10-29 13:19:50] iter = 00550, loss = 1.8346
2024-10-29 13:19:51: [2024-10-29 13:19:51] iter = 00560, loss = 1.0031
2024-10-29 13:19:51: [2024-10-29 13:19:51] iter = 00570, loss = 2.9605
2024-10-29 13:19:52: [2024-10-29 13:19:52] iter = 00580, loss = 5.8419
2024-10-29 13:19:52: [2024-10-29 13:19:52] iter = 00590, loss = 7.1999
2024-10-29 13:19:52: [2024-10-29 13:19:52] iter = 00600, loss = 1.6797
2024-10-29 13:19:53: [2024-10-29 13:19:53] iter = 00610, loss = 2.0778
2024-10-29 13:19:53: [2024-10-29 13:19:53] iter = 00620, loss = 2.4299
2024-10-29 13:19:54: [2024-10-29 13:19:54] iter = 00630, loss = 2.1335
2024-10-29 13:19:54: [2024-10-29 13:19:54] iter = 00640, loss = 1.1686
2024-10-29 13:19:54: [2024-10-29 13:19:54] iter = 00650, loss = 1.6340
2024-10-29 13:19:55: [2024-10-29 13:19:55] iter = 00660, loss = 0.9340
2024-10-29 13:19:55: [2024-10-29 13:19:55] iter = 00670, loss = 4.0387
2024-10-29 13:19:55: [2024-10-29 13:19:55] iter = 00680, loss = 2.0890
2024-10-29 13:19:56: [2024-10-29 13:19:56] iter = 00690, loss = 1.9351
2024-10-29 13:19:56: [2024-10-29 13:19:56] iter = 00700, loss = 2.2382
2024-10-29 13:19:56: [2024-10-29 13:19:56] iter = 00710, loss = 2.8916
2024-10-29 13:19:57: [2024-10-29 13:19:57] iter = 00720, loss = 1.6834
2024-10-29 13:19:57: [2024-10-29 13:19:57] iter = 00730, loss = 1.2802
2024-10-29 13:19:57: [2024-10-29 13:19:57] iter = 00740, loss = 1.6745
2024-10-29 13:19:58: [2024-10-29 13:19:58] iter = 00750, loss = 1.7686
2024-10-29 13:19:58: [2024-10-29 13:19:58] iter = 00760, loss = 2.9959
2024-10-29 13:19:58: [2024-10-29 13:19:58] iter = 00770, loss = 1.9214
2024-10-29 13:19:59: [2024-10-29 13:19:59] iter = 00780, loss = 0.8411
2024-10-29 13:19:59: [2024-10-29 13:19:59] iter = 00790, loss = 1.3007
2024-10-29 13:19:59: [2024-10-29 13:19:59] iter = 00800, loss = 1.3610
2024-10-29 13:20:00: [2024-10-29 13:20:00] iter = 00810, loss = 1.0471
2024-10-29 13:20:00: [2024-10-29 13:20:00] iter = 00820, loss = 1.0508
2024-10-29 13:20:00: [2024-10-29 13:20:00] iter = 00830, loss = 1.0010
2024-10-29 13:20:01: [2024-10-29 13:20:01] iter = 00840, loss = 1.8489
2024-10-29 13:20:01: [2024-10-29 13:20:01] iter = 00850, loss = 1.4911
2024-10-29 13:20:01: [2024-10-29 13:20:01] iter = 00860, loss = 1.5266
2024-10-29 13:20:02: [2024-10-29 13:20:02] iter = 00870, loss = 3.2270
2024-10-29 13:20:02: [2024-10-29 13:20:02] iter = 00880, loss = 1.1467
2024-10-29 13:20:03: [2024-10-29 13:20:03] iter = 00890, loss = 0.8692
2024-10-29 13:20:03: [2024-10-29 13:20:03] iter = 00900, loss = 2.8054
2024-10-29 13:20:03: [2024-10-29 13:20:03] iter = 00910, loss = 5.1956
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 00920, loss = 1.4494
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 00930, loss = 1.6401
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 00940, loss = 5.1067
2024-10-29 13:20:05: [2024-10-29 13:20:05] iter = 00950, loss = 4.1174
2024-10-29 13:20:05: [2024-10-29 13:20:05] iter = 00960, loss = 4.2171
2024-10-29 13:20:06: [2024-10-29 13:20:06] iter = 00970, loss = 1.6615
2024-10-29 13:20:06: [2024-10-29 13:20:06] iter = 00980, loss = 1.2300
2024-10-29 13:20:06: [2024-10-29 13:20:06] iter = 00990, loss = 0.9963
2024-10-29 13:20:07: [2024-10-29 13:20:07] iter = 01000, loss = 1.0236
2024-10-29 13:20:07: [2024-10-29 13:20:07] iter = 01010, loss = 0.8217
2024-10-29 13:20:07: [2024-10-29 13:20:07] iter = 01020, loss = 0.9453
2024-10-29 13:20:08: [2024-10-29 13:20:08] iter = 01030, loss = 1.3286
2024-10-29 13:20:08: [2024-10-29 13:20:08] iter = 01040, loss = 1.4053
2024-10-29 13:20:08: [2024-10-29 13:20:08] iter = 01050, loss = 1.1732
2024-10-29 13:20:09: [2024-10-29 13:20:09] iter = 01060, loss = 3.6088
2024-10-29 13:20:09: [2024-10-29 13:20:09] iter = 01070, loss = 1.6741
2024-10-29 13:20:09: [2024-10-29 13:20:09] iter = 01080, loss = 1.7511
2024-10-29 13:20:10: [2024-10-29 13:20:10] iter = 01090, loss = 1.2950
2024-10-29 13:20:10: [2024-10-29 13:20:10] iter = 01100, loss = 1.7131
2024-10-29 13:20:10: [2024-10-29 13:20:10] iter = 01110, loss = 2.0695
2024-10-29 13:20:11: [2024-10-29 13:20:11] iter = 01120, loss = 1.7622
2024-10-29 13:20:11: [2024-10-29 13:20:11] iter = 01130, loss = 0.9167
2024-10-29 13:20:11: [2024-10-29 13:20:11] iter = 01140, loss = 1.0313
2024-10-29 13:20:12: [2024-10-29 13:20:12] iter = 01150, loss = 2.2661
2024-10-29 13:20:12: [2024-10-29 13:20:12] iter = 01160, loss = 2.2147
2024-10-29 13:20:12: [2024-10-29 13:20:12] iter = 01170, loss = 1.5404
2024-10-29 13:20:13: [2024-10-29 13:20:13] iter = 01180, loss = 1.4076
2024-10-29 13:20:13: [2024-10-29 13:20:13] iter = 01190, loss = 1.0308
2024-10-29 13:20:13: [2024-10-29 13:20:13] iter = 01200, loss = 2.1115
2024-10-29 13:20:14: [2024-10-29 13:20:14] iter = 01210, loss = 1.4238
2024-10-29 13:20:14: [2024-10-29 13:20:14] iter = 01220, loss = 1.1469
2024-10-29 13:20:14: [2024-10-29 13:20:14] iter = 01230, loss = 2.0587
2024-10-29 13:20:15: [2024-10-29 13:20:15] iter = 01240, loss = 1.8284
2024-10-29 13:20:15: [2024-10-29 13:20:15] iter = 01250, loss = 1.2835
2024-10-29 13:20:15: [2024-10-29 13:20:15] iter = 01260, loss = 0.8788
2024-10-29 13:20:16: [2024-10-29 13:20:16] iter = 01270, loss = 1.3664
2024-10-29 13:20:16: [2024-10-29 13:20:16] iter = 01280, loss = 0.8467
2024-10-29 13:20:16: [2024-10-29 13:20:16] iter = 01290, loss = 1.1608
2024-10-29 13:20:17: [2024-10-29 13:20:17] iter = 01300, loss = 1.4725
2024-10-29 13:20:17: [2024-10-29 13:20:17] iter = 01310, loss = 0.9558
2024-10-29 13:20:18: [2024-10-29 13:20:18] iter = 01320, loss = 8.7727
2024-10-29 13:20:18: [2024-10-29 13:20:18] iter = 01330, loss = 1.8481
2024-10-29 13:20:19: [2024-10-29 13:20:19] iter = 01340, loss = 2.6430
2024-10-29 13:20:19: [2024-10-29 13:20:19] iter = 01350, loss = 1.9230
2024-10-29 13:20:20: [2024-10-29 13:20:20] iter = 01360, loss = 1.3864
2024-10-29 13:20:20: [2024-10-29 13:20:20] iter = 01370, loss = 1.0365
2024-10-29 13:20:21: [2024-10-29 13:20:21] iter = 01380, loss = 0.8897
2024-10-29 13:20:21: [2024-10-29 13:20:21] iter = 01390, loss = 0.7752
2024-10-29 13:20:21: [2024-10-29 13:20:21] iter = 01400, loss = 1.3307
2024-10-29 13:20:22: [2024-10-29 13:20:22] iter = 01410, loss = 0.9580
2024-10-29 13:20:22: [2024-10-29 13:20:22] iter = 01420, loss = 1.2285
2024-10-29 13:20:23: [2024-10-29 13:20:23] iter = 01430, loss = 5.9405
2024-10-29 13:20:23: [2024-10-29 13:20:23] iter = 01440, loss = 0.8990
2024-10-29 13:20:24: [2024-10-29 13:20:24] iter = 01450, loss = 1.4390
2024-10-29 13:20:24: [2024-10-29 13:20:24] iter = 01460, loss = 1.1462
2024-10-29 13:20:24: [2024-10-29 13:20:24] iter = 01470, loss = 0.9378
2024-10-29 13:20:25: [2024-10-29 13:20:25] iter = 01480, loss = 1.6031
2024-10-29 13:20:25: [2024-10-29 13:20:25] iter = 01490, loss = 0.9681
2024-10-29 13:20:26: [2024-10-29 13:20:26] iter = 01500, loss = 3.2418
2024-10-29 13:20:26: [2024-10-29 13:20:26] iter = 01510, loss = 1.5694
2024-10-29 13:20:27: [2024-10-29 13:20:27] iter = 01520, loss = 0.9729
2024-10-29 13:20:27: [2024-10-29 13:20:27] iter = 01530, loss = 3.2466
2024-10-29 13:20:28: [2024-10-29 13:20:28] iter = 01540, loss = 1.6595
2024-10-29 13:20:28: [2024-10-29 13:20:28] iter = 01550, loss = 2.3335
2024-10-29 13:20:28: [2024-10-29 13:20:28] iter = 01560, loss = 1.4626
2024-10-29 13:20:29: [2024-10-29 13:20:29] iter = 01570, loss = 1.1893
2024-10-29 13:20:29: [2024-10-29 13:20:29] iter = 01580, loss = 1.4007
2024-10-29 13:20:29: [2024-10-29 13:20:29] iter = 01590, loss = 0.9698
2024-10-29 13:20:30: [2024-10-29 13:20:30] iter = 01600, loss = 2.2571
2024-10-29 13:20:30: [2024-10-29 13:20:30] iter = 01610, loss = 4.4574
2024-10-29 13:20:31: [2024-10-29 13:20:31] iter = 01620, loss = 1.9845
2024-10-29 13:20:32: [2024-10-29 13:20:32] iter = 01630, loss = 2.2003
2024-10-29 13:20:32: [2024-10-29 13:20:32] iter = 01640, loss = 1.9852
2024-10-29 13:20:32: [2024-10-29 13:20:32] iter = 01650, loss = 2.6380
2024-10-29 13:20:33: [2024-10-29 13:20:33] iter = 01660, loss = 2.8984
2024-10-29 13:20:33: [2024-10-29 13:20:33] iter = 01670, loss = 0.8737
2024-10-29 13:20:33: [2024-10-29 13:20:33] iter = 01680, loss = 0.9635
2024-10-29 13:20:34: [2024-10-29 13:20:34] iter = 01690, loss = 2.2201
2024-10-29 13:20:34: [2024-10-29 13:20:34] iter = 01700, loss = 1.5386
2024-10-29 13:20:34: [2024-10-29 13:20:34] iter = 01710, loss = 2.5762
2024-10-29 13:20:35: [2024-10-29 13:20:35] iter = 01720, loss = 1.4375
2024-10-29 13:20:35: [2024-10-29 13:20:35] iter = 01730, loss = 1.9106
2024-10-29 13:20:35: [2024-10-29 13:20:35] iter = 01740, loss = 1.4113
2024-10-29 13:20:36: [2024-10-29 13:20:36] iter = 01750, loss = 0.8398
2024-10-29 13:20:36: [2024-10-29 13:20:36] iter = 01760, loss = 1.0684
2024-10-29 13:20:37: [2024-10-29 13:20:37] iter = 01770, loss = 1.2026
2024-10-29 13:20:37: [2024-10-29 13:20:37] iter = 01780, loss = 1.6493
2024-10-29 13:20:38: [2024-10-29 13:20:38] iter = 01790, loss = 1.6369
2024-10-29 13:20:38: [2024-10-29 13:20:38] iter = 01800, loss = 1.1207
2024-10-29 13:20:38: [2024-10-29 13:20:38] iter = 01810, loss = 0.9296
2024-10-29 13:20:39: [2024-10-29 13:20:39] iter = 01820, loss = 1.5421
2024-10-29 13:20:39: [2024-10-29 13:20:39] iter = 01830, loss = 1.8105
2024-10-29 13:20:39: [2024-10-29 13:20:39] iter = 01840, loss = 1.4257
2024-10-29 13:20:40: [2024-10-29 13:20:40] iter = 01850, loss = 1.9223
2024-10-29 13:20:40: [2024-10-29 13:20:40] iter = 01860, loss = 2.4471
2024-10-29 13:20:40: [2024-10-29 13:20:40] iter = 01870, loss = 1.4199
2024-10-29 13:20:41: [2024-10-29 13:20:41] iter = 01880, loss = 2.7975
2024-10-29 13:20:41: [2024-10-29 13:20:41] iter = 01890, loss = 3.2323
2024-10-29 13:20:41: [2024-10-29 13:20:41] iter = 01900, loss = 1.2372
2024-10-29 13:20:42: [2024-10-29 13:20:42] iter = 01910, loss = 1.3556
2024-10-29 13:20:42: [2024-10-29 13:20:42] iter = 01920, loss = 1.1278
2024-10-29 13:20:42: [2024-10-29 13:20:42] iter = 01930, loss = 1.0418
2024-10-29 13:20:43: [2024-10-29 13:20:43] iter = 01940, loss = 0.8652
2024-10-29 13:20:43: [2024-10-29 13:20:43] iter = 01950, loss = 0.9172
2024-10-29 13:20:43: [2024-10-29 13:20:43] iter = 01960, loss = 2.1637
2024-10-29 13:20:44: [2024-10-29 13:20:44] iter = 01970, loss = 1.8262
2024-10-29 13:20:44: [2024-10-29 13:20:44] iter = 01980, loss = 1.0911
2024-10-29 13:20:45: [2024-10-29 13:20:45] iter = 01990, loss = 1.1004
2024-10-29 13:20:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 13:20:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:20:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 45340}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:21:12: Evaluate 5 random ConvNet, ACCmean = 0.6115 ACCstd = 0.0150
-------------------------
2024-10-29 13:21:12: Evaluate 5 random ConvNet, SENmean = 0.6103 SENstd = 0.0032
-------------------------
2024-10-29 13:21:12: Evaluate 5 random ConvNet, SPEmean = 0.6103 SPEstd = 0.0032
-------------------------
2024-10-29 13:21:12: Evaluate 5 random ConvNet, F!mean = 0.4950 F!std = 0.0075
-------------------------
2024-10-29 13:21:12: Evaluate 5 random ConvNet, mean = 0.6115 std = 0.0150
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:21:12: [2024-10-29 13:21:12] iter = 02000, loss = 0.6772
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:21:12: [2024-10-29 13:21:12] iter = 02010, loss = 1.1546
2024-10-29 13:21:12: [2024-10-29 13:21:12] iter = 02020, loss = 1.1065
2024-10-29 13:21:13: [2024-10-29 13:21:13] iter = 02030, loss = 1.1529
2024-10-29 13:21:13: [2024-10-29 13:21:13] iter = 02040, loss = 4.5553
2024-10-29 13:21:13: [2024-10-29 13:21:13] iter = 02050, loss = 1.7999
2024-10-29 13:21:14: [2024-10-29 13:21:14] iter = 02060, loss = 1.0239
2024-10-29 13:21:15: [2024-10-29 13:21:15] iter = 02070, loss = 1.2790
2024-10-29 13:21:15: [2024-10-29 13:21:15] iter = 02080, loss = 0.9541
2024-10-29 13:21:16: [2024-10-29 13:21:16] iter = 02090, loss = 4.3815
2024-10-29 13:21:16: [2024-10-29 13:21:16] iter = 02100, loss = 1.0973
2024-10-29 13:21:17: [2024-10-29 13:21:17] iter = 02110, loss = 1.2853
2024-10-29 13:21:17: [2024-10-29 13:21:17] iter = 02120, loss = 1.1731
2024-10-29 13:21:17: [2024-10-29 13:21:17] iter = 02130, loss = 1.0332
2024-10-29 13:21:18: [2024-10-29 13:21:18] iter = 02140, loss = 1.1163
2024-10-29 13:21:18: [2024-10-29 13:21:18] iter = 02150, loss = 1.4152
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 02160, loss = 1.7791
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 02170, loss = 1.2921
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 02180, loss = 1.0060
2024-10-29 13:21:20: [2024-10-29 13:21:20] iter = 02190, loss = 1.2387
2024-10-29 13:21:20: [2024-10-29 13:21:20] iter = 02200, loss = 2.6480
2024-10-29 13:21:20: [2024-10-29 13:21:20] iter = 02210, loss = 1.6211
2024-10-29 13:21:21: [2024-10-29 13:21:21] iter = 02220, loss = 1.0897
2024-10-29 13:21:21: [2024-10-29 13:21:21] iter = 02230, loss = 1.4515
2024-10-29 13:21:21: [2024-10-29 13:21:21] iter = 02240, loss = 1.6594
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 02250, loss = 6.6142
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 02260, loss = 1.2964
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 02270, loss = 1.1532
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 02280, loss = 0.8707
2024-10-29 13:21:23: [2024-10-29 13:21:23] iter = 02290, loss = 1.4032
2024-10-29 13:21:23: [2024-10-29 13:21:23] iter = 02300, loss = 2.0463
2024-10-29 13:21:23: [2024-10-29 13:21:23] iter = 02310, loss = 1.8489
2024-10-29 13:21:24: [2024-10-29 13:21:24] iter = 02320, loss = 1.2896
2024-10-29 13:21:24: [2024-10-29 13:21:24] iter = 02330, loss = 0.9688
2024-10-29 13:21:25: [2024-10-29 13:21:25] iter = 02340, loss = 2.2311
2024-10-29 13:21:25: [2024-10-29 13:21:25] iter = 02350, loss = 2.0335
2024-10-29 13:21:26: [2024-10-29 13:21:26] iter = 02360, loss = 1.9067
2024-10-29 13:21:26: [2024-10-29 13:21:26] iter = 02370, loss = 1.4756
2024-10-29 13:21:27: [2024-10-29 13:21:27] iter = 02380, loss = 0.8420
2024-10-29 13:21:27: [2024-10-29 13:21:27] iter = 02390, loss = 1.3494
2024-10-29 13:21:27: [2024-10-29 13:21:27] iter = 02400, loss = 1.2594
2024-10-29 13:21:28: [2024-10-29 13:21:28] iter = 02410, loss = 1.0822
2024-10-29 13:21:28: [2024-10-29 13:21:28] iter = 02420, loss = 1.3117
2024-10-29 13:21:29: [2024-10-29 13:21:29] iter = 02430, loss = 0.8028
2024-10-29 13:21:29: [2024-10-29 13:21:29] iter = 02440, loss = 0.9154
2024-10-29 13:21:30: [2024-10-29 13:21:30] iter = 02450, loss = 1.8850
2024-10-29 13:21:30: [2024-10-29 13:21:30] iter = 02460, loss = 1.1881
2024-10-29 13:21:30: [2024-10-29 13:21:30] iter = 02470, loss = 1.5746
2024-10-29 13:21:31: [2024-10-29 13:21:31] iter = 02480, loss = 1.3258
2024-10-29 13:21:31: [2024-10-29 13:21:31] iter = 02490, loss = 3.6605
2024-10-29 13:21:31: [2024-10-29 13:21:31] iter = 02500, loss = 2.2469
2024-10-29 13:21:32: [2024-10-29 13:21:32] iter = 02510, loss = 4.5730
2024-10-29 13:21:32: [2024-10-29 13:21:32] iter = 02520, loss = 1.9374
2024-10-29 13:21:32: [2024-10-29 13:21:32] iter = 02530, loss = 1.4649
2024-10-29 13:21:33: [2024-10-29 13:21:33] iter = 02540, loss = 1.6344
2024-10-29 13:21:33: [2024-10-29 13:21:33] iter = 02550, loss = 2.6625
2024-10-29 13:21:34: [2024-10-29 13:21:34] iter = 02560, loss = 0.9718
2024-10-29 13:21:34: [2024-10-29 13:21:34] iter = 02570, loss = 1.3459
2024-10-29 13:21:34: [2024-10-29 13:21:34] iter = 02580, loss = 1.2246
2024-10-29 13:21:35: [2024-10-29 13:21:35] iter = 02590, loss = 0.9349
2024-10-29 13:21:36: [2024-10-29 13:21:36] iter = 02600, loss = 1.5151
2024-10-29 13:21:36: [2024-10-29 13:21:36] iter = 02610, loss = 1.5828
2024-10-29 13:21:36: [2024-10-29 13:21:36] iter = 02620, loss = 1.9959
2024-10-29 13:21:37: [2024-10-29 13:21:37] iter = 02630, loss = 1.5725
2024-10-29 13:21:37: [2024-10-29 13:21:37] iter = 02640, loss = 1.2478
2024-10-29 13:21:38: [2024-10-29 13:21:38] iter = 02650, loss = 7.3999
2024-10-29 13:21:38: [2024-10-29 13:21:38] iter = 02660, loss = 1.4778
2024-10-29 13:21:39: [2024-10-29 13:21:39] iter = 02670, loss = 2.0029
2024-10-29 13:21:39: [2024-10-29 13:21:39] iter = 02680, loss = 1.2929
2024-10-29 13:21:39: [2024-10-29 13:21:39] iter = 02690, loss = 1.7535
2024-10-29 13:21:40: [2024-10-29 13:21:40] iter = 02700, loss = 1.1487
2024-10-29 13:21:40: [2024-10-29 13:21:40] iter = 02710, loss = 3.9966
2024-10-29 13:21:40: [2024-10-29 13:21:40] iter = 02720, loss = 1.2375
2024-10-29 13:21:41: [2024-10-29 13:21:41] iter = 02730, loss = 2.0160
2024-10-29 13:21:41: [2024-10-29 13:21:41] iter = 02740, loss = 1.5273
2024-10-29 13:21:41: [2024-10-29 13:21:41] iter = 02750, loss = 1.1630
2024-10-29 13:21:42: [2024-10-29 13:21:42] iter = 02760, loss = 2.4969
2024-10-29 13:21:42: [2024-10-29 13:21:42] iter = 02770, loss = 1.0735
2024-10-29 13:21:42: [2024-10-29 13:21:42] iter = 02780, loss = 2.1384
2024-10-29 13:21:43: [2024-10-29 13:21:43] iter = 02790, loss = 3.5955
2024-10-29 13:21:43: [2024-10-29 13:21:43] iter = 02800, loss = 0.8117
2024-10-29 13:21:43: [2024-10-29 13:21:43] iter = 02810, loss = 1.1690
2024-10-29 13:21:44: [2024-10-29 13:21:44] iter = 02820, loss = 1.3004
2024-10-29 13:21:44: [2024-10-29 13:21:44] iter = 02830, loss = 2.6960
2024-10-29 13:21:44: [2024-10-29 13:21:44] iter = 02840, loss = 1.0983
2024-10-29 13:21:45: [2024-10-29 13:21:45] iter = 02850, loss = 1.5421
2024-10-29 13:21:45: [2024-10-29 13:21:45] iter = 02860, loss = 1.5854
2024-10-29 13:21:45: [2024-10-29 13:21:45] iter = 02870, loss = 3.3552
2024-10-29 13:21:46: [2024-10-29 13:21:46] iter = 02880, loss = 0.9860
2024-10-29 13:21:46: [2024-10-29 13:21:46] iter = 02890, loss = 0.9904
2024-10-29 13:21:46: [2024-10-29 13:21:46] iter = 02900, loss = 1.4833
2024-10-29 13:21:47: [2024-10-29 13:21:47] iter = 02910, loss = 1.7207
2024-10-29 13:21:47: [2024-10-29 13:21:47] iter = 02920, loss = 1.4363
2024-10-29 13:21:47: [2024-10-29 13:21:47] iter = 02930, loss = 3.5994
2024-10-29 13:21:48: [2024-10-29 13:21:48] iter = 02940, loss = 1.2134
2024-10-29 13:21:48: [2024-10-29 13:21:48] iter = 02950, loss = 0.9654
2024-10-29 13:21:48: [2024-10-29 13:21:48] iter = 02960, loss = 1.0328
2024-10-29 13:21:49: [2024-10-29 13:21:49] iter = 02970, loss = 1.8555
2024-10-29 13:21:49: [2024-10-29 13:21:49] iter = 02980, loss = 2.8678
2024-10-29 13:21:49: [2024-10-29 13:21:49] iter = 02990, loss = 0.9873
2024-10-29 13:21:50: [2024-10-29 13:21:50] iter = 03000, loss = 2.8705
2024-10-29 13:21:50: [2024-10-29 13:21:50] iter = 03010, loss = 1.9852
2024-10-29 13:21:50: [2024-10-29 13:21:50] iter = 03020, loss = 2.1387
2024-10-29 13:21:51: [2024-10-29 13:21:51] iter = 03030, loss = 1.9003
2024-10-29 13:21:51: [2024-10-29 13:21:51] iter = 03040, loss = 2.1819
2024-10-29 13:21:51: [2024-10-29 13:21:51] iter = 03050, loss = 1.6112
2024-10-29 13:21:52: [2024-10-29 13:21:52] iter = 03060, loss = 1.8929
2024-10-29 13:21:52: [2024-10-29 13:21:52] iter = 03070, loss = 0.8693
2024-10-29 13:21:52: [2024-10-29 13:21:52] iter = 03080, loss = 1.1902
2024-10-29 13:21:53: [2024-10-29 13:21:53] iter = 03090, loss = 4.3137
2024-10-29 13:21:53: [2024-10-29 13:21:53] iter = 03100, loss = 1.3402
2024-10-29 13:21:53: [2024-10-29 13:21:53] iter = 03110, loss = 1.4483
2024-10-29 13:21:54: [2024-10-29 13:21:54] iter = 03120, loss = 1.3305
2024-10-29 13:21:54: [2024-10-29 13:21:54] iter = 03130, loss = 1.5203
2024-10-29 13:21:55: [2024-10-29 13:21:55] iter = 03140, loss = 1.4515
2024-10-29 13:21:55: [2024-10-29 13:21:55] iter = 03150, loss = 2.1224
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 03160, loss = 1.1956
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 03170, loss = 0.8786
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 03180, loss = 2.6732
2024-10-29 13:21:57: [2024-10-29 13:21:57] iter = 03190, loss = 1.1513
2024-10-29 13:21:57: [2024-10-29 13:21:57] iter = 03200, loss = 6.5179
2024-10-29 13:21:57: [2024-10-29 13:21:57] iter = 03210, loss = 2.7526
2024-10-29 13:21:58: [2024-10-29 13:21:58] iter = 03220, loss = 1.1665
2024-10-29 13:21:58: [2024-10-29 13:21:58] iter = 03230, loss = 0.8314
2024-10-29 13:21:58: [2024-10-29 13:21:58] iter = 03240, loss = 3.8699
2024-10-29 13:21:59: [2024-10-29 13:21:59] iter = 03250, loss = 1.0431
2024-10-29 13:21:59: [2024-10-29 13:21:59] iter = 03260, loss = 1.8935
2024-10-29 13:21:59: [2024-10-29 13:21:59] iter = 03270, loss = 1.6222
2024-10-29 13:22:00: [2024-10-29 13:22:00] iter = 03280, loss = 1.0330
2024-10-29 13:22:00: [2024-10-29 13:22:00] iter = 03290, loss = 0.8356
2024-10-29 13:22:00: [2024-10-29 13:22:00] iter = 03300, loss = 1.2636
2024-10-29 13:22:01: [2024-10-29 13:22:01] iter = 03310, loss = 2.0974
2024-10-29 13:22:01: [2024-10-29 13:22:01] iter = 03320, loss = 1.2890
2024-10-29 13:22:02: [2024-10-29 13:22:02] iter = 03330, loss = 0.6882
2024-10-29 13:22:02: [2024-10-29 13:22:02] iter = 03340, loss = 1.1324
2024-10-29 13:22:03: [2024-10-29 13:22:03] iter = 03350, loss = 1.0320
2024-10-29 13:22:03: [2024-10-29 13:22:03] iter = 03360, loss = 0.8735
2024-10-29 13:22:03: [2024-10-29 13:22:03] iter = 03370, loss = 0.9296
2024-10-29 13:22:04: [2024-10-29 13:22:04] iter = 03380, loss = 1.3290
2024-10-29 13:22:04: [2024-10-29 13:22:04] iter = 03390, loss = 1.1114
2024-10-29 13:22:04: [2024-10-29 13:22:04] iter = 03400, loss = 2.2646
2024-10-29 13:22:05: [2024-10-29 13:22:05] iter = 03410, loss = 1.1782
2024-10-29 13:22:05: [2024-10-29 13:22:05] iter = 03420, loss = 1.0039
2024-10-29 13:22:05: [2024-10-29 13:22:05] iter = 03430, loss = 1.1855
2024-10-29 13:22:06: [2024-10-29 13:22:06] iter = 03440, loss = 1.0055
2024-10-29 13:22:06: [2024-10-29 13:22:06] iter = 03450, loss = 1.1544
2024-10-29 13:22:07: [2024-10-29 13:22:07] iter = 03460, loss = 1.9318
2024-10-29 13:22:07: [2024-10-29 13:22:07] iter = 03470, loss = 4.6293
2024-10-29 13:22:07: [2024-10-29 13:22:07] iter = 03480, loss = 1.3222
2024-10-29 13:22:08: [2024-10-29 13:22:08] iter = 03490, loss = 4.7968
2024-10-29 13:22:08: [2024-10-29 13:22:08] iter = 03500, loss = 1.4112
2024-10-29 13:22:08: [2024-10-29 13:22:08] iter = 03510, loss = 4.0292
2024-10-29 13:22:09: [2024-10-29 13:22:09] iter = 03520, loss = 12.9143
2024-10-29 13:22:09: [2024-10-29 13:22:09] iter = 03530, loss = 3.0684
2024-10-29 13:22:09: [2024-10-29 13:22:09] iter = 03540, loss = 1.5336
2024-10-29 13:22:10: [2024-10-29 13:22:10] iter = 03550, loss = 1.3805
2024-10-29 13:22:10: [2024-10-29 13:22:10] iter = 03560, loss = 1.3665
2024-10-29 13:22:10: [2024-10-29 13:22:10] iter = 03570, loss = 1.4643
2024-10-29 13:22:11: [2024-10-29 13:22:11] iter = 03580, loss = 0.8659
2024-10-29 13:22:11: [2024-10-29 13:22:11] iter = 03590, loss = 0.8817
2024-10-29 13:22:12: [2024-10-29 13:22:12] iter = 03600, loss = 1.7997
2024-10-29 13:22:12: [2024-10-29 13:22:12] iter = 03610, loss = 1.4892
2024-10-29 13:22:12: [2024-10-29 13:22:12] iter = 03620, loss = 0.9484
2024-10-29 13:22:13: [2024-10-29 13:22:13] iter = 03630, loss = 1.1617
2024-10-29 13:22:13: [2024-10-29 13:22:13] iter = 03640, loss = 1.0333
2024-10-29 13:22:14: [2024-10-29 13:22:14] iter = 03650, loss = 1.4464
2024-10-29 13:22:14: [2024-10-29 13:22:14] iter = 03660, loss = 0.9851
2024-10-29 13:22:14: [2024-10-29 13:22:14] iter = 03670, loss = 1.0488
2024-10-29 13:22:15: [2024-10-29 13:22:15] iter = 03680, loss = 1.6426
2024-10-29 13:22:15: [2024-10-29 13:22:15] iter = 03690, loss = 1.5406
2024-10-29 13:22:15: [2024-10-29 13:22:15] iter = 03700, loss = 1.0451
2024-10-29 13:22:16: [2024-10-29 13:22:16] iter = 03710, loss = 1.5297
2024-10-29 13:22:16: [2024-10-29 13:22:16] iter = 03720, loss = 1.7706
2024-10-29 13:22:16: [2024-10-29 13:22:16] iter = 03730, loss = 2.3174
2024-10-29 13:22:17: [2024-10-29 13:22:17] iter = 03740, loss = 1.6388
2024-10-29 13:22:17: [2024-10-29 13:22:17] iter = 03750, loss = 2.1168
2024-10-29 13:22:17: [2024-10-29 13:22:17] iter = 03760, loss = 0.7659
2024-10-29 13:22:18: [2024-10-29 13:22:18] iter = 03770, loss = 2.4784
2024-10-29 13:22:18: [2024-10-29 13:22:18] iter = 03780, loss = 2.4236
2024-10-29 13:22:18: [2024-10-29 13:22:18] iter = 03790, loss = 3.5254
2024-10-29 13:22:19: [2024-10-29 13:22:19] iter = 03800, loss = 6.7156
2024-10-29 13:22:19: [2024-10-29 13:22:19] iter = 03810, loss = 1.8344
2024-10-29 13:22:19: [2024-10-29 13:22:19] iter = 03820, loss = 1.4544
2024-10-29 13:22:20: [2024-10-29 13:22:20] iter = 03830, loss = 3.8561
2024-10-29 13:22:20: [2024-10-29 13:22:20] iter = 03840, loss = 2.8885
2024-10-29 13:22:20: [2024-10-29 13:22:20] iter = 03850, loss = 1.3986
2024-10-29 13:22:21: [2024-10-29 13:22:21] iter = 03860, loss = 1.2244
2024-10-29 13:22:21: [2024-10-29 13:22:21] iter = 03870, loss = 0.9902
2024-10-29 13:22:21: [2024-10-29 13:22:21] iter = 03880, loss = 1.1296
2024-10-29 13:22:22: [2024-10-29 13:22:22] iter = 03890, loss = 1.9625
2024-10-29 13:22:22: [2024-10-29 13:22:22] iter = 03900, loss = 1.8186
2024-10-29 13:22:22: [2024-10-29 13:22:22] iter = 03910, loss = 0.9902
2024-10-29 13:22:23: [2024-10-29 13:22:23] iter = 03920, loss = 3.5000
2024-10-29 13:22:23: [2024-10-29 13:22:23] iter = 03930, loss = 3.4363
2024-10-29 13:22:23: [2024-10-29 13:22:23] iter = 03940, loss = 2.2743
2024-10-29 13:22:24: [2024-10-29 13:22:24] iter = 03950, loss = 1.1348
2024-10-29 13:22:24: [2024-10-29 13:22:24] iter = 03960, loss = 0.8235
2024-10-29 13:22:24: [2024-10-29 13:22:24] iter = 03970, loss = 0.8174
2024-10-29 13:22:25: [2024-10-29 13:22:25] iter = 03980, loss = 1.7165
2024-10-29 13:22:25: [2024-10-29 13:22:25] iter = 03990, loss = 1.1262
2024-10-29 13:22:25: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 13:22:25: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:22:25: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 45727}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:22:53: Evaluate 5 random ConvNet, ACCmean = 0.6785 ACCstd = 0.0097
-------------------------
2024-10-29 13:22:53: Evaluate 5 random ConvNet, SENmean = 0.6003 SENstd = 0.0042
-------------------------
2024-10-29 13:22:53: Evaluate 5 random ConvNet, SPEmean = 0.6003 SPEstd = 0.0042
-------------------------
2024-10-29 13:22:53: Evaluate 5 random ConvNet, F!mean = 0.5233 F!std = 0.0030
-------------------------
2024-10-29 13:22:53: Evaluate 5 random ConvNet, mean = 0.6785 std = 0.0097
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:22:53: [2024-10-29 13:22:53] iter = 04000, loss = 1.1870
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:22:53: [2024-10-29 13:22:53] iter = 04010, loss = 3.8837
2024-10-29 13:22:53: [2024-10-29 13:22:53] iter = 04020, loss = 1.2182
2024-10-29 13:22:54: [2024-10-29 13:22:54] iter = 04030, loss = 2.2572
2024-10-29 13:22:55: [2024-10-29 13:22:55] iter = 04040, loss = 2.0502
2024-10-29 13:22:55: [2024-10-29 13:22:55] iter = 04050, loss = 1.1913
2024-10-29 13:22:55: [2024-10-29 13:22:55] iter = 04060, loss = 0.8000
2024-10-29 13:22:56: [2024-10-29 13:22:56] iter = 04070, loss = 0.8799
2024-10-29 13:22:56: [2024-10-29 13:22:56] iter = 04080, loss = 0.9717
2024-10-29 13:22:57: [2024-10-29 13:22:57] iter = 04090, loss = 1.0064
2024-10-29 13:22:57: [2024-10-29 13:22:57] iter = 04100, loss = 2.1425
2024-10-29 13:22:58: [2024-10-29 13:22:58] iter = 04110, loss = 1.4291
2024-10-29 13:22:58: [2024-10-29 13:22:58] iter = 04120, loss = 0.9072
2024-10-29 13:22:59: [2024-10-29 13:22:59] iter = 04130, loss = 0.7626
2024-10-29 13:22:59: [2024-10-29 13:22:59] iter = 04140, loss = 1.4873
2024-10-29 13:23:00: [2024-10-29 13:23:00] iter = 04150, loss = 1.5582
2024-10-29 13:23:00: [2024-10-29 13:23:00] iter = 04160, loss = 7.3103
2024-10-29 13:23:01: [2024-10-29 13:23:01] iter = 04170, loss = 1.2436
2024-10-29 13:23:02: [2024-10-29 13:23:02] iter = 04180, loss = 1.4326
2024-10-29 13:23:03: [2024-10-29 13:23:03] iter = 04190, loss = 0.8910
2024-10-29 13:23:03: [2024-10-29 13:23:03] iter = 04200, loss = 11.9173
2024-10-29 13:23:03: [2024-10-29 13:23:03] iter = 04210, loss = 1.1960
2024-10-29 13:23:04: [2024-10-29 13:23:04] iter = 04220, loss = 0.9909
2024-10-29 13:23:04: [2024-10-29 13:23:04] iter = 04230, loss = 2.2463
2024-10-29 13:23:04: [2024-10-29 13:23:04] iter = 04240, loss = 1.1858
2024-10-29 13:23:05: [2024-10-29 13:23:05] iter = 04250, loss = 4.2395
2024-10-29 13:23:05: [2024-10-29 13:23:05] iter = 04260, loss = 1.7978
2024-10-29 13:23:06: [2024-10-29 13:23:06] iter = 04270, loss = 4.6393
2024-10-29 13:23:06: [2024-10-29 13:23:06] iter = 04280, loss = 1.5065
2024-10-29 13:23:06: [2024-10-29 13:23:06] iter = 04290, loss = 1.1317
2024-10-29 13:23:07: [2024-10-29 13:23:07] iter = 04300, loss = 1.5573
2024-10-29 13:23:07: [2024-10-29 13:23:07] iter = 04310, loss = 1.4209
2024-10-29 13:23:07: [2024-10-29 13:23:07] iter = 04320, loss = 1.2542
2024-10-29 13:23:08: [2024-10-29 13:23:08] iter = 04330, loss = 6.1746
2024-10-29 13:23:08: [2024-10-29 13:23:08] iter = 04340, loss = 1.4124
2024-10-29 13:23:08: [2024-10-29 13:23:08] iter = 04350, loss = 0.7590
2024-10-29 13:23:09: [2024-10-29 13:23:09] iter = 04360, loss = 1.2630
2024-10-29 13:23:09: [2024-10-29 13:23:09] iter = 04370, loss = 1.6999
2024-10-29 13:23:09: [2024-10-29 13:23:09] iter = 04380, loss = 1.2103
2024-10-29 13:23:10: [2024-10-29 13:23:10] iter = 04390, loss = 1.4435
2024-10-29 13:23:10: [2024-10-29 13:23:10] iter = 04400, loss = 2.8170
2024-10-29 13:23:10: [2024-10-29 13:23:10] iter = 04410, loss = 4.2276
2024-10-29 13:23:11: [2024-10-29 13:23:11] iter = 04420, loss = 1.1381
2024-10-29 13:23:11: [2024-10-29 13:23:11] iter = 04430, loss = 2.4120
2024-10-29 13:23:11: [2024-10-29 13:23:11] iter = 04440, loss = 1.4319
2024-10-29 13:23:12: [2024-10-29 13:23:12] iter = 04450, loss = 1.0087
2024-10-29 13:23:12: [2024-10-29 13:23:12] iter = 04460, loss = 1.1507
2024-10-29 13:23:13: [2024-10-29 13:23:13] iter = 04470, loss = 1.9350
2024-10-29 13:23:13: [2024-10-29 13:23:13] iter = 04480, loss = 1.5112
2024-10-29 13:23:13: [2024-10-29 13:23:13] iter = 04490, loss = 2.1687
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 04500, loss = 1.9990
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 04510, loss = 1.2767
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 04520, loss = 1.6491
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 04530, loss = 1.6177
2024-10-29 13:23:15: [2024-10-29 13:23:15] iter = 04540, loss = 2.1955
2024-10-29 13:23:15: [2024-10-29 13:23:15] iter = 04550, loss = 4.3454
2024-10-29 13:23:15: [2024-10-29 13:23:15] iter = 04560, loss = 1.1877
2024-10-29 13:23:16: [2024-10-29 13:23:16] iter = 04570, loss = 3.4128
2024-10-29 13:23:16: [2024-10-29 13:23:16] iter = 04580, loss = 1.4327
2024-10-29 13:23:16: [2024-10-29 13:23:16] iter = 04590, loss = 2.0580
2024-10-29 13:23:17: [2024-10-29 13:23:17] iter = 04600, loss = 1.0827
2024-10-29 13:23:17: [2024-10-29 13:23:17] iter = 04610, loss = 0.8116
2024-10-29 13:23:17: [2024-10-29 13:23:17] iter = 04620, loss = 1.5970
2024-10-29 13:23:18: [2024-10-29 13:23:18] iter = 04630, loss = 2.0471
2024-10-29 13:23:18: [2024-10-29 13:23:18] iter = 04640, loss = 3.0255
2024-10-29 13:23:18: [2024-10-29 13:23:18] iter = 04650, loss = 1.6893
2024-10-29 13:23:19: [2024-10-29 13:23:19] iter = 04660, loss = 0.9846
2024-10-29 13:23:19: [2024-10-29 13:23:19] iter = 04670, loss = 1.9540
2024-10-29 13:23:19: [2024-10-29 13:23:19] iter = 04680, loss = 0.9704
2024-10-29 13:23:20: [2024-10-29 13:23:20] iter = 04690, loss = 1.0365
2024-10-29 13:23:20: [2024-10-29 13:23:20] iter = 04700, loss = 1.5831
2024-10-29 13:23:21: [2024-10-29 13:23:21] iter = 04710, loss = 1.0052
2024-10-29 13:23:21: [2024-10-29 13:23:21] iter = 04720, loss = 2.9829
2024-10-29 13:23:21: [2024-10-29 13:23:21] iter = 04730, loss = 0.8052
2024-10-29 13:23:22: [2024-10-29 13:23:22] iter = 04740, loss = 1.3225
2024-10-29 13:23:22: [2024-10-29 13:23:22] iter = 04750, loss = 13.1976
2024-10-29 13:23:22: [2024-10-29 13:23:22] iter = 04760, loss = 1.2081
2024-10-29 13:23:23: [2024-10-29 13:23:23] iter = 04770, loss = 1.9637
2024-10-29 13:23:23: [2024-10-29 13:23:23] iter = 04780, loss = 1.9317
2024-10-29 13:23:23: [2024-10-29 13:23:23] iter = 04790, loss = 0.8618
2024-10-29 13:23:24: [2024-10-29 13:23:24] iter = 04800, loss = 1.7511
2024-10-29 13:23:24: [2024-10-29 13:23:24] iter = 04810, loss = 0.9910
2024-10-29 13:23:25: [2024-10-29 13:23:25] iter = 04820, loss = 1.9159
2024-10-29 13:23:25: [2024-10-29 13:23:25] iter = 04830, loss = 2.1488
2024-10-29 13:23:25: [2024-10-29 13:23:25] iter = 04840, loss = 1.2524
2024-10-29 13:23:26: [2024-10-29 13:23:26] iter = 04850, loss = 1.2829
2024-10-29 13:23:26: [2024-10-29 13:23:26] iter = 04860, loss = 1.2816
2024-10-29 13:23:26: [2024-10-29 13:23:26] iter = 04870, loss = 4.5734
2024-10-29 13:23:27: [2024-10-29 13:23:27] iter = 04880, loss = 0.8691
2024-10-29 13:23:27: [2024-10-29 13:23:27] iter = 04890, loss = 1.9329
2024-10-29 13:23:28: [2024-10-29 13:23:28] iter = 04900, loss = 1.3922
2024-10-29 13:23:28: [2024-10-29 13:23:28] iter = 04910, loss = 1.1804
2024-10-29 13:23:28: [2024-10-29 13:23:28] iter = 04920, loss = 0.7396
2024-10-29 13:23:29: [2024-10-29 13:23:29] iter = 04930, loss = 2.3569
2024-10-29 13:23:29: [2024-10-29 13:23:29] iter = 04940, loss = 1.5866
2024-10-29 13:23:29: [2024-10-29 13:23:29] iter = 04950, loss = 1.7167
2024-10-29 13:23:30: [2024-10-29 13:23:30] iter = 04960, loss = 1.1247
2024-10-29 13:23:30: [2024-10-29 13:23:30] iter = 04970, loss = 1.9663
2024-10-29 13:23:30: [2024-10-29 13:23:30] iter = 04980, loss = 1.3851
2024-10-29 13:23:31: [2024-10-29 13:23:31] iter = 04990, loss = 1.4366
2024-10-29 13:23:31: [2024-10-29 13:23:31] iter = 05000, loss = 1.0462
2024-10-29 13:23:31: [2024-10-29 13:23:31] iter = 05010, loss = 1.3229
2024-10-29 13:23:32: [2024-10-29 13:23:32] iter = 05020, loss = 1.5826
2024-10-29 13:23:32: [2024-10-29 13:23:32] iter = 05030, loss = 0.8610
2024-10-29 13:23:32: [2024-10-29 13:23:32] iter = 05040, loss = 0.8999
2024-10-29 13:23:33: [2024-10-29 13:23:33] iter = 05050, loss = 1.0902
2024-10-29 13:23:33: [2024-10-29 13:23:33] iter = 05060, loss = 5.5194
2024-10-29 13:23:33: [2024-10-29 13:23:33] iter = 05070, loss = 1.3035
2024-10-29 13:23:34: [2024-10-29 13:23:34] iter = 05080, loss = 2.1642
2024-10-29 13:23:34: [2024-10-29 13:23:34] iter = 05090, loss = 2.2945
2024-10-29 13:23:34: [2024-10-29 13:23:34] iter = 05100, loss = 1.5803
2024-10-29 13:23:35: [2024-10-29 13:23:35] iter = 05110, loss = 1.3822
2024-10-29 13:23:36: [2024-10-29 13:23:36] iter = 05120, loss = 1.9153
2024-10-29 13:23:36: [2024-10-29 13:23:36] iter = 05130, loss = 5.0277
2024-10-29 13:23:37: [2024-10-29 13:23:37] iter = 05140, loss = 1.0177
2024-10-29 13:23:37: [2024-10-29 13:23:37] iter = 05150, loss = 1.4956
2024-10-29 13:23:38: [2024-10-29 13:23:38] iter = 05160, loss = 2.4110
2024-10-29 13:23:38: [2024-10-29 13:23:38] iter = 05170, loss = 2.1385
2024-10-29 13:23:39: [2024-10-29 13:23:39] iter = 05180, loss = 2.6413
2024-10-29 13:23:39: [2024-10-29 13:23:39] iter = 05190, loss = 1.2031
2024-10-29 13:23:40: [2024-10-29 13:23:40] iter = 05200, loss = 0.7924
2024-10-29 13:23:40: [2024-10-29 13:23:40] iter = 05210, loss = 4.8236
2024-10-29 13:23:40: [2024-10-29 13:23:40] iter = 05220, loss = 2.0839
2024-10-29 13:23:41: [2024-10-29 13:23:41] iter = 05230, loss = 3.5462
2024-10-29 13:23:41: [2024-10-29 13:23:41] iter = 05240, loss = 1.1996
2024-10-29 13:23:42: [2024-10-29 13:23:42] iter = 05250, loss = 1.3825
2024-10-29 13:23:42: [2024-10-29 13:23:42] iter = 05260, loss = 1.1438
2024-10-29 13:23:42: [2024-10-29 13:23:42] iter = 05270, loss = 1.3444
2024-10-29 13:23:43: [2024-10-29 13:23:43] iter = 05280, loss = 2.2584
2024-10-29 13:23:43: [2024-10-29 13:23:43] iter = 05290, loss = 4.9302
2024-10-29 13:23:43: [2024-10-29 13:23:43] iter = 05300, loss = 1.3158
2024-10-29 13:23:44: [2024-10-29 13:23:44] iter = 05310, loss = 1.8286
2024-10-29 13:23:44: [2024-10-29 13:23:44] iter = 05320, loss = 4.4419
2024-10-29 13:23:44: [2024-10-29 13:23:44] iter = 05330, loss = 1.0840
2024-10-29 13:23:45: [2024-10-29 13:23:45] iter = 05340, loss = 1.1289
2024-10-29 13:23:45: [2024-10-29 13:23:45] iter = 05350, loss = 1.2903
2024-10-29 13:23:45: [2024-10-29 13:23:45] iter = 05360, loss = 0.7502
2024-10-29 13:23:46: [2024-10-29 13:23:46] iter = 05370, loss = 2.2042
2024-10-29 13:23:46: [2024-10-29 13:23:46] iter = 05380, loss = 1.5124
2024-10-29 13:23:46: [2024-10-29 13:23:46] iter = 05390, loss = 1.5615
2024-10-29 13:23:47: [2024-10-29 13:23:47] iter = 05400, loss = 1.1099
2024-10-29 13:23:47: [2024-10-29 13:23:47] iter = 05410, loss = 0.9115
2024-10-29 13:23:48: [2024-10-29 13:23:48] iter = 05420, loss = 1.7994
2024-10-29 13:23:48: [2024-10-29 13:23:48] iter = 05430, loss = 1.0094
2024-10-29 13:23:48: [2024-10-29 13:23:48] iter = 05440, loss = 1.1943
2024-10-29 13:23:49: [2024-10-29 13:23:49] iter = 05450, loss = 1.4995
2024-10-29 13:23:49: [2024-10-29 13:23:49] iter = 05460, loss = 1.1247
2024-10-29 13:23:49: [2024-10-29 13:23:49] iter = 05470, loss = 3.9345
2024-10-29 13:23:50: [2024-10-29 13:23:50] iter = 05480, loss = 1.9648
2024-10-29 13:23:50: [2024-10-29 13:23:50] iter = 05490, loss = 1.0134
2024-10-29 13:23:50: [2024-10-29 13:23:50] iter = 05500, loss = 1.4589
2024-10-29 13:23:51: [2024-10-29 13:23:51] iter = 05510, loss = 1.9473
2024-10-29 13:23:51: [2024-10-29 13:23:51] iter = 05520, loss = 1.7765
2024-10-29 13:23:51: [2024-10-29 13:23:51] iter = 05530, loss = 0.7206
2024-10-29 13:23:52: [2024-10-29 13:23:52] iter = 05540, loss = 1.5928
2024-10-29 13:23:52: [2024-10-29 13:23:52] iter = 05550, loss = 1.4640
2024-10-29 13:23:52: [2024-10-29 13:23:52] iter = 05560, loss = 0.7571
2024-10-29 13:23:53: [2024-10-29 13:23:53] iter = 05570, loss = 0.9622
2024-10-29 13:23:53: [2024-10-29 13:23:53] iter = 05580, loss = 5.3752
2024-10-29 13:23:53: [2024-10-29 13:23:53] iter = 05590, loss = 1.7251
2024-10-29 13:23:54: [2024-10-29 13:23:54] iter = 05600, loss = 1.2909
2024-10-29 13:23:54: [2024-10-29 13:23:54] iter = 05610, loss = 0.9298
2024-10-29 13:23:54: [2024-10-29 13:23:54] iter = 05620, loss = 1.6463
2024-10-29 13:23:55: [2024-10-29 13:23:55] iter = 05630, loss = 1.0537
2024-10-29 13:23:55: [2024-10-29 13:23:55] iter = 05640, loss = 1.3320
2024-10-29 13:23:55: [2024-10-29 13:23:55] iter = 05650, loss = 1.0961
2024-10-29 13:23:56: [2024-10-29 13:23:56] iter = 05660, loss = 1.0248
2024-10-29 13:23:56: [2024-10-29 13:23:56] iter = 05670, loss = 1.3939
2024-10-29 13:23:56: [2024-10-29 13:23:56] iter = 05680, loss = 1.3244
2024-10-29 13:23:57: [2024-10-29 13:23:57] iter = 05690, loss = 1.6541
2024-10-29 13:23:57: [2024-10-29 13:23:57] iter = 05700, loss = 1.6770
2024-10-29 13:23:57: [2024-10-29 13:23:57] iter = 05710, loss = 0.9134
2024-10-29 13:23:58: [2024-10-29 13:23:58] iter = 05720, loss = 1.1045
2024-10-29 13:23:58: [2024-10-29 13:23:58] iter = 05730, loss = 1.1629
2024-10-29 13:23:58: [2024-10-29 13:23:58] iter = 05740, loss = 1.6528
2024-10-29 13:23:59: [2024-10-29 13:23:59] iter = 05750, loss = 1.0684
2024-10-29 13:23:59: [2024-10-29 13:23:59] iter = 05760, loss = 4.7798
2024-10-29 13:23:59: [2024-10-29 13:23:59] iter = 05770, loss = 8.3679
2024-10-29 13:24:00: [2024-10-29 13:24:00] iter = 05780, loss = 1.5975
2024-10-29 13:24:00: [2024-10-29 13:24:00] iter = 05790, loss = 3.4173
2024-10-29 13:24:00: [2024-10-29 13:24:00] iter = 05800, loss = 1.1539
2024-10-29 13:24:01: [2024-10-29 13:24:01] iter = 05810, loss = 4.3660
2024-10-29 13:24:01: [2024-10-29 13:24:01] iter = 05820, loss = 2.0707
2024-10-29 13:24:01: [2024-10-29 13:24:01] iter = 05830, loss = 1.4806
2024-10-29 13:24:02: [2024-10-29 13:24:02] iter = 05840, loss = 1.7437
2024-10-29 13:24:02: [2024-10-29 13:24:02] iter = 05850, loss = 1.0050
2024-10-29 13:24:02: [2024-10-29 13:24:02] iter = 05860, loss = 2.1297
2024-10-29 13:24:03: [2024-10-29 13:24:03] iter = 05870, loss = 2.0599
2024-10-29 13:24:03: [2024-10-29 13:24:03] iter = 05880, loss = 1.5335
2024-10-29 13:24:03: [2024-10-29 13:24:03] iter = 05890, loss = 2.5123
2024-10-29 13:24:04: [2024-10-29 13:24:04] iter = 05900, loss = 1.9616
2024-10-29 13:24:04: [2024-10-29 13:24:04] iter = 05910, loss = 1.3007
2024-10-29 13:24:04: [2024-10-29 13:24:04] iter = 05920, loss = 1.0273
2024-10-29 13:24:05: [2024-10-29 13:24:05] iter = 05930, loss = 1.3264
2024-10-29 13:24:05: [2024-10-29 13:24:05] iter = 05940, loss = 2.1612
2024-10-29 13:24:05: [2024-10-29 13:24:05] iter = 05950, loss = 1.0947
2024-10-29 13:24:06: [2024-10-29 13:24:06] iter = 05960, loss = 1.2803
2024-10-29 13:24:06: [2024-10-29 13:24:06] iter = 05970, loss = 1.9090
2024-10-29 13:24:06: [2024-10-29 13:24:06] iter = 05980, loss = 2.0098
2024-10-29 13:24:07: [2024-10-29 13:24:07] iter = 05990, loss = 1.8447
2024-10-29 13:24:07: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 13:24:07: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:24:07: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 47340}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:24:38: Evaluate 5 random ConvNet, ACCmean = 0.5134 ACCstd = 0.0107
-------------------------
2024-10-29 13:24:38: Evaluate 5 random ConvNet, SENmean = 0.6007 SENstd = 0.0056
-------------------------
2024-10-29 13:24:38: Evaluate 5 random ConvNet, SPEmean = 0.6007 SPEstd = 0.0056
-------------------------
2024-10-29 13:24:38: Evaluate 5 random ConvNet, F!mean = 0.4410 F!std = 0.0061
-------------------------
2024-10-29 13:24:38: Evaluate 5 random ConvNet, mean = 0.5134 std = 0.0107
-------------------------
2024-10-29 13:24:38: [2024-10-29 13:24:38] iter = 06000, loss = 1.2972
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:24:39: [2024-10-29 13:24:39] iter = 06010, loss = 1.5800
2024-10-29 13:24:39: [2024-10-29 13:24:39] iter = 06020, loss = 1.0214
2024-10-29 13:24:39: [2024-10-29 13:24:39] iter = 06030, loss = 0.9071
2024-10-29 13:24:40: [2024-10-29 13:24:40] iter = 06040, loss = 2.0590
2024-10-29 13:24:40: [2024-10-29 13:24:40] iter = 06050, loss = 1.6406
2024-10-29 13:24:40: [2024-10-29 13:24:40] iter = 06060, loss = 2.2166
2024-10-29 13:24:41: [2024-10-29 13:24:41] iter = 06070, loss = 1.7992
2024-10-29 13:24:41: [2024-10-29 13:24:41] iter = 06080, loss = 1.4165
2024-10-29 13:24:41: [2024-10-29 13:24:41] iter = 06090, loss = 1.1309
2024-10-29 13:24:42: [2024-10-29 13:24:42] iter = 06100, loss = 1.8054
2024-10-29 13:24:42: [2024-10-29 13:24:42] iter = 06110, loss = 1.0542
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 06120, loss = 0.9142
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 06130, loss = 1.6076
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 06140, loss = 1.0093
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 06150, loss = 0.9548
2024-10-29 13:24:44: [2024-10-29 13:24:44] iter = 06160, loss = 0.9842
2024-10-29 13:24:44: [2024-10-29 13:24:44] iter = 06170, loss = 0.9908
2024-10-29 13:24:45: [2024-10-29 13:24:45] iter = 06180, loss = 0.9833
2024-10-29 13:24:45: [2024-10-29 13:24:45] iter = 06190, loss = 1.0446
2024-10-29 13:24:45: [2024-10-29 13:24:45] iter = 06200, loss = 1.6830
2024-10-29 13:24:46: [2024-10-29 13:24:46] iter = 06210, loss = 1.0720
2024-10-29 13:24:46: [2024-10-29 13:24:46] iter = 06220, loss = 3.1225
2024-10-29 13:24:46: [2024-10-29 13:24:46] iter = 06230, loss = 2.9517
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 06240, loss = 1.9000
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 06250, loss = 1.3897
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 06260, loss = 1.1378
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 06270, loss = 1.3903
2024-10-29 13:24:48: [2024-10-29 13:24:48] iter = 06280, loss = 2.0270
2024-10-29 13:24:48: [2024-10-29 13:24:48] iter = 06290, loss = 1.2759
2024-10-29 13:24:49: [2024-10-29 13:24:49] iter = 06300, loss = 1.2461
2024-10-29 13:24:49: [2024-10-29 13:24:49] iter = 06310, loss = 1.1207
2024-10-29 13:24:49: [2024-10-29 13:24:49] iter = 06320, loss = 0.8553
2024-10-29 13:24:50: [2024-10-29 13:24:50] iter = 06330, loss = 2.2508
2024-10-29 13:24:50: [2024-10-29 13:24:50] iter = 06340, loss = 1.5821
2024-10-29 13:24:50: [2024-10-29 13:24:50] iter = 06350, loss = 1.1615
2024-10-29 13:24:51: [2024-10-29 13:24:51] iter = 06360, loss = 1.5089
2024-10-29 13:24:51: [2024-10-29 13:24:51] iter = 06370, loss = 1.5346
2024-10-29 13:24:51: [2024-10-29 13:24:51] iter = 06380, loss = 1.2533
2024-10-29 13:24:52: [2024-10-29 13:24:52] iter = 06390, loss = 2.2025
2024-10-29 13:24:52: [2024-10-29 13:24:52] iter = 06400, loss = 5.8613
2024-10-29 13:24:52: [2024-10-29 13:24:52] iter = 06410, loss = 1.1155
2024-10-29 13:24:53: [2024-10-29 13:24:53] iter = 06420, loss = 1.4300
2024-10-29 13:24:53: [2024-10-29 13:24:53] iter = 06430, loss = 1.1073
2024-10-29 13:24:53: [2024-10-29 13:24:53] iter = 06440, loss = 1.4089
2024-10-29 13:24:54: [2024-10-29 13:24:54] iter = 06450, loss = 1.9126
2024-10-29 13:24:54: [2024-10-29 13:24:54] iter = 06460, loss = 1.2934
2024-10-29 13:24:54: [2024-10-29 13:24:54] iter = 06470, loss = 4.7489
2024-10-29 13:24:55: [2024-10-29 13:24:55] iter = 06480, loss = 1.2692
2024-10-29 13:24:55: [2024-10-29 13:24:55] iter = 06490, loss = 2.5388
2024-10-29 13:24:55: [2024-10-29 13:24:55] iter = 06500, loss = 3.1150
2024-10-29 13:24:56: [2024-10-29 13:24:56] iter = 06510, loss = 1.5747
2024-10-29 13:24:56: [2024-10-29 13:24:56] iter = 06520, loss = 9.7616
2024-10-29 13:24:56: [2024-10-29 13:24:56] iter = 06530, loss = 1.3827
2024-10-29 13:24:57: [2024-10-29 13:24:57] iter = 06540, loss = 1.7688
2024-10-29 13:24:57: [2024-10-29 13:24:57] iter = 06550, loss = 0.9388
2024-10-29 13:24:57: [2024-10-29 13:24:57] iter = 06560, loss = 1.6117
2024-10-29 13:24:58: [2024-10-29 13:24:58] iter = 06570, loss = 1.4133
2024-10-29 13:24:58: [2024-10-29 13:24:58] iter = 06580, loss = 1.7844
2024-10-29 13:24:58: [2024-10-29 13:24:58] iter = 06590, loss = 1.3724
2024-10-29 13:24:59: [2024-10-29 13:24:59] iter = 06600, loss = 1.4070
2024-10-29 13:24:59: [2024-10-29 13:24:59] iter = 06610, loss = 1.0037
2024-10-29 13:24:59: [2024-10-29 13:24:59] iter = 06620, loss = 1.2808
2024-10-29 13:25:00: [2024-10-29 13:25:00] iter = 06630, loss = 1.9519
2024-10-29 13:25:00: [2024-10-29 13:25:00] iter = 06640, loss = 2.2859
2024-10-29 13:25:00: [2024-10-29 13:25:00] iter = 06650, loss = 1.2793
2024-10-29 13:25:01: [2024-10-29 13:25:01] iter = 06660, loss = 3.5577
2024-10-29 13:25:01: [2024-10-29 13:25:01] iter = 06670, loss = 1.6495
2024-10-29 13:25:01: [2024-10-29 13:25:01] iter = 06680, loss = 2.5833
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 06690, loss = 4.3478
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 06700, loss = 1.3427
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 06710, loss = 0.8778
2024-10-29 13:25:03: [2024-10-29 13:25:03] iter = 06720, loss = 1.8772
2024-10-29 13:25:03: [2024-10-29 13:25:03] iter = 06730, loss = 3.2210
2024-10-29 13:25:03: [2024-10-29 13:25:03] iter = 06740, loss = 0.8397
2024-10-29 13:25:04: [2024-10-29 13:25:04] iter = 06750, loss = 1.7039
2024-10-29 13:25:04: [2024-10-29 13:25:04] iter = 06760, loss = 1.2089
2024-10-29 13:25:04: [2024-10-29 13:25:04] iter = 06770, loss = 1.8269
2024-10-29 13:25:05: [2024-10-29 13:25:05] iter = 06780, loss = 0.9182
2024-10-29 13:25:05: [2024-10-29 13:25:05] iter = 06790, loss = 1.0165
2024-10-29 13:25:05: [2024-10-29 13:25:05] iter = 06800, loss = 0.7866
2024-10-29 13:25:06: [2024-10-29 13:25:06] iter = 06810, loss = 0.6822
2024-10-29 13:25:06: [2024-10-29 13:25:06] iter = 06820, loss = 2.5384
2024-10-29 13:25:06: [2024-10-29 13:25:06] iter = 06830, loss = 1.6936
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 06840, loss = 1.6395
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 06850, loss = 0.9568
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 06860, loss = 1.8706
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 06870, loss = 0.9721
2024-10-29 13:25:08: [2024-10-29 13:25:08] iter = 06880, loss = 2.3773
2024-10-29 13:25:08: [2024-10-29 13:25:08] iter = 06890, loss = 1.3544
2024-10-29 13:25:09: [2024-10-29 13:25:09] iter = 06900, loss = 1.9422
2024-10-29 13:25:09: [2024-10-29 13:25:09] iter = 06910, loss = 8.0498
2024-10-29 13:25:09: [2024-10-29 13:25:09] iter = 06920, loss = 2.6100
2024-10-29 13:25:10: [2024-10-29 13:25:10] iter = 06930, loss = 1.1087
2024-10-29 13:25:10: [2024-10-29 13:25:10] iter = 06940, loss = 0.9988
2024-10-29 13:25:11: [2024-10-29 13:25:11] iter = 06950, loss = 1.0910
2024-10-29 13:25:11: [2024-10-29 13:25:11] iter = 06960, loss = 0.9572
2024-10-29 13:25:12: [2024-10-29 13:25:12] iter = 06970, loss = 12.8813
2024-10-29 13:25:12: [2024-10-29 13:25:12] iter = 06980, loss = 1.1630
2024-10-29 13:25:13: [2024-10-29 13:25:13] iter = 06990, loss = 1.9105
2024-10-29 13:25:13: [2024-10-29 13:25:13] iter = 07000, loss = 1.0604
2024-10-29 13:25:13: [2024-10-29 13:25:13] iter = 07010, loss = 1.1278
2024-10-29 13:25:14: [2024-10-29 13:25:14] iter = 07020, loss = 1.3754
2024-10-29 13:25:14: [2024-10-29 13:25:14] iter = 07030, loss = 0.9211
2024-10-29 13:25:15: [2024-10-29 13:25:15] iter = 07040, loss = 1.7112
2024-10-29 13:25:15: [2024-10-29 13:25:15] iter = 07050, loss = 0.9944
2024-10-29 13:25:15: [2024-10-29 13:25:15] iter = 07060, loss = 1.5513
2024-10-29 13:25:16: [2024-10-29 13:25:16] iter = 07070, loss = 0.9739
2024-10-29 13:25:16: [2024-10-29 13:25:16] iter = 07080, loss = 1.0550
2024-10-29 13:25:17: [2024-10-29 13:25:17] iter = 07090, loss = 1.3255
2024-10-29 13:25:17: [2024-10-29 13:25:17] iter = 07100, loss = 1.8376
2024-10-29 13:25:17: [2024-10-29 13:25:17] iter = 07110, loss = 1.0461
2024-10-29 13:25:18: [2024-10-29 13:25:18] iter = 07120, loss = 1.3024
2024-10-29 13:25:18: [2024-10-29 13:25:18] iter = 07130, loss = 4.9034
2024-10-29 13:25:18: [2024-10-29 13:25:18] iter = 07140, loss = 1.3866
2024-10-29 13:25:19: [2024-10-29 13:25:19] iter = 07150, loss = 1.4429
2024-10-29 13:25:19: [2024-10-29 13:25:19] iter = 07160, loss = 1.1000
2024-10-29 13:25:19: [2024-10-29 13:25:19] iter = 07170, loss = 0.8225
2024-10-29 13:25:20: [2024-10-29 13:25:20] iter = 07180, loss = 0.9641
2024-10-29 13:25:20: [2024-10-29 13:25:20] iter = 07190, loss = 1.2168
2024-10-29 13:25:20: [2024-10-29 13:25:20] iter = 07200, loss = 5.8183
2024-10-29 13:25:21: [2024-10-29 13:25:21] iter = 07210, loss = 1.3024
2024-10-29 13:25:21: [2024-10-29 13:25:21] iter = 07220, loss = 2.1221
2024-10-29 13:25:21: [2024-10-29 13:25:21] iter = 07230, loss = 0.9233
2024-10-29 13:25:22: [2024-10-29 13:25:22] iter = 07240, loss = 1.3786
2024-10-29 13:25:22: [2024-10-29 13:25:22] iter = 07250, loss = 1.0938
2024-10-29 13:25:22: [2024-10-29 13:25:22] iter = 07260, loss = 2.4663
2024-10-29 13:25:23: [2024-10-29 13:25:23] iter = 07270, loss = 1.4193
2024-10-29 13:25:23: [2024-10-29 13:25:23] iter = 07280, loss = 1.0733
2024-10-29 13:25:23: [2024-10-29 13:25:23] iter = 07290, loss = 1.0479
2024-10-29 13:25:24: [2024-10-29 13:25:24] iter = 07300, loss = 1.1508
2024-10-29 13:25:24: [2024-10-29 13:25:24] iter = 07310, loss = 1.1338
2024-10-29 13:25:24: [2024-10-29 13:25:24] iter = 07320, loss = 3.0504
2024-10-29 13:25:25: [2024-10-29 13:25:25] iter = 07330, loss = 1.2815
2024-10-29 13:25:25: [2024-10-29 13:25:25] iter = 07340, loss = 3.1012
2024-10-29 13:25:26: [2024-10-29 13:25:26] iter = 07350, loss = 1.5033
2024-10-29 13:25:26: [2024-10-29 13:25:26] iter = 07360, loss = 2.4422
2024-10-29 13:25:26: [2024-10-29 13:25:26] iter = 07370, loss = 0.8182
2024-10-29 13:25:27: [2024-10-29 13:25:27] iter = 07380, loss = 1.2175
2024-10-29 13:25:27: [2024-10-29 13:25:27] iter = 07390, loss = 1.1549
2024-10-29 13:25:27: [2024-10-29 13:25:27] iter = 07400, loss = 1.2525
2024-10-29 13:25:28: [2024-10-29 13:25:28] iter = 07410, loss = 2.5126
2024-10-29 13:25:28: [2024-10-29 13:25:28] iter = 07420, loss = 2.0776
2024-10-29 13:25:28: [2024-10-29 13:25:28] iter = 07430, loss = 1.1625
2024-10-29 13:25:29: [2024-10-29 13:25:29] iter = 07440, loss = 2.3222
2024-10-29 13:25:29: [2024-10-29 13:25:29] iter = 07450, loss = 1.4790
2024-10-29 13:25:30: [2024-10-29 13:25:30] iter = 07460, loss = 1.0645
2024-10-29 13:25:30: [2024-10-29 13:25:30] iter = 07470, loss = 1.6045
2024-10-29 13:25:31: [2024-10-29 13:25:31] iter = 07480, loss = 1.9656
2024-10-29 13:25:32: [2024-10-29 13:25:32] iter = 07490, loss = 1.0556
2024-10-29 13:25:32: [2024-10-29 13:25:32] iter = 07500, loss = 1.2309
2024-10-29 13:25:33: [2024-10-29 13:25:33] iter = 07510, loss = 1.0100
2024-10-29 13:25:33: [2024-10-29 13:25:33] iter = 07520, loss = 1.6408
2024-10-29 13:25:34: [2024-10-29 13:25:34] iter = 07530, loss = 1.2738
2024-10-29 13:25:34: [2024-10-29 13:25:34] iter = 07540, loss = 2.4960
2024-10-29 13:25:35: [2024-10-29 13:25:35] iter = 07550, loss = 2.5175
2024-10-29 13:25:35: [2024-10-29 13:25:35] iter = 07560, loss = 1.8927
2024-10-29 13:25:36: [2024-10-29 13:25:36] iter = 07570, loss = 1.1027
2024-10-29 13:25:36: [2024-10-29 13:25:36] iter = 07580, loss = 1.8316
2024-10-29 13:25:37: [2024-10-29 13:25:37] iter = 07590, loss = 1.8486
2024-10-29 13:25:37: [2024-10-29 13:25:37] iter = 07600, loss = 0.8563
2024-10-29 13:25:37: [2024-10-29 13:25:37] iter = 07610, loss = 1.5696
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 07620, loss = 1.0635
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 07630, loss = 1.2695
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 07640, loss = 1.4319
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 07650, loss = 1.6380
2024-10-29 13:25:39: [2024-10-29 13:25:39] iter = 07660, loss = 1.0713
2024-10-29 13:25:39: [2024-10-29 13:25:39] iter = 07670, loss = 1.3241
2024-10-29 13:25:39: [2024-10-29 13:25:39] iter = 07680, loss = 4.9302
2024-10-29 13:25:40: [2024-10-29 13:25:40] iter = 07690, loss = 1.0826
2024-10-29 13:25:40: [2024-10-29 13:25:40] iter = 07700, loss = 1.1432
2024-10-29 13:25:40: [2024-10-29 13:25:40] iter = 07710, loss = 4.1761
2024-10-29 13:25:41: [2024-10-29 13:25:41] iter = 07720, loss = 2.5329
2024-10-29 13:25:41: [2024-10-29 13:25:41] iter = 07730, loss = 1.2767
2024-10-29 13:25:41: [2024-10-29 13:25:41] iter = 07740, loss = 3.7311
2024-10-29 13:25:42: [2024-10-29 13:25:42] iter = 07750, loss = 1.0449
2024-10-29 13:25:42: [2024-10-29 13:25:42] iter = 07760, loss = 3.5627
2024-10-29 13:25:42: [2024-10-29 13:25:42] iter = 07770, loss = 1.8500
2024-10-29 13:25:43: [2024-10-29 13:25:43] iter = 07780, loss = 1.2507
2024-10-29 13:25:43: [2024-10-29 13:25:43] iter = 07790, loss = 1.9512
2024-10-29 13:25:43: [2024-10-29 13:25:43] iter = 07800, loss = 1.0802
2024-10-29 13:25:44: [2024-10-29 13:25:44] iter = 07810, loss = 1.1089
2024-10-29 13:25:44: [2024-10-29 13:25:44] iter = 07820, loss = 0.6844
2024-10-29 13:25:45: [2024-10-29 13:25:45] iter = 07830, loss = 0.9486
2024-10-29 13:25:45: [2024-10-29 13:25:45] iter = 07840, loss = 1.1666
2024-10-29 13:25:45: [2024-10-29 13:25:45] iter = 07850, loss = 1.0189
2024-10-29 13:25:46: [2024-10-29 13:25:46] iter = 07860, loss = 4.0458
2024-10-29 13:25:46: [2024-10-29 13:25:46] iter = 07870, loss = 2.5079
2024-10-29 13:25:46: [2024-10-29 13:25:46] iter = 07880, loss = 4.3358
2024-10-29 13:25:47: [2024-10-29 13:25:47] iter = 07890, loss = 1.6051
2024-10-29 13:25:47: [2024-10-29 13:25:47] iter = 07900, loss = 3.2796
2024-10-29 13:25:47: [2024-10-29 13:25:47] iter = 07910, loss = 1.3865
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 07920, loss = 13.7158
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 07930, loss = 2.4782
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 07940, loss = 3.1455
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 07950, loss = 1.1905
2024-10-29 13:25:49: [2024-10-29 13:25:49] iter = 07960, loss = 1.0321
2024-10-29 13:25:49: [2024-10-29 13:25:49] iter = 07970, loss = 1.8189
2024-10-29 13:25:50: [2024-10-29 13:25:50] iter = 07980, loss = 2.1997
2024-10-29 13:25:50: [2024-10-29 13:25:50] iter = 07990, loss = 1.1563
2024-10-29 13:25:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 13:25:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:25:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50662}

[2024-10-29 13:10:33] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.025295 train acc = 1.0000, test acc = 0.5808, test_sen =0.6333, test_spe =0.6333, test_f1 =0.4858
[2024-10-29 13:11:51] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.005318 train acc = 1.0000, test acc = 0.6419, test_sen =0.6337, test_spe =0.6337, test_f1 =0.5177
[2024-10-29 13:11:57] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.005151 train acc = 1.0000, test acc = 0.6626, test_sen =0.6260, test_spe =0.6260, test_f1 =0.5254
[2024-10-29 13:12:02] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.224072 train acc = 0.9000, test acc = 0.6671, test_sen =0.6236, test_spe =0.6236, test_f1 =0.5268
[2024-10-29 13:12:07] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.049911 train acc = 1.0000, test acc = 0.6998, test_sen =0.6243, test_spe =0.6243, test_f1 =0.5429
[2024-10-29 13:12:13] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001018 train acc = 1.0000, test acc = 0.6891, test_sen =0.6154, test_spe =0.6154, test_f1 =0.5343
[2024-10-29 13:13:30] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.088348 train acc = 0.9500, test acc = 0.6153, test_sen =0.6095, test_spe =0.6095, test_f1 =0.4967
[2024-10-29 13:13:36] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.014399 train acc = 1.0000, test acc = 0.5379, test_sen =0.6081, test_spe =0.6081, test_f1 =0.4563
[2024-10-29 13:13:41] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.055238 train acc = 0.9500, test acc = 0.5933, test_sen =0.6091, test_spe =0.6091, test_f1 =0.4856
[2024-10-29 13:13:46] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.008016 train acc = 1.0000, test acc = 0.6207, test_sen =0.6047, test_spe =0.6047, test_f1 =0.4978
[2024-10-29 13:13:51] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.004508 train acc = 1.0000, test acc = 0.5895, test_sen =0.6081, test_spe =0.6081, test_f1 =0.4834
[2024-10-29 13:15:10] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.085511 train acc = 0.9500, test acc = 0.5435, test_sen =0.6198, test_spe =0.6198, test_f1 =0.4622
[2024-10-29 13:15:17] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.005667 train acc = 1.0000, test acc = 0.5514, test_sen =0.6156, test_spe =0.6156, test_f1 =0.4655
[2024-10-29 13:15:22] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.089611 train acc = 0.9500, test acc = 0.5446, test_sen =0.6180, test_spe =0.6180, test_f1 =0.4624
[2024-10-29 13:15:28] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.145400 train acc = 0.9500, test acc = 0.5452, test_sen =0.6165, test_spe =0.6165, test_f1 =0.4623
[2024-10-29 13:15:33] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.044380 train acc = 1.0000, test acc = 0.5040, test_sen =0.6225, test_spe =0.6225, test_f1 =0.4404
[2024-10-29 13:16:54] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.003819 train acc = 1.0000, test acc = 0.5846, test_sen =0.6095, test_spe =0.6095, test_f1 =0.4813
[2024-10-29 13:16:59] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.001960 train acc = 1.0000, test acc = 0.5739, test_sen =0.6053, test_spe =0.6053, test_f1 =0.4746
[2024-10-29 13:17:05] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.020335 train acc = 1.0000, test acc = 0.5504, test_sen =0.6049, test_spe =0.6049, test_f1 =0.4622
[2024-10-29 13:17:10] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.054242 train acc = 1.0000, test acc = 0.6039, test_sen =0.6127, test_spe =0.6127, test_f1 =0.4921
[2024-10-29 13:17:15] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.052771 train acc = 1.0000, test acc = 0.5856, test_sen =0.6166, test_spe =0.6166, test_f1 =0.4838
[2024-10-29 13:18:35] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.005929 train acc = 1.0000, test acc = 0.5684, test_sen =0.6239, test_spe =0.6239, test_f1 =0.4768
[2024-10-29 13:18:41] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.138313 train acc = 0.9500, test acc = 0.5861, test_sen =0.6218, test_spe =0.6218, test_f1 =0.4855
[2024-10-29 13:18:46] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.016923 train acc = 1.0000, test acc = 0.5530, test_sen =0.6200, test_spe =0.6200, test_f1 =0.4674
[2024-10-29 13:18:52] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.015404 train acc = 1.0000, test acc = 0.6186, test_sen =0.6219, test_spe =0.6219, test_f1 =0.5022
[2024-10-29 13:18:59] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.012913 train acc = 1.0000, test acc = 0.5742, test_sen =0.6141, test_spe =0.6141, test_f1 =0.4772
[2024-10-29 13:19:09] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.000048 train acc = 1.0000, test acc = 0.6963, test_sen =0.5989, test_spe =0.5989, test_f1 =0.5308
[2024-10-29 13:19:15] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.004443 train acc = 1.0000, test acc = 0.6823, test_sen =0.6121, test_spe =0.6121, test_f1 =0.5298
[2024-10-29 13:19:20] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.000067 train acc = 1.0000, test acc = 0.6784, test_sen =0.6116, test_spe =0.6116, test_f1 =0.5277
[2024-10-29 13:19:25] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.005495 train acc = 1.0000, test acc = 0.6636, test_sen =0.6169, test_spe =0.6169, test_f1 =0.5227
[2024-10-29 13:19:31] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.004676 train acc = 1.0000, test acc = 0.6594, test_sen =0.6208, test_spe =0.6208, test_f1 =0.5220
[2024-10-29 13:20:51] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.007342 train acc = 1.0000, test acc = 0.6040, test_sen =0.6064, test_spe =0.6064, test_f1 =0.4902
[2024-10-29 13:20:56] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.007225 train acc = 1.0000, test acc = 0.5966, test_sen =0.6079, test_spe =0.6079, test_f1 =0.4869
[2024-10-29 13:21:01] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.009625 train acc = 1.0000, test acc = 0.6159, test_sen =0.6142, test_spe =0.6142, test_f1 =0.4985
[2024-10-29 13:21:06] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.088014 train acc = 0.9500, test acc = 0.6388, test_sen =0.6088, test_spe =0.6088, test_f1 =0.5079
[2024-10-29 13:21:12] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002339 train acc = 1.0000, test acc = 0.6025, test_sen =0.6141, test_spe =0.6141, test_f1 =0.4917
[2024-10-29 13:22:30] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.153500 train acc = 0.9500, test acc = 0.6966, test_sen =0.5935, test_spe =0.5935, test_f1 =0.5286
[2024-10-29 13:22:36] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004844 train acc = 1.0000, test acc = 0.6748, test_sen =0.6056, test_spe =0.6056, test_f1 =0.5237
[2024-10-29 13:22:41] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002721 train acc = 1.0000, test acc = 0.6678, test_sen =0.6037, test_spe =0.6037, test_f1 =0.5197
[2024-10-29 13:22:47] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.016686 train acc = 1.0000, test acc = 0.6753, test_sen =0.6002, test_spe =0.6002, test_f1 =0.5219
[2024-10-29 13:22:53] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.010640 train acc = 1.0000, test acc = 0.6782, test_sen =0.5988, test_spe =0.5988, test_f1 =0.5226
[2024-10-29 13:24:13] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.079554 train acc = 1.0000, test acc = 0.5191, test_sen =0.5995, test_spe =0.5995, test_f1 =0.4440
[2024-10-29 13:24:20] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.006368 train acc = 1.0000, test acc = 0.5266, test_sen =0.6083, test_spe =0.6083, test_f1 =0.4501
[2024-10-29 13:24:27] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.038446 train acc = 1.0000, test acc = 0.5181, test_sen =0.5913, test_spe =0.5913, test_f1 =0.4415
[2024-10-29 13:24:33] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001634 train acc = 1.0000, test acc = 0.4961, test_sen =0.6042, test_spe =0.6042, test_f1 =0.4319
[2024-10-29 13:24:38] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.004892 train acc = 1.0000, test acc = 0.5072, test_sen =0.6003, test_spe =0.6003, test_f1 =0.4374
[2024-10-29 13:25:56] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.112716 train acc = 0.9500, test acc = 0.4137, test_sen =0.5680, test_spe =0.5680, test_f1 =0.3750/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:19: Evaluate 5 random ConvNet, ACCmean = 0.3933 ACCstd = 0.0173
-------------------------
2024-10-29 13:26:19: Evaluate 5 random ConvNet, SENmean = 0.5662 SENstd = 0.0031
-------------------------
2024-10-29 13:26:19: Evaluate 5 random ConvNet, SPEmean = 0.5662 SPEstd = 0.0031
-------------------------
2024-10-29 13:26:19: Evaluate 5 random ConvNet, F!mean = 0.3612 F!std = 0.0121
-------------------------
2024-10-29 13:26:19: Evaluate 5 random ConvNet, mean = 0.3933 std = 0.0173
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:19: [2024-10-29 13:26:19] iter = 08000, loss = 1.5427
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:19: [2024-10-29 13:26:19] iter = 08010, loss = 1.5606
2024-10-29 13:26:20: [2024-10-29 13:26:20] iter = 08020, loss = 3.1406
2024-10-29 13:26:20: [2024-10-29 13:26:20] iter = 08030, loss = 4.3331
2024-10-29 13:26:20: [2024-10-29 13:26:20] iter = 08040, loss = 0.8005
2024-10-29 13:26:21: [2024-10-29 13:26:21] iter = 08050, loss = 0.9733
2024-10-29 13:26:21: [2024-10-29 13:26:21] iter = 08060, loss = 1.1928
2024-10-29 13:26:21: [2024-10-29 13:26:21] iter = 08070, loss = 1.4394
2024-10-29 13:26:21: [2024-10-29 13:26:21] iter = 08080, loss = 2.1943
2024-10-29 13:26:22: [2024-10-29 13:26:22] iter = 08090, loss = 2.1721
2024-10-29 13:26:22: [2024-10-29 13:26:22] iter = 08100, loss = 1.1857
2024-10-29 13:26:22: [2024-10-29 13:26:22] iter = 08110, loss = 1.6192
2024-10-29 13:26:23: [2024-10-29 13:26:23] iter = 08120, loss = 1.4332
2024-10-29 13:26:23: [2024-10-29 13:26:23] iter = 08130, loss = 5.5529
2024-10-29 13:26:23: [2024-10-29 13:26:23] iter = 08140, loss = 1.1643
2024-10-29 13:26:24: [2024-10-29 13:26:24] iter = 08150, loss = 1.3402
2024-10-29 13:26:24: [2024-10-29 13:26:24] iter = 08160, loss = 1.6909
2024-10-29 13:26:24: [2024-10-29 13:26:24] iter = 08170, loss = 1.1490
2024-10-29 13:26:25: [2024-10-29 13:26:25] iter = 08180, loss = 1.1657
2024-10-29 13:26:25: [2024-10-29 13:26:25] iter = 08190, loss = 1.0381
2024-10-29 13:26:26: [2024-10-29 13:26:26] iter = 08200, loss = 0.9050
2024-10-29 13:26:26: [2024-10-29 13:26:26] iter = 08210, loss = 1.7934
2024-10-29 13:26:26: [2024-10-29 13:26:26] iter = 08220, loss = 3.5293
2024-10-29 13:26:27: [2024-10-29 13:26:27] iter = 08230, loss = 1.8946
2024-10-29 13:26:27: [2024-10-29 13:26:27] iter = 08240, loss = 0.8467
2024-10-29 13:26:27: [2024-10-29 13:26:27] iter = 08250, loss = 1.2622
2024-10-29 13:26:28: [2024-10-29 13:26:28] iter = 08260, loss = 0.9150
2024-10-29 13:26:28: [2024-10-29 13:26:28] iter = 08270, loss = 1.3145
2024-10-29 13:26:28: [2024-10-29 13:26:28] iter = 08280, loss = 4.2085
2024-10-29 13:26:29: [2024-10-29 13:26:29] iter = 08290, loss = 0.9859
2024-10-29 13:26:29: [2024-10-29 13:26:29] iter = 08300, loss = 1.6502
2024-10-29 13:26:29: [2024-10-29 13:26:29] iter = 08310, loss = 2.1917
2024-10-29 13:26:30: [2024-10-29 13:26:30] iter = 08320, loss = 1.5760
2024-10-29 13:26:30: [2024-10-29 13:26:30] iter = 08330, loss = 0.7748
2024-10-29 13:26:30: [2024-10-29 13:26:30] iter = 08340, loss = 1.2223
2024-10-29 13:26:31: [2024-10-29 13:26:31] iter = 08350, loss = 5.6333
2024-10-29 13:26:31: [2024-10-29 13:26:31] iter = 08360, loss = 1.1866
2024-10-29 13:26:31: [2024-10-29 13:26:31] iter = 08370, loss = 1.6552
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 08380, loss = 1.9685
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 08390, loss = 1.4671
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 08400, loss = 1.0594
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 08410, loss = 0.9233
2024-10-29 13:26:33: [2024-10-29 13:26:33] iter = 08420, loss = 1.0002
2024-10-29 13:26:33: [2024-10-29 13:26:33] iter = 08430, loss = 2.1368
2024-10-29 13:26:33: [2024-10-29 13:26:33] iter = 08440, loss = 1.2332
2024-10-29 13:26:34: [2024-10-29 13:26:34] iter = 08450, loss = 1.5874
2024-10-29 13:26:34: [2024-10-29 13:26:34] iter = 08460, loss = 1.2546
2024-10-29 13:26:34: [2024-10-29 13:26:34] iter = 08470, loss = 1.2340
2024-10-29 13:26:35: [2024-10-29 13:26:35] iter = 08480, loss = 1.0459
2024-10-29 13:26:35: [2024-10-29 13:26:35] iter = 08490, loss = 1.1287
2024-10-29 13:26:35: [2024-10-29 13:26:35] iter = 08500, loss = 1.2125
2024-10-29 13:26:36: [2024-10-29 13:26:36] iter = 08510, loss = 1.7551
2024-10-29 13:26:36: [2024-10-29 13:26:36] iter = 08520, loss = 1.8171
2024-10-29 13:26:36: [2024-10-29 13:26:36] iter = 08530, loss = 1.7941
2024-10-29 13:26:37: [2024-10-29 13:26:37] iter = 08540, loss = 10.6666
2024-10-29 13:26:37: [2024-10-29 13:26:37] iter = 08550, loss = 1.7593
2024-10-29 13:26:37: [2024-10-29 13:26:37] iter = 08560, loss = 1.5153
2024-10-29 13:26:38: [2024-10-29 13:26:38] iter = 08570, loss = 1.2406
2024-10-29 13:26:38: [2024-10-29 13:26:38] iter = 08580, loss = 1.0936
2024-10-29 13:26:38: [2024-10-29 13:26:38] iter = 08590, loss = 1.7839
2024-10-29 13:26:39: [2024-10-29 13:26:39] iter = 08600, loss = 1.4681
2024-10-29 13:26:39: [2024-10-29 13:26:39] iter = 08610, loss = 2.3142
2024-10-29 13:26:39: [2024-10-29 13:26:39] iter = 08620, loss = 6.3173
2024-10-29 13:26:40: [2024-10-29 13:26:40] iter = 08630, loss = 1.2833
2024-10-29 13:26:40: [2024-10-29 13:26:40] iter = 08640, loss = 1.0937
2024-10-29 13:26:40: [2024-10-29 13:26:40] iter = 08650, loss = 0.7916
2024-10-29 13:26:41: [2024-10-29 13:26:41] iter = 08660, loss = 2.3226
2024-10-29 13:26:41: [2024-10-29 13:26:41] iter = 08670, loss = 1.9496
2024-10-29 13:26:42: [2024-10-29 13:26:42] iter = 08680, loss = 1.4194
2024-10-29 13:26:42: [2024-10-29 13:26:42] iter = 08690, loss = 2.4129
2024-10-29 13:26:43: [2024-10-29 13:26:43] iter = 08700, loss = 1.4181
2024-10-29 13:26:43: [2024-10-29 13:26:43] iter = 08710, loss = 1.1229
2024-10-29 13:26:44: [2024-10-29 13:26:44] iter = 08720, loss = 1.4628
2024-10-29 13:26:44: [2024-10-29 13:26:44] iter = 08730, loss = 0.9931
2024-10-29 13:26:45: [2024-10-29 13:26:45] iter = 08740, loss = 1.4045
2024-10-29 13:26:45: [2024-10-29 13:26:45] iter = 08750, loss = 0.8126
2024-10-29 13:26:46: [2024-10-29 13:26:46] iter = 08760, loss = 1.5881
2024-10-29 13:26:46: [2024-10-29 13:26:46] iter = 08770, loss = 1.6134
2024-10-29 13:26:47: [2024-10-29 13:26:47] iter = 08780, loss = 0.9320
2024-10-29 13:26:47: [2024-10-29 13:26:47] iter = 08790, loss = 1.1731
2024-10-29 13:26:48: [2024-10-29 13:26:48] iter = 08800, loss = 0.7510
2024-10-29 13:26:48: [2024-10-29 13:26:48] iter = 08810, loss = 1.2475
2024-10-29 13:26:48: [2024-10-29 13:26:48] iter = 08820, loss = 2.4383
2024-10-29 13:26:49: [2024-10-29 13:26:49] iter = 08830, loss = 1.5736
2024-10-29 13:26:49: [2024-10-29 13:26:49] iter = 08840, loss = 2.5097
2024-10-29 13:26:50: [2024-10-29 13:26:50] iter = 08850, loss = 2.0537
2024-10-29 13:26:50: [2024-10-29 13:26:50] iter = 08860, loss = 3.6295
2024-10-29 13:26:51: [2024-10-29 13:26:51] iter = 08870, loss = 1.8343
2024-10-29 13:26:51: [2024-10-29 13:26:51] iter = 08880, loss = 1.1872
2024-10-29 13:26:51: [2024-10-29 13:26:51] iter = 08890, loss = 1.1554
2024-10-29 13:26:52: [2024-10-29 13:26:52] iter = 08900, loss = 2.5617
2024-10-29 13:26:52: [2024-10-29 13:26:52] iter = 08910, loss = 1.5121
2024-10-29 13:26:52: [2024-10-29 13:26:52] iter = 08920, loss = 1.2128
2024-10-29 13:26:53: [2024-10-29 13:26:53] iter = 08930, loss = 1.2245
2024-10-29 13:26:54: [2024-10-29 13:26:54] iter = 08940, loss = 1.5789
2024-10-29 13:26:54: [2024-10-29 13:26:54] iter = 08950, loss = 1.3058
2024-10-29 13:26:54: [2024-10-29 13:26:54] iter = 08960, loss = 1.5558
2024-10-29 13:26:55: [2024-10-29 13:26:55] iter = 08970, loss = 0.9442
2024-10-29 13:26:55: [2024-10-29 13:26:55] iter = 08980, loss = 1.0844
2024-10-29 13:26:55: [2024-10-29 13:26:55] iter = 08990, loss = 1.0393
2024-10-29 13:26:56: [2024-10-29 13:26:56] iter = 09000, loss = 0.8558
2024-10-29 13:26:56: [2024-10-29 13:26:56] iter = 09010, loss = 9.0823
2024-10-29 13:26:56: [2024-10-29 13:26:56] iter = 09020, loss = 1.1189
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 09030, loss = 1.4091
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 09040, loss = 1.5187
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 09050, loss = 1.6888
2024-10-29 13:26:58: [2024-10-29 13:26:58] iter = 09060, loss = 1.0698
2024-10-29 13:26:58: [2024-10-29 13:26:58] iter = 09070, loss = 1.4142
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 09080, loss = 1.6241
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 09090, loss = 2.1726
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 09100, loss = 1.0487
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 09110, loss = 2.4374
2024-10-29 13:27:00: [2024-10-29 13:27:00] iter = 09120, loss = 1.8971
2024-10-29 13:27:00: [2024-10-29 13:27:00] iter = 09130, loss = 5.1869
2024-10-29 13:27:00: [2024-10-29 13:27:00] iter = 09140, loss = 1.5870
2024-10-29 13:27:01: [2024-10-29 13:27:01] iter = 09150, loss = 1.5155
2024-10-29 13:27:01: [2024-10-29 13:27:01] iter = 09160, loss = 1.7646
2024-10-29 13:27:01: [2024-10-29 13:27:01] iter = 09170, loss = 1.2937
2024-10-29 13:27:02: [2024-10-29 13:27:02] iter = 09180, loss = 1.0184
2024-10-29 13:27:02: [2024-10-29 13:27:02] iter = 09190, loss = 1.1202
2024-10-29 13:27:03: [2024-10-29 13:27:03] iter = 09200, loss = 0.8291
2024-10-29 13:27:03: [2024-10-29 13:27:03] iter = 09210, loss = 1.7046
2024-10-29 13:27:03: [2024-10-29 13:27:03] iter = 09220, loss = 6.7733
2024-10-29 13:27:04: [2024-10-29 13:27:04] iter = 09230, loss = 3.0065
2024-10-29 13:27:04: [2024-10-29 13:27:04] iter = 09240, loss = 0.9519
2024-10-29 13:27:04: [2024-10-29 13:27:04] iter = 09250, loss = 1.2469
2024-10-29 13:27:05: [2024-10-29 13:27:05] iter = 09260, loss = 2.0351
2024-10-29 13:27:05: [2024-10-29 13:27:05] iter = 09270, loss = 0.9611
2024-10-29 13:27:05: [2024-10-29 13:27:05] iter = 09280, loss = 1.3414
2024-10-29 13:27:06: [2024-10-29 13:27:06] iter = 09290, loss = 1.1141
2024-10-29 13:27:06: [2024-10-29 13:27:06] iter = 09300, loss = 1.5210
2024-10-29 13:27:06: [2024-10-29 13:27:06] iter = 09310, loss = 0.8313
2024-10-29 13:27:07: [2024-10-29 13:27:07] iter = 09320, loss = 3.2874
2024-10-29 13:27:07: [2024-10-29 13:27:07] iter = 09330, loss = 1.2357
2024-10-29 13:27:07: [2024-10-29 13:27:07] iter = 09340, loss = 1.5732
2024-10-29 13:27:08: [2024-10-29 13:27:08] iter = 09350, loss = 1.7604
2024-10-29 13:27:08: [2024-10-29 13:27:08] iter = 09360, loss = 1.0865
2024-10-29 13:27:09: [2024-10-29 13:27:09] iter = 09370, loss = 0.8631
2024-10-29 13:27:09: [2024-10-29 13:27:09] iter = 09380, loss = 2.7904
2024-10-29 13:27:09: [2024-10-29 13:27:09] iter = 09390, loss = 2.6328
2024-10-29 13:27:10: [2024-10-29 13:27:10] iter = 09400, loss = 1.0309
2024-10-29 13:27:10: [2024-10-29 13:27:10] iter = 09410, loss = 4.5956
2024-10-29 13:27:10: [2024-10-29 13:27:10] iter = 09420, loss = 0.8046
2024-10-29 13:27:11: [2024-10-29 13:27:11] iter = 09430, loss = 0.9921
2024-10-29 13:27:11: [2024-10-29 13:27:11] iter = 09440, loss = 2.6563
2024-10-29 13:27:11: [2024-10-29 13:27:11] iter = 09450, loss = 1.3507
2024-10-29 13:27:12: [2024-10-29 13:27:12] iter = 09460, loss = 0.9806
2024-10-29 13:27:12: [2024-10-29 13:27:12] iter = 09470, loss = 1.0347
2024-10-29 13:27:12: [2024-10-29 13:27:12] iter = 09480, loss = 1.6658
2024-10-29 13:27:13: [2024-10-29 13:27:13] iter = 09490, loss = 1.9613
2024-10-29 13:27:13: [2024-10-29 13:27:13] iter = 09500, loss = 1.0243
2024-10-29 13:27:13: [2024-10-29 13:27:13] iter = 09510, loss = 9.4211
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 09520, loss = 5.1082
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 09530, loss = 5.2571
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 09540, loss = 1.7295
2024-10-29 13:27:15: [2024-10-29 13:27:15] iter = 09550, loss = 1.2922
2024-10-29 13:27:15: [2024-10-29 13:27:15] iter = 09560, loss = 1.5881
2024-10-29 13:27:15: [2024-10-29 13:27:15] iter = 09570, loss = 3.0930
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 09580, loss = 0.9834
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 09590, loss = 2.0810
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 09600, loss = 4.3891
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 09610, loss = 1.5541
2024-10-29 13:27:17: [2024-10-29 13:27:17] iter = 09620, loss = 2.2898
2024-10-29 13:27:17: [2024-10-29 13:27:17] iter = 09630, loss = 3.1072
2024-10-29 13:27:17: [2024-10-29 13:27:17] iter = 09640, loss = 4.1045
2024-10-29 13:27:18: [2024-10-29 13:27:18] iter = 09650, loss = 1.6598
2024-10-29 13:27:18: [2024-10-29 13:27:18] iter = 09660, loss = 2.4511
2024-10-29 13:27:18: [2024-10-29 13:27:18] iter = 09670, loss = 1.3261
2024-10-29 13:27:19: [2024-10-29 13:27:19] iter = 09680, loss = 1.9483
2024-10-29 13:27:19: [2024-10-29 13:27:19] iter = 09690, loss = 2.0967
2024-10-29 13:27:19: [2024-10-29 13:27:19] iter = 09700, loss = 1.4235
2024-10-29 13:27:20: [2024-10-29 13:27:20] iter = 09710, loss = 1.2635
2024-10-29 13:27:20: [2024-10-29 13:27:20] iter = 09720, loss = 1.6502
2024-10-29 13:27:20: [2024-10-29 13:27:20] iter = 09730, loss = 1.3751
2024-10-29 13:27:21: [2024-10-29 13:27:21] iter = 09740, loss = 1.6729
2024-10-29 13:27:21: [2024-10-29 13:27:21] iter = 09750, loss = 1.2159
2024-10-29 13:27:21: [2024-10-29 13:27:21] iter = 09760, loss = 2.1124
2024-10-29 13:27:22: [2024-10-29 13:27:22] iter = 09770, loss = 2.0985
2024-10-29 13:27:22: [2024-10-29 13:27:22] iter = 09780, loss = 1.7006
2024-10-29 13:27:22: [2024-10-29 13:27:22] iter = 09790, loss = 3.0222
2024-10-29 13:27:23: [2024-10-29 13:27:23] iter = 09800, loss = 1.2775
2024-10-29 13:27:23: [2024-10-29 13:27:23] iter = 09810, loss = 1.7964
2024-10-29 13:27:23: [2024-10-29 13:27:23] iter = 09820, loss = 1.1765
2024-10-29 13:27:24: [2024-10-29 13:27:24] iter = 09830, loss = 1.6678
2024-10-29 13:27:24: [2024-10-29 13:27:24] iter = 09840, loss = 1.1334
2024-10-29 13:27:24: [2024-10-29 13:27:24] iter = 09850, loss = 7.1927
2024-10-29 13:27:25: [2024-10-29 13:27:25] iter = 09860, loss = 1.3457
2024-10-29 13:27:25: [2024-10-29 13:27:25] iter = 09870, loss = 2.0029
2024-10-29 13:27:25: [2024-10-29 13:27:25] iter = 09880, loss = 1.6915
2024-10-29 13:27:26: [2024-10-29 13:27:26] iter = 09890, loss = 1.0637
2024-10-29 13:27:26: [2024-10-29 13:27:26] iter = 09900, loss = 1.2849
2024-10-29 13:27:26: [2024-10-29 13:27:26] iter = 09910, loss = 2.0761
2024-10-29 13:27:27: [2024-10-29 13:27:27] iter = 09920, loss = 0.7590
2024-10-29 13:27:27: [2024-10-29 13:27:27] iter = 09930, loss = 1.4403
2024-10-29 13:27:27: [2024-10-29 13:27:27] iter = 09940, loss = 1.4956
2024-10-29 13:27:28: [2024-10-29 13:27:28] iter = 09950, loss = 6.0292
2024-10-29 13:27:28: [2024-10-29 13:27:28] iter = 09960, loss = 1.0169
2024-10-29 13:27:28: [2024-10-29 13:27:28] iter = 09970, loss = 1.7010
2024-10-29 13:27:29: [2024-10-29 13:27:29] iter = 09980, loss = 2.2945
2024-10-29 13:27:29: [2024-10-29 13:27:29] iter = 09990, loss = 1.7872
2024-10-29 13:27:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 13:27:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:27:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49738}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:27:58: Evaluate 5 random ConvNet, ACCmean = 0.6473 ACCstd = 0.0159
-------------------------
2024-10-29 13:27:58: Evaluate 5 random ConvNet, SENmean = 0.5788 SENstd = 0.0034
-------------------------
2024-10-29 13:27:58: Evaluate 5 random ConvNet, SPEmean = 0.5788 SPEstd = 0.0034
-------------------------
2024-10-29 13:27:58: Evaluate 5 random ConvNet, F!mean = 0.5010 F!std = 0.0066
-------------------------
2024-10-29 13:27:58: Evaluate 5 random ConvNet, mean = 0.6473 std = 0.0159
-------------------------
2024-10-29 13:27:58: [2024-10-29 13:27:58] iter = 10000, loss = 9.6639
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:27:59: [2024-10-29 13:27:59] iter = 10010, loss = 1.5173
2024-10-29 13:27:59: [2024-10-29 13:27:59] iter = 10020, loss = 1.1054
2024-10-29 13:28:00: [2024-10-29 13:28:00] iter = 10030, loss = 2.8109
2024-10-29 13:28:00: [2024-10-29 13:28:00] iter = 10040, loss = 1.9801
2024-10-29 13:28:01: [2024-10-29 13:28:01] iter = 10050, loss = 1.1905
2024-10-29 13:28:01: [2024-10-29 13:28:01] iter = 10060, loss = 2.9347
2024-10-29 13:28:02: [2024-10-29 13:28:02] iter = 10070, loss = 1.3515
2024-10-29 13:28:02: [2024-10-29 13:28:02] iter = 10080, loss = 1.6426
2024-10-29 13:28:02: [2024-10-29 13:28:02] iter = 10090, loss = 3.7409
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 10100, loss = 0.9385
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 10110, loss = 1.5843
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 10120, loss = 1.2471
2024-10-29 13:28:04: [2024-10-29 13:28:04] iter = 10130, loss = 1.9600
2024-10-29 13:28:04: [2024-10-29 13:28:04] iter = 10140, loss = 1.1683
2024-10-29 13:28:04: [2024-10-29 13:28:04] iter = 10150, loss = 0.7160
2024-10-29 13:28:05: [2024-10-29 13:28:05] iter = 10160, loss = 1.7128
2024-10-29 13:28:05: [2024-10-29 13:28:05] iter = 10170, loss = 1.3748
2024-10-29 13:28:06: [2024-10-29 13:28:06] iter = 10180, loss = 1.3873
2024-10-29 13:28:06: [2024-10-29 13:28:06] iter = 10190, loss = 1.5697
2024-10-29 13:28:06: [2024-10-29 13:28:06] iter = 10200, loss = 2.0723
2024-10-29 13:28:07: [2024-10-29 13:28:07] iter = 10210, loss = 0.9147
2024-10-29 13:28:07: [2024-10-29 13:28:07] iter = 10220, loss = 1.4506
2024-10-29 13:28:07: [2024-10-29 13:28:07] iter = 10230, loss = 1.6757
2024-10-29 13:28:08: [2024-10-29 13:28:08] iter = 10240, loss = 5.0859
2024-10-29 13:28:08: [2024-10-29 13:28:08] iter = 10250, loss = 1.5482
2024-10-29 13:28:08: [2024-10-29 13:28:08] iter = 10260, loss = 3.5233
2024-10-29 13:28:09: [2024-10-29 13:28:09] iter = 10270, loss = 1.2987
2024-10-29 13:28:09: [2024-10-29 13:28:09] iter = 10280, loss = 1.4414
2024-10-29 13:28:09: [2024-10-29 13:28:09] iter = 10290, loss = 1.4899
2024-10-29 13:28:10: [2024-10-29 13:28:10] iter = 10300, loss = 0.9310
2024-10-29 13:28:10: [2024-10-29 13:28:10] iter = 10310, loss = 4.1958
2024-10-29 13:28:11: [2024-10-29 13:28:11] iter = 10320, loss = 1.2058
2024-10-29 13:28:11: [2024-10-29 13:28:11] iter = 10330, loss = 2.0163
2024-10-29 13:28:11: [2024-10-29 13:28:11] iter = 10340, loss = 1.4675
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 10350, loss = 3.6646
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 10360, loss = 7.6920
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 10370, loss = 1.3208
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 10380, loss = 6.2953
2024-10-29 13:28:13: [2024-10-29 13:28:13] iter = 10390, loss = 1.2812
2024-10-29 13:28:13: [2024-10-29 13:28:13] iter = 10400, loss = 2.3293
2024-10-29 13:28:13: [2024-10-29 13:28:13] iter = 10410, loss = 1.2836
2024-10-29 13:28:14: [2024-10-29 13:28:14] iter = 10420, loss = 1.1856
2024-10-29 13:28:14: [2024-10-29 13:28:14] iter = 10430, loss = 0.9651
2024-10-29 13:28:14: [2024-10-29 13:28:14] iter = 10440, loss = 1.3753
2024-10-29 13:28:15: [2024-10-29 13:28:15] iter = 10450, loss = 1.5161
2024-10-29 13:28:15: [2024-10-29 13:28:15] iter = 10460, loss = 0.9250
2024-10-29 13:28:15: [2024-10-29 13:28:15] iter = 10470, loss = 1.0582
2024-10-29 13:28:16: [2024-10-29 13:28:16] iter = 10480, loss = 2.0681
2024-10-29 13:28:16: [2024-10-29 13:28:16] iter = 10490, loss = 2.2761
2024-10-29 13:28:16: [2024-10-29 13:28:16] iter = 10500, loss = 1.6403
2024-10-29 13:28:17: [2024-10-29 13:28:17] iter = 10510, loss = 3.2571
2024-10-29 13:28:17: [2024-10-29 13:28:17] iter = 10520, loss = 1.2173
2024-10-29 13:28:17: [2024-10-29 13:28:17] iter = 10530, loss = 5.2212
2024-10-29 13:28:18: [2024-10-29 13:28:18] iter = 10540, loss = 1.4450
2024-10-29 13:28:18: [2024-10-29 13:28:18] iter = 10550, loss = 3.9104
2024-10-29 13:28:18: [2024-10-29 13:28:18] iter = 10560, loss = 1.1455
2024-10-29 13:28:19: [2024-10-29 13:28:19] iter = 10570, loss = 1.1202
2024-10-29 13:28:19: [2024-10-29 13:28:19] iter = 10580, loss = 1.6681
2024-10-29 13:28:19: [2024-10-29 13:28:19] iter = 10590, loss = 1.2290
2024-10-29 13:28:20: [2024-10-29 13:28:20] iter = 10600, loss = 2.0854
2024-10-29 13:28:20: [2024-10-29 13:28:20] iter = 10610, loss = 1.7655
2024-10-29 13:28:20: [2024-10-29 13:28:20] iter = 10620, loss = 1.9952
2024-10-29 13:28:21: [2024-10-29 13:28:21] iter = 10630, loss = 2.0432
2024-10-29 13:28:21: [2024-10-29 13:28:21] iter = 10640, loss = 0.9298
2024-10-29 13:28:21: [2024-10-29 13:28:21] iter = 10650, loss = 1.3816
2024-10-29 13:28:22: [2024-10-29 13:28:22] iter = 10660, loss = 1.7747
2024-10-29 13:28:22: [2024-10-29 13:28:22] iter = 10670, loss = 1.5412
2024-10-29 13:28:22: [2024-10-29 13:28:22] iter = 10680, loss = 1.3915
2024-10-29 13:28:23: [2024-10-29 13:28:23] iter = 10690, loss = 1.7277
2024-10-29 13:28:23: [2024-10-29 13:28:23] iter = 10700, loss = 0.9730
2024-10-29 13:28:24: [2024-10-29 13:28:24] iter = 10710, loss = 1.1744
2024-10-29 13:28:24: [2024-10-29 13:28:24] iter = 10720, loss = 1.0629
2024-10-29 13:28:24: [2024-10-29 13:28:24] iter = 10730, loss = 2.3697
2024-10-29 13:28:25: [2024-10-29 13:28:25] iter = 10740, loss = 1.0196
2024-10-29 13:28:25: [2024-10-29 13:28:25] iter = 10750, loss = 1.3063
2024-10-29 13:28:26: [2024-10-29 13:28:26] iter = 10760, loss = 1.2336
2024-10-29 13:28:26: [2024-10-29 13:28:26] iter = 10770, loss = 1.2405
2024-10-29 13:28:26: [2024-10-29 13:28:26] iter = 10780, loss = 1.1935
2024-10-29 13:28:27: [2024-10-29 13:28:27] iter = 10790, loss = 1.3042
2024-10-29 13:28:27: [2024-10-29 13:28:27] iter = 10800, loss = 3.6937
2024-10-29 13:28:28: [2024-10-29 13:28:28] iter = 10810, loss = 1.6249
2024-10-29 13:28:28: [2024-10-29 13:28:28] iter = 10820, loss = 1.0749
2024-10-29 13:28:29: [2024-10-29 13:28:29] iter = 10830, loss = 1.1646
2024-10-29 13:28:29: [2024-10-29 13:28:29] iter = 10840, loss = 0.9393
2024-10-29 13:28:29: [2024-10-29 13:28:29] iter = 10850, loss = 1.8018
2024-10-29 13:28:30: [2024-10-29 13:28:30] iter = 10860, loss = 1.5439
2024-10-29 13:28:30: [2024-10-29 13:28:30] iter = 10870, loss = 2.2157
2024-10-29 13:28:31: [2024-10-29 13:28:31] iter = 10880, loss = 1.5394
2024-10-29 13:28:31: [2024-10-29 13:28:31] iter = 10890, loss = 1.1556
2024-10-29 13:28:31: [2024-10-29 13:28:31] iter = 10900, loss = 0.9642
2024-10-29 13:28:32: [2024-10-29 13:28:32] iter = 10910, loss = 0.8425
2024-10-29 13:28:32: [2024-10-29 13:28:32] iter = 10920, loss = 1.8681
2024-10-29 13:28:33: [2024-10-29 13:28:33] iter = 10930, loss = 1.3580
2024-10-29 13:28:33: [2024-10-29 13:28:33] iter = 10940, loss = 1.0493
2024-10-29 13:28:33: [2024-10-29 13:28:33] iter = 10950, loss = 1.3938
2024-10-29 13:28:34: [2024-10-29 13:28:34] iter = 10960, loss = 0.8249
2024-10-29 13:28:34: [2024-10-29 13:28:34] iter = 10970, loss = 1.1167
2024-10-29 13:28:34: [2024-10-29 13:28:34] iter = 10980, loss = 2.0841
2024-10-29 13:28:35: [2024-10-29 13:28:35] iter = 10990, loss = 2.6122
2024-10-29 13:28:35: [2024-10-29 13:28:35] iter = 11000, loss = 3.5714
2024-10-29 13:28:35: [2024-10-29 13:28:35] iter = 11010, loss = 1.6104
2024-10-29 13:28:35: [2024-10-29 13:28:35] iter = 11020, loss = 1.6714
2024-10-29 13:28:36: [2024-10-29 13:28:36] iter = 11030, loss = 1.1419
2024-10-29 13:28:36: [2024-10-29 13:28:36] iter = 11040, loss = 4.1368
2024-10-29 13:28:36: [2024-10-29 13:28:36] iter = 11050, loss = 0.8834
2024-10-29 13:28:37: [2024-10-29 13:28:37] iter = 11060, loss = 3.5629
2024-10-29 13:28:37: [2024-10-29 13:28:37] iter = 11070, loss = 1.4396
2024-10-29 13:28:37: [2024-10-29 13:28:37] iter = 11080, loss = 1.4555
2024-10-29 13:28:38: [2024-10-29 13:28:38] iter = 11090, loss = 2.5635
2024-10-29 13:28:38: [2024-10-29 13:28:38] iter = 11100, loss = 0.8453
2024-10-29 13:28:38: [2024-10-29 13:28:38] iter = 11110, loss = 2.4397
2024-10-29 13:28:39: [2024-10-29 13:28:39] iter = 11120, loss = 0.7927
2024-10-29 13:28:39: [2024-10-29 13:28:39] iter = 11130, loss = 1.0194
2024-10-29 13:28:40: [2024-10-29 13:28:40] iter = 11140, loss = 1.0384
2024-10-29 13:28:40: [2024-10-29 13:28:40] iter = 11150, loss = 0.8551
2024-10-29 13:28:40: [2024-10-29 13:28:40] iter = 11160, loss = 1.2120
2024-10-29 13:28:41: [2024-10-29 13:28:41] iter = 11170, loss = 1.0589
2024-10-29 13:28:41: [2024-10-29 13:28:41] iter = 11180, loss = 1.5911
2024-10-29 13:28:42: [2024-10-29 13:28:42] iter = 11190, loss = 1.2696
2024-10-29 13:28:42: [2024-10-29 13:28:42] iter = 11200, loss = 0.9657
2024-10-29 13:28:42: [2024-10-29 13:28:42] iter = 11210, loss = 1.2249
2024-10-29 13:28:43: [2024-10-29 13:28:43] iter = 11220, loss = 1.7730
2024-10-29 13:28:43: [2024-10-29 13:28:43] iter = 11230, loss = 1.5398
2024-10-29 13:28:43: [2024-10-29 13:28:43] iter = 11240, loss = 1.5635
2024-10-29 13:28:44: [2024-10-29 13:28:44] iter = 11250, loss = 9.6104
2024-10-29 13:28:44: [2024-10-29 13:28:44] iter = 11260, loss = 1.2238
2024-10-29 13:28:44: [2024-10-29 13:28:44] iter = 11270, loss = 3.1476
2024-10-29 13:28:45: [2024-10-29 13:28:45] iter = 11280, loss = 3.0725
2024-10-29 13:28:45: [2024-10-29 13:28:45] iter = 11290, loss = 1.2154
2024-10-29 13:28:45: [2024-10-29 13:28:45] iter = 11300, loss = 0.9003
2024-10-29 13:28:46: [2024-10-29 13:28:46] iter = 11310, loss = 1.2540
2024-10-29 13:28:46: [2024-10-29 13:28:46] iter = 11320, loss = 2.6566
2024-10-29 13:28:46: [2024-10-29 13:28:46] iter = 11330, loss = 2.4356
2024-10-29 13:28:47: [2024-10-29 13:28:47] iter = 11340, loss = 1.5958
2024-10-29 13:28:47: [2024-10-29 13:28:47] iter = 11350, loss = 1.2404
2024-10-29 13:28:47: [2024-10-29 13:28:47] iter = 11360, loss = 1.0911
2024-10-29 13:28:48: [2024-10-29 13:28:48] iter = 11370, loss = 2.1143
2024-10-29 13:28:48: [2024-10-29 13:28:48] iter = 11380, loss = 1.6108
2024-10-29 13:28:48: [2024-10-29 13:28:48] iter = 11390, loss = 4.2404
2024-10-29 13:28:49: [2024-10-29 13:28:49] iter = 11400, loss = 1.9634
2024-10-29 13:28:49: [2024-10-29 13:28:49] iter = 11410, loss = 0.9752
2024-10-29 13:28:49: [2024-10-29 13:28:49] iter = 11420, loss = 1.3513
2024-10-29 13:28:50: [2024-10-29 13:28:50] iter = 11430, loss = 1.1669
2024-10-29 13:28:50: [2024-10-29 13:28:50] iter = 11440, loss = 1.6395
2024-10-29 13:28:50: [2024-10-29 13:28:50] iter = 11450, loss = 1.7984
2024-10-29 13:28:51: [2024-10-29 13:28:51] iter = 11460, loss = 2.5862
2024-10-29 13:28:51: [2024-10-29 13:28:51] iter = 11470, loss = 1.3591
2024-10-29 13:28:51: [2024-10-29 13:28:51] iter = 11480, loss = 1.0141
2024-10-29 13:28:52: [2024-10-29 13:28:52] iter = 11490, loss = 1.3894
2024-10-29 13:28:52: [2024-10-29 13:28:52] iter = 11500, loss = 1.1530
2024-10-29 13:28:52: [2024-10-29 13:28:52] iter = 11510, loss = 4.8827
2024-10-29 13:28:53: [2024-10-29 13:28:53] iter = 11520, loss = 1.6787
2024-10-29 13:28:53: [2024-10-29 13:28:53] iter = 11530, loss = 1.2645
2024-10-29 13:28:53: [2024-10-29 13:28:53] iter = 11540, loss = 3.2785
2024-10-29 13:28:54: [2024-10-29 13:28:54] iter = 11550, loss = 1.7481
2024-10-29 13:28:54: [2024-10-29 13:28:54] iter = 11560, loss = 1.5119
2024-10-29 13:28:54: [2024-10-29 13:28:54] iter = 11570, loss = 1.7722
2024-10-29 13:28:55: [2024-10-29 13:28:55] iter = 11580, loss = 1.2376
2024-10-29 13:28:55: [2024-10-29 13:28:55] iter = 11590, loss = 1.6818
2024-10-29 13:28:55: [2024-10-29 13:28:55] iter = 11600, loss = 1.0582
2024-10-29 13:28:56: [2024-10-29 13:28:56] iter = 11610, loss = 0.9164
2024-10-29 13:28:56: [2024-10-29 13:28:56] iter = 11620, loss = 1.4629
2024-10-29 13:28:56: [2024-10-29 13:28:56] iter = 11630, loss = 0.9849
2024-10-29 13:28:57: [2024-10-29 13:28:57] iter = 11640, loss = 1.1886
2024-10-29 13:28:57: [2024-10-29 13:28:57] iter = 11650, loss = 1.2967
2024-10-29 13:28:57: [2024-10-29 13:28:57] iter = 11660, loss = 1.3412
2024-10-29 13:28:58: [2024-10-29 13:28:58] iter = 11670, loss = 1.2329
2024-10-29 13:28:58: [2024-10-29 13:28:58] iter = 11680, loss = 1.0818
2024-10-29 13:28:59: [2024-10-29 13:28:59] iter = 11690, loss = 2.0309
2024-10-29 13:28:59: [2024-10-29 13:28:59] iter = 11700, loss = 4.3172
2024-10-29 13:28:59: [2024-10-29 13:28:59] iter = 11710, loss = 1.0949
2024-10-29 13:29:00: [2024-10-29 13:29:00] iter = 11720, loss = 1.4984
2024-10-29 13:29:00: [2024-10-29 13:29:00] iter = 11730, loss = 1.5802
2024-10-29 13:29:00: [2024-10-29 13:29:00] iter = 11740, loss = 1.3621
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 11750, loss = 1.2753
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 11760, loss = 1.3542
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 11770, loss = 1.8145
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 11780, loss = 1.4809
2024-10-29 13:29:02: [2024-10-29 13:29:02] iter = 11790, loss = 0.7174
2024-10-29 13:29:02: [2024-10-29 13:29:02] iter = 11800, loss = 1.0938
2024-10-29 13:29:03: [2024-10-29 13:29:03] iter = 11810, loss = 1.2326
2024-10-29 13:29:03: [2024-10-29 13:29:03] iter = 11820, loss = 1.1470
2024-10-29 13:29:03: [2024-10-29 13:29:03] iter = 11830, loss = 1.2469
2024-10-29 13:29:04: [2024-10-29 13:29:04] iter = 11840, loss = 1.3563
2024-10-29 13:29:04: [2024-10-29 13:29:04] iter = 11850, loss = 2.0663
2024-10-29 13:29:04: [2024-10-29 13:29:04] iter = 11860, loss = 1.7802
2024-10-29 13:29:05: [2024-10-29 13:29:05] iter = 11870, loss = 1.3178
2024-10-29 13:29:05: [2024-10-29 13:29:05] iter = 11880, loss = 1.4935
2024-10-29 13:29:05: [2024-10-29 13:29:05] iter = 11890, loss = 1.8137
2024-10-29 13:29:06: [2024-10-29 13:29:06] iter = 11900, loss = 1.1998
2024-10-29 13:29:06: [2024-10-29 13:29:06] iter = 11910, loss = 4.6308
2024-10-29 13:29:06: [2024-10-29 13:29:06] iter = 11920, loss = 0.9346
2024-10-29 13:29:07: [2024-10-29 13:29:07] iter = 11930, loss = 1.1767
2024-10-29 13:29:07: [2024-10-29 13:29:07] iter = 11940, loss = 1.1180
2024-10-29 13:29:08: [2024-10-29 13:29:08] iter = 11950, loss = 1.1460
2024-10-29 13:29:09: [2024-10-29 13:29:09] iter = 11960, loss = 0.7969
2024-10-29 13:29:09: [2024-10-29 13:29:09] iter = 11970, loss = 0.8449
2024-10-29 13:29:09: [2024-10-29 13:29:09] iter = 11980, loss = 2.3864
2024-10-29 13:29:10: [2024-10-29 13:29:10] iter = 11990, loss = 1.5676
2024-10-29 13:29:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 13:29:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:29:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50929}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:29:42: Evaluate 5 random ConvNet, ACCmean = 0.5075 ACCstd = 0.0091
-------------------------
2024-10-29 13:29:42: Evaluate 5 random ConvNet, SENmean = 0.6011 SENstd = 0.0057
-------------------------
2024-10-29 13:29:42: Evaluate 5 random ConvNet, SPEmean = 0.6011 SPEstd = 0.0057
-------------------------
2024-10-29 13:29:42: Evaluate 5 random ConvNet, F!mean = 0.4378 F!std = 0.0053
-------------------------
2024-10-29 13:29:42: Evaluate 5 random ConvNet, mean = 0.5075 std = 0.0091
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:29:42: [2024-10-29 13:29:42] iter = 12000, loss = 0.9252
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:29:42: [2024-10-29 13:29:42] iter = 12010, loss = 1.2661
2024-10-29 13:29:43: [2024-10-29 13:29:43] iter = 12020, loss = 1.4962
2024-10-29 13:29:43: [2024-10-29 13:29:43] iter = 12030, loss = 1.3731
2024-10-29 13:29:43: [2024-10-29 13:29:43] iter = 12040, loss = 1.0046
2024-10-29 13:29:44: [2024-10-29 13:29:44] iter = 12050, loss = 1.9322
2024-10-29 13:29:44: [2024-10-29 13:29:44] iter = 12060, loss = 1.7615
2024-10-29 13:29:44: [2024-10-29 13:29:44] iter = 12070, loss = 1.0057
2024-10-29 13:29:45: [2024-10-29 13:29:45] iter = 12080, loss = 0.9030
2024-10-29 13:29:45: [2024-10-29 13:29:45] iter = 12090, loss = 0.8853
2024-10-29 13:29:45: [2024-10-29 13:29:45] iter = 12100, loss = 0.9981
2024-10-29 13:29:46: [2024-10-29 13:29:46] iter = 12110, loss = 1.2077
2024-10-29 13:29:46: [2024-10-29 13:29:46] iter = 12120, loss = 1.1887
2024-10-29 13:29:46: [2024-10-29 13:29:46] iter = 12130, loss = 1.1335
2024-10-29 13:29:47: [2024-10-29 13:29:47] iter = 12140, loss = 1.4215
2024-10-29 13:29:47: [2024-10-29 13:29:47] iter = 12150, loss = 2.1039
2024-10-29 13:29:47: [2024-10-29 13:29:47] iter = 12160, loss = 1.7138
2024-10-29 13:29:48: [2024-10-29 13:29:48] iter = 12170, loss = 2.3296
2024-10-29 13:29:48: [2024-10-29 13:29:48] iter = 12180, loss = 1.7942
2024-10-29 13:29:48: [2024-10-29 13:29:48] iter = 12190, loss = 1.7710
2024-10-29 13:29:49: [2024-10-29 13:29:49] iter = 12200, loss = 1.1677
2024-10-29 13:29:49: [2024-10-29 13:29:49] iter = 12210, loss = 1.1997
2024-10-29 13:29:49: [2024-10-29 13:29:49] iter = 12220, loss = 1.2854
2024-10-29 13:29:50: [2024-10-29 13:29:50] iter = 12230, loss = 1.0388
2024-10-29 13:29:50: [2024-10-29 13:29:50] iter = 12240, loss = 1.5025
2024-10-29 13:29:50: [2024-10-29 13:29:50] iter = 12250, loss = 2.0173
2024-10-29 13:29:51: [2024-10-29 13:29:51] iter = 12260, loss = 1.0944
2024-10-29 13:29:51: [2024-10-29 13:29:51] iter = 12270, loss = 1.1200
2024-10-29 13:29:51: [2024-10-29 13:29:51] iter = 12280, loss = 1.3674
2024-10-29 13:29:52: [2024-10-29 13:29:52] iter = 12290, loss = 1.4419
2024-10-29 13:29:52: [2024-10-29 13:29:52] iter = 12300, loss = 2.6743
2024-10-29 13:29:52: [2024-10-29 13:29:52] iter = 12310, loss = 1.1571
2024-10-29 13:29:53: [2024-10-29 13:29:53] iter = 12320, loss = 0.9294
2024-10-29 13:29:53: [2024-10-29 13:29:53] iter = 12330, loss = 1.2201
2024-10-29 13:29:53: [2024-10-29 13:29:53] iter = 12340, loss = 1.6289
2024-10-29 13:29:54: [2024-10-29 13:29:54] iter = 12350, loss = 3.2111
2024-10-29 13:29:54: [2024-10-29 13:29:54] iter = 12360, loss = 3.0184
2024-10-29 13:29:54: [2024-10-29 13:29:54] iter = 12370, loss = 0.9751
2024-10-29 13:29:55: [2024-10-29 13:29:55] iter = 12380, loss = 1.1827
2024-10-29 13:29:55: [2024-10-29 13:29:55] iter = 12390, loss = 1.8834
2024-10-29 13:29:55: [2024-10-29 13:29:55] iter = 12400, loss = 1.1599
2024-10-29 13:29:56: [2024-10-29 13:29:56] iter = 12410, loss = 1.1809
2024-10-29 13:29:56: [2024-10-29 13:29:56] iter = 12420, loss = 1.0466
2024-10-29 13:29:56: [2024-10-29 13:29:56] iter = 12430, loss = 1.2239
2024-10-29 13:29:57: [2024-10-29 13:29:57] iter = 12440, loss = 1.0667
2024-10-29 13:29:57: [2024-10-29 13:29:57] iter = 12450, loss = 1.4243
2024-10-29 13:29:57: [2024-10-29 13:29:57] iter = 12460, loss = 1.6972
2024-10-29 13:29:58: [2024-10-29 13:29:58] iter = 12470, loss = 1.4716
2024-10-29 13:29:58: [2024-10-29 13:29:58] iter = 12480, loss = 1.4738
2024-10-29 13:29:58: [2024-10-29 13:29:58] iter = 12490, loss = 1.6782
2024-10-29 13:29:59: [2024-10-29 13:29:59] iter = 12500, loss = 1.9987
2024-10-29 13:29:59: [2024-10-29 13:29:59] iter = 12510, loss = 5.3764
2024-10-29 13:29:59: [2024-10-29 13:29:59] iter = 12520, loss = 1.5769
2024-10-29 13:30:00: [2024-10-29 13:30:00] iter = 12530, loss = 1.2255
2024-10-29 13:30:00: [2024-10-29 13:30:00] iter = 12540, loss = 3.6300
2024-10-29 13:30:00: [2024-10-29 13:30:00] iter = 12550, loss = 1.8540
2024-10-29 13:30:01: [2024-10-29 13:30:01] iter = 12560, loss = 1.1554
2024-10-29 13:30:01: [2024-10-29 13:30:01] iter = 12570, loss = 1.0298
2024-10-29 13:30:02: [2024-10-29 13:30:02] iter = 12580, loss = 2.4256
2024-10-29 13:30:02: [2024-10-29 13:30:02] iter = 12590, loss = 2.0283
2024-10-29 13:30:02: [2024-10-29 13:30:02] iter = 12600, loss = 1.1436
2024-10-29 13:30:03: [2024-10-29 13:30:03] iter = 12610, loss = 2.2285
2024-10-29 13:30:03: [2024-10-29 13:30:03] iter = 12620, loss = 1.0655
2024-10-29 13:30:04: [2024-10-29 13:30:04] iter = 12630, loss = 0.9450
2024-10-29 13:30:04: [2024-10-29 13:30:04] iter = 12640, loss = 1.3959
2024-10-29 13:30:04: [2024-10-29 13:30:04] iter = 12650, loss = 0.9643
2024-10-29 13:30:05: [2024-10-29 13:30:05] iter = 12660, loss = 1.2658
2024-10-29 13:30:05: [2024-10-29 13:30:05] iter = 12670, loss = 1.2484
2024-10-29 13:30:06: [2024-10-29 13:30:06] iter = 12680, loss = 0.9273
2024-10-29 13:30:06: [2024-10-29 13:30:06] iter = 12690, loss = 1.0262
2024-10-29 13:30:06: [2024-10-29 13:30:06] iter = 12700, loss = 1.1345
2024-10-29 13:30:07: [2024-10-29 13:30:07] iter = 12710, loss = 1.0504
2024-10-29 13:30:07: [2024-10-29 13:30:07] iter = 12720, loss = 2.0975
2024-10-29 13:30:07: [2024-10-29 13:30:07] iter = 12730, loss = 1.5133
2024-10-29 13:30:08: [2024-10-29 13:30:08] iter = 12740, loss = 0.9863
2024-10-29 13:30:08: [2024-10-29 13:30:08] iter = 12750, loss = 1.0620
2024-10-29 13:30:08: [2024-10-29 13:30:08] iter = 12760, loss = 0.8356
2024-10-29 13:30:09: [2024-10-29 13:30:09] iter = 12770, loss = 1.1694
2024-10-29 13:30:09: [2024-10-29 13:30:09] iter = 12780, loss = 1.1338
2024-10-29 13:30:09: [2024-10-29 13:30:09] iter = 12790, loss = 1.1061
2024-10-29 13:30:10: [2024-10-29 13:30:10] iter = 12800, loss = 2.5253
2024-10-29 13:30:10: [2024-10-29 13:30:10] iter = 12810, loss = 10.7245
2024-10-29 13:30:10: [2024-10-29 13:30:10] iter = 12820, loss = 12.8544
2024-10-29 13:30:11: [2024-10-29 13:30:11] iter = 12830, loss = 2.1952
2024-10-29 13:30:11: [2024-10-29 13:30:11] iter = 12840, loss = 1.6538
2024-10-29 13:30:11: [2024-10-29 13:30:11] iter = 12850, loss = 2.0969
2024-10-29 13:30:12: [2024-10-29 13:30:12] iter = 12860, loss = 2.2924
2024-10-29 13:30:12: [2024-10-29 13:30:12] iter = 12870, loss = 2.1388
2024-10-29 13:30:12: [2024-10-29 13:30:12] iter = 12880, loss = 0.9634
2024-10-29 13:30:13: [2024-10-29 13:30:13] iter = 12890, loss = 0.7600
2024-10-29 13:30:13: [2024-10-29 13:30:13] iter = 12900, loss = 1.4199
2024-10-29 13:30:13: [2024-10-29 13:30:13] iter = 12910, loss = 1.4452
2024-10-29 13:30:14: [2024-10-29 13:30:14] iter = 12920, loss = 1.2714
2024-10-29 13:30:15: [2024-10-29 13:30:15] iter = 12930, loss = 1.2638
2024-10-29 13:30:15: [2024-10-29 13:30:15] iter = 12940, loss = 1.2669
2024-10-29 13:30:15: [2024-10-29 13:30:15] iter = 12950, loss = 1.3595
2024-10-29 13:30:16: [2024-10-29 13:30:16] iter = 12960, loss = 1.0124
2024-10-29 13:30:16: [2024-10-29 13:30:16] iter = 12970, loss = 2.3791
2024-10-29 13:30:16: [2024-10-29 13:30:16] iter = 12980, loss = 0.8104
2024-10-29 13:30:17: [2024-10-29 13:30:17] iter = 12990, loss = 1.9836
2024-10-29 13:30:17: [2024-10-29 13:30:17] iter = 13000, loss = 1.1933
2024-10-29 13:30:17: [2024-10-29 13:30:17] iter = 13010, loss = 1.6329
2024-10-29 13:30:18: [2024-10-29 13:30:18] iter = 13020, loss = 2.5156
2024-10-29 13:30:18: [2024-10-29 13:30:18] iter = 13030, loss = 1.8482
2024-10-29 13:30:18: [2024-10-29 13:30:18] iter = 13040, loss = 1.1340
2024-10-29 13:30:19: [2024-10-29 13:30:19] iter = 13050, loss = 2.7801
2024-10-29 13:30:19: [2024-10-29 13:30:19] iter = 13060, loss = 1.4367
2024-10-29 13:30:19: [2024-10-29 13:30:19] iter = 13070, loss = 1.1498
2024-10-29 13:30:20: [2024-10-29 13:30:20] iter = 13080, loss = 0.9024
2024-10-29 13:30:20: [2024-10-29 13:30:20] iter = 13090, loss = 1.9284
2024-10-29 13:30:21: [2024-10-29 13:30:21] iter = 13100, loss = 1.1408
2024-10-29 13:30:21: [2024-10-29 13:30:21] iter = 13110, loss = 1.2858
2024-10-29 13:30:22: [2024-10-29 13:30:22] iter = 13120, loss = 0.7178
2024-10-29 13:30:22: [2024-10-29 13:30:22] iter = 13130, loss = 0.9272
2024-10-29 13:30:23: [2024-10-29 13:30:23] iter = 13140, loss = 0.9722
2024-10-29 13:30:23: [2024-10-29 13:30:23] iter = 13150, loss = 0.9898
2024-10-29 13:30:24: [2024-10-29 13:30:24] iter = 13160, loss = 1.3757
2024-10-29 13:30:24: [2024-10-29 13:30:24] iter = 13170, loss = 1.8005
2024-10-29 13:30:25: [2024-10-29 13:30:24] iter = 13180, loss = 1.1365
2024-10-29 13:30:25: [2024-10-29 13:30:25] iter = 13190, loss = 1.0757
2024-10-29 13:30:25: [2024-10-29 13:30:25] iter = 13200, loss = 1.0736
2024-10-29 13:30:26: [2024-10-29 13:30:26] iter = 13210, loss = 1.2171
2024-10-29 13:30:26: [2024-10-29 13:30:26] iter = 13220, loss = 1.3508
2024-10-29 13:30:27: [2024-10-29 13:30:27] iter = 13230, loss = 1.3693
2024-10-29 13:30:28: [2024-10-29 13:30:28] iter = 13240, loss = 1.4611
2024-10-29 13:30:28: [2024-10-29 13:30:28] iter = 13250, loss = 1.9400
2024-10-29 13:30:29: [2024-10-29 13:30:29] iter = 13260, loss = 12.4606
2024-10-29 13:30:29: [2024-10-29 13:30:29] iter = 13270, loss = 1.1305
2024-10-29 13:30:29: [2024-10-29 13:30:29] iter = 13280, loss = 1.7466
2024-10-29 13:30:30: [2024-10-29 13:30:30] iter = 13290, loss = 1.1735
2024-10-29 13:30:30: [2024-10-29 13:30:30] iter = 13300, loss = 4.0254
2024-10-29 13:30:30: [2024-10-29 13:30:30] iter = 13310, loss = 1.1487
2024-10-29 13:30:31: [2024-10-29 13:30:31] iter = 13320, loss = 1.3987
2024-10-29 13:30:31: [2024-10-29 13:30:31] iter = 13330, loss = 1.7119
2024-10-29 13:30:31: [2024-10-29 13:30:31] iter = 13340, loss = 1.2368
2024-10-29 13:30:32: [2024-10-29 13:30:32] iter = 13350, loss = 1.7745
2024-10-29 13:30:32: [2024-10-29 13:30:32] iter = 13360, loss = 1.5828
2024-10-29 13:30:32: [2024-10-29 13:30:32] iter = 13370, loss = 1.0772
2024-10-29 13:30:32: [2024-10-29 13:30:32] iter = 13380, loss = 2.3765
2024-10-29 13:30:33: [2024-10-29 13:30:33] iter = 13390, loss = 5.8240
2024-10-29 13:30:33: [2024-10-29 13:30:33] iter = 13400, loss = 2.8387
2024-10-29 13:30:33: [2024-10-29 13:30:33] iter = 13410, loss = 1.8228
2024-10-29 13:30:34: [2024-10-29 13:30:34] iter = 13420, loss = 1.1854
2024-10-29 13:30:34: [2024-10-29 13:30:34] iter = 13430, loss = 0.5802
2024-10-29 13:30:34: [2024-10-29 13:30:34] iter = 13440, loss = 3.1414
2024-10-29 13:30:35: [2024-10-29 13:30:35] iter = 13450, loss = 1.8649
2024-10-29 13:30:35: [2024-10-29 13:30:35] iter = 13460, loss = 1.0896
2024-10-29 13:30:35: [2024-10-29 13:30:35] iter = 13470, loss = 1.2707
2024-10-29 13:30:36: [2024-10-29 13:30:36] iter = 13480, loss = 1.3766
2024-10-29 13:30:37: [2024-10-29 13:30:37] iter = 13490, loss = 1.0458
2024-10-29 13:30:37: [2024-10-29 13:30:37] iter = 13500, loss = 1.7523
2024-10-29 13:30:37: [2024-10-29 13:30:37] iter = 13510, loss = 1.8603
2024-10-29 13:30:38: [2024-10-29 13:30:38] iter = 13520, loss = 1.2604
2024-10-29 13:30:38: [2024-10-29 13:30:38] iter = 13530, loss = 1.9639
2024-10-29 13:30:38: [2024-10-29 13:30:38] iter = 13540, loss = 1.1777
2024-10-29 13:30:39: [2024-10-29 13:30:38] iter = 13550, loss = 1.4566
2024-10-29 13:30:39: [2024-10-29 13:30:39] iter = 13560, loss = 1.1078
2024-10-29 13:30:39: [2024-10-29 13:30:39] iter = 13570, loss = 0.9767
2024-10-29 13:30:40: [2024-10-29 13:30:40] iter = 13580, loss = 1.7017
2024-10-29 13:30:40: [2024-10-29 13:30:40] iter = 13590, loss = 0.8061
2024-10-29 13:30:40: [2024-10-29 13:30:40] iter = 13600, loss = 1.3171
2024-10-29 13:30:41: [2024-10-29 13:30:41] iter = 13610, loss = 8.3929
2024-10-29 13:30:41: [2024-10-29 13:30:41] iter = 13620, loss = 1.1344
2024-10-29 13:30:41: [2024-10-29 13:30:41] iter = 13630, loss = 3.2166
2024-10-29 13:30:42: [2024-10-29 13:30:42] iter = 13640, loss = 2.0104
2024-10-29 13:30:42: [2024-10-29 13:30:42] iter = 13650, loss = 0.8825
2024-10-29 13:30:42: [2024-10-29 13:30:42] iter = 13660, loss = 4.4746
2024-10-29 13:30:43: [2024-10-29 13:30:43] iter = 13670, loss = 1.5946
2024-10-29 13:30:43: [2024-10-29 13:30:43] iter = 13680, loss = 1.4908
2024-10-29 13:30:43: [2024-10-29 13:30:43] iter = 13690, loss = 1.1928
2024-10-29 13:30:44: [2024-10-29 13:30:44] iter = 13700, loss = 1.0542
2024-10-29 13:30:44: [2024-10-29 13:30:44] iter = 13710, loss = 1.1093
2024-10-29 13:30:44: [2024-10-29 13:30:44] iter = 13720, loss = 1.3543
2024-10-29 13:30:45: [2024-10-29 13:30:45] iter = 13730, loss = 2.2250
2024-10-29 13:30:45: [2024-10-29 13:30:45] iter = 13740, loss = 1.3673
2024-10-29 13:30:45: [2024-10-29 13:30:45] iter = 13750, loss = 0.8658
2024-10-29 13:30:46: [2024-10-29 13:30:46] iter = 13760, loss = 3.6252
2024-10-29 13:30:46: [2024-10-29 13:30:46] iter = 13770, loss = 1.7417
2024-10-29 13:30:47: [2024-10-29 13:30:47] iter = 13780, loss = 1.3115
2024-10-29 13:30:47: [2024-10-29 13:30:47] iter = 13790, loss = 0.8837
2024-10-29 13:30:47: [2024-10-29 13:30:47] iter = 13800, loss = 1.7169
2024-10-29 13:30:48: [2024-10-29 13:30:48] iter = 13810, loss = 1.4187
2024-10-29 13:30:48: [2024-10-29 13:30:48] iter = 13820, loss = 1.8492
2024-10-29 13:30:48: [2024-10-29 13:30:48] iter = 13830, loss = 2.0135
2024-10-29 13:30:49: [2024-10-29 13:30:49] iter = 13840, loss = 1.7561
2024-10-29 13:30:49: [2024-10-29 13:30:49] iter = 13850, loss = 1.4540
2024-10-29 13:30:49: [2024-10-29 13:30:49] iter = 13860, loss = 1.6334
2024-10-29 13:30:50: [2024-10-29 13:30:50] iter = 13870, loss = 1.2899
2024-10-29 13:30:50: [2024-10-29 13:30:50] iter = 13880, loss = 0.9322
2024-10-29 13:30:51: [2024-10-29 13:30:51] iter = 13890, loss = 1.1822
2024-10-29 13:30:51: [2024-10-29 13:30:51] iter = 13900, loss = 1.1434
2024-10-29 13:30:51: [2024-10-29 13:30:51] iter = 13910, loss = 2.4157
2024-10-29 13:30:52: [2024-10-29 13:30:52] iter = 13920, loss = 6.1011
2024-10-29 13:30:52: [2024-10-29 13:30:52] iter = 13930, loss = 1.1020
2024-10-29 13:30:53: [2024-10-29 13:30:53] iter = 13940, loss = 1.2539
2024-10-29 13:30:53: [2024-10-29 13:30:53] iter = 13950, loss = 1.4622
2024-10-29 13:30:54: [2024-10-29 13:30:54] iter = 13960, loss = 2.3600
2024-10-29 13:30:54: [2024-10-29 13:30:54] iter = 13970, loss = 1.3551
2024-10-29 13:30:55: [2024-10-29 13:30:55] iter = 13980, loss = 1.0772
2024-10-29 13:30:55: [2024-10-29 13:30:55] iter = 13990, loss = 1.3525
2024-10-29 13:30:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 13:30:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:30:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 55766}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:31:22: Evaluate 5 random ConvNet, ACCmean = 0.6406 ACCstd = 0.0079
-------------------------
2024-10-29 13:31:22: Evaluate 5 random ConvNet, SENmean = 0.6106 SENstd = 0.0021
-------------------------
2024-10-29 13:31:22: Evaluate 5 random ConvNet, SPEmean = 0.6106 SPEstd = 0.0021
-------------------------
2024-10-29 13:31:22: Evaluate 5 random ConvNet, F!mean = 0.5094 F!std = 0.0035
-------------------------
2024-10-29 13:31:22: Evaluate 5 random ConvNet, mean = 0.6406 std = 0.0079
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:31:22: [2024-10-29 13:31:22] iter = 14000, loss = 1.0459
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:31:22: [2024-10-29 13:31:22] iter = 14010, loss = 1.2280
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 14020, loss = 1.5733
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 14030, loss = 1.6641
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 14040, loss = 1.9878
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 14050, loss = 1.9688
2024-10-29 13:31:24: [2024-10-29 13:31:24] iter = 14060, loss = 1.6085
2024-10-29 13:31:24: [2024-10-29 13:31:24] iter = 14070, loss = 1.4117
2024-10-29 13:31:25: [2024-10-29 13:31:25] iter = 14080, loss = 0.8463
2024-10-29 13:31:25: [2024-10-29 13:31:25] iter = 14090, loss = 2.3800
2024-10-29 13:31:25: [2024-10-29 13:31:25] iter = 14100, loss = 1.2193
2024-10-29 13:31:26: [2024-10-29 13:31:26] iter = 14110, loss = 1.1237
2024-10-29 13:31:26: [2024-10-29 13:31:26] iter = 14120, loss = 2.3708
2024-10-29 13:31:26: [2024-10-29 13:31:26] iter = 14130, loss = 1.1767
2024-10-29 13:31:27: [2024-10-29 13:31:27] iter = 14140, loss = 0.9746
2024-10-29 13:31:28: [2024-10-29 13:31:27] iter = 14150, loss = 1.0530
2024-10-29 13:31:28: [2024-10-29 13:31:28] iter = 14160, loss = 2.9283
2024-10-29 13:31:28: [2024-10-29 13:31:28] iter = 14170, loss = 1.0038
2024-10-29 13:31:28: [2024-10-29 13:31:28] iter = 14180, loss = 1.8454
2024-10-29 13:31:29: [2024-10-29 13:31:29] iter = 14190, loss = 10.0954
2024-10-29 13:31:29: [2024-10-29 13:31:29] iter = 14200, loss = 1.3597
2024-10-29 13:31:29: [2024-10-29 13:31:29] iter = 14210, loss = 0.9082
2024-10-29 13:31:30: [2024-10-29 13:31:30] iter = 14220, loss = 1.2910
2024-10-29 13:31:30: [2024-10-29 13:31:30] iter = 14230, loss = 1.7836
2024-10-29 13:31:31: [2024-10-29 13:31:31] iter = 14240, loss = 1.1803
2024-10-29 13:31:31: [2024-10-29 13:31:31] iter = 14250, loss = 4.2540
2024-10-29 13:31:31: [2024-10-29 13:31:31] iter = 14260, loss = 1.0208
2024-10-29 13:31:32: [2024-10-29 13:31:32] iter = 14270, loss = 0.6531
2024-10-29 13:31:32: [2024-10-29 13:31:32] iter = 14280, loss = 1.0926
2024-10-29 13:31:33: [2024-10-29 13:31:33] iter = 14290, loss = 2.5601
2024-10-29 13:31:34: [2024-10-29 13:31:34] iter = 14300, loss = 2.4525
2024-10-29 13:31:34: [2024-10-29 13:31:34] iter = 14310, loss = 2.2388
2024-10-29 13:31:35: [2024-10-29 13:31:35] iter = 14320, loss = 1.3345
2024-10-29 13:31:35: [2024-10-29 13:31:35] iter = 14330, loss = 1.8797
2024-10-29 13:31:36: [2024-10-29 13:31:36] iter = 14340, loss = 2.6406
2024-10-29 13:31:36: [2024-10-29 13:31:36] iter = 14350, loss = 1.2350
2024-10-29 13:31:37: [2024-10-29 13:31:37] iter = 14360, loss = 1.3313
2024-10-29 13:31:38: [2024-10-29 13:31:38] iter = 14370, loss = 5.3485
2024-10-29 13:31:39: [2024-10-29 13:31:39] iter = 14380, loss = 1.8190
2024-10-29 13:31:39: [2024-10-29 13:31:39] iter = 14390, loss = 1.4318
2024-10-29 13:31:40: [2024-10-29 13:31:40] iter = 14400, loss = 1.3365
2024-10-29 13:31:41: [2024-10-29 13:31:41] iter = 14410, loss = 1.9510
2024-10-29 13:31:41: [2024-10-29 13:31:41] iter = 14420, loss = 2.7537
2024-10-29 13:31:42: [2024-10-29 13:31:42] iter = 14430, loss = 1.1669
2024-10-29 13:31:42: [2024-10-29 13:31:42] iter = 14440, loss = 1.4051
2024-10-29 13:31:42: [2024-10-29 13:31:42] iter = 14450, loss = 1.0819
2024-10-29 13:31:43: [2024-10-29 13:31:43] iter = 14460, loss = 1.1242
2024-10-29 13:31:43: [2024-10-29 13:31:43] iter = 14470, loss = 0.9934
2024-10-29 13:31:43: [2024-10-29 13:31:43] iter = 14480, loss = 0.7731
2024-10-29 13:31:44: [2024-10-29 13:31:44] iter = 14490, loss = 1.6353
2024-10-29 13:31:44: [2024-10-29 13:31:44] iter = 14500, loss = 1.2725
2024-10-29 13:31:44: [2024-10-29 13:31:44] iter = 14510, loss = 1.2443
2024-10-29 13:31:45: [2024-10-29 13:31:45] iter = 14520, loss = 3.3035
2024-10-29 13:31:45: [2024-10-29 13:31:45] iter = 14530, loss = 1.6888
2024-10-29 13:31:45: [2024-10-29 13:31:45] iter = 14540, loss = 1.7579
2024-10-29 13:31:46: [2024-10-29 13:31:46] iter = 14550, loss = 0.8391
2024-10-29 13:31:46: [2024-10-29 13:31:46] iter = 14560, loss = 1.2762
2024-10-29 13:31:46: [2024-10-29 13:31:46] iter = 14570, loss = 0.9692
2024-10-29 13:31:47: [2024-10-29 13:31:47] iter = 14580, loss = 1.7604
2024-10-29 13:31:47: [2024-10-29 13:31:47] iter = 14590, loss = 0.7959
2024-10-29 13:31:47: [2024-10-29 13:31:47] iter = 14600, loss = 2.8574
2024-10-29 13:31:48: [2024-10-29 13:31:48] iter = 14610, loss = 1.6419
2024-10-29 13:31:48: [2024-10-29 13:31:48] iter = 14620, loss = 1.4247
2024-10-29 13:31:49: [2024-10-29 13:31:49] iter = 14630, loss = 0.9475
2024-10-29 13:31:49: [2024-10-29 13:31:49] iter = 14640, loss = 1.0523
2024-10-29 13:31:50: [2024-10-29 13:31:50] iter = 14650, loss = 1.6234
2024-10-29 13:31:50: [2024-10-29 13:31:50] iter = 14660, loss = 1.9916
2024-10-29 13:31:50: [2024-10-29 13:31:50] iter = 14670, loss = 1.4665
2024-10-29 13:31:51: [2024-10-29 13:31:51] iter = 14680, loss = 1.7416
2024-10-29 13:31:51: [2024-10-29 13:31:51] iter = 14690, loss = 1.6645
2024-10-29 13:31:51: [2024-10-29 13:31:51] iter = 14700, loss = 1.8512
2024-10-29 13:31:52: [2024-10-29 13:31:52] iter = 14710, loss = 1.1061
2024-10-29 13:31:52: [2024-10-29 13:31:52] iter = 14720, loss = 1.3029
2024-10-29 13:31:52: [2024-10-29 13:31:52] iter = 14730, loss = 1.2548
2024-10-29 13:31:53: [2024-10-29 13:31:53] iter = 14740, loss = 1.0764
2024-10-29 13:31:53: [2024-10-29 13:31:53] iter = 14750, loss = 2.4306
2024-10-29 13:31:53: [2024-10-29 13:31:53] iter = 14760, loss = 2.0485
2024-10-29 13:31:54: [2024-10-29 13:31:54] iter = 14770, loss = 1.0468
2024-10-29 13:31:54: [2024-10-29 13:31:54] iter = 14780, loss = 1.7180
2024-10-29 13:31:54: [2024-10-29 13:31:54] iter = 14790, loss = 2.3511
2024-10-29 13:31:55: [2024-10-29 13:31:55] iter = 14800, loss = 1.1601
2024-10-29 13:31:55: [2024-10-29 13:31:55] iter = 14810, loss = 1.2020
2024-10-29 13:31:55: [2024-10-29 13:31:55] iter = 14820, loss = 1.0344
2024-10-29 13:31:56: [2024-10-29 13:31:56] iter = 14830, loss = 1.5754
2024-10-29 13:31:56: [2024-10-29 13:31:56] iter = 14840, loss = 3.5130
2024-10-29 13:31:56: [2024-10-29 13:31:56] iter = 14850, loss = 3.2353
2024-10-29 13:31:57: [2024-10-29 13:31:57] iter = 14860, loss = 1.6827
2024-10-29 13:31:57: [2024-10-29 13:31:57] iter = 14870, loss = 1.9365
2024-10-29 13:31:57: [2024-10-29 13:31:57] iter = 14880, loss = 1.3613
2024-10-29 13:31:58: [2024-10-29 13:31:58] iter = 14890, loss = 1.2120
2024-10-29 13:31:58: [2024-10-29 13:31:58] iter = 14900, loss = 1.2656
2024-10-29 13:31:58: [2024-10-29 13:31:58] iter = 14910, loss = 1.2870
2024-10-29 13:31:59: [2024-10-29 13:31:59] iter = 14920, loss = 2.0210
2024-10-29 13:31:59: [2024-10-29 13:31:59] iter = 14930, loss = 1.0810
2024-10-29 13:31:59: [2024-10-29 13:31:59] iter = 14940, loss = 0.9518
2024-10-29 13:32:00: [2024-10-29 13:32:00] iter = 14950, loss = 0.9005
2024-10-29 13:32:00: [2024-10-29 13:32:00] iter = 14960, loss = 0.7804
2024-10-29 13:32:00: [2024-10-29 13:32:00] iter = 14970, loss = 1.1239
2024-10-29 13:32:01: [2024-10-29 13:32:01] iter = 14980, loss = 1.9356
2024-10-29 13:32:01: [2024-10-29 13:32:01] iter = 14990, loss = 1.3831
2024-10-29 13:32:01: [2024-10-29 13:32:01] iter = 15000, loss = 1.3802
2024-10-29 13:32:02: [2024-10-29 13:32:02] iter = 15010, loss = 2.0793
2024-10-29 13:32:02: [2024-10-29 13:32:02] iter = 15020, loss = 1.0586
2024-10-29 13:32:02: [2024-10-29 13:32:02] iter = 15030, loss = 2.0740
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 15040, loss = 4.5093
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 15050, loss = 1.0100
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 15060, loss = 1.6058
2024-10-29 13:32:04: [2024-10-29 13:32:04] iter = 15070, loss = 3.2985
2024-10-29 13:32:04: [2024-10-29 13:32:04] iter = 15080, loss = 1.4164
2024-10-29 13:32:04: [2024-10-29 13:32:04] iter = 15090, loss = 6.1159
2024-10-29 13:32:05: [2024-10-29 13:32:05] iter = 15100, loss = 3.9667
2024-10-29 13:32:05: [2024-10-29 13:32:05] iter = 15110, loss = 1.2697
2024-10-29 13:32:05: [2024-10-29 13:32:05] iter = 15120, loss = 2.0035
2024-10-29 13:32:06: [2024-10-29 13:32:06] iter = 15130, loss = 1.0512
2024-10-29 13:32:06: [2024-10-29 13:32:06] iter = 15140, loss = 1.1895
2024-10-29 13:32:06: [2024-10-29 13:32:06] iter = 15150, loss = 0.7436
2024-10-29 13:32:07: [2024-10-29 13:32:07] iter = 15160, loss = 0.9037
2024-10-29 13:32:07: [2024-10-29 13:32:07] iter = 15170, loss = 1.1048
2024-10-29 13:32:07: [2024-10-29 13:32:07] iter = 15180, loss = 1.1315
2024-10-29 13:32:08: [2024-10-29 13:32:08] iter = 15190, loss = 1.9707
2024-10-29 13:32:08: [2024-10-29 13:32:08] iter = 15200, loss = 1.3039
2024-10-29 13:32:09: [2024-10-29 13:32:09] iter = 15210, loss = 5.0047
2024-10-29 13:32:09: [2024-10-29 13:32:09] iter = 15220, loss = 1.5667
2024-10-29 13:32:09: [2024-10-29 13:32:09] iter = 15230, loss = 2.3040
2024-10-29 13:32:10: [2024-10-29 13:32:10] iter = 15240, loss = 1.1175
2024-10-29 13:32:10: [2024-10-29 13:32:10] iter = 15250, loss = 1.3238
2024-10-29 13:32:10: [2024-10-29 13:32:10] iter = 15260, loss = 1.5439
2024-10-29 13:32:11: [2024-10-29 13:32:11] iter = 15270, loss = 11.8363
2024-10-29 13:32:11: [2024-10-29 13:32:11] iter = 15280, loss = 1.3764
2024-10-29 13:32:11: [2024-10-29 13:32:11] iter = 15290, loss = 1.0932
2024-10-29 13:32:12: [2024-10-29 13:32:12] iter = 15300, loss = 3.2355
2024-10-29 13:32:12: [2024-10-29 13:32:12] iter = 15310, loss = 0.8780
2024-10-29 13:32:12: [2024-10-29 13:32:12] iter = 15320, loss = 1.3493
2024-10-29 13:32:13: [2024-10-29 13:32:13] iter = 15330, loss = 1.8293
2024-10-29 13:32:13: [2024-10-29 13:32:13] iter = 15340, loss = 1.8184
2024-10-29 13:32:13: [2024-10-29 13:32:13] iter = 15350, loss = 1.6940
2024-10-29 13:32:14: [2024-10-29 13:32:14] iter = 15360, loss = 1.6491
2024-10-29 13:32:14: [2024-10-29 13:32:14] iter = 15370, loss = 1.6217
2024-10-29 13:32:14: [2024-10-29 13:32:14] iter = 15380, loss = 2.1468
2024-10-29 13:32:15: [2024-10-29 13:32:15] iter = 15390, loss = 1.6931
2024-10-29 13:32:15: [2024-10-29 13:32:15] iter = 15400, loss = 1.8773
2024-10-29 13:32:15: [2024-10-29 13:32:15] iter = 15410, loss = 1.7791
2024-10-29 13:32:15: [2024-10-29 13:32:15] iter = 15420, loss = 0.9120
2024-10-29 13:32:16: [2024-10-29 13:32:16] iter = 15430, loss = 1.6376
2024-10-29 13:32:16: [2024-10-29 13:32:16] iter = 15440, loss = 1.0361
2024-10-29 13:32:17: [2024-10-29 13:32:16] iter = 15450, loss = 0.9475
2024-10-29 13:32:17: [2024-10-29 13:32:17] iter = 15460, loss = 3.6127
2024-10-29 13:32:17: [2024-10-29 13:32:17] iter = 15470, loss = 1.5852
2024-10-29 13:32:17: [2024-10-29 13:32:17] iter = 15480, loss = 1.8336
2024-10-29 13:32:18: [2024-10-29 13:32:18] iter = 15490, loss = 0.9556
2024-10-29 13:32:18: [2024-10-29 13:32:18] iter = 15500, loss = 2.1672
2024-10-29 13:32:18: [2024-10-29 13:32:18] iter = 15510, loss = 5.8633
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 15520, loss = 1.0449
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 15530, loss = 1.4922
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 15540, loss = 0.9269
2024-10-29 13:32:20: [2024-10-29 13:32:20] iter = 15550, loss = 0.9793
2024-10-29 13:32:20: [2024-10-29 13:32:20] iter = 15560, loss = 1.6326
2024-10-29 13:32:21: [2024-10-29 13:32:21] iter = 15570, loss = 2.6591
2024-10-29 13:32:21: [2024-10-29 13:32:21] iter = 15580, loss = 2.4184
2024-10-29 13:32:21: [2024-10-29 13:32:21] iter = 15590, loss = 8.2954
2024-10-29 13:32:22: [2024-10-29 13:32:22] iter = 15600, loss = 1.6847
2024-10-29 13:32:22: [2024-10-29 13:32:22] iter = 15610, loss = 1.4084
2024-10-29 13:32:22: [2024-10-29 13:32:22] iter = 15620, loss = 0.8954
2024-10-29 13:32:23: [2024-10-29 13:32:23] iter = 15630, loss = 1.9655
2024-10-29 13:32:23: [2024-10-29 13:32:23] iter = 15640, loss = 2.3496
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 15650, loss = 4.9641
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 15660, loss = 1.2435
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 15670, loss = 1.6340
2024-10-29 13:32:25: [2024-10-29 13:32:25] iter = 15680, loss = 1.8891
2024-10-29 13:32:25: [2024-10-29 13:32:25] iter = 15690, loss = 2.1499
2024-10-29 13:32:25: [2024-10-29 13:32:25] iter = 15700, loss = 2.3898
2024-10-29 13:32:26: [2024-10-29 13:32:26] iter = 15710, loss = 1.0771
2024-10-29 13:32:26: [2024-10-29 13:32:26] iter = 15720, loss = 0.9323
2024-10-29 13:32:27: [2024-10-29 13:32:27] iter = 15730, loss = 1.6388
2024-10-29 13:32:27: [2024-10-29 13:32:27] iter = 15740, loss = 1.1758
2024-10-29 13:32:28: [2024-10-29 13:32:28] iter = 15750, loss = 0.7524
2024-10-29 13:32:28: [2024-10-29 13:32:28] iter = 15760, loss = 1.6147
2024-10-29 13:32:28: [2024-10-29 13:32:28] iter = 15770, loss = 1.1455
2024-10-29 13:32:29: [2024-10-29 13:32:29] iter = 15780, loss = 1.2794
2024-10-29 13:32:29: [2024-10-29 13:32:29] iter = 15790, loss = 0.8626
2024-10-29 13:32:29: [2024-10-29 13:32:29] iter = 15800, loss = 3.8121
2024-10-29 13:32:30: [2024-10-29 13:32:30] iter = 15810, loss = 1.2385
2024-10-29 13:32:30: [2024-10-29 13:32:30] iter = 15820, loss = 2.5912
2024-10-29 13:32:30: [2024-10-29 13:32:30] iter = 15830, loss = 3.9868
2024-10-29 13:32:31: [2024-10-29 13:32:31] iter = 15840, loss = 0.9762
2024-10-29 13:32:31: [2024-10-29 13:32:31] iter = 15850, loss = 1.9642
2024-10-29 13:32:31: [2024-10-29 13:32:31] iter = 15860, loss = 1.2165
2024-10-29 13:32:32: [2024-10-29 13:32:32] iter = 15870, loss = 1.0609
2024-10-29 13:32:32: [2024-10-29 13:32:32] iter = 15880, loss = 2.2161
2024-10-29 13:32:32: [2024-10-29 13:32:32] iter = 15890, loss = 1.1743
2024-10-29 13:32:33: [2024-10-29 13:32:33] iter = 15900, loss = 1.2178
2024-10-29 13:32:33: [2024-10-29 13:32:33] iter = 15910, loss = 1.4016
2024-10-29 13:32:33: [2024-10-29 13:32:33] iter = 15920, loss = 1.5961
2024-10-29 13:32:34: [2024-10-29 13:32:34] iter = 15930, loss = 1.4753
2024-10-29 13:32:34: [2024-10-29 13:32:34] iter = 15940, loss = 2.1373
2024-10-29 13:32:34: [2024-10-29 13:32:34] iter = 15950, loss = 2.1418
2024-10-29 13:32:35: [2024-10-29 13:32:35] iter = 15960, loss = 2.0395
2024-10-29 13:32:35: [2024-10-29 13:32:35] iter = 15970, loss = 1.0948
2024-10-29 13:32:35: [2024-10-29 13:32:35] iter = 15980, loss = 1.0846
2024-10-29 13:32:36: [2024-10-29 13:32:36] iter = 15990, loss = 3.1561
2024-10-29 13:32:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 13:32:36: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:32:36: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 56533}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:33:05: Evaluate 5 random ConvNet, ACCmean = 0.7556 ACCstd = 0.0094
-------------------------
2024-10-29 13:33:05: Evaluate 5 random ConvNet, SENmean = 0.5689 SENstd = 0.0015
-------------------------
2024-10-29 13:33:05: Evaluate 5 random ConvNet, SPEmean = 0.5689 SPEstd = 0.0015
-------------------------
2024-10-29 13:33:05: Evaluate 5 random ConvNet, F!mean = 0.5404 F!std = 0.0027
-------------------------
2024-10-29 13:33:05: Evaluate 5 random ConvNet, mean = 0.7556 std = 0.0094
-------------------------
2024-10-29 13:33:05: [2024-10-29 13:33:05] iter = 16000, loss = 3.9283
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:33:05: [2024-10-29 13:33:05] iter = 16010, loss = 1.6417
2024-10-29 13:33:05: [2024-10-29 13:33:05] iter = 16020, loss = 2.0429
2024-10-29 13:33:06: [2024-10-29 13:33:06] iter = 16030, loss = 1.1550
2024-10-29 13:33:06: [2024-10-29 13:33:06] iter = 16040, loss = 3.4432
2024-10-29 13:33:07: [2024-10-29 13:33:07] iter = 16050, loss = 1.1680
2024-10-29 13:33:07: [2024-10-29 13:33:07] iter = 16060, loss = 1.6450
2024-10-29 13:33:07: [2024-10-29 13:33:07] iter = 16070, loss = 2.3029
2024-10-29 13:33:08: [2024-10-29 13:33:08] iter = 16080, loss = 1.5277
2024-10-29 13:33:08: [2024-10-29 13:33:08] iter = 16090, loss = 2.0234
2024-10-29 13:33:08: [2024-10-29 13:33:08] iter = 16100, loss = 1.3901
2024-10-29 13:33:09: [2024-10-29 13:33:09] iter = 16110, loss = 1.0169
2024-10-29 13:33:09: [2024-10-29 13:33:09] iter = 16120, loss = 1.4515
2024-10-29 13:33:09: [2024-10-29 13:33:09] iter = 16130, loss = 1.2085
2024-10-29 13:33:10: [2024-10-29 13:33:10] iter = 16140, loss = 1.6759
2024-10-29 13:33:10: [2024-10-29 13:33:10] iter = 16150, loss = 1.3691
2024-10-29 13:33:11: [2024-10-29 13:33:11] iter = 16160, loss = 1.2653
2024-10-29 13:33:11: [2024-10-29 13:33:11] iter = 16170, loss = 1.1621
2024-10-29 13:33:11: [2024-10-29 13:33:11] iter = 16180, loss = 1.0178
2024-10-29 13:33:12: [2024-10-29 13:33:12] iter = 16190, loss = 1.0422
2024-10-29 13:33:12: [2024-10-29 13:33:12] iter = 16200, loss = 1.2441
2024-10-29 13:33:13: [2024-10-29 13:33:13] iter = 16210, loss = 1.0165
2024-10-29 13:33:13: [2024-10-29 13:33:13] iter = 16220, loss = 1.1048
2024-10-29 13:33:14: [2024-10-29 13:33:14] iter = 16230, loss = 1.1427
2024-10-29 13:33:14: [2024-10-29 13:33:14] iter = 16240, loss = 1.4641
2024-10-29 13:33:15: [2024-10-29 13:33:15] iter = 16250, loss = 1.0036
2024-10-29 13:33:15: [2024-10-29 13:33:15] iter = 16260, loss = 1.8191
2024-10-29 13:33:15: [2024-10-29 13:33:15] iter = 16270, loss = 1.0612
2024-10-29 13:33:16: [2024-10-29 13:33:16] iter = 16280, loss = 1.4197
2024-10-29 13:33:16: [2024-10-29 13:33:16] iter = 16290, loss = 1.4041
2024-10-29 13:33:16: [2024-10-29 13:33:16] iter = 16300, loss = 1.4816
2024-10-29 13:33:17: [2024-10-29 13:33:17] iter = 16310, loss = 1.3014
2024-10-29 13:33:17: [2024-10-29 13:33:17] iter = 16320, loss = 1.7739
2024-10-29 13:33:18: [2024-10-29 13:33:18] iter = 16330, loss = 5.1387
2024-10-29 13:33:18: [2024-10-29 13:33:18] iter = 16340, loss = 1.6298
2024-10-29 13:33:18: [2024-10-29 13:33:18] iter = 16350, loss = 1.9698
2024-10-29 13:33:19: [2024-10-29 13:33:19] iter = 16360, loss = 1.2918
2024-10-29 13:33:19: [2024-10-29 13:33:19] iter = 16370, loss = 1.8199
2024-10-29 13:33:19: [2024-10-29 13:33:19] iter = 16380, loss = 1.4218
2024-10-29 13:33:19: [2024-10-29 13:33:19] iter = 16390, loss = 1.8121
2024-10-29 13:33:20: [2024-10-29 13:33:20] iter = 16400, loss = 1.3852
2024-10-29 13:33:20: [2024-10-29 13:33:20] iter = 16410, loss = 0.9618
2024-10-29 13:33:20: [2024-10-29 13:33:20] iter = 16420, loss = 1.0170
2024-10-29 13:33:21: [2024-10-29 13:33:21] iter = 16430, loss = 4.4239
2024-10-29 13:33:21: [2024-10-29 13:33:21] iter = 16440, loss = 1.9368
2024-10-29 13:33:21: [2024-10-29 13:33:21] iter = 16450, loss = 2.7633
2024-10-29 13:33:22: [2024-10-29 13:33:22] iter = 16460, loss = 1.1868
2024-10-29 13:33:22: [2024-10-29 13:33:22] iter = 16470, loss = 1.4884
2024-10-29 13:33:22: [2024-10-29 13:33:22] iter = 16480, loss = 1.4719
2024-10-29 13:33:23: [2024-10-29 13:33:23] iter = 16490, loss = 1.2829
2024-10-29 13:33:23: [2024-10-29 13:33:23] iter = 16500, loss = 2.5557
2024-10-29 13:33:24: [2024-10-29 13:33:23] iter = 16510, loss = 0.7829
2024-10-29 13:33:24: [2024-10-29 13:33:24] iter = 16520, loss = 1.9970
2024-10-29 13:33:24: [2024-10-29 13:33:24] iter = 16530, loss = 1.7741
2024-10-29 13:33:25: [2024-10-29 13:33:25] iter = 16540, loss = 0.9670
2024-10-29 13:33:25: [2024-10-29 13:33:25] iter = 16550, loss = 6.2127
2024-10-29 13:33:26: [2024-10-29 13:33:26] iter = 16560, loss = 1.7550
2024-10-29 13:33:26: [2024-10-29 13:33:26] iter = 16570, loss = 1.4730
2024-10-29 13:33:26: [2024-10-29 13:33:26] iter = 16580, loss = 2.3081
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 16590, loss = 1.1415
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 16600, loss = 1.7281
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 16610, loss = 1.1100
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 16620, loss = 0.8941
2024-10-29 13:33:28: [2024-10-29 13:33:28] iter = 16630, loss = 0.9528
2024-10-29 13:33:28: [2024-10-29 13:33:28] iter = 16640, loss = 1.7744
2024-10-29 13:33:28: [2024-10-29 13:33:28] iter = 16650, loss = 4.4567
2024-10-29 13:33:29: [2024-10-29 13:33:29] iter = 16660, loss = 1.7892
2024-10-29 13:33:29: [2024-10-29 13:33:29] iter = 16670, loss = 0.9016
2024-10-29 13:33:29: [2024-10-29 13:33:29] iter = 16680, loss = 1.1215
2024-10-29 13:33:30: [2024-10-29 13:33:30] iter = 16690, loss = 2.7269
2024-10-29 13:33:30: [2024-10-29 13:33:30] iter = 16700, loss = 5.9286
2024-10-29 13:33:30: [2024-10-29 13:33:30] iter = 16710, loss = 1.0873
2024-10-29 13:33:31: [2024-10-29 13:33:31] iter = 16720, loss = 2.0254
2024-10-29 13:33:31: [2024-10-29 13:33:31] iter = 16730, loss = 1.1752
2024-10-29 13:33:31: [2024-10-29 13:33:31] iter = 16740, loss = 1.0896
2024-10-29 13:33:32: [2024-10-29 13:33:32] iter = 16750, loss = 0.6794
2024-10-29 13:33:32: [2024-10-29 13:33:32] iter = 16760, loss = 1.2038
2024-10-29 13:33:32: [2024-10-29 13:33:32] iter = 16770, loss = 1.2505
2024-10-29 13:33:33: [2024-10-29 13:33:33] iter = 16780, loss = 3.6672
2024-10-29 13:33:33: [2024-10-29 13:33:33] iter = 16790, loss = 1.1421
2024-10-29 13:33:33: [2024-10-29 13:33:33] iter = 16800, loss = 1.7519
2024-10-29 13:33:34: [2024-10-29 13:33:34] iter = 16810, loss = 1.0249
2024-10-29 13:33:34: [2024-10-29 13:33:34] iter = 16820, loss = 6.2486
2024-10-29 13:33:34: [2024-10-29 13:33:34] iter = 16830, loss = 3.1194
2024-10-29 13:33:35: [2024-10-29 13:33:35] iter = 16840, loss = 3.7347
2024-10-29 13:33:35: [2024-10-29 13:33:35] iter = 16850, loss = 2.8623
2024-10-29 13:33:35: [2024-10-29 13:33:35] iter = 16860, loss = 1.0163
2024-10-29 13:33:36: [2024-10-29 13:33:36] iter = 16870, loss = 1.7484
2024-10-29 13:33:36: [2024-10-29 13:33:36] iter = 16880, loss = 2.0810
2024-10-29 13:33:36: [2024-10-29 13:33:36] iter = 16890, loss = 1.5310
2024-10-29 13:33:37: [2024-10-29 13:33:37] iter = 16900, loss = 3.9282
2024-10-29 13:33:37: [2024-10-29 13:33:37] iter = 16910, loss = 1.0789
2024-10-29 13:33:38: [2024-10-29 13:33:38] iter = 16920, loss = 1.2505
2024-10-29 13:33:38: [2024-10-29 13:33:38] iter = 16930, loss = 0.9799
2024-10-29 13:33:38: [2024-10-29 13:33:38] iter = 16940, loss = 1.8732
2024-10-29 13:33:39: [2024-10-29 13:33:39] iter = 16950, loss = 1.6435
2024-10-29 13:33:39: [2024-10-29 13:33:39] iter = 16960, loss = 1.4010
2024-10-29 13:33:39: [2024-10-29 13:33:39] iter = 16970, loss = 1.5237
2024-10-29 13:33:40: [2024-10-29 13:33:40] iter = 16980, loss = 1.0258
2024-10-29 13:33:40: [2024-10-29 13:33:40] iter = 16990, loss = 1.1438
2024-10-29 13:33:40: [2024-10-29 13:33:40] iter = 17000, loss = 1.1886
2024-10-29 13:33:41: [2024-10-29 13:33:41] iter = 17010, loss = 1.3179
2024-10-29 13:33:41: [2024-10-29 13:33:41] iter = 17020, loss = 1.2594
2024-10-29 13:33:41: [2024-10-29 13:33:41] iter = 17030, loss = 3.2545
2024-10-29 13:33:42: [2024-10-29 13:33:42] iter = 17040, loss = 1.8628
2024-10-29 13:33:42: [2024-10-29 13:33:42] iter = 17050, loss = 1.2496
2024-10-29 13:33:42: [2024-10-29 13:33:42] iter = 17060, loss = 0.8421
2024-10-29 13:33:43: [2024-10-29 13:33:43] iter = 17070, loss = 0.8869
2024-10-29 13:33:43: [2024-10-29 13:33:43] iter = 17080, loss = 3.3286
2024-10-29 13:33:43: [2024-10-29 13:33:43] iter = 17090, loss = 1.1032
2024-10-29 13:33:44: [2024-10-29 13:33:44] iter = 17100, loss = 3.5008
2024-10-29 13:33:44: [2024-10-29 13:33:44] iter = 17110, loss = 1.6764
2024-10-29 13:33:44: [2024-10-29 13:33:44] iter = 17120, loss = 1.0670
2024-10-29 13:33:45: [2024-10-29 13:33:45] iter = 17130, loss = 2.1345
2024-10-29 13:33:45: [2024-10-29 13:33:45] iter = 17140, loss = 1.5428
2024-10-29 13:33:45: [2024-10-29 13:33:45] iter = 17150, loss = 1.2784
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 17160, loss = 0.9402
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 17170, loss = 1.1738
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 17180, loss = 1.6683
2024-10-29 13:33:47: [2024-10-29 13:33:47] iter = 17190, loss = 1.1831
2024-10-29 13:33:47: [2024-10-29 13:33:47] iter = 17200, loss = 1.1351
2024-10-29 13:33:47: [2024-10-29 13:33:47] iter = 17210, loss = 4.0441
2024-10-29 13:33:48: [2024-10-29 13:33:48] iter = 17220, loss = 0.7528
2024-10-29 13:33:48: [2024-10-29 13:33:48] iter = 17230, loss = 3.0591
2024-10-29 13:33:48: [2024-10-29 13:33:48] iter = 17240, loss = 0.8651
2024-10-29 13:33:49: [2024-10-29 13:33:49] iter = 17250, loss = 1.5402
2024-10-29 13:33:49: [2024-10-29 13:33:49] iter = 17260, loss = 1.1394
2024-10-29 13:33:49: [2024-10-29 13:33:49] iter = 17270, loss = 1.7492
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 17280, loss = 1.1550
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 17290, loss = 2.1834
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 17300, loss = 1.5985
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 17310, loss = 1.1683
2024-10-29 13:33:51: [2024-10-29 13:33:51] iter = 17320, loss = 1.3698
2024-10-29 13:33:51: [2024-10-29 13:33:51] iter = 17330, loss = 1.1788
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 17340, loss = 1.6787
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 17350, loss = 1.3016
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 17360, loss = 1.8522
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 17370, loss = 1.2337
2024-10-29 13:33:53: [2024-10-29 13:33:53] iter = 17380, loss = 1.2526
2024-10-29 13:33:53: [2024-10-29 13:33:53] iter = 17390, loss = 1.5700
2024-10-29 13:33:54: [2024-10-29 13:33:54] iter = 17400, loss = 1.6837
2024-10-29 13:33:54: [2024-10-29 13:33:54] iter = 17410, loss = 2.4809
2024-10-29 13:33:54: [2024-10-29 13:33:54] iter = 17420, loss = 1.2635
2024-10-29 13:33:55: [2024-10-29 13:33:55] iter = 17430, loss = 0.9648
2024-10-29 13:33:55: [2024-10-29 13:33:55] iter = 17440, loss = 2.1203
2024-10-29 13:33:55: [2024-10-29 13:33:55] iter = 17450, loss = 1.2774
2024-10-29 13:33:56: [2024-10-29 13:33:56] iter = 17460, loss = 2.6728
2024-10-29 13:33:56: [2024-10-29 13:33:56] iter = 17470, loss = 1.0139
2024-10-29 13:33:57: [2024-10-29 13:33:57] iter = 17480, loss = 3.8866
2024-10-29 13:33:57: [2024-10-29 13:33:57] iter = 17490, loss = 2.0489
2024-10-29 13:33:58: [2024-10-29 13:33:58] iter = 17500, loss = 1.4682
2024-10-29 13:33:59: [2024-10-29 13:33:59] iter = 17510, loss = 2.6889
2024-10-29 13:33:59: [2024-10-29 13:33:59] iter = 17520, loss = 5.1247
2024-10-29 13:34:00: [2024-10-29 13:34:00] iter = 17530, loss = 0.9783
2024-10-29 13:34:00: [2024-10-29 13:34:00] iter = 17540, loss = 1.0593
2024-10-29 13:34:01: [2024-10-29 13:34:01] iter = 17550, loss = 1.2181
2024-10-29 13:34:01: [2024-10-29 13:34:01] iter = 17560, loss = 0.9787
2024-10-29 13:34:02: [2024-10-29 13:34:02] iter = 17570, loss = 0.9409
2024-10-29 13:34:03: [2024-10-29 13:34:03] iter = 17580, loss = 1.4687
2024-10-29 13:34:03: [2024-10-29 13:34:03] iter = 17590, loss = 1.6119
2024-10-29 13:34:04: [2024-10-29 13:34:04] iter = 17600, loss = 1.4453
2024-10-29 13:34:04: [2024-10-29 13:34:04] iter = 17610, loss = 0.9055
2024-10-29 13:34:04: [2024-10-29 13:34:04] iter = 17620, loss = 1.1554
2024-10-29 13:34:05: [2024-10-29 13:34:05] iter = 17630, loss = 2.8230
2024-10-29 13:34:05: [2024-10-29 13:34:05] iter = 17640, loss = 3.5689
2024-10-29 13:34:06: [2024-10-29 13:34:06] iter = 17650, loss = 1.2317
2024-10-29 13:34:06: [2024-10-29 13:34:06] iter = 17660, loss = 2.1476
2024-10-29 13:34:06: [2024-10-29 13:34:06] iter = 17670, loss = 1.3846
2024-10-29 13:34:06: [2024-10-29 13:34:06] iter = 17680, loss = 1.5471
2024-10-29 13:34:07: [2024-10-29 13:34:07] iter = 17690, loss = 1.0627
2024-10-29 13:34:07: [2024-10-29 13:34:07] iter = 17700, loss = 0.9711
2024-10-29 13:34:07: [2024-10-29 13:34:07] iter = 17710, loss = 1.5820
2024-10-29 13:34:08: [2024-10-29 13:34:08] iter = 17720, loss = 1.9820
2024-10-29 13:34:08: [2024-10-29 13:34:08] iter = 17730, loss = 1.9002
2024-10-29 13:34:08: [2024-10-29 13:34:08] iter = 17740, loss = 2.8201
2024-10-29 13:34:09: [2024-10-29 13:34:09] iter = 17750, loss = 1.1609
2024-10-29 13:34:09: [2024-10-29 13:34:09] iter = 17760, loss = 1.0217
2024-10-29 13:34:09: [2024-10-29 13:34:09] iter = 17770, loss = 1.2844
2024-10-29 13:34:10: [2024-10-29 13:34:10] iter = 17780, loss = 1.0155
2024-10-29 13:34:10: [2024-10-29 13:34:10] iter = 17790, loss = 4.8769
2024-10-29 13:34:10: [2024-10-29 13:34:10] iter = 17800, loss = 1.2436
2024-10-29 13:34:11: [2024-10-29 13:34:11] iter = 17810, loss = 1.0841
2024-10-29 13:34:11: [2024-10-29 13:34:11] iter = 17820, loss = 1.3510
2024-10-29 13:34:11: [2024-10-29 13:34:11] iter = 17830, loss = 2.0227
2024-10-29 13:34:12: [2024-10-29 13:34:12] iter = 17840, loss = 7.3856
2024-10-29 13:34:12: [2024-10-29 13:34:12] iter = 17850, loss = 2.2300
2024-10-29 13:34:13: [2024-10-29 13:34:13] iter = 17860, loss = 1.4505
2024-10-29 13:34:13: [2024-10-29 13:34:13] iter = 17870, loss = 2.8151
2024-10-29 13:34:14: [2024-10-29 13:34:14] iter = 17880, loss = 1.5480
2024-10-29 13:34:14: [2024-10-29 13:34:14] iter = 17890, loss = 1.3991
2024-10-29 13:34:14: [2024-10-29 13:34:14] iter = 17900, loss = 2.7677
2024-10-29 13:34:15: [2024-10-29 13:34:15] iter = 17910, loss = 1.1976
2024-10-29 13:34:15: [2024-10-29 13:34:15] iter = 17920, loss = 1.4289
2024-10-29 13:34:16: [2024-10-29 13:34:16] iter = 17930, loss = 2.9518
2024-10-29 13:34:16: [2024-10-29 13:34:16] iter = 17940, loss = 1.2784
2024-10-29 13:34:16: [2024-10-29 13:34:16] iter = 17950, loss = 1.4897
2024-10-29 13:34:17: [2024-10-29 13:34:17] iter = 17960, loss = 2.8877
2024-10-29 13:34:17: [2024-10-29 13:34:17] iter = 17970, loss = 1.3958
2024-10-29 13:34:17: [2024-10-29 13:34:17] iter = 17980, loss = 6.3333
2024-10-29 13:34:18: [2024-10-29 13:34:18] iter = 17990, loss = 1.4729
2024-10-29 13:34:18: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 13:34:18: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:34:18: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 58523}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:34:45: Evaluate 5 random ConvNet, ACCmean = 0.6948 ACCstd = 0.0088
-------------------------
2024-10-29 13:34:45: Evaluate 5 random ConvNet, SENmean = 0.5883 SENstd = 0.0043
-------------------------
2024-10-29 13:34:45: Evaluate 5 random ConvNet, SPEmean = 0.5883 SPEstd = 0.0043
-------------------------
2024-10-29 13:34:45: Evaluate 5 random ConvNet, F!mean = 0.5256 F!std = 0.0046
-------------------------
2024-10-29 13:34:45: Evaluate 5 random ConvNet, mean = 0.6948 std = 0.0088
-------------------------
2024-10-29 13:34:45: [2024-10-29 13:34:45] iter = 18000, loss = 3.1175
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:34:45: [2024-10-29 13:34:45] iter = 18010, loss = 5.1999
2024-10-29 13:34:46: [2024-10-29 13:34:46] iter = 18020, loss = 1.0835
2024-10-29 13:34:46: [2024-10-29 13:34:46] iter = 18030, loss = 0.8641
2024-10-29 13:34:47: [2024-10-29 13:34:47] iter = 18040, loss = 4.7815
2024-10-29 13:34:47: [2024-10-29 13:34:47] iter = 18050, loss = 1.5176
2024-10-29 13:34:48: [2024-10-29 13:34:48] iter = 18060, loss = 1.3015
2024-10-29 13:34:48: [2024-10-29 13:34:48] iter = 18070, loss = 1.5852
2024-10-29 13:34:48: [2024-10-29 13:34:48] iter = 18080, loss = 1.5753
2024-10-29 13:34:49: [2024-10-29 13:34:49] iter = 18090, loss = 2.6946
2024-10-29 13:34:49: [2024-10-29 13:34:49] iter = 18100, loss = 0.8795
2024-10-29 13:34:50: [2024-10-29 13:34:50] iter = 18110, loss = 1.8414
2024-10-29 13:34:50: [2024-10-29 13:34:50] iter = 18120, loss = 2.4162
2024-10-29 13:34:51: [2024-10-29 13:34:51] iter = 18130, loss = 1.6346
2024-10-29 13:34:51: [2024-10-29 13:34:51] iter = 18140, loss = 1.1831
2024-10-29 13:34:51: [2024-10-29 13:34:51] iter = 18150, loss = 1.5604
2024-10-29 13:34:52: [2024-10-29 13:34:52] iter = 18160, loss = 1.7783
2024-10-29 13:34:52: [2024-10-29 13:34:52] iter = 18170, loss = 1.0929
2024-10-29 13:34:53: [2024-10-29 13:34:53] iter = 18180, loss = 2.1952
2024-10-29 13:34:53: [2024-10-29 13:34:53] iter = 18190, loss = 0.9471
2024-10-29 13:34:53: [2024-10-29 13:34:53] iter = 18200, loss = 1.3224
2024-10-29 13:34:54: [2024-10-29 13:34:54] iter = 18210, loss = 1.1689
2024-10-29 13:34:54: [2024-10-29 13:34:54] iter = 18220, loss = 2.2540
2024-10-29 13:34:54: [2024-10-29 13:34:54] iter = 18230, loss = 1.8442
2024-10-29 13:34:55: [2024-10-29 13:34:55] iter = 18240, loss = 1.7066
2024-10-29 13:34:55: [2024-10-29 13:34:55] iter = 18250, loss = 1.4535
2024-10-29 13:34:55: [2024-10-29 13:34:55] iter = 18260, loss = 3.9731
2024-10-29 13:34:56: [2024-10-29 13:34:56] iter = 18270, loss = 1.8200
2024-10-29 13:34:56: [2024-10-29 13:34:56] iter = 18280, loss = 1.1022
2024-10-29 13:34:56: [2024-10-29 13:34:56] iter = 18290, loss = 1.0071
2024-10-29 13:34:57: [2024-10-29 13:34:57] iter = 18300, loss = 1.6247
2024-10-29 13:34:57: [2024-10-29 13:34:57] iter = 18310, loss = 0.9380
2024-10-29 13:34:57: [2024-10-29 13:34:57] iter = 18320, loss = 5.0454
2024-10-29 13:34:58: [2024-10-29 13:34:58] iter = 18330, loss = 1.5673
2024-10-29 13:34:58: [2024-10-29 13:34:58] iter = 18340, loss = 5.2900
2024-10-29 13:34:58: [2024-10-29 13:34:58] iter = 18350, loss = 1.6099
2024-10-29 13:34:59: [2024-10-29 13:34:59] iter = 18360, loss = 1.3388
2024-10-29 13:34:59: [2024-10-29 13:34:59] iter = 18370, loss = 2.0021
2024-10-29 13:34:59: [2024-10-29 13:34:59] iter = 18380, loss = 0.9889
2024-10-29 13:35:00: [2024-10-29 13:35:00] iter = 18390, loss = 0.9857
2024-10-29 13:35:00: [2024-10-29 13:35:00] iter = 18400, loss = 1.6419
2024-10-29 13:35:00: [2024-10-29 13:35:00] iter = 18410, loss = 1.8422
2024-10-29 13:35:01: [2024-10-29 13:35:01] iter = 18420, loss = 1.7700
2024-10-29 13:35:01: [2024-10-29 13:35:01] iter = 18430, loss = 1.4287
2024-10-29 13:35:01: [2024-10-29 13:35:01] iter = 18440, loss = 1.9382
2024-10-29 13:35:02: [2024-10-29 13:35:02] iter = 18450, loss = 1.0672
2024-10-29 13:35:02: [2024-10-29 13:35:02] iter = 18460, loss = 1.6091
2024-10-29 13:35:02: [2024-10-29 13:35:02] iter = 18470, loss = 1.2975
2024-10-29 13:35:03: [2024-10-29 13:35:03] iter = 18480, loss = 2.0566
2024-10-29 13:35:03: [2024-10-29 13:35:03] iter = 18490, loss = 1.8437
2024-10-29 13:35:04: [2024-10-29 13:35:04] iter = 18500, loss = 1.4348
2024-10-29 13:35:04: [2024-10-29 13:35:04] iter = 18510, loss = 1.8189
2024-10-29 13:35:04: [2024-10-29 13:35:04] iter = 18520, loss = 0.8847
2024-10-29 13:35:05: [2024-10-29 13:35:05] iter = 18530, loss = 0.8598
2024-10-29 13:35:05: [2024-10-29 13:35:05] iter = 18540, loss = 1.1113
2024-10-29 13:35:05: [2024-10-29 13:35:05] iter = 18550, loss = 1.1463
2024-10-29 13:35:06: [2024-10-29 13:35:06] iter = 18560, loss = 3.1165
2024-10-29 13:35:06: [2024-10-29 13:35:06] iter = 18570, loss = 1.1425
2024-10-29 13:35:06: [2024-10-29 13:35:06] iter = 18580, loss = 3.7312
2024-10-29 13:35:07: [2024-10-29 13:35:07] iter = 18590, loss = 1.4507
2024-10-29 13:35:07: [2024-10-29 13:35:07] iter = 18600, loss = 1.2689
2024-10-29 13:35:08: [2024-10-29 13:35:08] iter = 18610, loss = 1.6573
2024-10-29 13:35:08: [2024-10-29 13:35:08] iter = 18620, loss = 1.0184
2024-10-29 13:35:08: [2024-10-29 13:35:08] iter = 18630, loss = 1.3775
2024-10-29 13:35:09: [2024-10-29 13:35:09] iter = 18640, loss = 1.6263
2024-10-29 13:35:09: [2024-10-29 13:35:09] iter = 18650, loss = 0.9615
2024-10-29 13:35:10: [2024-10-29 13:35:10] iter = 18660, loss = 1.4209
2024-10-29 13:35:10: [2024-10-29 13:35:10] iter = 18670, loss = 0.7711
2024-10-29 13:35:10: [2024-10-29 13:35:10] iter = 18680, loss = 0.9242
2024-10-29 13:35:11: [2024-10-29 13:35:11] iter = 18690, loss = 0.7434
2024-10-29 13:35:11: [2024-10-29 13:35:11] iter = 18700, loss = 1.5286
2024-10-29 13:35:12: [2024-10-29 13:35:12] iter = 18710, loss = 0.7670
2024-10-29 13:35:12: [2024-10-29 13:35:12] iter = 18720, loss = 0.9910
2024-10-29 13:35:12: [2024-10-29 13:35:12] iter = 18730, loss = 0.8611
2024-10-29 13:35:13: [2024-10-29 13:35:13] iter = 18740, loss = 1.2209
2024-10-29 13:35:13: [2024-10-29 13:35:13] iter = 18750, loss = 1.0479
2024-10-29 13:35:13: [2024-10-29 13:35:13] iter = 18760, loss = 1.4801
2024-10-29 13:35:14: [2024-10-29 13:35:14] iter = 18770, loss = 1.1447
2024-10-29 13:35:14: [2024-10-29 13:35:14] iter = 18780, loss = 3.3605
2024-10-29 13:35:15: [2024-10-29 13:35:15] iter = 18790, loss = 1.3411
2024-10-29 13:35:15: [2024-10-29 13:35:15] iter = 18800, loss = 1.1102
2024-10-29 13:35:15: [2024-10-29 13:35:15] iter = 18810, loss = 1.2404
2024-10-29 13:35:16: [2024-10-29 13:35:16] iter = 18820, loss = 1.8686
2024-10-29 13:35:17: [2024-10-29 13:35:17] iter = 18830, loss = 1.6443
2024-10-29 13:35:17: [2024-10-29 13:35:17] iter = 18840, loss = 1.5703
2024-10-29 13:35:17: [2024-10-29 13:35:17] iter = 18850, loss = 2.1500
2024-10-29 13:35:18: [2024-10-29 13:35:18] iter = 18860, loss = 2.0313
2024-10-29 13:35:18: [2024-10-29 13:35:18] iter = 18870, loss = 1.3972
2024-10-29 13:35:19: [2024-10-29 13:35:19] iter = 18880, loss = 1.1726
2024-10-29 13:35:19: [2024-10-29 13:35:19] iter = 18890, loss = 1.4768
2024-10-29 13:35:20: [2024-10-29 13:35:20] iter = 18900, loss = 0.7819
2024-10-29 13:35:20: [2024-10-29 13:35:20] iter = 18910, loss = 1.3402
2024-10-29 13:35:20: [2024-10-29 13:35:20] iter = 18920, loss = 1.0874
2024-10-29 13:35:21: [2024-10-29 13:35:21] iter = 18930, loss = 2.5512
2024-10-29 13:35:21: [2024-10-29 13:35:21] iter = 18940, loss = 1.3271
2024-10-29 13:35:21: [2024-10-29 13:35:21] iter = 18950, loss = 1.7872
2024-10-29 13:35:22: [2024-10-29 13:35:22] iter = 18960, loss = 1.9282
2024-10-29 13:35:22: [2024-10-29 13:35:22] iter = 18970, loss = 1.2491
2024-10-29 13:35:22: [2024-10-29 13:35:22] iter = 18980, loss = 1.2294
2024-10-29 13:35:23: [2024-10-29 13:35:23] iter = 18990, loss = 1.8746
2024-10-29 13:35:23: [2024-10-29 13:35:23] iter = 19000, loss = 1.6458
2024-10-29 13:35:23: [2024-10-29 13:35:23] iter = 19010, loss = 4.7595
2024-10-29 13:35:24: [2024-10-29 13:35:24] iter = 19020, loss = 2.7005
2024-10-29 13:35:24: [2024-10-29 13:35:24] iter = 19030, loss = 1.5727
2024-10-29 13:35:24: [2024-10-29 13:35:24] iter = 19040, loss = 2.0443
2024-10-29 13:35:25: [2024-10-29 13:35:25] iter = 19050, loss = 4.0536
2024-10-29 13:35:25: [2024-10-29 13:35:25] iter = 19060, loss = 1.3033
2024-10-29 13:35:25: [2024-10-29 13:35:25] iter = 19070, loss = 1.6513
2024-10-29 13:35:26: [2024-10-29 13:35:26] iter = 19080, loss = 1.2653
2024-10-29 13:35:26: [2024-10-29 13:35:26] iter = 19090, loss = 1.0920
2024-10-29 13:35:26: [2024-10-29 13:35:26] iter = 19100, loss = 1.5154
2024-10-29 13:35:26: [2024-10-29 13:35:26] iter = 19110, loss = 0.8518
2024-10-29 13:35:27: [2024-10-29 13:35:27] iter = 19120, loss = 1.7780
2024-10-29 13:35:27: [2024-10-29 13:35:27] iter = 19130, loss = 1.0219
2024-10-29 13:35:27: [2024-10-29 13:35:27] iter = 19140, loss = 1.8648
2024-10-29 13:35:28: [2024-10-29 13:35:28] iter = 19150, loss = 2.0729
2024-10-29 13:35:28: [2024-10-29 13:35:28] iter = 19160, loss = 2.6607
2024-10-29 13:35:28: [2024-10-29 13:35:28] iter = 19170, loss = 1.2417
2024-10-29 13:35:28: [2024-10-29 13:35:28] iter = 19180, loss = 1.1531
2024-10-29 13:35:29: [2024-10-29 13:35:29] iter = 19190, loss = 1.1736
2024-10-29 13:35:29: [2024-10-29 13:35:29] iter = 19200, loss = 1.4395
2024-10-29 13:35:29: [2024-10-29 13:35:29] iter = 19210, loss = 1.6087
2024-10-29 13:35:30: [2024-10-29 13:35:30] iter = 19220, loss = 1.1648
2024-10-29 13:35:30: [2024-10-29 13:35:30] iter = 19230, loss = 1.4830
2024-10-29 13:35:30: [2024-10-29 13:35:30] iter = 19240, loss = 1.7472
2024-10-29 13:35:30: [2024-10-29 13:35:30] iter = 19250, loss = 2.1943
2024-10-29 13:35:31: [2024-10-29 13:35:31] iter = 19260, loss = 1.9525
2024-10-29 13:35:31: [2024-10-29 13:35:31] iter = 19270, loss = 1.1165
2024-10-29 13:35:31: [2024-10-29 13:35:31] iter = 19280, loss = 1.4058
2024-10-29 13:35:32: [2024-10-29 13:35:32] iter = 19290, loss = 1.9639
2024-10-29 13:35:32: [2024-10-29 13:35:32] iter = 19300, loss = 0.9176
2024-10-29 13:35:32: [2024-10-29 13:35:32] iter = 19310, loss = 0.8903
2024-10-29 13:35:33: [2024-10-29 13:35:33] iter = 19320, loss = 0.8598
2024-10-29 13:35:33: [2024-10-29 13:35:33] iter = 19330, loss = 2.1563
2024-10-29 13:35:33: [2024-10-29 13:35:33] iter = 19340, loss = 1.0439
2024-10-29 13:35:34: [2024-10-29 13:35:34] iter = 19350, loss = 0.7994
2024-10-29 13:35:34: [2024-10-29 13:35:34] iter = 19360, loss = 1.7217
2024-10-29 13:35:34: [2024-10-29 13:35:34] iter = 19370, loss = 2.9254
2024-10-29 13:35:35: [2024-10-29 13:35:35] iter = 19380, loss = 6.0831
2024-10-29 13:35:35: [2024-10-29 13:35:35] iter = 19390, loss = 1.8158
2024-10-29 13:35:35: [2024-10-29 13:35:35] iter = 19400, loss = 1.0410
2024-10-29 13:35:36: [2024-10-29 13:35:36] iter = 19410, loss = 1.2020
2024-10-29 13:35:36: [2024-10-29 13:35:36] iter = 19420, loss = 1.0951
2024-10-29 13:35:36: [2024-10-29 13:35:36] iter = 19430, loss = 1.5465
2024-10-29 13:35:37: [2024-10-29 13:35:37] iter = 19440, loss = 1.4446
2024-10-29 13:35:37: [2024-10-29 13:35:37] iter = 19450, loss = 1.1338
2024-10-29 13:35:37: [2024-10-29 13:35:37] iter = 19460, loss = 1.4602
2024-10-29 13:35:37: [2024-10-29 13:35:37] iter = 19470, loss = 1.0645
2024-10-29 13:35:38: [2024-10-29 13:35:38] iter = 19480, loss = 3.9795
2024-10-29 13:35:38: [2024-10-29 13:35:38] iter = 19490, loss = 1.8078
2024-10-29 13:35:38: [2024-10-29 13:35:38] iter = 19500, loss = 2.0410
2024-10-29 13:35:38: [2024-10-29 13:35:38] iter = 19510, loss = 1.1507
2024-10-29 13:35:39: [2024-10-29 13:35:39] iter = 19520, loss = 1.7409
2024-10-29 13:35:39: [2024-10-29 13:35:39] iter = 19530, loss = 1.5593
2024-10-29 13:35:39: [2024-10-29 13:35:39] iter = 19540, loss = 1.6684
2024-10-29 13:35:40: [2024-10-29 13:35:40] iter = 19550, loss = 2.7613
2024-10-29 13:35:40: [2024-10-29 13:35:40] iter = 19560, loss = 2.1461
2024-10-29 13:35:40: [2024-10-29 13:35:40] iter = 19570, loss = 0.7900
2024-10-29 13:35:41: [2024-10-29 13:35:41] iter = 19580, loss = 1.0604
2024-10-29 13:35:41: [2024-10-29 13:35:41] iter = 19590, loss = 1.2559
2024-10-29 13:35:41: [2024-10-29 13:35:41] iter = 19600, loss = 5.1371
2024-10-29 13:35:42: [2024-10-29 13:35:41] iter = 19610, loss = 1.5649
2024-10-29 13:35:42: [2024-10-29 13:35:42] iter = 19620, loss = 1.4006
2024-10-29 13:35:42: [2024-10-29 13:35:42] iter = 19630, loss = 0.9412
2024-10-29 13:35:42: [2024-10-29 13:35:42] iter = 19640, loss = 3.2237
2024-10-29 13:35:43: [2024-10-29 13:35:43] iter = 19650, loss = 0.9612
2024-10-29 13:35:43: [2024-10-29 13:35:43] iter = 19660, loss = 1.1583
2024-10-29 13:35:44: [2024-10-29 13:35:44] iter = 19670, loss = 1.1314
2024-10-29 13:35:44: [2024-10-29 13:35:44] iter = 19680, loss = 1.8565
2024-10-29 13:35:44: [2024-10-29 13:35:44] iter = 19690, loss = 1.5014
2024-10-29 13:35:44: [2024-10-29 13:35:44] iter = 19700, loss = 1.4261
2024-10-29 13:35:45: [2024-10-29 13:35:45] iter = 19710, loss = 1.4502
2024-10-29 13:35:45: [2024-10-29 13:35:45] iter = 19720, loss = 1.0749
2024-10-29 13:35:45: [2024-10-29 13:35:45] iter = 19730, loss = 3.6409
2024-10-29 13:35:46: [2024-10-29 13:35:46] iter = 19740, loss = 0.7813
2024-10-29 13:35:46: [2024-10-29 13:35:46] iter = 19750, loss = 6.6901
2024-10-29 13:35:46: [2024-10-29 13:35:46] iter = 19760, loss = 1.9798
2024-10-29 13:35:47: [2024-10-29 13:35:47] iter = 19770, loss = 1.3151
2024-10-29 13:35:47: [2024-10-29 13:35:47] iter = 19780, loss = 2.0632
2024-10-29 13:35:47: [2024-10-29 13:35:47] iter = 19790, loss = 1.8750
2024-10-29 13:35:48: [2024-10-29 13:35:48] iter = 19800, loss = 1.5375
2024-10-29 13:35:48: [2024-10-29 13:35:48] iter = 19810, loss = 2.8361
2024-10-29 13:35:48: [2024-10-29 13:35:48] iter = 19820, loss = 1.2923
2024-10-29 13:35:49: [2024-10-29 13:35:49] iter = 19830, loss = 1.4334
2024-10-29 13:35:49: [2024-10-29 13:35:49] iter = 19840, loss = 2.4024
2024-10-29 13:35:49: [2024-10-29 13:35:49] iter = 19850, loss = 1.6646
2024-10-29 13:35:49: [2024-10-29 13:35:49] iter = 19860, loss = 3.3225
2024-10-29 13:35:50: [2024-10-29 13:35:50] iter = 19870, loss = 4.9005
2024-10-29 13:35:50: [2024-10-29 13:35:50] iter = 19880, loss = 0.8970
2024-10-29 13:35:50: [2024-10-29 13:35:50] iter = 19890, loss = 0.9051
2024-10-29 13:35:50: [2024-10-29 13:35:50] iter = 19900, loss = 2.8712
2024-10-29 13:35:51: [2024-10-29 13:35:51] iter = 19910, loss = 1.5176
2024-10-29 13:35:51: [2024-10-29 13:35:51] iter = 19920, loss = 1.9057
2024-10-29 13:35:51: [2024-10-29 13:35:51] iter = 19930, loss = 0.9444
2024-10-29 13:35:52: [2024-10-29 13:35:52] iter = 19940, loss = 1.6864
2024-10-29 13:35:52: [2024-10-29 13:35:52] iter = 19950, loss = 1.1543
2024-10-29 13:35:52: [2024-10-29 13:35:52] iter = 19960, loss = 2.0826
2024-10-29 13:35:53: [2024-10-29 13:35:53] iter = 19970, loss = 1.4368
2024-10-29 13:35:53: [2024-10-29 13:35:53] iter = 19980, loss = 0.8728
2024-10-29 13:35:53: [2024-10-29 13:35:53] iter = 19990, loss = 4.0703
2024-10-29 13:35:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:35:53: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:35:53: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53953}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:36:18: Evaluate 5 random ConvNet, ACCmean = 0.4943 ACCstd = 0.0173
-------------------------
2024-10-29 13:36:18: Evaluate 5 random ConvNet, SENmean = 0.5971 SENstd = 0.0036
-------------------------
2024-10-29 13:36:18: Evaluate 5 random ConvNet, SPEmean = 0.5971 SPEstd = 0.0036
-------------------------
2024-10-29 13:36:18: Evaluate 5 random ConvNet, F!mean = 0.4293 F!std = 0.0101
-------------------------
2024-10-29 13:36:18: Evaluate 5 random ConvNet, mean = 0.4943 std = 0.0173
-------------------------
2024-10-29 13:36:18: [2024-10-29 13:36:18] iter = 20000, loss = 1.3024
2024-10-29 13:36:18: 
================== Exp 4 ==================
 
2024-10-29 13:36:18: Hyper-parameters: 
{'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f20047a2730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_ChestMNIST (INFO)>}
2024-10-29 13:36:18: Evaluation model pool: ['ConvNet']
2024-10-29 13:36:20: class c = 0: 70472 real images
2024-10-29 13:36:20: class c = 1: 7996 real images
2024-10-29 13:36:20: real images channel 0, mean = 0.4936, std = 0.2380
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 13:36:20: initialize synthetic data from random real images
2024-10-29 13:36:20: [2024-10-29 13:36:20] training begins
2024-10-29 13:36:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 13:36:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:36:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 78524}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:36:45: Evaluate 5 random ConvNet, ACCmean = 0.3230 ACCstd = 0.0107
-------------------------
2024-10-29 13:36:45: Evaluate 5 random ConvNet, SENmean = 0.4510 SENstd = 0.0042
-------------------------
2024-10-29 13:36:45: Evaluate 5 random ConvNet, SPEmean = 0.4510 SPEstd = 0.0042
-------------------------
2024-10-29 13:36:45: Evaluate 5 random ConvNet, F!mean = 0.2974 F!std = 0.0075
-------------------------
2024-10-29 13:36:45: Evaluate 5 random ConvNet, mean = 0.3230 std = 0.0107
-------------------------
2024-10-29 13:36:45: [2024-10-29 13:36:45] iter = 00000, loss = 6.7271
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:36:46: [2024-10-29 13:36:46] iter = 00010, loss = 3.3232
2024-10-29 13:36:46: [2024-10-29 13:36:46] iter = 00020, loss = 2.4036
2024-10-29 13:36:46: [2024-10-29 13:36:46] iter = 00030, loss = 3.4673
2024-10-29 13:36:47: [2024-10-29 13:36:47] iter = 00040, loss = 1.9214
2024-10-29 13:36:47: [2024-10-29 13:36:47] iter = 00050, loss = 1.2799
2024-10-29 13:36:47: [2024-10-29 13:36:47] iter = 00060, loss = 2.0282
2024-10-29 13:36:48: [2024-10-29 13:36:48] iter = 00070, loss = 1.3235
2024-10-29 13:36:48: [2024-10-29 13:36:48] iter = 00080, loss = 1.7698
2024-10-29 13:36:48: [2024-10-29 13:36:48] iter = 00090, loss = 1.1937
2024-10-29 13:36:49: [2024-10-29 13:36:49] iter = 00100, loss = 2.0777
2024-10-29 13:36:49: [2024-10-29 13:36:49] iter = 00110, loss = 3.4287
2024-10-29 13:36:49: [2024-10-29 13:36:49] iter = 00120, loss = 1.9268
2024-10-29 13:36:49: [2024-10-29 13:36:49] iter = 00130, loss = 0.9919
2024-10-29 13:36:50: [2024-10-29 13:36:50] iter = 00140, loss = 2.0302
2024-10-29 13:36:50: [2024-10-29 13:36:50] iter = 00150, loss = 2.0127
2024-10-29 13:36:50: [2024-10-29 13:36:50] iter = 00160, loss = 2.0316
2024-10-29 13:36:51: [2024-10-29 13:36:51] iter = 00170, loss = 1.1709
2024-10-29 13:36:51: [2024-10-29 13:36:51] iter = 00180, loss = 1.4788
2024-10-29 13:36:51: [2024-10-29 13:36:51] iter = 00190, loss = 5.6113
2024-10-29 13:36:52: [2024-10-29 13:36:51] iter = 00200, loss = 0.7989
2024-10-29 13:36:52: [2024-10-29 13:36:52] iter = 00210, loss = 1.7012
2024-10-29 13:36:52: [2024-10-29 13:36:52] iter = 00220, loss = 1.1176
2024-10-29 13:36:53: [2024-10-29 13:36:53] iter = 00230, loss = 3.8485
2024-10-29 13:36:53: [2024-10-29 13:36:53] iter = 00240, loss = 1.5574
2024-10-29 13:36:53: [2024-10-29 13:36:53] iter = 00250, loss = 8.6693
2024-10-29 13:36:53: [2024-10-29 13:36:53] iter = 00260, loss = 1.6763
2024-10-29 13:36:54: [2024-10-29 13:36:54] iter = 00270, loss = 1.2345
2024-10-29 13:36:54: [2024-10-29 13:36:54] iter = 00280, loss = 1.1850
2024-10-29 13:36:54: [2024-10-29 13:36:54] iter = 00290, loss = 1.8285
2024-10-29 13:36:55: [2024-10-29 13:36:55] iter = 00300, loss = 0.9993
2024-10-29 13:36:55: [2024-10-29 13:36:55] iter = 00310, loss = 3.3619
2024-10-29 13:36:55: [2024-10-29 13:36:55] iter = 00320, loss = 1.8504
2024-10-29 13:36:56: [2024-10-29 13:36:56] iter = 00330, loss = 2.1006
2024-10-29 13:36:56: [2024-10-29 13:36:56] iter = 00340, loss = 1.6603
2024-10-29 13:36:56: [2024-10-29 13:36:56] iter = 00350, loss = 1.5185
2024-10-29 13:36:56: [2024-10-29 13:36:56] iter = 00360, loss = 1.4382
2024-10-29 13:36:57: [2024-10-29 13:36:57] iter = 00370, loss = 2.8009
2024-10-29 13:36:57: [2024-10-29 13:36:57] iter = 00380, loss = 4.1110
2024-10-29 13:36:57: [2024-10-29 13:36:57] iter = 00390, loss = 7.5287
2024-10-29 13:36:58: [2024-10-29 13:36:58] iter = 00400, loss = 1.5576
2024-10-29 13:36:58: [2024-10-29 13:36:58] iter = 00410, loss = 2.2833
2024-10-29 13:36:58: [2024-10-29 13:36:58] iter = 00420, loss = 1.3771
2024-10-29 13:36:58: [2024-10-29 13:36:58] iter = 00430, loss = 0.9746
2024-10-29 13:36:59: [2024-10-29 13:36:59] iter = 00440, loss = 1.1202
2024-10-29 13:36:59: [2024-10-29 13:36:59] iter = 00450, loss = 1.6992
2024-10-29 13:36:59: [2024-10-29 13:36:59] iter = 00460, loss = 1.2576
2024-10-29 13:37:00: [2024-10-29 13:37:00] iter = 00470, loss = 1.4588
2024-10-29 13:37:00: [2024-10-29 13:37:00] iter = 00480, loss = 0.8839
2024-10-29 13:37:00: [2024-10-29 13:37:00] iter = 00490, loss = 1.0645
2024-10-29 13:37:00: [2024-10-29 13:37:00] iter = 00500, loss = 1.4559
2024-10-29 13:37:01: [2024-10-29 13:37:01] iter = 00510, loss = 2.2386
2024-10-29 13:37:01: [2024-10-29 13:37:01] iter = 00520, loss = 3.5162
2024-10-29 13:37:01: [2024-10-29 13:37:01] iter = 00530, loss = 1.9027
2024-10-29 13:37:02: [2024-10-29 13:37:02] iter = 00540, loss = 1.3622
2024-10-29 13:37:02: [2024-10-29 13:37:02] iter = 00550, loss = 0.9253
2024-10-29 13:37:02: [2024-10-29 13:37:02] iter = 00560, loss = 1.1495
2024-10-29 13:37:03: [2024-10-29 13:37:03] iter = 00570, loss = 2.0301
2024-10-29 13:37:03: [2024-10-29 13:37:03] iter = 00580, loss = 1.3912
2024-10-29 13:37:03: [2024-10-29 13:37:03] iter = 00590, loss = 1.7025
2024-10-29 13:37:03: [2024-10-29 13:37:03] iter = 00600, loss = 7.2421
2024-10-29 13:37:03: [2024-10-29 13:37:03] iter = 00610, loss = 1.7281
2024-10-29 13:37:04: [2024-10-29 13:37:04] iter = 00620, loss = 3.3703
2024-10-29 13:37:04: [2024-10-29 13:37:04] iter = 00630, loss = 2.2832
2024-10-29 13:37:04: [2024-10-29 13:37:04] iter = 00640, loss = 1.5925
2024-10-29 13:37:05: [2024-10-29 13:37:05] iter = 00650, loss = 2.1970
2024-10-29 13:37:05: [2024-10-29 13:37:05] iter = 00660, loss = 1.0962
2024-10-29 13:37:05: [2024-10-29 13:37:05] iter = 00670, loss = 1.3827
2024-10-29 13:37:05: [2024-10-29 13:37:05] iter = 00680, loss = 1.1145
2024-10-29 13:37:06: [2024-10-29 13:37:06] iter = 00690, loss = 1.2909
2024-10-29 13:37:06: [2024-10-29 13:37:06] iter = 00700, loss = 1.1715
2024-10-29 13:37:06: [2024-10-29 13:37:06] iter = 00710, loss = 1.2099
2024-10-29 13:37:07: [2024-10-29 13:37:07] iter = 00720, loss = 1.9006
2024-10-29 13:37:07: [2024-10-29 13:37:07] iter = 00730, loss = 1.0779
2024-10-29 13:37:07: [2024-10-29 13:37:07] iter = 00740, loss = 0.8077
2024-10-29 13:37:07: [2024-10-29 13:37:07] iter = 00750, loss = 1.1461
2024-10-29 13:37:08: [2024-10-29 13:37:08] iter = 00760, loss = 1.2849
2024-10-29 13:37:08: [2024-10-29 13:37:08] iter = 00770, loss = 4.4323
2024-10-29 13:37:08: [2024-10-29 13:37:08] iter = 00780, loss = 1.1490
2024-10-29 13:37:09: [2024-10-29 13:37:09] iter = 00790, loss = 3.2850
2024-10-29 13:37:09: [2024-10-29 13:37:09] iter = 00800, loss = 0.9954
2024-10-29 13:37:09: [2024-10-29 13:37:09] iter = 00810, loss = 2.8827
2024-10-29 13:37:10: [2024-10-29 13:37:10] iter = 00820, loss = 1.2460
2024-10-29 13:37:10: [2024-10-29 13:37:10] iter = 00830, loss = 1.5281
2024-10-29 13:37:10: [2024-10-29 13:37:10] iter = 00840, loss = 4.2314
2024-10-29 13:37:10: [2024-10-29 13:37:10] iter = 00850, loss = 2.0744
2024-10-29 13:37:11: [2024-10-29 13:37:11] iter = 00860, loss = 1.3736
2024-10-29 13:37:11: [2024-10-29 13:37:11] iter = 00870, loss = 1.8010
2024-10-29 13:37:11: [2024-10-29 13:37:11] iter = 00880, loss = 1.3619
2024-10-29 13:37:12: [2024-10-29 13:37:12] iter = 00890, loss = 1.2024
2024-10-29 13:37:12: [2024-10-29 13:37:12] iter = 00900, loss = 1.4309
2024-10-29 13:37:12: [2024-10-29 13:37:12] iter = 00910, loss = 0.9963
2024-10-29 13:37:13: [2024-10-29 13:37:12] iter = 00920, loss = 1.4073
2024-10-29 13:37:13: [2024-10-29 13:37:13] iter = 00930, loss = 1.0384
2024-10-29 13:37:13: [2024-10-29 13:37:13] iter = 00940, loss = 2.8595
2024-10-29 13:37:13: [2024-10-29 13:37:13] iter = 00950, loss = 1.5596
2024-10-29 13:37:14: [2024-10-29 13:37:14] iter = 00960, loss = 1.8597
2024-10-29 13:37:14: [2024-10-29 13:37:14] iter = 00970, loss = 1.8223
2024-10-29 13:37:14: [2024-10-29 13:37:14] iter = 00980, loss = 1.4788
2024-10-29 13:37:15: [2024-10-29 13:37:15] iter = 00990, loss = 1.5195
2024-10-29 13:37:15: [2024-10-29 13:37:15] iter = 01000, loss = 4.0709
2024-10-29 13:37:15: [2024-10-29 13:37:15] iter = 01010, loss = 1.3284
2024-10-29 13:37:15: [2024-10-29 13:37:15] iter = 01020, loss = 0.9430
2024-10-29 13:37:16: [2024-10-29 13:37:16] iter = 01030, loss = 2.1541
2024-10-29 13:37:16: [2024-10-29 13:37:16] iter = 01040, loss = 1.6291
2024-10-29 13:37:16: [2024-10-29 13:37:16] iter = 01050, loss = 2.0775
2024-10-29 13:37:17: [2024-10-29 13:37:17] iter = 01060, loss = 1.1291
2024-10-29 13:37:17: [2024-10-29 13:37:17] iter = 01070, loss = 1.3196
2024-10-29 13:37:17: [2024-10-29 13:37:17] iter = 01080, loss = 1.1491
2024-10-29 13:37:17: [2024-10-29 13:37:17] iter = 01090, loss = 1.1374
2024-10-29 13:37:18: [2024-10-29 13:37:18] iter = 01100, loss = 1.0594
2024-10-29 13:37:18: [2024-10-29 13:37:18] iter = 01110, loss = 0.9848
2024-10-29 13:37:18: [2024-10-29 13:37:18] iter = 01120, loss = 4.1279
2024-10-29 13:37:19: [2024-10-29 13:37:19] iter = 01130, loss = 1.4183
2024-10-29 13:37:19: [2024-10-29 13:37:19] iter = 01140, loss = 1.3667
2024-10-29 13:37:19: [2024-10-29 13:37:19] iter = 01150, loss = 1.9124
2024-10-29 13:37:20: [2024-10-29 13:37:20] iter = 01160, loss = 3.1776
2024-10-29 13:37:20: [2024-10-29 13:37:20] iter = 01170, loss = 1.0240
2024-10-29 13:37:20: [2024-10-29 13:37:20] iter = 01180, loss = 0.7215
2024-10-29 13:37:20: [2024-10-29 13:37:20] iter = 01190, loss = 1.3489
2024-10-29 13:37:20: [2024-10-29 13:37:20] iter = 01200, loss = 9.4525
2024-10-29 13:37:21: [2024-10-29 13:37:21] iter = 01210, loss = 0.9084
2024-10-29 13:37:21: [2024-10-29 13:37:21] iter = 01220, loss = 1.4577
2024-10-29 13:37:21: [2024-10-29 13:37:21] iter = 01230, loss = 2.3868
2024-10-29 13:37:21: [2024-10-29 13:37:21] iter = 01240, loss = 1.0008
2024-10-29 13:37:22: [2024-10-29 13:37:22] iter = 01250, loss = 1.7410
2024-10-29 13:37:22: [2024-10-29 13:37:22] iter = 01260, loss = 1.8710
2024-10-29 13:37:22: [2024-10-29 13:37:22] iter = 01270, loss = 1.9478
2024-10-29 13:37:22: [2024-10-29 13:37:22] iter = 01280, loss = 1.1665
2024-10-29 13:37:23: [2024-10-29 13:37:23] iter = 01290, loss = 1.1023
2024-10-29 13:37:23: [2024-10-29 13:37:23] iter = 01300, loss = 1.5325
2024-10-29 13:37:23: [2024-10-29 13:37:23] iter = 01310, loss = 1.1007
2024-10-29 13:37:24: [2024-10-29 13:37:24] iter = 01320, loss = 1.6104
2024-10-29 13:37:24: [2024-10-29 13:37:24] iter = 01330, loss = 1.5932
2024-10-29 13:37:24: [2024-10-29 13:37:24] iter = 01340, loss = 1.5432
2024-10-29 13:37:24: [2024-10-29 13:37:24] iter = 01350, loss = 1.0010
2024-10-29 13:37:25: [2024-10-29 13:37:25] iter = 01360, loss = 1.2720
2024-10-29 13:37:25: [2024-10-29 13:37:25] iter = 01370, loss = 2.0662
2024-10-29 13:37:25: [2024-10-29 13:37:25] iter = 01380, loss = 0.9896
2024-10-29 13:37:26: [2024-10-29 13:37:26] iter = 01390, loss = 1.0212
2024-10-29 13:37:26: [2024-10-29 13:37:26] iter = 01400, loss = 1.5660
2024-10-29 13:37:26: [2024-10-29 13:37:26] iter = 01410, loss = 1.0755
2024-10-29 13:37:27: [2024-10-29 13:37:27] iter = 01420, loss = 1.3833
2024-10-29 13:37:27: [2024-10-29 13:37:27] iter = 01430, loss = 3.3885
2024-10-29 13:37:28: [2024-10-29 13:37:28] iter = 01440, loss = 0.8568
2024-10-29 13:37:28: [2024-10-29 13:37:28] iter = 01450, loss = 0.8440
2024-10-29 13:37:28: [2024-10-29 13:37:28] iter = 01460, loss = 1.0974
2024-10-29 13:37:29: [2024-10-29 13:37:29] iter = 01470, loss = 1.4819
2024-10-29 13:37:29: [2024-10-29 13:37:29] iter = 01480, loss = 0.7395
2024-10-29 13:37:29: [2024-10-29 13:37:29] iter = 01490, loss = 1.2198
2024-10-29 13:37:30: [2024-10-29 13:37:29] iter = 01500, loss = 1.4892
2024-10-29 13:37:30: [2024-10-29 13:37:30] iter = 01510, loss = 1.3188
2024-10-29 13:37:30: [2024-10-29 13:37:30] iter = 01520, loss = 1.2016
2024-10-29 13:37:30: [2024-10-29 13:37:30] iter = 01530, loss = 2.2531
2024-10-29 13:37:31: [2024-10-29 13:37:31] iter = 01540, loss = 1.1326
2024-10-29 13:37:31: [2024-10-29 13:37:31] iter = 01550, loss = 2.3397
2024-10-29 13:37:31: [2024-10-29 13:37:31] iter = 01560, loss = 1.2188
2024-10-29 13:37:32: [2024-10-29 13:37:32] iter = 01570, loss = 1.1014
2024-10-29 13:37:32: [2024-10-29 13:37:32] iter = 01580, loss = 2.1274
2024-10-29 13:37:32: [2024-10-29 13:37:32] iter = 01590, loss = 6.3357
2024-10-29 13:37:33: [2024-10-29 13:37:32] iter = 01600, loss = 1.3864
2024-10-29 13:37:33: [2024-10-29 13:37:33] iter = 01610, loss = 0.6000
2024-10-29 13:37:33: [2024-10-29 13:37:33] iter = 01620, loss = 7.0334
2024-10-29 13:37:33: [2024-10-29 13:37:33] iter = 01630, loss = 1.2767
2024-10-29 13:37:34: [2024-10-29 13:37:34] iter = 01640, loss = 2.2733
2024-10-29 13:37:34: [2024-10-29 13:37:34] iter = 01650, loss = 1.2549
2024-10-29 13:37:34: [2024-10-29 13:37:34] iter = 01660, loss = 1.1197
2024-10-29 13:37:35: [2024-10-29 13:37:35] iter = 01670, loss = 2.6534
2024-10-29 13:37:35: [2024-10-29 13:37:35] iter = 01680, loss = 1.4551
2024-10-29 13:37:35: [2024-10-29 13:37:35] iter = 01690, loss = 2.1035
2024-10-29 13:37:36: [2024-10-29 13:37:36] iter = 01700, loss = 1.3963
2024-10-29 13:37:36: [2024-10-29 13:37:36] iter = 01710, loss = 1.5671
2024-10-29 13:37:36: [2024-10-29 13:37:36] iter = 01720, loss = 1.2808
2024-10-29 13:37:37: [2024-10-29 13:37:37] iter = 01730, loss = 1.4044
2024-10-29 13:37:37: [2024-10-29 13:37:37] iter = 01740, loss = 1.1431
2024-10-29 13:37:37: [2024-10-29 13:37:37] iter = 01750, loss = 5.2294
2024-10-29 13:37:38: [2024-10-29 13:37:38] iter = 01760, loss = 0.8779
2024-10-29 13:37:38: [2024-10-29 13:37:38] iter = 01770, loss = 1.5747
2024-10-29 13:37:38: [2024-10-29 13:37:38] iter = 01780, loss = 1.9569
2024-10-29 13:37:38: [2024-10-29 13:37:38] iter = 01790, loss = 1.2852
2024-10-29 13:37:39: [2024-10-29 13:37:39] iter = 01800, loss = 0.9887
2024-10-29 13:37:39: [2024-10-29 13:37:39] iter = 01810, loss = 1.0846
2024-10-29 13:37:39: [2024-10-29 13:37:39] iter = 01820, loss = 1.1352
2024-10-29 13:37:39: [2024-10-29 13:37:39] iter = 01830, loss = 1.2707
2024-10-29 13:37:40: [2024-10-29 13:37:40] iter = 01840, loss = 2.2480
2024-10-29 13:37:40: [2024-10-29 13:37:40] iter = 01850, loss = 1.3456
2024-10-29 13:37:40: [2024-10-29 13:37:40] iter = 01860, loss = 8.0283
2024-10-29 13:37:40: [2024-10-29 13:37:40] iter = 01870, loss = 1.4584
2024-10-29 13:37:41: [2024-10-29 13:37:41] iter = 01880, loss = 6.9069
2024-10-29 13:37:41: [2024-10-29 13:37:41] iter = 01890, loss = 1.5608
2024-10-29 13:37:41: [2024-10-29 13:37:41] iter = 01900, loss = 2.6236
2024-10-29 13:37:42: [2024-10-29 13:37:42] iter = 01910, loss = 2.2704
2024-10-29 13:37:42: [2024-10-29 13:37:42] iter = 01920, loss = 1.7614
2024-10-29 13:37:42: [2024-10-29 13:37:42] iter = 01930, loss = 2.4545
2024-10-29 13:37:43: [2024-10-29 13:37:43] iter = 01940, loss = 1.7485
2024-10-29 13:37:43: [2024-10-29 13:37:43] iter = 01950, loss = 1.9035
2024-10-29 13:37:43: [2024-10-29 13:37:43] iter = 01960, loss = 1.0061
2024-10-29 13:37:44: [2024-10-29 13:37:44] iter = 01970, loss = 1.6823
2024-10-29 13:37:44: [2024-10-29 13:37:44] iter = 01980, loss = 2.3847
2024-10-29 13:37:44: [2024-10-29 13:37:44] iter = 01990, loss = 2.1815
2024-10-29 13:37:44: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 13:37:44: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:37:44: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 64914}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:38:08: Evaluate 5 random ConvNet, ACCmean = 0.5767 ACCstd = 0.0090
-------------------------
2024-10-29 13:38:08: Evaluate 5 random ConvNet, SENmean = 0.6049 SENstd = 0.0020
-------------------------
2024-10-29 13:38:08: Evaluate 5 random ConvNet, SPEmean = 0.6049 SPEstd = 0.0020
-------------------------
2024-10-29 13:38:08: Evaluate 5 random ConvNet, F!mean = 0.4759 F!std = 0.0046
-------------------------
2024-10-29 13:38:08: Evaluate 5 random ConvNet, mean = 0.5767 std = 0.0090
-------------------------
2024-10-29 13:38:08: [2024-10-29 13:38:08] iter = 02000, loss = 1.3495
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:38:08: [2024-10-29 13:38:08] iter = 02010, loss = 1.1276
2024-10-29 13:38:08: [2024-10-29 13:38:08] iter = 02020, loss = 1.1463
2024-10-29 13:38:09: [2024-10-29 13:38:09] iter = 02030, loss = 1.0474
2024-10-29 13:38:09: [2024-10-29 13:38:09] iter = 02040, loss = 1.6866
2024-10-29 13:38:09: [2024-10-29 13:38:09] iter = 02050, loss = 1.0789
2024-10-29 13:38:10: [2024-10-29 13:38:10] iter = 02060, loss = 3.7387
2024-10-29 13:38:10: [2024-10-29 13:38:10] iter = 02070, loss = 1.5405
2024-10-29 13:38:10: [2024-10-29 13:38:10] iter = 02080, loss = 1.2437
2024-10-29 13:38:10: [2024-10-29 13:38:10] iter = 02090, loss = 1.3446
2024-10-29 13:38:11: [2024-10-29 13:38:11] iter = 02100, loss = 1.3814
2024-10-29 13:38:11: [2024-10-29 13:38:11] iter = 02110, loss = 2.2130
2024-10-29 13:38:11: [2024-10-29 13:38:11] iter = 02120, loss = 1.7461
2024-10-29 13:38:12: [2024-10-29 13:38:12] iter = 02130, loss = 1.5805
2024-10-29 13:38:12: [2024-10-29 13:38:12] iter = 02140, loss = 2.8055
2024-10-29 13:38:12: [2024-10-29 13:38:12] iter = 02150, loss = 2.2547
2024-10-29 13:38:13: [2024-10-29 13:38:13] iter = 02160, loss = 2.2033
2024-10-29 13:38:13: [2024-10-29 13:38:13] iter = 02170, loss = 1.3631
2024-10-29 13:38:13: [2024-10-29 13:38:13] iter = 02180, loss = 1.4041
2024-10-29 13:38:14: [2024-10-29 13:38:14] iter = 02190, loss = 1.4322
2024-10-29 13:38:14: [2024-10-29 13:38:14] iter = 02200, loss = 1.2032
2024-10-29 13:38:14: [2024-10-29 13:38:14] iter = 02210, loss = 1.7977
2024-10-29 13:38:15: [2024-10-29 13:38:15] iter = 02220, loss = 1.2738
2024-10-29 13:38:15: [2024-10-29 13:38:15] iter = 02230, loss = 0.9416
2024-10-29 13:38:15: [2024-10-29 13:38:15] iter = 02240, loss = 9.0019
2024-10-29 13:38:15: [2024-10-29 13:38:15] iter = 02250, loss = 2.0213
2024-10-29 13:38:16: [2024-10-29 13:38:16] iter = 02260, loss = 2.5479
2024-10-29 13:38:16: [2024-10-29 13:38:16] iter = 02270, loss = 1.2947
2024-10-29 13:38:16: [2024-10-29 13:38:16] iter = 02280, loss = 1.1451
2024-10-29 13:38:17: [2024-10-29 13:38:16] iter = 02290, loss = 1.8891
2024-10-29 13:38:17: [2024-10-29 13:38:17] iter = 02300, loss = 1.5271
2024-10-29 13:38:17: [2024-10-29 13:38:17] iter = 02310, loss = 1.1780
2024-10-29 13:38:17: [2024-10-29 13:38:17] iter = 02320, loss = 1.4180
2024-10-29 13:38:18: [2024-10-29 13:38:18] iter = 02330, loss = 0.9015
2024-10-29 13:38:18: [2024-10-29 13:38:18] iter = 02340, loss = 1.4673
2024-10-29 13:38:18: [2024-10-29 13:38:18] iter = 02350, loss = 1.8673
2024-10-29 13:38:19: [2024-10-29 13:38:19] iter = 02360, loss = 2.2145
2024-10-29 13:38:19: [2024-10-29 13:38:19] iter = 02370, loss = 1.3329
2024-10-29 13:38:19: [2024-10-29 13:38:19] iter = 02380, loss = 1.6491
2024-10-29 13:38:20: [2024-10-29 13:38:20] iter = 02390, loss = 1.2690
2024-10-29 13:38:20: [2024-10-29 13:38:20] iter = 02400, loss = 2.1991
2024-10-29 13:38:20: [2024-10-29 13:38:20] iter = 02410, loss = 1.7668
2024-10-29 13:38:21: [2024-10-29 13:38:21] iter = 02420, loss = 4.6147
2024-10-29 13:38:21: [2024-10-29 13:38:21] iter = 02430, loss = 1.2187
2024-10-29 13:38:21: [2024-10-29 13:38:21] iter = 02440, loss = 0.9890
2024-10-29 13:38:21: [2024-10-29 13:38:21] iter = 02450, loss = 3.9635
2024-10-29 13:38:22: [2024-10-29 13:38:22] iter = 02460, loss = 1.6086
2024-10-29 13:38:22: [2024-10-29 13:38:22] iter = 02470, loss = 1.5792
2024-10-29 13:38:22: [2024-10-29 13:38:22] iter = 02480, loss = 1.5742
2024-10-29 13:38:23: [2024-10-29 13:38:23] iter = 02490, loss = 2.0121
2024-10-29 13:38:23: [2024-10-29 13:38:23] iter = 02500, loss = 1.5171
2024-10-29 13:38:23: [2024-10-29 13:38:23] iter = 02510, loss = 1.4623
2024-10-29 13:38:24: [2024-10-29 13:38:24] iter = 02520, loss = 1.3364
2024-10-29 13:38:24: [2024-10-29 13:38:24] iter = 02530, loss = 1.2913
2024-10-29 13:38:24: [2024-10-29 13:38:24] iter = 02540, loss = 1.5612
2024-10-29 13:38:24: [2024-10-29 13:38:24] iter = 02550, loss = 1.6539
2024-10-29 13:38:25: [2024-10-29 13:38:25] iter = 02560, loss = 4.1131
2024-10-29 13:38:25: [2024-10-29 13:38:25] iter = 02570, loss = 1.5699
2024-10-29 13:38:25: [2024-10-29 13:38:25] iter = 02580, loss = 1.8190
2024-10-29 13:38:25: [2024-10-29 13:38:25] iter = 02590, loss = 2.1036
2024-10-29 13:38:26: [2024-10-29 13:38:26] iter = 02600, loss = 5.1395
2024-10-29 13:38:26: [2024-10-29 13:38:26] iter = 02610, loss = 0.8657
2024-10-29 13:38:26: [2024-10-29 13:38:26] iter = 02620, loss = 0.9701
2024-10-29 13:38:27: [2024-10-29 13:38:27] iter = 02630, loss = 1.8950
2024-10-29 13:38:27: [2024-10-29 13:38:27] iter = 02640, loss = 0.9400
2024-10-29 13:38:27: [2024-10-29 13:38:27] iter = 02650, loss = 1.9212
2024-10-29 13:38:27: [2024-10-29 13:38:27] iter = 02660, loss = 1.5483
2024-10-29 13:38:28: [2024-10-29 13:38:28] iter = 02670, loss = 0.8797
2024-10-29 13:38:28: [2024-10-29 13:38:28] iter = 02680, loss = 1.2562
2024-10-29 13:38:28: [2024-10-29 13:38:28] iter = 02690, loss = 6.8424
2024-10-29 13:38:29: [2024-10-29 13:38:29] iter = 02700, loss = 1.4748
2024-10-29 13:38:29: [2024-10-29 13:38:29] iter = 02710, loss = 1.1686
2024-10-29 13:38:29: [2024-10-29 13:38:29] iter = 02720, loss = 1.1007
2024-10-29 13:38:30: [2024-10-29 13:38:30] iter = 02730, loss = 5.5274
2024-10-29 13:38:30: [2024-10-29 13:38:30] iter = 02740, loss = 5.0563
2024-10-29 13:38:30: [2024-10-29 13:38:30] iter = 02750, loss = 1.3593
2024-10-29 13:38:31: [2024-10-29 13:38:31] iter = 02760, loss = 1.2789
2024-10-29 13:38:31: [2024-10-29 13:38:31] iter = 02770, loss = 4.4636
2024-10-29 13:38:31: [2024-10-29 13:38:31] iter = 02780, loss = 0.8790
2024-10-29 13:38:32: [2024-10-29 13:38:32] iter = 02790, loss = 1.1959
2024-10-29 13:38:32: [2024-10-29 13:38:32] iter = 02800, loss = 0.8947
2024-10-29 13:38:33: [2024-10-29 13:38:33] iter = 02810, loss = 2.2014
2024-10-29 13:38:33: [2024-10-29 13:38:33] iter = 02820, loss = 1.4265
2024-10-29 13:38:33: [2024-10-29 13:38:33] iter = 02830, loss = 1.1130
2024-10-29 13:38:34: [2024-10-29 13:38:34] iter = 02840, loss = 6.5922
2024-10-29 13:38:34: [2024-10-29 13:38:34] iter = 02850, loss = 1.1646
2024-10-29 13:38:34: [2024-10-29 13:38:34] iter = 02860, loss = 0.9602
2024-10-29 13:38:34: [2024-10-29 13:38:34] iter = 02870, loss = 1.4948
2024-10-29 13:38:35: [2024-10-29 13:38:35] iter = 02880, loss = 0.9760
2024-10-29 13:38:35: [2024-10-29 13:38:35] iter = 02890, loss = 1.3731
2024-10-29 13:38:35: [2024-10-29 13:38:35] iter = 02900, loss = 1.4144
2024-10-29 13:38:36: [2024-10-29 13:38:36] iter = 02910, loss = 0.9017
2024-10-29 13:38:36: [2024-10-29 13:38:36] iter = 02920, loss = 1.8865
2024-10-29 13:38:36: [2024-10-29 13:38:36] iter = 02930, loss = 1.6706
2024-10-29 13:38:37: [2024-10-29 13:38:37] iter = 02940, loss = 1.7351
2024-10-29 13:38:37: [2024-10-29 13:38:37] iter = 02950, loss = 1.0414
2024-10-29 13:38:37: [2024-10-29 13:38:37] iter = 02960, loss = 1.4949
2024-10-29 13:38:37: [2024-10-29 13:38:37] iter = 02970, loss = 1.1420
2024-10-29 13:38:38: [2024-10-29 13:38:38] iter = 02980, loss = 1.2441
2024-10-29 13:38:38: [2024-10-29 13:38:38] iter = 02990, loss = 7.5227
2024-10-29 13:38:38: [2024-10-29 13:38:38] iter = 03000, loss = 1.0519
2024-10-29 13:38:39: [2024-10-29 13:38:39] iter = 03010, loss = 2.2397
2024-10-29 13:38:39: [2024-10-29 13:38:39] iter = 03020, loss = 0.8697
2024-10-29 13:38:39: [2024-10-29 13:38:39] iter = 03030, loss = 2.8671
2024-10-29 13:38:40: [2024-10-29 13:38:40] iter = 03040, loss = 1.3702
2024-10-29 13:38:40: [2024-10-29 13:38:40] iter = 03050, loss = 0.9087
2024-10-29 13:38:40: [2024-10-29 13:38:40] iter = 03060, loss = 1.7675
2024-10-29 13:38:40: [2024-10-29 13:38:40] iter = 03070, loss = 2.1828
2024-10-29 13:38:41: [2024-10-29 13:38:41] iter = 03080, loss = 1.4505
2024-10-29 13:38:41: [2024-10-29 13:38:41] iter = 03090, loss = 1.1003
2024-10-29 13:38:41: [2024-10-29 13:38:41] iter = 03100, loss = 1.7831
2024-10-29 13:38:42: [2024-10-29 13:38:42] iter = 03110, loss = 0.9869
2024-10-29 13:38:42: [2024-10-29 13:38:42] iter = 03120, loss = 1.0510
2024-10-29 13:38:42: [2024-10-29 13:38:42] iter = 03130, loss = 1.5992
2024-10-29 13:38:43: [2024-10-29 13:38:43] iter = 03140, loss = 0.9541
2024-10-29 13:38:43: [2024-10-29 13:38:43] iter = 03150, loss = 1.2951
2024-10-29 13:38:43: [2024-10-29 13:38:43] iter = 03160, loss = 1.4324
2024-10-29 13:38:44: [2024-10-29 13:38:44] iter = 03170, loss = 4.8159
2024-10-29 13:38:44: [2024-10-29 13:38:44] iter = 03180, loss = 1.3903
2024-10-29 13:38:44: [2024-10-29 13:38:44] iter = 03190, loss = 6.0078
2024-10-29 13:38:45: [2024-10-29 13:38:45] iter = 03200, loss = 2.0999
2024-10-29 13:38:45: [2024-10-29 13:38:45] iter = 03210, loss = 1.9007
2024-10-29 13:38:45: [2024-10-29 13:38:45] iter = 03220, loss = 0.9909
2024-10-29 13:38:45: [2024-10-29 13:38:45] iter = 03230, loss = 1.2125
2024-10-29 13:38:46: [2024-10-29 13:38:46] iter = 03240, loss = 1.7208
2024-10-29 13:38:46: [2024-10-29 13:38:46] iter = 03250, loss = 1.3422
2024-10-29 13:38:46: [2024-10-29 13:38:46] iter = 03260, loss = 2.7340
2024-10-29 13:38:46: [2024-10-29 13:38:46] iter = 03270, loss = 0.7284
2024-10-29 13:38:47: [2024-10-29 13:38:47] iter = 03280, loss = 1.3850
2024-10-29 13:38:47: [2024-10-29 13:38:47] iter = 03290, loss = 1.3893
2024-10-29 13:38:47: [2024-10-29 13:38:47] iter = 03300, loss = 1.2743
2024-10-29 13:38:47: [2024-10-29 13:38:47] iter = 03310, loss = 1.8511
2024-10-29 13:38:48: [2024-10-29 13:38:48] iter = 03320, loss = 2.4238
2024-10-29 13:38:48: [2024-10-29 13:38:48] iter = 03330, loss = 1.5168
2024-10-29 13:38:48: [2024-10-29 13:38:48] iter = 03340, loss = 2.0702
2024-10-29 13:38:49: [2024-10-29 13:38:49] iter = 03350, loss = 2.3028
2024-10-29 13:38:49: [2024-10-29 13:38:49] iter = 03360, loss = 1.9110
2024-10-29 13:38:49: [2024-10-29 13:38:49] iter = 03370, loss = 3.6209
2024-10-29 13:38:50: [2024-10-29 13:38:50] iter = 03380, loss = 1.2373
2024-10-29 13:38:50: [2024-10-29 13:38:50] iter = 03390, loss = 1.2803
2024-10-29 13:38:50: [2024-10-29 13:38:50] iter = 03400, loss = 5.3237
2024-10-29 13:38:51: [2024-10-29 13:38:51] iter = 03410, loss = 1.6507
2024-10-29 13:38:51: [2024-10-29 13:38:51] iter = 03420, loss = 2.5716
2024-10-29 13:38:51: [2024-10-29 13:38:51] iter = 03430, loss = 1.3721
2024-10-29 13:38:51: [2024-10-29 13:38:51] iter = 03440, loss = 1.8420
2024-10-29 13:38:52: [2024-10-29 13:38:52] iter = 03450, loss = 2.0807
2024-10-29 13:38:52: [2024-10-29 13:38:52] iter = 03460, loss = 2.4311
2024-10-29 13:38:52: [2024-10-29 13:38:52] iter = 03470, loss = 1.3499
2024-10-29 13:38:53: [2024-10-29 13:38:53] iter = 03480, loss = 2.0269
2024-10-29 13:38:53: [2024-10-29 13:38:53] iter = 03490, loss = 0.6409
2024-10-29 13:38:54: [2024-10-29 13:38:54] iter = 03500, loss = 1.8724
2024-10-29 13:38:54: [2024-10-29 13:38:54] iter = 03510, loss = 1.4847
2024-10-29 13:38:54: [2024-10-29 13:38:54] iter = 03520, loss = 1.8717
2024-10-29 13:38:55: [2024-10-29 13:38:55] iter = 03530, loss = 1.1599
2024-10-29 13:38:55: [2024-10-29 13:38:55] iter = 03540, loss = 0.8172
2024-10-29 13:38:55: [2024-10-29 13:38:55] iter = 03550, loss = 1.6224
2024-10-29 13:38:55: [2024-10-29 13:38:55] iter = 03560, loss = 1.6969
2024-10-29 13:38:56: [2024-10-29 13:38:56] iter = 03570, loss = 1.4607
2024-10-29 13:38:56: [2024-10-29 13:38:56] iter = 03580, loss = 1.5105
2024-10-29 13:38:56: [2024-10-29 13:38:56] iter = 03590, loss = 2.1297
2024-10-29 13:38:57: [2024-10-29 13:38:57] iter = 03600, loss = 1.1555
2024-10-29 13:38:57: [2024-10-29 13:38:57] iter = 03610, loss = 3.0500
2024-10-29 13:38:57: [2024-10-29 13:38:57] iter = 03620, loss = 1.2115
2024-10-29 13:38:57: [2024-10-29 13:38:57] iter = 03630, loss = 1.2096
2024-10-29 13:38:58: [2024-10-29 13:38:58] iter = 03640, loss = 1.5415
2024-10-29 13:38:58: [2024-10-29 13:38:58] iter = 03650, loss = 1.3898
2024-10-29 13:38:58: [2024-10-29 13:38:58] iter = 03660, loss = 2.2307
2024-10-29 13:38:58: [2024-10-29 13:38:58] iter = 03670, loss = 1.2961
2024-10-29 13:38:59: [2024-10-29 13:38:59] iter = 03680, loss = 1.9589
2024-10-29 13:38:59: [2024-10-29 13:38:59] iter = 03690, loss = 0.7817
2024-10-29 13:38:59: [2024-10-29 13:38:59] iter = 03700, loss = 1.8718
2024-10-29 13:39:00: [2024-10-29 13:39:00] iter = 03710, loss = 1.0160
2024-10-29 13:39:00: [2024-10-29 13:39:00] iter = 03720, loss = 2.5841
2024-10-29 13:39:00: [2024-10-29 13:39:00] iter = 03730, loss = 2.0382
2024-10-29 13:39:01: [2024-10-29 13:39:01] iter = 03740, loss = 1.0440
2024-10-29 13:39:01: [2024-10-29 13:39:01] iter = 03750, loss = 1.2736
2024-10-29 13:39:01: [2024-10-29 13:39:01] iter = 03760, loss = 0.7905
2024-10-29 13:39:01: [2024-10-29 13:39:01] iter = 03770, loss = 1.5527
2024-10-29 13:39:02: [2024-10-29 13:39:02] iter = 03780, loss = 1.1750
2024-10-29 13:39:02: [2024-10-29 13:39:02] iter = 03790, loss = 2.4725
2024-10-29 13:39:02: [2024-10-29 13:39:02] iter = 03800, loss = 0.9936
2024-10-29 13:39:03: [2024-10-29 13:39:03] iter = 03810, loss = 1.7984
2024-10-29 13:39:03: [2024-10-29 13:39:03] iter = 03820, loss = 0.9244
2024-10-29 13:39:03: [2024-10-29 13:39:03] iter = 03830, loss = 3.0982
2024-10-29 13:39:04: [2024-10-29 13:39:04] iter = 03840, loss = 1.3447
2024-10-29 13:39:04: [2024-10-29 13:39:04] iter = 03850, loss = 4.0461
2024-10-29 13:39:04: [2024-10-29 13:39:04] iter = 03860, loss = 1.3019
2024-10-29 13:39:05: [2024-10-29 13:39:05] iter = 03870, loss = 2.5348
2024-10-29 13:39:05: [2024-10-29 13:39:05] iter = 03880, loss = 1.1306
2024-10-29 13:39:05: [2024-10-29 13:39:05] iter = 03890, loss = 1.3593
2024-10-29 13:39:05: [2024-10-29 13:39:05] iter = 03900, loss = 1.4009
2024-10-29 13:39:06: [2024-10-29 13:39:06] iter = 03910, loss = 0.9933
2024-10-29 13:39:06: [2024-10-29 13:39:06] iter = 03920, loss = 1.3829
2024-10-29 13:39:06: [2024-10-29 13:39:06] iter = 03930, loss = 1.1733
2024-10-29 13:39:06: [2024-10-29 13:39:06] iter = 03940, loss = 1.7610
2024-10-29 13:39:07: [2024-10-29 13:39:07] iter = 03950, loss = 1.3807
2024-10-29 13:39:07: [2024-10-29 13:39:07] iter = 03960, loss = 3.5362
2024-10-29 13:39:07: [2024-10-29 13:39:07] iter = 03970, loss = 1.3408
2024-10-29 13:39:08: [2024-10-29 13:39:08] iter = 03980, loss = 1.4188
2024-10-29 13:39:08: [2024-10-29 13:39:08] iter = 03990, loss = 1.2129
2024-10-29 13:39:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 13:39:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:39:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 48620}

[2024-10-29 13:26:02] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.038894 train acc = 1.0000, test acc = 0.3959, test_sen =0.5672, test_spe =0.5672, test_f1 =0.3632
[2024-10-29 13:26:08] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000724 train acc = 1.0000, test acc = 0.3634, test_sen =0.5600, test_spe =0.5600, test_f1 =0.3399
[2024-10-29 13:26:14] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.004616 train acc = 1.0000, test acc = 0.3879, test_sen =0.5672, test_spe =0.5672, test_f1 =0.3579
[2024-10-29 13:26:19] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.023167 train acc = 1.0000, test acc = 0.4059, test_sen =0.5684, test_spe =0.5684, test_f1 =0.3701
[2024-10-29 13:27:35] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.011641 train acc = 1.0000, test acc = 0.6438, test_sen =0.5760, test_spe =0.5760, test_f1 =0.4986
[2024-10-29 13:27:42] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.000866 train acc = 1.0000, test acc = 0.6550, test_sen =0.5758, test_spe =0.5758, test_f1 =0.5034
[2024-10-29 13:27:47] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.014708 train acc = 1.0000, test acc = 0.6737, test_sen =0.5795, test_spe =0.5795, test_f1 =0.5129
[2024-10-29 13:27:53] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002442 train acc = 1.0000, test acc = 0.6349, test_sen =0.5776, test_spe =0.5776, test_f1 =0.4952
[2024-10-29 13:27:58] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.011400 train acc = 1.0000, test acc = 0.6289, test_sen =0.5851, test_spe =0.5851, test_f1 =0.4951
[2024-10-29 13:29:19] Evaluate_00: epoch = 1000 train time = 7 s train loss = 0.028977 train acc = 1.0000, test acc = 0.5039, test_sen =0.5921, test_spe =0.5921, test_f1 =0.4338
[2024-10-29 13:29:24] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004748 train acc = 1.0000, test acc = 0.5203, test_sen =0.5982, test_spe =0.5982, test_f1 =0.4443
[2024-10-29 13:29:30] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.005151 train acc = 1.0000, test acc = 0.5008, test_sen =0.6074, test_spe =0.6074, test_f1 =0.4354
[2024-10-29 13:29:36] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001609 train acc = 1.0000, test acc = 0.5160, test_sen =0.6067, test_spe =0.6067, test_f1 =0.4438
[2024-10-29 13:29:42] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.006982 train acc = 1.0000, test acc = 0.4966, test_sen =0.6009, test_spe =0.6009, test_f1 =0.4316
[2024-10-29 13:31:01] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.317232 train acc = 0.9000, test acc = 0.6459, test_sen =0.6106, test_spe =0.6106, test_f1 =0.5120
[2024-10-29 13:31:06] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.005051 train acc = 1.0000, test acc = 0.6280, test_sen =0.6112, test_spe =0.6112, test_f1 =0.5035
[2024-10-29 13:31:11] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.068541 train acc = 1.0000, test acc = 0.6454, test_sen =0.6069, test_spe =0.6069, test_f1 =0.5105
[2024-10-29 13:31:17] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.007711 train acc = 1.0000, test acc = 0.6490, test_sen =0.6107, test_spe =0.6107, test_f1 =0.5135
[2024-10-29 13:31:22] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.006945 train acc = 1.0000, test acc = 0.6347, test_sen =0.6135, test_spe =0.6135, test_f1 =0.5075
[2024-10-29 13:32:41] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.043146 train acc = 1.0000, test acc = 0.7540, test_sen =0.5690, test_spe =0.5690, test_f1 =0.5399
[2024-10-29 13:32:48] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002397 train acc = 1.0000, test acc = 0.7526, test_sen =0.5698, test_spe =0.5698, test_f1 =0.5398
[2024-10-29 13:32:54] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.131590 train acc = 0.9500, test acc = 0.7423, test_sen =0.5702, test_spe =0.5702, test_f1 =0.5362
[2024-10-29 13:33:00] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.028012 train acc = 1.0000, test acc = 0.7712, test_sen =0.5659, test_spe =0.5659, test_f1 =0.5444
[2024-10-29 13:33:05] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.004071 train acc = 1.0000, test acc = 0.7580, test_sen =0.5694, test_spe =0.5694, test_f1 =0.5416
[2024-10-29 13:34:23] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.041330 train acc = 1.0000, test acc = 0.7113, test_sen =0.5923, test_spe =0.5923, test_f1 =0.5345
[2024-10-29 13:34:29] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004757 train acc = 1.0000, test acc = 0.6893, test_sen =0.5935, test_spe =0.5935, test_f1 =0.5254
[2024-10-29 13:34:34] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.007489 train acc = 1.0000, test acc = 0.6873, test_sen =0.5883, test_spe =0.5883, test_f1 =0.5224
[2024-10-29 13:34:39] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.009197 train acc = 1.0000, test acc = 0.6967, test_sen =0.5818, test_spe =0.5818, test_f1 =0.5236
[2024-10-29 13:34:45] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.051954 train acc = 1.0000, test acc = 0.6895, test_sen =0.5857, test_spe =0.5857, test_f1 =0.5222
[2024-10-29 13:35:58] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002754 train acc = 1.0000, test acc = 0.5011, test_sen =0.5974, test_spe =0.5974, test_f1 =0.4334
[2024-10-29 13:36:03] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.014674 train acc = 1.0000, test acc = 0.4972, test_sen =0.5936, test_spe =0.5936, test_f1 =0.4303
[2024-10-29 13:36:08] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.021095 train acc = 1.0000, test acc = 0.4614, test_sen =0.5964, test_spe =0.5964, test_f1 =0.4098
[2024-10-29 13:36:13] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.007197 train acc = 1.0000, test acc = 0.5123, test_sen =0.5942, test_spe =0.5942, test_f1 =0.4390
[2024-10-29 13:36:18] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.004950 train acc = 1.0000, test acc = 0.4994, test_sen =0.6038, test_spe =0.6038, test_f1 =0.4338
[2024-10-29 13:36:26] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002003 train acc = 1.0000, test acc = 0.3297, test_sen =0.4549, test_spe =0.4549, test_f1 =0.3026
[2024-10-29 13:36:31] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.007304 train acc = 1.0000, test acc = 0.3382, test_sen =0.4476, test_spe =0.4476, test_f1 =0.3072
[2024-10-29 13:36:36] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.005213 train acc = 1.0000, test acc = 0.3157, test_sen =0.4494, test_spe =0.4494, test_f1 =0.2923
[2024-10-29 13:36:41] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.008405 train acc = 1.0000, test acc = 0.3239, test_sen =0.4569, test_spe =0.4569, test_f1 =0.2989
[2024-10-29 13:36:45] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.017439 train acc = 1.0000, test acc = 0.3073, test_sen =0.4461, test_spe =0.4461, test_f1 =0.2859
[2024-10-29 13:37:49] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001638 train acc = 1.0000, test acc = 0.5816, test_sen =0.6075, test_spe =0.6075, test_f1 =0.4792
[2024-10-29 13:37:54] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.000749 train acc = 1.0000, test acc = 0.5700, test_sen =0.6026, test_spe =0.6026, test_f1 =0.4719
[2024-10-29 13:37:58] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002791 train acc = 1.0000, test acc = 0.5912, test_sen =0.6027, test_spe =0.6027, test_f1 =0.4827
[2024-10-29 13:38:03] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.006172 train acc = 1.0000, test acc = 0.5750, test_sen =0.6069, test_spe =0.6069, test_f1 =0.4756
[2024-10-29 13:38:08] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.039224 train acc = 1.0000, test acc = 0.5656, test_sen =0.6047, test_spe =0.6047, test_f1 =0.4702
[2024-10-29 13:39:13] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.057992 train acc = 1.0000, test acc = 0.6889, test_sen =0.5883, test_spe =0.5883, test_f1 =0.5231
[2024-10-29 13:39:18] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.085063 train acc = 0.9500, test acc = 0.7036, test_sen =0.5885, test_spe =0.5885, test_f1 =0.5295
[2024-10-29 13:39:23] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.028403 train acc = 1.0000, test acc = 0.7119, test_sen =0.5823, test_spe =0.5823, test_f1 =0.5302/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:39:33: Evaluate 5 random ConvNet, ACCmean = 0.7048 ACCstd = 0.0163
-------------------------
2024-10-29 13:39:33: Evaluate 5 random ConvNet, SENmean = 0.5844 SENstd = 0.0074
-------------------------
2024-10-29 13:39:33: Evaluate 5 random ConvNet, SPEmean = 0.5844 SPEstd = 0.0074
-------------------------
2024-10-29 13:39:33: Evaluate 5 random ConvNet, F!mean = 0.5279 F!std = 0.0037
-------------------------
2024-10-29 13:39:33: Evaluate 5 random ConvNet, mean = 0.7048 std = 0.0163
-------------------------
2024-10-29 13:39:33: [2024-10-29 13:39:33] iter = 04000, loss = 1.4103
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:39:33: [2024-10-29 13:39:33] iter = 04010, loss = 4.3813
2024-10-29 13:39:34: [2024-10-29 13:39:34] iter = 04020, loss = 0.8914
2024-10-29 13:39:34: [2024-10-29 13:39:34] iter = 04030, loss = 1.1536
2024-10-29 13:39:35: [2024-10-29 13:39:34] iter = 04040, loss = 1.4044
2024-10-29 13:39:35: [2024-10-29 13:39:35] iter = 04050, loss = 2.2631
2024-10-29 13:39:35: [2024-10-29 13:39:35] iter = 04060, loss = 1.1582
2024-10-29 13:39:36: [2024-10-29 13:39:35] iter = 04070, loss = 1.4361
2024-10-29 13:39:36: [2024-10-29 13:39:36] iter = 04080, loss = 4.8867
2024-10-29 13:39:36: [2024-10-29 13:39:36] iter = 04090, loss = 0.8385
2024-10-29 13:39:37: [2024-10-29 13:39:36] iter = 04100, loss = 0.9884
2024-10-29 13:39:37: [2024-10-29 13:39:37] iter = 04110, loss = 0.9474
2024-10-29 13:39:37: [2024-10-29 13:39:37] iter = 04120, loss = 1.0493
2024-10-29 13:39:38: [2024-10-29 13:39:38] iter = 04130, loss = 1.6531
2024-10-29 13:39:38: [2024-10-29 13:39:38] iter = 04140, loss = 0.9736
2024-10-29 13:39:38: [2024-10-29 13:39:38] iter = 04150, loss = 2.8990
2024-10-29 13:39:38: [2024-10-29 13:39:38] iter = 04160, loss = 1.4831
2024-10-29 13:39:39: [2024-10-29 13:39:39] iter = 04170, loss = 1.3941
2024-10-29 13:39:39: [2024-10-29 13:39:39] iter = 04180, loss = 2.7429
2024-10-29 13:39:39: [2024-10-29 13:39:39] iter = 04190, loss = 1.8446
2024-10-29 13:39:39: [2024-10-29 13:39:39] iter = 04200, loss = 3.0166
2024-10-29 13:39:40: [2024-10-29 13:39:40] iter = 04210, loss = 1.3894
2024-10-29 13:39:40: [2024-10-29 13:39:40] iter = 04220, loss = 1.4663
2024-10-29 13:39:40: [2024-10-29 13:39:40] iter = 04230, loss = 0.9929
2024-10-29 13:39:41: [2024-10-29 13:39:41] iter = 04240, loss = 2.2478
2024-10-29 13:39:41: [2024-10-29 13:39:41] iter = 04250, loss = 0.8063
2024-10-29 13:39:41: [2024-10-29 13:39:41] iter = 04260, loss = 1.2799
2024-10-29 13:39:41: [2024-10-29 13:39:41] iter = 04270, loss = 1.7856
2024-10-29 13:39:42: [2024-10-29 13:39:42] iter = 04280, loss = 1.9084
2024-10-29 13:39:42: [2024-10-29 13:39:42] iter = 04290, loss = 0.7893
2024-10-29 13:39:42: [2024-10-29 13:39:42] iter = 04300, loss = 1.9693
2024-10-29 13:39:43: [2024-10-29 13:39:43] iter = 04310, loss = 1.4894
2024-10-29 13:39:43: [2024-10-29 13:39:43] iter = 04320, loss = 1.4574
2024-10-29 13:39:43: [2024-10-29 13:39:43] iter = 04330, loss = 1.4563
2024-10-29 13:39:44: [2024-10-29 13:39:44] iter = 04340, loss = 1.1001
2024-10-29 13:39:44: [2024-10-29 13:39:44] iter = 04350, loss = 0.8917
2024-10-29 13:39:44: [2024-10-29 13:39:44] iter = 04360, loss = 1.6608
2024-10-29 13:39:44: [2024-10-29 13:39:44] iter = 04370, loss = 1.6846
2024-10-29 13:39:45: [2024-10-29 13:39:45] iter = 04380, loss = 1.5854
2024-10-29 13:39:45: [2024-10-29 13:39:45] iter = 04390, loss = 1.4129
2024-10-29 13:39:45: [2024-10-29 13:39:45] iter = 04400, loss = 1.9618
2024-10-29 13:39:45: [2024-10-29 13:39:45] iter = 04410, loss = 1.6912
2024-10-29 13:39:45: [2024-10-29 13:39:45] iter = 04420, loss = 0.9164
2024-10-29 13:39:46: [2024-10-29 13:39:46] iter = 04430, loss = 1.1997
2024-10-29 13:39:46: [2024-10-29 13:39:46] iter = 04440, loss = 1.1655
2024-10-29 13:39:46: [2024-10-29 13:39:46] iter = 04450, loss = 0.6013
2024-10-29 13:39:46: [2024-10-29 13:39:46] iter = 04460, loss = 5.6766
2024-10-29 13:39:47: [2024-10-29 13:39:47] iter = 04470, loss = 0.7792
2024-10-29 13:39:47: [2024-10-29 13:39:47] iter = 04480, loss = 1.5574
2024-10-29 13:39:47: [2024-10-29 13:39:47] iter = 04490, loss = 1.2776
2024-10-29 13:39:47: [2024-10-29 13:39:47] iter = 04500, loss = 3.1614
2024-10-29 13:39:48: [2024-10-29 13:39:48] iter = 04510, loss = 1.5647
2024-10-29 13:39:48: [2024-10-29 13:39:48] iter = 04520, loss = 4.2868
2024-10-29 13:39:48: [2024-10-29 13:39:48] iter = 04530, loss = 1.5069
2024-10-29 13:39:48: [2024-10-29 13:39:48] iter = 04540, loss = 2.0685
2024-10-29 13:39:49: [2024-10-29 13:39:49] iter = 04550, loss = 0.7914
2024-10-29 13:39:49: [2024-10-29 13:39:49] iter = 04560, loss = 1.3081
2024-10-29 13:39:49: [2024-10-29 13:39:49] iter = 04570, loss = 0.9569
2024-10-29 13:39:49: [2024-10-29 13:39:49] iter = 04580, loss = 1.0581
2024-10-29 13:39:50: [2024-10-29 13:39:50] iter = 04590, loss = 1.4872
2024-10-29 13:39:50: [2024-10-29 13:39:50] iter = 04600, loss = 0.7729
2024-10-29 13:39:50: [2024-10-29 13:39:50] iter = 04610, loss = 2.7101
2024-10-29 13:39:50: [2024-10-29 13:39:50] iter = 04620, loss = 2.7353
2024-10-29 13:39:51: [2024-10-29 13:39:51] iter = 04630, loss = 0.8682
2024-10-29 13:39:51: [2024-10-29 13:39:51] iter = 04640, loss = 1.6852
2024-10-29 13:39:51: [2024-10-29 13:39:51] iter = 04650, loss = 1.4439
2024-10-29 13:39:52: [2024-10-29 13:39:52] iter = 04660, loss = 2.0194
2024-10-29 13:39:52: [2024-10-29 13:39:52] iter = 04670, loss = 1.8132
2024-10-29 13:39:52: [2024-10-29 13:39:52] iter = 04680, loss = 1.2741
2024-10-29 13:39:52: [2024-10-29 13:39:52] iter = 04690, loss = 1.2344
2024-10-29 13:39:53: [2024-10-29 13:39:53] iter = 04700, loss = 1.2057
2024-10-29 13:39:53: [2024-10-29 13:39:53] iter = 04710, loss = 2.4212
2024-10-29 13:39:53: [2024-10-29 13:39:53] iter = 04720, loss = 1.8005
2024-10-29 13:39:54: [2024-10-29 13:39:54] iter = 04730, loss = 1.0528
2024-10-29 13:39:54: [2024-10-29 13:39:54] iter = 04740, loss = 1.1530
2024-10-29 13:39:54: [2024-10-29 13:39:54] iter = 04750, loss = 1.0700
2024-10-29 13:39:54: [2024-10-29 13:39:54] iter = 04760, loss = 0.8742
2024-10-29 13:39:54: [2024-10-29 13:39:54] iter = 04770, loss = 3.1560
2024-10-29 13:39:55: [2024-10-29 13:39:55] iter = 04780, loss = 1.1091
2024-10-29 13:39:55: [2024-10-29 13:39:55] iter = 04790, loss = 1.6112
2024-10-29 13:39:55: [2024-10-29 13:39:55] iter = 04800, loss = 1.3090
2024-10-29 13:39:55: [2024-10-29 13:39:55] iter = 04810, loss = 3.3141
2024-10-29 13:39:56: [2024-10-29 13:39:56] iter = 04820, loss = 1.9942
2024-10-29 13:39:56: [2024-10-29 13:39:56] iter = 04830, loss = 1.7026
2024-10-29 13:39:56: [2024-10-29 13:39:56] iter = 04840, loss = 1.3606
2024-10-29 13:39:56: [2024-10-29 13:39:56] iter = 04850, loss = 8.4274
2024-10-29 13:39:57: [2024-10-29 13:39:57] iter = 04860, loss = 0.9363
2024-10-29 13:39:57: [2024-10-29 13:39:57] iter = 04870, loss = 1.6866
2024-10-29 13:39:57: [2024-10-29 13:39:57] iter = 04880, loss = 1.6039
2024-10-29 13:39:57: [2024-10-29 13:39:57] iter = 04890, loss = 3.7452
2024-10-29 13:39:58: [2024-10-29 13:39:58] iter = 04900, loss = 1.5805
2024-10-29 13:39:58: [2024-10-29 13:39:58] iter = 04910, loss = 2.4075
2024-10-29 13:39:58: [2024-10-29 13:39:58] iter = 04920, loss = 1.7252
2024-10-29 13:39:59: [2024-10-29 13:39:59] iter = 04930, loss = 2.2998
2024-10-29 13:39:59: [2024-10-29 13:39:59] iter = 04940, loss = 2.1062
2024-10-29 13:39:59: [2024-10-29 13:39:59] iter = 04950, loss = 1.3049
2024-10-29 13:40:00: [2024-10-29 13:40:00] iter = 04960, loss = 1.9186
2024-10-29 13:40:00: [2024-10-29 13:40:00] iter = 04970, loss = 1.9654
2024-10-29 13:40:00: [2024-10-29 13:40:00] iter = 04980, loss = 1.1602
2024-10-29 13:40:00: [2024-10-29 13:40:00] iter = 04990, loss = 1.4952
2024-10-29 13:40:01: [2024-10-29 13:40:00] iter = 05000, loss = 0.8434
2024-10-29 13:40:01: [2024-10-29 13:40:01] iter = 05010, loss = 4.7948
2024-10-29 13:40:01: [2024-10-29 13:40:01] iter = 05020, loss = 2.2225
2024-10-29 13:40:01: [2024-10-29 13:40:01] iter = 05030, loss = 1.0159
2024-10-29 13:40:02: [2024-10-29 13:40:02] iter = 05040, loss = 1.6933
2024-10-29 13:40:02: [2024-10-29 13:40:02] iter = 05050, loss = 1.5879
2024-10-29 13:40:02: [2024-10-29 13:40:02] iter = 05060, loss = 1.6391
2024-10-29 13:40:02: [2024-10-29 13:40:02] iter = 05070, loss = 1.0527
2024-10-29 13:40:03: [2024-10-29 13:40:03] iter = 05080, loss = 1.8434
2024-10-29 13:40:03: [2024-10-29 13:40:03] iter = 05090, loss = 1.2743
2024-10-29 13:40:03: [2024-10-29 13:40:03] iter = 05100, loss = 4.8421
2024-10-29 13:40:03: [2024-10-29 13:40:03] iter = 05110, loss = 4.7801
2024-10-29 13:40:04: [2024-10-29 13:40:04] iter = 05120, loss = 1.3595
2024-10-29 13:40:04: [2024-10-29 13:40:04] iter = 05130, loss = 1.3101
2024-10-29 13:40:04: [2024-10-29 13:40:04] iter = 05140, loss = 1.3167
2024-10-29 13:40:05: [2024-10-29 13:40:05] iter = 05150, loss = 0.6628
2024-10-29 13:40:05: [2024-10-29 13:40:05] iter = 05160, loss = 1.4290
2024-10-29 13:40:05: [2024-10-29 13:40:05] iter = 05170, loss = 3.3503
2024-10-29 13:40:05: [2024-10-29 13:40:05] iter = 05180, loss = 2.1291
2024-10-29 13:40:06: [2024-10-29 13:40:06] iter = 05190, loss = 2.2133
2024-10-29 13:40:06: [2024-10-29 13:40:06] iter = 05200, loss = 1.0254
2024-10-29 13:40:06: [2024-10-29 13:40:06] iter = 05210, loss = 1.6670
2024-10-29 13:40:06: [2024-10-29 13:40:06] iter = 05220, loss = 0.8769
2024-10-29 13:40:07: [2024-10-29 13:40:07] iter = 05230, loss = 4.1326
2024-10-29 13:40:07: [2024-10-29 13:40:07] iter = 05240, loss = 1.3478
2024-10-29 13:40:07: [2024-10-29 13:40:07] iter = 05250, loss = 1.4586
2024-10-29 13:40:08: [2024-10-29 13:40:08] iter = 05260, loss = 1.0028
2024-10-29 13:40:08: [2024-10-29 13:40:08] iter = 05270, loss = 1.2280
2024-10-29 13:40:08: [2024-10-29 13:40:08] iter = 05280, loss = 1.0487
2024-10-29 13:40:09: [2024-10-29 13:40:09] iter = 05290, loss = 1.0221
2024-10-29 13:40:09: [2024-10-29 13:40:09] iter = 05300, loss = 1.1881
2024-10-29 13:40:09: [2024-10-29 13:40:09] iter = 05310, loss = 3.1461
2024-10-29 13:40:10: [2024-10-29 13:40:10] iter = 05320, loss = 1.2067
2024-10-29 13:40:10: [2024-10-29 13:40:10] iter = 05330, loss = 1.2556
2024-10-29 13:40:10: [2024-10-29 13:40:10] iter = 05340, loss = 1.0414
2024-10-29 13:40:10: [2024-10-29 13:40:10] iter = 05350, loss = 2.0900
2024-10-29 13:40:11: [2024-10-29 13:40:11] iter = 05360, loss = 0.9348
2024-10-29 13:40:11: [2024-10-29 13:40:11] iter = 05370, loss = 1.1178
2024-10-29 13:40:11: [2024-10-29 13:40:11] iter = 05380, loss = 1.9024
2024-10-29 13:40:12: [2024-10-29 13:40:12] iter = 05390, loss = 0.9723
2024-10-29 13:40:12: [2024-10-29 13:40:12] iter = 05400, loss = 1.2149
2024-10-29 13:40:12: [2024-10-29 13:40:12] iter = 05410, loss = 1.4640
2024-10-29 13:40:13: [2024-10-29 13:40:13] iter = 05420, loss = 1.2812
2024-10-29 13:40:13: [2024-10-29 13:40:13] iter = 05430, loss = 5.1064
2024-10-29 13:40:13: [2024-10-29 13:40:13] iter = 05440, loss = 1.3969
2024-10-29 13:40:14: [2024-10-29 13:40:14] iter = 05450, loss = 2.7484
2024-10-29 13:40:14: [2024-10-29 13:40:14] iter = 05460, loss = 0.8655
2024-10-29 13:40:14: [2024-10-29 13:40:14] iter = 05470, loss = 1.1974
2024-10-29 13:40:14: [2024-10-29 13:40:14] iter = 05480, loss = 4.0317
2024-10-29 13:40:15: [2024-10-29 13:40:15] iter = 05490, loss = 1.6890
2024-10-29 13:40:15: [2024-10-29 13:40:15] iter = 05500, loss = 1.3189
2024-10-29 13:40:15: [2024-10-29 13:40:15] iter = 05510, loss = 0.9936
2024-10-29 13:40:15: [2024-10-29 13:40:15] iter = 05520, loss = 4.7799
2024-10-29 13:40:16: [2024-10-29 13:40:16] iter = 05530, loss = 2.3875
2024-10-29 13:40:16: [2024-10-29 13:40:16] iter = 05540, loss = 4.7857
2024-10-29 13:40:16: [2024-10-29 13:40:16] iter = 05550, loss = 2.3029
2024-10-29 13:40:17: [2024-10-29 13:40:17] iter = 05560, loss = 1.1066
2024-10-29 13:40:17: [2024-10-29 13:40:17] iter = 05570, loss = 1.0630
2024-10-29 13:40:17: [2024-10-29 13:40:17] iter = 05580, loss = 2.2941
2024-10-29 13:40:18: [2024-10-29 13:40:18] iter = 05590, loss = 1.3098
2024-10-29 13:40:18: [2024-10-29 13:40:18] iter = 05600, loss = 2.1077
2024-10-29 13:40:18: [2024-10-29 13:40:18] iter = 05610, loss = 3.7248
2024-10-29 13:40:19: [2024-10-29 13:40:19] iter = 05620, loss = 2.3852
2024-10-29 13:40:19: [2024-10-29 13:40:19] iter = 05630, loss = 1.7656
2024-10-29 13:40:19: [2024-10-29 13:40:19] iter = 05640, loss = 1.2319
2024-10-29 13:40:20: [2024-10-29 13:40:20] iter = 05650, loss = 1.4719
2024-10-29 13:40:20: [2024-10-29 13:40:20] iter = 05660, loss = 1.4395
2024-10-29 13:40:20: [2024-10-29 13:40:20] iter = 05670, loss = 1.3830
2024-10-29 13:40:21: [2024-10-29 13:40:21] iter = 05680, loss = 3.9900
2024-10-29 13:40:21: [2024-10-29 13:40:21] iter = 05690, loss = 3.2147
2024-10-29 13:40:21: [2024-10-29 13:40:21] iter = 05700, loss = 1.6096
2024-10-29 13:40:21: [2024-10-29 13:40:21] iter = 05710, loss = 1.4743
2024-10-29 13:40:22: [2024-10-29 13:40:22] iter = 05720, loss = 1.0431
2024-10-29 13:40:22: [2024-10-29 13:40:22] iter = 05730, loss = 2.8037
2024-10-29 13:40:22: [2024-10-29 13:40:22] iter = 05740, loss = 1.2289
2024-10-29 13:40:23: [2024-10-29 13:40:23] iter = 05750, loss = 1.3289
2024-10-29 13:40:23: [2024-10-29 13:40:23] iter = 05760, loss = 1.1770
2024-10-29 13:40:23: [2024-10-29 13:40:23] iter = 05770, loss = 5.4204
2024-10-29 13:40:23: [2024-10-29 13:40:23] iter = 05780, loss = 1.7736
2024-10-29 13:40:24: [2024-10-29 13:40:24] iter = 05790, loss = 1.1125
2024-10-29 13:40:24: [2024-10-29 13:40:24] iter = 05800, loss = 1.9701
2024-10-29 13:40:24: [2024-10-29 13:40:24] iter = 05810, loss = 0.9714
2024-10-29 13:40:25: [2024-10-29 13:40:25] iter = 05820, loss = 0.9928
2024-10-29 13:40:25: [2024-10-29 13:40:25] iter = 05830, loss = 1.5425
2024-10-29 13:40:25: [2024-10-29 13:40:25] iter = 05840, loss = 0.8500
2024-10-29 13:40:25: [2024-10-29 13:40:25] iter = 05850, loss = 1.7947
2024-10-29 13:40:26: [2024-10-29 13:40:26] iter = 05860, loss = 0.9323
2024-10-29 13:40:26: [2024-10-29 13:40:26] iter = 05870, loss = 7.5566
2024-10-29 13:40:26: [2024-10-29 13:40:26] iter = 05880, loss = 1.1987
2024-10-29 13:40:26: [2024-10-29 13:40:26] iter = 05890, loss = 0.7180
2024-10-29 13:40:27: [2024-10-29 13:40:27] iter = 05900, loss = 0.8178
2024-10-29 13:40:27: [2024-10-29 13:40:27] iter = 05910, loss = 1.6529
2024-10-29 13:40:27: [2024-10-29 13:40:27] iter = 05920, loss = 1.0872
2024-10-29 13:40:27: [2024-10-29 13:40:27] iter = 05930, loss = 0.9383
2024-10-29 13:40:28: [2024-10-29 13:40:28] iter = 05940, loss = 1.5069
2024-10-29 13:40:28: [2024-10-29 13:40:28] iter = 05950, loss = 1.0692
2024-10-29 13:40:28: [2024-10-29 13:40:28] iter = 05960, loss = 0.9441
2024-10-29 13:40:29: [2024-10-29 13:40:29] iter = 05970, loss = 1.1252
2024-10-29 13:40:29: [2024-10-29 13:40:29] iter = 05980, loss = 1.3617
2024-10-29 13:40:29: [2024-10-29 13:40:29] iter = 05990, loss = 1.3978
2024-10-29 13:40:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 13:40:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:40:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30099}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:40:55: Evaluate 5 random ConvNet, ACCmean = 0.5962 ACCstd = 0.0180
-------------------------
2024-10-29 13:40:55: Evaluate 5 random ConvNet, SENmean = 0.6013 SENstd = 0.0045
-------------------------
2024-10-29 13:40:55: Evaluate 5 random ConvNet, SPEmean = 0.6013 SPEstd = 0.0045
-------------------------
2024-10-29 13:40:55: Evaluate 5 random ConvNet, F!mean = 0.4846 F!std = 0.0085
-------------------------
2024-10-29 13:40:55: Evaluate 5 random ConvNet, mean = 0.5962 std = 0.0180
-------------------------
2024-10-29 13:40:55: [2024-10-29 13:40:55] iter = 06000, loss = 0.8986
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:40:55: [2024-10-29 13:40:55] iter = 06010, loss = 1.3369
2024-10-29 13:40:56: [2024-10-29 13:40:56] iter = 06020, loss = 1.0506
2024-10-29 13:40:56: [2024-10-29 13:40:56] iter = 06030, loss = 1.1591
2024-10-29 13:40:56: [2024-10-29 13:40:56] iter = 06040, loss = 1.7804
2024-10-29 13:40:57: [2024-10-29 13:40:57] iter = 06050, loss = 1.2983
2024-10-29 13:40:57: [2024-10-29 13:40:57] iter = 06060, loss = 1.8985
2024-10-29 13:40:57: [2024-10-29 13:40:57] iter = 06070, loss = 1.5772
2024-10-29 13:40:57: [2024-10-29 13:40:57] iter = 06080, loss = 6.3269
2024-10-29 13:40:58: [2024-10-29 13:40:58] iter = 06090, loss = 1.2419
2024-10-29 13:40:58: [2024-10-29 13:40:58] iter = 06100, loss = 3.3725
2024-10-29 13:40:58: [2024-10-29 13:40:58] iter = 06110, loss = 5.3620
2024-10-29 13:40:59: [2024-10-29 13:40:59] iter = 06120, loss = 1.5028
2024-10-29 13:40:59: [2024-10-29 13:40:59] iter = 06130, loss = 1.6318
2024-10-29 13:40:59: [2024-10-29 13:40:59] iter = 06140, loss = 3.3646
2024-10-29 13:41:00: [2024-10-29 13:41:00] iter = 06150, loss = 1.2733
2024-10-29 13:41:00: [2024-10-29 13:41:00] iter = 06160, loss = 1.1286
2024-10-29 13:41:00: [2024-10-29 13:41:00] iter = 06170, loss = 1.1192
2024-10-29 13:41:00: [2024-10-29 13:41:00] iter = 06180, loss = 1.2281
2024-10-29 13:41:01: [2024-10-29 13:41:01] iter = 06190, loss = 1.3882
2024-10-29 13:41:01: [2024-10-29 13:41:01] iter = 06200, loss = 3.0667
2024-10-29 13:41:01: [2024-10-29 13:41:01] iter = 06210, loss = 1.6554
2024-10-29 13:41:02: [2024-10-29 13:41:02] iter = 06220, loss = 2.5345
2024-10-29 13:41:02: [2024-10-29 13:41:02] iter = 06230, loss = 1.7267
2024-10-29 13:41:02: [2024-10-29 13:41:02] iter = 06240, loss = 1.6259
2024-10-29 13:41:02: [2024-10-29 13:41:02] iter = 06250, loss = 1.2841
2024-10-29 13:41:03: [2024-10-29 13:41:03] iter = 06260, loss = 1.2004
2024-10-29 13:41:03: [2024-10-29 13:41:03] iter = 06270, loss = 1.4284
2024-10-29 13:41:03: [2024-10-29 13:41:03] iter = 06280, loss = 1.5006
2024-10-29 13:41:04: [2024-10-29 13:41:03] iter = 06290, loss = 0.9084
2024-10-29 13:41:04: [2024-10-29 13:41:04] iter = 06300, loss = 3.0358
2024-10-29 13:41:04: [2024-10-29 13:41:04] iter = 06310, loss = 0.9062
2024-10-29 13:41:04: [2024-10-29 13:41:04] iter = 06320, loss = 1.1384
2024-10-29 13:41:05: [2024-10-29 13:41:05] iter = 06330, loss = 1.4208
2024-10-29 13:41:05: [2024-10-29 13:41:05] iter = 06340, loss = 1.1688
2024-10-29 13:41:05: [2024-10-29 13:41:05] iter = 06350, loss = 2.7583
2024-10-29 13:41:05: [2024-10-29 13:41:05] iter = 06360, loss = 0.7789
2024-10-29 13:41:06: [2024-10-29 13:41:06] iter = 06370, loss = 1.2892
2024-10-29 13:41:06: [2024-10-29 13:41:06] iter = 06380, loss = 1.2111
2024-10-29 13:41:06: [2024-10-29 13:41:06] iter = 06390, loss = 1.7628
2024-10-29 13:41:06: [2024-10-29 13:41:06] iter = 06400, loss = 1.1612
2024-10-29 13:41:07: [2024-10-29 13:41:07] iter = 06410, loss = 3.6938
2024-10-29 13:41:07: [2024-10-29 13:41:07] iter = 06420, loss = 1.1821
2024-10-29 13:41:07: [2024-10-29 13:41:07] iter = 06430, loss = 1.0960
2024-10-29 13:41:08: [2024-10-29 13:41:08] iter = 06440, loss = 1.4732
2024-10-29 13:41:08: [2024-10-29 13:41:08] iter = 06450, loss = 6.1074
2024-10-29 13:41:08: [2024-10-29 13:41:08] iter = 06460, loss = 5.2414
2024-10-29 13:41:08: [2024-10-29 13:41:08] iter = 06470, loss = 1.3965
2024-10-29 13:41:09: [2024-10-29 13:41:09] iter = 06480, loss = 1.2865
2024-10-29 13:41:09: [2024-10-29 13:41:09] iter = 06490, loss = 1.5003
2024-10-29 13:41:09: [2024-10-29 13:41:09] iter = 06500, loss = 1.1635
2024-10-29 13:41:10: [2024-10-29 13:41:10] iter = 06510, loss = 6.9644
2024-10-29 13:41:10: [2024-10-29 13:41:10] iter = 06520, loss = 2.4712
2024-10-29 13:41:10: [2024-10-29 13:41:10] iter = 06530, loss = 1.0236
2024-10-29 13:41:10: [2024-10-29 13:41:10] iter = 06540, loss = 1.6887
2024-10-29 13:41:11: [2024-10-29 13:41:11] iter = 06550, loss = 1.7907
2024-10-29 13:41:11: [2024-10-29 13:41:11] iter = 06560, loss = 2.2287
2024-10-29 13:41:11: [2024-10-29 13:41:11] iter = 06570, loss = 1.4224
2024-10-29 13:41:12: [2024-10-29 13:41:12] iter = 06580, loss = 1.9795
2024-10-29 13:41:12: [2024-10-29 13:41:12] iter = 06590, loss = 0.9658
2024-10-29 13:41:12: [2024-10-29 13:41:12] iter = 06600, loss = 1.1473
2024-10-29 13:41:12: [2024-10-29 13:41:12] iter = 06610, loss = 0.7104
2024-10-29 13:41:13: [2024-10-29 13:41:13] iter = 06620, loss = 1.1569
2024-10-29 13:41:13: [2024-10-29 13:41:13] iter = 06630, loss = 2.7066
2024-10-29 13:41:13: [2024-10-29 13:41:13] iter = 06640, loss = 1.9036
2024-10-29 13:41:14: [2024-10-29 13:41:14] iter = 06650, loss = 5.2799
2024-10-29 13:41:14: [2024-10-29 13:41:14] iter = 06660, loss = 1.5589
2024-10-29 13:41:14: [2024-10-29 13:41:14] iter = 06670, loss = 5.1567
2024-10-29 13:41:15: [2024-10-29 13:41:15] iter = 06680, loss = 1.5181
2024-10-29 13:41:15: [2024-10-29 13:41:15] iter = 06690, loss = 1.2808
2024-10-29 13:41:15: [2024-10-29 13:41:15] iter = 06700, loss = 1.8167
2024-10-29 13:41:15: [2024-10-29 13:41:15] iter = 06710, loss = 1.1080
2024-10-29 13:41:16: [2024-10-29 13:41:16] iter = 06720, loss = 1.4508
2024-10-29 13:41:16: [2024-10-29 13:41:16] iter = 06730, loss = 1.2105
2024-10-29 13:41:16: [2024-10-29 13:41:16] iter = 06740, loss = 1.2378
2024-10-29 13:41:17: [2024-10-29 13:41:17] iter = 06750, loss = 1.5064
2024-10-29 13:41:17: [2024-10-29 13:41:17] iter = 06760, loss = 1.0326
2024-10-29 13:41:17: [2024-10-29 13:41:17] iter = 06770, loss = 1.1367
2024-10-29 13:41:18: [2024-10-29 13:41:18] iter = 06780, loss = 1.5835
2024-10-29 13:41:18: [2024-10-29 13:41:18] iter = 06790, loss = 0.9879
2024-10-29 13:41:18: [2024-10-29 13:41:18] iter = 06800, loss = 3.1249
2024-10-29 13:41:19: [2024-10-29 13:41:19] iter = 06810, loss = 1.3668
2024-10-29 13:41:19: [2024-10-29 13:41:19] iter = 06820, loss = 0.8307
2024-10-29 13:41:19: [2024-10-29 13:41:19] iter = 06830, loss = 1.1993
2024-10-29 13:41:20: [2024-10-29 13:41:20] iter = 06840, loss = 1.8607
2024-10-29 13:41:20: [2024-10-29 13:41:20] iter = 06850, loss = 2.2460
2024-10-29 13:41:20: [2024-10-29 13:41:20] iter = 06860, loss = 0.6795
2024-10-29 13:41:21: [2024-10-29 13:41:21] iter = 06870, loss = 1.3087
2024-10-29 13:41:21: [2024-10-29 13:41:21] iter = 06880, loss = 0.8856
2024-10-29 13:41:21: [2024-10-29 13:41:21] iter = 06890, loss = 1.0391
2024-10-29 13:41:21: [2024-10-29 13:41:21] iter = 06900, loss = 1.0283
2024-10-29 13:41:22: [2024-10-29 13:41:22] iter = 06910, loss = 2.1345
2024-10-29 13:41:22: [2024-10-29 13:41:22] iter = 06920, loss = 1.1345
2024-10-29 13:41:22: [2024-10-29 13:41:22] iter = 06930, loss = 1.4167
2024-10-29 13:41:22: [2024-10-29 13:41:22] iter = 06940, loss = 0.6142
2024-10-29 13:41:23: [2024-10-29 13:41:23] iter = 06950, loss = 1.1863
2024-10-29 13:41:23: [2024-10-29 13:41:23] iter = 06960, loss = 1.3632
2024-10-29 13:41:23: [2024-10-29 13:41:23] iter = 06970, loss = 1.5378
2024-10-29 13:41:24: [2024-10-29 13:41:24] iter = 06980, loss = 1.9507
2024-10-29 13:41:24: [2024-10-29 13:41:24] iter = 06990, loss = 1.3674
2024-10-29 13:41:24: [2024-10-29 13:41:24] iter = 07000, loss = 0.8805
2024-10-29 13:41:24: [2024-10-29 13:41:24] iter = 07010, loss = 1.3854
2024-10-29 13:41:25: [2024-10-29 13:41:25] iter = 07020, loss = 1.3442
2024-10-29 13:41:25: [2024-10-29 13:41:25] iter = 07030, loss = 0.8584
2024-10-29 13:41:26: [2024-10-29 13:41:26] iter = 07040, loss = 1.7457
2024-10-29 13:41:26: [2024-10-29 13:41:26] iter = 07050, loss = 0.9910
2024-10-29 13:41:26: [2024-10-29 13:41:26] iter = 07060, loss = 1.1536
2024-10-29 13:41:27: [2024-10-29 13:41:27] iter = 07070, loss = 1.7951
2024-10-29 13:41:27: [2024-10-29 13:41:27] iter = 07080, loss = 7.4493
2024-10-29 13:41:27: [2024-10-29 13:41:27] iter = 07090, loss = 1.1110
2024-10-29 13:41:28: [2024-10-29 13:41:28] iter = 07100, loss = 1.2509
2024-10-29 13:41:28: [2024-10-29 13:41:28] iter = 07110, loss = 2.4253
2024-10-29 13:41:28: [2024-10-29 13:41:28] iter = 07120, loss = 1.6085
2024-10-29 13:41:29: [2024-10-29 13:41:29] iter = 07130, loss = 1.3587
2024-10-29 13:41:29: [2024-10-29 13:41:29] iter = 07140, loss = 1.2208
2024-10-29 13:41:29: [2024-10-29 13:41:29] iter = 07150, loss = 0.7816
2024-10-29 13:41:30: [2024-10-29 13:41:30] iter = 07160, loss = 1.2494
2024-10-29 13:41:30: [2024-10-29 13:41:30] iter = 07170, loss = 1.8916
2024-10-29 13:41:30: [2024-10-29 13:41:30] iter = 07180, loss = 1.1785
2024-10-29 13:41:31: [2024-10-29 13:41:31] iter = 07190, loss = 1.1239
2024-10-29 13:41:31: [2024-10-29 13:41:31] iter = 07200, loss = 1.3379
2024-10-29 13:41:31: [2024-10-29 13:41:31] iter = 07210, loss = 2.6229
2024-10-29 13:41:31: [2024-10-29 13:41:31] iter = 07220, loss = 2.9260
2024-10-29 13:41:32: [2024-10-29 13:41:32] iter = 07230, loss = 1.4922
2024-10-29 13:41:32: [2024-10-29 13:41:32] iter = 07240, loss = 1.3550
2024-10-29 13:41:32: [2024-10-29 13:41:32] iter = 07250, loss = 1.2368
2024-10-29 13:41:33: [2024-10-29 13:41:33] iter = 07260, loss = 1.4716
2024-10-29 13:41:33: [2024-10-29 13:41:33] iter = 07270, loss = 1.2954
2024-10-29 13:41:33: [2024-10-29 13:41:33] iter = 07280, loss = 4.3028
2024-10-29 13:41:33: [2024-10-29 13:41:33] iter = 07290, loss = 10.0086
2024-10-29 13:41:34: [2024-10-29 13:41:34] iter = 07300, loss = 1.3720
2024-10-29 13:41:34: [2024-10-29 13:41:34] iter = 07310, loss = 1.4097
2024-10-29 13:41:34: [2024-10-29 13:41:34] iter = 07320, loss = 0.6220
2024-10-29 13:41:35: [2024-10-29 13:41:35] iter = 07330, loss = 2.6439
2024-10-29 13:41:35: [2024-10-29 13:41:35] iter = 07340, loss = 0.9689
2024-10-29 13:41:35: [2024-10-29 13:41:35] iter = 07350, loss = 1.3981
2024-10-29 13:41:35: [2024-10-29 13:41:35] iter = 07360, loss = 2.3197
2024-10-29 13:41:36: [2024-10-29 13:41:36] iter = 07370, loss = 1.6741
2024-10-29 13:41:36: [2024-10-29 13:41:36] iter = 07380, loss = 1.2070
2024-10-29 13:41:36: [2024-10-29 13:41:36] iter = 07390, loss = 1.2542
2024-10-29 13:41:36: [2024-10-29 13:41:36] iter = 07400, loss = 1.9606
2024-10-29 13:41:37: [2024-10-29 13:41:37] iter = 07410, loss = 1.9697
2024-10-29 13:41:37: [2024-10-29 13:41:37] iter = 07420, loss = 1.2502
2024-10-29 13:41:37: [2024-10-29 13:41:37] iter = 07430, loss = 3.8979
2024-10-29 13:41:37: [2024-10-29 13:41:37] iter = 07440, loss = 1.2078
2024-10-29 13:41:38: [2024-10-29 13:41:38] iter = 07450, loss = 1.2486
2024-10-29 13:41:38: [2024-10-29 13:41:38] iter = 07460, loss = 3.1970
2024-10-29 13:41:39: [2024-10-29 13:41:39] iter = 07470, loss = 2.7331
2024-10-29 13:41:39: [2024-10-29 13:41:39] iter = 07480, loss = 1.4563
2024-10-29 13:41:39: [2024-10-29 13:41:39] iter = 07490, loss = 1.4796
2024-10-29 13:41:40: [2024-10-29 13:41:40] iter = 07500, loss = 2.0623
2024-10-29 13:41:40: [2024-10-29 13:41:40] iter = 07510, loss = 1.5720
2024-10-29 13:41:40: [2024-10-29 13:41:40] iter = 07520, loss = 1.8861
2024-10-29 13:41:41: [2024-10-29 13:41:41] iter = 07530, loss = 1.5069
2024-10-29 13:41:41: [2024-10-29 13:41:41] iter = 07540, loss = 1.1193
2024-10-29 13:41:41: [2024-10-29 13:41:41] iter = 07550, loss = 1.6408
2024-10-29 13:41:42: [2024-10-29 13:41:42] iter = 07560, loss = 1.4521
2024-10-29 13:41:42: [2024-10-29 13:41:42] iter = 07570, loss = 1.7366
2024-10-29 13:41:42: [2024-10-29 13:41:42] iter = 07580, loss = 3.2739
2024-10-29 13:41:43: [2024-10-29 13:41:43] iter = 07590, loss = 1.6677
2024-10-29 13:41:43: [2024-10-29 13:41:43] iter = 07600, loss = 1.1317
2024-10-29 13:41:43: [2024-10-29 13:41:43] iter = 07610, loss = 1.5926
2024-10-29 13:41:43: [2024-10-29 13:41:43] iter = 07620, loss = 0.8097
2024-10-29 13:41:44: [2024-10-29 13:41:44] iter = 07630, loss = 1.5723
2024-10-29 13:41:44: [2024-10-29 13:41:44] iter = 07640, loss = 3.9288
2024-10-29 13:41:44: [2024-10-29 13:41:44] iter = 07650, loss = 1.4838
2024-10-29 13:41:45: [2024-10-29 13:41:45] iter = 07660, loss = 1.0256
2024-10-29 13:41:45: [2024-10-29 13:41:45] iter = 07670, loss = 1.9496
2024-10-29 13:41:45: [2024-10-29 13:41:45] iter = 07680, loss = 0.7824
2024-10-29 13:41:46: [2024-10-29 13:41:46] iter = 07690, loss = 1.9129
2024-10-29 13:41:46: [2024-10-29 13:41:46] iter = 07700, loss = 0.9972
2024-10-29 13:41:46: [2024-10-29 13:41:46] iter = 07710, loss = 1.6465
2024-10-29 13:41:47: [2024-10-29 13:41:47] iter = 07720, loss = 1.3270
2024-10-29 13:41:47: [2024-10-29 13:41:47] iter = 07730, loss = 1.2140
2024-10-29 13:41:47: [2024-10-29 13:41:47] iter = 07740, loss = 1.0457
2024-10-29 13:41:48: [2024-10-29 13:41:48] iter = 07750, loss = 5.4187
2024-10-29 13:41:48: [2024-10-29 13:41:48] iter = 07760, loss = 2.0960
2024-10-29 13:41:48: [2024-10-29 13:41:48] iter = 07770, loss = 1.5718
2024-10-29 13:41:48: [2024-10-29 13:41:48] iter = 07780, loss = 0.8849
2024-10-29 13:41:48: [2024-10-29 13:41:48] iter = 07790, loss = 1.7424
2024-10-29 13:41:49: [2024-10-29 13:41:49] iter = 07800, loss = 0.9111
2024-10-29 13:41:49: [2024-10-29 13:41:49] iter = 07810, loss = 1.1164
2024-10-29 13:41:49: [2024-10-29 13:41:49] iter = 07820, loss = 2.9603
2024-10-29 13:41:49: [2024-10-29 13:41:49] iter = 07830, loss = 1.1548
2024-10-29 13:41:50: [2024-10-29 13:41:50] iter = 07840, loss = 2.1965
2024-10-29 13:41:50: [2024-10-29 13:41:50] iter = 07850, loss = 1.0626
2024-10-29 13:41:50: [2024-10-29 13:41:50] iter = 07860, loss = 2.6459
2024-10-29 13:41:50: [2024-10-29 13:41:50] iter = 07870, loss = 2.0623
2024-10-29 13:41:51: [2024-10-29 13:41:51] iter = 07880, loss = 1.1642
2024-10-29 13:41:51: [2024-10-29 13:41:51] iter = 07890, loss = 1.4281
2024-10-29 13:41:51: [2024-10-29 13:41:51] iter = 07900, loss = 0.8019
2024-10-29 13:41:52: [2024-10-29 13:41:52] iter = 07910, loss = 1.3307
2024-10-29 13:41:52: [2024-10-29 13:41:52] iter = 07920, loss = 1.5550
2024-10-29 13:41:52: [2024-10-29 13:41:52] iter = 07930, loss = 1.2449
2024-10-29 13:41:53: [2024-10-29 13:41:53] iter = 07940, loss = 1.2551
2024-10-29 13:41:53: [2024-10-29 13:41:53] iter = 07950, loss = 0.9892
2024-10-29 13:41:53: [2024-10-29 13:41:53] iter = 07960, loss = 1.2340
2024-10-29 13:41:54: [2024-10-29 13:41:54] iter = 07970, loss = 1.0239
2024-10-29 13:41:54: [2024-10-29 13:41:54] iter = 07980, loss = 1.7931
2024-10-29 13:41:54: [2024-10-29 13:41:54] iter = 07990, loss = 1.9143
2024-10-29 13:41:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 13:41:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:41:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 15038}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:42:20: Evaluate 5 random ConvNet, ACCmean = 0.6176 ACCstd = 0.0135
-------------------------
2024-10-29 13:42:20: Evaluate 5 random ConvNet, SENmean = 0.5941 SENstd = 0.0070
-------------------------
2024-10-29 13:42:20: Evaluate 5 random ConvNet, SPEmean = 0.5941 SPEstd = 0.0070
-------------------------
2024-10-29 13:42:20: Evaluate 5 random ConvNet, F!mean = 0.4928 F!std = 0.0067
-------------------------
2024-10-29 13:42:20: Evaluate 5 random ConvNet, mean = 0.6176 std = 0.0135
-------------------------
2024-10-29 13:42:20: [2024-10-29 13:42:20] iter = 08000, loss = 5.2273
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:42:20: [2024-10-29 13:42:20] iter = 08010, loss = 1.9588
2024-10-29 13:42:20: [2024-10-29 13:42:20] iter = 08020, loss = 3.2674
2024-10-29 13:42:21: [2024-10-29 13:42:21] iter = 08030, loss = 1.9344
2024-10-29 13:42:21: [2024-10-29 13:42:21] iter = 08040, loss = 2.9637
2024-10-29 13:42:21: [2024-10-29 13:42:21] iter = 08050, loss = 3.3038
2024-10-29 13:42:22: [2024-10-29 13:42:22] iter = 08060, loss = 1.1757
2024-10-29 13:42:22: [2024-10-29 13:42:22] iter = 08070, loss = 1.7793
2024-10-29 13:42:22: [2024-10-29 13:42:22] iter = 08080, loss = 1.1287
2024-10-29 13:42:22: [2024-10-29 13:42:22] iter = 08090, loss = 1.9479
2024-10-29 13:42:23: [2024-10-29 13:42:23] iter = 08100, loss = 2.6959
2024-10-29 13:42:23: [2024-10-29 13:42:23] iter = 08110, loss = 2.1546
2024-10-29 13:42:23: [2024-10-29 13:42:23] iter = 08120, loss = 1.6177
2024-10-29 13:42:24: [2024-10-29 13:42:24] iter = 08130, loss = 2.3062
2024-10-29 13:42:24: [2024-10-29 13:42:24] iter = 08140, loss = 1.9124
2024-10-29 13:42:24: [2024-10-29 13:42:24] iter = 08150, loss = 3.0198
2024-10-29 13:42:25: [2024-10-29 13:42:25] iter = 08160, loss = 3.9279
2024-10-29 13:42:25: [2024-10-29 13:42:25] iter = 08170, loss = 1.6393
2024-10-29 13:42:25: [2024-10-29 13:42:25] iter = 08180, loss = 1.2903
2024-10-29 13:42:25: [2024-10-29 13:42:25] iter = 08190, loss = 2.0631
2024-10-29 13:42:26: [2024-10-29 13:42:26] iter = 08200, loss = 2.9946
2024-10-29 13:42:26: [2024-10-29 13:42:26] iter = 08210, loss = 1.5349
2024-10-29 13:42:26: [2024-10-29 13:42:26] iter = 08220, loss = 3.9660
2024-10-29 13:42:26: [2024-10-29 13:42:26] iter = 08230, loss = 6.4650
2024-10-29 13:42:26: [2024-10-29 13:42:26] iter = 08240, loss = 1.2555
2024-10-29 13:42:27: [2024-10-29 13:42:27] iter = 08250, loss = 1.5062
2024-10-29 13:42:27: [2024-10-29 13:42:27] iter = 08260, loss = 1.8865
2024-10-29 13:42:27: [2024-10-29 13:42:27] iter = 08270, loss = 1.0845
2024-10-29 13:42:28: [2024-10-29 13:42:28] iter = 08280, loss = 2.3621
2024-10-29 13:42:28: [2024-10-29 13:42:28] iter = 08290, loss = 1.7764
2024-10-29 13:42:28: [2024-10-29 13:42:28] iter = 08300, loss = 1.2019
2024-10-29 13:42:28: [2024-10-29 13:42:28] iter = 08310, loss = 1.1190
2024-10-29 13:42:29: [2024-10-29 13:42:29] iter = 08320, loss = 1.6585
2024-10-29 13:42:29: [2024-10-29 13:42:29] iter = 08330, loss = 1.8169
2024-10-29 13:42:29: [2024-10-29 13:42:29] iter = 08340, loss = 2.9529
2024-10-29 13:42:30: [2024-10-29 13:42:30] iter = 08350, loss = 1.4497
2024-10-29 13:42:30: [2024-10-29 13:42:30] iter = 08360, loss = 1.9018
2024-10-29 13:42:30: [2024-10-29 13:42:30] iter = 08370, loss = 1.1905
2024-10-29 13:42:30: [2024-10-29 13:42:30] iter = 08380, loss = 2.0642
2024-10-29 13:42:31: [2024-10-29 13:42:31] iter = 08390, loss = 1.0041
2024-10-29 13:42:31: [2024-10-29 13:42:31] iter = 08400, loss = 1.3822
2024-10-29 13:42:31: [2024-10-29 13:42:31] iter = 08410, loss = 0.9198
2024-10-29 13:42:31: [2024-10-29 13:42:31] iter = 08420, loss = 2.4278
2024-10-29 13:42:32: [2024-10-29 13:42:32] iter = 08430, loss = 3.9137
2024-10-29 13:42:32: [2024-10-29 13:42:32] iter = 08440, loss = 0.8974
2024-10-29 13:42:32: [2024-10-29 13:42:32] iter = 08450, loss = 1.2225
2024-10-29 13:42:33: [2024-10-29 13:42:33] iter = 08460, loss = 0.8021
2024-10-29 13:42:33: [2024-10-29 13:42:33] iter = 08470, loss = 1.1529
2024-10-29 13:42:33: [2024-10-29 13:42:33] iter = 08480, loss = 5.8598
2024-10-29 13:42:33: [2024-10-29 13:42:33] iter = 08490, loss = 0.9972
2024-10-29 13:42:34: [2024-10-29 13:42:34] iter = 08500, loss = 1.4913
2024-10-29 13:42:34: [2024-10-29 13:42:34] iter = 08510, loss = 1.1436
2024-10-29 13:42:34: [2024-10-29 13:42:34] iter = 08520, loss = 1.7797
2024-10-29 13:42:34: [2024-10-29 13:42:34] iter = 08530, loss = 1.9696
2024-10-29 13:42:35: [2024-10-29 13:42:35] iter = 08540, loss = 1.9077
2024-10-29 13:42:35: [2024-10-29 13:42:35] iter = 08550, loss = 1.9650
2024-10-29 13:42:35: [2024-10-29 13:42:35] iter = 08560, loss = 0.9804
2024-10-29 13:42:36: [2024-10-29 13:42:36] iter = 08570, loss = 1.0364
2024-10-29 13:42:36: [2024-10-29 13:42:36] iter = 08580, loss = 1.7774
2024-10-29 13:42:36: [2024-10-29 13:42:36] iter = 08590, loss = 1.1688
2024-10-29 13:42:37: [2024-10-29 13:42:37] iter = 08600, loss = 2.8900
2024-10-29 13:42:37: [2024-10-29 13:42:37] iter = 08610, loss = 1.2203
2024-10-29 13:42:37: [2024-10-29 13:42:37] iter = 08620, loss = 1.8046
2024-10-29 13:42:38: [2024-10-29 13:42:38] iter = 08630, loss = 1.1211
2024-10-29 13:42:38: [2024-10-29 13:42:38] iter = 08640, loss = 1.1587
2024-10-29 13:42:38: [2024-10-29 13:42:38] iter = 08650, loss = 1.2543
2024-10-29 13:42:38: [2024-10-29 13:42:38] iter = 08660, loss = 0.9472
2024-10-29 13:42:39: [2024-10-29 13:42:39] iter = 08670, loss = 2.3018
2024-10-29 13:42:39: [2024-10-29 13:42:39] iter = 08680, loss = 1.7198
2024-10-29 13:42:39: [2024-10-29 13:42:39] iter = 08690, loss = 0.8910
2024-10-29 13:42:39: [2024-10-29 13:42:39] iter = 08700, loss = 1.4371
2024-10-29 13:42:40: [2024-10-29 13:42:40] iter = 08710, loss = 1.2111
2024-10-29 13:42:40: [2024-10-29 13:42:40] iter = 08720, loss = 1.5804
2024-10-29 13:42:40: [2024-10-29 13:42:40] iter = 08730, loss = 2.7101
2024-10-29 13:42:40: [2024-10-29 13:42:40] iter = 08740, loss = 1.6416
2024-10-29 13:42:41: [2024-10-29 13:42:41] iter = 08750, loss = 2.6364
2024-10-29 13:42:41: [2024-10-29 13:42:41] iter = 08760, loss = 1.8270
2024-10-29 13:42:41: [2024-10-29 13:42:41] iter = 08770, loss = 1.2471
2024-10-29 13:42:41: [2024-10-29 13:42:41] iter = 08780, loss = 1.1403
2024-10-29 13:42:42: [2024-10-29 13:42:42] iter = 08790, loss = 1.1510
2024-10-29 13:42:42: [2024-10-29 13:42:42] iter = 08800, loss = 1.4643
2024-10-29 13:42:42: [2024-10-29 13:42:42] iter = 08810, loss = 1.3591
2024-10-29 13:42:43: [2024-10-29 13:42:43] iter = 08820, loss = 6.2826
2024-10-29 13:42:43: [2024-10-29 13:42:43] iter = 08830, loss = 1.5111
2024-10-29 13:42:43: [2024-10-29 13:42:43] iter = 08840, loss = 1.1939
2024-10-29 13:42:44: [2024-10-29 13:42:44] iter = 08850, loss = 1.2992
2024-10-29 13:42:44: [2024-10-29 13:42:44] iter = 08860, loss = 1.1755
2024-10-29 13:42:44: [2024-10-29 13:42:44] iter = 08870, loss = 2.6370
2024-10-29 13:42:44: [2024-10-29 13:42:44] iter = 08880, loss = 3.2074
2024-10-29 13:42:45: [2024-10-29 13:42:45] iter = 08890, loss = 0.9435
2024-10-29 13:42:45: [2024-10-29 13:42:45] iter = 08900, loss = 3.6994
2024-10-29 13:42:45: [2024-10-29 13:42:45] iter = 08910, loss = 0.9664
2024-10-29 13:42:46: [2024-10-29 13:42:46] iter = 08920, loss = 1.1872
2024-10-29 13:42:46: [2024-10-29 13:42:46] iter = 08930, loss = 1.5897
2024-10-29 13:42:46: [2024-10-29 13:42:46] iter = 08940, loss = 1.2874
2024-10-29 13:42:47: [2024-10-29 13:42:47] iter = 08950, loss = 1.6564
2024-10-29 13:42:47: [2024-10-29 13:42:47] iter = 08960, loss = 1.6629
2024-10-29 13:42:47: [2024-10-29 13:42:47] iter = 08970, loss = 1.1477
2024-10-29 13:42:48: [2024-10-29 13:42:48] iter = 08980, loss = 3.3717
2024-10-29 13:42:48: [2024-10-29 13:42:48] iter = 08990, loss = 1.3250
2024-10-29 13:42:48: [2024-10-29 13:42:48] iter = 09000, loss = 1.2600
2024-10-29 13:42:49: [2024-10-29 13:42:49] iter = 09010, loss = 1.4933
2024-10-29 13:42:49: [2024-10-29 13:42:49] iter = 09020, loss = 1.8984
2024-10-29 13:42:49: [2024-10-29 13:42:49] iter = 09030, loss = 0.8162
2024-10-29 13:42:50: [2024-10-29 13:42:50] iter = 09040, loss = 2.6545
2024-10-29 13:42:50: [2024-10-29 13:42:50] iter = 09050, loss = 3.4433
2024-10-29 13:42:50: [2024-10-29 13:42:50] iter = 09060, loss = 1.2854
2024-10-29 13:42:51: [2024-10-29 13:42:51] iter = 09070, loss = 3.0608
2024-10-29 13:42:51: [2024-10-29 13:42:51] iter = 09080, loss = 1.7033
2024-10-29 13:42:51: [2024-10-29 13:42:51] iter = 09090, loss = 1.5116
2024-10-29 13:42:52: [2024-10-29 13:42:51] iter = 09100, loss = 1.2738
2024-10-29 13:42:52: [2024-10-29 13:42:52] iter = 09110, loss = 2.2740
2024-10-29 13:42:52: [2024-10-29 13:42:52] iter = 09120, loss = 1.7079
2024-10-29 13:42:52: [2024-10-29 13:42:52] iter = 09130, loss = 1.2546
2024-10-29 13:42:53: [2024-10-29 13:42:53] iter = 09140, loss = 6.4120
2024-10-29 13:42:53: [2024-10-29 13:42:53] iter = 09150, loss = 1.8277
2024-10-29 13:42:53: [2024-10-29 13:42:53] iter = 09160, loss = 1.0431
2024-10-29 13:42:54: [2024-10-29 13:42:54] iter = 09170, loss = 1.2834
2024-10-29 13:42:54: [2024-10-29 13:42:54] iter = 09180, loss = 0.8347
2024-10-29 13:42:54: [2024-10-29 13:42:54] iter = 09190, loss = 1.2280
2024-10-29 13:42:55: [2024-10-29 13:42:55] iter = 09200, loss = 1.3039
2024-10-29 13:42:55: [2024-10-29 13:42:55] iter = 09210, loss = 1.2227
2024-10-29 13:42:55: [2024-10-29 13:42:55] iter = 09220, loss = 2.0671
2024-10-29 13:42:55: [2024-10-29 13:42:55] iter = 09230, loss = 1.1083
2024-10-29 13:42:56: [2024-10-29 13:42:56] iter = 09240, loss = 1.0842
2024-10-29 13:42:56: [2024-10-29 13:42:56] iter = 09250, loss = 2.3060
2024-10-29 13:42:56: [2024-10-29 13:42:56] iter = 09260, loss = 0.8966
2024-10-29 13:42:56: [2024-10-29 13:42:56] iter = 09270, loss = 2.3834
2024-10-29 13:42:57: [2024-10-29 13:42:57] iter = 09280, loss = 0.8695
2024-10-29 13:42:57: [2024-10-29 13:42:57] iter = 09290, loss = 0.9783
2024-10-29 13:42:57: [2024-10-29 13:42:57] iter = 09300, loss = 1.3237
2024-10-29 13:42:58: [2024-10-29 13:42:58] iter = 09310, loss = 1.1604
2024-10-29 13:42:58: [2024-10-29 13:42:58] iter = 09320, loss = 2.0713
2024-10-29 13:42:58: [2024-10-29 13:42:58] iter = 09330, loss = 1.0156
2024-10-29 13:42:59: [2024-10-29 13:42:59] iter = 09340, loss = 3.5928
2024-10-29 13:42:59: [2024-10-29 13:42:59] iter = 09350, loss = 1.5960
2024-10-29 13:42:59: [2024-10-29 13:42:59] iter = 09360, loss = 1.3181
2024-10-29 13:43:00: [2024-10-29 13:43:00] iter = 09370, loss = 1.8632
2024-10-29 13:43:00: [2024-10-29 13:43:00] iter = 09380, loss = 1.8899
2024-10-29 13:43:00: [2024-10-29 13:43:00] iter = 09390, loss = 1.3255
2024-10-29 13:43:01: [2024-10-29 13:43:01] iter = 09400, loss = 2.1391
2024-10-29 13:43:01: [2024-10-29 13:43:01] iter = 09410, loss = 1.9678
2024-10-29 13:43:01: [2024-10-29 13:43:01] iter = 09420, loss = 1.5933
2024-10-29 13:43:02: [2024-10-29 13:43:02] iter = 09430, loss = 1.3586
2024-10-29 13:43:02: [2024-10-29 13:43:02] iter = 09440, loss = 1.7376
2024-10-29 13:43:02: [2024-10-29 13:43:02] iter = 09450, loss = 1.7141
2024-10-29 13:43:02: [2024-10-29 13:43:02] iter = 09460, loss = 0.8515
2024-10-29 13:43:03: [2024-10-29 13:43:03] iter = 09470, loss = 1.2984
2024-10-29 13:43:03: [2024-10-29 13:43:03] iter = 09480, loss = 1.5248
2024-10-29 13:43:03: [2024-10-29 13:43:03] iter = 09490, loss = 1.1097
2024-10-29 13:43:04: [2024-10-29 13:43:04] iter = 09500, loss = 1.4763
2024-10-29 13:43:04: [2024-10-29 13:43:04] iter = 09510, loss = 1.4681
2024-10-29 13:43:04: [2024-10-29 13:43:04] iter = 09520, loss = 3.2295
2024-10-29 13:43:04: [2024-10-29 13:43:04] iter = 09530, loss = 1.9634
2024-10-29 13:43:05: [2024-10-29 13:43:05] iter = 09540, loss = 1.2790
2024-10-29 13:43:05: [2024-10-29 13:43:05] iter = 09550, loss = 1.3160
2024-10-29 13:43:05: [2024-10-29 13:43:05] iter = 09560, loss = 1.3815
2024-10-29 13:43:05: [2024-10-29 13:43:05] iter = 09570, loss = 1.4139
2024-10-29 13:43:06: [2024-10-29 13:43:06] iter = 09580, loss = 0.8411
2024-10-29 13:43:06: [2024-10-29 13:43:06] iter = 09590, loss = 0.7461
2024-10-29 13:43:06: [2024-10-29 13:43:06] iter = 09600, loss = 3.6277
2024-10-29 13:43:07: [2024-10-29 13:43:07] iter = 09610, loss = 1.0886
2024-10-29 13:43:07: [2024-10-29 13:43:07] iter = 09620, loss = 1.1657
2024-10-29 13:43:07: [2024-10-29 13:43:07] iter = 09630, loss = 1.6438
2024-10-29 13:43:07: [2024-10-29 13:43:07] iter = 09640, loss = 1.1170
2024-10-29 13:43:08: [2024-10-29 13:43:08] iter = 09650, loss = 2.1738
2024-10-29 13:43:08: [2024-10-29 13:43:08] iter = 09660, loss = 2.2707
2024-10-29 13:43:08: [2024-10-29 13:43:08] iter = 09670, loss = 1.8037
2024-10-29 13:43:09: [2024-10-29 13:43:09] iter = 09680, loss = 1.4231
2024-10-29 13:43:09: [2024-10-29 13:43:09] iter = 09690, loss = 1.5055
2024-10-29 13:43:09: [2024-10-29 13:43:09] iter = 09700, loss = 1.1020
2024-10-29 13:43:09: [2024-10-29 13:43:09] iter = 09710, loss = 1.4141
2024-10-29 13:43:10: [2024-10-29 13:43:10] iter = 09720, loss = 5.3718
2024-10-29 13:43:10: [2024-10-29 13:43:10] iter = 09730, loss = 1.2044
2024-10-29 13:43:10: [2024-10-29 13:43:10] iter = 09740, loss = 1.7098
2024-10-29 13:43:11: [2024-10-29 13:43:11] iter = 09750, loss = 1.0398
2024-10-29 13:43:11: [2024-10-29 13:43:11] iter = 09760, loss = 6.6639
2024-10-29 13:43:11: [2024-10-29 13:43:11] iter = 09770, loss = 1.4023
2024-10-29 13:43:12: [2024-10-29 13:43:12] iter = 09780, loss = 1.1437
2024-10-29 13:43:12: [2024-10-29 13:43:12] iter = 09790, loss = 0.9240
2024-10-29 13:43:12: [2024-10-29 13:43:12] iter = 09800, loss = 2.9047
2024-10-29 13:43:12: [2024-10-29 13:43:12] iter = 09810, loss = 0.7590
2024-10-29 13:43:13: [2024-10-29 13:43:13] iter = 09820, loss = 2.3235
2024-10-29 13:43:13: [2024-10-29 13:43:13] iter = 09830, loss = 1.3863
2024-10-29 13:43:13: [2024-10-29 13:43:13] iter = 09840, loss = 1.3430
2024-10-29 13:43:14: [2024-10-29 13:43:14] iter = 09850, loss = 0.8735
2024-10-29 13:43:14: [2024-10-29 13:43:14] iter = 09860, loss = 1.5445
2024-10-29 13:43:14: [2024-10-29 13:43:14] iter = 09870, loss = 1.0730
2024-10-29 13:43:15: [2024-10-29 13:43:15] iter = 09880, loss = 1.2518
2024-10-29 13:43:15: [2024-10-29 13:43:15] iter = 09890, loss = 2.6999
2024-10-29 13:43:15: [2024-10-29 13:43:15] iter = 09900, loss = 1.0653
2024-10-29 13:43:16: [2024-10-29 13:43:16] iter = 09910, loss = 1.7371
2024-10-29 13:43:16: [2024-10-29 13:43:16] iter = 09920, loss = 2.0055
2024-10-29 13:43:16: [2024-10-29 13:43:16] iter = 09930, loss = 1.4294
2024-10-29 13:43:17: [2024-10-29 13:43:17] iter = 09940, loss = 1.1641
2024-10-29 13:43:17: [2024-10-29 13:43:17] iter = 09950, loss = 1.7126
2024-10-29 13:43:17: [2024-10-29 13:43:17] iter = 09960, loss = 4.2752
2024-10-29 13:43:17: [2024-10-29 13:43:17] iter = 09970, loss = 1.2375
2024-10-29 13:43:18: [2024-10-29 13:43:18] iter = 09980, loss = 2.8903
2024-10-29 13:43:18: [2024-10-29 13:43:18] iter = 09990, loss = 0.9429
2024-10-29 13:43:18: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 13:43:18: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:43:18: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 98911}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:43:43: Evaluate 5 random ConvNet, ACCmean = 0.5858 ACCstd = 0.0120
-------------------------
2024-10-29 13:43:43: Evaluate 5 random ConvNet, SENmean = 0.6263 SENstd = 0.0024
-------------------------
2024-10-29 13:43:43: Evaluate 5 random ConvNet, SPEmean = 0.6263 SPEstd = 0.0024
-------------------------
2024-10-29 13:43:43: Evaluate 5 random ConvNet, F!mean = 0.4866 F!std = 0.0066
-------------------------
2024-10-29 13:43:43: Evaluate 5 random ConvNet, mean = 0.5858 std = 0.0120
-------------------------
2024-10-29 13:43:43: [2024-10-29 13:43:43] iter = 10000, loss = 0.8446
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:43:44: [2024-10-29 13:43:44] iter = 10010, loss = 1.4347
2024-10-29 13:43:44: [2024-10-29 13:43:44] iter = 10020, loss = 1.6121
2024-10-29 13:43:44: [2024-10-29 13:43:44] iter = 10030, loss = 1.0640
2024-10-29 13:43:44: [2024-10-29 13:43:44] iter = 10040, loss = 1.6297
2024-10-29 13:43:45: [2024-10-29 13:43:45] iter = 10050, loss = 0.8461
2024-10-29 13:43:45: [2024-10-29 13:43:45] iter = 10060, loss = 1.2513
2024-10-29 13:43:45: [2024-10-29 13:43:45] iter = 10070, loss = 0.8158
2024-10-29 13:43:45: [2024-10-29 13:43:45] iter = 10080, loss = 1.1327
2024-10-29 13:43:46: [2024-10-29 13:43:46] iter = 10090, loss = 1.3767
2024-10-29 13:43:46: [2024-10-29 13:43:46] iter = 10100, loss = 2.2612
2024-10-29 13:43:46: [2024-10-29 13:43:46] iter = 10110, loss = 1.1785
2024-10-29 13:43:46: [2024-10-29 13:43:46] iter = 10120, loss = 0.8702
2024-10-29 13:43:47: [2024-10-29 13:43:47] iter = 10130, loss = 1.0956
2024-10-29 13:43:47: [2024-10-29 13:43:47] iter = 10140, loss = 2.5032
2024-10-29 13:43:47: [2024-10-29 13:43:47] iter = 10150, loss = 1.0888
2024-10-29 13:43:48: [2024-10-29 13:43:48] iter = 10160, loss = 0.9597
2024-10-29 13:43:48: [2024-10-29 13:43:48] iter = 10170, loss = 1.6962
2024-10-29 13:43:48: [2024-10-29 13:43:48] iter = 10180, loss = 2.4238
2024-10-29 13:43:49: [2024-10-29 13:43:49] iter = 10190, loss = 12.7113
2024-10-29 13:43:49: [2024-10-29 13:43:49] iter = 10200, loss = 1.3334
2024-10-29 13:43:49: [2024-10-29 13:43:49] iter = 10210, loss = 6.6036
2024-10-29 13:43:50: [2024-10-29 13:43:50] iter = 10220, loss = 1.0851
2024-10-29 13:43:50: [2024-10-29 13:43:50] iter = 10230, loss = 1.9712
2024-10-29 13:43:50: [2024-10-29 13:43:50] iter = 10240, loss = 0.8140
2024-10-29 13:43:50: [2024-10-29 13:43:50] iter = 10250, loss = 5.2786
2024-10-29 13:43:51: [2024-10-29 13:43:51] iter = 10260, loss = 0.9109
2024-10-29 13:43:51: [2024-10-29 13:43:51] iter = 10270, loss = 1.1129
2024-10-29 13:43:51: [2024-10-29 13:43:51] iter = 10280, loss = 1.1318
2024-10-29 13:43:52: [2024-10-29 13:43:52] iter = 10290, loss = 2.4063
2024-10-29 13:43:52: [2024-10-29 13:43:52] iter = 10300, loss = 3.5037
2024-10-29 13:43:52: [2024-10-29 13:43:52] iter = 10310, loss = 1.6178
2024-10-29 13:43:52: [2024-10-29 13:43:52] iter = 10320, loss = 1.9143
2024-10-29 13:43:53: [2024-10-29 13:43:53] iter = 10330, loss = 1.5923
2024-10-29 13:43:53: [2024-10-29 13:43:53] iter = 10340, loss = 0.9882
2024-10-29 13:43:53: [2024-10-29 13:43:53] iter = 10350, loss = 1.0107
2024-10-29 13:43:54: [2024-10-29 13:43:54] iter = 10360, loss = 2.6415
2024-10-29 13:43:54: [2024-10-29 13:43:54] iter = 10370, loss = 0.9889
2024-10-29 13:43:54: [2024-10-29 13:43:54] iter = 10380, loss = 1.1291
2024-10-29 13:43:55: [2024-10-29 13:43:55] iter = 10390, loss = 1.1535
2024-10-29 13:43:55: [2024-10-29 13:43:55] iter = 10400, loss = 4.4246
2024-10-29 13:43:55: [2024-10-29 13:43:55] iter = 10410, loss = 5.4324
2024-10-29 13:43:56: [2024-10-29 13:43:56] iter = 10420, loss = 1.4176
2024-10-29 13:43:56: [2024-10-29 13:43:56] iter = 10430, loss = 1.7182
2024-10-29 13:43:56: [2024-10-29 13:43:56] iter = 10440, loss = 1.6983
2024-10-29 13:43:57: [2024-10-29 13:43:57] iter = 10450, loss = 0.8303
2024-10-29 13:43:57: [2024-10-29 13:43:57] iter = 10460, loss = 0.8552
2024-10-29 13:43:57: [2024-10-29 13:43:57] iter = 10470, loss = 1.5746
2024-10-29 13:43:58: [2024-10-29 13:43:58] iter = 10480, loss = 1.2835
2024-10-29 13:43:58: [2024-10-29 13:43:58] iter = 10490, loss = 1.2844
2024-10-29 13:43:58: [2024-10-29 13:43:58] iter = 10500, loss = 1.0993
2024-10-29 13:43:59: [2024-10-29 13:43:59] iter = 10510, loss = 0.8532
2024-10-29 13:43:59: [2024-10-29 13:43:59] iter = 10520, loss = 0.7696
2024-10-29 13:43:59: [2024-10-29 13:43:59] iter = 10530, loss = 0.9965
2024-10-29 13:43:59: [2024-10-29 13:43:59] iter = 10540, loss = 0.9293
2024-10-29 13:44:00: [2024-10-29 13:44:00] iter = 10550, loss = 5.5397
2024-10-29 13:44:00: [2024-10-29 13:44:00] iter = 10560, loss = 1.4727
2024-10-29 13:44:01: [2024-10-29 13:44:01] iter = 10570, loss = 1.7973
2024-10-29 13:44:01: [2024-10-29 13:44:01] iter = 10580, loss = 1.0290
2024-10-29 13:44:01: [2024-10-29 13:44:01] iter = 10590, loss = 2.0883
2024-10-29 13:44:01: [2024-10-29 13:44:01] iter = 10600, loss = 1.7514
2024-10-29 13:44:02: [2024-10-29 13:44:02] iter = 10610, loss = 1.9146
2024-10-29 13:44:02: [2024-10-29 13:44:02] iter = 10620, loss = 2.3101
2024-10-29 13:44:02: [2024-10-29 13:44:02] iter = 10630, loss = 1.0045
2024-10-29 13:44:02: [2024-10-29 13:44:02] iter = 10640, loss = 1.0725
2024-10-29 13:44:03: [2024-10-29 13:44:03] iter = 10650, loss = 1.6635
2024-10-29 13:44:03: [2024-10-29 13:44:03] iter = 10660, loss = 1.3524
2024-10-29 13:44:03: [2024-10-29 13:44:03] iter = 10670, loss = 1.8617
2024-10-29 13:44:04: [2024-10-29 13:44:04] iter = 10680, loss = 4.4521
2024-10-29 13:44:04: [2024-10-29 13:44:04] iter = 10690, loss = 0.8849
2024-10-29 13:44:04: [2024-10-29 13:44:04] iter = 10700, loss = 0.9522
2024-10-29 13:44:05: [2024-10-29 13:44:05] iter = 10710, loss = 2.3819
2024-10-29 13:44:05: [2024-10-29 13:44:05] iter = 10720, loss = 3.0800
2024-10-29 13:44:05: [2024-10-29 13:44:05] iter = 10730, loss = 1.1731
2024-10-29 13:44:06: [2024-10-29 13:44:06] iter = 10740, loss = 1.1482
2024-10-29 13:44:06: [2024-10-29 13:44:06] iter = 10750, loss = 1.0115
2024-10-29 13:44:06: [2024-10-29 13:44:06] iter = 10760, loss = 0.9714
2024-10-29 13:44:07: [2024-10-29 13:44:07] iter = 10770, loss = 0.8907
2024-10-29 13:44:07: [2024-10-29 13:44:07] iter = 10780, loss = 1.1236
2024-10-29 13:44:07: [2024-10-29 13:44:07] iter = 10790, loss = 1.0631
2024-10-29 13:44:07: [2024-10-29 13:44:07] iter = 10800, loss = 0.7164
2024-10-29 13:44:07: [2024-10-29 13:44:07] iter = 10810, loss = 1.0156
2024-10-29 13:44:08: [2024-10-29 13:44:08] iter = 10820, loss = 2.0002
2024-10-29 13:44:08: [2024-10-29 13:44:08] iter = 10830, loss = 0.7970
2024-10-29 13:44:08: [2024-10-29 13:44:08] iter = 10840, loss = 1.4211
2024-10-29 13:44:09: [2024-10-29 13:44:09] iter = 10850, loss = 1.1066
2024-10-29 13:44:09: [2024-10-29 13:44:09] iter = 10860, loss = 2.4928
2024-10-29 13:44:09: [2024-10-29 13:44:09] iter = 10870, loss = 1.4952
2024-10-29 13:44:09: [2024-10-29 13:44:09] iter = 10880, loss = 1.4539
2024-10-29 13:44:10: [2024-10-29 13:44:10] iter = 10890, loss = 1.2471
2024-10-29 13:44:10: [2024-10-29 13:44:10] iter = 10900, loss = 1.1515
2024-10-29 13:44:10: [2024-10-29 13:44:10] iter = 10910, loss = 1.7408
2024-10-29 13:44:11: [2024-10-29 13:44:11] iter = 10920, loss = 6.3871
2024-10-29 13:44:11: [2024-10-29 13:44:11] iter = 10930, loss = 1.4348
2024-10-29 13:44:11: [2024-10-29 13:44:11] iter = 10940, loss = 0.9975
2024-10-29 13:44:12: [2024-10-29 13:44:12] iter = 10950, loss = 0.7929
2024-10-29 13:44:12: [2024-10-29 13:44:12] iter = 10960, loss = 1.4174
2024-10-29 13:44:12: [2024-10-29 13:44:12] iter = 10970, loss = 0.8288
2024-10-29 13:44:13: [2024-10-29 13:44:13] iter = 10980, loss = 2.7262
2024-10-29 13:44:13: [2024-10-29 13:44:13] iter = 10990, loss = 1.0124
2024-10-29 13:44:13: [2024-10-29 13:44:13] iter = 11000, loss = 1.0413
2024-10-29 13:44:14: [2024-10-29 13:44:14] iter = 11010, loss = 1.4074
2024-10-29 13:44:14: [2024-10-29 13:44:14] iter = 11020, loss = 3.3979
2024-10-29 13:44:14: [2024-10-29 13:44:14] iter = 11030, loss = 1.7819
2024-10-29 13:44:14: [2024-10-29 13:44:14] iter = 11040, loss = 1.0248
2024-10-29 13:44:15: [2024-10-29 13:44:15] iter = 11050, loss = 1.9833
2024-10-29 13:44:15: [2024-10-29 13:44:15] iter = 11060, loss = 1.7339
2024-10-29 13:44:15: [2024-10-29 13:44:15] iter = 11070, loss = 1.3866
2024-10-29 13:44:15: [2024-10-29 13:44:15] iter = 11080, loss = 0.8230
2024-10-29 13:44:16: [2024-10-29 13:44:16] iter = 11090, loss = 0.9568
2024-10-29 13:44:16: [2024-10-29 13:44:16] iter = 11100, loss = 1.4187
2024-10-29 13:44:16: [2024-10-29 13:44:16] iter = 11110, loss = 1.2390
2024-10-29 13:44:16: [2024-10-29 13:44:16] iter = 11120, loss = 1.2423
2024-10-29 13:44:17: [2024-10-29 13:44:17] iter = 11130, loss = 1.8210
2024-10-29 13:44:17: [2024-10-29 13:44:17] iter = 11140, loss = 1.6228
2024-10-29 13:44:17: [2024-10-29 13:44:17] iter = 11150, loss = 1.2546
2024-10-29 13:44:17: [2024-10-29 13:44:17] iter = 11160, loss = 2.2877
2024-10-29 13:44:18: [2024-10-29 13:44:18] iter = 11170, loss = 10.7492
2024-10-29 13:44:18: [2024-10-29 13:44:18] iter = 11180, loss = 1.6252
2024-10-29 13:44:18: [2024-10-29 13:44:18] iter = 11190, loss = 3.7789
2024-10-29 13:44:19: [2024-10-29 13:44:19] iter = 11200, loss = 1.6945
2024-10-29 13:44:19: [2024-10-29 13:44:19] iter = 11210, loss = 1.1172
2024-10-29 13:44:19: [2024-10-29 13:44:19] iter = 11220, loss = 1.1032
2024-10-29 13:44:20: [2024-10-29 13:44:20] iter = 11230, loss = 1.2580
2024-10-29 13:44:20: [2024-10-29 13:44:20] iter = 11240, loss = 1.0489
2024-10-29 13:44:20: [2024-10-29 13:44:20] iter = 11250, loss = 0.9166
2024-10-29 13:44:21: [2024-10-29 13:44:21] iter = 11260, loss = 1.0669
2024-10-29 13:44:21: [2024-10-29 13:44:21] iter = 11270, loss = 3.1079
2024-10-29 13:44:21: [2024-10-29 13:44:21] iter = 11280, loss = 1.2409
2024-10-29 13:44:22: [2024-10-29 13:44:22] iter = 11290, loss = 1.8652
2024-10-29 13:44:22: [2024-10-29 13:44:22] iter = 11300, loss = 1.4940
2024-10-29 13:44:22: [2024-10-29 13:44:22] iter = 11310, loss = 1.2009
2024-10-29 13:44:23: [2024-10-29 13:44:23] iter = 11320, loss = 1.6646
2024-10-29 13:44:23: [2024-10-29 13:44:23] iter = 11330, loss = 1.7850
2024-10-29 13:44:23: [2024-10-29 13:44:23] iter = 11340, loss = 1.5977
2024-10-29 13:44:24: [2024-10-29 13:44:24] iter = 11350, loss = 1.7834
2024-10-29 13:44:24: [2024-10-29 13:44:24] iter = 11360, loss = 1.1767
2024-10-29 13:44:24: [2024-10-29 13:44:24] iter = 11370, loss = 1.0896
2024-10-29 13:44:24: [2024-10-29 13:44:24] iter = 11380, loss = 1.2937
2024-10-29 13:44:25: [2024-10-29 13:44:25] iter = 11390, loss = 1.3317
2024-10-29 13:44:25: [2024-10-29 13:44:25] iter = 11400, loss = 1.8044
2024-10-29 13:44:25: [2024-10-29 13:44:25] iter = 11410, loss = 1.0071
2024-10-29 13:44:26: [2024-10-29 13:44:26] iter = 11420, loss = 0.9366
2024-10-29 13:44:26: [2024-10-29 13:44:26] iter = 11430, loss = 1.0721
2024-10-29 13:44:26: [2024-10-29 13:44:26] iter = 11440, loss = 3.5760
2024-10-29 13:44:27: [2024-10-29 13:44:27] iter = 11450, loss = 1.0132
2024-10-29 13:44:27: [2024-10-29 13:44:27] iter = 11460, loss = 2.7070
2024-10-29 13:44:27: [2024-10-29 13:44:27] iter = 11470, loss = 1.0412
2024-10-29 13:44:28: [2024-10-29 13:44:28] iter = 11480, loss = 2.8409
2024-10-29 13:44:28: [2024-10-29 13:44:28] iter = 11490, loss = 1.1483
2024-10-29 13:44:28: [2024-10-29 13:44:28] iter = 11500, loss = 1.1997
2024-10-29 13:44:28: [2024-10-29 13:44:28] iter = 11510, loss = 1.0780
2024-10-29 13:44:29: [2024-10-29 13:44:29] iter = 11520, loss = 9.1136
2024-10-29 13:44:29: [2024-10-29 13:44:29] iter = 11530, loss = 1.8943
2024-10-29 13:44:29: [2024-10-29 13:44:29] iter = 11540, loss = 0.9165
2024-10-29 13:44:30: [2024-10-29 13:44:30] iter = 11550, loss = 1.2639
2024-10-29 13:44:30: [2024-10-29 13:44:30] iter = 11560, loss = 1.1566
2024-10-29 13:44:30: [2024-10-29 13:44:30] iter = 11570, loss = 1.6548
2024-10-29 13:44:31: [2024-10-29 13:44:31] iter = 11580, loss = 1.3449
2024-10-29 13:44:31: [2024-10-29 13:44:31] iter = 11590, loss = 1.5089
2024-10-29 13:44:31: [2024-10-29 13:44:31] iter = 11600, loss = 2.1247
2024-10-29 13:44:32: [2024-10-29 13:44:32] iter = 11610, loss = 1.4419
2024-10-29 13:44:32: [2024-10-29 13:44:32] iter = 11620, loss = 0.9241
2024-10-29 13:44:32: [2024-10-29 13:44:32] iter = 11630, loss = 1.5451
2024-10-29 13:44:32: [2024-10-29 13:44:32] iter = 11640, loss = 8.2894
2024-10-29 13:44:33: [2024-10-29 13:44:33] iter = 11650, loss = 5.1551
2024-10-29 13:44:33: [2024-10-29 13:44:33] iter = 11660, loss = 0.9861
2024-10-29 13:44:33: [2024-10-29 13:44:33] iter = 11670, loss = 1.7805
2024-10-29 13:44:34: [2024-10-29 13:44:34] iter = 11680, loss = 0.9655
2024-10-29 13:44:34: [2024-10-29 13:44:34] iter = 11690, loss = 1.1915
2024-10-29 13:44:34: [2024-10-29 13:44:34] iter = 11700, loss = 1.1596
2024-10-29 13:44:35: [2024-10-29 13:44:35] iter = 11710, loss = 1.1926
2024-10-29 13:44:35: [2024-10-29 13:44:35] iter = 11720, loss = 1.8325
2024-10-29 13:44:35: [2024-10-29 13:44:35] iter = 11730, loss = 2.9243
2024-10-29 13:44:36: [2024-10-29 13:44:36] iter = 11740, loss = 1.0068
2024-10-29 13:44:36: [2024-10-29 13:44:36] iter = 11750, loss = 1.0698
2024-10-29 13:44:36: [2024-10-29 13:44:36] iter = 11760, loss = 1.8572
2024-10-29 13:44:36: [2024-10-29 13:44:36] iter = 11770, loss = 1.1141
2024-10-29 13:44:37: [2024-10-29 13:44:37] iter = 11780, loss = 13.6452
2024-10-29 13:44:37: [2024-10-29 13:44:37] iter = 11790, loss = 8.9575
2024-10-29 13:44:37: [2024-10-29 13:44:37] iter = 11800, loss = 2.5351
2024-10-29 13:44:38: [2024-10-29 13:44:38] iter = 11810, loss = 2.1963
2024-10-29 13:44:38: [2024-10-29 13:44:38] iter = 11820, loss = 1.4184
2024-10-29 13:44:38: [2024-10-29 13:44:38] iter = 11830, loss = 1.0643
2024-10-29 13:44:39: [2024-10-29 13:44:39] iter = 11840, loss = 1.4954
2024-10-29 13:44:39: [2024-10-29 13:44:39] iter = 11850, loss = 1.9164
2024-10-29 13:44:39: [2024-10-29 13:44:39] iter = 11860, loss = 1.7473
2024-10-29 13:44:39: [2024-10-29 13:44:39] iter = 11870, loss = 0.9135
2024-10-29 13:44:40: [2024-10-29 13:44:40] iter = 11880, loss = 1.7096
2024-10-29 13:44:40: [2024-10-29 13:44:40] iter = 11890, loss = 1.2894
2024-10-29 13:44:40: [2024-10-29 13:44:40] iter = 11900, loss = 1.1851
2024-10-29 13:44:41: [2024-10-29 13:44:41] iter = 11910, loss = 1.4306
2024-10-29 13:44:41: [2024-10-29 13:44:41] iter = 11920, loss = 1.6038
2024-10-29 13:44:41: [2024-10-29 13:44:41] iter = 11930, loss = 1.3315
2024-10-29 13:44:42: [2024-10-29 13:44:42] iter = 11940, loss = 1.2833
2024-10-29 13:44:42: [2024-10-29 13:44:42] iter = 11950, loss = 1.2769
2024-10-29 13:44:42: [2024-10-29 13:44:42] iter = 11960, loss = 0.8335
2024-10-29 13:44:43: [2024-10-29 13:44:43] iter = 11970, loss = 5.2848
2024-10-29 13:44:43: [2024-10-29 13:44:43] iter = 11980, loss = 1.0619
2024-10-29 13:44:43: [2024-10-29 13:44:43] iter = 11990, loss = 1.1516
2024-10-29 13:44:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 13:44:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:44:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 83910}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:45:09: Evaluate 5 random ConvNet, ACCmean = 0.3502 ACCstd = 0.0120
-------------------------
2024-10-29 13:45:09: Evaluate 5 random ConvNet, SENmean = 0.5658 SENstd = 0.0021
-------------------------
2024-10-29 13:45:09: Evaluate 5 random ConvNet, SPEmean = 0.5658 SPEstd = 0.0021
-------------------------
2024-10-29 13:45:09: Evaluate 5 random ConvNet, F!mean = 0.3311 F!std = 0.0089
-------------------------
2024-10-29 13:45:09: Evaluate 5 random ConvNet, mean = 0.3502 std = 0.0120
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:45:09: [2024-10-29 13:45:09] iter = 12000, loss = 1.6435
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:45:09: [2024-10-29 13:45:09] iter = 12010, loss = 2.9682
2024-10-29 13:45:10: [2024-10-29 13:45:10] iter = 12020, loss = 1.1232
2024-10-29 13:45:10: [2024-10-29 13:45:10] iter = 12030, loss = 1.8811
2024-10-29 13:45:10: [2024-10-29 13:45:10] iter = 12040, loss = 0.7614
2024-10-29 13:45:10: [2024-10-29 13:45:10] iter = 12050, loss = 1.2535
2024-10-29 13:45:11: [2024-10-29 13:45:11] iter = 12060, loss = 3.5636
2024-10-29 13:45:11: [2024-10-29 13:45:11] iter = 12070, loss = 0.8645
2024-10-29 13:45:11: [2024-10-29 13:45:11] iter = 12080, loss = 1.7605
2024-10-29 13:45:12: [2024-10-29 13:45:12] iter = 12090, loss = 1.2704
2024-10-29 13:45:12: [2024-10-29 13:45:12] iter = 12100, loss = 2.1459
2024-10-29 13:45:12: [2024-10-29 13:45:12] iter = 12110, loss = 1.8469
2024-10-29 13:45:13: [2024-10-29 13:45:13] iter = 12120, loss = 1.8765
2024-10-29 13:45:13: [2024-10-29 13:45:13] iter = 12130, loss = 2.1820
2024-10-29 13:45:13: [2024-10-29 13:45:13] iter = 12140, loss = 6.4897
2024-10-29 13:45:14: [2024-10-29 13:45:14] iter = 12150, loss = 1.0501
2024-10-29 13:45:14: [2024-10-29 13:45:14] iter = 12160, loss = 1.6082
2024-10-29 13:45:14: [2024-10-29 13:45:14] iter = 12170, loss = 3.9290
2024-10-29 13:45:15: [2024-10-29 13:45:15] iter = 12180, loss = 3.0662
2024-10-29 13:45:15: [2024-10-29 13:45:15] iter = 12190, loss = 0.9444
2024-10-29 13:45:15: [2024-10-29 13:45:15] iter = 12200, loss = 1.3461
2024-10-29 13:45:16: [2024-10-29 13:45:16] iter = 12210, loss = 2.0038
2024-10-29 13:45:16: [2024-10-29 13:45:16] iter = 12220, loss = 1.2050
2024-10-29 13:45:16: [2024-10-29 13:45:16] iter = 12230, loss = 1.9064
2024-10-29 13:45:16: [2024-10-29 13:45:16] iter = 12240, loss = 2.8548
2024-10-29 13:45:17: [2024-10-29 13:45:17] iter = 12250, loss = 1.2056
2024-10-29 13:45:17: [2024-10-29 13:45:17] iter = 12260, loss = 0.9673
2024-10-29 13:45:17: [2024-10-29 13:45:17] iter = 12270, loss = 1.0360
2024-10-29 13:45:18: [2024-10-29 13:45:18] iter = 12280, loss = 0.7697
2024-10-29 13:45:18: [2024-10-29 13:45:18] iter = 12290, loss = 1.0763
2024-10-29 13:45:18: [2024-10-29 13:45:18] iter = 12300, loss = 1.3005
2024-10-29 13:45:18: [2024-10-29 13:45:18] iter = 12310, loss = 1.0808
2024-10-29 13:45:19: [2024-10-29 13:45:19] iter = 12320, loss = 0.7980
2024-10-29 13:45:19: [2024-10-29 13:45:19] iter = 12330, loss = 1.2874
2024-10-29 13:45:19: [2024-10-29 13:45:19] iter = 12340, loss = 0.9565
2024-10-29 13:45:19: [2024-10-29 13:45:19] iter = 12350, loss = 2.5272
2024-10-29 13:45:20: [2024-10-29 13:45:20] iter = 12360, loss = 1.3601
2024-10-29 13:45:20: [2024-10-29 13:45:20] iter = 12370, loss = 0.8851
2024-10-29 13:45:20: [2024-10-29 13:45:20] iter = 12380, loss = 1.1010
2024-10-29 13:45:20: [2024-10-29 13:45:20] iter = 12390, loss = 4.8002
2024-10-29 13:45:20: [2024-10-29 13:45:20] iter = 12400, loss = 3.1794
2024-10-29 13:45:21: [2024-10-29 13:45:21] iter = 12410, loss = 1.1408
2024-10-29 13:45:21: [2024-10-29 13:45:21] iter = 12420, loss = 1.2632
2024-10-29 13:45:21: [2024-10-29 13:45:21] iter = 12430, loss = 2.0445
2024-10-29 13:45:21: [2024-10-29 13:45:21] iter = 12440, loss = 1.1540
2024-10-29 13:45:22: [2024-10-29 13:45:22] iter = 12450, loss = 1.9460
2024-10-29 13:45:22: [2024-10-29 13:45:22] iter = 12460, loss = 0.9848
2024-10-29 13:45:22: [2024-10-29 13:45:22] iter = 12470, loss = 1.6761
2024-10-29 13:45:22: [2024-10-29 13:45:22] iter = 12480, loss = 2.0676
2024-10-29 13:45:22: [2024-10-29 13:45:22] iter = 12490, loss = 1.3858
2024-10-29 13:45:23: [2024-10-29 13:45:23] iter = 12500, loss = 1.9337
2024-10-29 13:45:23: [2024-10-29 13:45:23] iter = 12510, loss = 1.8163
2024-10-29 13:45:23: [2024-10-29 13:45:23] iter = 12520, loss = 1.5626
2024-10-29 13:45:23: [2024-10-29 13:45:23] iter = 12530, loss = 1.2121
2024-10-29 13:45:24: [2024-10-29 13:45:24] iter = 12540, loss = 1.2141
2024-10-29 13:45:24: [2024-10-29 13:45:24] iter = 12550, loss = 1.1981
2024-10-29 13:45:24: [2024-10-29 13:45:24] iter = 12560, loss = 4.6433
2024-10-29 13:45:24: [2024-10-29 13:45:24] iter = 12570, loss = 1.1802
2024-10-29 13:45:25: [2024-10-29 13:45:25] iter = 12580, loss = 1.2552
2024-10-29 13:45:25: [2024-10-29 13:45:25] iter = 12590, loss = 3.4801
2024-10-29 13:45:25: [2024-10-29 13:45:25] iter = 12600, loss = 1.0097
2024-10-29 13:45:25: [2024-10-29 13:45:25] iter = 12610, loss = 1.1907
2024-10-29 13:45:26: [2024-10-29 13:45:26] iter = 12620, loss = 1.1223
2024-10-29 13:45:26: [2024-10-29 13:45:26] iter = 12630, loss = 1.9920
2024-10-29 13:45:26: [2024-10-29 13:45:26] iter = 12640, loss = 1.0616
2024-10-29 13:45:26: [2024-10-29 13:45:26] iter = 12650, loss = 0.8984
2024-10-29 13:45:27: [2024-10-29 13:45:27] iter = 12660, loss = 1.1458
2024-10-29 13:45:27: [2024-10-29 13:45:27] iter = 12670, loss = 1.7934
2024-10-29 13:45:27: [2024-10-29 13:45:27] iter = 12680, loss = 5.4736
2024-10-29 13:45:27: [2024-10-29 13:45:27] iter = 12690, loss = 1.4527
2024-10-29 13:45:28: [2024-10-29 13:45:28] iter = 12700, loss = 1.1474
2024-10-29 13:45:28: [2024-10-29 13:45:28] iter = 12710, loss = 0.6433
2024-10-29 13:45:28: [2024-10-29 13:45:28] iter = 12720, loss = 1.0397
2024-10-29 13:45:29: [2024-10-29 13:45:29] iter = 12730, loss = 2.8843
2024-10-29 13:45:29: [2024-10-29 13:45:29] iter = 12740, loss = 1.4344
2024-10-29 13:45:29: [2024-10-29 13:45:29] iter = 12750, loss = 1.2214
2024-10-29 13:45:29: [2024-10-29 13:45:29] iter = 12760, loss = 1.8397
2024-10-29 13:45:30: [2024-10-29 13:45:30] iter = 12770, loss = 0.7548
2024-10-29 13:45:30: [2024-10-29 13:45:30] iter = 12780, loss = 1.8183
2024-10-29 13:45:30: [2024-10-29 13:45:30] iter = 12790, loss = 1.2252
2024-10-29 13:45:30: [2024-10-29 13:45:30] iter = 12800, loss = 0.9614
2024-10-29 13:45:31: [2024-10-29 13:45:31] iter = 12810, loss = 1.2022
2024-10-29 13:45:31: [2024-10-29 13:45:31] iter = 12820, loss = 1.1828
2024-10-29 13:45:31: [2024-10-29 13:45:31] iter = 12830, loss = 1.3412
2024-10-29 13:45:32: [2024-10-29 13:45:32] iter = 12840, loss = 0.8998
2024-10-29 13:45:32: [2024-10-29 13:45:32] iter = 12850, loss = 4.6979
2024-10-29 13:45:32: [2024-10-29 13:45:32] iter = 12860, loss = 1.1059
2024-10-29 13:45:33: [2024-10-29 13:45:33] iter = 12870, loss = 2.4413
2024-10-29 13:45:33: [2024-10-29 13:45:33] iter = 12880, loss = 1.4985
2024-10-29 13:45:34: [2024-10-29 13:45:34] iter = 12890, loss = 2.4223
2024-10-29 13:45:34: [2024-10-29 13:45:34] iter = 12900, loss = 1.6687
2024-10-29 13:45:34: [2024-10-29 13:45:34] iter = 12910, loss = 4.9498
2024-10-29 13:45:35: [2024-10-29 13:45:35] iter = 12920, loss = 2.3127
2024-10-29 13:45:35: [2024-10-29 13:45:35] iter = 12930, loss = 0.8957
2024-10-29 13:45:35: [2024-10-29 13:45:35] iter = 12940, loss = 1.0850
2024-10-29 13:45:35: [2024-10-29 13:45:35] iter = 12950, loss = 1.4191
2024-10-29 13:45:36: [2024-10-29 13:45:36] iter = 12960, loss = 1.3100
2024-10-29 13:45:36: [2024-10-29 13:45:36] iter = 12970, loss = 1.9871
2024-10-29 13:45:36: [2024-10-29 13:45:36] iter = 12980, loss = 1.0065
2024-10-29 13:45:36: [2024-10-29 13:45:36] iter = 12990, loss = 1.3120
2024-10-29 13:45:37: [2024-10-29 13:45:37] iter = 13000, loss = 1.8451
2024-10-29 13:45:37: [2024-10-29 13:45:37] iter = 13010, loss = 1.1574
2024-10-29 13:45:37: [2024-10-29 13:45:37] iter = 13020, loss = 1.5520
2024-10-29 13:45:37: [2024-10-29 13:45:37] iter = 13030, loss = 1.1101
2024-10-29 13:45:38: [2024-10-29 13:45:38] iter = 13040, loss = 1.5819
2024-10-29 13:45:38: [2024-10-29 13:45:38] iter = 13050, loss = 1.4535
2024-10-29 13:45:38: [2024-10-29 13:45:38] iter = 13060, loss = 1.7278
2024-10-29 13:45:38: [2024-10-29 13:45:38] iter = 13070, loss = 1.0230
2024-10-29 13:45:38: [2024-10-29 13:45:38] iter = 13080, loss = 2.5516
2024-10-29 13:45:39: [2024-10-29 13:45:39] iter = 13090, loss = 2.3541
2024-10-29 13:45:39: [2024-10-29 13:45:39] iter = 13100, loss = 1.5735
2024-10-29 13:45:39: [2024-10-29 13:45:39] iter = 13110, loss = 0.7888
2024-10-29 13:45:39: [2024-10-29 13:45:39] iter = 13120, loss = 1.3095
2024-10-29 13:45:40: [2024-10-29 13:45:40] iter = 13130, loss = 1.0194
2024-10-29 13:45:40: [2024-10-29 13:45:40] iter = 13140, loss = 1.2501
2024-10-29 13:45:40: [2024-10-29 13:45:40] iter = 13150, loss = 1.7463
2024-10-29 13:45:40: [2024-10-29 13:45:40] iter = 13160, loss = 1.3097
2024-10-29 13:45:41: [2024-10-29 13:45:41] iter = 13170, loss = 6.0646
2024-10-29 13:45:41: [2024-10-29 13:45:41] iter = 13180, loss = 1.6828
2024-10-29 13:45:41: [2024-10-29 13:45:41] iter = 13190, loss = 1.8537
2024-10-29 13:45:42: [2024-10-29 13:45:42] iter = 13200, loss = 1.8490
2024-10-29 13:45:42: [2024-10-29 13:45:42] iter = 13210, loss = 1.1231
2024-10-29 13:45:42: [2024-10-29 13:45:42] iter = 13220, loss = 1.4790
2024-10-29 13:45:43: [2024-10-29 13:45:43] iter = 13230, loss = 1.4295
2024-10-29 13:45:43: [2024-10-29 13:45:43] iter = 13240, loss = 1.0596
2024-10-29 13:45:43: [2024-10-29 13:45:43] iter = 13250, loss = 1.3814
2024-10-29 13:45:44: [2024-10-29 13:45:44] iter = 13260, loss = 0.7625
2024-10-29 13:45:44: [2024-10-29 13:45:44] iter = 13270, loss = 1.8895
2024-10-29 13:45:44: [2024-10-29 13:45:44] iter = 13280, loss = 2.5933
2024-10-29 13:45:44: [2024-10-29 13:45:44] iter = 13290, loss = 1.1736
2024-10-29 13:45:44: [2024-10-29 13:45:44] iter = 13300, loss = 0.9619
2024-10-29 13:45:45: [2024-10-29 13:45:45] iter = 13310, loss = 1.4470
2024-10-29 13:45:45: [2024-10-29 13:45:45] iter = 13320, loss = 6.4172
2024-10-29 13:45:45: [2024-10-29 13:45:45] iter = 13330, loss = 1.3716
2024-10-29 13:45:45: [2024-10-29 13:45:45] iter = 13340, loss = 1.4027
2024-10-29 13:45:46: [2024-10-29 13:45:46] iter = 13350, loss = 1.0033
2024-10-29 13:45:46: [2024-10-29 13:45:46] iter = 13360, loss = 1.2043
2024-10-29 13:45:46: [2024-10-29 13:45:46] iter = 13370, loss = 2.0775
2024-10-29 13:45:46: [2024-10-29 13:45:46] iter = 13380, loss = 0.9700
2024-10-29 13:45:47: [2024-10-29 13:45:47] iter = 13390, loss = 0.9821
2024-10-29 13:45:47: [2024-10-29 13:45:47] iter = 13400, loss = 1.2904
2024-10-29 13:45:47: [2024-10-29 13:45:47] iter = 13410, loss = 1.2368
2024-10-29 13:45:47: [2024-10-29 13:45:47] iter = 13420, loss = 1.5467
2024-10-29 13:45:48: [2024-10-29 13:45:48] iter = 13430, loss = 1.5289
2024-10-29 13:45:48: [2024-10-29 13:45:48] iter = 13440, loss = 1.1578
2024-10-29 13:45:48: [2024-10-29 13:45:48] iter = 13450, loss = 4.2596
2024-10-29 13:45:48: [2024-10-29 13:45:48] iter = 13460, loss = 0.9496
2024-10-29 13:45:49: [2024-10-29 13:45:49] iter = 13470, loss = 1.2919
2024-10-29 13:45:49: [2024-10-29 13:45:49] iter = 13480, loss = 0.8702
2024-10-29 13:45:49: [2024-10-29 13:45:49] iter = 13490, loss = 0.9888
2024-10-29 13:45:50: [2024-10-29 13:45:50] iter = 13500, loss = 1.9751
2024-10-29 13:45:50: [2024-10-29 13:45:50] iter = 13510, loss = 1.2145
2024-10-29 13:45:50: [2024-10-29 13:45:50] iter = 13520, loss = 1.7477
2024-10-29 13:45:50: [2024-10-29 13:45:50] iter = 13530, loss = 2.1128
2024-10-29 13:45:51: [2024-10-29 13:45:51] iter = 13540, loss = 1.1163
2024-10-29 13:45:51: [2024-10-29 13:45:51] iter = 13550, loss = 1.2025
2024-10-29 13:45:51: [2024-10-29 13:45:51] iter = 13560, loss = 1.4770
2024-10-29 13:45:51: [2024-10-29 13:45:51] iter = 13570, loss = 0.8781
2024-10-29 13:45:52: [2024-10-29 13:45:52] iter = 13580, loss = 3.1671
2024-10-29 13:45:52: [2024-10-29 13:45:52] iter = 13590, loss = 0.9887
2024-10-29 13:45:52: [2024-10-29 13:45:52] iter = 13600, loss = 0.9709
2024-10-29 13:45:53: [2024-10-29 13:45:53] iter = 13610, loss = 0.9968
2024-10-29 13:45:53: [2024-10-29 13:45:53] iter = 13620, loss = 1.4911
2024-10-29 13:45:53: [2024-10-29 13:45:53] iter = 13630, loss = 0.9725
2024-10-29 13:45:53: [2024-10-29 13:45:53] iter = 13640, loss = 1.6691
2024-10-29 13:45:54: [2024-10-29 13:45:54] iter = 13650, loss = 2.1759
2024-10-29 13:45:54: [2024-10-29 13:45:54] iter = 13660, loss = 1.8571
2024-10-29 13:45:54: [2024-10-29 13:45:54] iter = 13670, loss = 1.9727
2024-10-29 13:45:55: [2024-10-29 13:45:55] iter = 13680, loss = 1.7409
2024-10-29 13:45:55: [2024-10-29 13:45:55] iter = 13690, loss = 0.9968
2024-10-29 13:45:55: [2024-10-29 13:45:55] iter = 13700, loss = 0.9448
2024-10-29 13:45:56: [2024-10-29 13:45:56] iter = 13710, loss = 1.9292
2024-10-29 13:45:56: [2024-10-29 13:45:56] iter = 13720, loss = 1.6533
2024-10-29 13:45:56: [2024-10-29 13:45:56] iter = 13730, loss = 1.2479
2024-10-29 13:45:57: [2024-10-29 13:45:57] iter = 13740, loss = 1.2006
2024-10-29 13:45:57: [2024-10-29 13:45:57] iter = 13750, loss = 1.4164
2024-10-29 13:45:57: [2024-10-29 13:45:57] iter = 13760, loss = 1.1049
2024-10-29 13:45:58: [2024-10-29 13:45:58] iter = 13770, loss = 1.1319
2024-10-29 13:45:58: [2024-10-29 13:45:58] iter = 13780, loss = 1.0666
2024-10-29 13:45:58: [2024-10-29 13:45:58] iter = 13790, loss = 1.1751
2024-10-29 13:45:58: [2024-10-29 13:45:58] iter = 13800, loss = 1.1537
2024-10-29 13:45:58: [2024-10-29 13:45:58] iter = 13810, loss = 1.4921
2024-10-29 13:45:59: [2024-10-29 13:45:59] iter = 13820, loss = 0.9034
2024-10-29 13:45:59: [2024-10-29 13:45:59] iter = 13830, loss = 1.9393
2024-10-29 13:45:59: [2024-10-29 13:45:59] iter = 13840, loss = 0.8346
2024-10-29 13:45:59: [2024-10-29 13:45:59] iter = 13850, loss = 2.6720
2024-10-29 13:46:00: [2024-10-29 13:46:00] iter = 13860, loss = 2.5889
2024-10-29 13:46:00: [2024-10-29 13:46:00] iter = 13870, loss = 1.1238
2024-10-29 13:46:00: [2024-10-29 13:46:00] iter = 13880, loss = 1.4286
2024-10-29 13:46:00: [2024-10-29 13:46:00] iter = 13890, loss = 3.8430
2024-10-29 13:46:01: [2024-10-29 13:46:01] iter = 13900, loss = 1.5250
2024-10-29 13:46:01: [2024-10-29 13:46:01] iter = 13910, loss = 1.2004
2024-10-29 13:46:01: [2024-10-29 13:46:01] iter = 13920, loss = 1.9994
2024-10-29 13:46:02: [2024-10-29 13:46:02] iter = 13930, loss = 0.8745
2024-10-29 13:46:02: [2024-10-29 13:46:02] iter = 13940, loss = 1.4091
2024-10-29 13:46:02: [2024-10-29 13:46:02] iter = 13950, loss = 1.6269
2024-10-29 13:46:03: [2024-10-29 13:46:03] iter = 13960, loss = 1.3742
2024-10-29 13:46:03: [2024-10-29 13:46:03] iter = 13970, loss = 5.0077
2024-10-29 13:46:03: [2024-10-29 13:46:03] iter = 13980, loss = 3.5095
2024-10-29 13:46:03: [2024-10-29 13:46:03] iter = 13990, loss = 1.1169
2024-10-29 13:46:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 13:46:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:46:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 64242}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:46:30: Evaluate 5 random ConvNet, ACCmean = 0.5908 ACCstd = 0.0109
-------------------------
2024-10-29 13:46:30: Evaluate 5 random ConvNet, SENmean = 0.6060 SENstd = 0.0033
-------------------------
2024-10-29 13:46:30: Evaluate 5 random ConvNet, SPEmean = 0.6060 SPEstd = 0.0033
-------------------------
2024-10-29 13:46:30: Evaluate 5 random ConvNet, F!mean = 0.4834 F!std = 0.0056
-------------------------
2024-10-29 13:46:30: Evaluate 5 random ConvNet, mean = 0.5908 std = 0.0109
-------------------------
2024-10-29 13:46:30: [2024-10-29 13:46:30] iter = 14000, loss = 0.9473
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:46:31: [2024-10-29 13:46:31] iter = 14010, loss = 1.2597
2024-10-29 13:46:31: [2024-10-29 13:46:31] iter = 14020, loss = 1.1385
2024-10-29 13:46:31: [2024-10-29 13:46:31] iter = 14030, loss = 1.9662
2024-10-29 13:46:31: [2024-10-29 13:46:31] iter = 14040, loss = 2.0355
2024-10-29 13:46:32: [2024-10-29 13:46:32] iter = 14050, loss = 0.9982
2024-10-29 13:46:32: [2024-10-29 13:46:32] iter = 14060, loss = 1.4448
2024-10-29 13:46:32: [2024-10-29 13:46:32] iter = 14070, loss = 2.2130
2024-10-29 13:46:33: [2024-10-29 13:46:33] iter = 14080, loss = 1.8873
2024-10-29 13:46:33: [2024-10-29 13:46:33] iter = 14090, loss = 1.7643
2024-10-29 13:46:33: [2024-10-29 13:46:33] iter = 14100, loss = 1.3734
2024-10-29 13:46:34: [2024-10-29 13:46:34] iter = 14110, loss = 3.4666
2024-10-29 13:46:34: [2024-10-29 13:46:34] iter = 14120, loss = 1.7924
2024-10-29 13:46:34: [2024-10-29 13:46:34] iter = 14130, loss = 1.6955
2024-10-29 13:46:35: [2024-10-29 13:46:35] iter = 14140, loss = 1.4851
2024-10-29 13:46:35: [2024-10-29 13:46:35] iter = 14150, loss = 5.0658
2024-10-29 13:46:35: [2024-10-29 13:46:35] iter = 14160, loss = 1.7602
2024-10-29 13:46:36: [2024-10-29 13:46:36] iter = 14170, loss = 1.2405
2024-10-29 13:46:36: [2024-10-29 13:46:36] iter = 14180, loss = 2.1541
2024-10-29 13:46:36: [2024-10-29 13:46:36] iter = 14190, loss = 2.5553
2024-10-29 13:46:36: [2024-10-29 13:46:36] iter = 14200, loss = 1.4009
2024-10-29 13:46:37: [2024-10-29 13:46:37] iter = 14210, loss = 1.1651
2024-10-29 13:46:37: [2024-10-29 13:46:37] iter = 14220, loss = 1.3620
2024-10-29 13:46:37: [2024-10-29 13:46:37] iter = 14230, loss = 2.0270
2024-10-29 13:46:38: [2024-10-29 13:46:38] iter = 14240, loss = 1.4143
2024-10-29 13:46:38: [2024-10-29 13:46:38] iter = 14250, loss = 1.7168
2024-10-29 13:46:38: [2024-10-29 13:46:38] iter = 14260, loss = 1.2928
2024-10-29 13:46:39: [2024-10-29 13:46:39] iter = 14270, loss = 1.9333
2024-10-29 13:46:39: [2024-10-29 13:46:39] iter = 14280, loss = 1.3604
2024-10-29 13:46:39: [2024-10-29 13:46:39] iter = 14290, loss = 1.6130
2024-10-29 13:46:39: [2024-10-29 13:46:39] iter = 14300, loss = 1.2052
2024-10-29 13:46:40: [2024-10-29 13:46:40] iter = 14310, loss = 0.6958
2024-10-29 13:46:40: [2024-10-29 13:46:40] iter = 14320, loss = 1.2416
2024-10-29 13:46:40: [2024-10-29 13:46:40] iter = 14330, loss = 2.0392
2024-10-29 13:46:41: [2024-10-29 13:46:41] iter = 14340, loss = 1.7496
2024-10-29 13:46:41: [2024-10-29 13:46:41] iter = 14350, loss = 0.8232
2024-10-29 13:46:41: [2024-10-29 13:46:41] iter = 14360, loss = 0.9912
2024-10-29 13:46:42: [2024-10-29 13:46:42] iter = 14370, loss = 2.2258
2024-10-29 13:46:42: [2024-10-29 13:46:42] iter = 14380, loss = 0.7022
2024-10-29 13:46:42: [2024-10-29 13:46:42] iter = 14390, loss = 1.3504
2024-10-29 13:46:42: [2024-10-29 13:46:42] iter = 14400, loss = 1.7405
2024-10-29 13:46:43: [2024-10-29 13:46:43] iter = 14410, loss = 1.0313
2024-10-29 13:46:43: [2024-10-29 13:46:43] iter = 14420, loss = 1.0800
2024-10-29 13:46:43: [2024-10-29 13:46:43] iter = 14430, loss = 1.3929
2024-10-29 13:46:44: [2024-10-29 13:46:44] iter = 14440, loss = 1.2029
2024-10-29 13:46:44: [2024-10-29 13:46:44] iter = 14450, loss = 1.5882
2024-10-29 13:46:44: [2024-10-29 13:46:44] iter = 14460, loss = 1.0746
2024-10-29 13:46:45: [2024-10-29 13:46:45] iter = 14470, loss = 3.3687
2024-10-29 13:46:45: [2024-10-29 13:46:45] iter = 14480, loss = 1.8683
2024-10-29 13:46:45: [2024-10-29 13:46:45] iter = 14490, loss = 6.3961
2024-10-29 13:46:46: [2024-10-29 13:46:46] iter = 14500, loss = 5.4709
2024-10-29 13:46:46: [2024-10-29 13:46:46] iter = 14510, loss = 2.6560
2024-10-29 13:46:46: [2024-10-29 13:46:46] iter = 14520, loss = 0.8995
2024-10-29 13:46:47: [2024-10-29 13:46:47] iter = 14530, loss = 1.3827
2024-10-29 13:46:47: [2024-10-29 13:46:47] iter = 14540, loss = 1.4079
2024-10-29 13:46:47: [2024-10-29 13:46:47] iter = 14550, loss = 2.1750
2024-10-29 13:46:47: [2024-10-29 13:46:47] iter = 14560, loss = 1.0230
2024-10-29 13:46:48: [2024-10-29 13:46:48] iter = 14570, loss = 1.9299
2024-10-29 13:46:48: [2024-10-29 13:46:48] iter = 14580, loss = 1.6193
2024-10-29 13:46:48: [2024-10-29 13:46:48] iter = 14590, loss = 2.2514
2024-10-29 13:46:49: [2024-10-29 13:46:49] iter = 14600, loss = 2.2518
2024-10-29 13:46:49: [2024-10-29 13:46:49] iter = 14610, loss = 1.3494
2024-10-29 13:46:49: [2024-10-29 13:46:49] iter = 14620, loss = 0.9773
2024-10-29 13:46:50: [2024-10-29 13:46:49] iter = 14630, loss = 1.3150
2024-10-29 13:46:50: [2024-10-29 13:46:50] iter = 14640, loss = 1.9483
2024-10-29 13:46:50: [2024-10-29 13:46:50] iter = 14650, loss = 1.6486
2024-10-29 13:46:50: [2024-10-29 13:46:50] iter = 14660, loss = 1.5314
2024-10-29 13:46:51: [2024-10-29 13:46:51] iter = 14670, loss = 1.7191
2024-10-29 13:46:51: [2024-10-29 13:46:51] iter = 14680, loss = 1.0972
2024-10-29 13:46:51: [2024-10-29 13:46:51] iter = 14690, loss = 1.4663
2024-10-29 13:46:51: [2024-10-29 13:46:51] iter = 14700, loss = 1.7349
2024-10-29 13:46:52: [2024-10-29 13:46:52] iter = 14710, loss = 1.1488
2024-10-29 13:46:52: [2024-10-29 13:46:52] iter = 14720, loss = 0.9906
2024-10-29 13:46:52: [2024-10-29 13:46:52] iter = 14730, loss = 1.7474
2024-10-29 13:46:53: [2024-10-29 13:46:53] iter = 14740, loss = 11.9219
2024-10-29 13:46:53: [2024-10-29 13:46:53] iter = 14750, loss = 1.3694
2024-10-29 13:46:53: [2024-10-29 13:46:53] iter = 14760, loss = 1.1370
2024-10-29 13:46:54: [2024-10-29 13:46:54] iter = 14770, loss = 4.4026
2024-10-29 13:46:54: [2024-10-29 13:46:54] iter = 14780, loss = 1.5416
2024-10-29 13:46:54: [2024-10-29 13:46:54] iter = 14790, loss = 1.1136
2024-10-29 13:46:54: [2024-10-29 13:46:54] iter = 14800, loss = 1.1833
2024-10-29 13:46:55: [2024-10-29 13:46:55] iter = 14810, loss = 1.6439
2024-10-29 13:46:55: [2024-10-29 13:46:55] iter = 14820, loss = 0.9695
2024-10-29 13:46:55: [2024-10-29 13:46:55] iter = 14830, loss = 0.9932
2024-10-29 13:46:56: [2024-10-29 13:46:56] iter = 14840, loss = 1.4777
2024-10-29 13:46:56: [2024-10-29 13:46:56] iter = 14850, loss = 1.6332
2024-10-29 13:46:56: [2024-10-29 13:46:56] iter = 14860, loss = 1.6594
2024-10-29 13:46:56: [2024-10-29 13:46:56] iter = 14870, loss = 1.0185
2024-10-29 13:46:57: [2024-10-29 13:46:57] iter = 14880, loss = 1.1128
2024-10-29 13:46:57: [2024-10-29 13:46:57] iter = 14890, loss = 0.9273
2024-10-29 13:46:57: [2024-10-29 13:46:57] iter = 14900, loss = 1.2054
2024-10-29 13:46:57: [2024-10-29 13:46:57] iter = 14910, loss = 1.5958
2024-10-29 13:46:58: [2024-10-29 13:46:58] iter = 14920, loss = 1.0499
2024-10-29 13:46:58: [2024-10-29 13:46:58] iter = 14930, loss = 1.8712
2024-10-29 13:46:58: [2024-10-29 13:46:58] iter = 14940, loss = 6.5034
2024-10-29 13:46:58: [2024-10-29 13:46:58] iter = 14950, loss = 2.5200
2024-10-29 13:46:59: [2024-10-29 13:46:59] iter = 14960, loss = 1.2250
2024-10-29 13:46:59: [2024-10-29 13:46:59] iter = 14970, loss = 0.8921
2024-10-29 13:46:59: [2024-10-29 13:46:59] iter = 14980, loss = 1.9963
2024-10-29 13:46:59: [2024-10-29 13:46:59] iter = 14990, loss = 1.9678
2024-10-29 13:47:00: [2024-10-29 13:47:00] iter = 15000, loss = 1.4621
2024-10-29 13:47:00: [2024-10-29 13:47:00] iter = 15010, loss = 1.0443
2024-10-29 13:47:00: [2024-10-29 13:47:00] iter = 15020, loss = 0.8808
2024-10-29 13:47:00: [2024-10-29 13:47:00] iter = 15030, loss = 1.1777
2024-10-29 13:47:01: [2024-10-29 13:47:01] iter = 15040, loss = 1.2303
2024-10-29 13:47:01: [2024-10-29 13:47:01] iter = 15050, loss = 0.9266
2024-10-29 13:47:01: [2024-10-29 13:47:01] iter = 15060, loss = 1.5712
2024-10-29 13:47:01: [2024-10-29 13:47:01] iter = 15070, loss = 1.0855
2024-10-29 13:47:02: [2024-10-29 13:47:02] iter = 15080, loss = 1.2650
2024-10-29 13:47:02: [2024-10-29 13:47:02] iter = 15090, loss = 0.9737
2024-10-29 13:47:02: [2024-10-29 13:47:02] iter = 15100, loss = 1.0024
2024-10-29 13:47:03: [2024-10-29 13:47:03] iter = 15110, loss = 1.4989
2024-10-29 13:47:03: [2024-10-29 13:47:03] iter = 15120, loss = 1.0114
2024-10-29 13:47:03: [2024-10-29 13:47:03] iter = 15130, loss = 1.1271
2024-10-29 13:47:04: [2024-10-29 13:47:04] iter = 15140, loss = 2.2284
2024-10-29 13:47:04: [2024-10-29 13:47:04] iter = 15150, loss = 2.5265
2024-10-29 13:47:04: [2024-10-29 13:47:04] iter = 15160, loss = 1.6914
2024-10-29 13:47:04: [2024-10-29 13:47:04] iter = 15170, loss = 2.1913
2024-10-29 13:47:05: [2024-10-29 13:47:05] iter = 15180, loss = 3.2788
2024-10-29 13:47:05: [2024-10-29 13:47:05] iter = 15190, loss = 1.1916
2024-10-29 13:47:05: [2024-10-29 13:47:05] iter = 15200, loss = 0.9119
2024-10-29 13:47:05: [2024-10-29 13:47:05] iter = 15210, loss = 1.0809
2024-10-29 13:47:05: [2024-10-29 13:47:05] iter = 15220, loss = 3.3236
2024-10-29 13:47:06: [2024-10-29 13:47:06] iter = 15230, loss = 0.8372
2024-10-29 13:47:06: [2024-10-29 13:47:06] iter = 15240, loss = 0.9469
2024-10-29 13:47:06: [2024-10-29 13:47:06] iter = 15250, loss = 1.2950
2024-10-29 13:47:06: [2024-10-29 13:47:06] iter = 15260, loss = 2.1110
2024-10-29 13:47:07: [2024-10-29 13:47:07] iter = 15270, loss = 1.8481
2024-10-29 13:47:07: [2024-10-29 13:47:07] iter = 15280, loss = 0.8514
2024-10-29 13:47:07: [2024-10-29 13:47:07] iter = 15290, loss = 0.9235
2024-10-29 13:47:07: [2024-10-29 13:47:07] iter = 15300, loss = 0.9218
2024-10-29 13:47:08: [2024-10-29 13:47:08] iter = 15310, loss = 5.8449
2024-10-29 13:47:08: [2024-10-29 13:47:08] iter = 15320, loss = 3.0801
2024-10-29 13:47:08: [2024-10-29 13:47:08] iter = 15330, loss = 1.7553
2024-10-29 13:47:09: [2024-10-29 13:47:09] iter = 15340, loss = 1.7884
2024-10-29 13:47:09: [2024-10-29 13:47:09] iter = 15350, loss = 1.0179
2024-10-29 13:47:09: [2024-10-29 13:47:09] iter = 15360, loss = 0.9922
2024-10-29 13:47:09: [2024-10-29 13:47:09] iter = 15370, loss = 1.7492
2024-10-29 13:47:09: [2024-10-29 13:47:09] iter = 15380, loss = 0.9603
2024-10-29 13:47:10: [2024-10-29 13:47:10] iter = 15390, loss = 1.0646
2024-10-29 13:47:10: [2024-10-29 13:47:10] iter = 15400, loss = 0.9703
2024-10-29 13:47:10: [2024-10-29 13:47:10] iter = 15410, loss = 3.3419
2024-10-29 13:47:11: [2024-10-29 13:47:11] iter = 15420, loss = 2.1478
2024-10-29 13:47:11: [2024-10-29 13:47:11] iter = 15430, loss = 1.6231
2024-10-29 13:47:11: [2024-10-29 13:47:11] iter = 15440, loss = 1.5441
2024-10-29 13:47:12: [2024-10-29 13:47:12] iter = 15450, loss = 3.7086
2024-10-29 13:47:12: [2024-10-29 13:47:12] iter = 15460, loss = 1.6925
2024-10-29 13:47:12: [2024-10-29 13:47:12] iter = 15470, loss = 0.9953
2024-10-29 13:47:13: [2024-10-29 13:47:13] iter = 15480, loss = 0.9012
2024-10-29 13:47:13: [2024-10-29 13:47:13] iter = 15490, loss = 3.0817
2024-10-29 13:47:13: [2024-10-29 13:47:13] iter = 15500, loss = 1.0514
2024-10-29 13:47:13: [2024-10-29 13:47:13] iter = 15510, loss = 0.9964
2024-10-29 13:47:14: [2024-10-29 13:47:14] iter = 15520, loss = 1.0353
2024-10-29 13:47:14: [2024-10-29 13:47:14] iter = 15530, loss = 1.4526
2024-10-29 13:47:15: [2024-10-29 13:47:15] iter = 15540, loss = 1.3965
2024-10-29 13:47:15: [2024-10-29 13:47:15] iter = 15550, loss = 2.6024
2024-10-29 13:47:15: [2024-10-29 13:47:15] iter = 15560, loss = 1.1535
2024-10-29 13:47:16: [2024-10-29 13:47:16] iter = 15570, loss = 1.2671
2024-10-29 13:47:16: [2024-10-29 13:47:16] iter = 15580, loss = 1.8771
2024-10-29 13:47:17: [2024-10-29 13:47:17] iter = 15590, loss = 1.3783
2024-10-29 13:47:17: [2024-10-29 13:47:17] iter = 15600, loss = 1.7524
2024-10-29 13:47:17: [2024-10-29 13:47:17] iter = 15610, loss = 1.4826
2024-10-29 13:47:18: [2024-10-29 13:47:18] iter = 15620, loss = 2.0149
2024-10-29 13:47:18: [2024-10-29 13:47:18] iter = 15630, loss = 1.4765
2024-10-29 13:47:19: [2024-10-29 13:47:19] iter = 15640, loss = 2.5441
2024-10-29 13:47:19: [2024-10-29 13:47:19] iter = 15650, loss = 1.7872
2024-10-29 13:47:19: [2024-10-29 13:47:19] iter = 15660, loss = 0.8972
2024-10-29 13:47:20: [2024-10-29 13:47:20] iter = 15670, loss = 7.9476
2024-10-29 13:47:20: [2024-10-29 13:47:20] iter = 15680, loss = 2.2901
2024-10-29 13:47:21: [2024-10-29 13:47:21] iter = 15690, loss = 1.2990
2024-10-29 13:47:21: [2024-10-29 13:47:21] iter = 15700, loss = 1.5546
2024-10-29 13:47:21: [2024-10-29 13:47:21] iter = 15710, loss = 2.1702
2024-10-29 13:47:22: [2024-10-29 13:47:22] iter = 15720, loss = 1.5811
2024-10-29 13:47:22: [2024-10-29 13:47:22] iter = 15730, loss = 0.9483
2024-10-29 13:47:22: [2024-10-29 13:47:22] iter = 15740, loss = 1.3479
2024-10-29 13:47:23: [2024-10-29 13:47:23] iter = 15750, loss = 1.0108
2024-10-29 13:47:23: [2024-10-29 13:47:23] iter = 15760, loss = 0.6955
2024-10-29 13:47:23: [2024-10-29 13:47:23] iter = 15770, loss = 1.1379
2024-10-29 13:47:24: [2024-10-29 13:47:24] iter = 15780, loss = 1.2662
2024-10-29 13:47:24: [2024-10-29 13:47:24] iter = 15790, loss = 1.0138
2024-10-29 13:47:25: [2024-10-29 13:47:25] iter = 15800, loss = 1.2851
2024-10-29 13:47:25: [2024-10-29 13:47:25] iter = 15810, loss = 1.4134
2024-10-29 13:47:25: [2024-10-29 13:47:25] iter = 15820, loss = 1.3607
2024-10-29 13:47:26: [2024-10-29 13:47:26] iter = 15830, loss = 1.7725
2024-10-29 13:47:26: [2024-10-29 13:47:26] iter = 15840, loss = 1.9164
2024-10-29 13:47:27: [2024-10-29 13:47:27] iter = 15850, loss = 1.0569
2024-10-29 13:47:27: [2024-10-29 13:47:27] iter = 15860, loss = 2.3758
2024-10-29 13:47:27: [2024-10-29 13:47:27] iter = 15870, loss = 3.4304
2024-10-29 13:47:28: [2024-10-29 13:47:28] iter = 15880, loss = 1.2158
2024-10-29 13:47:28: [2024-10-29 13:47:28] iter = 15890, loss = 1.0275
2024-10-29 13:47:28: [2024-10-29 13:47:28] iter = 15900, loss = 1.0922
2024-10-29 13:47:29: [2024-10-29 13:47:29] iter = 15910, loss = 1.2585
2024-10-29 13:47:29: [2024-10-29 13:47:29] iter = 15920, loss = 1.3151
2024-10-29 13:47:30: [2024-10-29 13:47:30] iter = 15930, loss = 2.0165
2024-10-29 13:47:30: [2024-10-29 13:47:30] iter = 15940, loss = 1.5338
2024-10-29 13:47:31: [2024-10-29 13:47:31] iter = 15950, loss = 1.3997
2024-10-29 13:47:31: [2024-10-29 13:47:31] iter = 15960, loss = 1.3635
2024-10-29 13:47:31: [2024-10-29 13:47:31] iter = 15970, loss = 1.7467
2024-10-29 13:47:32: [2024-10-29 13:47:32] iter = 15980, loss = 4.7683
2024-10-29 13:47:32: [2024-10-29 13:47:32] iter = 15990, loss = 2.7506
2024-10-29 13:47:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 13:47:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:47:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53253}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:48:01: Evaluate 5 random ConvNet, ACCmean = 0.5404 ACCstd = 0.0298
-------------------------
2024-10-29 13:48:01: Evaluate 5 random ConvNet, SENmean = 0.5943 SENstd = 0.0021
-------------------------
2024-10-29 13:48:01: Evaluate 5 random ConvNet, SPEmean = 0.5943 SPEstd = 0.0021
-------------------------
2024-10-29 13:48:01: Evaluate 5 random ConvNet, F!mean = 0.4538 F!std = 0.0161
-------------------------
2024-10-29 13:48:01: Evaluate 5 random ConvNet, mean = 0.5404 std = 0.0298
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:48:01: [2024-10-29 13:48:01] iter = 16000, loss = 1.3003
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:48:01: [2024-10-29 13:48:01] iter = 16010, loss = 4.9425
2024-10-29 13:48:01: [2024-10-29 13:48:01] iter = 16020, loss = 1.6310
2024-10-29 13:48:02: [2024-10-29 13:48:02] iter = 16030, loss = 1.6355
2024-10-29 13:48:02: [2024-10-29 13:48:02] iter = 16040, loss = 1.8340
2024-10-29 13:48:02: [2024-10-29 13:48:02] iter = 16050, loss = 1.1796
2024-10-29 13:48:02: [2024-10-29 13:48:02] iter = 16060, loss = 1.0229
2024-10-29 13:48:03: [2024-10-29 13:48:03] iter = 16070, loss = 1.2855
2024-10-29 13:48:03: [2024-10-29 13:48:03] iter = 16080, loss = 1.2226
2024-10-29 13:48:03: [2024-10-29 13:48:03] iter = 16090, loss = 1.1614
2024-10-29 13:48:04: [2024-10-29 13:48:04] iter = 16100, loss = 1.9581
2024-10-29 13:48:04: [2024-10-29 13:48:04] iter = 16110, loss = 1.3246
2024-10-29 13:48:04: [2024-10-29 13:48:04] iter = 16120, loss = 1.0587
2024-10-29 13:48:04: [2024-10-29 13:48:04] iter = 16130, loss = 1.6493
2024-10-29 13:48:05: [2024-10-29 13:48:05] iter = 16140, loss = 1.8030
2024-10-29 13:48:05: [2024-10-29 13:48:05] iter = 16150, loss = 0.8693
2024-10-29 13:48:05: [2024-10-29 13:48:05] iter = 16160, loss = 1.1840
2024-10-29 13:48:05: [2024-10-29 13:48:05] iter = 16170, loss = 1.3350
2024-10-29 13:48:06: [2024-10-29 13:48:06] iter = 16180, loss = 1.7260
2024-10-29 13:48:06: [2024-10-29 13:48:06] iter = 16190, loss = 0.9505
2024-10-29 13:48:06: [2024-10-29 13:48:06] iter = 16200, loss = 1.6357
2024-10-29 13:48:07: [2024-10-29 13:48:07] iter = 16210, loss = 1.0020
2024-10-29 13:48:07: [2024-10-29 13:48:07] iter = 16220, loss = 2.4972
2024-10-29 13:48:07: [2024-10-29 13:48:07] iter = 16230, loss = 1.7615
2024-10-29 13:48:07: [2024-10-29 13:48:07] iter = 16240, loss = 3.5750
2024-10-29 13:48:08: [2024-10-29 13:48:08] iter = 16250, loss = 8.6687
2024-10-29 13:48:08: [2024-10-29 13:48:08] iter = 16260, loss = 1.4208
2024-10-29 13:48:08: [2024-10-29 13:48:08] iter = 16270, loss = 5.1559
2024-10-29 13:48:09: [2024-10-29 13:48:09] iter = 16280, loss = 0.9346
2024-10-29 13:48:09: [2024-10-29 13:48:09] iter = 16290, loss = 1.5404
2024-10-29 13:48:09: [2024-10-29 13:48:09] iter = 16300, loss = 1.2107
2024-10-29 13:48:10: [2024-10-29 13:48:10] iter = 16310, loss = 1.0241
2024-10-29 13:48:10: [2024-10-29 13:48:10] iter = 16320, loss = 2.0566
2024-10-29 13:48:10: [2024-10-29 13:48:10] iter = 16330, loss = 1.2022
2024-10-29 13:48:10: [2024-10-29 13:48:10] iter = 16340, loss = 1.0645
2024-10-29 13:48:11: [2024-10-29 13:48:11] iter = 16350, loss = 1.0390
2024-10-29 13:48:11: [2024-10-29 13:48:11] iter = 16360, loss = 0.9754
2024-10-29 13:48:11: [2024-10-29 13:48:11] iter = 16370, loss = 2.8926
2024-10-29 13:48:12: [2024-10-29 13:48:12] iter = 16380, loss = 1.1341
2024-10-29 13:48:12: [2024-10-29 13:48:12] iter = 16390, loss = 1.4285
2024-10-29 13:48:12: [2024-10-29 13:48:12] iter = 16400, loss = 1.1902
2024-10-29 13:48:13: [2024-10-29 13:48:13] iter = 16410, loss = 1.4480
2024-10-29 13:48:13: [2024-10-29 13:48:13] iter = 16420, loss = 1.5001
2024-10-29 13:48:13: [2024-10-29 13:48:13] iter = 16430, loss = 1.0343
2024-10-29 13:48:14: [2024-10-29 13:48:14] iter = 16440, loss = 2.7837
2024-10-29 13:48:14: [2024-10-29 13:48:14] iter = 16450, loss = 1.0113
2024-10-29 13:48:14: [2024-10-29 13:48:14] iter = 16460, loss = 1.5861
2024-10-29 13:48:14: [2024-10-29 13:48:14] iter = 16470, loss = 1.8930
2024-10-29 13:48:15: [2024-10-29 13:48:15] iter = 16480, loss = 4.1342
2024-10-29 13:48:15: [2024-10-29 13:48:15] iter = 16490, loss = 1.4776
2024-10-29 13:48:15: [2024-10-29 13:48:15] iter = 16500, loss = 1.0641
2024-10-29 13:48:16: [2024-10-29 13:48:16] iter = 16510, loss = 1.0567
2024-10-29 13:48:16: [2024-10-29 13:48:16] iter = 16520, loss = 2.2872
2024-10-29 13:48:16: [2024-10-29 13:48:16] iter = 16530, loss = 0.9641
2024-10-29 13:48:17: [2024-10-29 13:48:17] iter = 16540, loss = 6.9987
2024-10-29 13:48:17: [2024-10-29 13:48:17] iter = 16550, loss = 4.8271
2024-10-29 13:48:17: [2024-10-29 13:48:17] iter = 16560, loss = 1.8934
2024-10-29 13:48:18: [2024-10-29 13:48:18] iter = 16570, loss = 1.5857
2024-10-29 13:48:18: [2024-10-29 13:48:18] iter = 16580, loss = 1.2670
2024-10-29 13:48:18: [2024-10-29 13:48:18] iter = 16590, loss = 1.8297
2024-10-29 13:48:19: [2024-10-29 13:48:19] iter = 16600, loss = 0.9391
2024-10-29 13:48:19: [2024-10-29 13:48:19] iter = 16610, loss = 0.9650
2024-10-29 13:48:19: [2024-10-29 13:48:19] iter = 16620, loss = 0.9762
2024-10-29 13:48:20: [2024-10-29 13:48:20] iter = 16630, loss = 1.0438
2024-10-29 13:48:20: [2024-10-29 13:48:20] iter = 16640, loss = 1.5680
2024-10-29 13:48:20: [2024-10-29 13:48:20] iter = 16650, loss = 1.4990
2024-10-29 13:48:21: [2024-10-29 13:48:21] iter = 16660, loss = 1.2676
2024-10-29 13:48:21: [2024-10-29 13:48:21] iter = 16670, loss = 0.7248
2024-10-29 13:48:21: [2024-10-29 13:48:21] iter = 16680, loss = 1.2933
2024-10-29 13:48:21: [2024-10-29 13:48:21] iter = 16690, loss = 1.4948
2024-10-29 13:48:22: [2024-10-29 13:48:22] iter = 16700, loss = 1.0388
2024-10-29 13:48:22: [2024-10-29 13:48:22] iter = 16710, loss = 2.6981
2024-10-29 13:48:22: [2024-10-29 13:48:22] iter = 16720, loss = 1.9971
2024-10-29 13:48:23: [2024-10-29 13:48:23] iter = 16730, loss = 0.9183
2024-10-29 13:48:23: [2024-10-29 13:48:23] iter = 16740, loss = 1.2294
2024-10-29 13:48:23: [2024-10-29 13:48:23] iter = 16750, loss = 3.7180
2024-10-29 13:48:24: [2024-10-29 13:48:24] iter = 16760, loss = 1.3591
2024-10-29 13:48:24: [2024-10-29 13:48:24] iter = 16770, loss = 1.8091
2024-10-29 13:48:24: [2024-10-29 13:48:24] iter = 16780, loss = 0.8517
2024-10-29 13:48:24: [2024-10-29 13:48:24] iter = 16790, loss = 1.4485
2024-10-29 13:48:25: [2024-10-29 13:48:25] iter = 16800, loss = 0.8576
2024-10-29 13:48:25: [2024-10-29 13:48:25] iter = 16810, loss = 6.7710
2024-10-29 13:48:25: [2024-10-29 13:48:25] iter = 16820, loss = 3.3403
2024-10-29 13:48:26: [2024-10-29 13:48:26] iter = 16830, loss = 1.6957
2024-10-29 13:48:26: [2024-10-29 13:48:26] iter = 16840, loss = 1.6646
2024-10-29 13:48:26: [2024-10-29 13:48:26] iter = 16850, loss = 1.0961
2024-10-29 13:48:26: [2024-10-29 13:48:26] iter = 16860, loss = 2.3445
2024-10-29 13:48:27: [2024-10-29 13:48:27] iter = 16870, loss = 1.8180
2024-10-29 13:48:27: [2024-10-29 13:48:27] iter = 16880, loss = 1.1205
2024-10-29 13:48:27: [2024-10-29 13:48:27] iter = 16890, loss = 1.0179
2024-10-29 13:48:27: [2024-10-29 13:48:27] iter = 16900, loss = 0.7897
2024-10-29 13:48:28: [2024-10-29 13:48:28] iter = 16910, loss = 0.8626
2024-10-29 13:48:28: [2024-10-29 13:48:28] iter = 16920, loss = 0.9319
2024-10-29 13:48:28: [2024-10-29 13:48:28] iter = 16930, loss = 3.0072
2024-10-29 13:48:29: [2024-10-29 13:48:29] iter = 16940, loss = 1.5008
2024-10-29 13:48:29: [2024-10-29 13:48:29] iter = 16950, loss = 1.9161
2024-10-29 13:48:29: [2024-10-29 13:48:29] iter = 16960, loss = 2.0976
2024-10-29 13:48:29: [2024-10-29 13:48:29] iter = 16970, loss = 1.7821
2024-10-29 13:48:30: [2024-10-29 13:48:30] iter = 16980, loss = 1.0024
2024-10-29 13:48:30: [2024-10-29 13:48:30] iter = 16990, loss = 1.6025
2024-10-29 13:48:30: [2024-10-29 13:48:30] iter = 17000, loss = 1.2665
2024-10-29 13:48:30: [2024-10-29 13:48:30] iter = 17010, loss = 3.6775
2024-10-29 13:48:31: [2024-10-29 13:48:31] iter = 17020, loss = 1.5456
2024-10-29 13:48:31: [2024-10-29 13:48:31] iter = 17030, loss = 1.3082
2024-10-29 13:48:31: [2024-10-29 13:48:31] iter = 17040, loss = 1.3922
2024-10-29 13:48:31: [2024-10-29 13:48:31] iter = 17050, loss = 1.5151
2024-10-29 13:48:32: [2024-10-29 13:48:32] iter = 17060, loss = 1.2924
2024-10-29 13:48:32: [2024-10-29 13:48:32] iter = 17070, loss = 1.7696
2024-10-29 13:48:32: [2024-10-29 13:48:32] iter = 17080, loss = 1.1688
2024-10-29 13:48:32: [2024-10-29 13:48:32] iter = 17090, loss = 0.6739
2024-10-29 13:48:33: [2024-10-29 13:48:33] iter = 17100, loss = 8.2122
2024-10-29 13:48:33: [2024-10-29 13:48:33] iter = 17110, loss = 1.5602
2024-10-29 13:48:33: [2024-10-29 13:48:33] iter = 17120, loss = 0.8133
2024-10-29 13:48:34: [2024-10-29 13:48:34] iter = 17130, loss = 1.0867
2024-10-29 13:48:34: [2024-10-29 13:48:34] iter = 17140, loss = 1.0688
2024-10-29 13:48:34: [2024-10-29 13:48:34] iter = 17150, loss = 0.7611
2024-10-29 13:48:35: [2024-10-29 13:48:35] iter = 17160, loss = 8.1924
2024-10-29 13:48:35: [2024-10-29 13:48:35] iter = 17170, loss = 1.6189
2024-10-29 13:48:35: [2024-10-29 13:48:35] iter = 17180, loss = 0.6935
2024-10-29 13:48:36: [2024-10-29 13:48:36] iter = 17190, loss = 1.7450
2024-10-29 13:48:36: [2024-10-29 13:48:36] iter = 17200, loss = 1.1634
2024-10-29 13:48:36: [2024-10-29 13:48:36] iter = 17210, loss = 1.0810
2024-10-29 13:48:37: [2024-10-29 13:48:37] iter = 17220, loss = 1.0659
2024-10-29 13:48:37: [2024-10-29 13:48:37] iter = 17230, loss = 2.8817
2024-10-29 13:48:37: [2024-10-29 13:48:37] iter = 17240, loss = 1.7448
2024-10-29 13:48:38: [2024-10-29 13:48:38] iter = 17250, loss = 1.3128
2024-10-29 13:48:38: [2024-10-29 13:48:38] iter = 17260, loss = 1.3933
2024-10-29 13:48:38: [2024-10-29 13:48:38] iter = 17270, loss = 2.3738
2024-10-29 13:48:39: [2024-10-29 13:48:39] iter = 17280, loss = 1.2332
2024-10-29 13:48:39: [2024-10-29 13:48:39] iter = 17290, loss = 1.1787
2024-10-29 13:48:39: [2024-10-29 13:48:39] iter = 17300, loss = 1.6473
2024-10-29 13:48:40: [2024-10-29 13:48:40] iter = 17310, loss = 1.5265
2024-10-29 13:48:40: [2024-10-29 13:48:40] iter = 17320, loss = 1.2604
2024-10-29 13:48:40: [2024-10-29 13:48:40] iter = 17330, loss = 5.8143
2024-10-29 13:48:41: [2024-10-29 13:48:41] iter = 17340, loss = 1.1286
2024-10-29 13:48:41: [2024-10-29 13:48:41] iter = 17350, loss = 2.0028
2024-10-29 13:48:41: [2024-10-29 13:48:41] iter = 17360, loss = 1.2056
2024-10-29 13:48:42: [2024-10-29 13:48:42] iter = 17370, loss = 0.9706
2024-10-29 13:48:42: [2024-10-29 13:48:42] iter = 17380, loss = 1.2101
2024-10-29 13:48:42: [2024-10-29 13:48:42] iter = 17390, loss = 1.1096
2024-10-29 13:48:43: [2024-10-29 13:48:43] iter = 17400, loss = 1.1321
2024-10-29 13:48:43: [2024-10-29 13:48:43] iter = 17410, loss = 1.6286
2024-10-29 13:48:43: [2024-10-29 13:48:43] iter = 17420, loss = 0.8353
2024-10-29 13:48:44: [2024-10-29 13:48:44] iter = 17430, loss = 1.1225
2024-10-29 13:48:44: [2024-10-29 13:48:44] iter = 17440, loss = 0.8356
2024-10-29 13:48:45: [2024-10-29 13:48:45] iter = 17450, loss = 1.0981
2024-10-29 13:48:45: [2024-10-29 13:48:45] iter = 17460, loss = 1.2187
2024-10-29 13:48:45: [2024-10-29 13:48:45] iter = 17470, loss = 1.1734
2024-10-29 13:48:46: [2024-10-29 13:48:46] iter = 17480, loss = 4.1444
2024-10-29 13:48:46: [2024-10-29 13:48:46] iter = 17490, loss = 1.3432
2024-10-29 13:48:47: [2024-10-29 13:48:47] iter = 17500, loss = 0.7667
2024-10-29 13:48:47: [2024-10-29 13:48:47] iter = 17510, loss = 0.8998
2024-10-29 13:48:48: [2024-10-29 13:48:48] iter = 17520, loss = 2.1589
2024-10-29 13:48:48: [2024-10-29 13:48:48] iter = 17530, loss = 1.6100
2024-10-29 13:48:49: [2024-10-29 13:48:49] iter = 17540, loss = 1.4499
2024-10-29 13:48:49: [2024-10-29 13:48:49] iter = 17550, loss = 2.5343
2024-10-29 13:48:50: [2024-10-29 13:48:50] iter = 17560, loss = 1.7457
2024-10-29 13:48:50: [2024-10-29 13:48:50] iter = 17570, loss = 1.1229
2024-10-29 13:48:51: [2024-10-29 13:48:51] iter = 17580, loss = 1.1289
2024-10-29 13:48:51: [2024-10-29 13:48:51] iter = 17590, loss = 0.8776
2024-10-29 13:48:51: [2024-10-29 13:48:51] iter = 17600, loss = 1.2079
2024-10-29 13:48:52: [2024-10-29 13:48:52] iter = 17610, loss = 1.0345
2024-10-29 13:48:52: [2024-10-29 13:48:52] iter = 17620, loss = 5.7857
2024-10-29 13:48:53: [2024-10-29 13:48:53] iter = 17630, loss = 1.1519
2024-10-29 13:48:53: [2024-10-29 13:48:53] iter = 17640, loss = 0.9316
2024-10-29 13:48:54: [2024-10-29 13:48:54] iter = 17650, loss = 1.3566
2024-10-29 13:48:54: [2024-10-29 13:48:54] iter = 17660, loss = 2.3372
2024-10-29 13:48:54: [2024-10-29 13:48:54] iter = 17670, loss = 1.9360
2024-10-29 13:48:55: [2024-10-29 13:48:55] iter = 17680, loss = 1.4286
2024-10-29 13:48:55: [2024-10-29 13:48:55] iter = 17690, loss = 0.8679
2024-10-29 13:48:56: [2024-10-29 13:48:56] iter = 17700, loss = 1.5099
2024-10-29 13:48:56: [2024-10-29 13:48:56] iter = 17710, loss = 2.1506
2024-10-29 13:48:57: [2024-10-29 13:48:57] iter = 17720, loss = 1.0465
2024-10-29 13:48:57: [2024-10-29 13:48:57] iter = 17730, loss = 1.4676
2024-10-29 13:48:58: [2024-10-29 13:48:58] iter = 17740, loss = 2.2750
2024-10-29 13:48:58: [2024-10-29 13:48:58] iter = 17750, loss = 1.1631
2024-10-29 13:48:59: [2024-10-29 13:48:59] iter = 17760, loss = 1.2574
2024-10-29 13:48:59: [2024-10-29 13:48:59] iter = 17770, loss = 1.4033
2024-10-29 13:49:00: [2024-10-29 13:49:00] iter = 17780, loss = 1.1661
2024-10-29 13:49:00: [2024-10-29 13:49:00] iter = 17790, loss = 2.0750
2024-10-29 13:49:01: [2024-10-29 13:49:01] iter = 17800, loss = 0.9501
2024-10-29 13:49:01: [2024-10-29 13:49:01] iter = 17810, loss = 1.1195
2024-10-29 13:49:02: [2024-10-29 13:49:02] iter = 17820, loss = 1.1266
2024-10-29 13:49:02: [2024-10-29 13:49:02] iter = 17830, loss = 1.1951
2024-10-29 13:49:03: [2024-10-29 13:49:03] iter = 17840, loss = 1.0341
2024-10-29 13:49:03: [2024-10-29 13:49:03] iter = 17850, loss = 0.9179
2024-10-29 13:49:04: [2024-10-29 13:49:04] iter = 17860, loss = 6.4392
2024-10-29 13:49:04: [2024-10-29 13:49:04] iter = 17870, loss = 0.9439
2024-10-29 13:49:04: [2024-10-29 13:49:04] iter = 17880, loss = 1.5067
2024-10-29 13:49:05: [2024-10-29 13:49:05] iter = 17890, loss = 2.6191
2024-10-29 13:49:05: [2024-10-29 13:49:05] iter = 17900, loss = 0.9689
2024-10-29 13:49:06: [2024-10-29 13:49:06] iter = 17910, loss = 1.7476
2024-10-29 13:49:07: [2024-10-29 13:49:07] iter = 17920, loss = 3.3026
2024-10-29 13:49:07: [2024-10-29 13:49:07] iter = 17930, loss = 1.5935
2024-10-29 13:49:07: [2024-10-29 13:49:07] iter = 17940, loss = 6.1812
2024-10-29 13:49:08: [2024-10-29 13:49:08] iter = 17950, loss = 1.0428
2024-10-29 13:49:08: [2024-10-29 13:49:08] iter = 17960, loss = 1.0171
2024-10-29 13:49:09: [2024-10-29 13:49:09] iter = 17970, loss = 1.1222
2024-10-29 13:49:09: [2024-10-29 13:49:09] iter = 17980, loss = 2.4586
2024-10-29 13:49:10: [2024-10-29 13:49:10] iter = 17990, loss = 1.3135
2024-10-29 13:49:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 13:49:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:49:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50485}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:49:45: Evaluate 5 random ConvNet, ACCmean = 0.4967 ACCstd = 0.0132
-------------------------
2024-10-29 13:49:45: Evaluate 5 random ConvNet, SENmean = 0.6166 SENstd = 0.0027
-------------------------
2024-10-29 13:49:45: Evaluate 5 random ConvNet, SPEmean = 0.6166 SPEstd = 0.0027
-------------------------
2024-10-29 13:49:45: Evaluate 5 random ConvNet, F!mean = 0.4348 F!std = 0.0082
-------------------------
2024-10-29 13:49:45: Evaluate 5 random ConvNet, mean = 0.4967 std = 0.0132
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:49:45: [2024-10-29 13:49:45] iter = 18000, loss = 1.3653
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:49:46: [2024-10-29 13:49:46] iter = 18010, loss = 1.5098
2024-10-29 13:49:46: [2024-10-29 13:49:46] iter = 18020, loss = 1.3712
2024-10-29 13:49:47: [2024-10-29 13:49:47] iter = 18030, loss = 1.9404
2024-10-29 13:49:48: [2024-10-29 13:49:48] iter = 18040, loss = 1.2985
2024-10-29 13:49:48: [2024-10-29 13:49:48] iter = 18050, loss = 1.3535
2024-10-29 13:49:49: [2024-10-29 13:49:49] iter = 18060, loss = 0.9892
2024-10-29 13:49:50: [2024-10-29 13:49:50] iter = 18070, loss = 1.2937
2024-10-29 13:49:50: [2024-10-29 13:49:50] iter = 18080, loss = 2.4364
2024-10-29 13:49:51: [2024-10-29 13:49:51] iter = 18090, loss = 1.4141
2024-10-29 13:49:52: [2024-10-29 13:49:52] iter = 18100, loss = 1.0508
2024-10-29 13:49:52: [2024-10-29 13:49:52] iter = 18110, loss = 0.9488
2024-10-29 13:49:53: [2024-10-29 13:49:53] iter = 18120, loss = 0.8381
2024-10-29 13:49:54: [2024-10-29 13:49:54] iter = 18130, loss = 1.0091
2024-10-29 13:49:54: [2024-10-29 13:49:54] iter = 18140, loss = 1.4440
2024-10-29 13:49:55: [2024-10-29 13:49:55] iter = 18150, loss = 3.3267
2024-10-29 13:49:55: [2024-10-29 13:49:55] iter = 18160, loss = 0.8511
2024-10-29 13:49:56: [2024-10-29 13:49:56] iter = 18170, loss = 1.0670
2024-10-29 13:49:56: [2024-10-29 13:49:56] iter = 18180, loss = 1.0768
2024-10-29 13:49:57: [2024-10-29 13:49:57] iter = 18190, loss = 3.0557
2024-10-29 13:49:58: [2024-10-29 13:49:58] iter = 18200, loss = 1.0865
2024-10-29 13:49:58: [2024-10-29 13:49:58] iter = 18210, loss = 1.8092
2024-10-29 13:49:59: [2024-10-29 13:49:59] iter = 18220, loss = 1.6107
2024-10-29 13:49:59: [2024-10-29 13:49:59] iter = 18230, loss = 3.6634
2024-10-29 13:50:00: [2024-10-29 13:50:00] iter = 18240, loss = 1.4215
2024-10-29 13:50:00: [2024-10-29 13:50:00] iter = 18250, loss = 1.5219
2024-10-29 13:50:01: [2024-10-29 13:50:01] iter = 18260, loss = 1.5878
2024-10-29 13:50:01: [2024-10-29 13:50:01] iter = 18270, loss = 0.8032
2024-10-29 13:50:01: [2024-10-29 13:50:01] iter = 18280, loss = 1.2466
2024-10-29 13:50:02: [2024-10-29 13:50:02] iter = 18290, loss = 1.3837
2024-10-29 13:50:02: [2024-10-29 13:50:02] iter = 18300, loss = 1.4749
2024-10-29 13:50:03: [2024-10-29 13:50:03] iter = 18310, loss = 0.9961
2024-10-29 13:50:03: [2024-10-29 13:50:03] iter = 18320, loss = 4.6490
2024-10-29 13:50:04: [2024-10-29 13:50:04] iter = 18330, loss = 1.1693
2024-10-29 13:50:04: [2024-10-29 13:50:04] iter = 18340, loss = 4.6886
2024-10-29 13:50:05: [2024-10-29 13:50:05] iter = 18350, loss = 1.8887
2024-10-29 13:50:06: [2024-10-29 13:50:06] iter = 18360, loss = 1.7878
2024-10-29 13:50:06: [2024-10-29 13:50:06] iter = 18370, loss = 0.8513
2024-10-29 13:50:07: [2024-10-29 13:50:07] iter = 18380, loss = 3.7233
2024-10-29 13:50:07: [2024-10-29 13:50:07] iter = 18390, loss = 2.5001
2024-10-29 13:50:08: [2024-10-29 13:50:08] iter = 18400, loss = 1.1212
2024-10-29 13:50:08: [2024-10-29 13:50:08] iter = 18410, loss = 0.9015
2024-10-29 13:50:09: [2024-10-29 13:50:09] iter = 18420, loss = 2.4558
2024-10-29 13:50:09: [2024-10-29 13:50:09] iter = 18430, loss = 1.4722
2024-10-29 13:50:10: [2024-10-29 13:50:10] iter = 18440, loss = 1.1804
2024-10-29 13:50:10: [2024-10-29 13:50:10] iter = 18450, loss = 1.1867
2024-10-29 13:50:10: [2024-10-29 13:50:10] iter = 18460, loss = 1.2584
2024-10-29 13:50:11: [2024-10-29 13:50:11] iter = 18470, loss = 1.3413
2024-10-29 13:50:11: [2024-10-29 13:50:11] iter = 18480, loss = 1.3830
2024-10-29 13:50:12: [2024-10-29 13:50:12] iter = 18490, loss = 4.2228
2024-10-29 13:50:12: [2024-10-29 13:50:12] iter = 18500, loss = 0.8663
2024-10-29 13:50:13: [2024-10-29 13:50:13] iter = 18510, loss = 1.2385
2024-10-29 13:50:13: [2024-10-29 13:50:13] iter = 18520, loss = 1.8350
2024-10-29 13:50:14: [2024-10-29 13:50:14] iter = 18530, loss = 2.4999
2024-10-29 13:50:14: [2024-10-29 13:50:14] iter = 18540, loss = 0.9310
2024-10-29 13:50:15: [2024-10-29 13:50:15] iter = 18550, loss = 0.9191
2024-10-29 13:50:15: [2024-10-29 13:50:15] iter = 18560, loss = 1.6987
2024-10-29 13:50:16: [2024-10-29 13:50:16] iter = 18570, loss = 1.0028
2024-10-29 13:50:16: [2024-10-29 13:50:16] iter = 18580, loss = 1.3133
2024-10-29 13:50:17: [2024-10-29 13:50:17] iter = 18590, loss = 1.0996
2024-10-29 13:50:17: [2024-10-29 13:50:17] iter = 18600, loss = 0.9649
2024-10-29 13:50:17: [2024-10-29 13:50:17] iter = 18610, loss = 1.9433
2024-10-29 13:50:18: [2024-10-29 13:50:18] iter = 18620, loss = 1.1477
2024-10-29 13:50:18: [2024-10-29 13:50:18] iter = 18630, loss = 1.7938
2024-10-29 13:50:19: [2024-10-29 13:50:19] iter = 18640, loss = 1.5798
2024-10-29 13:50:19: [2024-10-29 13:50:19] iter = 18650, loss = 1.6448
2024-10-29 13:50:20: [2024-10-29 13:50:20] iter = 18660, loss = 1.0137
2024-10-29 13:50:20: [2024-10-29 13:50:20] iter = 18670, loss = 1.2578
2024-10-29 13:50:20: [2024-10-29 13:50:20] iter = 18680, loss = 1.4472
2024-10-29 13:50:21: [2024-10-29 13:50:21] iter = 18690, loss = 1.8584
2024-10-29 13:50:21: [2024-10-29 13:50:21] iter = 18700, loss = 1.8570
2024-10-29 13:50:22: [2024-10-29 13:50:22] iter = 18710, loss = 1.0398
2024-10-29 13:50:22: [2024-10-29 13:50:22] iter = 18720, loss = 1.3383
2024-10-29 13:50:23: [2024-10-29 13:50:23] iter = 18730, loss = 1.3484
2024-10-29 13:50:23: [2024-10-29 13:50:23] iter = 18740, loss = 2.3891
2024-10-29 13:50:24: [2024-10-29 13:50:24] iter = 18750, loss = 1.2650
2024-10-29 13:50:24: [2024-10-29 13:50:24] iter = 18760, loss = 1.2195
2024-10-29 13:50:25: [2024-10-29 13:50:25] iter = 18770, loss = 1.3139
2024-10-29 13:50:25: [2024-10-29 13:50:25] iter = 18780, loss = 0.9182
2024-10-29 13:50:25: [2024-10-29 13:50:25] iter = 18790, loss = 2.0653
2024-10-29 13:50:26: [2024-10-29 13:50:26] iter = 18800, loss = 1.4201
2024-10-29 13:50:26: [2024-10-29 13:50:26] iter = 18810, loss = 1.2474
2024-10-29 13:50:27: [2024-10-29 13:50:27] iter = 18820, loss = 0.9854
2024-10-29 13:50:28: [2024-10-29 13:50:28] iter = 18830, loss = 1.1715
2024-10-29 13:50:28: [2024-10-29 13:50:28] iter = 18840, loss = 1.1779
2024-10-29 13:50:28: [2024-10-29 13:50:28] iter = 18850, loss = 1.3549
2024-10-29 13:50:29: [2024-10-29 13:50:29] iter = 18860, loss = 0.7134
2024-10-29 13:50:29: [2024-10-29 13:50:29] iter = 18870, loss = 3.6678
2024-10-29 13:50:30: [2024-10-29 13:50:30] iter = 18880, loss = 0.9473
2024-10-29 13:50:30: [2024-10-29 13:50:30] iter = 18890, loss = 1.4764
2024-10-29 13:50:31: [2024-10-29 13:50:31] iter = 18900, loss = 1.2787
2024-10-29 13:50:31: [2024-10-29 13:50:31] iter = 18910, loss = 1.7734
2024-10-29 13:50:32: [2024-10-29 13:50:32] iter = 18920, loss = 1.2645
2024-10-29 13:50:32: [2024-10-29 13:50:32] iter = 18930, loss = 1.6007
2024-10-29 13:50:33: [2024-10-29 13:50:33] iter = 18940, loss = 2.7056
2024-10-29 13:50:33: [2024-10-29 13:50:33] iter = 18950, loss = 2.3147
2024-10-29 13:50:34: [2024-10-29 13:50:34] iter = 18960, loss = 1.2056
2024-10-29 13:50:35: [2024-10-29 13:50:35] iter = 18970, loss = 1.7557
2024-10-29 13:50:35: [2024-10-29 13:50:35] iter = 18980, loss = 1.2715
2024-10-29 13:50:36: [2024-10-29 13:50:36] iter = 18990, loss = 1.3963
2024-10-29 13:50:36: [2024-10-29 13:50:36] iter = 19000, loss = 2.7012
2024-10-29 13:50:37: [2024-10-29 13:50:37] iter = 19010, loss = 2.0793
2024-10-29 13:50:37: [2024-10-29 13:50:37] iter = 19020, loss = 0.9611
2024-10-29 13:50:38: [2024-10-29 13:50:38] iter = 19030, loss = 1.3643
2024-10-29 13:50:38: [2024-10-29 13:50:38] iter = 19040, loss = 1.4740
2024-10-29 13:50:39: [2024-10-29 13:50:39] iter = 19050, loss = 1.2052
2024-10-29 13:50:40: [2024-10-29 13:50:40] iter = 19060, loss = 1.3080
2024-10-29 13:50:41: [2024-10-29 13:50:41] iter = 19070, loss = 1.4248
2024-10-29 13:50:41: [2024-10-29 13:50:41] iter = 19080, loss = 0.9575
2024-10-29 13:50:42: [2024-10-29 13:50:42] iter = 19090, loss = 1.9896
2024-10-29 13:50:42: [2024-10-29 13:50:42] iter = 19100, loss = 1.6378
2024-10-29 13:50:42: [2024-10-29 13:50:42] iter = 19110, loss = 2.2817
2024-10-29 13:50:43: [2024-10-29 13:50:43] iter = 19120, loss = 1.2837
2024-10-29 13:50:43: [2024-10-29 13:50:43] iter = 19130, loss = 1.6140
2024-10-29 13:50:44: [2024-10-29 13:50:44] iter = 19140, loss = 2.1077
2024-10-29 13:50:44: [2024-10-29 13:50:44] iter = 19150, loss = 1.3336
2024-10-29 13:50:45: [2024-10-29 13:50:45] iter = 19160, loss = 0.9026
2024-10-29 13:50:45: [2024-10-29 13:50:45] iter = 19170, loss = 0.9628
2024-10-29 13:50:46: [2024-10-29 13:50:46] iter = 19180, loss = 1.2287
2024-10-29 13:50:46: [2024-10-29 13:50:46] iter = 19190, loss = 1.4456
2024-10-29 13:50:47: [2024-10-29 13:50:47] iter = 19200, loss = 1.3985
2024-10-29 13:50:47: [2024-10-29 13:50:47] iter = 19210, loss = 1.4625
2024-10-29 13:50:47: [2024-10-29 13:50:47] iter = 19220, loss = 1.2451
2024-10-29 13:50:48: [2024-10-29 13:50:48] iter = 19230, loss = 0.9630
2024-10-29 13:50:48: [2024-10-29 13:50:48] iter = 19240, loss = 7.8110
2024-10-29 13:50:49: [2024-10-29 13:50:49] iter = 19250, loss = 1.6191
2024-10-29 13:50:50: [2024-10-29 13:50:50] iter = 19260, loss = 4.7064
2024-10-29 13:50:50: [2024-10-29 13:50:50] iter = 19270, loss = 0.8889
2024-10-29 13:50:51: [2024-10-29 13:50:51] iter = 19280, loss = 1.7522
2024-10-29 13:50:51: [2024-10-29 13:50:51] iter = 19290, loss = 1.8358
2024-10-29 13:50:52: [2024-10-29 13:50:52] iter = 19300, loss = 1.8325
2024-10-29 13:50:52: [2024-10-29 13:50:52] iter = 19310, loss = 0.9080
2024-10-29 13:50:53: [2024-10-29 13:50:53] iter = 19320, loss = 1.2506
2024-10-29 13:50:53: [2024-10-29 13:50:53] iter = 19330, loss = 0.8735
2024-10-29 13:50:54: [2024-10-29 13:50:54] iter = 19340, loss = 1.1764
2024-10-29 13:50:54: [2024-10-29 13:50:54] iter = 19350, loss = 0.8702
2024-10-29 13:50:55: [2024-10-29 13:50:55] iter = 19360, loss = 3.3504
2024-10-29 13:50:55: [2024-10-29 13:50:55] iter = 19370, loss = 1.0612
2024-10-29 13:50:55: [2024-10-29 13:50:55] iter = 19380, loss = 4.4023
2024-10-29 13:50:56: [2024-10-29 13:50:56] iter = 19390, loss = 2.7901
2024-10-29 13:50:56: [2024-10-29 13:50:56] iter = 19400, loss = 1.3889
2024-10-29 13:50:57: [2024-10-29 13:50:57] iter = 19410, loss = 1.3403
2024-10-29 13:50:57: [2024-10-29 13:50:57] iter = 19420, loss = 1.0304
2024-10-29 13:50:58: [2024-10-29 13:50:58] iter = 19430, loss = 0.9821
2024-10-29 13:50:58: [2024-10-29 13:50:58] iter = 19440, loss = 1.7272
2024-10-29 13:50:59: [2024-10-29 13:50:59] iter = 19450, loss = 1.1328
2024-10-29 13:50:59: [2024-10-29 13:50:59] iter = 19460, loss = 1.1623
2024-10-29 13:51:00: [2024-10-29 13:51:00] iter = 19470, loss = 1.5288
2024-10-29 13:51:00: [2024-10-29 13:51:00] iter = 19480, loss = 1.6630
2024-10-29 13:51:01: [2024-10-29 13:51:01] iter = 19490, loss = 1.6907
2024-10-29 13:51:01: [2024-10-29 13:51:01] iter = 19500, loss = 1.5224
2024-10-29 13:51:02: [2024-10-29 13:51:02] iter = 19510, loss = 1.0544
2024-10-29 13:51:02: [2024-10-29 13:51:02] iter = 19520, loss = 1.0274
2024-10-29 13:51:03: [2024-10-29 13:51:03] iter = 19530, loss = 1.5205
2024-10-29 13:51:03: [2024-10-29 13:51:03] iter = 19540, loss = 1.3631
2024-10-29 13:51:04: [2024-10-29 13:51:04] iter = 19550, loss = 0.9865
2024-10-29 13:51:04: [2024-10-29 13:51:04] iter = 19560, loss = 8.4692
2024-10-29 13:51:05: [2024-10-29 13:51:05] iter = 19570, loss = 1.2733
2024-10-29 13:51:05: [2024-10-29 13:51:05] iter = 19580, loss = 2.1166
2024-10-29 13:51:06: [2024-10-29 13:51:06] iter = 19590, loss = 1.4292
2024-10-29 13:51:06: [2024-10-29 13:51:06] iter = 19600, loss = 1.9771
2024-10-29 13:51:07: [2024-10-29 13:51:07] iter = 19610, loss = 1.2421
2024-10-29 13:51:07: [2024-10-29 13:51:07] iter = 19620, loss = 0.7600
2024-10-29 13:51:08: [2024-10-29 13:51:08] iter = 19630, loss = 1.6550
2024-10-29 13:51:08: [2024-10-29 13:51:08] iter = 19640, loss = 1.0988
2024-10-29 13:51:09: [2024-10-29 13:51:09] iter = 19650, loss = 1.8308
2024-10-29 13:51:10: [2024-10-29 13:51:10] iter = 19660, loss = 1.3692
2024-10-29 13:51:10: [2024-10-29 13:51:10] iter = 19670, loss = 1.1217
2024-10-29 13:51:11: [2024-10-29 13:51:11] iter = 19680, loss = 1.2788
2024-10-29 13:51:11: [2024-10-29 13:51:11] iter = 19690, loss = 7.6719
2024-10-29 13:51:12: [2024-10-29 13:51:12] iter = 19700, loss = 3.1469
2024-10-29 13:51:12: [2024-10-29 13:51:12] iter = 19710, loss = 1.5077
2024-10-29 13:51:13: [2024-10-29 13:51:13] iter = 19720, loss = 1.4958
2024-10-29 13:51:13: [2024-10-29 13:51:13] iter = 19730, loss = 1.2743
2024-10-29 13:51:14: [2024-10-29 13:51:14] iter = 19740, loss = 4.2017
2024-10-29 13:51:14: [2024-10-29 13:51:14] iter = 19750, loss = 1.7025
2024-10-29 13:51:15: [2024-10-29 13:51:15] iter = 19760, loss = 3.0586
2024-10-29 13:51:15: [2024-10-29 13:51:15] iter = 19770, loss = 2.1346
2024-10-29 13:51:16: [2024-10-29 13:51:16] iter = 19780, loss = 1.9932
2024-10-29 13:51:17: [2024-10-29 13:51:17] iter = 19790, loss = 1.9563
2024-10-29 13:51:17: [2024-10-29 13:51:17] iter = 19800, loss = 1.4898
2024-10-29 13:51:18: [2024-10-29 13:51:18] iter = 19810, loss = 8.3007
2024-10-29 13:51:18: [2024-10-29 13:51:18] iter = 19820, loss = 1.2527
2024-10-29 13:51:19: [2024-10-29 13:51:19] iter = 19830, loss = 3.6287
2024-10-29 13:51:19: [2024-10-29 13:51:19] iter = 19840, loss = 1.2830
2024-10-29 13:51:20: [2024-10-29 13:51:20] iter = 19850, loss = 1.2009
2024-10-29 13:51:20: [2024-10-29 13:51:20] iter = 19860, loss = 1.8801
2024-10-29 13:51:21: [2024-10-29 13:51:21] iter = 19870, loss = 1.3387
2024-10-29 13:51:21: [2024-10-29 13:51:21] iter = 19880, loss = 1.0314
2024-10-29 13:51:22: [2024-10-29 13:51:22] iter = 19890, loss = 1.1338
2024-10-29 13:51:23: [2024-10-29 13:51:23] iter = 19900, loss = 2.7556
2024-10-29 13:51:23: [2024-10-29 13:51:23] iter = 19910, loss = 1.3249
2024-10-29 13:51:24: [2024-10-29 13:51:24] iter = 19920, loss = 1.2865
2024-10-29 13:51:24: [2024-10-29 13:51:24] iter = 19930, loss = 1.1147
2024-10-29 13:51:25: [2024-10-29 13:51:25] iter = 19940, loss = 3.5353
2024-10-29 13:51:25: [2024-10-29 13:51:25] iter = 19950, loss = 2.5941
2024-10-29 13:51:26: [2024-10-29 13:51:26] iter = 19960, loss = 1.0422
2024-10-29 13:51:26: [2024-10-29 13:51:26] iter = 19970, loss = 0.9923
2024-10-29 13:51:27: [2024-10-29 13:51:27] iter = 19980, loss = 1.9011
2024-10-29 13:51:27: [2024-10-29 13:51:27] iter = 19990, loss = 1.8131
2024-10-29 13:51:28: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:51:28: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:51:28: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 88418}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:52:03: Evaluate 5 random ConvNet, ACCmean = 0.5133 ACCstd = 0.0270
-------------------------
2024-10-29 13:52:03: Evaluate 5 random ConvNet, SENmean = 0.6172 SENstd = 0.0052
-------------------------
2024-10-29 13:52:03: Evaluate 5 random ConvNet, SPEmean = 0.6172 SPEstd = 0.0052
-------------------------
2024-10-29 13:52:03: Evaluate 5 random ConvNet, F!mean = 0.4444 F!std = 0.0161
-------------------------
2024-10-29 13:52:03: Evaluate 5 random ConvNet, mean = 0.5133 std = 0.0270
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:52:03: [2024-10-29 13:52:03] iter = 20000, loss = 1.5872
2024-10-29 13:52:03: 
==================== Final Results ====================

2024-10-29 13:52:03: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 56.84%  std = 5.98%

[2024-10-29 13:39:28] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.036522 train acc = 1.0000, test acc = 0.6878, test_sen =0.5922, test_spe =0.5922, test_f1 =0.5242
[2024-10-29 13:39:33] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.031985 train acc = 1.0000, test acc = 0.7320, test_sen =0.5710, test_spe =0.5710, test_f1 =0.5326
[2024-10-29 13:40:34] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.056566 train acc = 1.0000, test acc = 0.5814, test_sen =0.6072, test_spe =0.6072, test_f1 =0.4790
[2024-10-29 13:40:40] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.002008 train acc = 1.0000, test acc = 0.6137, test_sen =0.5964, test_spe =0.5964, test_f1 =0.4918
[2024-10-29 13:40:45] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002999 train acc = 1.0000, test acc = 0.6184, test_sen =0.6041, test_spe =0.6041, test_f1 =0.4965
[2024-10-29 13:40:50] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.100729 train acc = 0.9500, test acc = 0.5717, test_sen =0.6031, test_spe =0.6031, test_f1 =0.4729
[2024-10-29 13:40:55] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.049828 train acc = 1.0000, test acc = 0.5959, test_sen =0.5959, test_spe =0.5959, test_f1 =0.4830
[2024-10-29 13:41:59] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.005092 train acc = 1.0000, test acc = 0.6215, test_sen =0.5821, test_spe =0.5821, test_f1 =0.4907
[2024-10-29 13:42:04] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.007860 train acc = 1.0000, test acc = 0.6286, test_sen =0.5959, test_spe =0.5959, test_f1 =0.4987
[2024-10-29 13:42:10] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.052577 train acc = 1.0000, test acc = 0.6233, test_sen =0.5924, test_spe =0.5924, test_f1 =0.4950
[2024-10-29 13:42:15] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.078360 train acc = 1.0000, test acc = 0.6237, test_sen =0.6035, test_spe =0.6035, test_f1 =0.4989
[2024-10-29 13:42:20] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.006346 train acc = 1.0000, test acc = 0.5910, test_sen =0.5967, test_spe =0.5967, test_f1 =0.4808
[2024-10-29 13:43:23] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.007259 train acc = 1.0000, test acc = 0.5804, test_sen =0.6268, test_spe =0.6268, test_f1 =0.4839
[2024-10-29 13:43:28] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.001918 train acc = 1.0000, test acc = 0.5929, test_sen =0.6304, test_spe =0.6304, test_f1 =0.4915
[2024-10-29 13:43:34] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.007033 train acc = 1.0000, test acc = 0.5689, test_sen =0.6242, test_spe =0.6242, test_f1 =0.4771
[2024-10-29 13:43:39] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.004345 train acc = 1.0000, test acc = 0.6043, test_sen =0.6262, test_spe =0.6262, test_f1 =0.4963
[2024-10-29 13:43:43] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.003072 train acc = 1.0000, test acc = 0.5824, test_sen =0.6237, test_spe =0.6237, test_f1 =0.4841
[2024-10-29 13:44:48] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001620 train acc = 1.0000, test acc = 0.3419, test_sen =0.5647, test_spe =0.5647, test_f1 =0.3248
[2024-10-29 13:44:53] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.027122 train acc = 1.0000, test acc = 0.3588, test_sen =0.5665, test_spe =0.5665, test_f1 =0.3375
[2024-10-29 13:44:58] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003969 train acc = 1.0000, test acc = 0.3437, test_sen =0.5684, test_spe =0.5684, test_f1 =0.3266
[2024-10-29 13:45:04] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.007946 train acc = 1.0000, test acc = 0.3374, test_sen =0.5623, test_spe =0.5623, test_f1 =0.3212
[2024-10-29 13:45:09] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.022516 train acc = 1.0000, test acc = 0.3695, test_sen =0.5671, test_spe =0.5671, test_f1 =0.3451
[2024-10-29 13:46:09] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.005078 train acc = 1.0000, test acc = 0.6026, test_sen =0.6064, test_spe =0.6064, test_f1 =0.4895
[2024-10-29 13:46:15] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.010411 train acc = 1.0000, test acc = 0.5976, test_sen =0.6097, test_spe =0.6097, test_f1 =0.4879
[2024-10-29 13:46:21] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003923 train acc = 1.0000, test acc = 0.5747, test_sen =0.6036, test_spe =0.6036, test_f1 =0.4746
[2024-10-29 13:46:26] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.097908 train acc = 0.9500, test acc = 0.5981, test_sen =0.6010, test_spe =0.6010, test_f1 =0.4856
[2024-10-29 13:46:30] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.006965 train acc = 1.0000, test acc = 0.5812, test_sen =0.6092, test_spe =0.6092, test_f1 =0.4795
[2024-10-29 13:47:39] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.005104 train acc = 1.0000, test acc = 0.4914, test_sen =0.5958, test_spe =0.5958, test_f1 =0.4275
[2024-10-29 13:47:45] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.067823 train acc = 0.9500, test acc = 0.5563, test_sen =0.5937, test_spe =0.5937, test_f1 =0.4624
[2024-10-29 13:47:51] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.011652 train acc = 1.0000, test acc = 0.5633, test_sen =0.5976, test_spe =0.5976, test_f1 =0.4671
[2024-10-29 13:47:56] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.003675 train acc = 1.0000, test acc = 0.5701, test_sen =0.5923, test_spe =0.5923, test_f1 =0.4691
[2024-10-29 13:48:01] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.140527 train acc = 0.9000, test acc = 0.5208, test_sen =0.5921, test_spe =0.5921, test_f1 =0.4431
[2024-10-29 13:49:17] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.161258 train acc = 0.9000, test acc = 0.5039, test_sen =0.6175, test_spe =0.6175, test_f1 =0.4393
[2024-10-29 13:49:24] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.012835 train acc = 1.0000, test acc = 0.4951, test_sen =0.6197, test_spe =0.6197, test_f1 =0.4346
[2024-10-29 13:49:31] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.002379 train acc = 1.0000, test acc = 0.4734, test_sen =0.6126, test_spe =0.6126, test_f1 =0.4202
[2024-10-29 13:49:38] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.065989 train acc = 1.0000, test acc = 0.4978, test_sen =0.6143, test_spe =0.6143, test_f1 =0.4351
[2024-10-29 13:49:45] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.043872 train acc = 1.0000, test acc = 0.5132, test_sen =0.6191, test_spe =0.6191, test_f1 =0.4450
[2024-10-29 13:51:34] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002907 train acc = 1.0000, test acc = 0.5039, test_sen =0.6209, test_spe =0.6209, test_f1 =0.4400
[2024-10-29 13:51:41] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.042858 train acc = 1.0000, test acc = 0.5190, test_sen =0.6138, test_spe =0.6138, test_f1 =0.4472
[2024-10-29 13:51:48] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.026099 train acc = 1.0000, test acc = 0.5105, test_sen =0.6212, test_spe =0.6212, test_f1 =0.4439
[2024-10-29 13:51:55] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.007938 train acc = 1.0000, test acc = 0.5584, test_sen =0.6214, test_spe =0.6214, test_f1 =0.4707
[2024-10-29 13:52:03] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.003810 train acc = 1.0000, test acc = 0.4749, test_sen =0.6085, test_spe =0.6085, test_f1 =0.4203
