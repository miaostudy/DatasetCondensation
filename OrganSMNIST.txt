nohup: ignoring input
2024-10-30 14:57:24: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
2024-10-30 14:57:26: 
================== Exp 0 ==================
 
2024-10-30 14:57:26: Hyper-parameters: 
{'dataset': 'OrganSMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fa9b88fdb20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganSMNIST (INFO)>}
2024-10-30 14:57:26: Evaluation model pool: ['ConvNet']
2024-10-30 14:57:33: class c = 0: 1148 real images
2024-10-30 14:57:33: class c = 1: 630 real images
2024-10-30 14:57:33: class c = 2: 614 real images
2024-10-30 14:57:33: class c = 3: 721 real images
2024-10-30 14:57:33: class c = 4: 1132 real images
2024-10-30 14:57:33: class c = 5: 1119 real images
2024-10-30 14:57:33: class c = 6: 3464 real images
2024-10-30 14:57:33: class c = 7: 741 real images
2024-10-30 14:57:33: class c = 8: 803 real images
2024-10-30 14:57:33: class c = 9: 2004 real images
2024-10-30 14:57:33: class c = 10: 1556 real images
2024-10-30 14:57:33: real images channel 0, mean = 0.4953, std = 0.2826
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 14:57:33: initialize synthetic data from random real images
2024-10-30 14:57:33: [2024-10-30 14:57:33] training begins
2024-10-30 14:57:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 14:57:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:57:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:00:25: Evaluate 5 random ConvNet, ACCmean = 0.4672 ACCstd = 0.0051
-------------------------
2024-10-30 15:00:25: Evaluate 5 random ConvNet, SENmean = 0.4560 SENstd = 0.0037
-------------------------
2024-10-30 15:00:25: Evaluate 5 random ConvNet, SPEmean = 0.9461 SPEstd = 0.0005
-------------------------
2024-10-30 15:00:25: Evaluate 5 random ConvNet, F!mean = 0.4427 F!std = 0.0023
-------------------------
2024-10-30 15:00:25: Evaluate 5 random ConvNet, mean = 0.4672 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:00:26: [2024-10-30 15:00:26] iter = 00000, loss = 14.7901
2024-10-30 15:00:30: [2024-10-30 15:00:30] iter = 00010, loss = 5.4137
2024-10-30 15:00:35: [2024-10-30 15:00:35] iter = 00020, loss = 3.1116
2024-10-30 15:00:40: [2024-10-30 15:00:40] iter = 00030, loss = 2.5779
2024-10-30 15:00:44: [2024-10-30 15:00:44] iter = 00040, loss = 3.4683
2024-10-30 15:00:48: [2024-10-30 15:00:48] iter = 00050, loss = 2.6790
2024-10-30 15:00:52: [2024-10-30 15:00:52] iter = 00060, loss = 2.5614
2024-10-30 15:00:56: [2024-10-30 15:00:56] iter = 00070, loss = 2.8787
2024-10-30 15:01:00: [2024-10-30 15:01:00] iter = 00080, loss = 2.6648
2024-10-30 15:01:05: [2024-10-30 15:01:05] iter = 00090, loss = 3.7682
2024-10-30 15:01:09: [2024-10-30 15:01:09] iter = 00100, loss = 2.7162
2024-10-30 15:01:13: [2024-10-30 15:01:13] iter = 00110, loss = 2.6731
2024-10-30 15:01:17: [2024-10-30 15:01:17] iter = 00120, loss = 2.3944
2024-10-30 15:01:22: [2024-10-30 15:01:22] iter = 00130, loss = 2.5030
2024-10-30 15:01:26: [2024-10-30 15:01:26] iter = 00140, loss = 3.6610
2024-10-30 15:01:30: [2024-10-30 15:01:30] iter = 00150, loss = 2.1536
2024-10-30 15:01:34: [2024-10-30 15:01:34] iter = 00160, loss = 2.4023
2024-10-30 15:01:39: [2024-10-30 15:01:38] iter = 00170, loss = 3.5039
2024-10-30 15:01:42: [2024-10-30 15:01:42] iter = 00180, loss = 2.6611
2024-10-30 15:01:46: [2024-10-30 15:01:46] iter = 00190, loss = 3.0391
2024-10-30 15:01:50: [2024-10-30 15:01:50] iter = 00200, loss = 3.8602
2024-10-30 15:01:54: [2024-10-30 15:01:54] iter = 00210, loss = 2.7089
2024-10-30 15:01:59: [2024-10-30 15:01:59] iter = 00220, loss = 2.9906
2024-10-30 15:02:03: [2024-10-30 15:02:03] iter = 00230, loss = 2.3555
2024-10-30 15:02:07: [2024-10-30 15:02:07] iter = 00240, loss = 2.2949
2024-10-30 15:02:10: [2024-10-30 15:02:10] iter = 00250, loss = 2.3495
2024-10-30 15:02:14: [2024-10-30 15:02:14] iter = 00260, loss = 2.1443
2024-10-30 15:02:18: [2024-10-30 15:02:18] iter = 00270, loss = 1.9378
2024-10-30 15:02:21: [2024-10-30 15:02:21] iter = 00280, loss = 2.5148
2024-10-30 15:02:25: [2024-10-30 15:02:25] iter = 00290, loss = 2.8782
2024-10-30 15:02:29: [2024-10-30 15:02:29] iter = 00300, loss = 2.8972
2024-10-30 15:02:33: [2024-10-30 15:02:33] iter = 00310, loss = 2.4752
2024-10-30 15:02:37: [2024-10-30 15:02:37] iter = 00320, loss = 2.7363
2024-10-30 15:02:40: [2024-10-30 15:02:40] iter = 00330, loss = 3.0076
2024-10-30 15:02:44: [2024-10-30 15:02:44] iter = 00340, loss = 2.5719
2024-10-30 15:02:47: [2024-10-30 15:02:47] iter = 00350, loss = 1.9817
2024-10-30 15:02:51: [2024-10-30 15:02:51] iter = 00360, loss = 3.1988
2024-10-30 15:02:55: [2024-10-30 15:02:55] iter = 00370, loss = 2.7076
2024-10-30 15:02:58: [2024-10-30 15:02:58] iter = 00380, loss = 2.3592
2024-10-30 15:03:03: [2024-10-30 15:03:03] iter = 00390, loss = 2.4077
2024-10-30 15:03:06: [2024-10-30 15:03:06] iter = 00400, loss = 2.4608
2024-10-30 15:03:10: [2024-10-30 15:03:10] iter = 00410, loss = 2.8021
2024-10-30 15:03:13: [2024-10-30 15:03:13] iter = 00420, loss = 2.4838
2024-10-30 15:03:16: [2024-10-30 15:03:16] iter = 00430, loss = 2.4760
2024-10-30 15:03:20: [2024-10-30 15:03:20] iter = 00440, loss = 2.8021
2024-10-30 15:03:23: [2024-10-30 15:03:23] iter = 00450, loss = 2.7441
2024-10-30 15:03:26: [2024-10-30 15:03:26] iter = 00460, loss = 2.7187
2024-10-30 15:03:30: [2024-10-30 15:03:30] iter = 00470, loss = 2.2936
2024-10-30 15:03:35: [2024-10-30 15:03:35] iter = 00480, loss = 2.1464
2024-10-30 15:03:38: [2024-10-30 15:03:38] iter = 00490, loss = 2.4646
2024-10-30 15:03:42: [2024-10-30 15:03:42] iter = 00500, loss = 2.9750
2024-10-30 15:03:46: [2024-10-30 15:03:46] iter = 00510, loss = 2.2002
2024-10-30 15:03:49: [2024-10-30 15:03:49] iter = 00520, loss = 3.3378
2024-10-30 15:03:52: [2024-10-30 15:03:52] iter = 00530, loss = 2.3281
2024-10-30 15:03:56: [2024-10-30 15:03:56] iter = 00540, loss = 3.4312
2024-10-30 15:04:01: [2024-10-30 15:04:01] iter = 00550, loss = 2.2933
2024-10-30 15:04:04: [2024-10-30 15:04:04] iter = 00560, loss = 2.2485
2024-10-30 15:04:09: [2024-10-30 15:04:09] iter = 00570, loss = 2.1538
2024-10-30 15:04:13: [2024-10-30 15:04:13] iter = 00580, loss = 2.3059
2024-10-30 15:04:16: [2024-10-30 15:04:16] iter = 00590, loss = 2.3353
2024-10-30 15:04:19: [2024-10-30 15:04:19] iter = 00600, loss = 3.1603
2024-10-30 15:04:22: [2024-10-30 15:04:22] iter = 00610, loss = 2.8445
2024-10-30 15:04:26: [2024-10-30 15:04:26] iter = 00620, loss = 2.1785
2024-10-30 15:04:30: [2024-10-30 15:04:30] iter = 00630, loss = 3.0321
2024-10-30 15:04:33: [2024-10-30 15:04:33] iter = 00640, loss = 2.3210
2024-10-30 15:04:37: [2024-10-30 15:04:37] iter = 00650, loss = 2.1093
2024-10-30 15:04:41: [2024-10-30 15:04:41] iter = 00660, loss = 2.1486
2024-10-30 15:04:45: [2024-10-30 15:04:45] iter = 00670, loss = 2.2725
2024-10-30 15:04:49: [2024-10-30 15:04:49] iter = 00680, loss = 2.3486
2024-10-30 15:04:53: [2024-10-30 15:04:53] iter = 00690, loss = 2.2062
2024-10-30 15:04:56: [2024-10-30 15:04:56] iter = 00700, loss = 2.1755
2024-10-30 15:05:00: [2024-10-30 15:05:00] iter = 00710, loss = 2.7782
2024-10-30 15:05:04: [2024-10-30 15:05:04] iter = 00720, loss = 2.7638
2024-10-30 15:05:07: [2024-10-30 15:05:07] iter = 00730, loss = 2.8742
2024-10-30 15:05:11: [2024-10-30 15:05:11] iter = 00740, loss = 2.4823
2024-10-30 15:05:16: [2024-10-30 15:05:16] iter = 00750, loss = 2.9557
2024-10-30 15:05:20: [2024-10-30 15:05:20] iter = 00760, loss = 2.5422
2024-10-30 15:05:24: [2024-10-30 15:05:24] iter = 00770, loss = 1.9862
2024-10-30 15:05:27: [2024-10-30 15:05:27] iter = 00780, loss = 2.6354
2024-10-30 15:05:31: [2024-10-30 15:05:31] iter = 00790, loss = 2.2531
2024-10-30 15:05:35: [2024-10-30 15:05:35] iter = 00800, loss = 4.3395
2024-10-30 15:05:38: [2024-10-30 15:05:38] iter = 00810, loss = 2.1501
2024-10-30 15:05:41: [2024-10-30 15:05:41] iter = 00820, loss = 2.4799
2024-10-30 15:05:45: [2024-10-30 15:05:45] iter = 00830, loss = 3.2513
2024-10-30 15:05:49: [2024-10-30 15:05:49] iter = 00840, loss = 2.2735
2024-10-30 15:05:52: [2024-10-30 15:05:52] iter = 00850, loss = 2.3395
2024-10-30 15:05:54: [2024-10-30 15:05:54] iter = 00860, loss = 1.9308
2024-10-30 15:05:57: [2024-10-30 15:05:57] iter = 00870, loss = 2.3899
2024-10-30 15:06:01: [2024-10-30 15:06:01] iter = 00880, loss = 3.0092
2024-10-30 15:06:04: [2024-10-30 15:06:04] iter = 00890, loss = 2.4512
2024-10-30 15:06:06: [2024-10-30 15:06:06] iter = 00900, loss = 2.1684
2024-10-30 15:06:10: [2024-10-30 15:06:10] iter = 00910, loss = 2.2189
2024-10-30 15:06:14: [2024-10-30 15:06:14] iter = 00920, loss = 2.9826
2024-10-30 15:06:17: [2024-10-30 15:06:17] iter = 00930, loss = 2.5325
2024-10-30 15:06:20: [2024-10-30 15:06:20] iter = 00940, loss = 2.4734
2024-10-30 15:06:23: [2024-10-30 15:06:23] iter = 00950, loss = 2.3085
2024-10-30 15:06:27: [2024-10-30 15:06:27] iter = 00960, loss = 2.2957
2024-10-30 15:06:30: [2024-10-30 15:06:30] iter = 00970, loss = 2.5834
2024-10-30 15:06:34: [2024-10-30 15:06:34] iter = 00980, loss = 2.2451
2024-10-30 15:06:36: [2024-10-30 15:06:36] iter = 00990, loss = 2.3411
2024-10-30 15:06:40: [2024-10-30 15:06:40] iter = 01000, loss = 1.9481
2024-10-30 15:06:43: [2024-10-30 15:06:43] iter = 01010, loss = 2.9443
2024-10-30 15:06:48: [2024-10-30 15:06:48] iter = 01020, loss = 2.2663
2024-10-30 15:06:51: [2024-10-30 15:06:51] iter = 01030, loss = 2.1949
2024-10-30 15:06:55: [2024-10-30 15:06:55] iter = 01040, loss = 2.0873
2024-10-30 15:06:58: [2024-10-30 15:06:58] iter = 01050, loss = 2.3150
2024-10-30 15:07:02: [2024-10-30 15:07:02] iter = 01060, loss = 2.1456
2024-10-30 15:07:05: [2024-10-30 15:07:05] iter = 01070, loss = 2.0511
2024-10-30 15:07:09: [2024-10-30 15:07:09] iter = 01080, loss = 2.8722
2024-10-30 15:07:13: [2024-10-30 15:07:13] iter = 01090, loss = 2.8882
2024-10-30 15:07:16: [2024-10-30 15:07:16] iter = 01100, loss = 3.0541
2024-10-30 15:07:18: [2024-10-30 15:07:18] iter = 01110, loss = 2.4131
2024-10-30 15:07:22: [2024-10-30 15:07:22] iter = 01120, loss = 2.0233
2024-10-30 15:07:25: [2024-10-30 15:07:25] iter = 01130, loss = 2.4440
2024-10-30 15:07:29: [2024-10-30 15:07:29] iter = 01140, loss = 2.6780
2024-10-30 15:07:32: [2024-10-30 15:07:32] iter = 01150, loss = 1.9210
2024-10-30 15:07:35: [2024-10-30 15:07:35] iter = 01160, loss = 2.7817
2024-10-30 15:07:38: [2024-10-30 15:07:38] iter = 01170, loss = 2.9604
2024-10-30 15:07:42: [2024-10-30 15:07:42] iter = 01180, loss = 3.0096
2024-10-30 15:07:45: [2024-10-30 15:07:45] iter = 01190, loss = 3.7261
2024-10-30 15:07:49: [2024-10-30 15:07:49] iter = 01200, loss = 2.2021
2024-10-30 15:07:52: [2024-10-30 15:07:52] iter = 01210, loss = 2.7872
2024-10-30 15:07:56: [2024-10-30 15:07:56] iter = 01220, loss = 2.5751
2024-10-30 15:07:59: [2024-10-30 15:07:59] iter = 01230, loss = 3.6827
2024-10-30 15:08:02: [2024-10-30 15:08:02] iter = 01240, loss = 1.9632
2024-10-30 15:08:06: [2024-10-30 15:08:06] iter = 01250, loss = 2.0135
2024-10-30 15:08:10: [2024-10-30 15:08:10] iter = 01260, loss = 2.2212
2024-10-30 15:08:13: [2024-10-30 15:08:13] iter = 01270, loss = 1.9343
2024-10-30 15:08:16: [2024-10-30 15:08:16] iter = 01280, loss = 2.5068
2024-10-30 15:08:20: [2024-10-30 15:08:20] iter = 01290, loss = 2.2020
2024-10-30 15:08:23: [2024-10-30 15:08:23] iter = 01300, loss = 2.3487
2024-10-30 15:08:27: [2024-10-30 15:08:27] iter = 01310, loss = 3.7260
2024-10-30 15:08:30: [2024-10-30 15:08:30] iter = 01320, loss = 2.3654
2024-10-30 15:08:33: [2024-10-30 15:08:33] iter = 01330, loss = 2.9729
2024-10-30 15:08:37: [2024-10-30 15:08:37] iter = 01340, loss = 2.1616
2024-10-30 15:08:41: [2024-10-30 15:08:41] iter = 01350, loss = 2.1100
2024-10-30 15:08:45: [2024-10-30 15:08:45] iter = 01360, loss = 2.5188
2024-10-30 15:08:48: [2024-10-30 15:08:48] iter = 01370, loss = 3.0686
2024-10-30 15:08:52: [2024-10-30 15:08:52] iter = 01380, loss = 2.3834
2024-10-30 15:08:55: [2024-10-30 15:08:55] iter = 01390, loss = 2.2780
2024-10-30 15:08:59: [2024-10-30 15:08:59] iter = 01400, loss = 2.6130
2024-10-30 15:09:03: [2024-10-30 15:09:02] iter = 01410, loss = 2.3183
2024-10-30 15:09:06: [2024-10-30 15:09:06] iter = 01420, loss = 2.4778
2024-10-30 15:09:11: [2024-10-30 15:09:11] iter = 01430, loss = 2.6445
2024-10-30 15:09:15: [2024-10-30 15:09:15] iter = 01440, loss = 2.0721
2024-10-30 15:09:19: [2024-10-30 15:09:19] iter = 01450, loss = 2.0047
2024-10-30 15:09:23: [2024-10-30 15:09:23] iter = 01460, loss = 1.9988
2024-10-30 15:09:26: [2024-10-30 15:09:26] iter = 01470, loss = 2.0096
2024-10-30 15:09:30: [2024-10-30 15:09:30] iter = 01480, loss = 2.3515
2024-10-30 15:09:34: [2024-10-30 15:09:34] iter = 01490, loss = 2.6268
2024-10-30 15:09:38: [2024-10-30 15:09:38] iter = 01500, loss = 2.2487
2024-10-30 15:09:41: [2024-10-30 15:09:41] iter = 01510, loss = 2.0368
2024-10-30 15:09:46: [2024-10-30 15:09:46] iter = 01520, loss = 2.4448
2024-10-30 15:09:50: [2024-10-30 15:09:50] iter = 01530, loss = 4.7642
2024-10-30 15:09:54: [2024-10-30 15:09:54] iter = 01540, loss = 2.2013
2024-10-30 15:09:58: [2024-10-30 15:09:58] iter = 01550, loss = 2.7943
2024-10-30 15:10:02: [2024-10-30 15:10:02] iter = 01560, loss = 2.3040
2024-10-30 15:10:05: [2024-10-30 15:10:05] iter = 01570, loss = 2.6903
2024-10-30 15:10:08: [2024-10-30 15:10:08] iter = 01580, loss = 1.8548
2024-10-30 15:10:13: [2024-10-30 15:10:13] iter = 01590, loss = 2.6461
2024-10-30 15:10:16: [2024-10-30 15:10:16] iter = 01600, loss = 2.4216
2024-10-30 15:10:19: [2024-10-30 15:10:19] iter = 01610, loss = 2.4439
2024-10-30 15:10:23: [2024-10-30 15:10:23] iter = 01620, loss = 2.3306
2024-10-30 15:10:26: [2024-10-30 15:10:26] iter = 01630, loss = 2.4498
2024-10-30 15:10:30: [2024-10-30 15:10:30] iter = 01640, loss = 2.6108
2024-10-30 15:10:34: [2024-10-30 15:10:34] iter = 01650, loss = 2.0041
2024-10-30 15:10:38: [2024-10-30 15:10:38] iter = 01660, loss = 2.2043
2024-10-30 15:10:42: [2024-10-30 15:10:42] iter = 01670, loss = 2.7891
2024-10-30 15:10:46: [2024-10-30 15:10:46] iter = 01680, loss = 2.6342
2024-10-30 15:10:50: [2024-10-30 15:10:50] iter = 01690, loss = 2.3969
2024-10-30 15:10:53: [2024-10-30 15:10:53] iter = 01700, loss = 2.3621
2024-10-30 15:10:57: [2024-10-30 15:10:57] iter = 01710, loss = 2.6258
2024-10-30 15:11:01: [2024-10-30 15:11:01] iter = 01720, loss = 1.9998
2024-10-30 15:11:05: [2024-10-30 15:11:05] iter = 01730, loss = 2.2413
2024-10-30 15:11:09: [2024-10-30 15:11:09] iter = 01740, loss = 2.0696
2024-10-30 15:11:13: [2024-10-30 15:11:13] iter = 01750, loss = 2.0393
2024-10-30 15:11:17: [2024-10-30 15:11:17] iter = 01760, loss = 2.0592
2024-10-30 15:11:22: [2024-10-30 15:11:22] iter = 01770, loss = 3.4876
2024-10-30 15:11:25: [2024-10-30 15:11:25] iter = 01780, loss = 2.3152
2024-10-30 15:11:29: [2024-10-30 15:11:29] iter = 01790, loss = 1.9093
2024-10-30 15:11:32: [2024-10-30 15:11:32] iter = 01800, loss = 3.4505
2024-10-30 15:11:36: [2024-10-30 15:11:36] iter = 01810, loss = 2.3940
2024-10-30 15:11:40: [2024-10-30 15:11:40] iter = 01820, loss = 3.0872
2024-10-30 15:11:44: [2024-10-30 15:11:44] iter = 01830, loss = 2.1820
2024-10-30 15:11:49: [2024-10-30 15:11:49] iter = 01840, loss = 2.3198
2024-10-30 15:11:53: [2024-10-30 15:11:53] iter = 01850, loss = 4.4845
2024-10-30 15:11:56: [2024-10-30 15:11:56] iter = 01860, loss = 3.2320
2024-10-30 15:11:59: [2024-10-30 15:11:59] iter = 01870, loss = 2.4016
2024-10-30 15:12:02: [2024-10-30 15:12:02] iter = 01880, loss = 2.5850
2024-10-30 15:12:05: [2024-10-30 15:12:05] iter = 01890, loss = 2.4947
2024-10-30 15:12:09: [2024-10-30 15:12:09] iter = 01900, loss = 2.3592
2024-10-30 15:12:13: [2024-10-30 15:12:13] iter = 01910, loss = 4.5356
2024-10-30 15:12:16: [2024-10-30 15:12:16] iter = 01920, loss = 1.7811
2024-10-30 15:12:20: [2024-10-30 15:12:20] iter = 01930, loss = 2.1572
2024-10-30 15:12:24: [2024-10-30 15:12:24] iter = 01940, loss = 2.3226
2024-10-30 15:12:28: [2024-10-30 15:12:28] iter = 01950, loss = 2.4194
2024-10-30 15:12:31: [2024-10-30 15:12:31] iter = 01960, loss = 2.4882
2024-10-30 15:12:35: [2024-10-30 15:12:35] iter = 01970, loss = 2.0243
2024-10-30 15:12:39: [2024-10-30 15:12:39] iter = 01980, loss = 1.9736
2024-10-30 15:12:43: [2024-10-30 15:12:43] iter = 01990, loss = 2.1858
2024-10-30 15:12:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 15:12:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:12:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 65940}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:15:04: Evaluate 5 random ConvNet, ACCmean = 0.6116 ACCstd = 0.0050
-------------------------
2024-10-30 15:15:04: Evaluate 5 random ConvNet, SENmean = 0.5852 SENstd = 0.0017
-------------------------
2024-10-30 15:15:04: Evaluate 5 random ConvNet, SPEmean = 0.9606 SPEstd = 0.0005
-------------------------
2024-10-30 15:15:04: Evaluate 5 random ConvNet, F!mean = 0.5727 F!std = 0.0027
-------------------------
2024-10-30 15:15:04: Evaluate 5 random ConvNet, mean = 0.6116 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:15:04: [2024-10-30 15:15:04] iter = 02000, loss = 3.1875
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:15:08: [2024-10-30 15:15:08] iter = 02010, loss = 2.5204
2024-10-30 15:15:11: [2024-10-30 15:15:11] iter = 02020, loss = 2.3170
2024-10-30 15:15:15: [2024-10-30 15:15:15] iter = 02030, loss = 2.0201
2024-10-30 15:15:18: [2024-10-30 15:15:18] iter = 02040, loss = 2.9513
2024-10-30 15:15:22: [2024-10-30 15:15:22] iter = 02050, loss = 2.0392
2024-10-30 15:15:26: [2024-10-30 15:15:26] iter = 02060, loss = 1.8807
2024-10-30 15:15:31: [2024-10-30 15:15:31] iter = 02070, loss = 2.3726
2024-10-30 15:15:35: [2024-10-30 15:15:35] iter = 02080, loss = 2.0364
2024-10-30 15:15:38: [2024-10-30 15:15:38] iter = 02090, loss = 1.9650
2024-10-30 15:15:40: [2024-10-30 15:15:40] iter = 02100, loss = 3.6719
2024-10-30 15:15:44: [2024-10-30 15:15:44] iter = 02110, loss = 3.1052
2024-10-30 15:15:47: [2024-10-30 15:15:47] iter = 02120, loss = 3.9977
2024-10-30 15:15:51: [2024-10-30 15:15:51] iter = 02130, loss = 2.6820
2024-10-30 15:15:55: [2024-10-30 15:15:55] iter = 02140, loss = 1.9856
2024-10-30 15:15:59: [2024-10-30 15:15:59] iter = 02150, loss = 1.9383
2024-10-30 15:16:03: [2024-10-30 15:16:03] iter = 02160, loss = 1.9473
2024-10-30 15:16:06: [2024-10-30 15:16:06] iter = 02170, loss = 2.1662
2024-10-30 15:16:09: [2024-10-30 15:16:09] iter = 02180, loss = 2.2157
2024-10-30 15:16:12: [2024-10-30 15:16:12] iter = 02190, loss = 2.8257
2024-10-30 15:16:16: [2024-10-30 15:16:16] iter = 02200, loss = 2.1344
2024-10-30 15:16:19: [2024-10-30 15:16:19] iter = 02210, loss = 2.1940
2024-10-30 15:16:22: [2024-10-30 15:16:22] iter = 02220, loss = 2.4407
2024-10-30 15:16:26: [2024-10-30 15:16:26] iter = 02230, loss = 1.9321
2024-10-30 15:16:30: [2024-10-30 15:16:30] iter = 02240, loss = 1.9555
2024-10-30 15:16:34: [2024-10-30 15:16:34] iter = 02250, loss = 2.2559
2024-10-30 15:16:38: [2024-10-30 15:16:38] iter = 02260, loss = 2.0289
2024-10-30 15:16:42: [2024-10-30 15:16:42] iter = 02270, loss = 6.8369
2024-10-30 15:16:44: [2024-10-30 15:16:44] iter = 02280, loss = 2.2749
2024-10-30 15:16:47: [2024-10-30 15:16:47] iter = 02290, loss = 2.4427
2024-10-30 15:16:49: [2024-10-30 15:16:49] iter = 02300, loss = 2.1754
2024-10-30 15:16:52: [2024-10-30 15:16:52] iter = 02310, loss = 2.3925
2024-10-30 15:16:55: [2024-10-30 15:16:55] iter = 02320, loss = 2.3910
2024-10-30 15:16:59: [2024-10-30 15:16:59] iter = 02330, loss = 2.2009
2024-10-30 15:17:03: [2024-10-30 15:17:03] iter = 02340, loss = 2.0663
2024-10-30 15:17:06: [2024-10-30 15:17:06] iter = 02350, loss = 3.2861
2024-10-30 15:17:09: [2024-10-30 15:17:09] iter = 02360, loss = 2.3055
2024-10-30 15:17:13: [2024-10-30 15:17:13] iter = 02370, loss = 2.2188
2024-10-30 15:17:15: [2024-10-30 15:17:15] iter = 02380, loss = 2.2535
2024-10-30 15:17:19: [2024-10-30 15:17:19] iter = 02390, loss = 3.6909
2024-10-30 15:17:22: [2024-10-30 15:17:22] iter = 02400, loss = 1.8001
2024-10-30 15:17:26: [2024-10-30 15:17:26] iter = 02410, loss = 2.0489
2024-10-30 15:17:30: [2024-10-30 15:17:30] iter = 02420, loss = 3.0447
2024-10-30 15:17:33: [2024-10-30 15:17:33] iter = 02430, loss = 2.6196
2024-10-30 15:17:37: [2024-10-30 15:17:37] iter = 02440, loss = 1.9971
2024-10-30 15:17:41: [2024-10-30 15:17:41] iter = 02450, loss = 1.9225
2024-10-30 15:17:44: [2024-10-30 15:17:44] iter = 02460, loss = 2.4418
2024-10-30 15:17:47: [2024-10-30 15:17:47] iter = 02470, loss = 2.1795
2024-10-30 15:17:51: [2024-10-30 15:17:51] iter = 02480, loss = 2.5029
2024-10-30 15:17:54: [2024-10-30 15:17:54] iter = 02490, loss = 2.8414
2024-10-30 15:17:57: [2024-10-30 15:17:57] iter = 02500, loss = 2.2062
2024-10-30 15:18:00: [2024-10-30 15:18:00] iter = 02510, loss = 2.6495
2024-10-30 15:18:04: [2024-10-30 15:18:04] iter = 02520, loss = 1.8974
2024-10-30 15:18:08: [2024-10-30 15:18:08] iter = 02530, loss = 2.2630
2024-10-30 15:18:11: [2024-10-30 15:18:11] iter = 02540, loss = 2.1063
2024-10-30 15:18:14: [2024-10-30 15:18:14] iter = 02550, loss = 2.2590
2024-10-30 15:18:18: [2024-10-30 15:18:18] iter = 02560, loss = 1.9931
2024-10-30 15:18:21: [2024-10-30 15:18:21] iter = 02570, loss = 4.1978
2024-10-30 15:18:24: [2024-10-30 15:18:24] iter = 02580, loss = 2.1703
2024-10-30 15:18:27: [2024-10-30 15:18:27] iter = 02590, loss = 2.3920
2024-10-30 15:18:31: [2024-10-30 15:18:31] iter = 02600, loss = 2.0989
2024-10-30 15:18:34: [2024-10-30 15:18:34] iter = 02610, loss = 3.0318
2024-10-30 15:18:38: [2024-10-30 15:18:38] iter = 02620, loss = 2.2037
2024-10-30 15:18:41: [2024-10-30 15:18:41] iter = 02630, loss = 2.1628
2024-10-30 15:18:44: [2024-10-30 15:18:44] iter = 02640, loss = 2.0036
2024-10-30 15:18:48: [2024-10-30 15:18:48] iter = 02650, loss = 2.2907
2024-10-30 15:18:51: [2024-10-30 15:18:51] iter = 02660, loss = 2.0848
2024-10-30 15:18:55: [2024-10-30 15:18:55] iter = 02670, loss = 2.1939
2024-10-30 15:18:58: [2024-10-30 15:18:58] iter = 02680, loss = 3.1934
2024-10-30 15:19:01: [2024-10-30 15:19:01] iter = 02690, loss = 2.5443
2024-10-30 15:19:05: [2024-10-30 15:19:05] iter = 02700, loss = 3.5346
2024-10-30 15:19:08: [2024-10-30 15:19:08] iter = 02710, loss = 1.9328
2024-10-30 15:19:11: [2024-10-30 15:19:11] iter = 02720, loss = 2.4081
2024-10-30 15:19:14: [2024-10-30 15:19:14] iter = 02730, loss = 2.3704
2024-10-30 15:19:17: [2024-10-30 15:19:17] iter = 02740, loss = 2.1991
2024-10-30 15:19:21: [2024-10-30 15:19:21] iter = 02750, loss = 1.9988
2024-10-30 15:19:25: [2024-10-30 15:19:25] iter = 02760, loss = 2.2717
2024-10-30 15:19:29: [2024-10-30 15:19:29] iter = 02770, loss = 2.8500
2024-10-30 15:19:33: [2024-10-30 15:19:33] iter = 02780, loss = 2.5934
2024-10-30 15:19:36: [2024-10-30 15:19:36] iter = 02790, loss = 2.1478
2024-10-30 15:19:41: [2024-10-30 15:19:41] iter = 02800, loss = 2.2318
2024-10-30 15:19:45: [2024-10-30 15:19:45] iter = 02810, loss = 2.4972
2024-10-30 15:19:49: [2024-10-30 15:19:49] iter = 02820, loss = 2.9277
2024-10-30 15:19:54: [2024-10-30 15:19:54] iter = 02830, loss = 2.4281
2024-10-30 15:19:58: [2024-10-30 15:19:58] iter = 02840, loss = 2.2756
2024-10-30 15:20:02: [2024-10-30 15:20:02] iter = 02850, loss = 2.2455
2024-10-30 15:20:06: [2024-10-30 15:20:06] iter = 02860, loss = 2.2611
2024-10-30 15:20:11: [2024-10-30 15:20:11] iter = 02870, loss = 2.0508
2024-10-30 15:20:14: [2024-10-30 15:20:14] iter = 02880, loss = 2.2814
2024-10-30 15:20:18: [2024-10-30 15:20:18] iter = 02890, loss = 1.9120
2024-10-30 15:20:22: [2024-10-30 15:20:22] iter = 02900, loss = 2.3695
2024-10-30 15:20:26: [2024-10-30 15:20:26] iter = 02910, loss = 2.2271
2024-10-30 15:20:29: [2024-10-30 15:20:29] iter = 02920, loss = 2.7596
2024-10-30 15:20:33: [2024-10-30 15:20:33] iter = 02930, loss = 2.1957
2024-10-30 15:20:38: [2024-10-30 15:20:38] iter = 02940, loss = 1.9540
2024-10-30 15:20:41: [2024-10-30 15:20:41] iter = 02950, loss = 2.0583
2024-10-30 15:20:45: [2024-10-30 15:20:45] iter = 02960, loss = 2.3646
2024-10-30 15:20:49: [2024-10-30 15:20:49] iter = 02970, loss = 5.1294
2024-10-30 15:20:53: [2024-10-30 15:20:53] iter = 02980, loss = 2.2893
2024-10-30 15:20:57: [2024-10-30 15:20:57] iter = 02990, loss = 2.3929
2024-10-30 15:21:00: [2024-10-30 15:21:00] iter = 03000, loss = 1.9899
2024-10-30 15:21:04: [2024-10-30 15:21:04] iter = 03010, loss = 1.9113
2024-10-30 15:21:07: [2024-10-30 15:21:07] iter = 03020, loss = 2.5564
2024-10-30 15:21:10: [2024-10-30 15:21:10] iter = 03030, loss = 2.0149
2024-10-30 15:21:14: [2024-10-30 15:21:14] iter = 03040, loss = 1.8694
2024-10-30 15:21:18: [2024-10-30 15:21:18] iter = 03050, loss = 2.1108
2024-10-30 15:21:22: [2024-10-30 15:21:22] iter = 03060, loss = 2.3692
2024-10-30 15:21:26: [2024-10-30 15:21:26] iter = 03070, loss = 2.0442
2024-10-30 15:21:30: [2024-10-30 15:21:30] iter = 03080, loss = 1.7119
2024-10-30 15:21:33: [2024-10-30 15:21:33] iter = 03090, loss = 2.0828
2024-10-30 15:21:38: [2024-10-30 15:21:38] iter = 03100, loss = 3.5578
2024-10-30 15:21:42: [2024-10-30 15:21:42] iter = 03110, loss = 2.9637
2024-10-30 15:21:45: [2024-10-30 15:21:45] iter = 03120, loss = 1.9929
2024-10-30 15:21:49: [2024-10-30 15:21:49] iter = 03130, loss = 2.5445
2024-10-30 15:21:53: [2024-10-30 15:21:53] iter = 03140, loss = 3.0530
2024-10-30 15:21:57: [2024-10-30 15:21:57] iter = 03150, loss = 2.3486
2024-10-30 15:22:01: [2024-10-30 15:22:01] iter = 03160, loss = 2.1551
2024-10-30 15:22:04: [2024-10-30 15:22:04] iter = 03170, loss = 2.2402
2024-10-30 15:22:08: [2024-10-30 15:22:08] iter = 03180, loss = 2.4335
2024-10-30 15:22:13: [2024-10-30 15:22:13] iter = 03190, loss = 2.2827
2024-10-30 15:22:16: [2024-10-30 15:22:16] iter = 03200, loss = 2.0513
2024-10-30 15:22:19: [2024-10-30 15:22:19] iter = 03210, loss = 2.7033
2024-10-30 15:22:23: [2024-10-30 15:22:23] iter = 03220, loss = 3.7420
2024-10-30 15:22:26: [2024-10-30 15:22:26] iter = 03230, loss = 1.9821
2024-10-30 15:22:30: [2024-10-30 15:22:30] iter = 03240, loss = 3.9475
2024-10-30 15:22:34: [2024-10-30 15:22:34] iter = 03250, loss = 2.1202
2024-10-30 15:22:38: [2024-10-30 15:22:38] iter = 03260, loss = 2.4783
2024-10-30 15:22:43: [2024-10-30 15:22:43] iter = 03270, loss = 2.1846
2024-10-30 15:22:47: [2024-10-30 15:22:47] iter = 03280, loss = 1.8940
2024-10-30 15:22:50: [2024-10-30 15:22:50] iter = 03290, loss = 2.1225
2024-10-30 15:22:54: [2024-10-30 15:22:54] iter = 03300, loss = 2.2112
2024-10-30 15:22:58: [2024-10-30 15:22:58] iter = 03310, loss = 2.3202
2024-10-30 15:23:02: [2024-10-30 15:23:02] iter = 03320, loss = 3.5700
2024-10-30 15:23:05: [2024-10-30 15:23:05] iter = 03330, loss = 2.2833
2024-10-30 15:23:09: [2024-10-30 15:23:09] iter = 03340, loss = 2.6182
2024-10-30 15:23:13: [2024-10-30 15:23:13] iter = 03350, loss = 1.9323
2024-10-30 15:23:17: [2024-10-30 15:23:17] iter = 03360, loss = 2.2990
2024-10-30 15:23:21: [2024-10-30 15:23:21] iter = 03370, loss = 1.9828
2024-10-30 15:23:24: [2024-10-30 15:23:24] iter = 03380, loss = 2.6935
2024-10-30 15:23:27: [2024-10-30 15:23:27] iter = 03390, loss = 2.2363
2024-10-30 15:23:30: [2024-10-30 15:23:30] iter = 03400, loss = 2.0018
2024-10-30 15:23:34: [2024-10-30 15:23:34] iter = 03410, loss = 2.2579
2024-10-30 15:23:37: [2024-10-30 15:23:37] iter = 03420, loss = 2.9702
2024-10-30 15:23:40: [2024-10-30 15:23:40] iter = 03430, loss = 2.0152
2024-10-30 15:23:44: [2024-10-30 15:23:44] iter = 03440, loss = 3.3171
2024-10-30 15:23:47: [2024-10-30 15:23:47] iter = 03450, loss = 2.1897
2024-10-30 15:23:51: [2024-10-30 15:23:51] iter = 03460, loss = 2.1970
2024-10-30 15:23:55: [2024-10-30 15:23:55] iter = 03470, loss = 1.9061
2024-10-30 15:23:58: [2024-10-30 15:23:58] iter = 03480, loss = 2.1972
2024-10-30 15:24:02: [2024-10-30 15:24:02] iter = 03490, loss = 2.0988
2024-10-30 15:24:05: [2024-10-30 15:24:05] iter = 03500, loss = 2.0262
2024-10-30 15:24:09: [2024-10-30 15:24:09] iter = 03510, loss = 2.2574
2024-10-30 15:24:12: [2024-10-30 15:24:12] iter = 03520, loss = 3.0759
2024-10-30 15:24:16: [2024-10-30 15:24:16] iter = 03530, loss = 2.0595
2024-10-30 15:24:20: [2024-10-30 15:24:20] iter = 03540, loss = 3.2963
2024-10-30 15:24:23: [2024-10-30 15:24:23] iter = 03550, loss = 1.8295
2024-10-30 15:24:27: [2024-10-30 15:24:27] iter = 03560, loss = 2.0235
2024-10-30 15:24:30: [2024-10-30 15:24:30] iter = 03570, loss = 2.9537
2024-10-30 15:24:34: [2024-10-30 15:24:34] iter = 03580, loss = 2.5482
2024-10-30 15:24:38: [2024-10-30 15:24:38] iter = 03590, loss = 2.6378
2024-10-30 15:24:41: [2024-10-30 15:24:41] iter = 03600, loss = 1.8158
2024-10-30 15:24:44: [2024-10-30 15:24:44] iter = 03610, loss = 1.8709
2024-10-30 15:24:48: [2024-10-30 15:24:48] iter = 03620, loss = 2.1941
2024-10-30 15:24:52: [2024-10-30 15:24:52] iter = 03630, loss = 4.2795
2024-10-30 15:24:55: [2024-10-30 15:24:55] iter = 03640, loss = 2.4104
2024-10-30 15:24:58: [2024-10-30 15:24:58] iter = 03650, loss = 2.0870
2024-10-30 15:25:01: [2024-10-30 15:25:01] iter = 03660, loss = 2.3018
2024-10-30 15:25:04: [2024-10-30 15:25:04] iter = 03670, loss = 2.2673
2024-10-30 15:25:08: [2024-10-30 15:25:08] iter = 03680, loss = 2.3561
2024-10-30 15:25:11: [2024-10-30 15:25:11] iter = 03690, loss = 3.1847
2024-10-30 15:25:15: [2024-10-30 15:25:15] iter = 03700, loss = 3.7425
2024-10-30 15:25:19: [2024-10-30 15:25:19] iter = 03710, loss = 2.5422
2024-10-30 15:25:22: [2024-10-30 15:25:21] iter = 03720, loss = 2.5031
2024-10-30 15:25:23: [2024-10-30 15:25:23] iter = 03730, loss = 1.9982
2024-10-30 15:25:25: [2024-10-30 15:25:25] iter = 03740, loss = 1.9076
2024-10-30 15:25:30: [2024-10-30 15:25:30] iter = 03750, loss = 2.1364
2024-10-30 15:25:34: [2024-10-30 15:25:34] iter = 03760, loss = 2.5606
2024-10-30 15:25:37: [2024-10-30 15:25:37] iter = 03770, loss = 2.4358
2024-10-30 15:25:41: [2024-10-30 15:25:41] iter = 03780, loss = 2.6360
2024-10-30 15:25:45: [2024-10-30 15:25:45] iter = 03790, loss = 2.3135
2024-10-30 15:25:49: [2024-10-30 15:25:49] iter = 03800, loss = 2.1559
2024-10-30 15:25:52: [2024-10-30 15:25:52] iter = 03810, loss = 2.2391
2024-10-30 15:25:56: [2024-10-30 15:25:56] iter = 03820, loss = 2.4782
2024-10-30 15:26:00: [2024-10-30 15:26:00] iter = 03830, loss = 2.0974
2024-10-30 15:26:04: [2024-10-30 15:26:04] iter = 03840, loss = 2.1442
2024-10-30 15:26:08: [2024-10-30 15:26:08] iter = 03850, loss = 2.3290
2024-10-30 15:26:11: [2024-10-30 15:26:11] iter = 03860, loss = 2.6918
2024-10-30 15:26:14: [2024-10-30 15:26:14] iter = 03870, loss = 2.1301
2024-10-30 15:26:18: [2024-10-30 15:26:18] iter = 03880, loss = 3.3112
2024-10-30 15:26:22: [2024-10-30 15:26:22] iter = 03890, loss = 3.3066
2024-10-30 15:26:25: [2024-10-30 15:26:25] iter = 03900, loss = 3.2781
2024-10-30 15:26:29: [2024-10-30 15:26:29] iter = 03910, loss = 1.9700
2024-10-30 15:26:33: [2024-10-30 15:26:33] iter = 03920, loss = 3.6368
2024-10-30 15:26:36: [2024-10-30 15:26:36] iter = 03930, loss = 2.4175
2024-10-30 15:26:40: [2024-10-30 15:26:40] iter = 03940, loss = 2.5360
2024-10-30 15:26:44: [2024-10-30 15:26:44] iter = 03950, loss = 2.0398
2024-10-30 15:26:48: [2024-10-30 15:26:48] iter = 03960, loss = 2.4287
2024-10-30 15:26:52: [2024-10-30 15:26:52] iter = 03970, loss = 2.0491
2024-10-30 15:26:56: [2024-10-30 15:26:56] iter = 03980, loss = 2.8683
2024-10-30 15:27:00: [2024-10-30 15:27:00] iter = 03990, loss = 1.9090
2024-10-30 15:27:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 15:27:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:27:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 24209}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:29:21: Evaluate 5 random ConvNet, ACCmean = 0.6035 ACCstd = 0.0029
-------------------------
2024-10-30 15:29:21: Evaluate 5 random ConvNet, SENmean = 0.5850 SENstd = 0.0017
-------------------------
2024-10-30 15:29:21: Evaluate 5 random ConvNet, SPEmean = 0.9596 SPEstd = 0.0003
-------------------------
2024-10-30 15:29:21: Evaluate 5 random ConvNet, F!mean = 0.5766 F!std = 0.0037
-------------------------
2024-10-30 15:29:21: Evaluate 5 random ConvNet, mean = 0.6035 std = 0.0029
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:29:22: [2024-10-30 15:29:22] iter = 04000, loss = 3.4345
2024-10-30 15:29:26: [2024-10-30 15:29:26] iter = 04010, loss = 2.2976
2024-10-30 15:29:30: [2024-10-30 15:29:30] iter = 04020, loss = 3.5643
2024-10-30 15:29:34: [2024-10-30 15:29:34] iter = 04030, loss = 1.9624
2024-10-30 15:29:38: [2024-10-30 15:29:38] iter = 04040, loss = 3.7975
2024-10-30 15:29:43: [2024-10-30 15:29:43] iter = 04050, loss = 1.9515
2024-10-30 15:29:46: [2024-10-30 15:29:46] iter = 04060, loss = 2.5979
2024-10-30 15:29:50: [2024-10-30 15:29:50] iter = 04070, loss = 1.9680
2024-10-30 15:29:54: [2024-10-30 15:29:54] iter = 04080, loss = 2.1294
2024-10-30 15:29:59: [2024-10-30 15:29:59] iter = 04090, loss = 2.5070
2024-10-30 15:30:04: [2024-10-30 15:30:04] iter = 04100, loss = 2.3235
2024-10-30 15:30:08: [2024-10-30 15:30:08] iter = 04110, loss = 2.0115
2024-10-30 15:30:12: [2024-10-30 15:30:12] iter = 04120, loss = 2.5442
2024-10-30 15:30:16: [2024-10-30 15:30:16] iter = 04130, loss = 2.0254
2024-10-30 15:30:21: [2024-10-30 15:30:21] iter = 04140, loss = 3.5430
2024-10-30 15:30:26: [2024-10-30 15:30:26] iter = 04150, loss = 2.2531
2024-10-30 15:30:30: [2024-10-30 15:30:30] iter = 04160, loss = 2.2927
2024-10-30 15:30:33: [2024-10-30 15:30:33] iter = 04170, loss = 1.9039
2024-10-30 15:30:37: [2024-10-30 15:30:37] iter = 04180, loss = 2.2605
2024-10-30 15:30:42: [2024-10-30 15:30:42] iter = 04190, loss = 3.1612
2024-10-30 15:30:46: [2024-10-30 15:30:46] iter = 04200, loss = 2.2765
2024-10-30 15:30:51: [2024-10-30 15:30:51] iter = 04210, loss = 3.1726
2024-10-30 15:30:55: [2024-10-30 15:30:55] iter = 04220, loss = 2.1300
2024-10-30 15:30:59: [2024-10-30 15:30:59] iter = 04230, loss = 2.1665
2024-10-30 15:31:05: [2024-10-30 15:31:05] iter = 04240, loss = 1.7977
2024-10-30 15:31:09: [2024-10-30 15:31:09] iter = 04250, loss = 2.5501
2024-10-30 15:31:13: [2024-10-30 15:31:13] iter = 04260, loss = 2.2293
2024-10-30 15:31:18: [2024-10-30 15:31:18] iter = 04270, loss = 2.0288
2024-10-30 15:31:23: [2024-10-30 15:31:23] iter = 04280, loss = 2.6181
2024-10-30 15:31:27: [2024-10-30 15:31:27] iter = 04290, loss = 2.3375
2024-10-30 15:31:32: [2024-10-30 15:31:32] iter = 04300, loss = 2.2838
2024-10-30 15:31:36: [2024-10-30 15:31:36] iter = 04310, loss = 2.8303
2024-10-30 15:31:41: [2024-10-30 15:31:41] iter = 04320, loss = 3.7332
2024-10-30 15:31:45: [2024-10-30 15:31:45] iter = 04330, loss = 2.8156
2024-10-30 15:31:49: [2024-10-30 15:31:49] iter = 04340, loss = 2.3351
2024-10-30 15:31:53: [2024-10-30 15:31:53] iter = 04350, loss = 2.0500
2024-10-30 15:31:58: [2024-10-30 15:31:58] iter = 04360, loss = 1.9489
2024-10-30 15:32:01: [2024-10-30 15:32:01] iter = 04370, loss = 3.8414
2024-10-30 15:32:06: [2024-10-30 15:32:06] iter = 04380, loss = 2.3677
2024-10-30 15:32:11: [2024-10-30 15:32:11] iter = 04390, loss = 2.0265
2024-10-30 15:32:14: [2024-10-30 15:32:14] iter = 04400, loss = 2.1354
2024-10-30 15:32:19: [2024-10-30 15:32:19] iter = 04410, loss = 1.9670
2024-10-30 15:32:24: [2024-10-30 15:32:24] iter = 04420, loss = 3.2579
2024-10-30 15:32:28: [2024-10-30 15:32:28] iter = 04430, loss = 2.2598
2024-10-30 15:32:32: [2024-10-30 15:32:32] iter = 04440, loss = 2.6620
2024-10-30 15:32:36: [2024-10-30 15:32:36] iter = 04450, loss = 2.8642
2024-10-30 15:32:41: [2024-10-30 15:32:41] iter = 04460, loss = 2.0827
2024-10-30 15:32:46: [2024-10-30 15:32:46] iter = 04470, loss = 1.6065
2024-10-30 15:32:52: [2024-10-30 15:32:52] iter = 04480, loss = 2.1746
2024-10-30 15:32:57: [2024-10-30 15:32:57] iter = 04490, loss = 2.6450
2024-10-30 15:33:01: [2024-10-30 15:33:01] iter = 04500, loss = 2.1172
2024-10-30 15:33:06: [2024-10-30 15:33:06] iter = 04510, loss = 1.9628
2024-10-30 15:33:11: [2024-10-30 15:33:11] iter = 04520, loss = 2.8171
2024-10-30 15:33:16: [2024-10-30 15:33:16] iter = 04530, loss = 1.9275
2024-10-30 15:33:20: [2024-10-30 15:33:20] iter = 04540, loss = 2.0807
2024-10-30 15:33:25: [2024-10-30 15:33:25] iter = 04550, loss = 2.5649
2024-10-30 15:33:29: [2024-10-30 15:33:29] iter = 04560, loss = 2.9557
2024-10-30 15:33:33: [2024-10-30 15:33:33] iter = 04570, loss = 3.3367
2024-10-30 15:33:37: [2024-10-30 15:33:37] iter = 04580, loss = 1.9590
2024-10-30 15:33:42: [2024-10-30 15:33:42] iter = 04590, loss = 2.2163
2024-10-30 15:33:46: [2024-10-30 15:33:46] iter = 04600, loss = 2.4342
2024-10-30 15:33:50: [2024-10-30 15:33:50] iter = 04610, loss = 2.3260
2024-10-30 15:33:53: [2024-10-30 15:33:53] iter = 04620, loss = 2.4507
2024-10-30 15:33:58: [2024-10-30 15:33:58] iter = 04630, loss = 2.2279
2024-10-30 15:34:02: [2024-10-30 15:34:02] iter = 04640, loss = 2.0997
2024-10-30 15:34:06: [2024-10-30 15:34:06] iter = 04650, loss = 2.6451
2024-10-30 15:34:10: [2024-10-30 15:34:10] iter = 04660, loss = 2.0442
2024-10-30 15:34:14: [2024-10-30 15:34:14] iter = 04670, loss = 1.9940
2024-10-30 15:34:18: [2024-10-30 15:34:18] iter = 04680, loss = 2.1723
2024-10-30 15:34:22: [2024-10-30 15:34:22] iter = 04690, loss = 2.4255
2024-10-30 15:34:26: [2024-10-30 15:34:26] iter = 04700, loss = 2.4641
2024-10-30 15:34:31: [2024-10-30 15:34:31] iter = 04710, loss = 2.0215
2024-10-30 15:34:35: [2024-10-30 15:34:35] iter = 04720, loss = 2.4144
2024-10-30 15:34:39: [2024-10-30 15:34:39] iter = 04730, loss = 2.4498
2024-10-30 15:34:45: [2024-10-30 15:34:45] iter = 04740, loss = 2.0899
2024-10-30 15:34:50: [2024-10-30 15:34:50] iter = 04750, loss = 2.2789
2024-10-30 15:34:54: [2024-10-30 15:34:54] iter = 04760, loss = 1.9138
2024-10-30 15:34:59: [2024-10-30 15:34:59] iter = 04770, loss = 2.7565
2024-10-30 15:35:03: [2024-10-30 15:35:03] iter = 04780, loss = 2.3285
2024-10-30 15:35:07: [2024-10-30 15:35:07] iter = 04790, loss = 3.8751
2024-10-30 15:35:12: [2024-10-30 15:35:12] iter = 04800, loss = 2.4481
2024-10-30 15:35:18: [2024-10-30 15:35:18] iter = 04810, loss = 2.0169
2024-10-30 15:35:22: [2024-10-30 15:35:22] iter = 04820, loss = 2.5811
2024-10-30 15:35:27: [2024-10-30 15:35:27] iter = 04830, loss = 2.2411
2024-10-30 15:35:30: [2024-10-30 15:35:30] iter = 04840, loss = 2.4771
2024-10-30 15:35:34: [2024-10-30 15:35:34] iter = 04850, loss = 2.6320
2024-10-30 15:35:39: [2024-10-30 15:35:39] iter = 04860, loss = 2.9679
2024-10-30 15:35:42: [2024-10-30 15:35:42] iter = 04870, loss = 2.1578
2024-10-30 15:35:46: [2024-10-30 15:35:46] iter = 04880, loss = 2.1375
2024-10-30 15:35:49: [2024-10-30 15:35:49] iter = 04890, loss = 2.4911
2024-10-30 15:35:53: [2024-10-30 15:35:53] iter = 04900, loss = 2.1981
2024-10-30 15:35:57: [2024-10-30 15:35:57] iter = 04910, loss = 2.0399
2024-10-30 15:36:02: [2024-10-30 15:36:02] iter = 04920, loss = 2.2615
2024-10-30 15:36:04: [2024-10-30 15:36:04] iter = 04930, loss = 2.5326
2024-10-30 15:36:09: [2024-10-30 15:36:09] iter = 04940, loss = 2.5768
2024-10-30 15:36:13: [2024-10-30 15:36:13] iter = 04950, loss = 2.2892
2024-10-30 15:36:17: [2024-10-30 15:36:17] iter = 04960, loss = 3.5795
2024-10-30 15:36:20: [2024-10-30 15:36:20] iter = 04970, loss = 2.6829
2024-10-30 15:36:24: [2024-10-30 15:36:24] iter = 04980, loss = 1.8017
2024-10-30 15:36:29: [2024-10-30 15:36:29] iter = 04990, loss = 3.2609
2024-10-30 15:36:35: [2024-10-30 15:36:35] iter = 05000, loss = 2.2085
2024-10-30 15:36:39: [2024-10-30 15:36:39] iter = 05010, loss = 2.3643
2024-10-30 15:36:42: [2024-10-30 15:36:42] iter = 05020, loss = 2.7550
2024-10-30 15:36:45: [2024-10-30 15:36:45] iter = 05030, loss = 2.6053
2024-10-30 15:36:49: [2024-10-30 15:36:49] iter = 05040, loss = 2.2619
2024-10-30 15:36:54: [2024-10-30 15:36:54] iter = 05050, loss = 2.2828
2024-10-30 15:36:57: [2024-10-30 15:36:57] iter = 05060, loss = 3.0777
2024-10-30 15:37:03: [2024-10-30 15:37:03] iter = 05070, loss = 2.0971
2024-10-30 15:37:06: [2024-10-30 15:37:06] iter = 05080, loss = 1.6270
2024-10-30 15:37:09: [2024-10-30 15:37:09] iter = 05090, loss = 2.2902
2024-10-30 15:37:12: [2024-10-30 15:37:12] iter = 05100, loss = 2.2318
2024-10-30 15:37:15: [2024-10-30 15:37:15] iter = 05110, loss = 1.9909
2024-10-30 15:37:20: [2024-10-30 15:37:20] iter = 05120, loss = 4.8242
2024-10-30 15:37:22: [2024-10-30 15:37:22] iter = 05130, loss = 3.8142
2024-10-30 15:37:26: [2024-10-30 15:37:26] iter = 05140, loss = 2.6161
2024-10-30 15:37:30: [2024-10-30 15:37:30] iter = 05150, loss = 2.2295
2024-10-30 15:37:34: [2024-10-30 15:37:34] iter = 05160, loss = 2.8456
2024-10-30 15:37:39: [2024-10-30 15:37:39] iter = 05170, loss = 2.5020
2024-10-30 15:37:43: [2024-10-30 15:37:43] iter = 05180, loss = 1.9171
2024-10-30 15:37:47: [2024-10-30 15:37:47] iter = 05190, loss = 2.9222
2024-10-30 15:37:50: [2024-10-30 15:37:50] iter = 05200, loss = 3.1518
2024-10-30 15:37:52: [2024-10-30 15:37:52] iter = 05210, loss = 1.8893
2024-10-30 15:37:54: [2024-10-30 15:37:54] iter = 05220, loss = 2.0835
2024-10-30 15:37:58: [2024-10-30 15:37:58] iter = 05230, loss = 2.1852
2024-10-30 15:38:02: [2024-10-30 15:38:02] iter = 05240, loss = 1.7489
2024-10-30 15:38:07: [2024-10-30 15:38:07] iter = 05250, loss = 2.4266
2024-10-30 15:38:11: [2024-10-30 15:38:11] iter = 05260, loss = 2.6299
2024-10-30 15:38:16: [2024-10-30 15:38:16] iter = 05270, loss = 2.0301
2024-10-30 15:38:20: [2024-10-30 15:38:20] iter = 05280, loss = 2.6328
2024-10-30 15:38:24: [2024-10-30 15:38:24] iter = 05290, loss = 2.2023
2024-10-30 15:38:29: [2024-10-30 15:38:29] iter = 05300, loss = 1.9949
2024-10-30 15:38:33: [2024-10-30 15:38:33] iter = 05310, loss = 1.9466
2024-10-30 15:38:36: [2024-10-30 15:38:36] iter = 05320, loss = 1.9854
2024-10-30 15:38:40: [2024-10-30 15:38:40] iter = 05330, loss = 1.9389
2024-10-30 15:38:43: [2024-10-30 15:38:43] iter = 05340, loss = 2.0538
2024-10-30 15:38:47: [2024-10-30 15:38:47] iter = 05350, loss = 2.0491
2024-10-30 15:38:51: [2024-10-30 15:38:51] iter = 05360, loss = 2.3951
2024-10-30 15:38:54: [2024-10-30 15:38:54] iter = 05370, loss = 2.1513
2024-10-30 15:38:56: [2024-10-30 15:38:56] iter = 05380, loss = 3.8165
2024-10-30 15:39:00: [2024-10-30 15:39:00] iter = 05390, loss = 1.9920
2024-10-30 15:39:03: [2024-10-30 15:39:03] iter = 05400, loss = 2.0698
2024-10-30 15:39:07: [2024-10-30 15:39:07] iter = 05410, loss = 2.0611
2024-10-30 15:39:11: [2024-10-30 15:39:11] iter = 05420, loss = 3.0948
2024-10-30 15:39:16: [2024-10-30 15:39:16] iter = 05430, loss = 2.3638
2024-10-30 15:39:20: [2024-10-30 15:39:20] iter = 05440, loss = 2.8342
2024-10-30 15:39:25: [2024-10-30 15:39:25] iter = 05450, loss = 5.3926
2024-10-30 15:39:29: [2024-10-30 15:39:29] iter = 05460, loss = 2.4906
2024-10-30 15:39:33: [2024-10-30 15:39:33] iter = 05470, loss = 2.5903
2024-10-30 15:39:37: [2024-10-30 15:39:37] iter = 05480, loss = 2.2738
2024-10-30 15:39:40: [2024-10-30 15:39:40] iter = 05490, loss = 2.2488
2024-10-30 15:39:44: [2024-10-30 15:39:44] iter = 05500, loss = 1.9632
2024-10-30 15:39:48: [2024-10-30 15:39:48] iter = 05510, loss = 2.2638
2024-10-30 15:39:52: [2024-10-30 15:39:52] iter = 05520, loss = 2.4952
2024-10-30 15:39:57: [2024-10-30 15:39:57] iter = 05530, loss = 1.9879
2024-10-30 15:40:01: [2024-10-30 15:40:01] iter = 05540, loss = 2.0883
2024-10-30 15:40:05: [2024-10-30 15:40:05] iter = 05550, loss = 2.2581
2024-10-30 15:40:10: [2024-10-30 15:40:09] iter = 05560, loss = 4.0474
2024-10-30 15:40:14: [2024-10-30 15:40:14] iter = 05570, loss = 3.5242
2024-10-30 15:40:18: [2024-10-30 15:40:18] iter = 05580, loss = 2.3770
2024-10-30 15:40:22: [2024-10-30 15:40:22] iter = 05590, loss = 2.0304
2024-10-30 15:40:26: [2024-10-30 15:40:26] iter = 05600, loss = 2.6429
2024-10-30 15:40:31: [2024-10-30 15:40:31] iter = 05610, loss = 1.9283
2024-10-30 15:40:34: [2024-10-30 15:40:34] iter = 05620, loss = 2.2930
2024-10-30 15:40:37: [2024-10-30 15:40:37] iter = 05630, loss = 2.1686
2024-10-30 15:40:41: [2024-10-30 15:40:41] iter = 05640, loss = 2.3037
2024-10-30 15:40:45: [2024-10-30 15:40:45] iter = 05650, loss = 1.8848
2024-10-30 15:40:49: [2024-10-30 15:40:49] iter = 05660, loss = 1.8192
2024-10-30 15:40:53: [2024-10-30 15:40:53] iter = 05670, loss = 2.1607
2024-10-30 15:40:58: [2024-10-30 15:40:58] iter = 05680, loss = 2.1322
2024-10-30 15:41:03: [2024-10-30 15:41:03] iter = 05690, loss = 2.4420
2024-10-30 15:41:06: [2024-10-30 15:41:06] iter = 05700, loss = 2.2503
2024-10-30 15:41:10: [2024-10-30 15:41:10] iter = 05710, loss = 2.2541
2024-10-30 15:41:13: [2024-10-30 15:41:13] iter = 05720, loss = 2.1067
2024-10-30 15:41:17: [2024-10-30 15:41:17] iter = 05730, loss = 2.2820
2024-10-30 15:41:21: [2024-10-30 15:41:21] iter = 05740, loss = 2.4605
2024-10-30 15:41:25: [2024-10-30 15:41:25] iter = 05750, loss = 2.3233
2024-10-30 15:41:29: [2024-10-30 15:41:29] iter = 05760, loss = 2.1312
2024-10-30 15:41:33: [2024-10-30 15:41:33] iter = 05770, loss = 2.4783
2024-10-30 15:41:37: [2024-10-30 15:41:37] iter = 05780, loss = 2.3031
2024-10-30 15:41:41: [2024-10-30 15:41:41] iter = 05790, loss = 2.1676
2024-10-30 15:41:46: [2024-10-30 15:41:46] iter = 05800, loss = 1.9843
2024-10-30 15:41:50: [2024-10-30 15:41:50] iter = 05810, loss = 1.9666
2024-10-30 15:41:54: [2024-10-30 15:41:54] iter = 05820, loss = 3.2858
2024-10-30 15:41:59: [2024-10-30 15:41:59] iter = 05830, loss = 3.0168
2024-10-30 15:42:03: [2024-10-30 15:42:03] iter = 05840, loss = 3.1150
2024-10-30 15:42:08: [2024-10-30 15:42:08] iter = 05850, loss = 1.6362
2024-10-30 15:42:13: [2024-10-30 15:42:13] iter = 05860, loss = 3.6811
2024-10-30 15:42:17: [2024-10-30 15:42:17] iter = 05870, loss = 2.4111
2024-10-30 15:42:21: [2024-10-30 15:42:21] iter = 05880, loss = 3.3607
2024-10-30 15:42:26: [2024-10-30 15:42:26] iter = 05890, loss = 3.1867
2024-10-30 15:42:31: [2024-10-30 15:42:31] iter = 05900, loss = 2.0413
2024-10-30 15:42:37: [2024-10-30 15:42:37] iter = 05910, loss = 2.5209
2024-10-30 15:42:42: [2024-10-30 15:42:42] iter = 05920, loss = 2.5384
2024-10-30 15:42:47: [2024-10-30 15:42:47] iter = 05930, loss = 1.8581
2024-10-30 15:42:52: [2024-10-30 15:42:52] iter = 05940, loss = 1.9067
2024-10-30 15:42:55: [2024-10-30 15:42:55] iter = 05950, loss = 2.8093
2024-10-30 15:43:00: [2024-10-30 15:43:00] iter = 05960, loss = 2.5093
2024-10-30 15:43:04: [2024-10-30 15:43:04] iter = 05970, loss = 2.2907
2024-10-30 15:43:09: [2024-10-30 15:43:09] iter = 05980, loss = 1.9189
2024-10-30 15:43:13: [2024-10-30 15:43:13] iter = 05990, loss = 2.4473
2024-10-30 15:43:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 15:43:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:43:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97354}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:53: Evaluate 5 random ConvNet, ACCmean = 0.6078 ACCstd = 0.0032
-------------------------
2024-10-30 15:45:53: Evaluate 5 random ConvNet, SENmean = 0.5874 SENstd = 0.0023
-------------------------
2024-10-30 15:45:53: Evaluate 5 random ConvNet, SPEmean = 0.9599 SPEstd = 0.0003
-------------------------
2024-10-30 15:45:53: Evaluate 5 random ConvNet, F!mean = 0.5801 F!std = 0.0024
-------------------------
2024-10-30 15:45:53: Evaluate 5 random ConvNet, mean = 0.6078 std = 0.0032
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:54: [2024-10-30 15:45:54] iter = 06000, loss = 2.5287
2024-10-30 15:45:58: [2024-10-30 15:45:58] iter = 06010, loss = 3.0881
2024-10-30 15:46:02: [2024-10-30 15:46:02] iter = 06020, loss = 2.0991
2024-10-30 15:46:06: [2024-10-30 15:46:06] iter = 06030, loss = 2.0962
2024-10-30 15:46:10: [2024-10-30 15:46:10] iter = 06040, loss = 1.9727
2024-10-30 15:46:15: [2024-10-30 15:46:15] iter = 06050, loss = 4.7924
2024-10-30 15:46:19: [2024-10-30 15:46:19] iter = 06060, loss = 2.8582
2024-10-30 15:46:24: [2024-10-30 15:46:24] iter = 06070, loss = 2.3473
2024-10-30 15:46:28: [2024-10-30 15:46:28] iter = 06080, loss = 3.0718
2024-10-30 15:46:32: [2024-10-30 15:46:32] iter = 06090, loss = 3.0549
2024-10-30 15:46:36: [2024-10-30 15:46:36] iter = 06100, loss = 2.6361
2024-10-30 15:46:40: [2024-10-30 15:46:40] iter = 06110, loss = 2.3293
2024-10-30 15:46:44: [2024-10-30 15:46:44] iter = 06120, loss = 2.6640
2024-10-30 15:46:49: [2024-10-30 15:46:49] iter = 06130, loss = 2.0307
2024-10-30 15:46:53: [2024-10-30 15:46:53] iter = 06140, loss = 1.9820
2024-10-30 15:46:57: [2024-10-30 15:46:57] iter = 06150, loss = 2.1542
2024-10-30 15:47:00: [2024-10-30 15:47:00] iter = 06160, loss = 3.2878
2024-10-30 15:47:05: [2024-10-30 15:47:05] iter = 06170, loss = 2.4631
2024-10-30 15:47:10: [2024-10-30 15:47:10] iter = 06180, loss = 2.3370
2024-10-30 15:47:14: [2024-10-30 15:47:14] iter = 06190, loss = 2.2936
2024-10-30 15:47:18: [2024-10-30 15:47:18] iter = 06200, loss = 3.2112
2024-10-30 15:47:22: [2024-10-30 15:47:22] iter = 06210, loss = 2.7923
2024-10-30 15:47:26: [2024-10-30 15:47:26] iter = 06220, loss = 2.7727
2024-10-30 15:47:29: [2024-10-30 15:47:29] iter = 06230, loss = 4.4854
2024-10-30 15:47:33: [2024-10-30 15:47:33] iter = 06240, loss = 2.0960
2024-10-30 15:47:38: [2024-10-30 15:47:38] iter = 06250, loss = 2.6206
2024-10-30 15:47:42: [2024-10-30 15:47:42] iter = 06260, loss = 2.3421
2024-10-30 15:47:46: [2024-10-30 15:47:46] iter = 06270, loss = 2.6214
2024-10-30 15:47:50: [2024-10-30 15:47:50] iter = 06280, loss = 2.1852
2024-10-30 15:47:54: [2024-10-30 15:47:54] iter = 06290, loss = 1.6735
2024-10-30 15:47:59: [2024-10-30 15:47:59] iter = 06300, loss = 2.1789
2024-10-30 15:48:04: [2024-10-30 15:48:04] iter = 06310, loss = 2.2368
2024-10-30 15:48:08: [2024-10-30 15:48:08] iter = 06320, loss = 2.0971
2024-10-30 15:48:12: [2024-10-30 15:48:12] iter = 06330, loss = 2.0032
2024-10-30 15:48:18: [2024-10-30 15:48:18] iter = 06340, loss = 2.3695
2024-10-30 15:48:22: [2024-10-30 15:48:22] iter = 06350, loss = 1.8417
2024-10-30 15:48:26: [2024-10-30 15:48:26] iter = 06360, loss = 2.3604
2024-10-30 15:48:31: [2024-10-30 15:48:31] iter = 06370, loss = 2.3572
2024-10-30 15:48:35: [2024-10-30 15:48:35] iter = 06380, loss = 2.0843
2024-10-30 15:48:39: [2024-10-30 15:48:39] iter = 06390, loss = 2.1347
2024-10-30 15:48:43: [2024-10-30 15:48:42] iter = 06400, loss = 2.8114
2024-10-30 15:48:48: [2024-10-30 15:48:48] iter = 06410, loss = 5.0163
2024-10-30 15:48:52: [2024-10-30 15:48:52] iter = 06420, loss = 2.5122
2024-10-30 15:48:57: [2024-10-30 15:48:57] iter = 06430, loss = 1.9785
2024-10-30 15:49:01: [2024-10-30 15:49:01] iter = 06440, loss = 3.1996
2024-10-30 15:49:05: [2024-10-30 15:49:05] iter = 06450, loss = 2.0810
2024-10-30 15:49:09: [2024-10-30 15:49:09] iter = 06460, loss = 2.3597
2024-10-30 15:49:14: [2024-10-30 15:49:14] iter = 06470, loss = 2.1009
2024-10-30 15:49:19: [2024-10-30 15:49:19] iter = 06480, loss = 1.9417
2024-10-30 15:49:24: [2024-10-30 15:49:24] iter = 06490, loss = 2.7774
2024-10-30 15:49:27: [2024-10-30 15:49:27] iter = 06500, loss = 3.8906
2024-10-30 15:49:30: [2024-10-30 15:49:30] iter = 06510, loss = 2.2440
2024-10-30 15:49:34: [2024-10-30 15:49:34] iter = 06520, loss = 1.7690
2024-10-30 15:49:38: [2024-10-30 15:49:38] iter = 06530, loss = 1.5956
2024-10-30 15:49:43: [2024-10-30 15:49:43] iter = 06540, loss = 2.1035
2024-10-30 15:49:47: [2024-10-30 15:49:47] iter = 06550, loss = 2.3207
2024-10-30 15:49:51: [2024-10-30 15:49:51] iter = 06560, loss = 3.0706
2024-10-30 15:49:55: [2024-10-30 15:49:55] iter = 06570, loss = 2.6208
2024-10-30 15:50:00: [2024-10-30 15:50:00] iter = 06580, loss = 2.7029
2024-10-30 15:50:05: [2024-10-30 15:50:04] iter = 06590, loss = 2.2648
2024-10-30 15:50:09: [2024-10-30 15:50:09] iter = 06600, loss = 2.7549
2024-10-30 15:50:14: [2024-10-30 15:50:14] iter = 06610, loss = 4.2491
2024-10-30 15:50:18: [2024-10-30 15:50:18] iter = 06620, loss = 1.9104
2024-10-30 15:50:21: [2024-10-30 15:50:21] iter = 06630, loss = 1.9911
2024-10-30 15:50:26: [2024-10-30 15:50:26] iter = 06640, loss = 3.9602
2024-10-30 15:50:30: [2024-10-30 15:50:30] iter = 06650, loss = 2.1985
2024-10-30 15:50:34: [2024-10-30 15:50:34] iter = 06660, loss = 2.4113
2024-10-30 15:50:39: [2024-10-30 15:50:39] iter = 06670, loss = 2.3571
2024-10-30 15:50:43: [2024-10-30 15:50:43] iter = 06680, loss = 2.4786
2024-10-30 15:50:48: [2024-10-30 15:50:48] iter = 06690, loss = 2.0995
2024-10-30 15:50:53: [2024-10-30 15:50:53] iter = 06700, loss = 2.3183
2024-10-30 15:50:58: [2024-10-30 15:50:58] iter = 06710, loss = 2.3656
2024-10-30 15:51:01: [2024-10-30 15:51:01] iter = 06720, loss = 2.1965
2024-10-30 15:51:05: [2024-10-30 15:51:05] iter = 06730, loss = 3.0737
2024-10-30 15:51:10: [2024-10-30 15:51:09] iter = 06740, loss = 2.0534
2024-10-30 15:51:14: [2024-10-30 15:51:14] iter = 06750, loss = 2.1899
2024-10-30 15:51:19: [2024-10-30 15:51:19] iter = 06760, loss = 2.9565
2024-10-30 15:51:23: [2024-10-30 15:51:23] iter = 06770, loss = 2.7622
2024-10-30 15:51:27: [2024-10-30 15:51:27] iter = 06780, loss = 3.1906
2024-10-30 15:51:31: [2024-10-30 15:51:31] iter = 06790, loss = 2.1335
2024-10-30 15:51:35: [2024-10-30 15:51:35] iter = 06800, loss = 2.1874
2024-10-30 15:51:40: [2024-10-30 15:51:40] iter = 06810, loss = 2.2545
2024-10-30 15:51:44: [2024-10-30 15:51:44] iter = 06820, loss = 2.2789
2024-10-30 15:51:49: [2024-10-30 15:51:49] iter = 06830, loss = 5.6627
2024-10-30 15:51:54: [2024-10-30 15:51:54] iter = 06840, loss = 2.0324
2024-10-30 15:51:57: [2024-10-30 15:51:57] iter = 06850, loss = 2.1288
2024-10-30 15:52:01: [2024-10-30 15:52:01] iter = 06860, loss = 2.1078
2024-10-30 15:52:05: [2024-10-30 15:52:05] iter = 06870, loss = 2.8192
2024-10-30 15:52:09: [2024-10-30 15:52:09] iter = 06880, loss = 2.0653
2024-10-30 15:52:13: [2024-10-30 15:52:13] iter = 06890, loss = 2.1480
2024-10-30 15:52:17: [2024-10-30 15:52:17] iter = 06900, loss = 2.3351
2024-10-30 15:52:21: [2024-10-30 15:52:21] iter = 06910, loss = 2.7589
2024-10-30 15:52:25: [2024-10-30 15:52:25] iter = 06920, loss = 2.0907
2024-10-30 15:52:29: [2024-10-30 15:52:29] iter = 06930, loss = 2.1407
2024-10-30 15:52:32: [2024-10-30 15:52:32] iter = 06940, loss = 1.9069
2024-10-30 15:52:36: [2024-10-30 15:52:36] iter = 06950, loss = 2.1053
2024-10-30 15:52:40: [2024-10-30 15:52:40] iter = 06960, loss = 1.9138
2024-10-30 15:52:45: [2024-10-30 15:52:45] iter = 06970, loss = 2.6212
2024-10-30 15:52:49: [2024-10-30 15:52:49] iter = 06980, loss = 2.1240
2024-10-30 15:52:52: [2024-10-30 15:52:52] iter = 06990, loss = 2.7199
2024-10-30 15:52:56: [2024-10-30 15:52:56] iter = 07000, loss = 2.1873
2024-10-30 15:52:59: [2024-10-30 15:52:59] iter = 07010, loss = 2.5271
2024-10-30 15:53:03: [2024-10-30 15:53:03] iter = 07020, loss = 2.3826
2024-10-30 15:53:07: [2024-10-30 15:53:07] iter = 07030, loss = 2.4552
2024-10-30 15:53:09: [2024-10-30 15:53:09] iter = 07040, loss = 2.3096
2024-10-30 15:53:13: [2024-10-30 15:53:13] iter = 07050, loss = 2.3310
2024-10-30 15:53:17: [2024-10-30 15:53:17] iter = 07060, loss = 2.2807
2024-10-30 15:53:22: [2024-10-30 15:53:22] iter = 07070, loss = 3.7340
2024-10-30 15:53:26: [2024-10-30 15:53:26] iter = 07080, loss = 5.3070
2024-10-30 15:53:30: [2024-10-30 15:53:30] iter = 07090, loss = 4.5124
2024-10-30 15:53:35: [2024-10-30 15:53:35] iter = 07100, loss = 2.8890
2024-10-30 15:53:39: [2024-10-30 15:53:39] iter = 07110, loss = 2.3542
2024-10-30 15:53:43: [2024-10-30 15:53:43] iter = 07120, loss = 2.5330
2024-10-30 15:53:47: [2024-10-30 15:53:47] iter = 07130, loss = 2.0698
2024-10-30 15:53:52: [2024-10-30 15:53:52] iter = 07140, loss = 2.0932
2024-10-30 15:53:56: [2024-10-30 15:53:56] iter = 07150, loss = 2.0575
2024-10-30 15:53:59: [2024-10-30 15:53:59] iter = 07160, loss = 2.1141
2024-10-30 15:54:02: [2024-10-30 15:54:02] iter = 07170, loss = 2.1385
2024-10-30 15:54:04: [2024-10-30 15:54:04] iter = 07180, loss = 2.3465
2024-10-30 15:54:09: [2024-10-30 15:54:09] iter = 07190, loss = 2.4062
2024-10-30 15:54:13: [2024-10-30 15:54:13] iter = 07200, loss = 2.1660
2024-10-30 15:54:17: [2024-10-30 15:54:17] iter = 07210, loss = 2.1804
2024-10-30 15:54:20: [2024-10-30 15:54:20] iter = 07220, loss = 2.1401
2024-10-30 15:54:24: [2024-10-30 15:54:24] iter = 07230, loss = 2.6194
2024-10-30 15:54:28: [2024-10-30 15:54:28] iter = 07240, loss = 2.3105
2024-10-30 15:54:31: [2024-10-30 15:54:31] iter = 07250, loss = 2.2678
2024-10-30 15:54:36: [2024-10-30 15:54:36] iter = 07260, loss = 2.0656
2024-10-30 15:54:40: [2024-10-30 15:54:40] iter = 07270, loss = 2.6239
2024-10-30 15:54:43: [2024-10-30 15:54:43] iter = 07280, loss = 2.0821
2024-10-30 15:54:47: [2024-10-30 15:54:47] iter = 07290, loss = 1.9341
2024-10-30 15:54:52: [2024-10-30 15:54:52] iter = 07300, loss = 1.8786
2024-10-30 15:54:55: [2024-10-30 15:54:55] iter = 07310, loss = 2.8842
2024-10-30 15:54:59: [2024-10-30 15:54:59] iter = 07320, loss = 2.6560
2024-10-30 15:55:03: [2024-10-30 15:55:03] iter = 07330, loss = 2.6074
2024-10-30 15:55:07: [2024-10-30 15:55:07] iter = 07340, loss = 2.1658
2024-10-30 15:55:11: [2024-10-30 15:55:11] iter = 07350, loss = 2.2685
2024-10-30 15:55:15: [2024-10-30 15:55:15] iter = 07360, loss = 2.7160
2024-10-30 15:55:19: [2024-10-30 15:55:19] iter = 07370, loss = 2.1038
2024-10-30 15:55:23: [2024-10-30 15:55:23] iter = 07380, loss = 2.8109
2024-10-30 15:55:27: [2024-10-30 15:55:27] iter = 07390, loss = 2.1980
2024-10-30 15:55:31: [2024-10-30 15:55:31] iter = 07400, loss = 2.0998
2024-10-30 15:55:36: [2024-10-30 15:55:36] iter = 07410, loss = 2.7953
2024-10-30 15:55:40: [2024-10-30 15:55:40] iter = 07420, loss = 1.8376
2024-10-30 15:55:45: [2024-10-30 15:55:45] iter = 07430, loss = 2.1632
2024-10-30 15:55:49: [2024-10-30 15:55:49] iter = 07440, loss = 2.1311
2024-10-30 15:55:52: [2024-10-30 15:55:52] iter = 07450, loss = 2.2214
2024-10-30 15:55:55: [2024-10-30 15:55:55] iter = 07460, loss = 2.6181
2024-10-30 15:56:00: [2024-10-30 15:56:00] iter = 07470, loss = 3.9001
2024-10-30 15:56:04: [2024-10-30 15:56:04] iter = 07480, loss = 2.1497
2024-10-30 15:56:08: [2024-10-30 15:56:08] iter = 07490, loss = 1.7693
2024-10-30 15:56:12: [2024-10-30 15:56:12] iter = 07500, loss = 2.4959
2024-10-30 15:56:16: [2024-10-30 15:56:16] iter = 07510, loss = 2.3793
2024-10-30 15:56:21: [2024-10-30 15:56:21] iter = 07520, loss = 2.0465
2024-10-30 15:56:24: [2024-10-30 15:56:24] iter = 07530, loss = 2.4075
2024-10-30 15:56:28: [2024-10-30 15:56:28] iter = 07540, loss = 1.9478
2024-10-30 15:56:31: [2024-10-30 15:56:31] iter = 07550, loss = 3.0963
2024-10-30 15:56:35: [2024-10-30 15:56:35] iter = 07560, loss = 1.9633
2024-10-30 15:56:39: [2024-10-30 15:56:39] iter = 07570, loss = 2.3078
2024-10-30 15:56:43: [2024-10-30 15:56:43] iter = 07580, loss = 2.0383
2024-10-30 15:56:46: [2024-10-30 15:56:46] iter = 07590, loss = 2.3013
2024-10-30 15:56:51: [2024-10-30 15:56:51] iter = 07600, loss = 1.7256
2024-10-30 15:56:54: [2024-10-30 15:56:54] iter = 07610, loss = 2.2996
2024-10-30 15:56:58: [2024-10-30 15:56:58] iter = 07620, loss = 2.0660
2024-10-30 15:57:02: [2024-10-30 15:57:02] iter = 07630, loss = 2.4245
2024-10-30 15:57:06: [2024-10-30 15:57:06] iter = 07640, loss = 2.3264
2024-10-30 15:57:10: [2024-10-30 15:57:10] iter = 07650, loss = 2.0307
2024-10-30 15:57:15: [2024-10-30 15:57:15] iter = 07660, loss = 1.9550
2024-10-30 15:57:19: [2024-10-30 15:57:19] iter = 07670, loss = 2.3028
2024-10-30 15:57:22: [2024-10-30 15:57:22] iter = 07680, loss = 2.1894
2024-10-30 15:57:26: [2024-10-30 15:57:26] iter = 07690, loss = 3.0589
2024-10-30 15:57:31: [2024-10-30 15:57:31] iter = 07700, loss = 1.6510
2024-10-30 15:57:35: [2024-10-30 15:57:35] iter = 07710, loss = 1.9939
2024-10-30 15:57:40: [2024-10-30 15:57:40] iter = 07720, loss = 2.3468
2024-10-30 15:57:44: [2024-10-30 15:57:44] iter = 07730, loss = 2.0650
2024-10-30 15:57:48: [2024-10-30 15:57:48] iter = 07740, loss = 2.1270
2024-10-30 15:57:53: [2024-10-30 15:57:53] iter = 07750, loss = 2.2934
2024-10-30 15:57:57: [2024-10-30 15:57:57] iter = 07760, loss = 2.0154
2024-10-30 15:58:01: [2024-10-30 15:58:01] iter = 07770, loss = 2.1509
2024-10-30 15:58:04: [2024-10-30 15:58:04] iter = 07780, loss = 2.9393
2024-10-30 15:58:08: [2024-10-30 15:58:08] iter = 07790, loss = 1.8596
2024-10-30 15:58:12: [2024-10-30 15:58:12] iter = 07800, loss = 2.1405
2024-10-30 15:58:16: [2024-10-30 15:58:16] iter = 07810, loss = 2.4680
2024-10-30 15:58:19: [2024-10-30 15:58:19] iter = 07820, loss = 3.0937
2024-10-30 15:58:22: [2024-10-30 15:58:22] iter = 07830, loss = 2.4721
2024-10-30 15:58:26: [2024-10-30 15:58:26] iter = 07840, loss = 2.6777
2024-10-30 15:58:31: [2024-10-30 15:58:31] iter = 07850, loss = 2.1790
2024-10-30 15:58:35: [2024-10-30 15:58:35] iter = 07860, loss = 2.0994
2024-10-30 15:58:39: [2024-10-30 15:58:39] iter = 07870, loss = 2.2265
2024-10-30 15:58:43: [2024-10-30 15:58:43] iter = 07880, loss = 2.2447
2024-10-30 15:58:46: [2024-10-30 15:58:46] iter = 07890, loss = 2.3047
2024-10-30 15:58:50: [2024-10-30 15:58:50] iter = 07900, loss = 2.1268
2024-10-30 15:58:53: [2024-10-30 15:58:53] iter = 07910, loss = 1.9822
2024-10-30 15:58:56: [2024-10-30 15:58:56] iter = 07920, loss = 3.0660
2024-10-30 15:59:00: [2024-10-30 15:59:00] iter = 07930, loss = 2.0173
2024-10-30 15:59:03: [2024-10-30 15:59:03] iter = 07940, loss = 2.3157
2024-10-30 15:59:08: [2024-10-30 15:59:08] iter = 07950, loss = 2.7894
2024-10-30 15:59:13: [2024-10-30 15:59:13] iter = 07960, loss = 2.3906
2024-10-30 15:59:18: [2024-10-30 15:59:18] iter = 07970, loss = 2.0300
2024-10-30 15:59:22: [2024-10-30 15:59:22] iter = 07980, loss = 2.3984
2024-10-30 15:59:26: [2024-10-30 15:59:26] iter = 07990, loss = 1.9384
2024-10-30 15:59:31: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 15:59:31: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:59:31: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 71124}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:02:11: Evaluate 5 random ConvNet, ACCmean = 0.6234 ACCstd = 0.0030
-------------------------
2024-10-30 16:02:11: Evaluate 5 random ConvNet, SENmean = 0.5996 SENstd = 0.0039
-------------------------
2024-10-30 16:02:11: Evaluate 5 random ConvNet, SPEmean = 0.9618 SPEstd = 0.0003
-------------------------
2024-10-30 16:02:11: Evaluate 5 random ConvNet, F!mean = 0.5911 F!std = 0.0041
-------------------------
2024-10-30 16:02:11: Evaluate 5 random ConvNet, mean = 0.6234 std = 0.0030
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:02:12: [2024-10-30 16:02:12] iter = 08000, loss = 1.9922
2024-10-30 16:02:15: [2024-10-30 16:02:15] iter = 08010, loss = 2.6499
2024-10-30 16:02:19: [2024-10-30 16:02:19] iter = 08020, loss = 2.0142
2024-10-30 16:02:23: [2024-10-30 16:02:23] iter = 08030, loss = 1.6731
2024-10-30 16:02:27: [2024-10-30 16:02:27] iter = 08040, loss = 2.1601
2024-10-30 16:02:31: [2024-10-30 16:02:31] iter = 08050, loss = 2.6733
2024-10-30 16:02:36: [2024-10-30 16:02:36] iter = 08060, loss = 1.8437
2024-10-30 16:02:41: [2024-10-30 16:02:41] iter = 08070, loss = 2.5592
2024-10-30 16:02:45: [2024-10-30 16:02:45] iter = 08080, loss = 2.1695
2024-10-30 16:02:48: [2024-10-30 16:02:48] iter = 08090, loss = 2.3592
2024-10-30 16:02:54: [2024-10-30 16:02:54] iter = 08100, loss = 1.9936
2024-10-30 16:02:58: [2024-10-30 16:02:58] iter = 08110, loss = 2.0450
2024-10-30 16:03:02: [2024-10-30 16:03:02] iter = 08120, loss = 2.0032
2024-10-30 16:03:06: [2024-10-30 16:03:06] iter = 08130, loss = 2.3431
2024-10-30 16:03:11: [2024-10-30 16:03:11] iter = 08140, loss = 1.7500
2024-10-30 16:03:14: [2024-10-30 16:03:14] iter = 08150, loss = 2.0181
2024-10-30 16:03:18: [2024-10-30 16:03:18] iter = 08160, loss = 2.2037
2024-10-30 16:03:21: [2024-10-30 16:03:21] iter = 08170, loss = 2.3975
2024-10-30 16:03:24: [2024-10-30 16:03:24] iter = 08180, loss = 2.3523
2024-10-30 16:03:28: [2024-10-30 16:03:28] iter = 08190, loss = 2.3966
2024-10-30 16:03:31: [2024-10-30 16:03:31] iter = 08200, loss = 2.0015
2024-10-30 16:03:35: [2024-10-30 16:03:35] iter = 08210, loss = 2.0490
2024-10-30 16:03:39: [2024-10-30 16:03:39] iter = 08220, loss = 2.2200
2024-10-30 16:03:43: [2024-10-30 16:03:43] iter = 08230, loss = 2.0340
2024-10-30 16:03:47: [2024-10-30 16:03:47] iter = 08240, loss = 1.9643
2024-10-30 16:03:50: [2024-10-30 16:03:50] iter = 08250, loss = 3.0896
2024-10-30 16:03:54: [2024-10-30 16:03:54] iter = 08260, loss = 2.3427
2024-10-30 16:03:58: [2024-10-30 16:03:58] iter = 08270, loss = 3.2768
2024-10-30 16:04:02: [2024-10-30 16:04:02] iter = 08280, loss = 2.5172
2024-10-30 16:04:07: [2024-10-30 16:04:07] iter = 08290, loss = 2.4730
2024-10-30 16:04:11: [2024-10-30 16:04:11] iter = 08300, loss = 2.5059
2024-10-30 16:04:14: [2024-10-30 16:04:14] iter = 08310, loss = 3.1005
2024-10-30 16:04:18: [2024-10-30 16:04:18] iter = 08320, loss = 2.0417
2024-10-30 16:04:22: [2024-10-30 16:04:22] iter = 08330, loss = 1.9652
2024-10-30 16:04:28: [2024-10-30 16:04:28] iter = 08340, loss = 1.7542
2024-10-30 16:04:32: [2024-10-30 16:04:32] iter = 08350, loss = 2.9056
2024-10-30 16:04:37: [2024-10-30 16:04:37] iter = 08360, loss = 2.1411
2024-10-30 16:04:41: [2024-10-30 16:04:41] iter = 08370, loss = 2.4503
2024-10-30 16:04:46: [2024-10-30 16:04:46] iter = 08380, loss = 1.9035
2024-10-30 16:04:50: [2024-10-30 16:04:50] iter = 08390, loss = 2.0828
2024-10-30 16:04:53: [2024-10-30 16:04:53] iter = 08400, loss = 1.8614
2024-10-30 16:04:57: [2024-10-30 16:04:57] iter = 08410, loss = 2.1016
2024-10-30 16:05:01: [2024-10-30 16:05:01] iter = 08420, loss = 2.0982
2024-10-30 16:05:05: [2024-10-30 16:05:05] iter = 08430, loss = 2.5647
2024-10-30 16:05:09: [2024-10-30 16:05:09] iter = 08440, loss = 2.1966
2024-10-30 16:05:14: [2024-10-30 16:05:14] iter = 08450, loss = 2.0631
2024-10-30 16:05:16: [2024-10-30 16:05:16] iter = 08460, loss = 2.5405
2024-10-30 16:05:21: [2024-10-30 16:05:21] iter = 08470, loss = 2.7265
2024-10-30 16:05:25: [2024-10-30 16:05:25] iter = 08480, loss = 2.2629
2024-10-30 16:05:29: [2024-10-30 16:05:29] iter = 08490, loss = 2.3741
2024-10-30 16:05:33: [2024-10-30 16:05:33] iter = 08500, loss = 2.3426
2024-10-30 16:05:37: [2024-10-30 16:05:37] iter = 08510, loss = 2.8719
2024-10-30 16:05:42: [2024-10-30 16:05:42] iter = 08520, loss = 2.2648
2024-10-30 16:05:46: [2024-10-30 16:05:46] iter = 08530, loss = 2.1149
2024-10-30 16:05:50: [2024-10-30 16:05:50] iter = 08540, loss = 2.2779
2024-10-30 16:05:54: [2024-10-30 16:05:54] iter = 08550, loss = 2.1197
2024-10-30 16:05:59: [2024-10-30 16:05:59] iter = 08560, loss = 2.6839
2024-10-30 16:06:02: [2024-10-30 16:06:01] iter = 08570, loss = 2.0087
2024-10-30 16:06:05: [2024-10-30 16:06:05] iter = 08580, loss = 1.7875
2024-10-30 16:06:09: [2024-10-30 16:06:09] iter = 08590, loss = 2.4004
2024-10-30 16:06:14: [2024-10-30 16:06:14] iter = 08600, loss = 1.7534
2024-10-30 16:06:19: [2024-10-30 16:06:19] iter = 08610, loss = 2.1694
2024-10-30 16:06:22: [2024-10-30 16:06:22] iter = 08620, loss = 2.3579
2024-10-30 16:06:27: [2024-10-30 16:06:27] iter = 08630, loss = 1.6770
2024-10-30 16:06:30: [2024-10-30 16:06:30] iter = 08640, loss = 2.0212
2024-10-30 16:06:34: [2024-10-30 16:06:34] iter = 08650, loss = 2.0272
2024-10-30 16:06:38: [2024-10-30 16:06:38] iter = 08660, loss = 2.4608
2024-10-30 16:06:42: [2024-10-30 16:06:42] iter = 08670, loss = 1.9897
2024-10-30 16:06:46: [2024-10-30 16:06:46] iter = 08680, loss = 2.1356
2024-10-30 16:06:50: [2024-10-30 16:06:50] iter = 08690, loss = 3.3247
2024-10-30 16:06:54: [2024-10-30 16:06:54] iter = 08700, loss = 2.2823
2024-10-30 16:06:57: [2024-10-30 16:06:57] iter = 08710, loss = 3.0074
2024-10-30 16:07:00: [2024-10-30 16:07:00] iter = 08720, loss = 3.2828
2024-10-30 16:07:04: [2024-10-30 16:07:04] iter = 08730, loss = 2.0735
2024-10-30 16:07:07: [2024-10-30 16:07:07] iter = 08740, loss = 4.6403
2024-10-30 16:07:10: [2024-10-30 16:07:10] iter = 08750, loss = 2.1182
2024-10-30 16:07:14: [2024-10-30 16:07:14] iter = 08760, loss = 2.2619
2024-10-30 16:07:19: [2024-10-30 16:07:19] iter = 08770, loss = 2.2999
2024-10-30 16:07:24: [2024-10-30 16:07:24] iter = 08780, loss = 3.8410
2024-10-30 16:07:28: [2024-10-30 16:07:28] iter = 08790, loss = 1.7956
2024-10-30 16:07:32: [2024-10-30 16:07:32] iter = 08800, loss = 2.2573
2024-10-30 16:07:36: [2024-10-30 16:07:36] iter = 08810, loss = 2.4534
2024-10-30 16:07:40: [2024-10-30 16:07:40] iter = 08820, loss = 2.1463
2024-10-30 16:07:44: [2024-10-30 16:07:44] iter = 08830, loss = 2.3035
2024-10-30 16:07:47: [2024-10-30 16:07:47] iter = 08840, loss = 1.9922
2024-10-30 16:07:51: [2024-10-30 16:07:51] iter = 08850, loss = 2.9575
2024-10-30 16:07:55: [2024-10-30 16:07:55] iter = 08860, loss = 2.1504
2024-10-30 16:07:59: [2024-10-30 16:07:59] iter = 08870, loss = 1.9489
2024-10-30 16:08:04: [2024-10-30 16:08:04] iter = 08880, loss = 1.9312
2024-10-30 16:08:08: [2024-10-30 16:08:08] iter = 08890, loss = 2.4872
2024-10-30 16:08:13: [2024-10-30 16:08:13] iter = 08900, loss = 2.3384
2024-10-30 16:08:17: [2024-10-30 16:08:17] iter = 08910, loss = 2.1503
2024-10-30 16:08:22: [2024-10-30 16:08:22] iter = 08920, loss = 2.1278
2024-10-30 16:08:26: [2024-10-30 16:08:26] iter = 08930, loss = 3.1881
2024-10-30 16:08:31: [2024-10-30 16:08:31] iter = 08940, loss = 2.0666
2024-10-30 16:08:34: [2024-10-30 16:08:34] iter = 08950, loss = 1.9279
2024-10-30 16:08:39: [2024-10-30 16:08:39] iter = 08960, loss = 1.7803
2024-10-30 16:08:43: [2024-10-30 16:08:43] iter = 08970, loss = 2.1040
2024-10-30 16:08:47: [2024-10-30 16:08:47] iter = 08980, loss = 1.9088
2024-10-30 16:08:51: [2024-10-30 16:08:51] iter = 08990, loss = 2.1186
2024-10-30 16:08:54: [2024-10-30 16:08:54] iter = 09000, loss = 1.8734
2024-10-30 16:08:59: [2024-10-30 16:08:59] iter = 09010, loss = 1.9243
2024-10-30 16:09:02: [2024-10-30 16:09:02] iter = 09020, loss = 1.9679
2024-10-30 16:09:07: [2024-10-30 16:09:07] iter = 09030, loss = 2.4958
2024-10-30 16:09:12: [2024-10-30 16:09:12] iter = 09040, loss = 1.9082
2024-10-30 16:09:17: [2024-10-30 16:09:17] iter = 09050, loss = 2.9242
2024-10-30 16:09:21: [2024-10-30 16:09:21] iter = 09060, loss = 1.9840
2024-10-30 16:09:25: [2024-10-30 16:09:25] iter = 09070, loss = 2.6822
2024-10-30 16:09:29: [2024-10-30 16:09:29] iter = 09080, loss = 2.1750
2024-10-30 16:09:32: [2024-10-30 16:09:32] iter = 09090, loss = 2.2005
2024-10-30 16:09:36: [2024-10-30 16:09:36] iter = 09100, loss = 2.0753
2024-10-30 16:09:40: [2024-10-30 16:09:40] iter = 09110, loss = 2.2821
2024-10-30 16:09:44: [2024-10-30 16:09:44] iter = 09120, loss = 2.1398
2024-10-30 16:09:49: [2024-10-30 16:09:49] iter = 09130, loss = 1.8956
2024-10-30 16:09:53: [2024-10-30 16:09:53] iter = 09140, loss = 2.1159
2024-10-30 16:09:57: [2024-10-30 16:09:57] iter = 09150, loss = 2.1158
2024-10-30 16:10:02: [2024-10-30 16:10:02] iter = 09160, loss = 2.7420
2024-10-30 16:10:05: [2024-10-30 16:10:05] iter = 09170, loss = 2.3150
2024-10-30 16:10:09: [2024-10-30 16:10:09] iter = 09180, loss = 2.6729
2024-10-30 16:10:13: [2024-10-30 16:10:13] iter = 09190, loss = 2.1352
2024-10-30 16:10:18: [2024-10-30 16:10:18] iter = 09200, loss = 2.1895
2024-10-30 16:10:22: [2024-10-30 16:10:22] iter = 09210, loss = 1.7999
2024-10-30 16:10:26: [2024-10-30 16:10:26] iter = 09220, loss = 2.1066
2024-10-30 16:10:30: [2024-10-30 16:10:30] iter = 09230, loss = 1.6922
2024-10-30 16:10:34: [2024-10-30 16:10:34] iter = 09240, loss = 1.7197
2024-10-30 16:10:38: [2024-10-30 16:10:37] iter = 09250, loss = 2.2933
2024-10-30 16:10:41: [2024-10-30 16:10:41] iter = 09260, loss = 2.1981
2024-10-30 16:10:46: [2024-10-30 16:10:46] iter = 09270, loss = 1.8706
2024-10-30 16:10:51: [2024-10-30 16:10:51] iter = 09280, loss = 2.0590
2024-10-30 16:10:55: [2024-10-30 16:10:55] iter = 09290, loss = 2.8440
2024-10-30 16:10:59: [2024-10-30 16:10:59] iter = 09300, loss = 2.4777
2024-10-30 16:11:03: [2024-10-30 16:11:03] iter = 09310, loss = 1.8170
2024-10-30 16:11:07: [2024-10-30 16:11:07] iter = 09320, loss = 2.0408
2024-10-30 16:11:10: [2024-10-30 16:11:10] iter = 09330, loss = 2.3291
2024-10-30 16:11:14: [2024-10-30 16:11:14] iter = 09340, loss = 2.1398
2024-10-30 16:11:17: [2024-10-30 16:11:17] iter = 09350, loss = 2.6897
2024-10-30 16:11:21: [2024-10-30 16:11:21] iter = 09360, loss = 2.2370
2024-10-30 16:11:26: [2024-10-30 16:11:26] iter = 09370, loss = 2.6221
2024-10-30 16:11:30: [2024-10-30 16:11:30] iter = 09380, loss = 2.1362
2024-10-30 16:11:35: [2024-10-30 16:11:35] iter = 09390, loss = 2.0371
2024-10-30 16:11:40: [2024-10-30 16:11:39] iter = 09400, loss = 2.1193
2024-10-30 16:11:44: [2024-10-30 16:11:44] iter = 09410, loss = 1.8729
2024-10-30 16:11:47: [2024-10-30 16:11:47] iter = 09420, loss = 2.6324
2024-10-30 16:11:51: [2024-10-30 16:11:51] iter = 09430, loss = 2.0183
2024-10-30 16:11:56: [2024-10-30 16:11:56] iter = 09440, loss = 1.7954
2024-10-30 16:11:59: [2024-10-30 16:11:59] iter = 09450, loss = 1.9628
2024-10-30 16:12:03: [2024-10-30 16:12:03] iter = 09460, loss = 2.6444
2024-10-30 16:12:05: [2024-10-30 16:12:05] iter = 09470, loss = 1.7879
2024-10-30 16:12:09: [2024-10-30 16:12:09] iter = 09480, loss = 2.4397
2024-10-30 16:12:14: [2024-10-30 16:12:14] iter = 09490, loss = 1.7177
2024-10-30 16:12:18: [2024-10-30 16:12:18] iter = 09500, loss = 2.9991
2024-10-30 16:12:21: [2024-10-30 16:12:21] iter = 09510, loss = 3.7413
2024-10-30 16:12:26: [2024-10-30 16:12:26] iter = 09520, loss = 2.1593
2024-10-30 16:12:30: [2024-10-30 16:12:30] iter = 09530, loss = 1.8924
2024-10-30 16:12:35: [2024-10-30 16:12:35] iter = 09540, loss = 2.1929
2024-10-30 16:12:40: [2024-10-30 16:12:40] iter = 09550, loss = 4.3361
2024-10-30 16:12:44: [2024-10-30 16:12:44] iter = 09560, loss = 2.3325
2024-10-30 16:12:49: [2024-10-30 16:12:49] iter = 09570, loss = 2.1850
2024-10-30 16:12:52: [2024-10-30 16:12:52] iter = 09580, loss = 2.6396
2024-10-30 16:12:55: [2024-10-30 16:12:55] iter = 09590, loss = 5.2105
2024-10-30 16:13:00: [2024-10-30 16:13:00] iter = 09600, loss = 2.5144
2024-10-30 16:13:03: [2024-10-30 16:13:03] iter = 09610, loss = 2.1720
2024-10-30 16:13:07: [2024-10-30 16:13:07] iter = 09620, loss = 1.9401
2024-10-30 16:13:10: [2024-10-30 16:13:10] iter = 09630, loss = 1.7990
2024-10-30 16:13:14: [2024-10-30 16:13:14] iter = 09640, loss = 2.8807
2024-10-30 16:13:17: [2024-10-30 16:13:17] iter = 09650, loss = 2.6157
2024-10-30 16:13:21: [2024-10-30 16:13:21] iter = 09660, loss = 2.0264
2024-10-30 16:13:26: [2024-10-30 16:13:26] iter = 09670, loss = 2.1563
2024-10-30 16:13:31: [2024-10-30 16:13:31] iter = 09680, loss = 2.2059
2024-10-30 16:13:34: [2024-10-30 16:13:34] iter = 09690, loss = 2.0091
2024-10-30 16:13:40: [2024-10-30 16:13:40] iter = 09700, loss = 3.0760
2024-10-30 16:13:44: [2024-10-30 16:13:44] iter = 09710, loss = 2.0219
2024-10-30 16:13:49: [2024-10-30 16:13:49] iter = 09720, loss = 4.9449
2024-10-30 16:13:53: [2024-10-30 16:13:53] iter = 09730, loss = 1.9507
2024-10-30 16:13:56: [2024-10-30 16:13:56] iter = 09740, loss = 2.3815
2024-10-30 16:13:59: [2024-10-30 16:13:59] iter = 09750, loss = 2.9479
2024-10-30 16:14:03: [2024-10-30 16:14:03] iter = 09760, loss = 1.9004
2024-10-30 16:14:07: [2024-10-30 16:14:07] iter = 09770, loss = 2.2871
2024-10-30 16:14:10: [2024-10-30 16:14:10] iter = 09780, loss = 4.1985
2024-10-30 16:14:14: [2024-10-30 16:14:14] iter = 09790, loss = 2.9337
2024-10-30 16:14:18: [2024-10-30 16:14:18] iter = 09800, loss = 2.0306
2024-10-30 16:14:22: [2024-10-30 16:14:22] iter = 09810, loss = 2.8423
2024-10-30 16:14:26: [2024-10-30 16:14:26] iter = 09820, loss = 2.1750
2024-10-30 16:14:31: [2024-10-30 16:14:31] iter = 09830, loss = 1.9788
2024-10-30 16:14:35: [2024-10-30 16:14:35] iter = 09840, loss = 1.6504
2024-10-30 16:14:39: [2024-10-30 16:14:39] iter = 09850, loss = 2.0695
2024-10-30 16:14:43: [2024-10-30 16:14:43] iter = 09860, loss = 2.1820
2024-10-30 16:14:48: [2024-10-30 16:14:48] iter = 09870, loss = 1.9878
2024-10-30 16:14:53: [2024-10-30 16:14:53] iter = 09880, loss = 2.1891
2024-10-30 16:14:57: [2024-10-30 16:14:57] iter = 09890, loss = 1.9009
2024-10-30 16:15:02: [2024-10-30 16:15:02] iter = 09900, loss = 2.9744
2024-10-30 16:15:07: [2024-10-30 16:15:07] iter = 09910, loss = 2.3217
2024-10-30 16:15:13: [2024-10-30 16:15:13] iter = 09920, loss = 2.1823
2024-10-30 16:15:18: [2024-10-30 16:15:18] iter = 09930, loss = 1.8543
2024-10-30 16:15:23: [2024-10-30 16:15:23] iter = 09940, loss = 2.5188
2024-10-30 16:15:28: [2024-10-30 16:15:28] iter = 09950, loss = 2.0767
2024-10-30 16:15:32: [2024-10-30 16:15:32] iter = 09960, loss = 2.1771
2024-10-30 16:15:37: [2024-10-30 16:15:37] iter = 09970, loss = 3.1231
2024-10-30 16:15:41: [2024-10-30 16:15:41] iter = 09980, loss = 2.2111
2024-10-30 16:15:45: [2024-10-30 16:15:45] iter = 09990, loss = 2.2407
2024-10-30 16:15:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 16:15:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:15:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49911}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:18:25: Evaluate 5 random ConvNet, ACCmean = 0.6147 ACCstd = 0.0055
-------------------------
2024-10-30 16:18:25: Evaluate 5 random ConvNet, SENmean = 0.5920 SENstd = 0.0033
-------------------------
2024-10-30 16:18:25: Evaluate 5 random ConvNet, SPEmean = 0.9606 SPEstd = 0.0005
-------------------------
2024-10-30 16:18:25: Evaluate 5 random ConvNet, F!mean = 0.5874 F!std = 0.0037
-------------------------
2024-10-30 16:18:25: Evaluate 5 random ConvNet, mean = 0.6147 std = 0.0055
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:18:25: [2024-10-30 16:18:25] iter = 10000, loss = 2.2293
2024-10-30 16:18:28: [2024-10-30 16:18:28] iter = 10010, loss = 2.5848
2024-10-30 16:18:31: [2024-10-30 16:18:31] iter = 10020, loss = 2.1299
2024-10-30 16:18:35: [2024-10-30 16:18:35] iter = 10030, loss = 2.3284
2024-10-30 16:18:38: [2024-10-30 16:18:38] iter = 10040, loss = 2.3145
2024-10-30 16:18:41: [2024-10-30 16:18:41] iter = 10050, loss = 2.1774
2024-10-30 16:18:44: [2024-10-30 16:18:44] iter = 10060, loss = 2.3896
2024-10-30 16:18:48: [2024-10-30 16:18:48] iter = 10070, loss = 2.2925
2024-10-30 16:18:51: [2024-10-30 16:18:51] iter = 10080, loss = 2.0583
2024-10-30 16:18:54: [2024-10-30 16:18:54] iter = 10090, loss = 1.8154
2024-10-30 16:18:58: [2024-10-30 16:18:58] iter = 10100, loss = 1.8246
2024-10-30 16:19:02: [2024-10-30 16:19:02] iter = 10110, loss = 2.2720
2024-10-30 16:19:06: [2024-10-30 16:19:06] iter = 10120, loss = 2.0927
2024-10-30 16:19:10: [2024-10-30 16:19:10] iter = 10130, loss = 2.3975
2024-10-30 16:19:14: [2024-10-30 16:19:14] iter = 10140, loss = 1.9804
2024-10-30 16:19:18: [2024-10-30 16:19:18] iter = 10150, loss = 2.9145
2024-10-30 16:19:23: [2024-10-30 16:19:23] iter = 10160, loss = 2.3507
2024-10-30 16:19:26: [2024-10-30 16:19:26] iter = 10170, loss = 2.3020
2024-10-30 16:19:31: [2024-10-30 16:19:31] iter = 10180, loss = 2.1082
2024-10-30 16:19:35: [2024-10-30 16:19:35] iter = 10190, loss = 2.3736
2024-10-30 16:19:39: [2024-10-30 16:19:39] iter = 10200, loss = 2.1731
2024-10-30 16:19:43: [2024-10-30 16:19:43] iter = 10210, loss = 1.9857
2024-10-30 16:19:47: [2024-10-30 16:19:47] iter = 10220, loss = 1.9899
2024-10-30 16:19:50: [2024-10-30 16:19:50] iter = 10230, loss = 2.0017
2024-10-30 16:19:54: [2024-10-30 16:19:54] iter = 10240, loss = 1.8958
2024-10-30 16:19:58: [2024-10-30 16:19:58] iter = 10250, loss = 2.3268
2024-10-30 16:20:02: [2024-10-30 16:20:02] iter = 10260, loss = 1.9880
2024-10-30 16:20:06: [2024-10-30 16:20:06] iter = 10270, loss = 1.7529
2024-10-30 16:20:09: [2024-10-30 16:20:09] iter = 10280, loss = 2.0078
2024-10-30 16:20:13: [2024-10-30 16:20:13] iter = 10290, loss = 2.2938
2024-10-30 16:20:17: [2024-10-30 16:20:17] iter = 10300, loss = 3.1859
2024-10-30 16:20:21: [2024-10-30 16:20:21] iter = 10310, loss = 2.6752
2024-10-30 16:20:26: [2024-10-30 16:20:26] iter = 10320, loss = 2.1612
2024-10-30 16:20:31: [2024-10-30 16:20:31] iter = 10330, loss = 1.7602
2024-10-30 16:20:35: [2024-10-30 16:20:35] iter = 10340, loss = 2.2760
2024-10-30 16:20:40: [2024-10-30 16:20:40] iter = 10350, loss = 2.4919
2024-10-30 16:20:44: [2024-10-30 16:20:44] iter = 10360, loss = 2.1581
2024-10-30 16:20:47: [2024-10-30 16:20:47] iter = 10370, loss = 2.2360
2024-10-30 16:20:51: [2024-10-30 16:20:51] iter = 10380, loss = 2.1030
2024-10-30 16:20:54: [2024-10-30 16:20:54] iter = 10390, loss = 2.2639
2024-10-30 16:21:00: [2024-10-30 16:21:00] iter = 10400, loss = 1.6652
2024-10-30 16:21:04: [2024-10-30 16:21:04] iter = 10410, loss = 2.8478
2024-10-30 16:21:08: [2024-10-30 16:21:08] iter = 10420, loss = 2.2861
2024-10-30 16:21:13: [2024-10-30 16:21:13] iter = 10430, loss = 2.3023
2024-10-30 16:21:17: [2024-10-30 16:21:17] iter = 10440, loss = 2.3288
2024-10-30 16:21:20: [2024-10-30 16:21:20] iter = 10450, loss = 2.2281
2024-10-30 16:21:24: [2024-10-30 16:21:24] iter = 10460, loss = 1.9364
2024-10-30 16:21:28: [2024-10-30 16:21:28] iter = 10470, loss = 1.8099
2024-10-30 16:21:32: [2024-10-30 16:21:32] iter = 10480, loss = 1.8238
2024-10-30 16:21:36: [2024-10-30 16:21:36] iter = 10490, loss = 2.3388
2024-10-30 16:21:41: [2024-10-30 16:21:41] iter = 10500, loss = 7.3086
2024-10-30 16:21:44: [2024-10-30 16:21:44] iter = 10510, loss = 2.5491
2024-10-30 16:21:48: [2024-10-30 16:21:48] iter = 10520, loss = 3.0370
2024-10-30 16:21:53: [2024-10-30 16:21:53] iter = 10530, loss = 1.8534
2024-10-30 16:21:56: [2024-10-30 16:21:56] iter = 10540, loss = 2.2292
2024-10-30 16:22:00: [2024-10-30 16:22:00] iter = 10550, loss = 2.5645
2024-10-30 16:22:05: [2024-10-30 16:22:05] iter = 10560, loss = 2.1502
2024-10-30 16:22:09: [2024-10-30 16:22:09] iter = 10570, loss = 2.1963
2024-10-30 16:22:14: [2024-10-30 16:22:14] iter = 10580, loss = 2.6616
2024-10-30 16:22:19: [2024-10-30 16:22:19] iter = 10590, loss = 1.8531
2024-10-30 16:22:22: [2024-10-30 16:22:22] iter = 10600, loss = 2.0869
2024-10-30 16:22:25: [2024-10-30 16:22:25] iter = 10610, loss = 2.2671
2024-10-30 16:22:29: [2024-10-30 16:22:29] iter = 10620, loss = 2.5475
2024-10-30 16:22:32: [2024-10-30 16:22:32] iter = 10630, loss = 1.8847
2024-10-30 16:22:36: [2024-10-30 16:22:36] iter = 10640, loss = 2.2142
2024-10-30 16:22:40: [2024-10-30 16:22:40] iter = 10650, loss = 2.8041
2024-10-30 16:22:43: [2024-10-30 16:22:43] iter = 10660, loss = 2.1965
2024-10-30 16:22:48: [2024-10-30 16:22:48] iter = 10670, loss = 2.5026
2024-10-30 16:22:51: [2024-10-30 16:22:51] iter = 10680, loss = 1.8784
2024-10-30 16:22:56: [2024-10-30 16:22:56] iter = 10690, loss = 1.8734
2024-10-30 16:23:00: [2024-10-30 16:23:00] iter = 10700, loss = 2.7749
2024-10-30 16:23:03: [2024-10-30 16:23:03] iter = 10710, loss = 2.2783
2024-10-30 16:23:08: [2024-10-30 16:23:08] iter = 10720, loss = 2.1337
2024-10-30 16:23:12: [2024-10-30 16:23:12] iter = 10730, loss = 1.9302
2024-10-30 16:23:15: [2024-10-30 16:23:15] iter = 10740, loss = 2.2744
2024-10-30 16:23:19: [2024-10-30 16:23:19] iter = 10750, loss = 1.9202
2024-10-30 16:23:23: [2024-10-30 16:23:23] iter = 10760, loss = 2.1986
2024-10-30 16:23:27: [2024-10-30 16:23:27] iter = 10770, loss = 2.4200
2024-10-30 16:23:31: [2024-10-30 16:23:31] iter = 10780, loss = 1.9661
2024-10-30 16:23:35: [2024-10-30 16:23:35] iter = 10790, loss = 2.0854
2024-10-30 16:23:38: [2024-10-30 16:23:38] iter = 10800, loss = 2.3665
2024-10-30 16:23:41: [2024-10-30 16:23:41] iter = 10810, loss = 1.7477
2024-10-30 16:23:45: [2024-10-30 16:23:45] iter = 10820, loss = 1.9462
2024-10-30 16:23:49: [2024-10-30 16:23:49] iter = 10830, loss = 2.0422
2024-10-30 16:23:52: [2024-10-30 16:23:52] iter = 10840, loss = 2.0713
2024-10-30 16:23:57: [2024-10-30 16:23:57] iter = 10850, loss = 2.2410
2024-10-30 16:24:00: [2024-10-30 16:24:00] iter = 10860, loss = 2.1509
2024-10-30 16:24:04: [2024-10-30 16:24:04] iter = 10870, loss = 2.3232
2024-10-30 16:24:07: [2024-10-30 16:24:07] iter = 10880, loss = 2.4230
2024-10-30 16:24:10: [2024-10-30 16:24:10] iter = 10890, loss = 1.8670
2024-10-30 16:24:13: [2024-10-30 16:24:13] iter = 10900, loss = 2.3991
2024-10-30 16:24:17: [2024-10-30 16:24:17] iter = 10910, loss = 2.0285
2024-10-30 16:24:20: [2024-10-30 16:24:20] iter = 10920, loss = 2.1694
2024-10-30 16:24:23: [2024-10-30 16:24:23] iter = 10930, loss = 1.9803
2024-10-30 16:24:27: [2024-10-30 16:24:27] iter = 10940, loss = 1.9285
2024-10-30 16:24:31: [2024-10-30 16:24:31] iter = 10950, loss = 3.3858
2024-10-30 16:24:34: [2024-10-30 16:24:34] iter = 10960, loss = 2.0045
2024-10-30 16:24:38: [2024-10-30 16:24:38] iter = 10970, loss = 2.0945
2024-10-30 16:24:41: [2024-10-30 16:24:41] iter = 10980, loss = 2.4090
2024-10-30 16:24:45: [2024-10-30 16:24:45] iter = 10990, loss = 2.4750
2024-10-30 16:24:48: [2024-10-30 16:24:48] iter = 11000, loss = 1.8531
2024-10-30 16:24:52: [2024-10-30 16:24:52] iter = 11010, loss = 3.0136
2024-10-30 16:24:55: [2024-10-30 16:24:55] iter = 11020, loss = 2.6517
2024-10-30 16:24:59: [2024-10-30 16:24:59] iter = 11030, loss = 2.0347
2024-10-30 16:25:03: [2024-10-30 16:25:03] iter = 11040, loss = 2.0679
2024-10-30 16:25:07: [2024-10-30 16:25:07] iter = 11050, loss = 3.3793
2024-10-30 16:25:11: [2024-10-30 16:25:11] iter = 11060, loss = 1.9649
2024-10-30 16:25:15: [2024-10-30 16:25:15] iter = 11070, loss = 3.8825
2024-10-30 16:25:18: [2024-10-30 16:25:18] iter = 11080, loss = 1.8130
2024-10-30 16:25:21: [2024-10-30 16:25:21] iter = 11090, loss = 2.0273
2024-10-30 16:25:25: [2024-10-30 16:25:25] iter = 11100, loss = 1.7825
2024-10-30 16:25:28: [2024-10-30 16:25:28] iter = 11110, loss = 2.7199
2024-10-30 16:25:33: [2024-10-30 16:25:33] iter = 11120, loss = 1.9220
2024-10-30 16:25:36: [2024-10-30 16:25:36] iter = 11130, loss = 2.0264
2024-10-30 16:25:38: [2024-10-30 16:25:38] iter = 11140, loss = 1.9764
2024-10-30 16:25:40: [2024-10-30 16:25:40] iter = 11150, loss = 6.1693
2024-10-30 16:25:42: [2024-10-30 16:25:42] iter = 11160, loss = 2.5361
2024-10-30 16:25:45: [2024-10-30 16:25:45] iter = 11170, loss = 2.0972
2024-10-30 16:25:49: [2024-10-30 16:25:49] iter = 11180, loss = 2.2555
2024-10-30 16:25:51: [2024-10-30 16:25:51] iter = 11190, loss = 2.2845
2024-10-30 16:25:55: [2024-10-30 16:25:55] iter = 11200, loss = 2.4057
2024-10-30 16:25:59: [2024-10-30 16:25:59] iter = 11210, loss = 2.0304
2024-10-30 16:26:02: [2024-10-30 16:26:02] iter = 11220, loss = 2.3583
2024-10-30 16:26:05: [2024-10-30 16:26:05] iter = 11230, loss = 2.0932
2024-10-30 16:26:08: [2024-10-30 16:26:08] iter = 11240, loss = 3.8336
2024-10-30 16:26:11: [2024-10-30 16:26:11] iter = 11250, loss = 2.0507
2024-10-30 16:26:14: [2024-10-30 16:26:14] iter = 11260, loss = 2.2278
2024-10-30 16:26:19: [2024-10-30 16:26:19] iter = 11270, loss = 1.8306
2024-10-30 16:26:22: [2024-10-30 16:26:22] iter = 11280, loss = 1.9748
2024-10-30 16:26:26: [2024-10-30 16:26:26] iter = 11290, loss = 2.3096
2024-10-30 16:26:31: [2024-10-30 16:26:31] iter = 11300, loss = 2.4937
2024-10-30 16:26:35: [2024-10-30 16:26:35] iter = 11310, loss = 2.4971
2024-10-30 16:26:39: [2024-10-30 16:26:39] iter = 11320, loss = 2.1644
2024-10-30 16:26:43: [2024-10-30 16:26:43] iter = 11330, loss = 1.9180
2024-10-30 16:26:46: [2024-10-30 16:26:46] iter = 11340, loss = 1.9326
2024-10-30 16:26:50: [2024-10-30 16:26:50] iter = 11350, loss = 2.2356
2024-10-30 16:26:54: [2024-10-30 16:26:54] iter = 11360, loss = 2.3492
2024-10-30 16:26:57: [2024-10-30 16:26:57] iter = 11370, loss = 3.0315
2024-10-30 16:27:01: [2024-10-30 16:27:01] iter = 11380, loss = 1.9820
2024-10-30 16:27:04: [2024-10-30 16:27:04] iter = 11390, loss = 3.4592
2024-10-30 16:27:06: [2024-10-30 16:27:06] iter = 11400, loss = 2.1325
2024-10-30 16:27:09: [2024-10-30 16:27:09] iter = 11410, loss = 4.5737
2024-10-30 16:27:13: [2024-10-30 16:27:13] iter = 11420, loss = 1.9781
2024-10-30 16:27:17: [2024-10-30 16:27:17] iter = 11430, loss = 1.9026
2024-10-30 16:27:20: [2024-10-30 16:27:20] iter = 11440, loss = 2.3218
2024-10-30 16:27:23: [2024-10-30 16:27:23] iter = 11450, loss = 2.4687
2024-10-30 16:27:26: [2024-10-30 16:27:26] iter = 11460, loss = 2.9012
2024-10-30 16:27:29: [2024-10-30 16:27:29] iter = 11470, loss = 1.7836
2024-10-30 16:27:31: [2024-10-30 16:27:31] iter = 11480, loss = 2.0148
2024-10-30 16:27:35: [2024-10-30 16:27:35] iter = 11490, loss = 2.4187
2024-10-30 16:27:37: [2024-10-30 16:27:37] iter = 11500, loss = 3.0130
2024-10-30 16:27:39: [2024-10-30 16:27:39] iter = 11510, loss = 2.1249
2024-10-30 16:27:42: [2024-10-30 16:27:42] iter = 11520, loss = 2.3237
2024-10-30 16:27:46: [2024-10-30 16:27:46] iter = 11530, loss = 1.8246
2024-10-30 16:27:49: [2024-10-30 16:27:49] iter = 11540, loss = 3.3390
2024-10-30 16:27:52: [2024-10-30 16:27:52] iter = 11550, loss = 1.9979
2024-10-30 16:27:56: [2024-10-30 16:27:56] iter = 11560, loss = 2.8324
2024-10-30 16:27:59: [2024-10-30 16:27:59] iter = 11570, loss = 2.8340
2024-10-30 16:28:02: [2024-10-30 16:28:02] iter = 11580, loss = 2.0998
2024-10-30 16:28:05: [2024-10-30 16:28:05] iter = 11590, loss = 2.8548
2024-10-30 16:28:08: [2024-10-30 16:28:08] iter = 11600, loss = 2.0067
2024-10-30 16:28:12: [2024-10-30 16:28:12] iter = 11610, loss = 1.8847
2024-10-30 16:28:16: [2024-10-30 16:28:16] iter = 11620, loss = 1.8918
2024-10-30 16:28:20: [2024-10-30 16:28:20] iter = 11630, loss = 2.2418
2024-10-30 16:28:24: [2024-10-30 16:28:24] iter = 11640, loss = 1.9127
2024-10-30 16:28:28: [2024-10-30 16:28:28] iter = 11650, loss = 3.0556
2024-10-30 16:28:32: [2024-10-30 16:28:32] iter = 11660, loss = 2.0511
2024-10-30 16:28:36: [2024-10-30 16:28:36] iter = 11670, loss = 2.0153
2024-10-30 16:28:40: [2024-10-30 16:28:40] iter = 11680, loss = 2.5613
2024-10-30 16:28:43: [2024-10-30 16:28:43] iter = 11690, loss = 2.1796
2024-10-30 16:28:47: [2024-10-30 16:28:47] iter = 11700, loss = 2.9441
2024-10-30 16:28:50: [2024-10-30 16:28:50] iter = 11710, loss = 2.9083
2024-10-30 16:28:55: [2024-10-30 16:28:55] iter = 11720, loss = 2.1766
2024-10-30 16:28:58: [2024-10-30 16:28:58] iter = 11730, loss = 2.8017
2024-10-30 16:29:01: [2024-10-30 16:29:01] iter = 11740, loss = 3.3677
2024-10-30 16:29:06: [2024-10-30 16:29:06] iter = 11750, loss = 2.5042
2024-10-30 16:29:10: [2024-10-30 16:29:10] iter = 11760, loss = 2.3960
2024-10-30 16:29:14: [2024-10-30 16:29:14] iter = 11770, loss = 2.1891
2024-10-30 16:29:19: [2024-10-30 16:29:19] iter = 11780, loss = 2.2140
2024-10-30 16:29:23: [2024-10-30 16:29:23] iter = 11790, loss = 1.7347
2024-10-30 16:29:26: [2024-10-30 16:29:26] iter = 11800, loss = 2.1890
2024-10-30 16:29:29: [2024-10-30 16:29:29] iter = 11810, loss = 2.3312
2024-10-30 16:29:33: [2024-10-30 16:29:33] iter = 11820, loss = 3.6303
2024-10-30 16:29:37: [2024-10-30 16:29:37] iter = 11830, loss = 2.4598
2024-10-30 16:29:39: [2024-10-30 16:29:39] iter = 11840, loss = 1.8731
2024-10-30 16:29:44: [2024-10-30 16:29:44] iter = 11850, loss = 1.8531
2024-10-30 16:29:48: [2024-10-30 16:29:48] iter = 11860, loss = 1.9943
2024-10-30 16:29:51: [2024-10-30 16:29:51] iter = 11870, loss = 2.0725
2024-10-30 16:29:54: [2024-10-30 16:29:54] iter = 11880, loss = 2.0002
2024-10-30 16:29:57: [2024-10-30 16:29:57] iter = 11890, loss = 2.0652
2024-10-30 16:29:59: [2024-10-30 16:29:59] iter = 11900, loss = 2.1117
2024-10-30 16:30:02: [2024-10-30 16:30:02] iter = 11910, loss = 2.4517
2024-10-30 16:30:05: [2024-10-30 16:30:05] iter = 11920, loss = 2.1641
2024-10-30 16:30:10: [2024-10-30 16:30:10] iter = 11930, loss = 2.1473
2024-10-30 16:30:14: [2024-10-30 16:30:14] iter = 11940, loss = 2.4053
2024-10-30 16:30:16: [2024-10-30 16:30:16] iter = 11950, loss = 2.2039
2024-10-30 16:30:18: [2024-10-30 16:30:18] iter = 11960, loss = 1.8475
2024-10-30 16:30:21: [2024-10-30 16:30:21] iter = 11970, loss = 2.1989
2024-10-30 16:30:22: [2024-10-30 16:30:22] iter = 11980, loss = 2.1186
2024-10-30 16:30:26: [2024-10-30 16:30:26] iter = 11990, loss = 2.4642
2024-10-30 16:30:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 16:30:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:30:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 29646}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:32:51: Evaluate 5 random ConvNet, ACCmean = 0.6127 ACCstd = 0.0050
-------------------------
2024-10-30 16:32:51: Evaluate 5 random ConvNet, SENmean = 0.5891 SENstd = 0.0049
-------------------------
2024-10-30 16:32:51: Evaluate 5 random ConvNet, SPEmean = 0.9605 SPEstd = 0.0004
-------------------------
2024-10-30 16:32:51: Evaluate 5 random ConvNet, F!mean = 0.5807 F!std = 0.0069
-------------------------
2024-10-30 16:32:51: Evaluate 5 random ConvNet, mean = 0.6127 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:32:52: [2024-10-30 16:32:52] iter = 12000, loss = 2.4281
2024-10-30 16:32:56: [2024-10-30 16:32:56] iter = 12010, loss = 2.3391
2024-10-30 16:33:00: [2024-10-30 16:33:00] iter = 12020, loss = 1.9118
2024-10-30 16:33:05: [2024-10-30 16:33:05] iter = 12030, loss = 2.5970
2024-10-30 16:33:08: [2024-10-30 16:33:08] iter = 12040, loss = 2.4128
2024-10-30 16:33:11: [2024-10-30 16:33:11] iter = 12050, loss = 3.1193
2024-10-30 16:33:14: [2024-10-30 16:33:14] iter = 12060, loss = 2.0601
2024-10-30 16:33:18: [2024-10-30 16:33:18] iter = 12070, loss = 1.8538
2024-10-30 16:33:22: [2024-10-30 16:33:22] iter = 12080, loss = 2.0707
2024-10-30 16:33:26: [2024-10-30 16:33:26] iter = 12090, loss = 2.4316
2024-10-30 16:33:29: [2024-10-30 16:33:29] iter = 12100, loss = 1.9604
2024-10-30 16:33:32: [2024-10-30 16:33:32] iter = 12110, loss = 2.7807
2024-10-30 16:33:35: [2024-10-30 16:33:35] iter = 12120, loss = 2.6081
2024-10-30 16:33:40: [2024-10-30 16:33:40] iter = 12130, loss = 2.3044
2024-10-30 16:33:45: [2024-10-30 16:33:45] iter = 12140, loss = 1.8038
2024-10-30 16:33:49: [2024-10-30 16:33:49] iter = 12150, loss = 1.7702
2024-10-30 16:33:52: [2024-10-30 16:33:52] iter = 12160, loss = 1.9725
2024-10-30 16:33:57: [2024-10-30 16:33:57] iter = 12170, loss = 2.3636
2024-10-30 16:34:01: [2024-10-30 16:34:01] iter = 12180, loss = 2.6170
2024-10-30 16:34:05: [2024-10-30 16:34:05] iter = 12190, loss = 2.6127
2024-10-30 16:34:08: [2024-10-30 16:34:08] iter = 12200, loss = 2.3172
2024-10-30 16:34:12: [2024-10-30 16:34:12] iter = 12210, loss = 2.2122
2024-10-30 16:34:16: [2024-10-30 16:34:16] iter = 12220, loss = 2.1081
2024-10-30 16:34:20: [2024-10-30 16:34:20] iter = 12230, loss = 1.9485
2024-10-30 16:34:24: [2024-10-30 16:34:24] iter = 12240, loss = 4.9155
2024-10-30 16:34:28: [2024-10-30 16:34:28] iter = 12250, loss = 2.1093
2024-10-30 16:34:33: [2024-10-30 16:34:33] iter = 12260, loss = 2.2989
2024-10-30 16:34:38: [2024-10-30 16:34:38] iter = 12270, loss = 2.3170
2024-10-30 16:34:41: [2024-10-30 16:34:41] iter = 12280, loss = 2.0408
2024-10-30 16:34:46: [2024-10-30 16:34:46] iter = 12290, loss = 2.1370
2024-10-30 16:34:51: [2024-10-30 16:34:51] iter = 12300, loss = 2.8948
2024-10-30 16:34:54: [2024-10-30 16:34:54] iter = 12310, loss = 2.0103
2024-10-30 16:34:57: [2024-10-30 16:34:57] iter = 12320, loss = 2.1380
2024-10-30 16:35:01: [2024-10-30 16:35:01] iter = 12330, loss = 2.6118
2024-10-30 16:35:05: [2024-10-30 16:35:05] iter = 12340, loss = 2.3392
2024-10-30 16:35:08: [2024-10-30 16:35:08] iter = 12350, loss = 2.1914
2024-10-30 16:35:13: [2024-10-30 16:35:13] iter = 12360, loss = 1.9538
2024-10-30 16:35:17: [2024-10-30 16:35:17] iter = 12370, loss = 2.1025
2024-10-30 16:35:21: [2024-10-30 16:35:21] iter = 12380, loss = 2.3762
2024-10-30 16:35:25: [2024-10-30 16:35:25] iter = 12390, loss = 2.1252
2024-10-30 16:35:29: [2024-10-30 16:35:29] iter = 12400, loss = 2.6318
2024-10-30 16:35:33: [2024-10-30 16:35:33] iter = 12410, loss = 1.9350
2024-10-30 16:35:37: [2024-10-30 16:35:37] iter = 12420, loss = 1.9650
2024-10-30 16:35:41: [2024-10-30 16:35:41] iter = 12430, loss = 2.5339
2024-10-30 16:35:45: [2024-10-30 16:35:45] iter = 12440, loss = 2.9648
2024-10-30 16:35:49: [2024-10-30 16:35:49] iter = 12450, loss = 1.9864
2024-10-30 16:35:53: [2024-10-30 16:35:53] iter = 12460, loss = 2.2345
2024-10-30 16:35:56: [2024-10-30 16:35:56] iter = 12470, loss = 2.0915
2024-10-30 16:35:59: [2024-10-30 16:35:59] iter = 12480, loss = 1.9413
2024-10-30 16:36:03: [2024-10-30 16:36:03] iter = 12490, loss = 2.5292
2024-10-30 16:36:06: [2024-10-30 16:36:06] iter = 12500, loss = 1.9191
2024-10-30 16:36:09: [2024-10-30 16:36:09] iter = 12510, loss = 1.9093
2024-10-30 16:36:13: [2024-10-30 16:36:13] iter = 12520, loss = 2.1338
2024-10-30 16:36:17: [2024-10-30 16:36:17] iter = 12530, loss = 2.2451
2024-10-30 16:36:20: [2024-10-30 16:36:20] iter = 12540, loss = 3.5643
2024-10-30 16:36:25: [2024-10-30 16:36:25] iter = 12550, loss = 2.2474
2024-10-30 16:36:29: [2024-10-30 16:36:29] iter = 12560, loss = 1.8384
2024-10-30 16:36:33: [2024-10-30 16:36:33] iter = 12570, loss = 2.7435
2024-10-30 16:36:37: [2024-10-30 16:36:37] iter = 12580, loss = 1.9030
2024-10-30 16:36:41: [2024-10-30 16:36:41] iter = 12590, loss = 1.8320
2024-10-30 16:36:45: [2024-10-30 16:36:45] iter = 12600, loss = 2.1370
2024-10-30 16:36:49: [2024-10-30 16:36:49] iter = 12610, loss = 2.0516
2024-10-30 16:36:52: [2024-10-30 16:36:52] iter = 12620, loss = 2.7146
2024-10-30 16:36:56: [2024-10-30 16:36:56] iter = 12630, loss = 7.5568
2024-10-30 16:37:00: [2024-10-30 16:37:00] iter = 12640, loss = 2.0193
2024-10-30 16:37:04: [2024-10-30 16:37:04] iter = 12650, loss = 2.2116
2024-10-30 16:37:08: [2024-10-30 16:37:08] iter = 12660, loss = 2.1187
2024-10-30 16:37:13: [2024-10-30 16:37:13] iter = 12670, loss = 2.1071
2024-10-30 16:37:18: [2024-10-30 16:37:18] iter = 12680, loss = 2.1020
2024-10-30 16:37:22: [2024-10-30 16:37:22] iter = 12690, loss = 2.2196
2024-10-30 16:37:25: [2024-10-30 16:37:25] iter = 12700, loss = 2.6594
2024-10-30 16:37:29: [2024-10-30 16:37:29] iter = 12710, loss = 2.1422
2024-10-30 16:37:32: [2024-10-30 16:37:32] iter = 12720, loss = 2.2740
2024-10-30 16:37:36: [2024-10-30 16:37:36] iter = 12730, loss = 2.7843
2024-10-30 16:37:40: [2024-10-30 16:37:40] iter = 12740, loss = 1.7633
2024-10-30 16:37:45: [2024-10-30 16:37:45] iter = 12750, loss = 2.0716
2024-10-30 16:37:50: [2024-10-30 16:37:50] iter = 12760, loss = 1.9985
2024-10-30 16:37:54: [2024-10-30 16:37:54] iter = 12770, loss = 2.2218
2024-10-30 16:37:58: [2024-10-30 16:37:58] iter = 12780, loss = 2.4713
2024-10-30 16:38:02: [2024-10-30 16:38:02] iter = 12790, loss = 2.1073
2024-10-30 16:38:06: [2024-10-30 16:38:06] iter = 12800, loss = 2.4567
2024-10-30 16:38:10: [2024-10-30 16:38:10] iter = 12810, loss = 3.1820
2024-10-30 16:38:14: [2024-10-30 16:38:14] iter = 12820, loss = 1.9426
2024-10-30 16:38:18: [2024-10-30 16:38:18] iter = 12830, loss = 2.3738
2024-10-30 16:38:22: [2024-10-30 16:38:22] iter = 12840, loss = 2.3675
2024-10-30 16:38:25: [2024-10-30 16:38:25] iter = 12850, loss = 2.6322
2024-10-30 16:38:29: [2024-10-30 16:38:29] iter = 12860, loss = 2.3171
2024-10-30 16:38:34: [2024-10-30 16:38:34] iter = 12870, loss = 1.9808
2024-10-30 16:38:38: [2024-10-30 16:38:38] iter = 12880, loss = 3.1797
2024-10-30 16:38:43: [2024-10-30 16:38:43] iter = 12890, loss = 2.3875
2024-10-30 16:38:46: [2024-10-30 16:38:46] iter = 12900, loss = 1.9677
2024-10-30 16:38:50: [2024-10-30 16:38:50] iter = 12910, loss = 2.0857
2024-10-30 16:38:55: [2024-10-30 16:38:55] iter = 12920, loss = 3.3789
2024-10-30 16:38:58: [2024-10-30 16:38:58] iter = 12930, loss = 2.1359
2024-10-30 16:39:01: [2024-10-30 16:39:01] iter = 12940, loss = 2.8472
2024-10-30 16:39:05: [2024-10-30 16:39:05] iter = 12950, loss = 2.1747
2024-10-30 16:39:08: [2024-10-30 16:39:08] iter = 12960, loss = 2.7872
2024-10-30 16:39:12: [2024-10-30 16:39:12] iter = 12970, loss = 2.4099
2024-10-30 16:39:16: [2024-10-30 16:39:16] iter = 12980, loss = 3.4314
2024-10-30 16:39:20: [2024-10-30 16:39:20] iter = 12990, loss = 2.0083
2024-10-30 16:39:24: [2024-10-30 16:39:24] iter = 13000, loss = 3.4754
2024-10-30 16:39:29: [2024-10-30 16:39:29] iter = 13010, loss = 1.8291
2024-10-30 16:39:33: [2024-10-30 16:39:33] iter = 13020, loss = 2.0108
2024-10-30 16:39:37: [2024-10-30 16:39:37] iter = 13030, loss = 1.8846
2024-10-30 16:39:41: [2024-10-30 16:39:41] iter = 13040, loss = 2.2954
2024-10-30 16:39:45: [2024-10-30 16:39:45] iter = 13050, loss = 4.1310
2024-10-30 16:39:49: [2024-10-30 16:39:49] iter = 13060, loss = 2.0767
2024-10-30 16:39:53: [2024-10-30 16:39:53] iter = 13070, loss = 2.3249
2024-10-30 16:39:56: [2024-10-30 16:39:56] iter = 13080, loss = 2.1576
2024-10-30 16:40:01: [2024-10-30 16:40:01] iter = 13090, loss = 4.4191
2024-10-30 16:40:05: [2024-10-30 16:40:05] iter = 13100, loss = 2.2218
2024-10-30 16:40:09: [2024-10-30 16:40:09] iter = 13110, loss = 1.9651
2024-10-30 16:40:13: [2024-10-30 16:40:13] iter = 13120, loss = 1.8540
2024-10-30 16:40:17: [2024-10-30 16:40:17] iter = 13130, loss = 2.1803
2024-10-30 16:40:21: [2024-10-30 16:40:21] iter = 13140, loss = 1.8933
2024-10-30 16:40:24: [2024-10-30 16:40:24] iter = 13150, loss = 2.0168
2024-10-30 16:40:27: [2024-10-30 16:40:27] iter = 13160, loss = 2.5462
2024-10-30 16:40:30: [2024-10-30 16:40:30] iter = 13170, loss = 2.4405
2024-10-30 16:40:35: [2024-10-30 16:40:35] iter = 13180, loss = 2.2075
2024-10-30 16:40:39: [2024-10-30 16:40:39] iter = 13190, loss = 2.2040
2024-10-30 16:40:43: [2024-10-30 16:40:43] iter = 13200, loss = 2.6583
2024-10-30 16:40:46: [2024-10-30 16:40:46] iter = 13210, loss = 3.4315
2024-10-30 16:40:49: [2024-10-30 16:40:49] iter = 13220, loss = 2.1567
2024-10-30 16:40:54: [2024-10-30 16:40:54] iter = 13230, loss = 2.9013
2024-10-30 16:40:57: [2024-10-30 16:40:57] iter = 13240, loss = 2.5597
2024-10-30 16:41:01: [2024-10-30 16:41:01] iter = 13250, loss = 5.3058
2024-10-30 16:41:05: [2024-10-30 16:41:05] iter = 13260, loss = 3.2805
2024-10-30 16:41:09: [2024-10-30 16:41:09] iter = 13270, loss = 2.4450
2024-10-30 16:41:13: [2024-10-30 16:41:13] iter = 13280, loss = 3.4208
2024-10-30 16:41:17: [2024-10-30 16:41:17] iter = 13290, loss = 1.9807
2024-10-30 16:41:21: [2024-10-30 16:41:21] iter = 13300, loss = 2.4154
2024-10-30 16:41:23: [2024-10-30 16:41:23] iter = 13310, loss = 2.8024
2024-10-30 16:41:25: [2024-10-30 16:41:25] iter = 13320, loss = 1.9649
2024-10-30 16:41:29: [2024-10-30 16:41:29] iter = 13330, loss = 1.9656
2024-10-30 16:41:33: [2024-10-30 16:41:33] iter = 13340, loss = 2.2383
2024-10-30 16:41:37: [2024-10-30 16:41:37] iter = 13350, loss = 1.9336
2024-10-30 16:41:41: [2024-10-30 16:41:41] iter = 13360, loss = 2.3934
2024-10-30 16:41:46: [2024-10-30 16:41:46] iter = 13370, loss = 2.5304
2024-10-30 16:41:50: [2024-10-30 16:41:50] iter = 13380, loss = 2.2544
2024-10-30 16:41:54: [2024-10-30 16:41:54] iter = 13390, loss = 1.8345
2024-10-30 16:41:58: [2024-10-30 16:41:58] iter = 13400, loss = 2.6655
2024-10-30 16:42:03: [2024-10-30 16:42:03] iter = 13410, loss = 1.9101
2024-10-30 16:42:07: [2024-10-30 16:42:07] iter = 13420, loss = 2.2299
2024-10-30 16:42:11: [2024-10-30 16:42:11] iter = 13430, loss = 2.3185
2024-10-30 16:42:14: [2024-10-30 16:42:14] iter = 13440, loss = 2.3825
2024-10-30 16:42:18: [2024-10-30 16:42:18] iter = 13450, loss = 1.9757
2024-10-30 16:42:22: [2024-10-30 16:42:22] iter = 13460, loss = 2.3691
2024-10-30 16:42:26: [2024-10-30 16:42:26] iter = 13470, loss = 2.1824
2024-10-30 16:42:28: [2024-10-30 16:42:28] iter = 13480, loss = 2.6309
2024-10-30 16:42:32: [2024-10-30 16:42:32] iter = 13490, loss = 2.2390
2024-10-30 16:42:36: [2024-10-30 16:42:36] iter = 13500, loss = 2.4079
2024-10-30 16:42:40: [2024-10-30 16:42:40] iter = 13510, loss = 2.2002
2024-10-30 16:42:43: [2024-10-30 16:42:43] iter = 13520, loss = 1.9519
2024-10-30 16:42:47: [2024-10-30 16:42:47] iter = 13530, loss = 2.9271
2024-10-30 16:42:51: [2024-10-30 16:42:51] iter = 13540, loss = 2.0787
2024-10-30 16:42:55: [2024-10-30 16:42:55] iter = 13550, loss = 2.6676
2024-10-30 16:43:00: [2024-10-30 16:43:00] iter = 13560, loss = 2.6448
2024-10-30 16:43:02: [2024-10-30 16:43:02] iter = 13570, loss = 2.7679
2024-10-30 16:43:05: [2024-10-30 16:43:05] iter = 13580, loss = 2.3121
2024-10-30 16:43:08: [2024-10-30 16:43:08] iter = 13590, loss = 2.0343
2024-10-30 16:43:13: [2024-10-30 16:43:13] iter = 13600, loss = 2.5135
2024-10-30 16:43:17: [2024-10-30 16:43:17] iter = 13610, loss = 3.6056
2024-10-30 16:43:22: [2024-10-30 16:43:22] iter = 13620, loss = 3.2106
2024-10-30 16:43:27: [2024-10-30 16:43:27] iter = 13630, loss = 2.5447
2024-10-30 16:43:30: [2024-10-30 16:43:30] iter = 13640, loss = 6.4737
2024-10-30 16:43:34: [2024-10-30 16:43:34] iter = 13650, loss = 3.2457
2024-10-30 16:43:39: [2024-10-30 16:43:39] iter = 13660, loss = 2.4070
2024-10-30 16:43:43: [2024-10-30 16:43:43] iter = 13670, loss = 2.0702
2024-10-30 16:43:46: [2024-10-30 16:43:46] iter = 13680, loss = 2.3461
2024-10-30 16:43:50: [2024-10-30 16:43:50] iter = 13690, loss = 2.8109
2024-10-30 16:43:53: [2024-10-30 16:43:53] iter = 13700, loss = 1.9690
2024-10-30 16:43:57: [2024-10-30 16:43:57] iter = 13710, loss = 2.1083
2024-10-30 16:44:00: [2024-10-30 16:44:00] iter = 13720, loss = 2.5300
2024-10-30 16:44:04: [2024-10-30 16:44:04] iter = 13730, loss = 2.3962
2024-10-30 16:44:08: [2024-10-30 16:44:08] iter = 13740, loss = 2.4338
2024-10-30 16:44:12: [2024-10-30 16:44:12] iter = 13750, loss = 2.0127
2024-10-30 16:44:16: [2024-10-30 16:44:16] iter = 13760, loss = 3.8478
2024-10-30 16:44:21: [2024-10-30 16:44:21] iter = 13770, loss = 1.9550
2024-10-30 16:44:26: [2024-10-30 16:44:25] iter = 13780, loss = 2.5021
2024-10-30 16:44:30: [2024-10-30 16:44:30] iter = 13790, loss = 2.0085
2024-10-30 16:44:35: [2024-10-30 16:44:35] iter = 13800, loss = 2.4769
2024-10-30 16:44:39: [2024-10-30 16:44:39] iter = 13810, loss = 3.2139
2024-10-30 16:44:42: [2024-10-30 16:44:42] iter = 13820, loss = 2.0393
2024-10-30 16:44:46: [2024-10-30 16:44:46] iter = 13830, loss = 2.5595
2024-10-30 16:44:50: [2024-10-30 16:44:50] iter = 13840, loss = 1.8834
2024-10-30 16:44:54: [2024-10-30 16:44:54] iter = 13850, loss = 2.1204
2024-10-30 16:44:58: [2024-10-30 16:44:58] iter = 13860, loss = 2.3690
2024-10-30 16:45:03: [2024-10-30 16:45:03] iter = 13870, loss = 2.2888
2024-10-30 16:45:06: [2024-10-30 16:45:06] iter = 13880, loss = 2.0320
2024-10-30 16:45:11: [2024-10-30 16:45:11] iter = 13890, loss = 1.7162
2024-10-30 16:45:15: [2024-10-30 16:45:15] iter = 13900, loss = 2.3428
2024-10-30 16:45:18: [2024-10-30 16:45:18] iter = 13910, loss = 2.1696
2024-10-30 16:45:22: [2024-10-30 16:45:22] iter = 13920, loss = 2.0366
2024-10-30 16:45:26: [2024-10-30 16:45:26] iter = 13930, loss = 2.5037
2024-10-30 16:45:29: [2024-10-30 16:45:29] iter = 13940, loss = 3.8028
2024-10-30 16:45:32: [2024-10-30 16:45:32] iter = 13950, loss = 2.4557
2024-10-30 16:45:36: [2024-10-30 16:45:36] iter = 13960, loss = 2.0620
2024-10-30 16:45:40: [2024-10-30 16:45:40] iter = 13970, loss = 2.0640
2024-10-30 16:45:44: [2024-10-30 16:45:44] iter = 13980, loss = 2.0789
2024-10-30 16:45:49: [2024-10-30 16:45:49] iter = 13990, loss = 1.9602
2024-10-30 16:45:52: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 16:45:52: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:45:52: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52666}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:48:15: Evaluate 5 random ConvNet, ACCmean = 0.6119 ACCstd = 0.0034
-------------------------
2024-10-30 16:48:15: Evaluate 5 random ConvNet, SENmean = 0.5950 SENstd = 0.0034
-------------------------
2024-10-30 16:48:15: Evaluate 5 random ConvNet, SPEmean = 0.9604 SPEstd = 0.0004
-------------------------
2024-10-30 16:48:15: Evaluate 5 random ConvNet, F!mean = 0.5851 F!std = 0.0019
-------------------------
2024-10-30 16:48:15: Evaluate 5 random ConvNet, mean = 0.6119 std = 0.0034
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:48:15: [2024-10-30 16:48:15] iter = 14000, loss = 1.9006
2024-10-30 16:48:19: [2024-10-30 16:48:19] iter = 14010, loss = 1.7348
2024-10-30 16:48:23: [2024-10-30 16:48:23] iter = 14020, loss = 2.0824
2024-10-30 16:48:27: [2024-10-30 16:48:27] iter = 14030, loss = 2.0071
2024-10-30 16:48:31: [2024-10-30 16:48:31] iter = 14040, loss = 2.3942
2024-10-30 16:48:34: [2024-10-30 16:48:34] iter = 14050, loss = 2.3064
2024-10-30 16:48:39: [2024-10-30 16:48:39] iter = 14060, loss = 1.9499
2024-10-30 16:48:41: [2024-10-30 16:48:41] iter = 14070, loss = 1.9840
2024-10-30 16:48:45: [2024-10-30 16:48:45] iter = 14080, loss = 2.2070
2024-10-30 16:48:48: [2024-10-30 16:48:48] iter = 14090, loss = 2.5148
2024-10-30 16:48:53: [2024-10-30 16:48:53] iter = 14100, loss = 2.2624
2024-10-30 16:48:56: [2024-10-30 16:48:56] iter = 14110, loss = 2.8570
2024-10-30 16:48:59: [2024-10-30 16:48:59] iter = 14120, loss = 5.0073
2024-10-30 16:49:02: [2024-10-30 16:49:02] iter = 14130, loss = 3.3884
2024-10-30 16:49:06: [2024-10-30 16:49:06] iter = 14140, loss = 2.5966
2024-10-30 16:49:10: [2024-10-30 16:49:10] iter = 14150, loss = 1.9546
2024-10-30 16:49:14: [2024-10-30 16:49:14] iter = 14160, loss = 2.2951
2024-10-30 16:49:18: [2024-10-30 16:49:18] iter = 14170, loss = 2.2035
2024-10-30 16:49:22: [2024-10-30 16:49:22] iter = 14180, loss = 2.8020
2024-10-30 16:49:25: [2024-10-30 16:49:25] iter = 14190, loss = 2.2072
2024-10-30 16:49:29: [2024-10-30 16:49:29] iter = 14200, loss = 2.4769
2024-10-30 16:49:33: [2024-10-30 16:49:33] iter = 14210, loss = 2.0945
2024-10-30 16:49:37: [2024-10-30 16:49:37] iter = 14220, loss = 5.9578
2024-10-30 16:49:41: [2024-10-30 16:49:41] iter = 14230, loss = 3.2719
2024-10-30 16:49:46: [2024-10-30 16:49:46] iter = 14240, loss = 2.0719
2024-10-30 16:49:51: [2024-10-30 16:49:51] iter = 14250, loss = 3.4502
2024-10-30 16:49:55: [2024-10-30 16:49:55] iter = 14260, loss = 2.4246
2024-10-30 16:49:59: [2024-10-30 16:49:59] iter = 14270, loss = 2.2000
2024-10-30 16:50:02: [2024-10-30 16:50:02] iter = 14280, loss = 2.0058
2024-10-30 16:50:06: [2024-10-30 16:50:06] iter = 14290, loss = 1.8211
2024-10-30 16:50:09: [2024-10-30 16:50:09] iter = 14300, loss = 2.2010
2024-10-30 16:50:12: [2024-10-30 16:50:12] iter = 14310, loss = 2.3252
2024-10-30 16:50:15: [2024-10-30 16:50:15] iter = 14320, loss = 2.3391
2024-10-30 16:50:19: [2024-10-30 16:50:19] iter = 14330, loss = 2.0460
2024-10-30 16:50:23: [2024-10-30 16:50:23] iter = 14340, loss = 3.7102
2024-10-30 16:50:27: [2024-10-30 16:50:27] iter = 14350, loss = 2.5595
2024-10-30 16:50:31: [2024-10-30 16:50:31] iter = 14360, loss = 1.9920
2024-10-30 16:50:36: [2024-10-30 16:50:36] iter = 14370, loss = 1.8465
2024-10-30 16:50:39: [2024-10-30 16:50:39] iter = 14380, loss = 1.8956
2024-10-30 16:50:42: [2024-10-30 16:50:42] iter = 14390, loss = 2.3601
2024-10-30 16:50:46: [2024-10-30 16:50:46] iter = 14400, loss = 1.7748
2024-10-30 16:50:50: [2024-10-30 16:50:50] iter = 14410, loss = 2.2085
2024-10-30 16:50:54: [2024-10-30 16:50:54] iter = 14420, loss = 2.0551
2024-10-30 16:50:58: [2024-10-30 16:50:58] iter = 14430, loss = 2.0129
2024-10-30 16:51:02: [2024-10-30 16:51:02] iter = 14440, loss = 2.3783
2024-10-30 16:51:06: [2024-10-30 16:51:06] iter = 14450, loss = 1.8209
2024-10-30 16:51:10: [2024-10-30 16:51:10] iter = 14460, loss = 2.4246
2024-10-30 16:51:13: [2024-10-30 16:51:13] iter = 14470, loss = 2.3068
2024-10-30 16:51:17: [2024-10-30 16:51:17] iter = 14480, loss = 2.2362
2024-10-30 16:51:19: [2024-10-30 16:51:19] iter = 14490, loss = 2.2892
2024-10-30 16:51:23: [2024-10-30 16:51:23] iter = 14500, loss = 2.6934
2024-10-30 16:51:27: [2024-10-30 16:51:27] iter = 14510, loss = 2.5831
2024-10-30 16:51:30: [2024-10-30 16:51:30] iter = 14520, loss = 1.8265
2024-10-30 16:51:34: [2024-10-30 16:51:34] iter = 14530, loss = 2.1575
2024-10-30 16:51:37: [2024-10-30 16:51:37] iter = 14540, loss = 1.7870
2024-10-30 16:51:40: [2024-10-30 16:51:40] iter = 14550, loss = 2.4656
2024-10-30 16:51:42: [2024-10-30 16:51:42] iter = 14560, loss = 2.8521
2024-10-30 16:51:46: [2024-10-30 16:51:46] iter = 14570, loss = 2.3113
2024-10-30 16:51:50: [2024-10-30 16:51:50] iter = 14580, loss = 2.4986
2024-10-30 16:51:54: [2024-10-30 16:51:54] iter = 14590, loss = 2.7112
2024-10-30 16:51:59: [2024-10-30 16:51:59] iter = 14600, loss = 2.1615
2024-10-30 16:52:03: [2024-10-30 16:52:03] iter = 14610, loss = 2.1984
2024-10-30 16:52:07: [2024-10-30 16:52:07] iter = 14620, loss = 2.1690
2024-10-30 16:52:11: [2024-10-30 16:52:11] iter = 14630, loss = 2.3329
2024-10-30 16:52:14: [2024-10-30 16:52:14] iter = 14640, loss = 5.1141
2024-10-30 16:52:17: [2024-10-30 16:52:17] iter = 14650, loss = 2.3573
2024-10-30 16:52:21: [2024-10-30 16:52:21] iter = 14660, loss = 2.4257
2024-10-30 16:52:26: [2024-10-30 16:52:26] iter = 14670, loss = 2.2876
2024-10-30 16:52:29: [2024-10-30 16:52:29] iter = 14680, loss = 2.5349
2024-10-30 16:52:32: [2024-10-30 16:52:32] iter = 14690, loss = 3.1875
2024-10-30 16:52:36: [2024-10-30 16:52:36] iter = 14700, loss = 2.1366
2024-10-30 16:52:40: [2024-10-30 16:52:40] iter = 14710, loss = 1.9425
2024-10-30 16:52:44: [2024-10-30 16:52:44] iter = 14720, loss = 2.4381
2024-10-30 16:52:48: [2024-10-30 16:52:48] iter = 14730, loss = 1.9044
2024-10-30 16:52:51: [2024-10-30 16:52:51] iter = 14740, loss = 2.1920
2024-10-30 16:52:55: [2024-10-30 16:52:55] iter = 14750, loss = 2.2126
2024-10-30 16:52:58: [2024-10-30 16:52:58] iter = 14760, loss = 2.7783
2024-10-30 16:53:01: [2024-10-30 16:53:01] iter = 14770, loss = 2.4200
2024-10-30 16:53:04: [2024-10-30 16:53:04] iter = 14780, loss = 2.2415
2024-10-30 16:53:08: [2024-10-30 16:53:08] iter = 14790, loss = 2.1774
2024-10-30 16:53:11: [2024-10-30 16:53:11] iter = 14800, loss = 2.8395
2024-10-30 16:53:16: [2024-10-30 16:53:16] iter = 14810, loss = 2.1004
2024-10-30 16:53:19: [2024-10-30 16:53:19] iter = 14820, loss = 2.3970
2024-10-30 16:53:23: [2024-10-30 16:53:23] iter = 14830, loss = 2.1602
2024-10-30 16:53:27: [2024-10-30 16:53:27] iter = 14840, loss = 2.4886
2024-10-30 16:53:30: [2024-10-30 16:53:30] iter = 14850, loss = 1.8239
2024-10-30 16:53:34: [2024-10-30 16:53:34] iter = 14860, loss = 2.2645
2024-10-30 16:53:37: [2024-10-30 16:53:37] iter = 14870, loss = 1.8996
2024-10-30 16:53:41: [2024-10-30 16:53:41] iter = 14880, loss = 2.0808
2024-10-30 16:53:45: [2024-10-30 16:53:45] iter = 14890, loss = 2.1062
2024-10-30 16:53:48: [2024-10-30 16:53:48] iter = 14900, loss = 4.1581
2024-10-30 16:53:51: [2024-10-30 16:53:51] iter = 14910, loss = 2.2524
2024-10-30 16:53:54: [2024-10-30 16:53:54] iter = 14920, loss = 2.0108
2024-10-30 16:53:57: [2024-10-30 16:53:57] iter = 14930, loss = 2.2078
2024-10-30 16:54:00: [2024-10-30 16:54:00] iter = 14940, loss = 1.9841
2024-10-30 16:54:03: [2024-10-30 16:54:03] iter = 14950, loss = 2.1976
2024-10-30 16:54:06: [2024-10-30 16:54:06] iter = 14960, loss = 1.8298
2024-10-30 16:54:10: [2024-10-30 16:54:10] iter = 14970, loss = 1.9297
2024-10-30 16:54:13: [2024-10-30 16:54:13] iter = 14980, loss = 1.9380
2024-10-30 16:54:16: [2024-10-30 16:54:16] iter = 14990, loss = 1.7954
2024-10-30 16:54:20: [2024-10-30 16:54:20] iter = 15000, loss = 1.8293
2024-10-30 16:54:23: [2024-10-30 16:54:23] iter = 15010, loss = 1.9662
2024-10-30 16:54:27: [2024-10-30 16:54:27] iter = 15020, loss = 2.0009
2024-10-30 16:54:31: [2024-10-30 16:54:31] iter = 15030, loss = 2.5664
2024-10-30 16:54:35: [2024-10-30 16:54:35] iter = 15040, loss = 2.0653
2024-10-30 16:54:38: [2024-10-30 16:54:38] iter = 15050, loss = 3.0526
2024-10-30 16:54:42: [2024-10-30 16:54:42] iter = 15060, loss = 2.3267
2024-10-30 16:54:46: [2024-10-30 16:54:46] iter = 15070, loss = 1.9835
2024-10-30 16:54:49: [2024-10-30 16:54:49] iter = 15080, loss = 2.4253
2024-10-30 16:54:53: [2024-10-30 16:54:53] iter = 15090, loss = 2.6411
2024-10-30 16:54:57: [2024-10-30 16:54:57] iter = 15100, loss = 2.0377
2024-10-30 16:55:02: [2024-10-30 16:55:02] iter = 15110, loss = 4.1974
2024-10-30 16:55:05: [2024-10-30 16:55:05] iter = 15120, loss = 2.0907
2024-10-30 16:55:09: [2024-10-30 16:55:09] iter = 15130, loss = 2.4520
2024-10-30 16:55:12: [2024-10-30 16:55:12] iter = 15140, loss = 2.1848
2024-10-30 16:55:17: [2024-10-30 16:55:17] iter = 15150, loss = 2.0292
2024-10-30 16:55:21: [2024-10-30 16:55:21] iter = 15160, loss = 2.0995
2024-10-30 16:55:25: [2024-10-30 16:55:25] iter = 15170, loss = 2.1771
2024-10-30 16:55:29: [2024-10-30 16:55:29] iter = 15180, loss = 2.3574
2024-10-30 16:55:33: [2024-10-30 16:55:33] iter = 15190, loss = 2.1503
2024-10-30 16:55:37: [2024-10-30 16:55:37] iter = 15200, loss = 1.7407
2024-10-30 16:55:40: [2024-10-30 16:55:40] iter = 15210, loss = 2.0371
2024-10-30 16:55:45: [2024-10-30 16:55:45] iter = 15220, loss = 2.0301
2024-10-30 16:55:49: [2024-10-30 16:55:49] iter = 15230, loss = 2.6211
2024-10-30 16:55:53: [2024-10-30 16:55:53] iter = 15240, loss = 2.2154
2024-10-30 16:55:57: [2024-10-30 16:55:57] iter = 15250, loss = 2.1401
2024-10-30 16:56:02: [2024-10-30 16:56:02] iter = 15260, loss = 1.7959
2024-10-30 16:56:05: [2024-10-30 16:56:05] iter = 15270, loss = 2.2699
2024-10-30 16:56:10: [2024-10-30 16:56:10] iter = 15280, loss = 2.9689
2024-10-30 16:56:13: [2024-10-30 16:56:13] iter = 15290, loss = 1.9472
2024-10-30 16:56:16: [2024-10-30 16:56:16] iter = 15300, loss = 1.7718
2024-10-30 16:56:19: [2024-10-30 16:56:19] iter = 15310, loss = 1.9325
2024-10-30 16:56:23: [2024-10-30 16:56:23] iter = 15320, loss = 2.1802
2024-10-30 16:56:25: [2024-10-30 16:56:25] iter = 15330, loss = 2.0419
2024-10-30 16:56:29: [2024-10-30 16:56:29] iter = 15340, loss = 2.9962
2024-10-30 16:56:32: [2024-10-30 16:56:32] iter = 15350, loss = 2.0183
2024-10-30 16:56:35: [2024-10-30 16:56:35] iter = 15360, loss = 1.8551
2024-10-30 16:56:39: [2024-10-30 16:56:39] iter = 15370, loss = 2.1861
2024-10-30 16:56:42: [2024-10-30 16:56:42] iter = 15380, loss = 3.4373
2024-10-30 16:56:45: [2024-10-30 16:56:45] iter = 15390, loss = 2.2423
2024-10-30 16:56:49: [2024-10-30 16:56:49] iter = 15400, loss = 2.1946
2024-10-30 16:56:52: [2024-10-30 16:56:52] iter = 15410, loss = 1.9944
2024-10-30 16:56:56: [2024-10-30 16:56:56] iter = 15420, loss = 2.4787
2024-10-30 16:56:59: [2024-10-30 16:56:59] iter = 15430, loss = 2.2254
2024-10-30 16:57:03: [2024-10-30 16:57:03] iter = 15440, loss = 2.3278
2024-10-30 16:57:05: [2024-10-30 16:57:05] iter = 15450, loss = 2.4124
2024-10-30 16:57:10: [2024-10-30 16:57:10] iter = 15460, loss = 1.7833
2024-10-30 16:57:13: [2024-10-30 16:57:13] iter = 15470, loss = 2.7409
2024-10-30 16:57:16: [2024-10-30 16:57:16] iter = 15480, loss = 2.5736
2024-10-30 16:57:20: [2024-10-30 16:57:20] iter = 15490, loss = 2.0996
2024-10-30 16:57:23: [2024-10-30 16:57:23] iter = 15500, loss = 2.8926
2024-10-30 16:57:26: [2024-10-30 16:57:26] iter = 15510, loss = 3.4401
2024-10-30 16:57:30: [2024-10-30 16:57:30] iter = 15520, loss = 2.1854
2024-10-30 16:57:33: [2024-10-30 16:57:33] iter = 15530, loss = 2.8477
2024-10-30 16:57:37: [2024-10-30 16:57:37] iter = 15540, loss = 2.3332
2024-10-30 16:57:41: [2024-10-30 16:57:41] iter = 15550, loss = 1.8505
2024-10-30 16:57:45: [2024-10-30 16:57:45] iter = 15560, loss = 3.0997
2024-10-30 16:57:48: [2024-10-30 16:57:48] iter = 15570, loss = 2.1331
2024-10-30 16:57:52: [2024-10-30 16:57:52] iter = 15580, loss = 2.3523
2024-10-30 16:57:55: [2024-10-30 16:57:55] iter = 15590, loss = 2.0837
2024-10-30 16:57:59: [2024-10-30 16:57:59] iter = 15600, loss = 2.3367
2024-10-30 16:58:04: [2024-10-30 16:58:04] iter = 15610, loss = 2.5218
2024-10-30 16:58:07: [2024-10-30 16:58:07] iter = 15620, loss = 1.8369
2024-10-30 16:58:11: [2024-10-30 16:58:11] iter = 15630, loss = 2.3228
2024-10-30 16:58:15: [2024-10-30 16:58:15] iter = 15640, loss = 2.1935
2024-10-30 16:58:19: [2024-10-30 16:58:19] iter = 15650, loss = 3.1250
2024-10-30 16:58:21: [2024-10-30 16:58:21] iter = 15660, loss = 1.9523
2024-10-30 16:58:24: [2024-10-30 16:58:24] iter = 15670, loss = 2.0576
2024-10-30 16:58:28: [2024-10-30 16:58:28] iter = 15680, loss = 2.6787
2024-10-30 16:58:32: [2024-10-30 16:58:32] iter = 15690, loss = 3.4728
2024-10-30 16:58:35: [2024-10-30 16:58:35] iter = 15700, loss = 2.3606
2024-10-30 16:58:38: [2024-10-30 16:58:38] iter = 15710, loss = 2.5794
2024-10-30 16:58:41: [2024-10-30 16:58:41] iter = 15720, loss = 2.0437
2024-10-30 16:58:44: [2024-10-30 16:58:44] iter = 15730, loss = 2.2459
2024-10-30 16:58:47: [2024-10-30 16:58:47] iter = 15740, loss = 1.9555
2024-10-30 16:58:51: [2024-10-30 16:58:51] iter = 15750, loss = 2.2336
2024-10-30 16:58:54: [2024-10-30 16:58:54] iter = 15760, loss = 2.1711
2024-10-30 16:58:58: [2024-10-30 16:58:58] iter = 15770, loss = 2.1933
2024-10-30 16:59:03: [2024-10-30 16:59:03] iter = 15780, loss = 1.8350
2024-10-30 16:59:07: [2024-10-30 16:59:07] iter = 15790, loss = 2.2854
2024-10-30 16:59:12: [2024-10-30 16:59:12] iter = 15800, loss = 2.1152
2024-10-30 16:59:16: [2024-10-30 16:59:16] iter = 15810, loss = 3.0564
2024-10-30 16:59:18: [2024-10-30 16:59:18] iter = 15820, loss = 1.8900
2024-10-30 16:59:22: [2024-10-30 16:59:22] iter = 15830, loss = 3.3965
2024-10-30 16:59:26: [2024-10-30 16:59:26] iter = 15840, loss = 2.3152
2024-10-30 16:59:30: [2024-10-30 16:59:30] iter = 15850, loss = 2.1993
2024-10-30 16:59:34: [2024-10-30 16:59:34] iter = 15860, loss = 1.9088
2024-10-30 16:59:39: [2024-10-30 16:59:39] iter = 15870, loss = 2.0345
2024-10-30 16:59:43: [2024-10-30 16:59:43] iter = 15880, loss = 2.8043
2024-10-30 16:59:47: [2024-10-30 16:59:47] iter = 15890, loss = 2.1102
2024-10-30 16:59:52: [2024-10-30 16:59:52] iter = 15900, loss = 1.9811
2024-10-30 16:59:56: [2024-10-30 16:59:56] iter = 15910, loss = 2.5044
2024-10-30 16:59:59: [2024-10-30 16:59:59] iter = 15920, loss = 3.0921
2024-10-30 17:00:02: [2024-10-30 17:00:02] iter = 15930, loss = 2.8862
2024-10-30 17:00:06: [2024-10-30 17:00:06] iter = 15940, loss = 2.1162
2024-10-30 17:00:10: [2024-10-30 17:00:10] iter = 15950, loss = 2.4471
2024-10-30 17:00:13: [2024-10-30 17:00:13] iter = 15960, loss = 1.8007
2024-10-30 17:00:17: [2024-10-30 17:00:17] iter = 15970, loss = 1.8494
2024-10-30 17:00:20: [2024-10-30 17:00:20] iter = 15980, loss = 1.6190
2024-10-30 17:00:24: [2024-10-30 17:00:24] iter = 15990, loss = 2.4801
2024-10-30 17:00:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 17:00:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:00:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 27892}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/organsmnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/organsmnist.npz
Loaded the dataset:OrganSMNIST
[2024-10-30 14:58:12] Evaluate_00: epoch = 1000 train time = 37 s train loss = 0.003316 train acc = 1.0000, test acc = 0.4663, test_sen =0.4519, test_spe =0.9460, test_f1 =0.4412
[2024-10-30 14:58:46] Evaluate_01: epoch = 1000 train time = 32 s train loss = 0.008324 train acc = 1.0000, test acc = 0.4739, test_sen =0.4627, test_spe =0.9468, test_f1 =0.4466
[2024-10-30 14:59:19] Evaluate_02: epoch = 1000 train time = 31 s train loss = 0.013763 train acc = 1.0000, test acc = 0.4587, test_sen =0.4572, test_spe =0.9454, test_f1 =0.4409
[2024-10-30 14:59:52] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.024726 train acc = 1.0000, test acc = 0.4662, test_sen =0.4544, test_spe =0.9460, test_f1 =0.4409
[2024-10-30 15:00:25] Evaluate_04: epoch = 1000 train time = 31 s train loss = 0.017063 train acc = 1.0000, test acc = 0.4707, test_sen =0.4539, test_spe =0.9464, test_f1 =0.4440
[2024-10-30 15:13:21] Evaluate_00: epoch = 1000 train time = 34 s train loss = 0.009251 train acc = 1.0000, test acc = 0.6063, test_sen =0.5830, test_spe =0.9600, test_f1 =0.5703
[2024-10-30 15:13:44] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.042094 train acc = 0.9909, test acc = 0.6181, test_sen =0.5873, test_spe =0.9612, test_f1 =0.5745
[2024-10-30 15:14:10] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.036811 train acc = 1.0000, test acc = 0.6059, test_sen =0.5835, test_spe =0.9602, test_f1 =0.5693
[2024-10-30 15:14:34] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.007879 train acc = 1.0000, test acc = 0.6112, test_sen =0.5866, test_spe =0.9607, test_f1 =0.5729
[2024-10-30 15:15:04] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.007623 train acc = 1.0000, test acc = 0.6164, test_sen =0.5858, test_spe =0.9611, test_f1 =0.5768
[2024-10-30 15:27:31] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.026539 train acc = 1.0000, test acc = 0.6017, test_sen =0.5831, test_spe =0.9594, test_f1 =0.5738
[2024-10-30 15:27:59] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.011159 train acc = 1.0000, test acc = 0.6031, test_sen =0.5852, test_spe =0.9596, test_f1 =0.5758
[2024-10-30 15:28:27] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.009415 train acc = 1.0000, test acc = 0.6038, test_sen =0.5853, test_spe =0.9597, test_f1 =0.5759
[2024-10-30 15:28:53] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.039275 train acc = 1.0000, test acc = 0.6000, test_sen =0.5837, test_spe =0.9593, test_f1 =0.5739
[2024-10-30 15:29:21] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.056364 train acc = 0.9909, test acc = 0.6087, test_sen =0.5880, test_spe =0.9601, test_f1 =0.5837
[2024-10-30 15:43:51] Evaluate_00: epoch = 1000 train time = 33 s train loss = 0.008900 train acc = 1.0000, test acc = 0.6071, test_sen =0.5899, test_spe =0.9600, test_f1 =0.5825
[2024-10-30 15:44:20] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.059302 train acc = 0.9909, test acc = 0.6028, test_sen =0.5867, test_spe =0.9594, test_f1 =0.5781
[2024-10-30 15:44:51] Evaluate_02: epoch = 1000 train time = 29 s train loss = 0.046563 train acc = 1.0000, test acc = 0.6070, test_sen =0.5833, test_spe =0.9597, test_f1 =0.5765
[2024-10-30 15:45:24] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.021752 train acc = 1.0000, test acc = 0.6123, test_sen =0.5882, test_spe =0.9603, test_f1 =0.5819
[2024-10-30 15:45:53] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.078651 train acc = 0.9818, test acc = 0.6098, test_sen =0.5891, test_spe =0.9602, test_f1 =0.5815
[2024-10-30 16:00:05] Evaluate_00: epoch = 1000 train time = 33 s train loss = 0.052338 train acc = 1.0000, test acc = 0.6226, test_sen =0.6013, test_spe =0.9618, test_f1 =0.5912
[2024-10-30 16:00:35] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.043229 train acc = 1.0000, test acc = 0.6252, test_sen =0.6020, test_spe =0.9620, test_f1 =0.5940
[2024-10-30 16:01:05] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.010103 train acc = 1.0000, test acc = 0.6179, test_sen =0.5919, test_spe =0.9612, test_f1 =0.5836
[2024-10-30 16:01:37] Evaluate_03: epoch = 1000 train time = 31 s train loss = 0.069668 train acc = 0.9909, test acc = 0.6248, test_sen =0.6027, test_spe =0.9620, test_f1 =0.5956
[2024-10-30 16:02:11] Evaluate_04: epoch = 1000 train time = 32 s train loss = 0.056920 train acc = 0.9909, test acc = 0.6264, test_sen =0.6003, test_spe =0.9621, test_f1 =0.5913
[2024-10-30 16:16:21] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.051126 train acc = 1.0000, test acc = 0.6190, test_sen =0.5914, test_spe =0.9610, test_f1 =0.5901
[2024-10-30 16:16:51] Evaluate_01: epoch = 1000 train time = 29 s train loss = 0.011674 train acc = 1.0000, test acc = 0.6177, test_sen =0.5975, test_spe =0.9610, test_f1 =0.5910
[2024-10-30 16:17:25] Evaluate_02: epoch = 1000 train time = 32 s train loss = 0.078255 train acc = 0.9818, test acc = 0.6203, test_sen =0.5894, test_spe =0.9609, test_f1 =0.5871
[2024-10-30 16:17:54] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.007240 train acc = 1.0000, test acc = 0.6105, test_sen =0.5935, test_spe =0.9602, test_f1 =0.5881
[2024-10-30 16:18:25] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.056396 train acc = 1.0000, test acc = 0.6061, test_sen =0.5883, test_spe =0.9598, test_f1 =0.5806
[2024-10-30 16:30:57] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.006615 train acc = 1.0000, test acc = 0.6061, test_sen =0.5850, test_spe =0.9599, test_f1 =0.5761
[2024-10-30 16:31:26] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.035874 train acc = 1.0000, test acc = 0.6171, test_sen =0.5923, test_spe =0.9608, test_f1 =0.5867
[2024-10-30 16:31:54] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.028628 train acc = 1.0000, test acc = 0.6199, test_sen =0.5971, test_spe =0.9611, test_f1 =0.5908
[2024-10-30 16:32:25] Evaluate_03: epoch = 1000 train time = 30 s train loss = 0.024818 train acc = 1.0000, test acc = 0.6101, test_sen =0.5849, test_spe =0.9602, test_f1 =0.5726
[2024-10-30 16:32:51] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.086665 train acc = 0.9909, test acc = 0.6104, test_sen =0.5859, test_spe =0.9602, test_f1 =0.5774
[2024-10-30 16:46:22] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.056669 train acc = 1.0000, test acc = 0.6131, test_sen =0.5915, test_spe =0.9604, test_f1 =0.5828
[2024-10-30 16:46:49] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.042962 train acc = 1.0000, test acc = 0.6124, test_sen =0.5995, test_spe =0.9605, test_f1 =0.5875
[2024-10-30 16:47:17] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.068889 train acc = 1.0000, test acc = 0.6174, test_sen =0.5981, test_spe =0.9610, test_f1 =0.5872
[2024-10-30 16:47:46] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.040742 train acc = 1.0000, test acc = 0.6076, test_sen =0.5949, test_spe =0.9600, test_f1 =0.5846
[2024-10-30 16:48:15] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.007790 train acc = 1.0000, test acc = 0.6092, test_sen =0.5909, test_spe =0.9600, test_f1 =0.5833
[2024-10-30 17:00:56] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.011173 train acc = 1.0000, test acc = 0.6106, test_sen =0.5943, test_spe =0.9605, test_f1 =0.5875
[2024-10-30 17:01:25] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.007757 train acc = 1.0000, test acc = 0.5908, test_sen =0.5791, test_spe =0.9586, test_f1 =0.5700
[2024-10-30 17:01:55] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.043696 train acc = 1.0000, test acc = 0.6090, test_sen =0.5961, test_spe =0.9605, test_f1 =0.5879
[2024-10-30 17:02:32] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.023735 train acc = 1.0000, test acc = 0.6047, test_sen =0.5915, test_spe =0.9600, test_f1 =0.5855
[2024-10-30 17:03:01] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.008145 train acc = 1.0000, test acc = 0.5934, test_sen =0.5832, test_spe =0.9590, test_f1 =0.5738/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:03:01: Evaluate 5 random ConvNet, ACCmean = 0.6017 ACCstd = 0.0081
-------------------------
2024-10-30 17:03:01: Evaluate 5 random ConvNet, SENmean = 0.5888 SENstd = 0.0066
-------------------------
2024-10-30 17:03:01: Evaluate 5 random ConvNet, SPEmean = 0.9597 SPEstd = 0.0008
-------------------------
2024-10-30 17:03:01: Evaluate 5 random ConvNet, F!mean = 0.5809 F!std = 0.0075
-------------------------
2024-10-30 17:03:01: Evaluate 5 random ConvNet, mean = 0.6017 std = 0.0081
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:03:02: [2024-10-30 17:03:02] iter = 16000, loss = 2.4172
2024-10-30 17:03:06: [2024-10-30 17:03:06] iter = 16010, loss = 2.4388
2024-10-30 17:03:09: [2024-10-30 17:03:09] iter = 16020, loss = 1.6093
2024-10-30 17:03:12: [2024-10-30 17:03:12] iter = 16030, loss = 1.9036
2024-10-30 17:03:15: [2024-10-30 17:03:15] iter = 16040, loss = 2.3514
2024-10-30 17:03:19: [2024-10-30 17:03:19] iter = 16050, loss = 2.4353
2024-10-30 17:03:24: [2024-10-30 17:03:24] iter = 16060, loss = 2.4990
2024-10-30 17:03:28: [2024-10-30 17:03:28] iter = 16070, loss = 2.9507
2024-10-30 17:03:33: [2024-10-30 17:03:33] iter = 16080, loss = 2.4635
2024-10-30 17:03:39: [2024-10-30 17:03:39] iter = 16090, loss = 1.8379
2024-10-30 17:03:43: [2024-10-30 17:03:43] iter = 16100, loss = 3.3569
2024-10-30 17:03:46: [2024-10-30 17:03:46] iter = 16110, loss = 2.1102
2024-10-30 17:03:50: [2024-10-30 17:03:50] iter = 16120, loss = 2.0425
2024-10-30 17:03:54: [2024-10-30 17:03:54] iter = 16130, loss = 2.3231
2024-10-30 17:03:58: [2024-10-30 17:03:58] iter = 16140, loss = 2.2746
2024-10-30 17:04:02: [2024-10-30 17:04:02] iter = 16150, loss = 4.0974
2024-10-30 17:04:05: [2024-10-30 17:04:05] iter = 16160, loss = 2.2250
2024-10-30 17:04:09: [2024-10-30 17:04:09] iter = 16170, loss = 2.0386
2024-10-30 17:04:13: [2024-10-30 17:04:13] iter = 16180, loss = 2.1017
2024-10-30 17:04:17: [2024-10-30 17:04:17] iter = 16190, loss = 3.5271
2024-10-30 17:04:21: [2024-10-30 17:04:21] iter = 16200, loss = 2.3312
2024-10-30 17:04:24: [2024-10-30 17:04:24] iter = 16210, loss = 2.0845
2024-10-30 17:04:27: [2024-10-30 17:04:27] iter = 16220, loss = 2.1795
2024-10-30 17:04:31: [2024-10-30 17:04:31] iter = 16230, loss = 2.1642
2024-10-30 17:04:34: [2024-10-30 17:04:34] iter = 16240, loss = 2.0053
2024-10-30 17:04:38: [2024-10-30 17:04:38] iter = 16250, loss = 2.0394
2024-10-30 17:04:42: [2024-10-30 17:04:42] iter = 16260, loss = 2.2121
2024-10-30 17:04:45: [2024-10-30 17:04:45] iter = 16270, loss = 2.4601
2024-10-30 17:04:49: [2024-10-30 17:04:49] iter = 16280, loss = 1.9604
2024-10-30 17:04:52: [2024-10-30 17:04:52] iter = 16290, loss = 1.9650
2024-10-30 17:04:55: [2024-10-30 17:04:55] iter = 16300, loss = 2.0519
2024-10-30 17:04:59: [2024-10-30 17:04:59] iter = 16310, loss = 2.5048
2024-10-30 17:05:03: [2024-10-30 17:05:03] iter = 16320, loss = 2.1845
2024-10-30 17:05:07: [2024-10-30 17:05:07] iter = 16330, loss = 2.3168
2024-10-30 17:05:11: [2024-10-30 17:05:11] iter = 16340, loss = 2.0980
2024-10-30 17:05:15: [2024-10-30 17:05:15] iter = 16350, loss = 1.9086
2024-10-30 17:05:20: [2024-10-30 17:05:20] iter = 16360, loss = 2.3997
2024-10-30 17:05:24: [2024-10-30 17:05:24] iter = 16370, loss = 3.2450
2024-10-30 17:05:29: [2024-10-30 17:05:29] iter = 16380, loss = 2.2389
2024-10-30 17:05:33: [2024-10-30 17:05:33] iter = 16390, loss = 2.3776
2024-10-30 17:05:37: [2024-10-30 17:05:37] iter = 16400, loss = 1.9231
2024-10-30 17:05:41: [2024-10-30 17:05:41] iter = 16410, loss = 2.1669
2024-10-30 17:05:46: [2024-10-30 17:05:46] iter = 16420, loss = 2.1807
2024-10-30 17:05:50: [2024-10-30 17:05:50] iter = 16430, loss = 2.2040
2024-10-30 17:05:54: [2024-10-30 17:05:54] iter = 16440, loss = 1.8629
2024-10-30 17:05:58: [2024-10-30 17:05:58] iter = 16450, loss = 2.3255
2024-10-30 17:06:02: [2024-10-30 17:06:02] iter = 16460, loss = 2.0742
2024-10-30 17:06:05: [2024-10-30 17:06:05] iter = 16470, loss = 2.7500
2024-10-30 17:06:09: [2024-10-30 17:06:09] iter = 16480, loss = 2.1418
2024-10-30 17:06:14: [2024-10-30 17:06:14] iter = 16490, loss = 1.7342
2024-10-30 17:06:18: [2024-10-30 17:06:18] iter = 16500, loss = 2.2707
2024-10-30 17:06:23: [2024-10-30 17:06:23] iter = 16510, loss = 2.4601
2024-10-30 17:06:27: [2024-10-30 17:06:27] iter = 16520, loss = 2.0354
2024-10-30 17:06:30: [2024-10-30 17:06:30] iter = 16530, loss = 1.9206
2024-10-30 17:06:35: [2024-10-30 17:06:35] iter = 16540, loss = 2.2694
2024-10-30 17:06:39: [2024-10-30 17:06:39] iter = 16550, loss = 2.1485
2024-10-30 17:06:43: [2024-10-30 17:06:43] iter = 16560, loss = 2.4973
2024-10-30 17:06:47: [2024-10-30 17:06:47] iter = 16570, loss = 2.1812
2024-10-30 17:06:51: [2024-10-30 17:06:51] iter = 16580, loss = 2.0854
2024-10-30 17:06:55: [2024-10-30 17:06:55] iter = 16590, loss = 2.4753
2024-10-30 17:06:59: [2024-10-30 17:06:59] iter = 16600, loss = 1.8405
2024-10-30 17:07:03: [2024-10-30 17:07:03] iter = 16610, loss = 3.6767
2024-10-30 17:07:06: [2024-10-30 17:07:06] iter = 16620, loss = 2.0599
2024-10-30 17:07:09: [2024-10-30 17:07:09] iter = 16630, loss = 3.1807
2024-10-30 17:07:12: [2024-10-30 17:07:12] iter = 16640, loss = 2.3126
2024-10-30 17:07:15: [2024-10-30 17:07:15] iter = 16650, loss = 2.0862
2024-10-30 17:07:20: [2024-10-30 17:07:20] iter = 16660, loss = 1.9845
2024-10-30 17:07:23: [2024-10-30 17:07:23] iter = 16670, loss = 2.4472
2024-10-30 17:07:27: [2024-10-30 17:07:27] iter = 16680, loss = 2.4284
2024-10-30 17:07:30: [2024-10-30 17:07:30] iter = 16690, loss = 2.2949
2024-10-30 17:07:33: [2024-10-30 17:07:33] iter = 16700, loss = 2.1064
2024-10-30 17:07:36: [2024-10-30 17:07:36] iter = 16710, loss = 2.0965
2024-10-30 17:07:40: [2024-10-30 17:07:40] iter = 16720, loss = 2.3510
2024-10-30 17:07:44: [2024-10-30 17:07:44] iter = 16730, loss = 1.8809
2024-10-30 17:07:48: [2024-10-30 17:07:48] iter = 16740, loss = 2.2785
2024-10-30 17:07:53: [2024-10-30 17:07:53] iter = 16750, loss = 3.1156
2024-10-30 17:07:57: [2024-10-30 17:07:57] iter = 16760, loss = 1.9767
2024-10-30 17:08:00: [2024-10-30 17:08:00] iter = 16770, loss = 2.7461
2024-10-30 17:08:04: [2024-10-30 17:08:04] iter = 16780, loss = 2.2141
2024-10-30 17:08:08: [2024-10-30 17:08:08] iter = 16790, loss = 1.6760
2024-10-30 17:08:13: [2024-10-30 17:08:13] iter = 16800, loss = 3.1856
2024-10-30 17:08:17: [2024-10-30 17:08:17] iter = 16810, loss = 1.9281
2024-10-30 17:08:22: [2024-10-30 17:08:22] iter = 16820, loss = 2.4176
2024-10-30 17:08:26: [2024-10-30 17:08:26] iter = 16830, loss = 2.6841
2024-10-30 17:08:30: [2024-10-30 17:08:30] iter = 16840, loss = 2.0627
2024-10-30 17:08:33: [2024-10-30 17:08:33] iter = 16850, loss = 3.1039
2024-10-30 17:08:38: [2024-10-30 17:08:38] iter = 16860, loss = 2.5024
2024-10-30 17:08:41: [2024-10-30 17:08:41] iter = 16870, loss = 2.0062
2024-10-30 17:08:45: [2024-10-30 17:08:45] iter = 16880, loss = 3.2774
2024-10-30 17:08:48: [2024-10-30 17:08:48] iter = 16890, loss = 1.8955
2024-10-30 17:08:52: [2024-10-30 17:08:52] iter = 16900, loss = 2.9495
2024-10-30 17:08:56: [2024-10-30 17:08:56] iter = 16910, loss = 2.0068
2024-10-30 17:08:59: [2024-10-30 17:08:59] iter = 16920, loss = 2.1750
2024-10-30 17:09:03: [2024-10-30 17:09:03] iter = 16930, loss = 2.0161
2024-10-30 17:09:08: [2024-10-30 17:09:08] iter = 16940, loss = 2.6229
2024-10-30 17:09:12: [2024-10-30 17:09:12] iter = 16950, loss = 2.4983
2024-10-30 17:09:15: [2024-10-30 17:09:15] iter = 16960, loss = 2.1624
2024-10-30 17:09:19: [2024-10-30 17:09:19] iter = 16970, loss = 2.9782
2024-10-30 17:09:23: [2024-10-30 17:09:23] iter = 16980, loss = 2.3030
2024-10-30 17:09:27: [2024-10-30 17:09:27] iter = 16990, loss = 2.0044
2024-10-30 17:09:31: [2024-10-30 17:09:31] iter = 17000, loss = 1.8838
2024-10-30 17:09:35: [2024-10-30 17:09:35] iter = 17010, loss = 2.5900
2024-10-30 17:09:39: [2024-10-30 17:09:39] iter = 17020, loss = 2.5558
2024-10-30 17:09:43: [2024-10-30 17:09:43] iter = 17030, loss = 1.9117
2024-10-30 17:09:47: [2024-10-30 17:09:47] iter = 17040, loss = 2.2373
2024-10-30 17:09:50: [2024-10-30 17:09:50] iter = 17050, loss = 2.4370
2024-10-30 17:09:54: [2024-10-30 17:09:54] iter = 17060, loss = 2.0011
2024-10-30 17:09:57: [2024-10-30 17:09:57] iter = 17070, loss = 2.1321
2024-10-30 17:09:59: [2024-10-30 17:09:59] iter = 17080, loss = 2.7427
2024-10-30 17:10:02: [2024-10-30 17:10:02] iter = 17090, loss = 2.3450
2024-10-30 17:10:06: [2024-10-30 17:10:06] iter = 17100, loss = 2.0444
2024-10-30 17:10:11: [2024-10-30 17:10:11] iter = 17110, loss = 2.0238
2024-10-30 17:10:16: [2024-10-30 17:10:16] iter = 17120, loss = 1.8622
2024-10-30 17:10:20: [2024-10-30 17:10:20] iter = 17130, loss = 2.2971
2024-10-30 17:10:24: [2024-10-30 17:10:24] iter = 17140, loss = 2.2084
2024-10-30 17:10:28: [2024-10-30 17:10:28] iter = 17150, loss = 2.0565
2024-10-30 17:10:32: [2024-10-30 17:10:32] iter = 17160, loss = 2.2328
2024-10-30 17:10:34: [2024-10-30 17:10:34] iter = 17170, loss = 2.4533
2024-10-30 17:10:38: [2024-10-30 17:10:38] iter = 17180, loss = 2.0833
2024-10-30 17:10:42: [2024-10-30 17:10:42] iter = 17190, loss = 2.2503
2024-10-30 17:10:45: [2024-10-30 17:10:45] iter = 17200, loss = 3.0040
2024-10-30 17:10:49: [2024-10-30 17:10:49] iter = 17210, loss = 2.2902
2024-10-30 17:10:53: [2024-10-30 17:10:53] iter = 17220, loss = 1.8290
2024-10-30 17:10:58: [2024-10-30 17:10:58] iter = 17230, loss = 1.9403
2024-10-30 17:11:02: [2024-10-30 17:11:02] iter = 17240, loss = 1.9950
2024-10-30 17:11:05: [2024-10-30 17:11:04] iter = 17250, loss = 2.4529
2024-10-30 17:11:09: [2024-10-30 17:11:09] iter = 17260, loss = 3.3784
2024-10-30 17:11:12: [2024-10-30 17:11:12] iter = 17270, loss = 4.3340
2024-10-30 17:11:16: [2024-10-30 17:11:16] iter = 17280, loss = 2.0051
2024-10-30 17:11:20: [2024-10-30 17:11:20] iter = 17290, loss = 2.9797
2024-10-30 17:11:24: [2024-10-30 17:11:24] iter = 17300, loss = 2.8010
2024-10-30 17:11:28: [2024-10-30 17:11:28] iter = 17310, loss = 2.1380
2024-10-30 17:11:32: [2024-10-30 17:11:32] iter = 17320, loss = 1.9396
2024-10-30 17:11:36: [2024-10-30 17:11:36] iter = 17330, loss = 3.2346
2024-10-30 17:11:39: [2024-10-30 17:11:39] iter = 17340, loss = 3.3052
2024-10-30 17:11:44: [2024-10-30 17:11:44] iter = 17350, loss = 2.0838
2024-10-30 17:11:47: [2024-10-30 17:11:47] iter = 17360, loss = 1.8655
2024-10-30 17:11:51: [2024-10-30 17:11:51] iter = 17370, loss = 2.8860
2024-10-30 17:11:54: [2024-10-30 17:11:54] iter = 17380, loss = 2.8396
2024-10-30 17:11:58: [2024-10-30 17:11:58] iter = 17390, loss = 2.3029
2024-10-30 17:12:02: [2024-10-30 17:12:02] iter = 17400, loss = 2.2180
2024-10-30 17:12:05: [2024-10-30 17:12:05] iter = 17410, loss = 1.9006
2024-10-30 17:12:09: [2024-10-30 17:12:09] iter = 17420, loss = 2.5221
2024-10-30 17:12:13: [2024-10-30 17:12:13] iter = 17430, loss = 1.8359
2024-10-30 17:12:16: [2024-10-30 17:12:16] iter = 17440, loss = 2.2109
2024-10-30 17:12:20: [2024-10-30 17:12:20] iter = 17450, loss = 1.7545
2024-10-30 17:12:24: [2024-10-30 17:12:24] iter = 17460, loss = 2.2347
2024-10-30 17:12:28: [2024-10-30 17:12:28] iter = 17470, loss = 1.8266
2024-10-30 17:12:31: [2024-10-30 17:12:31] iter = 17480, loss = 3.9452
2024-10-30 17:12:35: [2024-10-30 17:12:35] iter = 17490, loss = 2.0935
2024-10-30 17:12:39: [2024-10-30 17:12:39] iter = 17500, loss = 1.9295
2024-10-30 17:12:43: [2024-10-30 17:12:43] iter = 17510, loss = 1.9725
2024-10-30 17:12:46: [2024-10-30 17:12:46] iter = 17520, loss = 3.9022
2024-10-30 17:12:49: [2024-10-30 17:12:49] iter = 17530, loss = 2.1383
2024-10-30 17:12:52: [2024-10-30 17:12:52] iter = 17540, loss = 2.0142
2024-10-30 17:12:56: [2024-10-30 17:12:56] iter = 17550, loss = 2.1944
2024-10-30 17:13:00: [2024-10-30 17:13:00] iter = 17560, loss = 2.8995
2024-10-30 17:13:04: [2024-10-30 17:13:04] iter = 17570, loss = 2.1322
2024-10-30 17:13:09: [2024-10-30 17:13:09] iter = 17580, loss = 2.2950
2024-10-30 17:13:13: [2024-10-30 17:13:13] iter = 17590, loss = 1.7879
2024-10-30 17:13:17: [2024-10-30 17:13:17] iter = 17600, loss = 2.5657
2024-10-30 17:13:21: [2024-10-30 17:13:21] iter = 17610, loss = 1.8135
2024-10-30 17:13:23: [2024-10-30 17:13:23] iter = 17620, loss = 2.5595
2024-10-30 17:13:27: [2024-10-30 17:13:27] iter = 17630, loss = 2.4230
2024-10-30 17:13:31: [2024-10-30 17:13:31] iter = 17640, loss = 2.4739
2024-10-30 17:13:35: [2024-10-30 17:13:35] iter = 17650, loss = 1.8385
2024-10-30 17:13:39: [2024-10-30 17:13:39] iter = 17660, loss = 2.1948
2024-10-30 17:13:43: [2024-10-30 17:13:43] iter = 17670, loss = 1.9270
2024-10-30 17:13:46: [2024-10-30 17:13:46] iter = 17680, loss = 2.0389
2024-10-30 17:13:50: [2024-10-30 17:13:50] iter = 17690, loss = 2.5653
2024-10-30 17:13:54: [2024-10-30 17:13:54] iter = 17700, loss = 2.0808
2024-10-30 17:13:59: [2024-10-30 17:13:59] iter = 17710, loss = 1.7097
2024-10-30 17:14:03: [2024-10-30 17:14:03] iter = 17720, loss = 1.6346
2024-10-30 17:14:06: [2024-10-30 17:14:06] iter = 17730, loss = 2.8109
2024-10-30 17:14:10: [2024-10-30 17:14:10] iter = 17740, loss = 1.8472
2024-10-30 17:14:13: [2024-10-30 17:14:13] iter = 17750, loss = 2.2515
2024-10-30 17:14:17: [2024-10-30 17:14:17] iter = 17760, loss = 2.4199
2024-10-30 17:14:21: [2024-10-30 17:14:21] iter = 17770, loss = 2.8398
2024-10-30 17:14:25: [2024-10-30 17:14:25] iter = 17780, loss = 1.9822
2024-10-30 17:14:30: [2024-10-30 17:14:30] iter = 17790, loss = 1.7256
2024-10-30 17:14:34: [2024-10-30 17:14:34] iter = 17800, loss = 1.8231
2024-10-30 17:14:38: [2024-10-30 17:14:38] iter = 17810, loss = 1.9204
2024-10-30 17:14:41: [2024-10-30 17:14:41] iter = 17820, loss = 2.0049
2024-10-30 17:14:44: [2024-10-30 17:14:44] iter = 17830, loss = 1.8467
2024-10-30 17:14:48: [2024-10-30 17:14:48] iter = 17840, loss = 2.0139
2024-10-30 17:14:52: [2024-10-30 17:14:52] iter = 17850, loss = 2.9696
2024-10-30 17:14:56: [2024-10-30 17:14:56] iter = 17860, loss = 2.1221
2024-10-30 17:15:00: [2024-10-30 17:15:00] iter = 17870, loss = 2.4511
2024-10-30 17:15:03: [2024-10-30 17:15:03] iter = 17880, loss = 2.5006
2024-10-30 17:15:07: [2024-10-30 17:15:07] iter = 17890, loss = 2.1335
2024-10-30 17:15:11: [2024-10-30 17:15:11] iter = 17900, loss = 2.3353
2024-10-30 17:15:15: [2024-10-30 17:15:15] iter = 17910, loss = 2.5456
2024-10-30 17:15:19: [2024-10-30 17:15:19] iter = 17920, loss = 2.1280
2024-10-30 17:15:23: [2024-10-30 17:15:23] iter = 17930, loss = 4.1495
2024-10-30 17:15:27: [2024-10-30 17:15:27] iter = 17940, loss = 2.2332
2024-10-30 17:15:32: [2024-10-30 17:15:32] iter = 17950, loss = 2.5060
2024-10-30 17:15:36: [2024-10-30 17:15:36] iter = 17960, loss = 2.4685
2024-10-30 17:15:40: [2024-10-30 17:15:40] iter = 17970, loss = 1.9988
2024-10-30 17:15:43: [2024-10-30 17:15:43] iter = 17980, loss = 1.7789
2024-10-30 17:15:48: [2024-10-30 17:15:48] iter = 17990, loss = 1.9744
2024-10-30 17:15:51: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 17:15:51: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:15:51: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 51635}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:18:15: Evaluate 5 random ConvNet, ACCmean = 0.6011 ACCstd = 0.0051
-------------------------
2024-10-30 17:18:15: Evaluate 5 random ConvNet, SENmean = 0.5888 SENstd = 0.0043
-------------------------
2024-10-30 17:18:15: Evaluate 5 random ConvNet, SPEmean = 0.9594 SPEstd = 0.0005
-------------------------
2024-10-30 17:18:15: Evaluate 5 random ConvNet, F!mean = 0.5749 F!std = 0.0059
-------------------------
2024-10-30 17:18:15: Evaluate 5 random ConvNet, mean = 0.6011 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:18:16: [2024-10-30 17:18:16] iter = 18000, loss = 2.2441
2024-10-30 17:18:20: [2024-10-30 17:18:20] iter = 18010, loss = 2.1294
2024-10-30 17:18:24: [2024-10-30 17:18:24] iter = 18020, loss = 2.2152
2024-10-30 17:18:28: [2024-10-30 17:18:28] iter = 18030, loss = 1.8980
2024-10-30 17:18:33: [2024-10-30 17:18:33] iter = 18040, loss = 2.7229
2024-10-30 17:18:36: [2024-10-30 17:18:36] iter = 18050, loss = 2.1291
2024-10-30 17:18:40: [2024-10-30 17:18:40] iter = 18060, loss = 2.0112
2024-10-30 17:18:44: [2024-10-30 17:18:44] iter = 18070, loss = 2.2689
2024-10-30 17:18:49: [2024-10-30 17:18:49] iter = 18080, loss = 2.0379
2024-10-30 17:18:53: [2024-10-30 17:18:53] iter = 18090, loss = 2.8670
2024-10-30 17:18:57: [2024-10-30 17:18:57] iter = 18100, loss = 3.3052
2024-10-30 17:19:01: [2024-10-30 17:19:01] iter = 18110, loss = 2.0888
2024-10-30 17:19:05: [2024-10-30 17:19:05] iter = 18120, loss = 1.9620
2024-10-30 17:19:09: [2024-10-30 17:19:09] iter = 18130, loss = 2.2779
2024-10-30 17:19:13: [2024-10-30 17:19:13] iter = 18140, loss = 2.4918
2024-10-30 17:19:17: [2024-10-30 17:19:17] iter = 18150, loss = 3.3837
2024-10-30 17:19:20: [2024-10-30 17:19:20] iter = 18160, loss = 2.1277
2024-10-30 17:19:23: [2024-10-30 17:19:23] iter = 18170, loss = 2.0183
2024-10-30 17:19:27: [2024-10-30 17:19:27] iter = 18180, loss = 2.6805
2024-10-30 17:19:31: [2024-10-30 17:19:31] iter = 18190, loss = 1.8058
2024-10-30 17:19:35: [2024-10-30 17:19:35] iter = 18200, loss = 2.4220
2024-10-30 17:19:39: [2024-10-30 17:19:39] iter = 18210, loss = 2.6555
2024-10-30 17:19:43: [2024-10-30 17:19:43] iter = 18220, loss = 5.5181
2024-10-30 17:19:46: [2024-10-30 17:19:46] iter = 18230, loss = 6.5446
2024-10-30 17:19:51: [2024-10-30 17:19:50] iter = 18240, loss = 1.8785
2024-10-30 17:19:55: [2024-10-30 17:19:55] iter = 18250, loss = 1.9560
2024-10-30 17:19:59: [2024-10-30 17:19:59] iter = 18260, loss = 2.0655
2024-10-30 17:20:05: [2024-10-30 17:20:05] iter = 18270, loss = 2.0771
2024-10-30 17:20:09: [2024-10-30 17:20:09] iter = 18280, loss = 1.9778
2024-10-30 17:20:13: [2024-10-30 17:20:13] iter = 18290, loss = 2.2991
2024-10-30 17:20:16: [2024-10-30 17:20:16] iter = 18300, loss = 2.5751
2024-10-30 17:20:19: [2024-10-30 17:20:19] iter = 18310, loss = 1.9558
2024-10-30 17:20:21: [2024-10-30 17:20:21] iter = 18320, loss = 1.7291
2024-10-30 17:20:25: [2024-10-30 17:20:25] iter = 18330, loss = 2.1848
2024-10-30 17:20:29: [2024-10-30 17:20:29] iter = 18340, loss = 1.8830
2024-10-30 17:20:33: [2024-10-30 17:20:33] iter = 18350, loss = 1.9773
2024-10-30 17:20:37: [2024-10-30 17:20:37] iter = 18360, loss = 1.9304
2024-10-30 17:20:41: [2024-10-30 17:20:41] iter = 18370, loss = 2.0705
2024-10-30 17:20:45: [2024-10-30 17:20:45] iter = 18380, loss = 1.7076
2024-10-30 17:20:48: [2024-10-30 17:20:48] iter = 18390, loss = 2.6519
2024-10-30 17:20:52: [2024-10-30 17:20:52] iter = 18400, loss = 2.3020
2024-10-30 17:20:56: [2024-10-30 17:20:56] iter = 18410, loss = 1.9017
2024-10-30 17:21:00: [2024-10-30 17:21:00] iter = 18420, loss = 2.8182
2024-10-30 17:21:05: [2024-10-30 17:21:05] iter = 18430, loss = 2.9382
2024-10-30 17:21:08: [2024-10-30 17:21:08] iter = 18440, loss = 2.0249
2024-10-30 17:21:11: [2024-10-30 17:21:11] iter = 18450, loss = 3.0605
2024-10-30 17:21:15: [2024-10-30 17:21:15] iter = 18460, loss = 3.7798
2024-10-30 17:21:19: [2024-10-30 17:21:19] iter = 18470, loss = 2.0387
2024-10-30 17:21:23: [2024-10-30 17:21:23] iter = 18480, loss = 2.7349
2024-10-30 17:21:27: [2024-10-30 17:21:27] iter = 18490, loss = 2.9034
2024-10-30 17:21:30: [2024-10-30 17:21:30] iter = 18500, loss = 3.8362
2024-10-30 17:21:33: [2024-10-30 17:21:33] iter = 18510, loss = 2.7837
2024-10-30 17:21:37: [2024-10-30 17:21:37] iter = 18520, loss = 2.3076
2024-10-30 17:21:40: [2024-10-30 17:21:40] iter = 18530, loss = 2.1194
2024-10-30 17:21:44: [2024-10-30 17:21:44] iter = 18540, loss = 1.9077
2024-10-30 17:21:47: [2024-10-30 17:21:47] iter = 18550, loss = 1.9201
2024-10-30 17:21:51: [2024-10-30 17:21:51] iter = 18560, loss = 2.2138
2024-10-30 17:21:55: [2024-10-30 17:21:55] iter = 18570, loss = 2.4775
2024-10-30 17:21:59: [2024-10-30 17:21:59] iter = 18580, loss = 2.6553
2024-10-30 17:22:02: [2024-10-30 17:22:02] iter = 18590, loss = 1.9513
2024-10-30 17:22:06: [2024-10-30 17:22:06] iter = 18600, loss = 2.4568
2024-10-30 17:22:09: [2024-10-30 17:22:09] iter = 18610, loss = 3.4637
2024-10-30 17:22:12: [2024-10-30 17:22:12] iter = 18620, loss = 2.1010
2024-10-30 17:22:16: [2024-10-30 17:22:16] iter = 18630, loss = 2.1626
2024-10-30 17:22:21: [2024-10-30 17:22:21] iter = 18640, loss = 1.6954
2024-10-30 17:22:25: [2024-10-30 17:22:25] iter = 18650, loss = 1.8088
2024-10-30 17:22:28: [2024-10-30 17:22:28] iter = 18660, loss = 2.6229
2024-10-30 17:22:31: [2024-10-30 17:22:31] iter = 18670, loss = 2.0512
2024-10-30 17:22:35: [2024-10-30 17:22:35] iter = 18680, loss = 2.5847
2024-10-30 17:22:38: [2024-10-30 17:22:38] iter = 18690, loss = 3.8773
2024-10-30 17:22:41: [2024-10-30 17:22:41] iter = 18700, loss = 2.7200
2024-10-30 17:22:45: [2024-10-30 17:22:45] iter = 18710, loss = 2.8667
2024-10-30 17:22:49: [2024-10-30 17:22:49] iter = 18720, loss = 2.1665
2024-10-30 17:22:53: [2024-10-30 17:22:53] iter = 18730, loss = 2.8718
2024-10-30 17:22:57: [2024-10-30 17:22:57] iter = 18740, loss = 2.7359
2024-10-30 17:23:00: [2024-10-30 17:23:00] iter = 18750, loss = 2.0299
2024-10-30 17:23:03: [2024-10-30 17:23:03] iter = 18760, loss = 2.2328
2024-10-30 17:23:07: [2024-10-30 17:23:07] iter = 18770, loss = 1.9281
2024-10-30 17:23:10: [2024-10-30 17:23:10] iter = 18780, loss = 5.2688
2024-10-30 17:23:14: [2024-10-30 17:23:14] iter = 18790, loss = 2.1355
2024-10-30 17:23:19: [2024-10-30 17:23:19] iter = 18800, loss = 2.6855
2024-10-30 17:23:22: [2024-10-30 17:23:22] iter = 18810, loss = 3.3518
2024-10-30 17:23:26: [2024-10-30 17:23:26] iter = 18820, loss = 2.6397
2024-10-30 17:23:31: [2024-10-30 17:23:31] iter = 18830, loss = 2.3796
2024-10-30 17:23:34: [2024-10-30 17:23:34] iter = 18840, loss = 2.1947
2024-10-30 17:23:38: [2024-10-30 17:23:38] iter = 18850, loss = 2.1098
2024-10-30 17:23:42: [2024-10-30 17:23:42] iter = 18860, loss = 2.0886
2024-10-30 17:23:46: [2024-10-30 17:23:46] iter = 18870, loss = 2.6078
2024-10-30 17:23:50: [2024-10-30 17:23:50] iter = 18880, loss = 1.9651
2024-10-30 17:23:53: [2024-10-30 17:23:53] iter = 18890, loss = 2.1530
2024-10-30 17:23:58: [2024-10-30 17:23:58] iter = 18900, loss = 2.4374
2024-10-30 17:24:01: [2024-10-30 17:24:01] iter = 18910, loss = 2.1202
2024-10-30 17:24:05: [2024-10-30 17:24:05] iter = 18920, loss = 3.2461
2024-10-30 17:24:09: [2024-10-30 17:24:09] iter = 18930, loss = 2.4404
2024-10-30 17:24:13: [2024-10-30 17:24:13] iter = 18940, loss = 2.5936
2024-10-30 17:24:18: [2024-10-30 17:24:18] iter = 18950, loss = 2.7193
2024-10-30 17:24:23: [2024-10-30 17:24:23] iter = 18960, loss = 2.0236
2024-10-30 17:24:27: [2024-10-30 17:24:27] iter = 18970, loss = 2.6995
2024-10-30 17:24:32: [2024-10-30 17:24:32] iter = 18980, loss = 2.1626
2024-10-30 17:24:37: [2024-10-30 17:24:37] iter = 18990, loss = 2.1047
2024-10-30 17:24:41: [2024-10-30 17:24:41] iter = 19000, loss = 4.3124
2024-10-30 17:24:44: [2024-10-30 17:24:44] iter = 19010, loss = 1.9576
2024-10-30 17:24:49: [2024-10-30 17:24:49] iter = 19020, loss = 2.0176
2024-10-30 17:24:53: [2024-10-30 17:24:53] iter = 19030, loss = 2.3509
2024-10-30 17:24:57: [2024-10-30 17:24:57] iter = 19040, loss = 1.8447
2024-10-30 17:25:01: [2024-10-30 17:25:01] iter = 19050, loss = 2.2870
2024-10-30 17:25:04: [2024-10-30 17:25:04] iter = 19060, loss = 2.0948
2024-10-30 17:25:09: [2024-10-30 17:25:09] iter = 19070, loss = 1.9133
2024-10-30 17:25:13: [2024-10-30 17:25:13] iter = 19080, loss = 2.9060
2024-10-30 17:25:18: [2024-10-30 17:25:18] iter = 19090, loss = 1.6979
2024-10-30 17:25:21: [2024-10-30 17:25:21] iter = 19100, loss = 1.6985
2024-10-30 17:25:25: [2024-10-30 17:25:25] iter = 19110, loss = 2.2643
2024-10-30 17:25:29: [2024-10-30 17:25:29] iter = 19120, loss = 2.4485
2024-10-30 17:25:34: [2024-10-30 17:25:34] iter = 19130, loss = 2.3911
2024-10-30 17:25:38: [2024-10-30 17:25:38] iter = 19140, loss = 2.7335
2024-10-30 17:25:42: [2024-10-30 17:25:42] iter = 19150, loss = 2.1125
2024-10-30 17:25:46: [2024-10-30 17:25:46] iter = 19160, loss = 1.9632
2024-10-30 17:25:50: [2024-10-30 17:25:50] iter = 19170, loss = 2.2286
2024-10-30 17:25:54: [2024-10-30 17:25:54] iter = 19180, loss = 2.2841
2024-10-30 17:25:57: [2024-10-30 17:25:57] iter = 19190, loss = 2.1471
2024-10-30 17:26:02: [2024-10-30 17:26:02] iter = 19200, loss = 2.8558
2024-10-30 17:26:05: [2024-10-30 17:26:05] iter = 19210, loss = 1.8371
2024-10-30 17:26:09: [2024-10-30 17:26:09] iter = 19220, loss = 2.5679
2024-10-30 17:26:13: [2024-10-30 17:26:13] iter = 19230, loss = 1.8713
2024-10-30 17:26:17: [2024-10-30 17:26:17] iter = 19240, loss = 2.3377
2024-10-30 17:26:21: [2024-10-30 17:26:21] iter = 19250, loss = 1.8270
2024-10-30 17:26:25: [2024-10-30 17:26:25] iter = 19260, loss = 2.1599
2024-10-30 17:26:29: [2024-10-30 17:26:29] iter = 19270, loss = 2.4805
2024-10-30 17:26:33: [2024-10-30 17:26:33] iter = 19280, loss = 2.2412
2024-10-30 17:26:37: [2024-10-30 17:26:37] iter = 19290, loss = 2.0806
2024-10-30 17:26:42: [2024-10-30 17:26:42] iter = 19300, loss = 1.6810
2024-10-30 17:26:45: [2024-10-30 17:26:45] iter = 19310, loss = 2.4553
2024-10-30 17:26:49: [2024-10-30 17:26:49] iter = 19320, loss = 2.5837
2024-10-30 17:26:52: [2024-10-30 17:26:52] iter = 19330, loss = 1.8953
2024-10-30 17:26:55: [2024-10-30 17:26:55] iter = 19340, loss = 1.7664
2024-10-30 17:26:59: [2024-10-30 17:26:59] iter = 19350, loss = 2.1724
2024-10-30 17:27:03: [2024-10-30 17:27:03] iter = 19360, loss = 2.5683
2024-10-30 17:27:06: [2024-10-30 17:27:06] iter = 19370, loss = 1.9370
2024-10-30 17:27:11: [2024-10-30 17:27:11] iter = 19380, loss = 1.9750
2024-10-30 17:27:15: [2024-10-30 17:27:15] iter = 19390, loss = 2.5329
2024-10-30 17:27:20: [2024-10-30 17:27:20] iter = 19400, loss = 2.4051
2024-10-30 17:27:24: [2024-10-30 17:27:24] iter = 19410, loss = 4.8407
2024-10-30 17:27:28: [2024-10-30 17:27:28] iter = 19420, loss = 2.7841
2024-10-30 17:27:33: [2024-10-30 17:27:33] iter = 19430, loss = 2.1889
2024-10-30 17:27:36: [2024-10-30 17:27:36] iter = 19440, loss = 2.1336
2024-10-30 17:27:41: [2024-10-30 17:27:41] iter = 19450, loss = 1.8544
2024-10-30 17:27:44: [2024-10-30 17:27:44] iter = 19460, loss = 4.0814
2024-10-30 17:27:48: [2024-10-30 17:27:48] iter = 19470, loss = 2.1036
2024-10-30 17:27:51: [2024-10-30 17:27:51] iter = 19480, loss = 2.0920
2024-10-30 17:27:55: [2024-10-30 17:27:55] iter = 19490, loss = 2.4639
2024-10-30 17:27:59: [2024-10-30 17:27:59] iter = 19500, loss = 1.9151
2024-10-30 17:28:03: [2024-10-30 17:28:03] iter = 19510, loss = 2.3663
2024-10-30 17:28:06: [2024-10-30 17:28:06] iter = 19520, loss = 2.1495
2024-10-30 17:28:10: [2024-10-30 17:28:10] iter = 19530, loss = 2.1598
2024-10-30 17:28:13: [2024-10-30 17:28:13] iter = 19540, loss = 2.1819
2024-10-30 17:28:17: [2024-10-30 17:28:17] iter = 19550, loss = 2.2711
2024-10-30 17:28:21: [2024-10-30 17:28:21] iter = 19560, loss = 1.9766
2024-10-30 17:28:24: [2024-10-30 17:28:24] iter = 19570, loss = 3.1820
2024-10-30 17:28:29: [2024-10-30 17:28:29] iter = 19580, loss = 3.5838
2024-10-30 17:28:33: [2024-10-30 17:28:33] iter = 19590, loss = 1.9436
2024-10-30 17:28:37: [2024-10-30 17:28:37] iter = 19600, loss = 2.5784
2024-10-30 17:28:41: [2024-10-30 17:28:41] iter = 19610, loss = 2.3770
2024-10-30 17:28:44: [2024-10-30 17:28:44] iter = 19620, loss = 3.3596
2024-10-30 17:28:49: [2024-10-30 17:28:49] iter = 19630, loss = 1.8153
2024-10-30 17:28:52: [2024-10-30 17:28:52] iter = 19640, loss = 1.9038
2024-10-30 17:28:56: [2024-10-30 17:28:56] iter = 19650, loss = 2.1027
2024-10-30 17:29:00: [2024-10-30 17:29:00] iter = 19660, loss = 2.9665
2024-10-30 17:29:03: [2024-10-30 17:29:03] iter = 19670, loss = 2.2575
2024-10-30 17:29:08: [2024-10-30 17:29:08] iter = 19680, loss = 2.2059
2024-10-30 17:29:11: [2024-10-30 17:29:11] iter = 19690, loss = 2.4508
2024-10-30 17:29:15: [2024-10-30 17:29:15] iter = 19700, loss = 2.7598
2024-10-30 17:29:20: [2024-10-30 17:29:20] iter = 19710, loss = 2.5907
2024-10-30 17:29:24: [2024-10-30 17:29:24] iter = 19720, loss = 2.6790
2024-10-30 17:29:28: [2024-10-30 17:29:28] iter = 19730, loss = 2.8822
2024-10-30 17:29:32: [2024-10-30 17:29:32] iter = 19740, loss = 1.7193
2024-10-30 17:29:36: [2024-10-30 17:29:36] iter = 19750, loss = 2.7633
2024-10-30 17:29:40: [2024-10-30 17:29:40] iter = 19760, loss = 1.8921
2024-10-30 17:29:44: [2024-10-30 17:29:44] iter = 19770, loss = 2.1113
2024-10-30 17:29:48: [2024-10-30 17:29:48] iter = 19780, loss = 1.9885
2024-10-30 17:29:51: [2024-10-30 17:29:51] iter = 19790, loss = 2.6149
2024-10-30 17:29:55: [2024-10-30 17:29:55] iter = 19800, loss = 1.8897
2024-10-30 17:29:58: [2024-10-30 17:29:58] iter = 19810, loss = 4.0567
2024-10-30 17:30:02: [2024-10-30 17:30:02] iter = 19820, loss = 2.3025
2024-10-30 17:30:05: [2024-10-30 17:30:05] iter = 19830, loss = 2.0577
2024-10-30 17:30:10: [2024-10-30 17:30:10] iter = 19840, loss = 2.2902
2024-10-30 17:30:14: [2024-10-30 17:30:14] iter = 19850, loss = 2.0447
2024-10-30 17:30:17: [2024-10-30 17:30:17] iter = 19860, loss = 1.6907
2024-10-30 17:30:21: [2024-10-30 17:30:21] iter = 19870, loss = 2.1239
2024-10-30 17:30:24: [2024-10-30 17:30:24] iter = 19880, loss = 2.3160
2024-10-30 17:30:28: [2024-10-30 17:30:28] iter = 19890, loss = 1.8306
2024-10-30 17:30:32: [2024-10-30 17:30:32] iter = 19900, loss = 2.0486
2024-10-30 17:30:34: [2024-10-30 17:30:34] iter = 19910, loss = 2.7557
2024-10-30 17:30:38: [2024-10-30 17:30:38] iter = 19920, loss = 3.6601
2024-10-30 17:30:42: [2024-10-30 17:30:42] iter = 19930, loss = 2.6709
2024-10-30 17:30:46: [2024-10-30 17:30:46] iter = 19940, loss = 2.0612
2024-10-30 17:30:49: [2024-10-30 17:30:49] iter = 19950, loss = 1.7118
2024-10-30 17:30:53: [2024-10-30 17:30:53] iter = 19960, loss = 2.0844
2024-10-30 17:30:57: [2024-10-30 17:30:57] iter = 19970, loss = 1.9665
2024-10-30 17:31:01: [2024-10-30 17:31:01] iter = 19980, loss = 2.1671
2024-10-30 17:31:04: [2024-10-30 17:31:04] iter = 19990, loss = 3.9825
2024-10-30 17:31:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 17:31:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:31:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 68554}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:26: Evaluate 5 random ConvNet, ACCmean = 0.5964 ACCstd = 0.0019
-------------------------
2024-10-30 17:33:26: Evaluate 5 random ConvNet, SENmean = 0.5788 SENstd = 0.0027
-------------------------
2024-10-30 17:33:26: Evaluate 5 random ConvNet, SPEmean = 0.9589 SPEstd = 0.0002
-------------------------
2024-10-30 17:33:26: Evaluate 5 random ConvNet, F!mean = 0.5673 F!std = 0.0035
-------------------------
2024-10-30 17:33:26: Evaluate 5 random ConvNet, mean = 0.5964 std = 0.0019
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:27: [2024-10-30 17:33:27] iter = 20000, loss = 2.8915
2024-10-30 17:33:27: 
================== Exp 1 ==================
 
2024-10-30 17:33:27: Hyper-parameters: 
{'dataset': 'OrganSMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fa9b88fdb20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganSMNIST (INFO)>}
2024-10-30 17:33:27: Evaluation model pool: ['ConvNet']
2024-10-30 17:33:28: class c = 0: 1148 real images
2024-10-30 17:33:28: class c = 1: 630 real images
2024-10-30 17:33:28: class c = 2: 614 real images
2024-10-30 17:33:28: class c = 3: 721 real images
2024-10-30 17:33:28: class c = 4: 1132 real images
2024-10-30 17:33:28: class c = 5: 1119 real images
2024-10-30 17:33:28: class c = 6: 3464 real images
2024-10-30 17:33:28: class c = 7: 741 real images
2024-10-30 17:33:28: class c = 8: 803 real images
2024-10-30 17:33:28: class c = 9: 2004 real images
2024-10-30 17:33:28: class c = 10: 1556 real images
2024-10-30 17:33:28: real images channel 0, mean = 0.4953, std = 0.2826
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 17:33:28: initialize synthetic data from random real images
2024-10-30 17:33:28: [2024-10-30 17:33:28] training begins
2024-10-30 17:33:28: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 17:33:28: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:33:28: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 6980}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:44: Evaluate 5 random ConvNet, ACCmean = 0.4810 ACCstd = 0.0067
-------------------------
2024-10-30 17:35:44: Evaluate 5 random ConvNet, SENmean = 0.4730 SENstd = 0.0056
-------------------------
2024-10-30 17:35:44: Evaluate 5 random ConvNet, SPEmean = 0.9472 SPEstd = 0.0006
-------------------------
2024-10-30 17:35:44: Evaluate 5 random ConvNet, F!mean = 0.4590 F!std = 0.0056
-------------------------
2024-10-30 17:35:44: Evaluate 5 random ConvNet, mean = 0.4810 std = 0.0067
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:44: [2024-10-30 17:35:44] iter = 00000, loss = 13.4074
2024-10-30 17:35:48: [2024-10-30 17:35:48] iter = 00010, loss = 4.1886
2024-10-30 17:35:52: [2024-10-30 17:35:52] iter = 00020, loss = 3.4825
2024-10-30 17:35:56: [2024-10-30 17:35:56] iter = 00030, loss = 3.5255
2024-10-30 17:36:00: [2024-10-30 17:36:00] iter = 00040, loss = 3.2539
2024-10-30 17:36:04: [2024-10-30 17:36:04] iter = 00050, loss = 3.6537
2024-10-30 17:36:07: [2024-10-30 17:36:07] iter = 00060, loss = 2.6974
2024-10-30 17:36:11: [2024-10-30 17:36:11] iter = 00070, loss = 2.5557
2024-10-30 17:36:14: [2024-10-30 17:36:14] iter = 00080, loss = 2.7667
2024-10-30 17:36:17: [2024-10-30 17:36:17] iter = 00090, loss = 2.5491
2024-10-30 17:36:21: [2024-10-30 17:36:21] iter = 00100, loss = 2.5966
2024-10-30 17:36:25: [2024-10-30 17:36:25] iter = 00110, loss = 2.5303
2024-10-30 17:36:29: [2024-10-30 17:36:29] iter = 00120, loss = 3.7973
2024-10-30 17:36:33: [2024-10-30 17:36:33] iter = 00130, loss = 2.3198
2024-10-30 17:36:37: [2024-10-30 17:36:37] iter = 00140, loss = 2.3779
2024-10-30 17:36:41: [2024-10-30 17:36:41] iter = 00150, loss = 2.3670
2024-10-30 17:36:44: [2024-10-30 17:36:44] iter = 00160, loss = 2.7073
2024-10-30 17:36:46: [2024-10-30 17:36:46] iter = 00170, loss = 2.0631
2024-10-30 17:36:49: [2024-10-30 17:36:49] iter = 00180, loss = 2.6635
2024-10-30 17:36:53: [2024-10-30 17:36:53] iter = 00190, loss = 2.7906
2024-10-30 17:36:56: [2024-10-30 17:36:56] iter = 00200, loss = 2.5428
2024-10-30 17:36:59: [2024-10-30 17:36:59] iter = 00210, loss = 2.4972
2024-10-30 17:37:03: [2024-10-30 17:37:03] iter = 00220, loss = 3.4834
2024-10-30 17:37:06: [2024-10-30 17:37:06] iter = 00230, loss = 3.7375
2024-10-30 17:37:09: [2024-10-30 17:37:09] iter = 00240, loss = 3.1674
2024-10-30 17:37:12: [2024-10-30 17:37:12] iter = 00250, loss = 2.4820
2024-10-30 17:37:16: [2024-10-30 17:37:16] iter = 00260, loss = 2.6363
2024-10-30 17:37:19: [2024-10-30 17:37:19] iter = 00270, loss = 2.4522
2024-10-30 17:37:23: [2024-10-30 17:37:23] iter = 00280, loss = 2.3294
2024-10-30 17:37:27: [2024-10-30 17:37:27] iter = 00290, loss = 2.8375
2024-10-30 17:37:31: [2024-10-30 17:37:31] iter = 00300, loss = 2.4672
2024-10-30 17:37:34: [2024-10-30 17:37:34] iter = 00310, loss = 2.3435
2024-10-30 17:37:38: [2024-10-30 17:37:38] iter = 00320, loss = 2.6041
2024-10-30 17:37:42: [2024-10-30 17:37:42] iter = 00330, loss = 2.3040
2024-10-30 17:37:46: [2024-10-30 17:37:46] iter = 00340, loss = 2.2944
2024-10-30 17:37:50: [2024-10-30 17:37:50] iter = 00350, loss = 4.8615
2024-10-30 17:37:53: [2024-10-30 17:37:53] iter = 00360, loss = 2.4920
2024-10-30 17:37:58: [2024-10-30 17:37:58] iter = 00370, loss = 2.6078
2024-10-30 17:38:01: [2024-10-30 17:38:01] iter = 00380, loss = 2.5287
2024-10-30 17:38:05: [2024-10-30 17:38:05] iter = 00390, loss = 2.1969
2024-10-30 17:38:08: [2024-10-30 17:38:08] iter = 00400, loss = 2.7442
2024-10-30 17:38:12: [2024-10-30 17:38:12] iter = 00410, loss = 3.5552
2024-10-30 17:38:16: [2024-10-30 17:38:16] iter = 00420, loss = 2.5234
2024-10-30 17:38:20: [2024-10-30 17:38:20] iter = 00430, loss = 2.9092
2024-10-30 17:38:23: [2024-10-30 17:38:23] iter = 00440, loss = 3.1331
2024-10-30 17:38:26: [2024-10-30 17:38:26] iter = 00450, loss = 2.5615
2024-10-30 17:38:29: [2024-10-30 17:38:29] iter = 00460, loss = 2.8613
2024-10-30 17:38:33: [2024-10-30 17:38:33] iter = 00470, loss = 3.3526
2024-10-30 17:38:37: [2024-10-30 17:38:37] iter = 00480, loss = 3.3565
2024-10-30 17:38:40: [2024-10-30 17:38:40] iter = 00490, loss = 2.8870
2024-10-30 17:38:44: [2024-10-30 17:38:44] iter = 00500, loss = 2.7735
2024-10-30 17:38:48: [2024-10-30 17:38:48] iter = 00510, loss = 2.6426
2024-10-30 17:38:52: [2024-10-30 17:38:52] iter = 00520, loss = 1.9285
2024-10-30 17:38:55: [2024-10-30 17:38:55] iter = 00530, loss = 2.4957
2024-10-30 17:38:58: [2024-10-30 17:38:58] iter = 00540, loss = 2.3209
2024-10-30 17:39:02: [2024-10-30 17:39:02] iter = 00550, loss = 2.7058
2024-10-30 17:39:06: [2024-10-30 17:39:06] iter = 00560, loss = 2.5093
2024-10-30 17:39:10: [2024-10-30 17:39:10] iter = 00570, loss = 2.2676
2024-10-30 17:39:13: [2024-10-30 17:39:13] iter = 00580, loss = 2.1653
2024-10-30 17:39:16: [2024-10-30 17:39:16] iter = 00590, loss = 2.2446
2024-10-30 17:39:20: [2024-10-30 17:39:20] iter = 00600, loss = 2.2183
2024-10-30 17:39:24: [2024-10-30 17:39:24] iter = 00610, loss = 2.4447
2024-10-30 17:39:28: [2024-10-30 17:39:28] iter = 00620, loss = 2.1088
2024-10-30 17:39:32: [2024-10-30 17:39:32] iter = 00630, loss = 2.6178
2024-10-30 17:39:37: [2024-10-30 17:39:37] iter = 00640, loss = 2.1516
2024-10-30 17:39:40: [2024-10-30 17:39:40] iter = 00650, loss = 2.0469
2024-10-30 17:39:43: [2024-10-30 17:39:43] iter = 00660, loss = 2.7946
2024-10-30 17:39:48: [2024-10-30 17:39:48] iter = 00670, loss = 2.0315
2024-10-30 17:39:51: [2024-10-30 17:39:51] iter = 00680, loss = 2.8099
2024-10-30 17:39:55: [2024-10-30 17:39:55] iter = 00690, loss = 2.1799
2024-10-30 17:39:58: [2024-10-30 17:39:58] iter = 00700, loss = 2.1086
2024-10-30 17:40:01: [2024-10-30 17:40:01] iter = 00710, loss = 3.1239
2024-10-30 17:40:05: [2024-10-30 17:40:05] iter = 00720, loss = 2.1396
2024-10-30 17:40:07: [2024-10-30 17:40:07] iter = 00730, loss = 2.3259
2024-10-30 17:40:11: [2024-10-30 17:40:11] iter = 00740, loss = 1.9237
2024-10-30 17:40:14: [2024-10-30 17:40:14] iter = 00750, loss = 2.5745
2024-10-30 17:40:18: [2024-10-30 17:40:18] iter = 00760, loss = 3.0417
2024-10-30 17:40:21: [2024-10-30 17:40:21] iter = 00770, loss = 2.2089
2024-10-30 17:40:25: [2024-10-30 17:40:25] iter = 00780, loss = 2.7142
2024-10-30 17:40:29: [2024-10-30 17:40:29] iter = 00790, loss = 2.6686
2024-10-30 17:40:33: [2024-10-30 17:40:33] iter = 00800, loss = 2.7625
2024-10-30 17:40:37: [2024-10-30 17:40:37] iter = 00810, loss = 2.0956
2024-10-30 17:40:40: [2024-10-30 17:40:40] iter = 00820, loss = 2.4188
2024-10-30 17:40:44: [2024-10-30 17:40:44] iter = 00830, loss = 2.1487
2024-10-30 17:40:47: [2024-10-30 17:40:47] iter = 00840, loss = 2.4820
2024-10-30 17:40:51: [2024-10-30 17:40:51] iter = 00850, loss = 2.6703
2024-10-30 17:40:54: [2024-10-30 17:40:54] iter = 00860, loss = 1.9041
2024-10-30 17:40:58: [2024-10-30 17:40:58] iter = 00870, loss = 2.2628
2024-10-30 17:41:02: [2024-10-30 17:41:02] iter = 00880, loss = 2.0925
2024-10-30 17:41:05: [2024-10-30 17:41:05] iter = 00890, loss = 2.0918
2024-10-30 17:41:08: [2024-10-30 17:41:08] iter = 00900, loss = 2.4354
2024-10-30 17:41:12: [2024-10-30 17:41:12] iter = 00910, loss = 2.0418
2024-10-30 17:41:16: [2024-10-30 17:41:16] iter = 00920, loss = 2.2470
2024-10-30 17:41:19: [2024-10-30 17:41:19] iter = 00930, loss = 2.4886
2024-10-30 17:41:23: [2024-10-30 17:41:23] iter = 00940, loss = 2.1916
2024-10-30 17:41:27: [2024-10-30 17:41:27] iter = 00950, loss = 2.2778
2024-10-30 17:41:31: [2024-10-30 17:41:31] iter = 00960, loss = 3.0334
2024-10-30 17:41:34: [2024-10-30 17:41:34] iter = 00970, loss = 1.9535
2024-10-30 17:41:37: [2024-10-30 17:41:37] iter = 00980, loss = 2.3278
2024-10-30 17:41:41: [2024-10-30 17:41:41] iter = 00990, loss = 2.7372
2024-10-30 17:41:45: [2024-10-30 17:41:45] iter = 01000, loss = 2.3750
2024-10-30 17:41:48: [2024-10-30 17:41:48] iter = 01010, loss = 2.9633
2024-10-30 17:41:53: [2024-10-30 17:41:53] iter = 01020, loss = 2.1295
2024-10-30 17:41:56: [2024-10-30 17:41:56] iter = 01030, loss = 3.2505
2024-10-30 17:41:59: [2024-10-30 17:41:59] iter = 01040, loss = 2.5184
2024-10-30 17:42:02: [2024-10-30 17:42:02] iter = 01050, loss = 3.5024
2024-10-30 17:42:05: [2024-10-30 17:42:05] iter = 01060, loss = 2.1721
2024-10-30 17:42:09: [2024-10-30 17:42:09] iter = 01070, loss = 4.9545
2024-10-30 17:42:13: [2024-10-30 17:42:13] iter = 01080, loss = 2.5893
2024-10-30 17:42:17: [2024-10-30 17:42:17] iter = 01090, loss = 2.0142
2024-10-30 17:42:21: [2024-10-30 17:42:21] iter = 01100, loss = 3.2824
2024-10-30 17:42:24: [2024-10-30 17:42:24] iter = 01110, loss = 3.7452
2024-10-30 17:42:27: [2024-10-30 17:42:27] iter = 01120, loss = 2.6947
2024-10-30 17:42:30: [2024-10-30 17:42:30] iter = 01130, loss = 1.9361
2024-10-30 17:42:33: [2024-10-30 17:42:33] iter = 01140, loss = 2.3159
2024-10-30 17:42:37: [2024-10-30 17:42:37] iter = 01150, loss = 2.2422
2024-10-30 17:42:39: [2024-10-30 17:42:39] iter = 01160, loss = 2.6063
2024-10-30 17:42:42: [2024-10-30 17:42:42] iter = 01170, loss = 2.0361
2024-10-30 17:42:45: [2024-10-30 17:42:45] iter = 01180, loss = 2.2450
2024-10-30 17:42:50: [2024-10-30 17:42:50] iter = 01190, loss = 2.2322
2024-10-30 17:42:53: [2024-10-30 17:42:53] iter = 01200, loss = 2.0146
2024-10-30 17:42:57: [2024-10-30 17:42:57] iter = 01210, loss = 2.1526
2024-10-30 17:43:01: [2024-10-30 17:43:01] iter = 01220, loss = 2.3650
2024-10-30 17:43:04: [2024-10-30 17:43:04] iter = 01230, loss = 2.4331
2024-10-30 17:43:08: [2024-10-30 17:43:08] iter = 01240, loss = 2.0449
2024-10-30 17:43:12: [2024-10-30 17:43:12] iter = 01250, loss = 2.8273
2024-10-30 17:43:17: [2024-10-30 17:43:17] iter = 01260, loss = 2.3045
2024-10-30 17:43:21: [2024-10-30 17:43:21] iter = 01270, loss = 2.0783
2024-10-30 17:43:24: [2024-10-30 17:43:24] iter = 01280, loss = 2.4592
2024-10-30 17:43:29: [2024-10-30 17:43:29] iter = 01290, loss = 2.3530
2024-10-30 17:43:33: [2024-10-30 17:43:33] iter = 01300, loss = 2.5681
2024-10-30 17:43:37: [2024-10-30 17:43:37] iter = 01310, loss = 4.3965
2024-10-30 17:43:39: [2024-10-30 17:43:39] iter = 01320, loss = 2.6948
2024-10-30 17:43:43: [2024-10-30 17:43:43] iter = 01330, loss = 3.0927
2024-10-30 17:43:47: [2024-10-30 17:43:47] iter = 01340, loss = 1.8441
2024-10-30 17:43:50: [2024-10-30 17:43:50] iter = 01350, loss = 1.8582
2024-10-30 17:43:53: [2024-10-30 17:43:53] iter = 01360, loss = 1.8060
2024-10-30 17:43:56: [2024-10-30 17:43:56] iter = 01370, loss = 2.6088
2024-10-30 17:43:59: [2024-10-30 17:43:59] iter = 01380, loss = 2.6150
2024-10-30 17:44:01: [2024-10-30 17:44:01] iter = 01390, loss = 1.9253
2024-10-30 17:44:04: [2024-10-30 17:44:04] iter = 01400, loss = 2.6483
2024-10-30 17:44:07: [2024-10-30 17:44:07] iter = 01410, loss = 2.4254
2024-10-30 17:44:10: [2024-10-30 17:44:10] iter = 01420, loss = 2.8868
2024-10-30 17:44:13: [2024-10-30 17:44:13] iter = 01430, loss = 2.1832
2024-10-30 17:44:16: [2024-10-30 17:44:16] iter = 01440, loss = 1.9282
2024-10-30 17:44:20: [2024-10-30 17:44:20] iter = 01450, loss = 2.1129
2024-10-30 17:44:23: [2024-10-30 17:44:23] iter = 01460, loss = 2.8053
2024-10-30 17:44:26: [2024-10-30 17:44:26] iter = 01470, loss = 2.3019
2024-10-30 17:44:30: [2024-10-30 17:44:30] iter = 01480, loss = 4.6255
2024-10-30 17:44:33: [2024-10-30 17:44:33] iter = 01490, loss = 2.7940
2024-10-30 17:44:37: [2024-10-30 17:44:37] iter = 01500, loss = 2.4092
2024-10-30 17:44:40: [2024-10-30 17:44:40] iter = 01510, loss = 2.4762
2024-10-30 17:44:43: [2024-10-30 17:44:43] iter = 01520, loss = 1.7147
2024-10-30 17:44:47: [2024-10-30 17:44:47] iter = 01530, loss = 2.3435
2024-10-30 17:44:51: [2024-10-30 17:44:51] iter = 01540, loss = 1.9524
2024-10-30 17:44:54: [2024-10-30 17:44:54] iter = 01550, loss = 3.7063
2024-10-30 17:44:58: [2024-10-30 17:44:58] iter = 01560, loss = 1.9825
2024-10-30 17:45:01: [2024-10-30 17:45:01] iter = 01570, loss = 3.1751
2024-10-30 17:45:05: [2024-10-30 17:45:05] iter = 01580, loss = 2.4874
2024-10-30 17:45:08: [2024-10-30 17:45:08] iter = 01590, loss = 2.0758
2024-10-30 17:45:11: [2024-10-30 17:45:11] iter = 01600, loss = 2.7054
2024-10-30 17:45:14: [2024-10-30 17:45:14] iter = 01610, loss = 3.6132
2024-10-30 17:45:17: [2024-10-30 17:45:17] iter = 01620, loss = 2.2406
2024-10-30 17:45:20: [2024-10-30 17:45:20] iter = 01630, loss = 2.0177
2024-10-30 17:45:22: [2024-10-30 17:45:22] iter = 01640, loss = 1.7344
2024-10-30 17:45:25: [2024-10-30 17:45:25] iter = 01650, loss = 1.9881
2024-10-30 17:45:28: [2024-10-30 17:45:28] iter = 01660, loss = 2.5763
2024-10-30 17:45:32: [2024-10-30 17:45:32] iter = 01670, loss = 1.9066
2024-10-30 17:45:34: [2024-10-30 17:45:34] iter = 01680, loss = 3.7840
2024-10-30 17:45:37: [2024-10-30 17:45:37] iter = 01690, loss = 3.3733
2024-10-30 17:45:40: [2024-10-30 17:45:40] iter = 01700, loss = 2.6517
2024-10-30 17:45:44: [2024-10-30 17:45:44] iter = 01710, loss = 3.6717
2024-10-30 17:45:45: [2024-10-30 17:45:45] iter = 01720, loss = 2.2302
2024-10-30 17:45:48: [2024-10-30 17:45:48] iter = 01730, loss = 2.3615
2024-10-30 17:45:51: [2024-10-30 17:45:51] iter = 01740, loss = 2.2339
2024-10-30 17:45:55: [2024-10-30 17:45:55] iter = 01750, loss = 2.0215
2024-10-30 17:45:58: [2024-10-30 17:45:58] iter = 01760, loss = 2.3200
2024-10-30 17:46:01: [2024-10-30 17:46:01] iter = 01770, loss = 2.5261
2024-10-30 17:46:04: [2024-10-30 17:46:04] iter = 01780, loss = 2.3971
2024-10-30 17:46:08: [2024-10-30 17:46:08] iter = 01790, loss = 1.9475
2024-10-30 17:46:10: [2024-10-30 17:46:10] iter = 01800, loss = 2.0737
2024-10-30 17:46:13: [2024-10-30 17:46:13] iter = 01810, loss = 2.4857
2024-10-30 17:46:16: [2024-10-30 17:46:16] iter = 01820, loss = 2.5691
2024-10-30 17:46:19: [2024-10-30 17:46:19] iter = 01830, loss = 2.0479
2024-10-30 17:46:22: [2024-10-30 17:46:22] iter = 01840, loss = 4.9404
2024-10-30 17:46:25: [2024-10-30 17:46:25] iter = 01850, loss = 2.1858
2024-10-30 17:46:28: [2024-10-30 17:46:28] iter = 01860, loss = 2.1212
2024-10-30 17:46:32: [2024-10-30 17:46:32] iter = 01870, loss = 3.2952
2024-10-30 17:46:34: [2024-10-30 17:46:34] iter = 01880, loss = 2.1967
2024-10-30 17:46:37: [2024-10-30 17:46:37] iter = 01890, loss = 2.3076
2024-10-30 17:46:41: [2024-10-30 17:46:41] iter = 01900, loss = 2.5956
2024-10-30 17:46:44: [2024-10-30 17:46:44] iter = 01910, loss = 2.1107
2024-10-30 17:46:47: [2024-10-30 17:46:47] iter = 01920, loss = 2.0610
2024-10-30 17:46:51: [2024-10-30 17:46:51] iter = 01930, loss = 2.0881
2024-10-30 17:46:55: [2024-10-30 17:46:55] iter = 01940, loss = 3.0392
2024-10-30 17:46:58: [2024-10-30 17:46:58] iter = 01950, loss = 2.1133
2024-10-30 17:47:02: [2024-10-30 17:47:02] iter = 01960, loss = 2.5327
2024-10-30 17:47:05: [2024-10-30 17:47:05] iter = 01970, loss = 3.5852
2024-10-30 17:47:08: [2024-10-30 17:47:08] iter = 01980, loss = 2.6290
2024-10-30 17:47:11: [2024-10-30 17:47:11] iter = 01990, loss = 2.2158
2024-10-30 17:47:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 17:47:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:47:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 34834}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:25: Evaluate 5 random ConvNet, ACCmean = 0.6201 ACCstd = 0.0037
-------------------------
2024-10-30 17:49:25: Evaluate 5 random ConvNet, SENmean = 0.5983 SENstd = 0.0031
-------------------------
2024-10-30 17:49:25: Evaluate 5 random ConvNet, SPEmean = 0.9613 SPEstd = 0.0004
-------------------------
2024-10-30 17:49:25: Evaluate 5 random ConvNet, F!mean = 0.5889 F!std = 0.0029
-------------------------
2024-10-30 17:49:25: Evaluate 5 random ConvNet, mean = 0.6201 std = 0.0037
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:25: [2024-10-30 17:49:25] iter = 02000, loss = 2.1674
2024-10-30 17:49:28: [2024-10-30 17:49:28] iter = 02010, loss = 2.1420
2024-10-30 17:49:31: [2024-10-30 17:49:31] iter = 02020, loss = 4.3271
2024-10-30 17:49:35: [2024-10-30 17:49:35] iter = 02030, loss = 2.8577
2024-10-30 17:49:38: [2024-10-30 17:49:38] iter = 02040, loss = 1.8050
2024-10-30 17:49:43: [2024-10-30 17:49:43] iter = 02050, loss = 2.8733
2024-10-30 17:49:46: [2024-10-30 17:49:46] iter = 02060, loss = 3.0385
2024-10-30 17:49:49: [2024-10-30 17:49:49] iter = 02070, loss = 2.2919
2024-10-30 17:49:52: [2024-10-30 17:49:52] iter = 02080, loss = 2.3177
2024-10-30 17:49:55: [2024-10-30 17:49:55] iter = 02090, loss = 1.9945
2024-10-30 17:49:59: [2024-10-30 17:49:59] iter = 02100, loss = 1.9239
2024-10-30 17:50:02: [2024-10-30 17:50:02] iter = 02110, loss = 1.8404
2024-10-30 17:50:06: [2024-10-30 17:50:06] iter = 02120, loss = 2.1596
2024-10-30 17:50:10: [2024-10-30 17:50:10] iter = 02130, loss = 2.5987
2024-10-30 17:50:13: [2024-10-30 17:50:13] iter = 02140, loss = 1.9115
2024-10-30 17:50:16: [2024-10-30 17:50:16] iter = 02150, loss = 2.8503
2024-10-30 17:50:20: [2024-10-30 17:50:20] iter = 02160, loss = 2.1353
2024-10-30 17:50:23: [2024-10-30 17:50:23] iter = 02170, loss = 2.2037
2024-10-30 17:50:26: [2024-10-30 17:50:26] iter = 02180, loss = 2.0804
2024-10-30 17:50:29: [2024-10-30 17:50:29] iter = 02190, loss = 2.1276
2024-10-30 17:50:32: [2024-10-30 17:50:32] iter = 02200, loss = 1.8346
2024-10-30 17:50:35: [2024-10-30 17:50:35] iter = 02210, loss = 2.4971
2024-10-30 17:50:38: [2024-10-30 17:50:38] iter = 02220, loss = 2.1103
2024-10-30 17:50:41: [2024-10-30 17:50:41] iter = 02230, loss = 2.5395
2024-10-30 17:50:44: [2024-10-30 17:50:44] iter = 02240, loss = 2.7601
2024-10-30 17:50:48: [2024-10-30 17:50:48] iter = 02250, loss = 2.8068
2024-10-30 17:50:51: [2024-10-30 17:50:51] iter = 02260, loss = 2.3757
2024-10-30 17:50:55: [2024-10-30 17:50:55] iter = 02270, loss = 3.1132
2024-10-30 17:50:58: [2024-10-30 17:50:58] iter = 02280, loss = 4.5389
2024-10-30 17:51:00: [2024-10-30 17:51:00] iter = 02290, loss = 1.9025
2024-10-30 17:51:03: [2024-10-30 17:51:03] iter = 02300, loss = 2.1439
2024-10-30 17:51:06: [2024-10-30 17:51:06] iter = 02310, loss = 2.6132
2024-10-30 17:51:10: [2024-10-30 17:51:10] iter = 02320, loss = 2.2421
2024-10-30 17:51:13: [2024-10-30 17:51:13] iter = 02330, loss = 2.1703
2024-10-30 17:51:16: [2024-10-30 17:51:16] iter = 02340, loss = 2.4986
2024-10-30 17:51:19: [2024-10-30 17:51:19] iter = 02350, loss = 2.0933
2024-10-30 17:51:22: [2024-10-30 17:51:22] iter = 02360, loss = 2.0013
2024-10-30 17:51:27: [2024-10-30 17:51:27] iter = 02370, loss = 2.4820
2024-10-30 17:51:30: [2024-10-30 17:51:30] iter = 02380, loss = 2.2127
2024-10-30 17:51:33: [2024-10-30 17:51:33] iter = 02390, loss = 2.8386
2024-10-30 17:51:36: [2024-10-30 17:51:36] iter = 02400, loss = 3.4603
2024-10-30 17:51:39: [2024-10-30 17:51:39] iter = 02410, loss = 2.4894
2024-10-30 17:51:42: [2024-10-30 17:51:42] iter = 02420, loss = 3.7283
2024-10-30 17:51:45: [2024-10-30 17:51:45] iter = 02430, loss = 2.0861
2024-10-30 17:51:48: [2024-10-30 17:51:48] iter = 02440, loss = 2.3638
2024-10-30 17:51:52: [2024-10-30 17:51:52] iter = 02450, loss = 2.4808
2024-10-30 17:51:55: [2024-10-30 17:51:55] iter = 02460, loss = 2.1638
2024-10-30 17:51:59: [2024-10-30 17:51:59] iter = 02470, loss = 2.9225
2024-10-30 17:52:02: [2024-10-30 17:52:02] iter = 02480, loss = 2.3800
2024-10-30 17:52:05: [2024-10-30 17:52:05] iter = 02490, loss = 1.9629
2024-10-30 17:52:08: [2024-10-30 17:52:08] iter = 02500, loss = 2.0250
2024-10-30 17:52:12: [2024-10-30 17:52:12] iter = 02510, loss = 2.1652
2024-10-30 17:52:15: [2024-10-30 17:52:15] iter = 02520, loss = 2.0942
2024-10-30 17:52:18: [2024-10-30 17:52:18] iter = 02530, loss = 2.0261
2024-10-30 17:52:21: [2024-10-30 17:52:21] iter = 02540, loss = 1.8477
2024-10-30 17:52:24: [2024-10-30 17:52:24] iter = 02550, loss = 2.3292
2024-10-30 17:52:27: [2024-10-30 17:52:27] iter = 02560, loss = 3.2770
2024-10-30 17:52:32: [2024-10-30 17:52:32] iter = 02570, loss = 3.4620
2024-10-30 17:52:36: [2024-10-30 17:52:36] iter = 02580, loss = 2.6693
2024-10-30 17:52:40: [2024-10-30 17:52:40] iter = 02590, loss = 2.0203
2024-10-30 17:52:44: [2024-10-30 17:52:44] iter = 02600, loss = 2.0047
2024-10-30 17:52:46: [2024-10-30 17:52:46] iter = 02610, loss = 4.2686
2024-10-30 17:52:49: [2024-10-30 17:52:49] iter = 02620, loss = 2.2070
2024-10-30 17:52:53: [2024-10-30 17:52:53] iter = 02630, loss = 2.1886
2024-10-30 17:52:56: [2024-10-30 17:52:56] iter = 02640, loss = 2.4296
2024-10-30 17:53:00: [2024-10-30 17:53:00] iter = 02650, loss = 2.2418
2024-10-30 17:53:04: [2024-10-30 17:53:04] iter = 02660, loss = 1.7954
2024-10-30 17:53:08: [2024-10-30 17:53:08] iter = 02670, loss = 3.7341
2024-10-30 17:53:12: [2024-10-30 17:53:12] iter = 02680, loss = 2.1959
2024-10-30 17:53:15: [2024-10-30 17:53:15] iter = 02690, loss = 2.5267
2024-10-30 17:53:19: [2024-10-30 17:53:19] iter = 02700, loss = 1.9685
2024-10-30 17:53:22: [2024-10-30 17:53:22] iter = 02710, loss = 1.8950
2024-10-30 17:53:26: [2024-10-30 17:53:26] iter = 02720, loss = 2.1856
2024-10-30 17:53:29: [2024-10-30 17:53:29] iter = 02730, loss = 2.2234
2024-10-30 17:53:31: [2024-10-30 17:53:31] iter = 02740, loss = 2.1804
2024-10-30 17:53:35: [2024-10-30 17:53:35] iter = 02750, loss = 2.2666
2024-10-30 17:53:39: [2024-10-30 17:53:39] iter = 02760, loss = 2.0492
2024-10-30 17:53:42: [2024-10-30 17:53:42] iter = 02770, loss = 2.3511
2024-10-30 17:53:45: [2024-10-30 17:53:45] iter = 02780, loss = 2.2158
2024-10-30 17:53:49: [2024-10-30 17:53:49] iter = 02790, loss = 2.0163
2024-10-30 17:53:52: [2024-10-30 17:53:52] iter = 02800, loss = 2.1544
2024-10-30 17:53:56: [2024-10-30 17:53:56] iter = 02810, loss = 2.2290
2024-10-30 17:53:59: [2024-10-30 17:53:59] iter = 02820, loss = 1.8723
2024-10-30 17:54:02: [2024-10-30 17:54:02] iter = 02830, loss = 3.8866
2024-10-30 17:54:06: [2024-10-30 17:54:06] iter = 02840, loss = 1.9117
2024-10-30 17:54:10: [2024-10-30 17:54:10] iter = 02850, loss = 2.5186
2024-10-30 17:54:14: [2024-10-30 17:54:14] iter = 02860, loss = 2.0712
2024-10-30 17:54:17: [2024-10-30 17:54:17] iter = 02870, loss = 2.6425
2024-10-30 17:54:21: [2024-10-30 17:54:21] iter = 02880, loss = 1.8973
2024-10-30 17:54:24: [2024-10-30 17:54:24] iter = 02890, loss = 2.3203
2024-10-30 17:54:28: [2024-10-30 17:54:28] iter = 02900, loss = 1.7932
2024-10-30 17:54:31: [2024-10-30 17:54:31] iter = 02910, loss = 2.3027
2024-10-30 17:54:33: [2024-10-30 17:54:33] iter = 02920, loss = 2.5452
2024-10-30 17:54:36: [2024-10-30 17:54:36] iter = 02930, loss = 1.7038
2024-10-30 17:54:40: [2024-10-30 17:54:40] iter = 02940, loss = 2.0044
2024-10-30 17:54:44: [2024-10-30 17:54:44] iter = 02950, loss = 2.0274
2024-10-30 17:54:47: [2024-10-30 17:54:47] iter = 02960, loss = 3.0513
2024-10-30 17:54:51: [2024-10-30 17:54:51] iter = 02970, loss = 2.2348
2024-10-30 17:54:54: [2024-10-30 17:54:54] iter = 02980, loss = 2.0643
2024-10-30 17:54:58: [2024-10-30 17:54:58] iter = 02990, loss = 2.2972
2024-10-30 17:55:01: [2024-10-30 17:55:01] iter = 03000, loss = 2.4401
2024-10-30 17:55:04: [2024-10-30 17:55:04] iter = 03010, loss = 1.9776
2024-10-30 17:55:08: [2024-10-30 17:55:08] iter = 03020, loss = 2.3986
2024-10-30 17:55:12: [2024-10-30 17:55:12] iter = 03030, loss = 2.0881
2024-10-30 17:55:15: [2024-10-30 17:55:15] iter = 03040, loss = 2.7454
2024-10-30 17:55:19: [2024-10-30 17:55:19] iter = 03050, loss = 2.7935
2024-10-30 17:55:23: [2024-10-30 17:55:23] iter = 03060, loss = 2.6222
2024-10-30 17:55:26: [2024-10-30 17:55:26] iter = 03070, loss = 3.4386
2024-10-30 17:55:29: [2024-10-30 17:55:29] iter = 03080, loss = 2.0446
2024-10-30 17:55:32: [2024-10-30 17:55:32] iter = 03090, loss = 2.1181
2024-10-30 17:55:35: [2024-10-30 17:55:35] iter = 03100, loss = 1.9764
2024-10-30 17:55:38: [2024-10-30 17:55:38] iter = 03110, loss = 2.1044
2024-10-30 17:55:41: [2024-10-30 17:55:41] iter = 03120, loss = 1.9630
2024-10-30 17:55:45: [2024-10-30 17:55:45] iter = 03130, loss = 1.7716
2024-10-30 17:55:49: [2024-10-30 17:55:49] iter = 03140, loss = 3.2917
2024-10-30 17:55:52: [2024-10-30 17:55:52] iter = 03150, loss = 2.3617
2024-10-30 17:55:56: [2024-10-30 17:55:56] iter = 03160, loss = 2.0992
2024-10-30 17:55:59: [2024-10-30 17:55:59] iter = 03170, loss = 2.1013
2024-10-30 17:56:03: [2024-10-30 17:56:03] iter = 03180, loss = 2.9351
2024-10-30 17:56:06: [2024-10-30 17:56:06] iter = 03190, loss = 3.5101
2024-10-30 17:56:09: [2024-10-30 17:56:09] iter = 03200, loss = 2.2396
2024-10-30 17:56:12: [2024-10-30 17:56:12] iter = 03210, loss = 2.1665
2024-10-30 17:56:14: [2024-10-30 17:56:14] iter = 03220, loss = 2.0519
2024-10-30 17:56:16: [2024-10-30 17:56:16] iter = 03230, loss = 2.1418
2024-10-30 17:56:19: [2024-10-30 17:56:19] iter = 03240, loss = 2.4782
2024-10-30 17:56:23: [2024-10-30 17:56:23] iter = 03250, loss = 3.7796
2024-10-30 17:56:26: [2024-10-30 17:56:26] iter = 03260, loss = 2.3428
2024-10-30 17:56:28: [2024-10-30 17:56:28] iter = 03270, loss = 1.8797
2024-10-30 17:56:32: [2024-10-30 17:56:32] iter = 03280, loss = 3.2956
2024-10-30 17:56:34: [2024-10-30 17:56:34] iter = 03290, loss = 2.4873
2024-10-30 17:56:36: [2024-10-30 17:56:36] iter = 03300, loss = 2.0638
2024-10-30 17:56:39: [2024-10-30 17:56:39] iter = 03310, loss = 2.7788
2024-10-30 17:56:42: [2024-10-30 17:56:42] iter = 03320, loss = 2.0844
2024-10-30 17:56:45: [2024-10-30 17:56:45] iter = 03330, loss = 2.5117
2024-10-30 17:56:48: [2024-10-30 17:56:48] iter = 03340, loss = 2.8533
2024-10-30 17:56:51: [2024-10-30 17:56:51] iter = 03350, loss = 2.4281
2024-10-30 17:56:54: [2024-10-30 17:56:54] iter = 03360, loss = 2.7269
2024-10-30 17:56:56: [2024-10-30 17:56:56] iter = 03370, loss = 2.2719
2024-10-30 17:56:59: [2024-10-30 17:56:59] iter = 03380, loss = 2.0767
2024-10-30 17:57:03: [2024-10-30 17:57:03] iter = 03390, loss = 3.0877
2024-10-30 17:57:05: [2024-10-30 17:57:05] iter = 03400, loss = 2.8619
2024-10-30 17:57:08: [2024-10-30 17:57:08] iter = 03410, loss = 1.7286
2024-10-30 17:57:11: [2024-10-30 17:57:11] iter = 03420, loss = 1.9796
2024-10-30 17:57:15: [2024-10-30 17:57:15] iter = 03430, loss = 1.7559
2024-10-30 17:57:17: [2024-10-30 17:57:17] iter = 03440, loss = 2.3971
2024-10-30 17:57:20: [2024-10-30 17:57:20] iter = 03450, loss = 2.3914
2024-10-30 17:57:23: [2024-10-30 17:57:23] iter = 03460, loss = 1.6818
2024-10-30 17:57:27: [2024-10-30 17:57:27] iter = 03470, loss = 1.8753
2024-10-30 17:57:31: [2024-10-30 17:57:31] iter = 03480, loss = 1.8939
2024-10-30 17:57:34: [2024-10-30 17:57:34] iter = 03490, loss = 1.9740
2024-10-30 17:57:38: [2024-10-30 17:57:38] iter = 03500, loss = 2.2777
2024-10-30 17:57:41: [2024-10-30 17:57:41] iter = 03510, loss = 2.3249
2024-10-30 17:57:44: [2024-10-30 17:57:44] iter = 03520, loss = 2.1537
2024-10-30 17:57:47: [2024-10-30 17:57:47] iter = 03530, loss = 3.0902
2024-10-30 17:57:51: [2024-10-30 17:57:51] iter = 03540, loss = 2.6091
2024-10-30 17:57:55: [2024-10-30 17:57:55] iter = 03550, loss = 2.1506
2024-10-30 17:57:58: [2024-10-30 17:57:58] iter = 03560, loss = 1.9904
2024-10-30 17:58:02: [2024-10-30 17:58:02] iter = 03570, loss = 2.5306
2024-10-30 17:58:06: [2024-10-30 17:58:06] iter = 03580, loss = 4.1115
2024-10-30 17:58:10: [2024-10-30 17:58:10] iter = 03590, loss = 2.2615
2024-10-30 17:58:14: [2024-10-30 17:58:14] iter = 03600, loss = 2.5127
2024-10-30 17:58:18: [2024-10-30 17:58:18] iter = 03610, loss = 2.2375
2024-10-30 17:58:22: [2024-10-30 17:58:22] iter = 03620, loss = 1.8963
2024-10-30 17:58:26: [2024-10-30 17:58:26] iter = 03630, loss = 3.9219
2024-10-30 17:58:29: [2024-10-30 17:58:29] iter = 03640, loss = 2.2633
2024-10-30 17:58:33: [2024-10-30 17:58:33] iter = 03650, loss = 2.5830
2024-10-30 17:58:36: [2024-10-30 17:58:36] iter = 03660, loss = 3.3266
2024-10-30 17:58:40: [2024-10-30 17:58:40] iter = 03670, loss = 1.8283
2024-10-30 17:58:44: [2024-10-30 17:58:44] iter = 03680, loss = 2.0068
2024-10-30 17:58:47: [2024-10-30 17:58:47] iter = 03690, loss = 2.2195
2024-10-30 17:58:51: [2024-10-30 17:58:51] iter = 03700, loss = 2.1203
2024-10-30 17:58:54: [2024-10-30 17:58:54] iter = 03710, loss = 2.3643
2024-10-30 17:58:57: [2024-10-30 17:58:57] iter = 03720, loss = 2.0724
2024-10-30 17:59:01: [2024-10-30 17:59:01] iter = 03730, loss = 3.0657
2024-10-30 17:59:05: [2024-10-30 17:59:05] iter = 03740, loss = 3.6064
2024-10-30 17:59:08: [2024-10-30 17:59:08] iter = 03750, loss = 2.1346
2024-10-30 17:59:11: [2024-10-30 17:59:11] iter = 03760, loss = 3.5088
2024-10-30 17:59:15: [2024-10-30 17:59:15] iter = 03770, loss = 2.3705
2024-10-30 17:59:18: [2024-10-30 17:59:18] iter = 03780, loss = 2.2843
2024-10-30 17:59:22: [2024-10-30 17:59:22] iter = 03790, loss = 2.3149
2024-10-30 17:59:25: [2024-10-30 17:59:25] iter = 03800, loss = 2.6277
2024-10-30 17:59:29: [2024-10-30 17:59:29] iter = 03810, loss = 1.9541
2024-10-30 17:59:33: [2024-10-30 17:59:33] iter = 03820, loss = 2.8371
2024-10-30 17:59:36: [2024-10-30 17:59:36] iter = 03830, loss = 1.9447
2024-10-30 17:59:39: [2024-10-30 17:59:39] iter = 03840, loss = 2.5284
2024-10-30 17:59:43: [2024-10-30 17:59:43] iter = 03850, loss = 2.1968
2024-10-30 17:59:46: [2024-10-30 17:59:46] iter = 03860, loss = 2.1910
2024-10-30 17:59:50: [2024-10-30 17:59:50] iter = 03870, loss = 2.8373
2024-10-30 17:59:53: [2024-10-30 17:59:53] iter = 03880, loss = 1.9354
2024-10-30 17:59:56: [2024-10-30 17:59:56] iter = 03890, loss = 2.5856
2024-10-30 17:59:59: [2024-10-30 17:59:59] iter = 03900, loss = 2.6560
2024-10-30 18:00:03: [2024-10-30 18:00:03] iter = 03910, loss = 1.9844
2024-10-30 18:00:06: [2024-10-30 18:00:06] iter = 03920, loss = 4.3148
2024-10-30 18:00:09: [2024-10-30 18:00:09] iter = 03930, loss = 1.7311
2024-10-30 18:00:13: [2024-10-30 18:00:13] iter = 03940, loss = 2.3335
2024-10-30 18:00:16: [2024-10-30 18:00:16] iter = 03950, loss = 1.8033
2024-10-30 18:00:20: [2024-10-30 18:00:20] iter = 03960, loss = 2.1570
2024-10-30 18:00:23: [2024-10-30 18:00:23] iter = 03970, loss = 2.1858
2024-10-30 18:00:26: [2024-10-30 18:00:26] iter = 03980, loss = 2.0304
2024-10-30 18:00:29: [2024-10-30 18:00:29] iter = 03990, loss = 2.0937
2024-10-30 18:00:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 18:00:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:00:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 32655}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:02:37: Evaluate 5 random ConvNet, ACCmean = 0.6226 ACCstd = 0.0048
-------------------------
2024-10-30 18:02:37: Evaluate 5 random ConvNet, SENmean = 0.5979 SENstd = 0.0056
-------------------------
2024-10-30 18:02:37: Evaluate 5 random ConvNet, SPEmean = 0.9616 SPEstd = 0.0005
-------------------------
2024-10-30 18:02:37: Evaluate 5 random ConvNet, F!mean = 0.5900 F!std = 0.0053
-------------------------
2024-10-30 18:02:37: Evaluate 5 random ConvNet, mean = 0.6226 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:02:38: [2024-10-30 18:02:38] iter = 04000, loss = 2.2094
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:02:41: [2024-10-30 18:02:41] iter = 04010, loss = 1.9357
2024-10-30 18:02:45: [2024-10-30 18:02:45] iter = 04020, loss = 1.8948
2024-10-30 18:02:49: [2024-10-30 18:02:49] iter = 04030, loss = 2.2603
2024-10-30 18:02:51: [2024-10-30 18:02:51] iter = 04040, loss = 2.5737
2024-10-30 18:02:54: [2024-10-30 18:02:54] iter = 04050, loss = 2.6851
2024-10-30 18:02:58: [2024-10-30 18:02:58] iter = 04060, loss = 1.8275
2024-10-30 18:03:01: [2024-10-30 18:03:01] iter = 04070, loss = 2.1270
2024-10-30 18:03:05: [2024-10-30 18:03:05] iter = 04080, loss = 2.8864
2024-10-30 18:03:08: [2024-10-30 18:03:08] iter = 04090, loss = 2.0869
2024-10-30 18:03:11: [2024-10-30 18:03:11] iter = 04100, loss = 2.8040
2024-10-30 18:03:14: [2024-10-30 18:03:14] iter = 04110, loss = 2.5685
2024-10-30 18:03:18: [2024-10-30 18:03:18] iter = 04120, loss = 2.2575
2024-10-30 18:03:21: [2024-10-30 18:03:21] iter = 04130, loss = 3.5368
2024-10-30 18:03:24: [2024-10-30 18:03:24] iter = 04140, loss = 2.8035
2024-10-30 18:03:27: [2024-10-30 18:03:27] iter = 04150, loss = 2.8676
2024-10-30 18:03:30: [2024-10-30 18:03:30] iter = 04160, loss = 1.9522
2024-10-30 18:03:33: [2024-10-30 18:03:33] iter = 04170, loss = 1.9602
2024-10-30 18:03:36: [2024-10-30 18:03:36] iter = 04180, loss = 2.0924
2024-10-30 18:03:39: [2024-10-30 18:03:39] iter = 04190, loss = 2.0933
2024-10-30 18:03:43: [2024-10-30 18:03:43] iter = 04200, loss = 3.4668
2024-10-30 18:03:46: [2024-10-30 18:03:46] iter = 04210, loss = 1.9924
2024-10-30 18:03:50: [2024-10-30 18:03:50] iter = 04220, loss = 4.1376
2024-10-30 18:03:53: [2024-10-30 18:03:53] iter = 04230, loss = 3.0724
2024-10-30 18:03:57: [2024-10-30 18:03:57] iter = 04240, loss = 2.5812
2024-10-30 18:04:00: [2024-10-30 18:04:00] iter = 04250, loss = 2.3451
2024-10-30 18:04:04: [2024-10-30 18:04:04] iter = 04260, loss = 1.9280
2024-10-30 18:04:07: [2024-10-30 18:04:07] iter = 04270, loss = 2.5216
2024-10-30 18:04:10: [2024-10-30 18:04:10] iter = 04280, loss = 2.0701
2024-10-30 18:04:13: [2024-10-30 18:04:13] iter = 04290, loss = 2.8400
2024-10-30 18:04:17: [2024-10-30 18:04:17] iter = 04300, loss = 2.4055
2024-10-30 18:04:20: [2024-10-30 18:04:20] iter = 04310, loss = 2.9023
2024-10-30 18:04:23: [2024-10-30 18:04:23] iter = 04320, loss = 1.8697
2024-10-30 18:04:26: [2024-10-30 18:04:26] iter = 04330, loss = 2.3826
2024-10-30 18:04:30: [2024-10-30 18:04:30] iter = 04340, loss = 2.7426
2024-10-30 18:04:33: [2024-10-30 18:04:33] iter = 04350, loss = 2.5014
2024-10-30 18:04:37: [2024-10-30 18:04:37] iter = 04360, loss = 2.5883
2024-10-30 18:04:40: [2024-10-30 18:04:40] iter = 04370, loss = 2.1570
2024-10-30 18:04:44: [2024-10-30 18:04:44] iter = 04380, loss = 4.0676
2024-10-30 18:04:47: [2024-10-30 18:04:47] iter = 04390, loss = 2.1114
2024-10-30 18:04:52: [2024-10-30 18:04:51] iter = 04400, loss = 2.0668
2024-10-30 18:04:55: [2024-10-30 18:04:55] iter = 04410, loss = 3.8907
2024-10-30 18:04:59: [2024-10-30 18:04:59] iter = 04420, loss = 1.9320
2024-10-30 18:05:03: [2024-10-30 18:05:03] iter = 04430, loss = 1.8301
2024-10-30 18:05:06: [2024-10-30 18:05:06] iter = 04440, loss = 2.5301
2024-10-30 18:05:09: [2024-10-30 18:05:09] iter = 04450, loss = 2.5646
2024-10-30 18:05:13: [2024-10-30 18:05:13] iter = 04460, loss = 1.9221
2024-10-30 18:05:17: [2024-10-30 18:05:17] iter = 04470, loss = 2.7560
2024-10-30 18:05:21: [2024-10-30 18:05:21] iter = 04480, loss = 2.4955
2024-10-30 18:05:23: [2024-10-30 18:05:23] iter = 04490, loss = 3.0346
2024-10-30 18:05:25: [2024-10-30 18:05:25] iter = 04500, loss = 1.9387
2024-10-30 18:05:27: [2024-10-30 18:05:27] iter = 04510, loss = 2.6095
2024-10-30 18:05:28: [2024-10-30 18:05:28] iter = 04520, loss = 2.7305
2024-10-30 18:05:30: [2024-10-30 18:05:30] iter = 04530, loss = 1.9951
2024-10-30 18:05:32: [2024-10-30 18:05:32] iter = 04540, loss = 1.9555
2024-10-30 18:05:34: [2024-10-30 18:05:34] iter = 04550, loss = 3.2449
2024-10-30 18:05:37: [2024-10-30 18:05:37] iter = 04560, loss = 2.4287
2024-10-30 18:05:40: [2024-10-30 18:05:40] iter = 04570, loss = 2.7687
2024-10-30 18:05:43: [2024-10-30 18:05:43] iter = 04580, loss = 1.8443
2024-10-30 18:05:47: [2024-10-30 18:05:47] iter = 04590, loss = 2.2704
2024-10-30 18:05:50: [2024-10-30 18:05:50] iter = 04600, loss = 1.7628
2024-10-30 18:05:54: [2024-10-30 18:05:54] iter = 04610, loss = 2.2801
2024-10-30 18:05:57: [2024-10-30 18:05:57] iter = 04620, loss = 2.7080
2024-10-30 18:06:00: [2024-10-30 18:06:00] iter = 04630, loss = 2.1292
2024-10-30 18:06:02: [2024-10-30 18:06:02] iter = 04640, loss = 2.8910
2024-10-30 18:06:06: [2024-10-30 18:06:06] iter = 04650, loss = 2.4616
2024-10-30 18:06:08: [2024-10-30 18:06:08] iter = 04660, loss = 2.1844
2024-10-30 18:06:10: [2024-10-30 18:06:10] iter = 04670, loss = 2.6276
2024-10-30 18:06:13: [2024-10-30 18:06:13] iter = 04680, loss = 2.2422
2024-10-30 18:06:16: [2024-10-30 18:06:16] iter = 04690, loss = 2.3964
2024-10-30 18:06:18: [2024-10-30 18:06:18] iter = 04700, loss = 2.3185
2024-10-30 18:06:21: [2024-10-30 18:06:21] iter = 04710, loss = 2.5547
2024-10-30 18:06:24: [2024-10-30 18:06:24] iter = 04720, loss = 1.7328
2024-10-30 18:06:28: [2024-10-30 18:06:28] iter = 04730, loss = 3.2868
2024-10-30 18:06:31: [2024-10-30 18:06:31] iter = 04740, loss = 2.0712
2024-10-30 18:06:34: [2024-10-30 18:06:34] iter = 04750, loss = 1.9775
2024-10-30 18:06:37: [2024-10-30 18:06:37] iter = 04760, loss = 2.6880
2024-10-30 18:06:40: [2024-10-30 18:06:40] iter = 04770, loss = 1.9284
2024-10-30 18:06:43: [2024-10-30 18:06:43] iter = 04780, loss = 2.9994
2024-10-30 18:06:46: [2024-10-30 18:06:46] iter = 04790, loss = 3.1809
2024-10-30 18:06:48: [2024-10-30 18:06:48] iter = 04800, loss = 2.1287
2024-10-30 18:06:51: [2024-10-30 18:06:51] iter = 04810, loss = 2.1943
2024-10-30 18:06:54: [2024-10-30 18:06:54] iter = 04820, loss = 2.3133
2024-10-30 18:06:57: [2024-10-30 18:06:57] iter = 04830, loss = 1.8395
2024-10-30 18:06:59: [2024-10-30 18:06:59] iter = 04840, loss = 1.8670
2024-10-30 18:07:01: [2024-10-30 18:07:01] iter = 04850, loss = 1.5915
2024-10-30 18:07:04: [2024-10-30 18:07:04] iter = 04860, loss = 2.3914
2024-10-30 18:07:05: [2024-10-30 18:07:05] iter = 04870, loss = 1.8255
2024-10-30 18:07:09: [2024-10-30 18:07:09] iter = 04880, loss = 2.1475
2024-10-30 18:07:12: [2024-10-30 18:07:12] iter = 04890, loss = 6.4001
2024-10-30 18:07:16: [2024-10-30 18:07:16] iter = 04900, loss = 2.4600
2024-10-30 18:07:18: [2024-10-30 18:07:18] iter = 04910, loss = 2.0933
2024-10-30 18:07:22: [2024-10-30 18:07:22] iter = 04920, loss = 2.2059
2024-10-30 18:07:26: [2024-10-30 18:07:26] iter = 04930, loss = 2.9767
2024-10-30 18:07:30: [2024-10-30 18:07:30] iter = 04940, loss = 3.5631
2024-10-30 18:07:32: [2024-10-30 18:07:32] iter = 04950, loss = 2.0441
2024-10-30 18:07:35: [2024-10-30 18:07:35] iter = 04960, loss = 1.9615
2024-10-30 18:07:38: [2024-10-30 18:07:38] iter = 04970, loss = 4.1918
2024-10-30 18:07:41: [2024-10-30 18:07:41] iter = 04980, loss = 3.2479
2024-10-30 18:07:43: [2024-10-30 18:07:43] iter = 04990, loss = 2.0894
2024-10-30 18:07:47: [2024-10-30 18:07:47] iter = 05000, loss = 2.4799
2024-10-30 18:07:51: [2024-10-30 18:07:51] iter = 05010, loss = 2.0819
2024-10-30 18:07:54: [2024-10-30 18:07:54] iter = 05020, loss = 2.3500
2024-10-30 18:07:57: [2024-10-30 18:07:57] iter = 05030, loss = 2.1848
2024-10-30 18:08:00: [2024-10-30 18:08:00] iter = 05040, loss = 2.5797
2024-10-30 18:08:04: [2024-10-30 18:08:04] iter = 05050, loss = 2.0629
2024-10-30 18:08:07: [2024-10-30 18:08:07] iter = 05060, loss = 2.0886
2024-10-30 18:08:11: [2024-10-30 18:08:11] iter = 05070, loss = 2.5833
2024-10-30 18:08:14: [2024-10-30 18:08:14] iter = 05080, loss = 3.9484
2024-10-30 18:08:18: [2024-10-30 18:08:18] iter = 05090, loss = 2.4515
2024-10-30 18:08:21: [2024-10-30 18:08:21] iter = 05100, loss = 1.9390
2024-10-30 18:08:24: [2024-10-30 18:08:24] iter = 05110, loss = 2.3636
2024-10-30 18:08:28: [2024-10-30 18:08:28] iter = 05120, loss = 2.0502
2024-10-30 18:08:32: [2024-10-30 18:08:32] iter = 05130, loss = 1.8285
2024-10-30 18:08:36: [2024-10-30 18:08:36] iter = 05140, loss = 2.3123
2024-10-30 18:08:38: [2024-10-30 18:08:38] iter = 05150, loss = 2.2837
2024-10-30 18:08:42: [2024-10-30 18:08:42] iter = 05160, loss = 2.1348
2024-10-30 18:08:46: [2024-10-30 18:08:46] iter = 05170, loss = 2.3354
2024-10-30 18:08:49: [2024-10-30 18:08:49] iter = 05180, loss = 1.9457
2024-10-30 18:08:52: [2024-10-30 18:08:52] iter = 05190, loss = 1.8965
2024-10-30 18:08:55: [2024-10-30 18:08:55] iter = 05200, loss = 2.2816
2024-10-30 18:08:57: [2024-10-30 18:08:57] iter = 05210, loss = 1.8681
2024-10-30 18:09:00: [2024-10-30 18:09:00] iter = 05220, loss = 2.9924
2024-10-30 18:09:03: [2024-10-30 18:09:03] iter = 05230, loss = 2.0660
2024-10-30 18:09:06: [2024-10-30 18:09:06] iter = 05240, loss = 2.6936
2024-10-30 18:09:10: [2024-10-30 18:09:10] iter = 05250, loss = 2.6367
2024-10-30 18:09:13: [2024-10-30 18:09:13] iter = 05260, loss = 2.1965
2024-10-30 18:09:18: [2024-10-30 18:09:18] iter = 05270, loss = 2.0107
2024-10-30 18:09:22: [2024-10-30 18:09:22] iter = 05280, loss = 2.3512
2024-10-30 18:09:26: [2024-10-30 18:09:26] iter = 05290, loss = 2.7889
2024-10-30 18:09:29: [2024-10-30 18:09:29] iter = 05300, loss = 1.8998
2024-10-30 18:09:33: [2024-10-30 18:09:33] iter = 05310, loss = 2.2424
2024-10-30 18:09:36: [2024-10-30 18:09:36] iter = 05320, loss = 3.2825
2024-10-30 18:09:38: [2024-10-30 18:09:38] iter = 05330, loss = 2.3558
2024-10-30 18:09:41: [2024-10-30 18:09:41] iter = 05340, loss = 2.2982
2024-10-30 18:09:46: [2024-10-30 18:09:46] iter = 05350, loss = 3.2046
2024-10-30 18:09:49: [2024-10-30 18:09:49] iter = 05360, loss = 2.4406
2024-10-30 18:09:52: [2024-10-30 18:09:52] iter = 05370, loss = 2.1728
2024-10-30 18:09:55: [2024-10-30 18:09:55] iter = 05380, loss = 2.0658
2024-10-30 18:09:57: [2024-10-30 18:09:57] iter = 05390, loss = 1.9963
2024-10-30 18:10:00: [2024-10-30 18:10:00] iter = 05400, loss = 2.5572
2024-10-30 18:10:04: [2024-10-30 18:10:04] iter = 05410, loss = 2.0256
2024-10-30 18:10:08: [2024-10-30 18:10:08] iter = 05420, loss = 2.8992
2024-10-30 18:10:11: [2024-10-30 18:10:11] iter = 05430, loss = 2.1810
2024-10-30 18:10:15: [2024-10-30 18:10:15] iter = 05440, loss = 2.0978
2024-10-30 18:10:18: [2024-10-30 18:10:18] iter = 05450, loss = 2.0089
2024-10-30 18:10:20: [2024-10-30 18:10:20] iter = 05460, loss = 2.4263
2024-10-30 18:10:23: [2024-10-30 18:10:23] iter = 05470, loss = 2.1814
2024-10-30 18:10:26: [2024-10-30 18:10:26] iter = 05480, loss = 1.6941
2024-10-30 18:10:30: [2024-10-30 18:10:30] iter = 05490, loss = 2.4392
2024-10-30 18:10:33: [2024-10-30 18:10:33] iter = 05500, loss = 2.1078
2024-10-30 18:10:36: [2024-10-30 18:10:36] iter = 05510, loss = 2.1511
2024-10-30 18:10:39: [2024-10-30 18:10:39] iter = 05520, loss = 1.9637
2024-10-30 18:10:43: [2024-10-30 18:10:43] iter = 05530, loss = 2.2230
2024-10-30 18:10:47: [2024-10-30 18:10:46] iter = 05540, loss = 2.1856
2024-10-30 18:10:49: [2024-10-30 18:10:49] iter = 05550, loss = 2.5755
2024-10-30 18:10:52: [2024-10-30 18:10:52] iter = 05560, loss = 2.3336
2024-10-30 18:10:55: [2024-10-30 18:10:55] iter = 05570, loss = 2.9956
2024-10-30 18:10:58: [2024-10-30 18:10:58] iter = 05580, loss = 2.4805
2024-10-30 18:11:02: [2024-10-30 18:11:02] iter = 05590, loss = 2.4456
2024-10-30 18:11:06: [2024-10-30 18:11:06] iter = 05600, loss = 3.6211
2024-10-30 18:11:08: [2024-10-30 18:11:08] iter = 05610, loss = 2.2414
2024-10-30 18:11:11: [2024-10-30 18:11:11] iter = 05620, loss = 2.5702
2024-10-30 18:11:14: [2024-10-30 18:11:14] iter = 05630, loss = 3.4549
2024-10-30 18:11:17: [2024-10-30 18:11:17] iter = 05640, loss = 2.5420
2024-10-30 18:11:21: [2024-10-30 18:11:21] iter = 05650, loss = 2.1540
2024-10-30 18:11:24: [2024-10-30 18:11:24] iter = 05660, loss = 2.2831
2024-10-30 18:11:27: [2024-10-30 18:11:27] iter = 05670, loss = 2.3007
2024-10-30 18:11:30: [2024-10-30 18:11:30] iter = 05680, loss = 2.2177
2024-10-30 18:11:33: [2024-10-30 18:11:33] iter = 05690, loss = 2.2776
2024-10-30 18:11:37: [2024-10-30 18:11:37] iter = 05700, loss = 2.2056
2024-10-30 18:11:40: [2024-10-30 18:11:40] iter = 05710, loss = 2.2436
2024-10-30 18:11:42: [2024-10-30 18:11:42] iter = 05720, loss = 2.3077
2024-10-30 18:11:45: [2024-10-30 18:11:45] iter = 05730, loss = 1.7873
2024-10-30 18:11:48: [2024-10-30 18:11:48] iter = 05740, loss = 2.1991
2024-10-30 18:11:51: [2024-10-30 18:11:51] iter = 05750, loss = 1.9897
2024-10-30 18:11:55: [2024-10-30 18:11:55] iter = 05760, loss = 2.1677
2024-10-30 18:11:59: [2024-10-30 18:11:59] iter = 05770, loss = 2.0134
2024-10-30 18:12:02: [2024-10-30 18:12:02] iter = 05780, loss = 1.6968
2024-10-30 18:12:06: [2024-10-30 18:12:06] iter = 05790, loss = 1.9831
2024-10-30 18:12:10: [2024-10-30 18:12:10] iter = 05800, loss = 2.4611
2024-10-30 18:12:13: [2024-10-30 18:12:13] iter = 05810, loss = 1.8518
2024-10-30 18:12:16: [2024-10-30 18:12:16] iter = 05820, loss = 2.4877
2024-10-30 18:12:20: [2024-10-30 18:12:20] iter = 05830, loss = 2.1250
2024-10-30 18:12:23: [2024-10-30 18:12:23] iter = 05840, loss = 1.8400
2024-10-30 18:12:28: [2024-10-30 18:12:28] iter = 05850, loss = 2.0497
2024-10-30 18:12:31: [2024-10-30 18:12:31] iter = 05860, loss = 2.4822
2024-10-30 18:12:35: [2024-10-30 18:12:35] iter = 05870, loss = 2.4683
2024-10-30 18:12:39: [2024-10-30 18:12:39] iter = 05880, loss = 1.8918
2024-10-30 18:12:42: [2024-10-30 18:12:42] iter = 05890, loss = 2.3845
2024-10-30 18:12:45: [2024-10-30 18:12:45] iter = 05900, loss = 2.1029
2024-10-30 18:12:48: [2024-10-30 18:12:48] iter = 05910, loss = 3.5219
2024-10-30 18:12:50: [2024-10-30 18:12:50] iter = 05920, loss = 1.9266
2024-10-30 18:12:53: [2024-10-30 18:12:53] iter = 05930, loss = 2.0080
2024-10-30 18:12:57: [2024-10-30 18:12:57] iter = 05940, loss = 1.5571
2024-10-30 18:13:00: [2024-10-30 18:13:00] iter = 05950, loss = 3.2262
2024-10-30 18:13:04: [2024-10-30 18:13:04] iter = 05960, loss = 2.2917
2024-10-30 18:13:08: [2024-10-30 18:13:08] iter = 05970, loss = 2.1450
2024-10-30 18:13:11: [2024-10-30 18:13:11] iter = 05980, loss = 2.0379
2024-10-30 18:13:14: [2024-10-30 18:13:14] iter = 05990, loss = 2.5503
2024-10-30 18:13:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 18:13:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:13:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97074}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:15:29: Evaluate 5 random ConvNet, ACCmean = 0.6064 ACCstd = 0.0074
-------------------------
2024-10-30 18:15:29: Evaluate 5 random ConvNet, SENmean = 0.5835 SENstd = 0.0068
-------------------------
2024-10-30 18:15:29: Evaluate 5 random ConvNet, SPEmean = 0.9599 SPEstd = 0.0008
-------------------------
2024-10-30 18:15:29: Evaluate 5 random ConvNet, F!mean = 0.5730 F!std = 0.0077
-------------------------
2024-10-30 18:15:29: Evaluate 5 random ConvNet, mean = 0.6064 std = 0.0074
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:15:30: [2024-10-30 18:15:30] iter = 06000, loss = 2.0340
2024-10-30 18:15:33: [2024-10-30 18:15:33] iter = 06010, loss = 2.0497
2024-10-30 18:15:36: [2024-10-30 18:15:36] iter = 06020, loss = 1.8608
2024-10-30 18:15:39: [2024-10-30 18:15:39] iter = 06030, loss = 2.1102
2024-10-30 18:15:42: [2024-10-30 18:15:42] iter = 06040, loss = 3.5303
2024-10-30 18:15:45: [2024-10-30 18:15:45] iter = 06050, loss = 2.4468
2024-10-30 18:15:48: [2024-10-30 18:15:48] iter = 06060, loss = 2.1332
2024-10-30 18:15:52: [2024-10-30 18:15:52] iter = 06070, loss = 2.0683
2024-10-30 18:15:55: [2024-10-30 18:15:55] iter = 06080, loss = 2.2864
2024-10-30 18:15:59: [2024-10-30 18:15:59] iter = 06090, loss = 2.0954
2024-10-30 18:16:02: [2024-10-30 18:16:02] iter = 06100, loss = 1.8905
2024-10-30 18:16:05: [2024-10-30 18:16:05] iter = 06110, loss = 2.4496
2024-10-30 18:16:09: [2024-10-30 18:16:09] iter = 06120, loss = 1.8526
2024-10-30 18:16:12: [2024-10-30 18:16:12] iter = 06130, loss = 2.3921
2024-10-30 18:16:15: [2024-10-30 18:16:15] iter = 06140, loss = 2.0569
2024-10-30 18:16:19: [2024-10-30 18:16:19] iter = 06150, loss = 1.9250
2024-10-30 18:16:22: [2024-10-30 18:16:22] iter = 06160, loss = 2.3225
2024-10-30 18:16:25: [2024-10-30 18:16:25] iter = 06170, loss = 2.4551
2024-10-30 18:16:28: [2024-10-30 18:16:28] iter = 06180, loss = 2.6609
2024-10-30 18:16:30: [2024-10-30 18:16:30] iter = 06190, loss = 1.9361
2024-10-30 18:16:32: [2024-10-30 18:16:32] iter = 06200, loss = 1.9209
2024-10-30 18:16:35: [2024-10-30 18:16:35] iter = 06210, loss = 4.2756
2024-10-30 18:16:38: [2024-10-30 18:16:38] iter = 06220, loss = 2.5896
2024-10-30 18:16:41: [2024-10-30 18:16:41] iter = 06230, loss = 2.0941
2024-10-30 18:16:45: [2024-10-30 18:16:45] iter = 06240, loss = 2.2815
2024-10-30 18:16:48: [2024-10-30 18:16:48] iter = 06250, loss = 2.0971
2024-10-30 18:16:51: [2024-10-30 18:16:51] iter = 06260, loss = 2.1137
2024-10-30 18:16:54: [2024-10-30 18:16:54] iter = 06270, loss = 2.3388
2024-10-30 18:16:58: [2024-10-30 18:16:58] iter = 06280, loss = 5.8041
2024-10-30 18:17:02: [2024-10-30 18:17:02] iter = 06290, loss = 2.2608
2024-10-30 18:17:05: [2024-10-30 18:17:05] iter = 06300, loss = 2.2235
2024-10-30 18:17:08: [2024-10-30 18:17:08] iter = 06310, loss = 1.7656
2024-10-30 18:17:12: [2024-10-30 18:17:12] iter = 06320, loss = 2.0619
2024-10-30 18:17:15: [2024-10-30 18:17:15] iter = 06330, loss = 2.3723
2024-10-30 18:17:19: [2024-10-30 18:17:19] iter = 06340, loss = 2.1181
2024-10-30 18:17:23: [2024-10-30 18:17:23] iter = 06350, loss = 2.1909
2024-10-30 18:17:27: [2024-10-30 18:17:27] iter = 06360, loss = 2.6999
2024-10-30 18:17:31: [2024-10-30 18:17:31] iter = 06370, loss = 1.9059
2024-10-30 18:17:35: [2024-10-30 18:17:35] iter = 06380, loss = 2.9950
2024-10-30 18:17:38: [2024-10-30 18:17:38] iter = 06390, loss = 2.6699
2024-10-30 18:17:42: [2024-10-30 18:17:42] iter = 06400, loss = 2.1600
2024-10-30 18:17:45: [2024-10-30 18:17:45] iter = 06410, loss = 2.4783
2024-10-30 18:17:48: [2024-10-30 18:17:48] iter = 06420, loss = 1.9285
2024-10-30 18:17:52: [2024-10-30 18:17:52] iter = 06430, loss = 2.7211
2024-10-30 18:17:56: [2024-10-30 18:17:56] iter = 06440, loss = 2.4365
2024-10-30 18:17:59: [2024-10-30 18:17:59] iter = 06450, loss = 2.2603
2024-10-30 18:18:02: [2024-10-30 18:18:02] iter = 06460, loss = 2.0589
2024-10-30 18:18:05: [2024-10-30 18:18:05] iter = 06470, loss = 1.8481
2024-10-30 18:18:08: [2024-10-30 18:18:08] iter = 06480, loss = 1.8047
2024-10-30 18:18:12: [2024-10-30 18:18:12] iter = 06490, loss = 1.8844
2024-10-30 18:18:15: [2024-10-30 18:18:15] iter = 06500, loss = 2.7707
2024-10-30 18:18:19: [2024-10-30 18:18:19] iter = 06510, loss = 2.0587
2024-10-30 18:18:22: [2024-10-30 18:18:22] iter = 06520, loss = 2.7184
2024-10-30 18:18:25: [2024-10-30 18:18:25] iter = 06530, loss = 2.4469
2024-10-30 18:18:28: [2024-10-30 18:18:28] iter = 06540, loss = 2.4494
2024-10-30 18:18:32: [2024-10-30 18:18:32] iter = 06550, loss = 1.9814
2024-10-30 18:18:35: [2024-10-30 18:18:35] iter = 06560, loss = 1.8599
2024-10-30 18:18:39: [2024-10-30 18:18:39] iter = 06570, loss = 2.1235
2024-10-30 18:18:42: [2024-10-30 18:18:42] iter = 06580, loss = 2.1289
2024-10-30 18:18:47: [2024-10-30 18:18:47] iter = 06590, loss = 1.9362
2024-10-30 18:18:51: [2024-10-30 18:18:51] iter = 06600, loss = 2.4425
2024-10-30 18:18:54: [2024-10-30 18:18:54] iter = 06610, loss = 2.3162
2024-10-30 18:18:58: [2024-10-30 18:18:58] iter = 06620, loss = 2.6637
2024-10-30 18:19:01: [2024-10-30 18:19:01] iter = 06630, loss = 3.1528
2024-10-30 18:19:05: [2024-10-30 18:19:05] iter = 06640, loss = 2.2817
2024-10-30 18:19:08: [2024-10-30 18:19:08] iter = 06650, loss = 2.8654
2024-10-30 18:19:11: [2024-10-30 18:19:11] iter = 06660, loss = 3.0674
2024-10-30 18:19:14: [2024-10-30 18:19:14] iter = 06670, loss = 1.8549
2024-10-30 18:19:17: [2024-10-30 18:19:17] iter = 06680, loss = 1.9345
2024-10-30 18:19:20: [2024-10-30 18:19:20] iter = 06690, loss = 1.9575
2024-10-30 18:19:24: [2024-10-30 18:19:24] iter = 06700, loss = 2.0824
2024-10-30 18:19:27: [2024-10-30 18:19:27] iter = 06710, loss = 1.7303
2024-10-30 18:19:30: [2024-10-30 18:19:30] iter = 06720, loss = 5.0672
2024-10-30 18:19:33: [2024-10-30 18:19:33] iter = 06730, loss = 2.9507
2024-10-30 18:19:37: [2024-10-30 18:19:37] iter = 06740, loss = 2.0618
2024-10-30 18:19:40: [2024-10-30 18:19:40] iter = 06750, loss = 2.4227
2024-10-30 18:19:43: [2024-10-30 18:19:43] iter = 06760, loss = 2.2928
2024-10-30 18:19:46: [2024-10-30 18:19:46] iter = 06770, loss = 4.5690
2024-10-30 18:19:49: [2024-10-30 18:19:49] iter = 06780, loss = 1.8661
2024-10-30 18:19:52: [2024-10-30 18:19:52] iter = 06790, loss = 2.1979
2024-10-30 18:19:55: [2024-10-30 18:19:55] iter = 06800, loss = 2.0946
2024-10-30 18:19:57: [2024-10-30 18:19:57] iter = 06810, loss = 2.7023
2024-10-30 18:20:00: [2024-10-30 18:20:00] iter = 06820, loss = 3.5874
2024-10-30 18:20:04: [2024-10-30 18:20:04] iter = 06830, loss = 1.9776
2024-10-30 18:20:07: [2024-10-30 18:20:07] iter = 06840, loss = 2.8764
2024-10-30 18:20:09: [2024-10-30 18:20:09] iter = 06850, loss = 2.4563
2024-10-30 18:20:13: [2024-10-30 18:20:13] iter = 06860, loss = 3.4481
2024-10-30 18:20:16: [2024-10-30 18:20:16] iter = 06870, loss = 2.3221
2024-10-30 18:20:19: [2024-10-30 18:20:18] iter = 06880, loss = 2.3159
2024-10-30 18:20:21: [2024-10-30 18:20:21] iter = 06890, loss = 2.7462
2024-10-30 18:20:24: [2024-10-30 18:20:24] iter = 06900, loss = 1.7763
2024-10-30 18:20:27: [2024-10-30 18:20:27] iter = 06910, loss = 2.0435
2024-10-30 18:20:30: [2024-10-30 18:20:30] iter = 06920, loss = 1.9877
2024-10-30 18:20:33: [2024-10-30 18:20:33] iter = 06930, loss = 2.3246
2024-10-30 18:20:37: [2024-10-30 18:20:37] iter = 06940, loss = 1.8953
2024-10-30 18:20:40: [2024-10-30 18:20:40] iter = 06950, loss = 2.6699
2024-10-30 18:20:43: [2024-10-30 18:20:43] iter = 06960, loss = 2.0487
2024-10-30 18:20:47: [2024-10-30 18:20:47] iter = 06970, loss = 2.6389
2024-10-30 18:20:50: [2024-10-30 18:20:50] iter = 06980, loss = 2.3155
2024-10-30 18:20:53: [2024-10-30 18:20:53] iter = 06990, loss = 1.9380
2024-10-30 18:20:56: [2024-10-30 18:20:56] iter = 07000, loss = 2.4442
2024-10-30 18:21:00: [2024-10-30 18:21:00] iter = 07010, loss = 2.3655
2024-10-30 18:21:03: [2024-10-30 18:21:03] iter = 07020, loss = 2.1391
2024-10-30 18:21:06: [2024-10-30 18:21:06] iter = 07030, loss = 2.4624
2024-10-30 18:21:10: [2024-10-30 18:21:10] iter = 07040, loss = 1.7193
2024-10-30 18:21:13: [2024-10-30 18:21:13] iter = 07050, loss = 1.9763
2024-10-30 18:21:16: [2024-10-30 18:21:16] iter = 07060, loss = 2.5728
2024-10-30 18:21:20: [2024-10-30 18:21:20] iter = 07070, loss = 2.2829
2024-10-30 18:21:23: [2024-10-30 18:21:23] iter = 07080, loss = 2.7145
2024-10-30 18:21:27: [2024-10-30 18:21:27] iter = 07090, loss = 2.5229
2024-10-30 18:21:30: [2024-10-30 18:21:30] iter = 07100, loss = 2.3181
2024-10-30 18:21:34: [2024-10-30 18:21:34] iter = 07110, loss = 2.0342
2024-10-30 18:21:38: [2024-10-30 18:21:38] iter = 07120, loss = 1.9447
2024-10-30 18:21:41: [2024-10-30 18:21:41] iter = 07130, loss = 1.7161
2024-10-30 18:21:44: [2024-10-30 18:21:44] iter = 07140, loss = 2.5035
2024-10-30 18:21:47: [2024-10-30 18:21:47] iter = 07150, loss = 2.3302
2024-10-30 18:21:51: [2024-10-30 18:21:51] iter = 07160, loss = 2.3175
2024-10-30 18:21:54: [2024-10-30 18:21:54] iter = 07170, loss = 2.1687
2024-10-30 18:21:58: [2024-10-30 18:21:58] iter = 07180, loss = 3.1276
2024-10-30 18:22:02: [2024-10-30 18:22:02] iter = 07190, loss = 2.5359
2024-10-30 18:22:05: [2024-10-30 18:22:05] iter = 07200, loss = 2.2887
2024-10-30 18:22:08: [2024-10-30 18:22:08] iter = 07210, loss = 2.7163
2024-10-30 18:22:12: [2024-10-30 18:22:12] iter = 07220, loss = 2.0441
2024-10-30 18:22:15: [2024-10-30 18:22:15] iter = 07230, loss = 2.3642
2024-10-30 18:22:19: [2024-10-30 18:22:19] iter = 07240, loss = 2.3960
2024-10-30 18:22:22: [2024-10-30 18:22:22] iter = 07250, loss = 1.8755
2024-10-30 18:22:25: [2024-10-30 18:22:25] iter = 07260, loss = 2.5035
2024-10-30 18:22:28: [2024-10-30 18:22:28] iter = 07270, loss = 2.4775
2024-10-30 18:22:32: [2024-10-30 18:22:32] iter = 07280, loss = 2.3999
2024-10-30 18:22:35: [2024-10-30 18:22:35] iter = 07290, loss = 2.0395
2024-10-30 18:22:38: [2024-10-30 18:22:38] iter = 07300, loss = 2.3820
2024-10-30 18:22:42: [2024-10-30 18:22:42] iter = 07310, loss = 1.9540
2024-10-30 18:22:45: [2024-10-30 18:22:45] iter = 07320, loss = 2.1511
2024-10-30 18:22:48: [2024-10-30 18:22:48] iter = 07330, loss = 2.4059
2024-10-30 18:22:52: [2024-10-30 18:22:52] iter = 07340, loss = 2.2278
2024-10-30 18:22:55: [2024-10-30 18:22:55] iter = 07350, loss = 2.3696
2024-10-30 18:23:00: [2024-10-30 18:23:00] iter = 07360, loss = 3.5395
2024-10-30 18:23:03: [2024-10-30 18:23:03] iter = 07370, loss = 2.2705
2024-10-30 18:23:06: [2024-10-30 18:23:06] iter = 07380, loss = 2.6210
2024-10-30 18:23:10: [2024-10-30 18:23:10] iter = 07390, loss = 3.3432
2024-10-30 18:23:14: [2024-10-30 18:23:14] iter = 07400, loss = 2.5189
2024-10-30 18:23:18: [2024-10-30 18:23:18] iter = 07410, loss = 1.9567
2024-10-30 18:23:21: [2024-10-30 18:23:21] iter = 07420, loss = 2.0380
2024-10-30 18:23:24: [2024-10-30 18:23:24] iter = 07430, loss = 2.2718
2024-10-30 18:23:27: [2024-10-30 18:23:27] iter = 07440, loss = 2.9002
2024-10-30 18:23:30: [2024-10-30 18:23:30] iter = 07450, loss = 3.4352
2024-10-30 18:23:33: [2024-10-30 18:23:33] iter = 07460, loss = 2.9117
2024-10-30 18:23:36: [2024-10-30 18:23:36] iter = 07470, loss = 2.1119
2024-10-30 18:23:40: [2024-10-30 18:23:40] iter = 07480, loss = 1.8796
2024-10-30 18:23:44: [2024-10-30 18:23:44] iter = 07490, loss = 2.2487
2024-10-30 18:23:48: [2024-10-30 18:23:48] iter = 07500, loss = 4.2809
2024-10-30 18:23:51: [2024-10-30 18:23:51] iter = 07510, loss = 3.2397
2024-10-30 18:23:54: [2024-10-30 18:23:54] iter = 07520, loss = 2.7413
2024-10-30 18:23:57: [2024-10-30 18:23:57] iter = 07530, loss = 2.0911
2024-10-30 18:24:00: [2024-10-30 18:24:00] iter = 07540, loss = 2.1506
2024-10-30 18:24:03: [2024-10-30 18:24:03] iter = 07550, loss = 2.1183
2024-10-30 18:24:06: [2024-10-30 18:24:06] iter = 07560, loss = 2.7204
2024-10-30 18:24:09: [2024-10-30 18:24:09] iter = 07570, loss = 3.0770
2024-10-30 18:24:11: [2024-10-30 18:24:11] iter = 07580, loss = 2.4823
2024-10-30 18:24:14: [2024-10-30 18:24:14] iter = 07590, loss = 2.0454
2024-10-30 18:24:18: [2024-10-30 18:24:18] iter = 07600, loss = 2.0285
2024-10-30 18:24:22: [2024-10-30 18:24:22] iter = 07610, loss = 2.1343
2024-10-30 18:24:25: [2024-10-30 18:24:25] iter = 07620, loss = 3.4022
2024-10-30 18:24:29: [2024-10-30 18:24:29] iter = 07630, loss = 2.3015
2024-10-30 18:24:32: [2024-10-30 18:24:32] iter = 07640, loss = 3.6939
2024-10-30 18:24:36: [2024-10-30 18:24:36] iter = 07650, loss = 2.0082
2024-10-30 18:24:39: [2024-10-30 18:24:39] iter = 07660, loss = 2.5173
2024-10-30 18:24:42: [2024-10-30 18:24:42] iter = 07670, loss = 2.4271
2024-10-30 18:24:46: [2024-10-30 18:24:46] iter = 07680, loss = 2.1212
2024-10-30 18:24:49: [2024-10-30 18:24:49] iter = 07690, loss = 2.0502
2024-10-30 18:24:52: [2024-10-30 18:24:52] iter = 07700, loss = 1.9741
2024-10-30 18:24:55: [2024-10-30 18:24:55] iter = 07710, loss = 1.7507
2024-10-30 18:24:59: [2024-10-30 18:24:59] iter = 07720, loss = 2.5816
2024-10-30 18:25:02: [2024-10-30 18:25:02] iter = 07730, loss = 1.8313
2024-10-30 18:25:05: [2024-10-30 18:25:05] iter = 07740, loss = 2.0773
2024-10-30 18:25:08: [2024-10-30 18:25:08] iter = 07750, loss = 2.1975
2024-10-30 18:25:12: [2024-10-30 18:25:12] iter = 07760, loss = 2.1963
2024-10-30 18:25:15: [2024-10-30 18:25:15] iter = 07770, loss = 2.6818
2024-10-30 18:25:18: [2024-10-30 18:25:18] iter = 07780, loss = 2.6591
2024-10-30 18:25:21: [2024-10-30 18:25:21] iter = 07790, loss = 2.0726
2024-10-30 18:25:25: [2024-10-30 18:25:25] iter = 07800, loss = 2.2159
2024-10-30 18:25:28: [2024-10-30 18:25:28] iter = 07810, loss = 2.4866
2024-10-30 18:25:32: [2024-10-30 18:25:32] iter = 07820, loss = 4.6590
2024-10-30 18:25:35: [2024-10-30 18:25:35] iter = 07830, loss = 2.0160
2024-10-30 18:25:39: [2024-10-30 18:25:39] iter = 07840, loss = 2.3631
2024-10-30 18:25:42: [2024-10-30 18:25:42] iter = 07850, loss = 1.7645
2024-10-30 18:25:44: [2024-10-30 18:25:44] iter = 07860, loss = 2.1672
2024-10-30 18:25:47: [2024-10-30 18:25:47] iter = 07870, loss = 2.3257
2024-10-30 18:25:50: [2024-10-30 18:25:50] iter = 07880, loss = 3.3295
2024-10-30 18:25:54: [2024-10-30 18:25:54] iter = 07890, loss = 2.5001
2024-10-30 18:25:56: [2024-10-30 18:25:56] iter = 07900, loss = 2.0729
2024-10-30 18:26:00: [2024-10-30 18:26:00] iter = 07910, loss = 2.0257
2024-10-30 18:26:03: [2024-10-30 18:26:03] iter = 07920, loss = 1.9238
2024-10-30 18:26:06: [2024-10-30 18:26:06] iter = 07930, loss = 1.9618
2024-10-30 18:26:09: [2024-10-30 18:26:09] iter = 07940, loss = 1.7973
2024-10-30 18:26:13: [2024-10-30 18:26:13] iter = 07950, loss = 2.8587
2024-10-30 18:26:16: [2024-10-30 18:26:16] iter = 07960, loss = 1.7130
2024-10-30 18:26:19: [2024-10-30 18:26:19] iter = 07970, loss = 2.0200
2024-10-30 18:26:22: [2024-10-30 18:26:22] iter = 07980, loss = 2.1093
2024-10-30 18:26:26: [2024-10-30 18:26:26] iter = 07990, loss = 2.5262
2024-10-30 18:26:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 18:26:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:26:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 90211}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:28:35: Evaluate 5 random ConvNet, ACCmean = 0.6128 ACCstd = 0.0044
-------------------------
2024-10-30 18:28:35: Evaluate 5 random ConvNet, SENmean = 0.5927 SENstd = 0.0050
-------------------------
2024-10-30 18:28:35: Evaluate 5 random ConvNet, SPEmean = 0.9606 SPEstd = 0.0004
-------------------------
2024-10-30 18:28:35: Evaluate 5 random ConvNet, F!mean = 0.5806 F!std = 0.0047
-------------------------
2024-10-30 18:28:35: Evaluate 5 random ConvNet, mean = 0.6128 std = 0.0044
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:28:35: [2024-10-30 18:28:35] iter = 08000, loss = 2.9695
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:28:39: [2024-10-30 18:28:39] iter = 08010, loss = 1.8936
2024-10-30 18:28:43: [2024-10-30 18:28:43] iter = 08020, loss = 1.9139
2024-10-30 18:28:46: [2024-10-30 18:28:46] iter = 08030, loss = 2.5558
2024-10-30 18:28:50: [2024-10-30 18:28:49] iter = 08040, loss = 2.5863
2024-10-30 18:28:52: [2024-10-30 18:28:52] iter = 08050, loss = 1.9954
2024-10-30 18:28:56: [2024-10-30 18:28:56] iter = 08060, loss = 1.6179
2024-10-30 18:28:59: [2024-10-30 18:28:59] iter = 08070, loss = 2.2326
2024-10-30 18:29:03: [2024-10-30 18:29:03] iter = 08080, loss = 1.9635
2024-10-30 18:29:05: [2024-10-30 18:29:05] iter = 08090, loss = 1.8354
2024-10-30 18:29:08: [2024-10-30 18:29:08] iter = 08100, loss = 2.3054
2024-10-30 18:29:12: [2024-10-30 18:29:12] iter = 08110, loss = 2.0829
2024-10-30 18:29:15: [2024-10-30 18:29:15] iter = 08120, loss = 2.2629
2024-10-30 18:29:18: [2024-10-30 18:29:18] iter = 08130, loss = 2.2581
2024-10-30 18:29:22: [2024-10-30 18:29:22] iter = 08140, loss = 2.2325
2024-10-30 18:29:26: [2024-10-30 18:29:26] iter = 08150, loss = 2.0900
2024-10-30 18:29:29: [2024-10-30 18:29:29] iter = 08160, loss = 1.8571
2024-10-30 18:29:32: [2024-10-30 18:29:32] iter = 08170, loss = 2.5427
2024-10-30 18:29:34: [2024-10-30 18:29:34] iter = 08180, loss = 2.7647
2024-10-30 18:29:36: [2024-10-30 18:29:36] iter = 08190, loss = 2.8074
2024-10-30 18:29:39: [2024-10-30 18:29:39] iter = 08200, loss = 2.2710
2024-10-30 18:29:42: [2024-10-30 18:29:42] iter = 08210, loss = 2.4913
2024-10-30 18:29:46: [2024-10-30 18:29:46] iter = 08220, loss = 2.3277
2024-10-30 18:29:49: [2024-10-30 18:29:49] iter = 08230, loss = 2.1463
2024-10-30 18:29:52: [2024-10-30 18:29:52] iter = 08240, loss = 2.4699
2024-10-30 18:29:55: [2024-10-30 18:29:55] iter = 08250, loss = 2.0366
2024-10-30 18:29:59: [2024-10-30 18:29:59] iter = 08260, loss = 2.1516
2024-10-30 18:30:02: [2024-10-30 18:30:02] iter = 08270, loss = 1.7887
2024-10-30 18:30:06: [2024-10-30 18:30:06] iter = 08280, loss = 1.7512
2024-10-30 18:30:09: [2024-10-30 18:30:09] iter = 08290, loss = 2.4145
2024-10-30 18:30:12: [2024-10-30 18:30:12] iter = 08300, loss = 2.2571
2024-10-30 18:30:15: [2024-10-30 18:30:15] iter = 08310, loss = 2.4078
2024-10-30 18:30:18: [2024-10-30 18:30:18] iter = 08320, loss = 2.4627
2024-10-30 18:30:22: [2024-10-30 18:30:22] iter = 08330, loss = 2.2567
2024-10-30 18:30:26: [2024-10-30 18:30:26] iter = 08340, loss = 1.7648
2024-10-30 18:30:28: [2024-10-30 18:30:28] iter = 08350, loss = 3.4419
2024-10-30 18:30:31: [2024-10-30 18:30:31] iter = 08360, loss = 1.9743
2024-10-30 18:30:34: [2024-10-30 18:30:34] iter = 08370, loss = 2.8153
2024-10-30 18:30:37: [2024-10-30 18:30:37] iter = 08380, loss = 2.1826
2024-10-30 18:30:40: [2024-10-30 18:30:40] iter = 08390, loss = 2.1449
2024-10-30 18:30:42: [2024-10-30 18:30:42] iter = 08400, loss = 2.0375
2024-10-30 18:30:45: [2024-10-30 18:30:45] iter = 08410, loss = 2.1964
2024-10-30 18:30:48: [2024-10-30 18:30:48] iter = 08420, loss = 2.0048
2024-10-30 18:30:51: [2024-10-30 18:30:51] iter = 08430, loss = 2.4386
2024-10-30 18:30:54: [2024-10-30 18:30:54] iter = 08440, loss = 2.3276
2024-10-30 18:30:58: [2024-10-30 18:30:58] iter = 08450, loss = 1.8167
2024-10-30 18:31:01: [2024-10-30 18:31:01] iter = 08460, loss = 4.3718
2024-10-30 18:31:05: [2024-10-30 18:31:05] iter = 08470, loss = 2.1519
2024-10-30 18:31:09: [2024-10-30 18:31:09] iter = 08480, loss = 1.8995
2024-10-30 18:31:12: [2024-10-30 18:31:12] iter = 08490, loss = 2.3492
2024-10-30 18:31:16: [2024-10-30 18:31:16] iter = 08500, loss = 2.1726
2024-10-30 18:31:19: [2024-10-30 18:31:19] iter = 08510, loss = 2.6620
2024-10-30 18:31:22: [2024-10-30 18:31:22] iter = 08520, loss = 2.1631
2024-10-30 18:31:25: [2024-10-30 18:31:25] iter = 08530, loss = 2.3635
2024-10-30 18:31:28: [2024-10-30 18:31:28] iter = 08540, loss = 2.0832
2024-10-30 18:31:31: [2024-10-30 18:31:31] iter = 08550, loss = 2.3437
2024-10-30 18:31:34: [2024-10-30 18:31:34] iter = 08560, loss = 2.0678
2024-10-30 18:31:38: [2024-10-30 18:31:38] iter = 08570, loss = 2.3113
2024-10-30 18:31:41: [2024-10-30 18:31:41] iter = 08580, loss = 2.6281
2024-10-30 18:31:44: [2024-10-30 18:31:44] iter = 08590, loss = 2.0776
2024-10-30 18:31:48: [2024-10-30 18:31:48] iter = 08600, loss = 3.0989
2024-10-30 18:31:52: [2024-10-30 18:31:52] iter = 08610, loss = 1.8954
2024-10-30 18:31:56: [2024-10-30 18:31:56] iter = 08620, loss = 2.0760
2024-10-30 18:32:00: [2024-10-30 18:32:00] iter = 08630, loss = 2.6978
2024-10-30 18:32:04: [2024-10-30 18:32:04] iter = 08640, loss = 1.9390
2024-10-30 18:32:08: [2024-10-30 18:32:08] iter = 08650, loss = 3.2635
2024-10-30 18:32:10: [2024-10-30 18:32:10] iter = 08660, loss = 2.0763
2024-10-30 18:32:14: [2024-10-30 18:32:14] iter = 08670, loss = 2.2369
2024-10-30 18:32:17: [2024-10-30 18:32:17] iter = 08680, loss = 1.8606
2024-10-30 18:32:21: [2024-10-30 18:32:21] iter = 08690, loss = 1.9337
2024-10-30 18:32:25: [2024-10-30 18:32:25] iter = 08700, loss = 4.3796
2024-10-30 18:32:29: [2024-10-30 18:32:29] iter = 08710, loss = 2.0983
2024-10-30 18:32:32: [2024-10-30 18:32:32] iter = 08720, loss = 2.3922
2024-10-30 18:32:35: [2024-10-30 18:32:35] iter = 08730, loss = 2.0717
2024-10-30 18:32:40: [2024-10-30 18:32:40] iter = 08740, loss = 1.7809
2024-10-30 18:32:44: [2024-10-30 18:32:44] iter = 08750, loss = 2.0529
2024-10-30 18:32:47: [2024-10-30 18:32:47] iter = 08760, loss = 2.1252
2024-10-30 18:32:51: [2024-10-30 18:32:51] iter = 08770, loss = 2.5389
2024-10-30 18:32:53: [2024-10-30 18:32:53] iter = 08780, loss = 3.2719
2024-10-30 18:32:57: [2024-10-30 18:32:57] iter = 08790, loss = 2.1706
2024-10-30 18:33:01: [2024-10-30 18:33:01] iter = 08800, loss = 2.1280
2024-10-30 18:33:04: [2024-10-30 18:33:04] iter = 08810, loss = 1.9217
2024-10-30 18:33:08: [2024-10-30 18:33:08] iter = 08820, loss = 2.2396
2024-10-30 18:33:11: [2024-10-30 18:33:11] iter = 08830, loss = 2.2103
2024-10-30 18:33:14: [2024-10-30 18:33:14] iter = 08840, loss = 3.8329
2024-10-30 18:33:18: [2024-10-30 18:33:18] iter = 08850, loss = 2.7205
2024-10-30 18:33:22: [2024-10-30 18:33:22] iter = 08860, loss = 2.3490
2024-10-30 18:33:26: [2024-10-30 18:33:26] iter = 08870, loss = 2.1624
2024-10-30 18:33:29: [2024-10-30 18:33:29] iter = 08880, loss = 1.8555
2024-10-30 18:33:33: [2024-10-30 18:33:33] iter = 08890, loss = 2.1074
2024-10-30 18:33:37: [2024-10-30 18:33:37] iter = 08900, loss = 4.0254
2024-10-30 18:33:40: [2024-10-30 18:33:40] iter = 08910, loss = 1.9083
2024-10-30 18:33:43: [2024-10-30 18:33:43] iter = 08920, loss = 1.9276
2024-10-30 18:33:46: [2024-10-30 18:33:46] iter = 08930, loss = 1.9514
2024-10-30 18:33:50: [2024-10-30 18:33:50] iter = 08940, loss = 1.6074
2024-10-30 18:33:54: [2024-10-30 18:33:54] iter = 08950, loss = 2.2991
2024-10-30 18:33:56: [2024-10-30 18:33:56] iter = 08960, loss = 2.3079
2024-10-30 18:33:59: [2024-10-30 18:33:59] iter = 08970, loss = 2.2950
2024-10-30 18:34:02: [2024-10-30 18:34:02] iter = 08980, loss = 1.9151
2024-10-30 18:34:07: [2024-10-30 18:34:07] iter = 08990, loss = 2.4971
2024-10-30 18:34:10: [2024-10-30 18:34:10] iter = 09000, loss = 1.9561
2024-10-30 18:34:14: [2024-10-30 18:34:14] iter = 09010, loss = 2.4818
2024-10-30 18:34:18: [2024-10-30 18:34:18] iter = 09020, loss = 2.5152
2024-10-30 18:34:22: [2024-10-30 18:34:22] iter = 09030, loss = 1.9352
2024-10-30 18:34:25: [2024-10-30 18:34:25] iter = 09040, loss = 2.1510
2024-10-30 18:34:28: [2024-10-30 18:34:28] iter = 09050, loss = 2.2026
2024-10-30 18:34:32: [2024-10-30 18:34:32] iter = 09060, loss = 2.0624
2024-10-30 18:34:36: [2024-10-30 18:34:36] iter = 09070, loss = 2.6624
2024-10-30 18:34:40: [2024-10-30 18:34:40] iter = 09080, loss = 2.3678
2024-10-30 18:34:44: [2024-10-30 18:34:44] iter = 09090, loss = 2.9431
2024-10-30 18:34:48: [2024-10-30 18:34:48] iter = 09100, loss = 2.0800
2024-10-30 18:34:51: [2024-10-30 18:34:51] iter = 09110, loss = 2.1357
2024-10-30 18:34:55: [2024-10-30 18:34:55] iter = 09120, loss = 1.7020
2024-10-30 18:34:59: [2024-10-30 18:34:59] iter = 09130, loss = 1.8889
2024-10-30 18:35:03: [2024-10-30 18:35:03] iter = 09140, loss = 2.2093
2024-10-30 18:35:06: [2024-10-30 18:35:06] iter = 09150, loss = 2.2103
2024-10-30 18:35:09: [2024-10-30 18:35:09] iter = 09160, loss = 2.0312
2024-10-30 18:35:12: [2024-10-30 18:35:12] iter = 09170, loss = 2.7939
2024-10-30 18:35:16: [2024-10-30 18:35:16] iter = 09180, loss = 2.1587
2024-10-30 18:35:20: [2024-10-30 18:35:20] iter = 09190, loss = 2.6515
2024-10-30 18:35:23: [2024-10-30 18:35:23] iter = 09200, loss = 1.9153
2024-10-30 18:35:26: [2024-10-30 18:35:26] iter = 09210, loss = 2.0865
2024-10-30 18:35:29: [2024-10-30 18:35:29] iter = 09220, loss = 2.1586
2024-10-30 18:35:33: [2024-10-30 18:35:33] iter = 09230, loss = 2.3180
2024-10-30 18:35:37: [2024-10-30 18:35:37] iter = 09240, loss = 3.1877
2024-10-30 18:35:40: [2024-10-30 18:35:40] iter = 09250, loss = 2.4646
2024-10-30 18:35:44: [2024-10-30 18:35:44] iter = 09260, loss = 2.8072
2024-10-30 18:35:47: [2024-10-30 18:35:47] iter = 09270, loss = 3.2272
2024-10-30 18:35:51: [2024-10-30 18:35:51] iter = 09280, loss = 3.2171
2024-10-30 18:35:54: [2024-10-30 18:35:54] iter = 09290, loss = 2.5797
2024-10-30 18:35:59: [2024-10-30 18:35:59] iter = 09300, loss = 2.3542
2024-10-30 18:36:02: [2024-10-30 18:36:02] iter = 09310, loss = 2.2384
2024-10-30 18:36:07: [2024-10-30 18:36:07] iter = 09320, loss = 2.0350
2024-10-30 18:36:11: [2024-10-30 18:36:11] iter = 09330, loss = 2.4736
2024-10-30 18:36:15: [2024-10-30 18:36:15] iter = 09340, loss = 2.1799
2024-10-30 18:36:18: [2024-10-30 18:36:18] iter = 09350, loss = 2.0429
2024-10-30 18:36:21: [2024-10-30 18:36:21] iter = 09360, loss = 2.3602
2024-10-30 18:36:23: [2024-10-30 18:36:23] iter = 09370, loss = 1.9301
2024-10-30 18:36:28: [2024-10-30 18:36:28] iter = 09380, loss = 2.4986
2024-10-30 18:36:31: [2024-10-30 18:36:31] iter = 09390, loss = 2.0723
2024-10-30 18:36:35: [2024-10-30 18:36:35] iter = 09400, loss = 2.1234
2024-10-30 18:36:39: [2024-10-30 18:36:39] iter = 09410, loss = 2.0580
2024-10-30 18:36:43: [2024-10-30 18:36:43] iter = 09420, loss = 2.7653
2024-10-30 18:36:48: [2024-10-30 18:36:48] iter = 09430, loss = 1.9595
2024-10-30 18:36:51: [2024-10-30 18:36:51] iter = 09440, loss = 2.4416
2024-10-30 18:36:55: [2024-10-30 18:36:55] iter = 09450, loss = 2.0813
2024-10-30 18:36:59: [2024-10-30 18:36:59] iter = 09460, loss = 2.1676
2024-10-30 18:37:03: [2024-10-30 18:37:03] iter = 09470, loss = 2.1428
2024-10-30 18:37:07: [2024-10-30 18:37:07] iter = 09480, loss = 2.8755
2024-10-30 18:37:11: [2024-10-30 18:37:11] iter = 09490, loss = 2.2407
2024-10-30 18:37:14: [2024-10-30 18:37:14] iter = 09500, loss = 1.8504
2024-10-30 18:37:17: [2024-10-30 18:37:17] iter = 09510, loss = 2.2196
2024-10-30 18:37:21: [2024-10-30 18:37:21] iter = 09520, loss = 3.3336
2024-10-30 18:37:25: [2024-10-30 18:37:25] iter = 09530, loss = 2.7891
2024-10-30 18:37:28: [2024-10-30 18:37:28] iter = 09540, loss = 2.8227
2024-10-30 18:37:30: [2024-10-30 18:37:30] iter = 09550, loss = 2.3740
2024-10-30 18:37:33: [2024-10-30 18:37:33] iter = 09560, loss = 2.0186
2024-10-30 18:37:37: [2024-10-30 18:37:37] iter = 09570, loss = 2.0319
2024-10-30 18:37:40: [2024-10-30 18:37:40] iter = 09580, loss = 2.6127
2024-10-30 18:37:44: [2024-10-30 18:37:43] iter = 09590, loss = 2.1900
2024-10-30 18:37:46: [2024-10-30 18:37:46] iter = 09600, loss = 2.5983
2024-10-30 18:37:48: [2024-10-30 18:37:48] iter = 09610, loss = 2.2346
2024-10-30 18:37:52: [2024-10-30 18:37:52] iter = 09620, loss = 1.9951
2024-10-30 18:37:56: [2024-10-30 18:37:56] iter = 09630, loss = 2.1122
2024-10-30 18:38:00: [2024-10-30 18:38:00] iter = 09640, loss = 2.6213
2024-10-30 18:38:03: [2024-10-30 18:38:03] iter = 09650, loss = 2.1140
2024-10-30 18:38:06: [2024-10-30 18:38:06] iter = 09660, loss = 3.5904
2024-10-30 18:38:09: [2024-10-30 18:38:09] iter = 09670, loss = 2.0991
2024-10-30 18:38:13: [2024-10-30 18:38:13] iter = 09680, loss = 2.6235
2024-10-30 18:38:17: [2024-10-30 18:38:17] iter = 09690, loss = 2.2575
2024-10-30 18:38:20: [2024-10-30 18:38:20] iter = 09700, loss = 2.0210
2024-10-30 18:38:24: [2024-10-30 18:38:24] iter = 09710, loss = 5.1605
2024-10-30 18:38:26: [2024-10-30 18:38:26] iter = 09720, loss = 2.0293
2024-10-30 18:38:30: [2024-10-30 18:38:30] iter = 09730, loss = 2.7875
2024-10-30 18:38:34: [2024-10-30 18:38:34] iter = 09740, loss = 1.9056
2024-10-30 18:38:36: [2024-10-30 18:38:36] iter = 09750, loss = 2.3767
2024-10-30 18:38:38: [2024-10-30 18:38:38] iter = 09760, loss = 2.2820
2024-10-30 18:38:41: [2024-10-30 18:38:41] iter = 09770, loss = 5.0896
2024-10-30 18:38:44: [2024-10-30 18:38:44] iter = 09780, loss = 3.0315
2024-10-30 18:38:47: [2024-10-30 18:38:47] iter = 09790, loss = 2.3457
2024-10-30 18:38:50: [2024-10-30 18:38:50] iter = 09800, loss = 2.3062
2024-10-30 18:38:54: [2024-10-30 18:38:54] iter = 09810, loss = 2.3287
2024-10-30 18:38:58: [2024-10-30 18:38:58] iter = 09820, loss = 2.2130
2024-10-30 18:39:02: [2024-10-30 18:39:02] iter = 09830, loss = 2.1334
2024-10-30 18:39:05: [2024-10-30 18:39:05] iter = 09840, loss = 1.9339
2024-10-30 18:39:08: [2024-10-30 18:39:08] iter = 09850, loss = 1.9483
2024-10-30 18:39:11: [2024-10-30 18:39:11] iter = 09860, loss = 2.3491
2024-10-30 18:39:14: [2024-10-30 18:39:14] iter = 09870, loss = 1.9171
2024-10-30 18:39:17: [2024-10-30 18:39:17] iter = 09880, loss = 2.6763
2024-10-30 18:39:20: [2024-10-30 18:39:20] iter = 09890, loss = 1.9079
2024-10-30 18:39:23: [2024-10-30 18:39:23] iter = 09900, loss = 2.9249
2024-10-30 18:39:26: [2024-10-30 18:39:26] iter = 09910, loss = 2.2148
2024-10-30 18:39:30: [2024-10-30 18:39:30] iter = 09920, loss = 2.3900
2024-10-30 18:39:34: [2024-10-30 18:39:34] iter = 09930, loss = 2.8338
2024-10-30 18:39:38: [2024-10-30 18:39:38] iter = 09940, loss = 3.6375
2024-10-30 18:39:41: [2024-10-30 18:39:41] iter = 09950, loss = 1.7278
2024-10-30 18:39:44: [2024-10-30 18:39:44] iter = 09960, loss = 1.9221
2024-10-30 18:39:48: [2024-10-30 18:39:48] iter = 09970, loss = 1.7715
2024-10-30 18:39:50: [2024-10-30 18:39:50] iter = 09980, loss = 2.1030
2024-10-30 18:39:53: [2024-10-30 18:39:53] iter = 09990, loss = 2.4669
2024-10-30 18:39:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 18:39:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:39:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 95843}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:42:06: Evaluate 5 random ConvNet, ACCmean = 0.6225 ACCstd = 0.0049
-------------------------
2024-10-30 18:42:06: Evaluate 5 random ConvNet, SENmean = 0.5980 SENstd = 0.0047
-------------------------
2024-10-30 18:42:06: Evaluate 5 random ConvNet, SPEmean = 0.9614 SPEstd = 0.0004
-------------------------
2024-10-30 18:42:06: Evaluate 5 random ConvNet, F!mean = 0.5908 F!std = 0.0051
-------------------------
2024-10-30 18:42:06: Evaluate 5 random ConvNet, mean = 0.6225 std = 0.0049
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:42:06: [2024-10-30 18:42:06] iter = 10000, loss = 3.5222
2024-10-30 18:42:10: [2024-10-30 18:42:10] iter = 10010, loss = 2.9873
2024-10-30 18:42:14: [2024-10-30 18:42:14] iter = 10020, loss = 1.8543
2024-10-30 18:42:17: [2024-10-30 18:42:17] iter = 10030, loss = 2.4990
2024-10-30 18:42:20: [2024-10-30 18:42:20] iter = 10040, loss = 2.0976
2024-10-30 18:42:22: [2024-10-30 18:42:22] iter = 10050, loss = 1.9035
2024-10-30 18:42:26: [2024-10-30 18:42:26] iter = 10060, loss = 2.2113
2024-10-30 18:42:29: [2024-10-30 18:42:29] iter = 10070, loss = 2.2464
2024-10-30 18:42:32: [2024-10-30 18:42:32] iter = 10080, loss = 2.0457
2024-10-30 18:42:35: [2024-10-30 18:42:35] iter = 10090, loss = 2.5732
2024-10-30 18:42:37: [2024-10-30 18:42:37] iter = 10100, loss = 2.4146
2024-10-30 18:42:40: [2024-10-30 18:42:40] iter = 10110, loss = 1.7762
2024-10-30 18:42:44: [2024-10-30 18:42:44] iter = 10120, loss = 2.0837
2024-10-30 18:42:47: [2024-10-30 18:42:47] iter = 10130, loss = 2.0526
2024-10-30 18:42:50: [2024-10-30 18:42:50] iter = 10140, loss = 2.1188
2024-10-30 18:42:52: [2024-10-30 18:42:52] iter = 10150, loss = 2.3157
2024-10-30 18:42:56: [2024-10-30 18:42:56] iter = 10160, loss = 2.5476
2024-10-30 18:43:00: [2024-10-30 18:43:00] iter = 10170, loss = 2.2549
2024-10-30 18:43:03: [2024-10-30 18:43:03] iter = 10180, loss = 2.4503
2024-10-30 18:43:07: [2024-10-30 18:43:07] iter = 10190, loss = 2.3633
2024-10-30 18:43:10: [2024-10-30 18:43:10] iter = 10200, loss = 7.7100
2024-10-30 18:43:13: [2024-10-30 18:43:13] iter = 10210, loss = 2.2929
2024-10-30 18:43:16: [2024-10-30 18:43:16] iter = 10220, loss = 2.4460
2024-10-30 18:43:20: [2024-10-30 18:43:20] iter = 10230, loss = 2.6141
2024-10-30 18:43:23: [2024-10-30 18:43:23] iter = 10240, loss = 2.2623
2024-10-30 18:43:26: [2024-10-30 18:43:26] iter = 10250, loss = 2.1973
2024-10-30 18:43:30: [2024-10-30 18:43:30] iter = 10260, loss = 1.8025
2024-10-30 18:43:32: [2024-10-30 18:43:32] iter = 10270, loss = 2.0022
2024-10-30 18:43:35: [2024-10-30 18:43:35] iter = 10280, loss = 2.0415
2024-10-30 18:43:38: [2024-10-30 18:43:38] iter = 10290, loss = 2.5954
2024-10-30 18:43:40: [2024-10-30 18:43:40] iter = 10300, loss = 2.2745
2024-10-30 18:43:44: [2024-10-30 18:43:44] iter = 10310, loss = 2.5623
2024-10-30 18:43:48: [2024-10-30 18:43:48] iter = 10320, loss = 2.4452
2024-10-30 18:43:51: [2024-10-30 18:43:51] iter = 10330, loss = 1.8422
2024-10-30 18:43:55: [2024-10-30 18:43:55] iter = 10340, loss = 1.5851
2024-10-30 18:43:58: [2024-10-30 18:43:58] iter = 10350, loss = 2.2886
2024-10-30 18:44:01: [2024-10-30 18:44:01] iter = 10360, loss = 3.5041
2024-10-30 18:44:04: [2024-10-30 18:44:04] iter = 10370, loss = 2.5849
2024-10-30 18:44:07: [2024-10-30 18:44:07] iter = 10380, loss = 1.9770
2024-10-30 18:44:11: [2024-10-30 18:44:11] iter = 10390, loss = 2.5586
2024-10-30 18:44:14: [2024-10-30 18:44:14] iter = 10400, loss = 2.0317
2024-10-30 18:44:17: [2024-10-30 18:44:17] iter = 10410, loss = 2.4426
2024-10-30 18:44:20: [2024-10-30 18:44:20] iter = 10420, loss = 2.2058
2024-10-30 18:44:23: [2024-10-30 18:44:23] iter = 10430, loss = 2.1706
2024-10-30 18:44:26: [2024-10-30 18:44:26] iter = 10440, loss = 3.0774
2024-10-30 18:44:30: [2024-10-30 18:44:30] iter = 10450, loss = 2.4733
2024-10-30 18:44:33: [2024-10-30 18:44:33] iter = 10460, loss = 2.6052
2024-10-30 18:44:37: [2024-10-30 18:44:37] iter = 10470, loss = 2.0037
2024-10-30 18:44:41: [2024-10-30 18:44:41] iter = 10480, loss = 2.1140
2024-10-30 18:44:44: [2024-10-30 18:44:44] iter = 10490, loss = 2.0118
2024-10-30 18:44:47: [2024-10-30 18:44:47] iter = 10500, loss = 2.6341
2024-10-30 18:44:49: [2024-10-30 18:44:49] iter = 10510, loss = 1.9123
2024-10-30 18:44:53: [2024-10-30 18:44:53] iter = 10520, loss = 1.8753
2024-10-30 18:44:56: [2024-10-30 18:44:56] iter = 10530, loss = 2.1709
2024-10-30 18:44:59: [2024-10-30 18:44:59] iter = 10540, loss = 2.4598
2024-10-30 18:45:02: [2024-10-30 18:45:02] iter = 10550, loss = 2.5955
2024-10-30 18:45:06: [2024-10-30 18:45:06] iter = 10560, loss = 2.1957
2024-10-30 18:45:10: [2024-10-30 18:45:10] iter = 10570, loss = 2.9790
2024-10-30 18:45:13: [2024-10-30 18:45:13] iter = 10580, loss = 3.6427
2024-10-30 18:45:16: [2024-10-30 18:45:16] iter = 10590, loss = 2.2435
2024-10-30 18:45:18: [2024-10-30 18:45:18] iter = 10600, loss = 2.1221
2024-10-30 18:45:21: [2024-10-30 18:45:21] iter = 10610, loss = 2.5133
2024-10-30 18:45:23: [2024-10-30 18:45:23] iter = 10620, loss = 1.7576
2024-10-30 18:45:27: [2024-10-30 18:45:27] iter = 10630, loss = 1.9928
2024-10-30 18:45:31: [2024-10-30 18:45:31] iter = 10640, loss = 3.1610
2024-10-30 18:45:34: [2024-10-30 18:45:34] iter = 10650, loss = 1.8197
2024-10-30 18:45:38: [2024-10-30 18:45:37] iter = 10660, loss = 2.4693
2024-10-30 18:45:41: [2024-10-30 18:45:41] iter = 10670, loss = 2.3754
2024-10-30 18:45:43: [2024-10-30 18:45:43] iter = 10680, loss = 2.1545
2024-10-30 18:45:47: [2024-10-30 18:45:47] iter = 10690, loss = 2.3688
2024-10-30 18:45:50: [2024-10-30 18:45:50] iter = 10700, loss = 2.8121
2024-10-30 18:45:54: [2024-10-30 18:45:54] iter = 10710, loss = 2.0529
2024-10-30 18:45:57: [2024-10-30 18:45:57] iter = 10720, loss = 2.0032
2024-10-30 18:46:00: [2024-10-30 18:46:00] iter = 10730, loss = 2.1338
2024-10-30 18:46:03: [2024-10-30 18:46:03] iter = 10740, loss = 2.1890
2024-10-30 18:46:07: [2024-10-30 18:46:07] iter = 10750, loss = 2.0328
2024-10-30 18:46:11: [2024-10-30 18:46:11] iter = 10760, loss = 2.4269
2024-10-30 18:46:14: [2024-10-30 18:46:14] iter = 10770, loss = 2.6314
2024-10-30 18:46:17: [2024-10-30 18:46:17] iter = 10780, loss = 2.7060
2024-10-30 18:46:21: [2024-10-30 18:46:21] iter = 10790, loss = 2.2626
2024-10-30 18:46:26: [2024-10-30 18:46:26] iter = 10800, loss = 2.7043
2024-10-30 18:46:31: [2024-10-30 18:46:31] iter = 10810, loss = 2.1140
2024-10-30 18:46:34: [2024-10-30 18:46:34] iter = 10820, loss = 5.3323
2024-10-30 18:46:38: [2024-10-30 18:46:38] iter = 10830, loss = 2.5977
2024-10-30 18:46:40: [2024-10-30 18:46:40] iter = 10840, loss = 2.6806
2024-10-30 18:46:44: [2024-10-30 18:46:44] iter = 10850, loss = 2.2475
2024-10-30 18:46:48: [2024-10-30 18:46:48] iter = 10860, loss = 2.0860
2024-10-30 18:46:52: [2024-10-30 18:46:52] iter = 10870, loss = 2.0312
2024-10-30 18:46:55: [2024-10-30 18:46:55] iter = 10880, loss = 2.9795
2024-10-30 18:46:59: [2024-10-30 18:46:59] iter = 10890, loss = 2.1990
2024-10-30 18:47:01: [2024-10-30 18:47:01] iter = 10900, loss = 2.3470
2024-10-30 18:47:04: [2024-10-30 18:47:04] iter = 10910, loss = 2.3042
2024-10-30 18:47:07: [2024-10-30 18:47:07] iter = 10920, loss = 2.7368
2024-10-30 18:47:10: [2024-10-30 18:47:10] iter = 10930, loss = 1.8612
2024-10-30 18:47:13: [2024-10-30 18:47:13] iter = 10940, loss = 2.1446
2024-10-30 18:47:16: [2024-10-30 18:47:16] iter = 10950, loss = 2.0325
2024-10-30 18:47:19: [2024-10-30 18:47:19] iter = 10960, loss = 3.5828
2024-10-30 18:47:22: [2024-10-30 18:47:22] iter = 10970, loss = 2.2052
2024-10-30 18:47:26: [2024-10-30 18:47:26] iter = 10980, loss = 1.8763
2024-10-30 18:47:30: [2024-10-30 18:47:30] iter = 10990, loss = 1.8638
2024-10-30 18:47:32: [2024-10-30 18:47:32] iter = 11000, loss = 2.3106
2024-10-30 18:47:36: [2024-10-30 18:47:36] iter = 11010, loss = 5.4793
2024-10-30 18:47:39: [2024-10-30 18:47:39] iter = 11020, loss = 2.3129
2024-10-30 18:47:42: [2024-10-30 18:47:42] iter = 11030, loss = 2.3260
2024-10-30 18:47:44: [2024-10-30 18:47:44] iter = 11040, loss = 1.9934
2024-10-30 18:47:48: [2024-10-30 18:47:48] iter = 11050, loss = 1.8680
2024-10-30 18:47:52: [2024-10-30 18:47:52] iter = 11060, loss = 1.9238
2024-10-30 18:47:55: [2024-10-30 18:47:55] iter = 11070, loss = 3.2356
2024-10-30 18:47:59: [2024-10-30 18:47:59] iter = 11080, loss = 2.0950
2024-10-30 18:48:02: [2024-10-30 18:48:02] iter = 11090, loss = 1.9282
2024-10-30 18:48:05: [2024-10-30 18:48:05] iter = 11100, loss = 2.0811
2024-10-30 18:48:07: [2024-10-30 18:48:07] iter = 11110, loss = 1.8697
2024-10-30 18:48:11: [2024-10-30 18:48:11] iter = 11120, loss = 2.7717
2024-10-30 18:48:15: [2024-10-30 18:48:15] iter = 11130, loss = 2.0247
2024-10-30 18:48:18: [2024-10-30 18:48:18] iter = 11140, loss = 2.0020
2024-10-30 18:48:22: [2024-10-30 18:48:22] iter = 11150, loss = 2.2724
2024-10-30 18:48:26: [2024-10-30 18:48:26] iter = 11160, loss = 2.3604
2024-10-30 18:48:28: [2024-10-30 18:48:28] iter = 11170, loss = 2.9529
2024-10-30 18:48:32: [2024-10-30 18:48:32] iter = 11180, loss = 1.7701
2024-10-30 18:48:35: [2024-10-30 18:48:35] iter = 11190, loss = 4.0736
2024-10-30 18:48:38: [2024-10-30 18:48:38] iter = 11200, loss = 2.5906
2024-10-30 18:48:41: [2024-10-30 18:48:41] iter = 11210, loss = 2.2114
2024-10-30 18:48:45: [2024-10-30 18:48:45] iter = 11220, loss = 2.1059
2024-10-30 18:48:47: [2024-10-30 18:48:47] iter = 11230, loss = 2.7408
2024-10-30 18:48:50: [2024-10-30 18:48:50] iter = 11240, loss = 2.9374
2024-10-30 18:48:53: [2024-10-30 18:48:53] iter = 11250, loss = 2.1555
2024-10-30 18:48:56: [2024-10-30 18:48:56] iter = 11260, loss = 1.9747
2024-10-30 18:48:59: [2024-10-30 18:48:59] iter = 11270, loss = 2.9252
2024-10-30 18:49:02: [2024-10-30 18:49:02] iter = 11280, loss = 2.4902
2024-10-30 18:49:05: [2024-10-30 18:49:05] iter = 11290, loss = 2.1743
2024-10-30 18:49:08: [2024-10-30 18:49:08] iter = 11300, loss = 3.2189
2024-10-30 18:49:11: [2024-10-30 18:49:10] iter = 11310, loss = 1.9543
2024-10-30 18:49:13: [2024-10-30 18:49:13] iter = 11320, loss = 2.0638
2024-10-30 18:49:16: [2024-10-30 18:49:16] iter = 11330, loss = 3.4413
2024-10-30 18:49:20: [2024-10-30 18:49:20] iter = 11340, loss = 1.8487
2024-10-30 18:49:22: [2024-10-30 18:49:22] iter = 11350, loss = 2.6690
2024-10-30 18:49:25: [2024-10-30 18:49:25] iter = 11360, loss = 1.9109
2024-10-30 18:49:28: [2024-10-30 18:49:28] iter = 11370, loss = 2.8038
2024-10-30 18:49:31: [2024-10-30 18:49:31] iter = 11380, loss = 2.1083
2024-10-30 18:49:36: [2024-10-30 18:49:36] iter = 11390, loss = 2.6988
2024-10-30 18:49:39: [2024-10-30 18:49:39] iter = 11400, loss = 1.9823
2024-10-30 18:49:43: [2024-10-30 18:49:43] iter = 11410, loss = 2.1349
2024-10-30 18:49:46: [2024-10-30 18:49:46] iter = 11420, loss = 2.0010
2024-10-30 18:49:50: [2024-10-30 18:49:50] iter = 11430, loss = 2.2416
2024-10-30 18:49:53: [2024-10-30 18:49:53] iter = 11440, loss = 2.1021
2024-10-30 18:49:56: [2024-10-30 18:49:56] iter = 11450, loss = 1.9077
2024-10-30 18:50:00: [2024-10-30 18:50:00] iter = 11460, loss = 1.8814
2024-10-30 18:50:03: [2024-10-30 18:50:03] iter = 11470, loss = 1.9047
2024-10-30 18:50:06: [2024-10-30 18:50:06] iter = 11480, loss = 1.7283
2024-10-30 18:50:09: [2024-10-30 18:50:09] iter = 11490, loss = 1.9676
2024-10-30 18:50:12: [2024-10-30 18:50:12] iter = 11500, loss = 2.6799
2024-10-30 18:50:16: [2024-10-30 18:50:16] iter = 11510, loss = 2.0892
2024-10-30 18:50:20: [2024-10-30 18:50:20] iter = 11520, loss = 4.0459
2024-10-30 18:50:22: [2024-10-30 18:50:22] iter = 11530, loss = 2.0783
2024-10-30 18:50:25: [2024-10-30 18:50:25] iter = 11540, loss = 2.0517
2024-10-30 18:50:28: [2024-10-30 18:50:28] iter = 11550, loss = 2.6129
2024-10-30 18:50:31: [2024-10-30 18:50:31] iter = 11560, loss = 2.6694
2024-10-30 18:50:34: [2024-10-30 18:50:34] iter = 11570, loss = 2.1533
2024-10-30 18:50:37: [2024-10-30 18:50:37] iter = 11580, loss = 2.7911
2024-10-30 18:50:39: [2024-10-30 18:50:39] iter = 11590, loss = 1.9327
2024-10-30 18:50:42: [2024-10-30 18:50:42] iter = 11600, loss = 2.2885
2024-10-30 18:50:45: [2024-10-30 18:50:45] iter = 11610, loss = 2.0334
2024-10-30 18:50:49: [2024-10-30 18:50:49] iter = 11620, loss = 1.7452
2024-10-30 18:50:52: [2024-10-30 18:50:52] iter = 11630, loss = 1.9055
2024-10-30 18:50:55: [2024-10-30 18:50:55] iter = 11640, loss = 2.0949
2024-10-30 18:50:58: [2024-10-30 18:50:58] iter = 11650, loss = 2.1344
2024-10-30 18:51:01: [2024-10-30 18:51:01] iter = 11660, loss = 1.7591
2024-10-30 18:51:04: [2024-10-30 18:51:04] iter = 11670, loss = 2.4337
2024-10-30 18:51:08: [2024-10-30 18:51:08] iter = 11680, loss = 1.8766
2024-10-30 18:51:12: [2024-10-30 18:51:12] iter = 11690, loss = 1.6615
2024-10-30 18:51:15: [2024-10-30 18:51:15] iter = 11700, loss = 2.0008
2024-10-30 18:51:18: [2024-10-30 18:51:18] iter = 11710, loss = 2.7978
2024-10-30 18:51:22: [2024-10-30 18:51:22] iter = 11720, loss = 2.1917
2024-10-30 18:51:26: [2024-10-30 18:51:26] iter = 11730, loss = 2.1212
2024-10-30 18:51:29: [2024-10-30 18:51:28] iter = 11740, loss = 2.8144
2024-10-30 18:51:31: [2024-10-30 18:51:31] iter = 11750, loss = 2.0465
2024-10-30 18:51:34: [2024-10-30 18:51:34] iter = 11760, loss = 2.3579
2024-10-30 18:51:36: [2024-10-30 18:51:36] iter = 11770, loss = 2.8938
2024-10-30 18:51:40: [2024-10-30 18:51:40] iter = 11780, loss = 2.1759
2024-10-30 18:51:42: [2024-10-30 18:51:42] iter = 11790, loss = 3.1990
2024-10-30 18:51:45: [2024-10-30 18:51:45] iter = 11800, loss = 2.6565
2024-10-30 18:51:49: [2024-10-30 18:51:49] iter = 11810, loss = 2.4750
2024-10-30 18:51:53: [2024-10-30 18:51:53] iter = 11820, loss = 2.2539
2024-10-30 18:51:56: [2024-10-30 18:51:56] iter = 11830, loss = 3.0035
2024-10-30 18:51:59: [2024-10-30 18:51:59] iter = 11840, loss = 2.1557
2024-10-30 18:52:03: [2024-10-30 18:52:03] iter = 11850, loss = 1.8821
2024-10-30 18:52:06: [2024-10-30 18:52:06] iter = 11860, loss = 2.4912
2024-10-30 18:52:10: [2024-10-30 18:52:10] iter = 11870, loss = 1.9975
2024-10-30 18:52:13: [2024-10-30 18:52:13] iter = 11880, loss = 2.2438
2024-10-30 18:52:17: [2024-10-30 18:52:17] iter = 11890, loss = 2.0646
2024-10-30 18:52:21: [2024-10-30 18:52:21] iter = 11900, loss = 2.0642
2024-10-30 18:52:24: [2024-10-30 18:52:24] iter = 11910, loss = 2.3545
2024-10-30 18:52:28: [2024-10-30 18:52:28] iter = 11920, loss = 3.4238
2024-10-30 18:52:31: [2024-10-30 18:52:31] iter = 11930, loss = 2.9296
2024-10-30 18:52:34: [2024-10-30 18:52:34] iter = 11940, loss = 2.7152
2024-10-30 18:52:38: [2024-10-30 18:52:38] iter = 11950, loss = 3.4317
2024-10-30 18:52:41: [2024-10-30 18:52:41] iter = 11960, loss = 1.7413
2024-10-30 18:52:45: [2024-10-30 18:52:45] iter = 11970, loss = 2.1521
2024-10-30 18:52:49: [2024-10-30 18:52:49] iter = 11980, loss = 2.4557
2024-10-30 18:52:52: [2024-10-30 18:52:52] iter = 11990, loss = 2.2441
2024-10-30 18:52:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 18:52:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:52:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 75152}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:55:10: Evaluate 5 random ConvNet, ACCmean = 0.6118 ACCstd = 0.0056
-------------------------
2024-10-30 18:55:10: Evaluate 5 random ConvNet, SENmean = 0.5886 SENstd = 0.0045
-------------------------
2024-10-30 18:55:10: Evaluate 5 random ConvNet, SPEmean = 0.9604 SPEstd = 0.0005
-------------------------
2024-10-30 18:55:10: Evaluate 5 random ConvNet, F!mean = 0.5781 F!std = 0.0041
-------------------------
2024-10-30 18:55:10: Evaluate 5 random ConvNet, mean = 0.6118 std = 0.0056
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:55:11: [2024-10-30 18:55:11] iter = 12000, loss = 2.0167
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:55:15: [2024-10-30 18:55:15] iter = 12010, loss = 3.2564
2024-10-30 18:55:18: [2024-10-30 18:55:18] iter = 12020, loss = 2.0739
2024-10-30 18:55:22: [2024-10-30 18:55:22] iter = 12030, loss = 2.2283
2024-10-30 18:55:25: [2024-10-30 18:55:25] iter = 12040, loss = 1.9444
2024-10-30 18:55:29: [2024-10-30 18:55:29] iter = 12050, loss = 2.4648
2024-10-30 18:55:33: [2024-10-30 18:55:33] iter = 12060, loss = 2.1402
2024-10-30 18:55:36: [2024-10-30 18:55:36] iter = 12070, loss = 2.4217
2024-10-30 18:55:40: [2024-10-30 18:55:40] iter = 12080, loss = 2.3087
2024-10-30 18:55:43: [2024-10-30 18:55:43] iter = 12090, loss = 3.2680
2024-10-30 18:55:46: [2024-10-30 18:55:46] iter = 12100, loss = 2.3282
2024-10-30 18:55:49: [2024-10-30 18:55:49] iter = 12110, loss = 4.4696
2024-10-30 18:55:52: [2024-10-30 18:55:52] iter = 12120, loss = 2.1976
2024-10-30 18:55:56: [2024-10-30 18:55:56] iter = 12130, loss = 2.2668
2024-10-30 18:56:00: [2024-10-30 18:56:00] iter = 12140, loss = 2.0189
2024-10-30 18:56:03: [2024-10-30 18:56:03] iter = 12150, loss = 2.3263
2024-10-30 18:56:07: [2024-10-30 18:56:07] iter = 12160, loss = 2.1502
2024-10-30 18:56:09: [2024-10-30 18:56:09] iter = 12170, loss = 3.1459
2024-10-30 18:56:12: [2024-10-30 18:56:12] iter = 12180, loss = 3.1419
2024-10-30 18:56:15: [2024-10-30 18:56:15] iter = 12190, loss = 2.2314
2024-10-30 18:56:19: [2024-10-30 18:56:19] iter = 12200, loss = 2.1958
2024-10-30 18:56:21: [2024-10-30 18:56:21] iter = 12210, loss = 2.7166
2024-10-30 18:56:25: [2024-10-30 18:56:25] iter = 12220, loss = 2.4636
2024-10-30 18:56:28: [2024-10-30 18:56:28] iter = 12230, loss = 3.3942
2024-10-30 18:56:30: [2024-10-30 18:56:30] iter = 12240, loss = 2.0810
2024-10-30 18:56:32: [2024-10-30 18:56:32] iter = 12250, loss = 2.9868
2024-10-30 18:56:35: [2024-10-30 18:56:35] iter = 12260, loss = 2.9314
2024-10-30 18:56:38: [2024-10-30 18:56:38] iter = 12270, loss = 2.3466
2024-10-30 18:56:41: [2024-10-30 18:56:41] iter = 12280, loss = 2.0405
2024-10-30 18:56:44: [2024-10-30 18:56:44] iter = 12290, loss = 2.4554
2024-10-30 18:56:47: [2024-10-30 18:56:47] iter = 12300, loss = 1.8468
2024-10-30 18:56:50: [2024-10-30 18:56:50] iter = 12310, loss = 2.2789
2024-10-30 18:56:54: [2024-10-30 18:56:54] iter = 12320, loss = 2.4114
2024-10-30 18:56:56: [2024-10-30 18:56:56] iter = 12330, loss = 1.8541
2024-10-30 18:56:59: [2024-10-30 18:56:59] iter = 12340, loss = 2.3985
2024-10-30 18:57:03: [2024-10-30 18:57:03] iter = 12350, loss = 2.4691
2024-10-30 18:57:06: [2024-10-30 18:57:06] iter = 12360, loss = 2.1995
2024-10-30 18:57:10: [2024-10-30 18:57:10] iter = 12370, loss = 1.7651
2024-10-30 18:57:14: [2024-10-30 18:57:14] iter = 12380, loss = 1.6743
2024-10-30 18:57:16: [2024-10-30 18:57:16] iter = 12390, loss = 1.9464
2024-10-30 18:57:20: [2024-10-30 18:57:20] iter = 12400, loss = 2.8176
2024-10-30 18:57:23: [2024-10-30 18:57:23] iter = 12410, loss = 2.2820
2024-10-30 18:57:26: [2024-10-30 18:57:26] iter = 12420, loss = 1.9838
2024-10-30 18:57:30: [2024-10-30 18:57:30] iter = 12430, loss = 1.9975
2024-10-30 18:57:32: [2024-10-30 18:57:32] iter = 12440, loss = 2.3646
2024-10-30 18:57:36: [2024-10-30 18:57:36] iter = 12450, loss = 2.0705
2024-10-30 18:57:39: [2024-10-30 18:57:39] iter = 12460, loss = 1.9558
2024-10-30 18:57:43: [2024-10-30 18:57:43] iter = 12470, loss = 2.7415
2024-10-30 18:57:46: [2024-10-30 18:57:46] iter = 12480, loss = 1.9982
2024-10-30 18:57:49: [2024-10-30 18:57:49] iter = 12490, loss = 2.1845
2024-10-30 18:57:52: [2024-10-30 18:57:52] iter = 12500, loss = 2.1206
2024-10-30 18:57:54: [2024-10-30 18:57:54] iter = 12510, loss = 3.3411
2024-10-30 18:57:57: [2024-10-30 18:57:57] iter = 12520, loss = 2.7115
2024-10-30 18:58:00: [2024-10-30 18:58:00] iter = 12530, loss = 1.8278
2024-10-30 18:58:04: [2024-10-30 18:58:04] iter = 12540, loss = 2.2652
2024-10-30 18:58:07: [2024-10-30 18:58:07] iter = 12550, loss = 2.1295
2024-10-30 18:58:10: [2024-10-30 18:58:10] iter = 12560, loss = 2.0201
2024-10-30 18:58:15: [2024-10-30 18:58:15] iter = 12570, loss = 2.3108
2024-10-30 18:58:18: [2024-10-30 18:58:18] iter = 12580, loss = 2.4996
2024-10-30 18:58:21: [2024-10-30 18:58:21] iter = 12590, loss = 2.9518
2024-10-30 18:58:24: [2024-10-30 18:58:24] iter = 12600, loss = 2.2306
2024-10-30 18:58:26: [2024-10-30 18:58:26] iter = 12610, loss = 2.7067
2024-10-30 18:58:30: [2024-10-30 18:58:30] iter = 12620, loss = 1.8394
2024-10-30 18:58:33: [2024-10-30 18:58:33] iter = 12630, loss = 2.1710
2024-10-30 18:58:36: [2024-10-30 18:58:36] iter = 12640, loss = 1.8474
2024-10-30 18:58:39: [2024-10-30 18:58:39] iter = 12650, loss = 2.0574
2024-10-30 18:58:43: [2024-10-30 18:58:43] iter = 12660, loss = 1.5766
2024-10-30 18:58:45: [2024-10-30 18:58:45] iter = 12670, loss = 2.4246
2024-10-30 18:58:49: [2024-10-30 18:58:49] iter = 12680, loss = 2.6166
2024-10-30 18:58:52: [2024-10-30 18:58:52] iter = 12690, loss = 2.8653
2024-10-30 18:58:55: [2024-10-30 18:58:55] iter = 12700, loss = 2.9062
2024-10-30 18:58:58: [2024-10-30 18:58:58] iter = 12710, loss = 2.6177
2024-10-30 18:59:01: [2024-10-30 18:59:01] iter = 12720, loss = 1.9524
2024-10-30 18:59:03: [2024-10-30 18:59:03] iter = 12730, loss = 1.9598
2024-10-30 18:59:06: [2024-10-30 18:59:06] iter = 12740, loss = 2.8707
2024-10-30 18:59:09: [2024-10-30 18:59:09] iter = 12750, loss = 1.9662
2024-10-30 18:59:12: [2024-10-30 18:59:12] iter = 12760, loss = 2.6004
2024-10-30 18:59:15: [2024-10-30 18:59:15] iter = 12770, loss = 2.1722
2024-10-30 18:59:18: [2024-10-30 18:59:18] iter = 12780, loss = 2.2372
2024-10-30 18:59:21: [2024-10-30 18:59:21] iter = 12790, loss = 3.5026
2024-10-30 18:59:24: [2024-10-30 18:59:24] iter = 12800, loss = 2.0287
2024-10-30 18:59:26: [2024-10-30 18:59:26] iter = 12810, loss = 2.2263
2024-10-30 18:59:30: [2024-10-30 18:59:30] iter = 12820, loss = 2.8316
2024-10-30 18:59:33: [2024-10-30 18:59:33] iter = 12830, loss = 1.9956
2024-10-30 18:59:37: [2024-10-30 18:59:37] iter = 12840, loss = 1.9779
2024-10-30 18:59:40: [2024-10-30 18:59:40] iter = 12850, loss = 2.0411
2024-10-30 18:59:43: [2024-10-30 18:59:43] iter = 12860, loss = 2.1302
2024-10-30 18:59:46: [2024-10-30 18:59:46] iter = 12870, loss = 1.9352
2024-10-30 18:59:50: [2024-10-30 18:59:50] iter = 12880, loss = 1.8278
2024-10-30 18:59:53: [2024-10-30 18:59:53] iter = 12890, loss = 2.2590
2024-10-30 18:59:57: [2024-10-30 18:59:57] iter = 12900, loss = 2.3013
2024-10-30 19:00:01: [2024-10-30 19:00:01] iter = 12910, loss = 2.4571
2024-10-30 19:00:04: [2024-10-30 19:00:04] iter = 12920, loss = 1.9703
2024-10-30 19:00:07: [2024-10-30 19:00:07] iter = 12930, loss = 2.4393
2024-10-30 19:00:11: [2024-10-30 19:00:11] iter = 12940, loss = 2.1556
2024-10-30 19:00:14: [2024-10-30 19:00:14] iter = 12950, loss = 2.0836
2024-10-30 19:00:18: [2024-10-30 19:00:18] iter = 12960, loss = 1.8500
2024-10-30 19:00:21: [2024-10-30 19:00:21] iter = 12970, loss = 1.9661
2024-10-30 19:00:24: [2024-10-30 19:00:24] iter = 12980, loss = 1.8681
2024-10-30 19:00:27: [2024-10-30 19:00:27] iter = 12990, loss = 2.0811
2024-10-30 19:00:30: [2024-10-30 19:00:30] iter = 13000, loss = 2.9357
2024-10-30 19:00:34: [2024-10-30 19:00:34] iter = 13010, loss = 2.3805
2024-10-30 19:00:38: [2024-10-30 19:00:38] iter = 13020, loss = 2.7790
2024-10-30 19:00:41: [2024-10-30 19:00:41] iter = 13030, loss = 4.8402
2024-10-30 19:00:44: [2024-10-30 19:00:44] iter = 13040, loss = 2.2774
2024-10-30 19:00:48: [2024-10-30 19:00:48] iter = 13050, loss = 2.5637
2024-10-30 19:00:51: [2024-10-30 19:00:51] iter = 13060, loss = 2.1558
2024-10-30 19:00:55: [2024-10-30 19:00:55] iter = 13070, loss = 3.0082
2024-10-30 19:00:58: [2024-10-30 19:00:58] iter = 13080, loss = 2.6374
2024-10-30 19:01:01: [2024-10-30 19:01:01] iter = 13090, loss = 3.9431
2024-10-30 19:01:05: [2024-10-30 19:01:04] iter = 13100, loss = 2.1376
2024-10-30 19:01:08: [2024-10-30 19:01:08] iter = 13110, loss = 2.1085
2024-10-30 19:01:13: [2024-10-30 19:01:13] iter = 13120, loss = 2.7471
2024-10-30 19:01:17: [2024-10-30 19:01:17] iter = 13130, loss = 2.0810
2024-10-30 19:01:21: [2024-10-30 19:01:21] iter = 13140, loss = 2.2287
2024-10-30 19:01:24: [2024-10-30 19:01:24] iter = 13150, loss = 1.9643
2024-10-30 19:01:27: [2024-10-30 19:01:27] iter = 13160, loss = 3.0367
2024-10-30 19:01:31: [2024-10-30 19:01:31] iter = 13170, loss = 2.6655
2024-10-30 19:01:34: [2024-10-30 19:01:34] iter = 13180, loss = 2.0886
2024-10-30 19:01:38: [2024-10-30 19:01:38] iter = 13190, loss = 1.9852
2024-10-30 19:01:41: [2024-10-30 19:01:41] iter = 13200, loss = 2.1209
2024-10-30 19:01:45: [2024-10-30 19:01:45] iter = 13210, loss = 2.4000
2024-10-30 19:01:49: [2024-10-30 19:01:49] iter = 13220, loss = 2.0466
2024-10-30 19:01:53: [2024-10-30 19:01:53] iter = 13230, loss = 2.0086
2024-10-30 19:01:56: [2024-10-30 19:01:56] iter = 13240, loss = 2.2840
2024-10-30 19:02:00: [2024-10-30 19:02:00] iter = 13250, loss = 2.0184
2024-10-30 19:02:03: [2024-10-30 19:02:03] iter = 13260, loss = 2.7555
2024-10-30 19:02:06: [2024-10-30 19:02:06] iter = 13270, loss = 1.7780
2024-10-30 19:02:10: [2024-10-30 19:02:10] iter = 13280, loss = 2.4605
2024-10-30 19:02:13: [2024-10-30 19:02:13] iter = 13290, loss = 3.8594
2024-10-30 19:02:17: [2024-10-30 19:02:17] iter = 13300, loss = 2.2504
2024-10-30 19:02:20: [2024-10-30 19:02:20] iter = 13310, loss = 2.6054
2024-10-30 19:02:24: [2024-10-30 19:02:24] iter = 13320, loss = 2.9401
2024-10-30 19:02:28: [2024-10-30 19:02:28] iter = 13330, loss = 2.5363
2024-10-30 19:02:32: [2024-10-30 19:02:32] iter = 13340, loss = 4.4204
2024-10-30 19:02:35: [2024-10-30 19:02:35] iter = 13350, loss = 2.0609
2024-10-30 19:02:39: [2024-10-30 19:02:39] iter = 13360, loss = 3.1645
2024-10-30 19:02:42: [2024-10-30 19:02:42] iter = 13370, loss = 2.0099
2024-10-30 19:02:46: [2024-10-30 19:02:46] iter = 13380, loss = 1.9511
2024-10-30 19:02:49: [2024-10-30 19:02:49] iter = 13390, loss = 2.4298
2024-10-30 19:02:52: [2024-10-30 19:02:52] iter = 13400, loss = 2.4208
2024-10-30 19:02:55: [2024-10-30 19:02:55] iter = 13410, loss = 2.1616
2024-10-30 19:02:59: [2024-10-30 19:02:59] iter = 13420, loss = 2.4967
2024-10-30 19:03:02: [2024-10-30 19:03:02] iter = 13430, loss = 1.8873
2024-10-30 19:03:05: [2024-10-30 19:03:05] iter = 13440, loss = 3.8545
2024-10-30 19:03:09: [2024-10-30 19:03:09] iter = 13450, loss = 2.1879
2024-10-30 19:03:13: [2024-10-30 19:03:13] iter = 13460, loss = 5.3915
2024-10-30 19:03:16: [2024-10-30 19:03:16] iter = 13470, loss = 2.4788
2024-10-30 19:03:19: [2024-10-30 19:03:19] iter = 13480, loss = 2.4635
2024-10-30 19:03:21: [2024-10-30 19:03:21] iter = 13490, loss = 2.2384
2024-10-30 19:03:24: [2024-10-30 19:03:24] iter = 13500, loss = 2.6586
2024-10-30 19:03:27: [2024-10-30 19:03:27] iter = 13510, loss = 2.1119
2024-10-30 19:03:31: [2024-10-30 19:03:31] iter = 13520, loss = 1.8596
2024-10-30 19:03:34: [2024-10-30 19:03:34] iter = 13530, loss = 2.3799
2024-10-30 19:03:38: [2024-10-30 19:03:38] iter = 13540, loss = 2.8332
2024-10-30 19:03:41: [2024-10-30 19:03:41] iter = 13550, loss = 2.0892
2024-10-30 19:03:44: [2024-10-30 19:03:44] iter = 13560, loss = 2.6595
2024-10-30 19:03:48: [2024-10-30 19:03:48] iter = 13570, loss = 1.8904
2024-10-30 19:03:51: [2024-10-30 19:03:51] iter = 13580, loss = 1.9605
2024-10-30 19:03:54: [2024-10-30 19:03:54] iter = 13590, loss = 2.2018
2024-10-30 19:03:57: [2024-10-30 19:03:57] iter = 13600, loss = 2.3719
2024-10-30 19:04:01: [2024-10-30 19:04:01] iter = 13610, loss = 2.6299
2024-10-30 19:04:05: [2024-10-30 19:04:05] iter = 13620, loss = 2.3014
2024-10-30 19:04:09: [2024-10-30 19:04:09] iter = 13630, loss = 1.9921
2024-10-30 19:04:13: [2024-10-30 19:04:13] iter = 13640, loss = 1.8322
2024-10-30 19:04:16: [2024-10-30 19:04:16] iter = 13650, loss = 2.3366
2024-10-30 19:04:20: [2024-10-30 19:04:20] iter = 13660, loss = 2.4320
2024-10-30 19:04:24: [2024-10-30 19:04:24] iter = 13670, loss = 2.1085
2024-10-30 19:04:27: [2024-10-30 19:04:27] iter = 13680, loss = 2.0217
2024-10-30 19:04:30: [2024-10-30 19:04:30] iter = 13690, loss = 1.6788
2024-10-30 19:04:34: [2024-10-30 19:04:34] iter = 13700, loss = 2.2618
2024-10-30 19:04:37: [2024-10-30 19:04:37] iter = 13710, loss = 1.9518
2024-10-30 19:04:41: [2024-10-30 19:04:41] iter = 13720, loss = 1.9683
2024-10-30 19:04:45: [2024-10-30 19:04:45] iter = 13730, loss = 2.1043
2024-10-30 19:04:48: [2024-10-30 19:04:48] iter = 13740, loss = 2.5065
2024-10-30 19:04:51: [2024-10-30 19:04:51] iter = 13750, loss = 2.1588
2024-10-30 19:04:54: [2024-10-30 19:04:54] iter = 13760, loss = 4.4137
2024-10-30 19:04:57: [2024-10-30 19:04:57] iter = 13770, loss = 3.5029
2024-10-30 19:05:00: [2024-10-30 19:05:00] iter = 13780, loss = 2.0688
2024-10-30 19:05:04: [2024-10-30 19:05:04] iter = 13790, loss = 2.1772
2024-10-30 19:05:07: [2024-10-30 19:05:07] iter = 13800, loss = 2.6025
2024-10-30 19:05:12: [2024-10-30 19:05:12] iter = 13810, loss = 1.9631
2024-10-30 19:05:15: [2024-10-30 19:05:15] iter = 13820, loss = 2.2587
2024-10-30 19:05:18: [2024-10-30 19:05:18] iter = 13830, loss = 2.2790
2024-10-30 19:05:21: [2024-10-30 19:05:21] iter = 13840, loss = 2.4609
2024-10-30 19:05:25: [2024-10-30 19:05:25] iter = 13850, loss = 2.1169
2024-10-30 19:05:28: [2024-10-30 19:05:28] iter = 13860, loss = 2.1776
2024-10-30 19:05:33: [2024-10-30 19:05:33] iter = 13870, loss = 1.7499
2024-10-30 19:05:35: [2024-10-30 19:05:35] iter = 13880, loss = 2.7057
2024-10-30 19:05:38: [2024-10-30 19:05:38] iter = 13890, loss = 2.4101
2024-10-30 19:05:41: [2024-10-30 19:05:41] iter = 13900, loss = 2.8280
2024-10-30 19:05:44: [2024-10-30 19:05:44] iter = 13910, loss = 2.0215
2024-10-30 19:05:47: [2024-10-30 19:05:47] iter = 13920, loss = 2.0031
2024-10-30 19:05:49: [2024-10-30 19:05:49] iter = 13930, loss = 3.0732
2024-10-30 19:05:52: [2024-10-30 19:05:52] iter = 13940, loss = 2.5749
2024-10-30 19:05:55: [2024-10-30 19:05:55] iter = 13950, loss = 1.8864
2024-10-30 19:05:59: [2024-10-30 19:05:59] iter = 13960, loss = 2.2359
2024-10-30 19:06:03: [2024-10-30 19:06:03] iter = 13970, loss = 1.8003
2024-10-30 19:06:08: [2024-10-30 19:06:08] iter = 13980, loss = 2.1146
2024-10-30 19:06:11: [2024-10-30 19:06:11] iter = 13990, loss = 4.9874
2024-10-30 19:06:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 19:06:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:06:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 73695}

[2024-10-30 17:16:23] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.029615 train acc = 1.0000, test acc = 0.5998, test_sen =0.5865, test_spe =0.9593, test_f1 =0.5695
[2024-10-30 17:16:51] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.032797 train acc = 1.0000, test acc = 0.6110, test_sen =0.5967, test_spe =0.9603, test_f1 =0.5855
[2024-10-30 17:17:20] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.034581 train acc = 1.0000, test acc = 0.6001, test_sen =0.5894, test_spe =0.9594, test_f1 =0.5766
[2024-10-30 17:17:46] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.078447 train acc = 0.9909, test acc = 0.5977, test_sen =0.5839, test_spe =0.9591, test_f1 =0.5697
[2024-10-30 17:18:15] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.013152 train acc = 1.0000, test acc = 0.5970, test_sen =0.5876, test_spe =0.9589, test_f1 =0.5731
[2024-10-30 17:31:37] Evaluate_00: epoch = 1000 train time = 28 s train loss = 0.012502 train acc = 1.0000, test acc = 0.5979, test_sen =0.5806, test_spe =0.9591, test_f1 =0.5708
[2024-10-30 17:32:03] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.064535 train acc = 1.0000, test acc = 0.5978, test_sen =0.5797, test_spe =0.9591, test_f1 =0.5671
[2024-10-30 17:32:31] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.011019 train acc = 1.0000, test acc = 0.5931, test_sen =0.5775, test_spe =0.9587, test_f1 =0.5640
[2024-10-30 17:32:58] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.040463 train acc = 1.0000, test acc = 0.5977, test_sen =0.5819, test_spe =0.9588, test_f1 =0.5716
[2024-10-30 17:33:26] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.009314 train acc = 1.0000, test acc = 0.5956, test_sen =0.5741, test_spe =0.9588, test_f1 =0.5630
[2024-10-30 17:33:54] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.002953 train acc = 1.0000, test acc = 0.4705, test_sen =0.4667, test_spe =0.9463, test_f1 =0.4523
[2024-10-30 17:34:23] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.004993 train acc = 1.0000, test acc = 0.4780, test_sen =0.4705, test_spe =0.9469, test_f1 =0.4555
[2024-10-30 17:34:51] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.045472 train acc = 1.0000, test acc = 0.4892, test_sen =0.4822, test_spe =0.9480, test_f1 =0.4687
[2024-10-30 17:35:20] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.005262 train acc = 1.0000, test acc = 0.4869, test_sen =0.4692, test_spe =0.9475, test_f1 =0.4579
[2024-10-30 17:35:44] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.003056 train acc = 1.0000, test acc = 0.4803, test_sen =0.4766, test_spe =0.9472, test_f1 =0.4608
[2024-10-30 17:47:40] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.008446 train acc = 1.0000, test acc = 0.6188, test_sen =0.5963, test_spe =0.9613, test_f1 =0.5860
[2024-10-30 17:48:05] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.011171 train acc = 1.0000, test acc = 0.6173, test_sen =0.6017, test_spe =0.9611, test_f1 =0.5876
[2024-10-30 17:48:29] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.083977 train acc = 0.9818, test acc = 0.6154, test_sen =0.5935, test_spe =0.9607, test_f1 =0.5862
[2024-10-30 17:48:54] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.006353 train acc = 1.0000, test acc = 0.6237, test_sen =0.5985, test_spe =0.9617, test_f1 =0.5921
[2024-10-30 17:49:25] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.007300 train acc = 1.0000, test acc = 0.6251, test_sen =0.6014, test_spe =0.9619, test_f1 =0.5927
[2024-10-30 18:00:54] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.005140 train acc = 1.0000, test acc = 0.6157, test_sen =0.5918, test_spe =0.9608, test_f1 =0.5823
[2024-10-30 18:01:19] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.029340 train acc = 1.0000, test acc = 0.6204, test_sen =0.5918, test_spe =0.9613, test_f1 =0.5865
[2024-10-30 18:01:43] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.011100 train acc = 1.0000, test acc = 0.6232, test_sen =0.5981, test_spe =0.9616, test_f1 =0.5923
[2024-10-30 18:02:08] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.006842 train acc = 1.0000, test acc = 0.6233, test_sen =0.6019, test_spe =0.9618, test_f1 =0.5908
[2024-10-30 18:02:37] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.008313 train acc = 1.0000, test acc = 0.6303, test_sen =0.6060, test_spe =0.9623, test_f1 =0.5980
[2024-10-30 18:13:43] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.028656 train acc = 1.0000, test acc = 0.5968, test_sen =0.5709, test_spe =0.9589, test_f1 =0.5585
[2024-10-30 18:14:08] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.035320 train acc = 0.9909, test acc = 0.6129, test_sen =0.5860, test_spe =0.9605, test_f1 =0.5769
[2024-10-30 18:14:35] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.040093 train acc = 1.0000, test acc = 0.6104, test_sen =0.5913, test_spe =0.9604, test_f1 =0.5807
[2024-10-30 18:15:04] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.009665 train acc = 1.0000, test acc = 0.5981, test_sen =0.5842, test_spe =0.9591, test_f1 =0.5724
[2024-10-30 18:15:29] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.009846 train acc = 1.0000, test acc = 0.6138, test_sen =0.5853, test_spe =0.9607, test_f1 =0.5766
[2024-10-30 18:26:56] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.036499 train acc = 1.0000, test acc = 0.6046, test_sen =0.5857, test_spe =0.9598, test_f1 =0.5723
[2024-10-30 18:27:19] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.062270 train acc = 1.0000, test acc = 0.6136, test_sen =0.5996, test_spe =0.9608, test_f1 =0.5850
[2024-10-30 18:27:46] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.038639 train acc = 1.0000, test acc = 0.6179, test_sen =0.5948, test_spe =0.9610, test_f1 =0.5845
[2024-10-30 18:28:08] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.045391 train acc = 0.9909, test acc = 0.6146, test_sen =0.5952, test_spe =0.9608, test_f1 =0.5824
[2024-10-30 18:28:35] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.047429 train acc = 1.0000, test acc = 0.6133, test_sen =0.5883, test_spe =0.9605, test_f1 =0.5789
[2024-10-30 18:40:19] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.071021 train acc = 1.0000, test acc = 0.6256, test_sen =0.6003, test_spe =0.9617, test_f1 =0.5948
[2024-10-30 18:40:45] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.113425 train acc = 0.9818, test acc = 0.6149, test_sen =0.5904, test_spe =0.9607, test_f1 =0.5832
[2024-10-30 18:41:10] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.012649 train acc = 1.0000, test acc = 0.6195, test_sen =0.5958, test_spe =0.9612, test_f1 =0.5869
[2024-10-30 18:41:39] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.027853 train acc = 1.0000, test acc = 0.6289, test_sen =0.6043, test_spe =0.9620, test_f1 =0.5968
[2024-10-30 18:42:06] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.023468 train acc = 1.0000, test acc = 0.6237, test_sen =0.5994, test_spe =0.9616, test_f1 =0.5924
[2024-10-30 18:53:20] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.012627 train acc = 1.0000, test acc = 0.6073, test_sen =0.5842, test_spe =0.9600, test_f1 =0.5747
[2024-10-30 18:53:48] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.008058 train acc = 1.0000, test acc = 0.6205, test_sen =0.5889, test_spe =0.9612, test_f1 =0.5830
[2024-10-30 18:54:14] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.008128 train acc = 1.0000, test acc = 0.6157, test_sen =0.5939, test_spe =0.9608, test_f1 =0.5824
[2024-10-30 18:54:43] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.010759 train acc = 1.0000, test acc = 0.6050, test_sen =0.5829, test_spe =0.9599, test_f1 =0.5727
[2024-10-30 18:55:10] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.069974 train acc = 0.9909, test acc = 0.6106, test_sen =0.5933, test_spe =0.9604, test_f1 =0.5780
[2024-10-30 19:06:37] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.007996 train acc = 1.0000, test acc = 0.6175, test_sen =0.5945, test_spe =0.9609, test_f1 =0.5857/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:08:27: Evaluate 5 random ConvNet, ACCmean = 0.6053 ACCstd = 0.0065
-------------------------
2024-10-30 19:08:27: Evaluate 5 random ConvNet, SENmean = 0.5845 SENstd = 0.0055
-------------------------
2024-10-30 19:08:27: Evaluate 5 random ConvNet, SPEmean = 0.9597 SPEstd = 0.0007
-------------------------
2024-10-30 19:08:27: Evaluate 5 random ConvNet, F!mean = 0.5756 F!std = 0.0057
-------------------------
2024-10-30 19:08:27: Evaluate 5 random ConvNet, mean = 0.6053 std = 0.0065
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:08:27: [2024-10-30 19:08:27] iter = 14000, loss = 2.1576
2024-10-30 19:08:31: [2024-10-30 19:08:31] iter = 14010, loss = 2.4284
2024-10-30 19:08:35: [2024-10-30 19:08:35] iter = 14020, loss = 1.9997
2024-10-30 19:08:39: [2024-10-30 19:08:39] iter = 14030, loss = 1.8705
2024-10-30 19:08:43: [2024-10-30 19:08:43] iter = 14040, loss = 3.2769
2024-10-30 19:08:47: [2024-10-30 19:08:47] iter = 14050, loss = 2.3050
2024-10-30 19:08:50: [2024-10-30 19:08:50] iter = 14060, loss = 3.2489
2024-10-30 19:08:53: [2024-10-30 19:08:53] iter = 14070, loss = 2.4066
2024-10-30 19:08:57: [2024-10-30 19:08:57] iter = 14080, loss = 3.4091
2024-10-30 19:09:00: [2024-10-30 19:09:00] iter = 14090, loss = 2.6105
2024-10-30 19:09:03: [2024-10-30 19:09:03] iter = 14100, loss = 2.3502
2024-10-30 19:09:06: [2024-10-30 19:09:06] iter = 14110, loss = 2.6325
2024-10-30 19:09:10: [2024-10-30 19:09:10] iter = 14120, loss = 1.8076
2024-10-30 19:09:13: [2024-10-30 19:09:13] iter = 14130, loss = 2.6662
2024-10-30 19:09:16: [2024-10-30 19:09:16] iter = 14140, loss = 5.0809
2024-10-30 19:09:20: [2024-10-30 19:09:20] iter = 14150, loss = 2.2986
2024-10-30 19:09:24: [2024-10-30 19:09:24] iter = 14160, loss = 2.9925
2024-10-30 19:09:27: [2024-10-30 19:09:27] iter = 14170, loss = 1.8883
2024-10-30 19:09:31: [2024-10-30 19:09:30] iter = 14180, loss = 2.5769
2024-10-30 19:09:35: [2024-10-30 19:09:35] iter = 14190, loss = 2.1474
2024-10-30 19:09:38: [2024-10-30 19:09:38] iter = 14200, loss = 1.8562
2024-10-30 19:09:41: [2024-10-30 19:09:41] iter = 14210, loss = 1.9036
2024-10-30 19:09:45: [2024-10-30 19:09:45] iter = 14220, loss = 2.4519
2024-10-30 19:09:48: [2024-10-30 19:09:48] iter = 14230, loss = 2.1013
2024-10-30 19:09:51: [2024-10-30 19:09:51] iter = 14240, loss = 2.0092
2024-10-30 19:09:53: [2024-10-30 19:09:53] iter = 14250, loss = 1.8523
2024-10-30 19:09:57: [2024-10-30 19:09:57] iter = 14260, loss = 2.1494
2024-10-30 19:10:01: [2024-10-30 19:10:01] iter = 14270, loss = 2.4863
2024-10-30 19:10:03: [2024-10-30 19:10:03] iter = 14280, loss = 2.2433
2024-10-30 19:10:07: [2024-10-30 19:10:07] iter = 14290, loss = 1.9638
2024-10-30 19:10:10: [2024-10-30 19:10:10] iter = 14300, loss = 3.1018
2024-10-30 19:10:14: [2024-10-30 19:10:14] iter = 14310, loss = 2.3072
2024-10-30 19:10:17: [2024-10-30 19:10:17] iter = 14320, loss = 1.9284
2024-10-30 19:10:21: [2024-10-30 19:10:21] iter = 14330, loss = 3.2416
2024-10-30 19:10:24: [2024-10-30 19:10:24] iter = 14340, loss = 2.1226
2024-10-30 19:10:28: [2024-10-30 19:10:28] iter = 14350, loss = 2.6255
2024-10-30 19:10:31: [2024-10-30 19:10:31] iter = 14360, loss = 1.9108
2024-10-30 19:10:34: [2024-10-30 19:10:34] iter = 14370, loss = 3.7029
2024-10-30 19:10:37: [2024-10-30 19:10:37] iter = 14380, loss = 2.1217
2024-10-30 19:10:41: [2024-10-30 19:10:41] iter = 14390, loss = 2.9034
2024-10-30 19:10:46: [2024-10-30 19:10:46] iter = 14400, loss = 1.7582
2024-10-30 19:10:49: [2024-10-30 19:10:49] iter = 14410, loss = 2.1012
2024-10-30 19:10:53: [2024-10-30 19:10:53] iter = 14420, loss = 3.3970
2024-10-30 19:10:57: [2024-10-30 19:10:56] iter = 14430, loss = 2.4571
2024-10-30 19:11:00: [2024-10-30 19:11:00] iter = 14440, loss = 1.8830
2024-10-30 19:11:04: [2024-10-30 19:11:04] iter = 14450, loss = 2.0207
2024-10-30 19:11:07: [2024-10-30 19:11:07] iter = 14460, loss = 1.8029
2024-10-30 19:11:10: [2024-10-30 19:11:10] iter = 14470, loss = 2.6710
2024-10-30 19:11:14: [2024-10-30 19:11:14] iter = 14480, loss = 1.9784
2024-10-30 19:11:17: [2024-10-30 19:11:17] iter = 14490, loss = 2.3866
2024-10-30 19:11:21: [2024-10-30 19:11:21] iter = 14500, loss = 2.6104
2024-10-30 19:11:23: [2024-10-30 19:11:23] iter = 14510, loss = 2.6791
2024-10-30 19:11:27: [2024-10-30 19:11:27] iter = 14520, loss = 1.8239
2024-10-30 19:11:30: [2024-10-30 19:11:30] iter = 14530, loss = 2.1747
2024-10-30 19:11:32: [2024-10-30 19:11:32] iter = 14540, loss = 2.2663
2024-10-30 19:11:35: [2024-10-30 19:11:35] iter = 14550, loss = 2.4382
2024-10-30 19:11:39: [2024-10-30 19:11:39] iter = 14560, loss = 2.3943
2024-10-30 19:11:42: [2024-10-30 19:11:42] iter = 14570, loss = 2.7128
2024-10-30 19:11:46: [2024-10-30 19:11:46] iter = 14580, loss = 2.8157
2024-10-30 19:11:49: [2024-10-30 19:11:49] iter = 14590, loss = 2.0263
2024-10-30 19:11:51: [2024-10-30 19:11:51] iter = 14600, loss = 2.0423
2024-10-30 19:11:54: [2024-10-30 19:11:54] iter = 14610, loss = 4.8747
2024-10-30 19:11:57: [2024-10-30 19:11:57] iter = 14620, loss = 2.2721
2024-10-30 19:12:00: [2024-10-30 19:12:00] iter = 14630, loss = 1.8374
2024-10-30 19:12:03: [2024-10-30 19:12:03] iter = 14640, loss = 2.3994
2024-10-30 19:12:07: [2024-10-30 19:12:07] iter = 14650, loss = 2.3396
2024-10-30 19:12:10: [2024-10-30 19:12:10] iter = 14660, loss = 2.1136
2024-10-30 19:12:14: [2024-10-30 19:12:14] iter = 14670, loss = 2.0349
2024-10-30 19:12:19: [2024-10-30 19:12:19] iter = 14680, loss = 1.9032
2024-10-30 19:12:22: [2024-10-30 19:12:22] iter = 14690, loss = 1.9376
2024-10-30 19:12:26: [2024-10-30 19:12:26] iter = 14700, loss = 2.5815
2024-10-30 19:12:28: [2024-10-30 19:12:28] iter = 14710, loss = 2.0025
2024-10-30 19:12:32: [2024-10-30 19:12:32] iter = 14720, loss = 2.0780
2024-10-30 19:12:35: [2024-10-30 19:12:35] iter = 14730, loss = 2.2015
2024-10-30 19:12:39: [2024-10-30 19:12:39] iter = 14740, loss = 2.1199
2024-10-30 19:12:43: [2024-10-30 19:12:43] iter = 14750, loss = 2.3677
2024-10-30 19:12:45: [2024-10-30 19:12:45] iter = 14760, loss = 2.0036
2024-10-30 19:12:48: [2024-10-30 19:12:48] iter = 14770, loss = 1.9564
2024-10-30 19:12:52: [2024-10-30 19:12:52] iter = 14780, loss = 2.1718
2024-10-30 19:12:55: [2024-10-30 19:12:55] iter = 14790, loss = 3.4758
2024-10-30 19:12:59: [2024-10-30 19:12:59] iter = 14800, loss = 2.1104
2024-10-30 19:13:03: [2024-10-30 19:13:03] iter = 14810, loss = 2.1661
2024-10-30 19:13:08: [2024-10-30 19:13:08] iter = 14820, loss = 2.2476
2024-10-30 19:13:12: [2024-10-30 19:13:12] iter = 14830, loss = 2.2880
2024-10-30 19:13:17: [2024-10-30 19:13:17] iter = 14840, loss = 2.2847
2024-10-30 19:13:21: [2024-10-30 19:13:21] iter = 14850, loss = 2.6991
2024-10-30 19:13:24: [2024-10-30 19:13:24] iter = 14860, loss = 2.2277
2024-10-30 19:13:28: [2024-10-30 19:13:28] iter = 14870, loss = 2.4646
2024-10-30 19:13:31: [2024-10-30 19:13:31] iter = 14880, loss = 5.8366
2024-10-30 19:13:35: [2024-10-30 19:13:35] iter = 14890, loss = 2.1508
2024-10-30 19:13:39: [2024-10-30 19:13:39] iter = 14900, loss = 2.3866
2024-10-30 19:13:42: [2024-10-30 19:13:42] iter = 14910, loss = 2.5648
2024-10-30 19:13:45: [2024-10-30 19:13:45] iter = 14920, loss = 2.1607
2024-10-30 19:13:49: [2024-10-30 19:13:49] iter = 14930, loss = 2.3897
2024-10-30 19:13:51: [2024-10-30 19:13:51] iter = 14940, loss = 2.6657
2024-10-30 19:13:54: [2024-10-30 19:13:54] iter = 14950, loss = 2.0788
2024-10-30 19:13:58: [2024-10-30 19:13:58] iter = 14960, loss = 2.7852
2024-10-30 19:14:01: [2024-10-30 19:14:01] iter = 14970, loss = 1.9869
2024-10-30 19:14:05: [2024-10-30 19:14:05] iter = 14980, loss = 3.0184
2024-10-30 19:14:08: [2024-10-30 19:14:08] iter = 14990, loss = 2.0875
2024-10-30 19:14:12: [2024-10-30 19:14:12] iter = 15000, loss = 1.8420
2024-10-30 19:14:16: [2024-10-30 19:14:16] iter = 15010, loss = 2.1859
2024-10-30 19:14:20: [2024-10-30 19:14:20] iter = 15020, loss = 2.3252
2024-10-30 19:14:23: [2024-10-30 19:14:23] iter = 15030, loss = 2.5367
2024-10-30 19:14:26: [2024-10-30 19:14:26] iter = 15040, loss = 2.7340
2024-10-30 19:14:29: [2024-10-30 19:14:29] iter = 15050, loss = 2.1111
2024-10-30 19:14:32: [2024-10-30 19:14:32] iter = 15060, loss = 2.1343
2024-10-30 19:14:36: [2024-10-30 19:14:36] iter = 15070, loss = 1.9795
2024-10-30 19:14:39: [2024-10-30 19:14:39] iter = 15080, loss = 2.3600
2024-10-30 19:14:43: [2024-10-30 19:14:43] iter = 15090, loss = 2.0638
2024-10-30 19:14:46: [2024-10-30 19:14:46] iter = 15100, loss = 2.0630
2024-10-30 19:14:50: [2024-10-30 19:14:50] iter = 15110, loss = 2.7794
2024-10-30 19:14:53: [2024-10-30 19:14:53] iter = 15120, loss = 3.7500
2024-10-30 19:14:57: [2024-10-30 19:14:57] iter = 15130, loss = 2.5717
2024-10-30 19:15:01: [2024-10-30 19:15:01] iter = 15140, loss = 2.8425
2024-10-30 19:15:04: [2024-10-30 19:15:04] iter = 15150, loss = 2.7144
2024-10-30 19:15:08: [2024-10-30 19:15:08] iter = 15160, loss = 1.9162
2024-10-30 19:15:12: [2024-10-30 19:15:12] iter = 15170, loss = 2.2031
2024-10-30 19:15:15: [2024-10-30 19:15:15] iter = 15180, loss = 2.9816
2024-10-30 19:15:19: [2024-10-30 19:15:19] iter = 15190, loss = 2.0275
2024-10-30 19:15:22: [2024-10-30 19:15:22] iter = 15200, loss = 1.9158
2024-10-30 19:15:26: [2024-10-30 19:15:26] iter = 15210, loss = 2.2073
2024-10-30 19:15:29: [2024-10-30 19:15:29] iter = 15220, loss = 2.5207
2024-10-30 19:15:33: [2024-10-30 19:15:33] iter = 15230, loss = 4.3070
2024-10-30 19:15:37: [2024-10-30 19:15:37] iter = 15240, loss = 2.3863
2024-10-30 19:15:40: [2024-10-30 19:15:40] iter = 15250, loss = 1.9713
2024-10-30 19:15:44: [2024-10-30 19:15:44] iter = 15260, loss = 1.9979
2024-10-30 19:15:47: [2024-10-30 19:15:47] iter = 15270, loss = 2.3214
2024-10-30 19:15:51: [2024-10-30 19:15:51] iter = 15280, loss = 2.9512
2024-10-30 19:15:54: [2024-10-30 19:15:54] iter = 15290, loss = 1.9034
2024-10-30 19:15:59: [2024-10-30 19:15:59] iter = 15300, loss = 2.1342
2024-10-30 19:16:02: [2024-10-30 19:16:02] iter = 15310, loss = 1.9023
2024-10-30 19:16:05: [2024-10-30 19:16:05] iter = 15320, loss = 2.7987
2024-10-30 19:16:09: [2024-10-30 19:16:09] iter = 15330, loss = 1.8882
2024-10-30 19:16:13: [2024-10-30 19:16:13] iter = 15340, loss = 2.4653
2024-10-30 19:16:16: [2024-10-30 19:16:16] iter = 15350, loss = 3.9069
2024-10-30 19:16:20: [2024-10-30 19:16:20] iter = 15360, loss = 2.0835
2024-10-30 19:16:24: [2024-10-30 19:16:24] iter = 15370, loss = 2.5108
2024-10-30 19:16:27: [2024-10-30 19:16:27] iter = 15380, loss = 2.3220
2024-10-30 19:16:30: [2024-10-30 19:16:30] iter = 15390, loss = 2.4155
2024-10-30 19:16:33: [2024-10-30 19:16:33] iter = 15400, loss = 2.6478
2024-10-30 19:16:37: [2024-10-30 19:16:37] iter = 15410, loss = 1.8748
2024-10-30 19:16:40: [2024-10-30 19:16:40] iter = 15420, loss = 2.7976
2024-10-30 19:16:44: [2024-10-30 19:16:43] iter = 15430, loss = 2.0873
2024-10-30 19:16:46: [2024-10-30 19:16:46] iter = 15440, loss = 2.3063
2024-10-30 19:16:49: [2024-10-30 19:16:49] iter = 15450, loss = 2.0294
2024-10-30 19:16:53: [2024-10-30 19:16:53] iter = 15460, loss = 2.8822
2024-10-30 19:16:55: [2024-10-30 19:16:55] iter = 15470, loss = 2.0792
2024-10-30 19:16:58: [2024-10-30 19:16:58] iter = 15480, loss = 2.3413
2024-10-30 19:17:02: [2024-10-30 19:17:02] iter = 15490, loss = 2.3029
2024-10-30 19:17:05: [2024-10-30 19:17:05] iter = 15500, loss = 2.1123
2024-10-30 19:17:08: [2024-10-30 19:17:08] iter = 15510, loss = 2.2950
2024-10-30 19:17:11: [2024-10-30 19:17:11] iter = 15520, loss = 2.1897
2024-10-30 19:17:13: [2024-10-30 19:17:13] iter = 15530, loss = 2.3506
2024-10-30 19:17:16: [2024-10-30 19:17:16] iter = 15540, loss = 2.3623
2024-10-30 19:17:20: [2024-10-30 19:17:20] iter = 15550, loss = 1.7112
2024-10-30 19:17:23: [2024-10-30 19:17:23] iter = 15560, loss = 2.4812
2024-10-30 19:17:26: [2024-10-30 19:17:26] iter = 15570, loss = 2.4086
2024-10-30 19:17:29: [2024-10-30 19:17:29] iter = 15580, loss = 2.2715
2024-10-30 19:17:32: [2024-10-30 19:17:32] iter = 15590, loss = 2.4693
2024-10-30 19:17:35: [2024-10-30 19:17:35] iter = 15600, loss = 3.0172
2024-10-30 19:17:39: [2024-10-30 19:17:39] iter = 15610, loss = 2.4496
2024-10-30 19:17:42: [2024-10-30 19:17:42] iter = 15620, loss = 2.1564
2024-10-30 19:17:46: [2024-10-30 19:17:46] iter = 15630, loss = 2.2604
2024-10-30 19:17:50: [2024-10-30 19:17:50] iter = 15640, loss = 3.0149
2024-10-30 19:17:53: [2024-10-30 19:17:53] iter = 15650, loss = 1.7704
2024-10-30 19:17:57: [2024-10-30 19:17:57] iter = 15660, loss = 2.0513
2024-10-30 19:18:00: [2024-10-30 19:18:00] iter = 15670, loss = 1.8286
2024-10-30 19:18:04: [2024-10-30 19:18:04] iter = 15680, loss = 1.9982
2024-10-30 19:18:08: [2024-10-30 19:18:08] iter = 15690, loss = 1.7455
2024-10-30 19:18:12: [2024-10-30 19:18:12] iter = 15700, loss = 2.7588
2024-10-30 19:18:16: [2024-10-30 19:18:16] iter = 15710, loss = 2.2846
2024-10-30 19:18:21: [2024-10-30 19:18:21] iter = 15720, loss = 1.8471
2024-10-30 19:18:27: [2024-10-30 19:18:27] iter = 15730, loss = 2.1778
2024-10-30 19:18:31: [2024-10-30 19:18:31] iter = 15740, loss = 2.1664
2024-10-30 19:18:34: [2024-10-30 19:18:34] iter = 15750, loss = 2.0018
2024-10-30 19:18:37: [2024-10-30 19:18:37] iter = 15760, loss = 2.5814
2024-10-30 19:18:40: [2024-10-30 19:18:40] iter = 15770, loss = 2.0744
2024-10-30 19:18:44: [2024-10-30 19:18:44] iter = 15780, loss = 2.0277
2024-10-30 19:18:47: [2024-10-30 19:18:47] iter = 15790, loss = 1.9742
2024-10-30 19:18:50: [2024-10-30 19:18:50] iter = 15800, loss = 2.7070
2024-10-30 19:18:53: [2024-10-30 19:18:53] iter = 15810, loss = 2.0137
2024-10-30 19:18:57: [2024-10-30 19:18:57] iter = 15820, loss = 2.3772
2024-10-30 19:19:00: [2024-10-30 19:19:00] iter = 15830, loss = 1.8780
2024-10-30 19:19:03: [2024-10-30 19:19:03] iter = 15840, loss = 1.8777
2024-10-30 19:19:06: [2024-10-30 19:19:06] iter = 15850, loss = 1.7658
2024-10-30 19:19:09: [2024-10-30 19:19:09] iter = 15860, loss = 2.1940
2024-10-30 19:19:13: [2024-10-30 19:19:13] iter = 15870, loss = 1.9395
2024-10-30 19:19:17: [2024-10-30 19:19:17] iter = 15880, loss = 2.0872
2024-10-30 19:19:21: [2024-10-30 19:19:21] iter = 15890, loss = 2.8387
2024-10-30 19:19:24: [2024-10-30 19:19:24] iter = 15900, loss = 2.5894
2024-10-30 19:19:28: [2024-10-30 19:19:28] iter = 15910, loss = 3.9333
2024-10-30 19:19:31: [2024-10-30 19:19:31] iter = 15920, loss = 1.9819
2024-10-30 19:19:34: [2024-10-30 19:19:34] iter = 15930, loss = 2.1858
2024-10-30 19:19:38: [2024-10-30 19:19:38] iter = 15940, loss = 2.2672
2024-10-30 19:19:42: [2024-10-30 19:19:42] iter = 15950, loss = 2.3941
2024-10-30 19:19:45: [2024-10-30 19:19:45] iter = 15960, loss = 2.4253
2024-10-30 19:19:49: [2024-10-30 19:19:49] iter = 15970, loss = 1.7974
2024-10-30 19:19:53: [2024-10-30 19:19:53] iter = 15980, loss = 2.0935
2024-10-30 19:19:55: [2024-10-30 19:19:55] iter = 15990, loss = 2.6835
2024-10-30 19:19:58: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 19:19:58: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:19:58: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 98345}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:22:09: Evaluate 5 random ConvNet, ACCmean = 0.6064 ACCstd = 0.0041
-------------------------
2024-10-30 19:22:09: Evaluate 5 random ConvNet, SENmean = 0.5901 SENstd = 0.0061
-------------------------
2024-10-30 19:22:09: Evaluate 5 random ConvNet, SPEmean = 0.9599 SPEstd = 0.0004
-------------------------
2024-10-30 19:22:09: Evaluate 5 random ConvNet, F!mean = 0.5800 F!std = 0.0053
-------------------------
2024-10-30 19:22:09: Evaluate 5 random ConvNet, mean = 0.6064 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:22:09: [2024-10-30 19:22:09] iter = 16000, loss = 2.8089
2024-10-30 19:22:13: [2024-10-30 19:22:13] iter = 16010, loss = 2.1932
2024-10-30 19:22:15: [2024-10-30 19:22:15] iter = 16020, loss = 2.2498
2024-10-30 19:22:18: [2024-10-30 19:22:18] iter = 16030, loss = 1.9232
2024-10-30 19:22:21: [2024-10-30 19:22:21] iter = 16040, loss = 1.8125
2024-10-30 19:22:24: [2024-10-30 19:22:24] iter = 16050, loss = 2.2294
2024-10-30 19:22:26: [2024-10-30 19:22:26] iter = 16060, loss = 2.0446
2024-10-30 19:22:29: [2024-10-30 19:22:29] iter = 16070, loss = 2.1718
2024-10-30 19:22:32: [2024-10-30 19:22:32] iter = 16080, loss = 3.1651
2024-10-30 19:22:35: [2024-10-30 19:22:35] iter = 16090, loss = 2.1731
2024-10-30 19:22:39: [2024-10-30 19:22:39] iter = 16100, loss = 2.8153
2024-10-30 19:22:41: [2024-10-30 19:22:41] iter = 16110, loss = 2.5757
2024-10-30 19:22:45: [2024-10-30 19:22:45] iter = 16120, loss = 2.0033
2024-10-30 19:22:48: [2024-10-30 19:22:48] iter = 16130, loss = 2.4172
2024-10-30 19:22:52: [2024-10-30 19:22:52] iter = 16140, loss = 2.4729
2024-10-30 19:22:56: [2024-10-30 19:22:56] iter = 16150, loss = 2.1614
2024-10-30 19:23:00: [2024-10-30 19:23:00] iter = 16160, loss = 2.0640
2024-10-30 19:23:03: [2024-10-30 19:23:03] iter = 16170, loss = 3.5512
2024-10-30 19:23:07: [2024-10-30 19:23:07] iter = 16180, loss = 2.2342
2024-10-30 19:23:10: [2024-10-30 19:23:10] iter = 16190, loss = 1.9470
2024-10-30 19:23:13: [2024-10-30 19:23:13] iter = 16200, loss = 2.0627
2024-10-30 19:23:17: [2024-10-30 19:23:17] iter = 16210, loss = 1.8630
2024-10-30 19:23:20: [2024-10-30 19:23:20] iter = 16220, loss = 2.3416
2024-10-30 19:23:24: [2024-10-30 19:23:24] iter = 16230, loss = 2.3749
2024-10-30 19:23:27: [2024-10-30 19:23:27] iter = 16240, loss = 2.2261
2024-10-30 19:23:31: [2024-10-30 19:23:31] iter = 16250, loss = 3.0320
2024-10-30 19:23:34: [2024-10-30 19:23:34] iter = 16260, loss = 1.8422
2024-10-30 19:23:38: [2024-10-30 19:23:38] iter = 16270, loss = 2.4004
2024-10-30 19:23:41: [2024-10-30 19:23:41] iter = 16280, loss = 2.6252
2024-10-30 19:23:44: [2024-10-30 19:23:44] iter = 16290, loss = 2.2556
2024-10-30 19:23:47: [2024-10-30 19:23:47] iter = 16300, loss = 2.0586
2024-10-30 19:23:50: [2024-10-30 19:23:50] iter = 16310, loss = 2.5346
2024-10-30 19:23:54: [2024-10-30 19:23:54] iter = 16320, loss = 1.7781
2024-10-30 19:23:57: [2024-10-30 19:23:57] iter = 16330, loss = 2.8063
2024-10-30 19:24:01: [2024-10-30 19:24:01] iter = 16340, loss = 2.2561
2024-10-30 19:24:04: [2024-10-30 19:24:04] iter = 16350, loss = 2.2944
2024-10-30 19:24:07: [2024-10-30 19:24:07] iter = 16360, loss = 2.0462
2024-10-30 19:24:10: [2024-10-30 19:24:10] iter = 16370, loss = 1.8174
2024-10-30 19:24:14: [2024-10-30 19:24:14] iter = 16380, loss = 2.0048
2024-10-30 19:24:17: [2024-10-30 19:24:17] iter = 16390, loss = 2.4568
2024-10-30 19:24:20: [2024-10-30 19:24:20] iter = 16400, loss = 2.1738
2024-10-30 19:24:24: [2024-10-30 19:24:24] iter = 16410, loss = 2.2122
2024-10-30 19:24:27: [2024-10-30 19:24:27] iter = 16420, loss = 1.8821
2024-10-30 19:24:30: [2024-10-30 19:24:30] iter = 16430, loss = 2.1000
2024-10-30 19:24:34: [2024-10-30 19:24:33] iter = 16440, loss = 2.3199
2024-10-30 19:24:37: [2024-10-30 19:24:37] iter = 16450, loss = 4.1255
2024-10-30 19:24:40: [2024-10-30 19:24:40] iter = 16460, loss = 2.0930
2024-10-30 19:24:44: [2024-10-30 19:24:44] iter = 16470, loss = 1.8916
2024-10-30 19:24:46: [2024-10-30 19:24:46] iter = 16480, loss = 2.7921
2024-10-30 19:24:49: [2024-10-30 19:24:49] iter = 16490, loss = 2.9971
2024-10-30 19:24:53: [2024-10-30 19:24:53] iter = 16500, loss = 2.0425
2024-10-30 19:24:57: [2024-10-30 19:24:57] iter = 16510, loss = 1.9161
2024-10-30 19:25:01: [2024-10-30 19:25:01] iter = 16520, loss = 2.1009
2024-10-30 19:25:05: [2024-10-30 19:25:05] iter = 16530, loss = 2.2273
2024-10-30 19:25:07: [2024-10-30 19:25:07] iter = 16540, loss = 2.4291
2024-10-30 19:25:11: [2024-10-30 19:25:11] iter = 16550, loss = 4.2010
2024-10-30 19:25:15: [2024-10-30 19:25:15] iter = 16560, loss = 2.2565
2024-10-30 19:25:18: [2024-10-30 19:25:18] iter = 16570, loss = 2.0167
2024-10-30 19:25:21: [2024-10-30 19:25:21] iter = 16580, loss = 2.0855
2024-10-30 19:25:24: [2024-10-30 19:25:24] iter = 16590, loss = 2.0799
2024-10-30 19:25:27: [2024-10-30 19:25:27] iter = 16600, loss = 1.7817
2024-10-30 19:25:31: [2024-10-30 19:25:31] iter = 16610, loss = 2.8394
2024-10-30 19:25:34: [2024-10-30 19:25:34] iter = 16620, loss = 1.9032
2024-10-30 19:25:37: [2024-10-30 19:25:37] iter = 16630, loss = 1.8115
2024-10-30 19:25:40: [2024-10-30 19:25:40] iter = 16640, loss = 2.4954
2024-10-30 19:25:44: [2024-10-30 19:25:44] iter = 16650, loss = 1.9676
2024-10-30 19:25:48: [2024-10-30 19:25:48] iter = 16660, loss = 1.8538
2024-10-30 19:25:51: [2024-10-30 19:25:51] iter = 16670, loss = 3.1926
2024-10-30 19:25:55: [2024-10-30 19:25:55] iter = 16680, loss = 1.9104
2024-10-30 19:25:59: [2024-10-30 19:25:59] iter = 16690, loss = 2.1429
2024-10-30 19:26:02: [2024-10-30 19:26:02] iter = 16700, loss = 2.3979
2024-10-30 19:26:06: [2024-10-30 19:26:06] iter = 16710, loss = 1.9771
2024-10-30 19:26:08: [2024-10-30 19:26:08] iter = 16720, loss = 2.1920
2024-10-30 19:26:11: [2024-10-30 19:26:11] iter = 16730, loss = 2.5346
2024-10-30 19:26:15: [2024-10-30 19:26:15] iter = 16740, loss = 4.0108
2024-10-30 19:26:19: [2024-10-30 19:26:19] iter = 16750, loss = 2.0611
2024-10-30 19:26:25: [2024-10-30 19:26:25] iter = 16760, loss = 2.0500
2024-10-30 19:26:30: [2024-10-30 19:26:30] iter = 16770, loss = 2.0118
2024-10-30 19:26:34: [2024-10-30 19:26:34] iter = 16780, loss = 2.3261
2024-10-30 19:26:37: [2024-10-30 19:26:37] iter = 16790, loss = 2.2558
2024-10-30 19:26:39: [2024-10-30 19:26:39] iter = 16800, loss = 1.9621
2024-10-30 19:26:41: [2024-10-30 19:26:41] iter = 16810, loss = 2.1528
2024-10-30 19:26:44: [2024-10-30 19:26:44] iter = 16820, loss = 1.9803
2024-10-30 19:26:48: [2024-10-30 19:26:48] iter = 16830, loss = 1.7119
2024-10-30 19:26:51: [2024-10-30 19:26:51] iter = 16840, loss = 2.7207
2024-10-30 19:26:55: [2024-10-30 19:26:55] iter = 16850, loss = 1.9583
2024-10-30 19:26:59: [2024-10-30 19:26:59] iter = 16860, loss = 2.4967
2024-10-30 19:27:02: [2024-10-30 19:27:02] iter = 16870, loss = 2.0540
2024-10-30 19:27:05: [2024-10-30 19:27:05] iter = 16880, loss = 2.3907
2024-10-30 19:27:08: [2024-10-30 19:27:08] iter = 16890, loss = 1.8678
2024-10-30 19:27:11: [2024-10-30 19:27:11] iter = 16900, loss = 2.6312
2024-10-30 19:27:15: [2024-10-30 19:27:15] iter = 16910, loss = 2.0377
2024-10-30 19:27:18: [2024-10-30 19:27:18] iter = 16920, loss = 1.9293
2024-10-30 19:27:22: [2024-10-30 19:27:22] iter = 16930, loss = 1.6624
2024-10-30 19:27:26: [2024-10-30 19:27:26] iter = 16940, loss = 1.9254
2024-10-30 19:27:29: [2024-10-30 19:27:29] iter = 16950, loss = 2.0521
2024-10-30 19:27:32: [2024-10-30 19:27:32] iter = 16960, loss = 2.0602
2024-10-30 19:27:34: [2024-10-30 19:27:34] iter = 16970, loss = 2.6344
2024-10-30 19:27:38: [2024-10-30 19:27:38] iter = 16980, loss = 2.2128
2024-10-30 19:27:41: [2024-10-30 19:27:41] iter = 16990, loss = 2.0152
2024-10-30 19:27:45: [2024-10-30 19:27:45] iter = 17000, loss = 2.9183
2024-10-30 19:27:48: [2024-10-30 19:27:48] iter = 17010, loss = 1.8896
2024-10-30 19:27:51: [2024-10-30 19:27:51] iter = 17020, loss = 2.7860
2024-10-30 19:27:55: [2024-10-30 19:27:55] iter = 17030, loss = 1.9989
2024-10-30 19:27:58: [2024-10-30 19:27:58] iter = 17040, loss = 1.9184
2024-10-30 19:28:01: [2024-10-30 19:28:01] iter = 17050, loss = 1.7990
2024-10-30 19:28:05: [2024-10-30 19:28:05] iter = 17060, loss = 2.2276
2024-10-30 19:28:09: [2024-10-30 19:28:09] iter = 17070, loss = 2.1684
2024-10-30 19:28:12: [2024-10-30 19:28:12] iter = 17080, loss = 1.9633
2024-10-30 19:28:15: [2024-10-30 19:28:15] iter = 17090, loss = 2.7288
2024-10-30 19:28:18: [2024-10-30 19:28:18] iter = 17100, loss = 2.2107
2024-10-30 19:28:22: [2024-10-30 19:28:22] iter = 17110, loss = 2.5433
2024-10-30 19:28:25: [2024-10-30 19:28:25] iter = 17120, loss = 2.5153
2024-10-30 19:28:29: [2024-10-30 19:28:29] iter = 17130, loss = 2.1167
2024-10-30 19:28:31: [2024-10-30 19:28:31] iter = 17140, loss = 2.2449
2024-10-30 19:28:34: [2024-10-30 19:28:34] iter = 17150, loss = 2.3282
2024-10-30 19:28:37: [2024-10-30 19:28:37] iter = 17160, loss = 1.9310
2024-10-30 19:28:40: [2024-10-30 19:28:40] iter = 17170, loss = 2.1660
2024-10-30 19:28:44: [2024-10-30 19:28:44] iter = 17180, loss = 3.7611
2024-10-30 19:28:48: [2024-10-30 19:28:48] iter = 17190, loss = 3.2662
2024-10-30 19:28:51: [2024-10-30 19:28:51] iter = 17200, loss = 2.1211
2024-10-30 19:28:55: [2024-10-30 19:28:55] iter = 17210, loss = 2.2423
2024-10-30 19:28:59: [2024-10-30 19:28:59] iter = 17220, loss = 1.9422
2024-10-30 19:29:03: [2024-10-30 19:29:03] iter = 17230, loss = 2.2013
2024-10-30 19:29:06: [2024-10-30 19:29:06] iter = 17240, loss = 2.5243
2024-10-30 19:29:09: [2024-10-30 19:29:09] iter = 17250, loss = 2.1771
2024-10-30 19:29:12: [2024-10-30 19:29:12] iter = 17260, loss = 1.8646
2024-10-30 19:29:16: [2024-10-30 19:29:16] iter = 17270, loss = 2.7929
2024-10-30 19:29:18: [2024-10-30 19:29:18] iter = 17280, loss = 1.8322
2024-10-30 19:29:21: [2024-10-30 19:29:21] iter = 17290, loss = 2.0027
2024-10-30 19:29:24: [2024-10-30 19:29:24] iter = 17300, loss = 2.1540
2024-10-30 19:29:27: [2024-10-30 19:29:27] iter = 17310, loss = 2.4046
2024-10-30 19:29:30: [2024-10-30 19:29:30] iter = 17320, loss = 2.5274
2024-10-30 19:29:33: [2024-10-30 19:29:33] iter = 17330, loss = 2.0204
2024-10-30 19:29:37: [2024-10-30 19:29:37] iter = 17340, loss = 1.9926
2024-10-30 19:29:40: [2024-10-30 19:29:40] iter = 17350, loss = 2.0911
2024-10-30 19:29:43: [2024-10-30 19:29:43] iter = 17360, loss = 2.0201
2024-10-30 19:29:47: [2024-10-30 19:29:47] iter = 17370, loss = 1.9352
2024-10-30 19:29:50: [2024-10-30 19:29:50] iter = 17380, loss = 2.0244
2024-10-30 19:29:53: [2024-10-30 19:29:53] iter = 17390, loss = 2.4485
2024-10-30 19:29:57: [2024-10-30 19:29:57] iter = 17400, loss = 2.4402
2024-10-30 19:30:00: [2024-10-30 19:30:00] iter = 17410, loss = 2.0301
2024-10-30 19:30:04: [2024-10-30 19:30:03] iter = 17420, loss = 2.2074
2024-10-30 19:30:07: [2024-10-30 19:30:07] iter = 17430, loss = 2.4934
2024-10-30 19:30:09: [2024-10-30 19:30:09] iter = 17440, loss = 4.3903
2024-10-30 19:30:13: [2024-10-30 19:30:13] iter = 17450, loss = 1.8950
2024-10-30 19:30:15: [2024-10-30 19:30:15] iter = 17460, loss = 2.0183
2024-10-30 19:30:19: [2024-10-30 19:30:19] iter = 17470, loss = 1.7957
2024-10-30 19:30:23: [2024-10-30 19:30:23] iter = 17480, loss = 1.9214
2024-10-30 19:30:27: [2024-10-30 19:30:27] iter = 17490, loss = 4.0268
2024-10-30 19:30:31: [2024-10-30 19:30:31] iter = 17500, loss = 2.6647
2024-10-30 19:30:34: [2024-10-30 19:30:34] iter = 17510, loss = 1.9981
2024-10-30 19:30:38: [2024-10-30 19:30:38] iter = 17520, loss = 2.0969
2024-10-30 19:30:42: [2024-10-30 19:30:42] iter = 17530, loss = 2.3808
2024-10-30 19:30:45: [2024-10-30 19:30:45] iter = 17540, loss = 2.0254
2024-10-30 19:30:48: [2024-10-30 19:30:48] iter = 17550, loss = 1.9760
2024-10-30 19:30:52: [2024-10-30 19:30:52] iter = 17560, loss = 2.7497
2024-10-30 19:30:55: [2024-10-30 19:30:55] iter = 17570, loss = 2.3454
2024-10-30 19:30:58: [2024-10-30 19:30:58] iter = 17580, loss = 2.2543
2024-10-30 19:31:01: [2024-10-30 19:31:01] iter = 17590, loss = 2.3556
2024-10-30 19:31:05: [2024-10-30 19:31:05] iter = 17600, loss = 2.2172
2024-10-30 19:31:07: [2024-10-30 19:31:07] iter = 17610, loss = 2.0257
2024-10-30 19:31:10: [2024-10-30 19:31:10] iter = 17620, loss = 2.5454
2024-10-30 19:31:13: [2024-10-30 19:31:13] iter = 17630, loss = 3.0493
2024-10-30 19:31:16: [2024-10-30 19:31:16] iter = 17640, loss = 2.1792
2024-10-30 19:31:19: [2024-10-30 19:31:19] iter = 17650, loss = 2.1056
2024-10-30 19:31:23: [2024-10-30 19:31:23] iter = 17660, loss = 2.3016
2024-10-30 19:31:27: [2024-10-30 19:31:27] iter = 17670, loss = 3.3970
2024-10-30 19:31:30: [2024-10-30 19:31:30] iter = 17680, loss = 1.8650
2024-10-30 19:31:34: [2024-10-30 19:31:34] iter = 17690, loss = 2.1754
2024-10-30 19:31:38: [2024-10-30 19:31:38] iter = 17700, loss = 2.4830
2024-10-30 19:31:41: [2024-10-30 19:31:41] iter = 17710, loss = 2.1284
2024-10-30 19:31:45: [2024-10-30 19:31:45] iter = 17720, loss = 2.0769
2024-10-30 19:31:48: [2024-10-30 19:31:48] iter = 17730, loss = 2.9664
2024-10-30 19:31:52: [2024-10-30 19:31:52] iter = 17740, loss = 2.3310
2024-10-30 19:31:55: [2024-10-30 19:31:55] iter = 17750, loss = 1.9881
2024-10-30 19:31:58: [2024-10-30 19:31:58] iter = 17760, loss = 1.7339
2024-10-30 19:32:01: [2024-10-30 19:32:01] iter = 17770, loss = 2.1815
2024-10-30 19:32:04: [2024-10-30 19:32:04] iter = 17780, loss = 2.1894
2024-10-30 19:32:07: [2024-10-30 19:32:07] iter = 17790, loss = 2.0441
2024-10-30 19:32:12: [2024-10-30 19:32:12] iter = 17800, loss = 1.6849
2024-10-30 19:32:14: [2024-10-30 19:32:14] iter = 17810, loss = 2.1170
2024-10-30 19:32:18: [2024-10-30 19:32:18] iter = 17820, loss = 2.4252
2024-10-30 19:32:21: [2024-10-30 19:32:21] iter = 17830, loss = 3.0893
2024-10-30 19:32:24: [2024-10-30 19:32:24] iter = 17840, loss = 2.0552
2024-10-30 19:32:26: [2024-10-30 19:32:26] iter = 17850, loss = 1.8342
2024-10-30 19:32:29: [2024-10-30 19:32:29] iter = 17860, loss = 3.7170
2024-10-30 19:32:32: [2024-10-30 19:32:32] iter = 17870, loss = 2.7587
2024-10-30 19:32:35: [2024-10-30 19:32:35] iter = 17880, loss = 2.4855
2024-10-30 19:32:38: [2024-10-30 19:32:38] iter = 17890, loss = 2.0105
2024-10-30 19:32:41: [2024-10-30 19:32:41] iter = 17900, loss = 3.3073
2024-10-30 19:32:45: [2024-10-30 19:32:45] iter = 17910, loss = 3.3957
2024-10-30 19:32:48: [2024-10-30 19:32:48] iter = 17920, loss = 2.1437
2024-10-30 19:32:51: [2024-10-30 19:32:51] iter = 17930, loss = 4.3487
2024-10-30 19:32:55: [2024-10-30 19:32:55] iter = 17940, loss = 1.8973
2024-10-30 19:32:58: [2024-10-30 19:32:58] iter = 17950, loss = 1.8431
2024-10-30 19:33:01: [2024-10-30 19:33:01] iter = 17960, loss = 1.7466
2024-10-30 19:33:05: [2024-10-30 19:33:05] iter = 17970, loss = 2.3369
2024-10-30 19:33:08: [2024-10-30 19:33:08] iter = 17980, loss = 2.9859
2024-10-30 19:33:11: [2024-10-30 19:33:11] iter = 17990, loss = 2.5129
2024-10-30 19:33:15: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 19:33:15: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:33:15: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 95123}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:35:18: Evaluate 5 random ConvNet, ACCmean = 0.6174 ACCstd = 0.0052
-------------------------
2024-10-30 19:35:18: Evaluate 5 random ConvNet, SENmean = 0.5978 SENstd = 0.0050
-------------------------
2024-10-30 19:35:18: Evaluate 5 random ConvNet, SPEmean = 0.9610 SPEstd = 0.0005
-------------------------
2024-10-30 19:35:18: Evaluate 5 random ConvNet, F!mean = 0.5903 F!std = 0.0050
-------------------------
2024-10-30 19:35:18: Evaluate 5 random ConvNet, mean = 0.6174 std = 0.0052
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:35:19: [2024-10-30 19:35:19] iter = 18000, loss = 2.7822
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:35:23: [2024-10-30 19:35:23] iter = 18010, loss = 1.9295
2024-10-30 19:35:26: [2024-10-30 19:35:26] iter = 18020, loss = 2.2267
2024-10-30 19:35:28: [2024-10-30 19:35:28] iter = 18030, loss = 2.6645
2024-10-30 19:35:30: [2024-10-30 19:35:30] iter = 18040, loss = 2.3043
2024-10-30 19:35:33: [2024-10-30 19:35:33] iter = 18050, loss = 1.8191
2024-10-30 19:35:35: [2024-10-30 19:35:35] iter = 18060, loss = 2.9976
2024-10-30 19:35:39: [2024-10-30 19:35:39] iter = 18070, loss = 1.7208
2024-10-30 19:35:42: [2024-10-30 19:35:42] iter = 18080, loss = 2.0470
2024-10-30 19:35:46: [2024-10-30 19:35:46] iter = 18090, loss = 2.6480
2024-10-30 19:35:50: [2024-10-30 19:35:50] iter = 18100, loss = 1.7617
2024-10-30 19:35:53: [2024-10-30 19:35:53] iter = 18110, loss = 2.9776
2024-10-30 19:35:56: [2024-10-30 19:35:56] iter = 18120, loss = 5.0700
2024-10-30 19:35:59: [2024-10-30 19:35:59] iter = 18130, loss = 1.8739
2024-10-30 19:36:03: [2024-10-30 19:36:03] iter = 18140, loss = 2.1951
2024-10-30 19:36:06: [2024-10-30 19:36:06] iter = 18150, loss = 2.9317
2024-10-30 19:36:09: [2024-10-30 19:36:09] iter = 18160, loss = 4.2992
2024-10-30 19:36:12: [2024-10-30 19:36:12] iter = 18170, loss = 2.3056
2024-10-30 19:36:16: [2024-10-30 19:36:16] iter = 18180, loss = 2.4132
2024-10-30 19:36:20: [2024-10-30 19:36:20] iter = 18190, loss = 1.8808
2024-10-30 19:36:24: [2024-10-30 19:36:24] iter = 18200, loss = 2.3442
2024-10-30 19:36:27: [2024-10-30 19:36:27] iter = 18210, loss = 2.5396
2024-10-30 19:36:30: [2024-10-30 19:36:29] iter = 18220, loss = 1.7554
2024-10-30 19:36:31: [2024-10-30 19:36:31] iter = 18230, loss = 2.3450
2024-10-30 19:36:34: [2024-10-30 19:36:34] iter = 18240, loss = 1.8729
2024-10-30 19:36:37: [2024-10-30 19:36:37] iter = 18250, loss = 1.9405
2024-10-30 19:36:40: [2024-10-30 19:36:40] iter = 18260, loss = 2.3943
2024-10-30 19:36:44: [2024-10-30 19:36:44] iter = 18270, loss = 2.7441
2024-10-30 19:36:47: [2024-10-30 19:36:47] iter = 18280, loss = 1.7870
2024-10-30 19:36:51: [2024-10-30 19:36:51] iter = 18290, loss = 3.4972
2024-10-30 19:36:54: [2024-10-30 19:36:54] iter = 18300, loss = 2.8103
2024-10-30 19:36:58: [2024-10-30 19:36:58] iter = 18310, loss = 2.3532
2024-10-30 19:37:02: [2024-10-30 19:37:02] iter = 18320, loss = 2.0150
2024-10-30 19:37:05: [2024-10-30 19:37:05] iter = 18330, loss = 3.3869
2024-10-30 19:37:08: [2024-10-30 19:37:08] iter = 18340, loss = 2.5139
2024-10-30 19:37:11: [2024-10-30 19:37:11] iter = 18350, loss = 2.1079
2024-10-30 19:37:15: [2024-10-30 19:37:15] iter = 18360, loss = 1.6106
2024-10-30 19:37:18: [2024-10-30 19:37:18] iter = 18370, loss = 2.1973
2024-10-30 19:37:21: [2024-10-30 19:37:21] iter = 18380, loss = 2.2862
2024-10-30 19:37:24: [2024-10-30 19:37:24] iter = 18390, loss = 2.0750
2024-10-30 19:37:27: [2024-10-30 19:37:27] iter = 18400, loss = 2.7053
2024-10-30 19:37:30: [2024-10-30 19:37:30] iter = 18410, loss = 1.9478
2024-10-30 19:37:33: [2024-10-30 19:37:33] iter = 18420, loss = 1.8500
2024-10-30 19:37:36: [2024-10-30 19:37:36] iter = 18430, loss = 2.1160
2024-10-30 19:37:40: [2024-10-30 19:37:40] iter = 18440, loss = 2.2848
2024-10-30 19:37:43: [2024-10-30 19:37:43] iter = 18450, loss = 1.9658
2024-10-30 19:37:46: [2024-10-30 19:37:46] iter = 18460, loss = 2.4843
2024-10-30 19:37:50: [2024-10-30 19:37:50] iter = 18470, loss = 2.5951
2024-10-30 19:37:53: [2024-10-30 19:37:53] iter = 18480, loss = 3.1863
2024-10-30 19:37:56: [2024-10-30 19:37:56] iter = 18490, loss = 2.1994
2024-10-30 19:37:59: [2024-10-30 19:37:59] iter = 18500, loss = 1.9731
2024-10-30 19:38:02: [2024-10-30 19:38:02] iter = 18510, loss = 1.8161
2024-10-30 19:38:05: [2024-10-30 19:38:05] iter = 18520, loss = 2.6984
2024-10-30 19:38:09: [2024-10-30 19:38:09] iter = 18530, loss = 2.2275
2024-10-30 19:38:12: [2024-10-30 19:38:12] iter = 18540, loss = 1.9917
2024-10-30 19:38:16: [2024-10-30 19:38:16] iter = 18550, loss = 1.8783
2024-10-30 19:38:19: [2024-10-30 19:38:19] iter = 18560, loss = 2.4644
2024-10-30 19:38:23: [2024-10-30 19:38:23] iter = 18570, loss = 2.2833
2024-10-30 19:38:25: [2024-10-30 19:38:25] iter = 18580, loss = 3.6295
2024-10-30 19:38:27: [2024-10-30 19:38:27] iter = 18590, loss = 2.0417
2024-10-30 19:38:30: [2024-10-30 19:38:30] iter = 18600, loss = 3.9828
2024-10-30 19:38:33: [2024-10-30 19:38:33] iter = 18610, loss = 3.8211
2024-10-30 19:38:38: [2024-10-30 19:38:38] iter = 18620, loss = 1.8643
2024-10-30 19:38:42: [2024-10-30 19:38:42] iter = 18630, loss = 2.0076
2024-10-30 19:38:45: [2024-10-30 19:38:45] iter = 18640, loss = 2.2356
2024-10-30 19:38:49: [2024-10-30 19:38:49] iter = 18650, loss = 1.9967
2024-10-30 19:38:51: [2024-10-30 19:38:51] iter = 18660, loss = 2.3167
2024-10-30 19:38:54: [2024-10-30 19:38:54] iter = 18670, loss = 2.5639
2024-10-30 19:38:59: [2024-10-30 19:38:59] iter = 18680, loss = 2.0430
2024-10-30 19:39:02: [2024-10-30 19:39:02] iter = 18690, loss = 3.5807
2024-10-30 19:39:04: [2024-10-30 19:39:04] iter = 18700, loss = 2.0354
2024-10-30 19:39:07: [2024-10-30 19:39:07] iter = 18710, loss = 1.9568
2024-10-30 19:39:10: [2024-10-30 19:39:10] iter = 18720, loss = 2.2350
2024-10-30 19:39:13: [2024-10-30 19:39:13] iter = 18730, loss = 2.4614
2024-10-30 19:39:16: [2024-10-30 19:39:16] iter = 18740, loss = 2.2510
2024-10-30 19:39:20: [2024-10-30 19:39:20] iter = 18750, loss = 1.8385
2024-10-30 19:39:23: [2024-10-30 19:39:23] iter = 18760, loss = 2.9951
2024-10-30 19:39:25: [2024-10-30 19:39:25] iter = 18770, loss = 2.2252
2024-10-30 19:39:29: [2024-10-30 19:39:29] iter = 18780, loss = 3.7735
2024-10-30 19:39:32: [2024-10-30 19:39:32] iter = 18790, loss = 2.0610
2024-10-30 19:39:34: [2024-10-30 19:39:34] iter = 18800, loss = 2.4464
2024-10-30 19:39:38: [2024-10-30 19:39:38] iter = 18810, loss = 2.0303
2024-10-30 19:39:41: [2024-10-30 19:39:41] iter = 18820, loss = 2.3099
2024-10-30 19:39:45: [2024-10-30 19:39:45] iter = 18830, loss = 1.9790
2024-10-30 19:39:48: [2024-10-30 19:39:48] iter = 18840, loss = 2.2234
2024-10-30 19:39:51: [2024-10-30 19:39:51] iter = 18850, loss = 2.3214
2024-10-30 19:39:55: [2024-10-30 19:39:55] iter = 18860, loss = 2.0698
2024-10-30 19:39:58: [2024-10-30 19:39:58] iter = 18870, loss = 1.9546
2024-10-30 19:40:01: [2024-10-30 19:40:01] iter = 18880, loss = 1.9773
2024-10-30 19:40:04: [2024-10-30 19:40:04] iter = 18890, loss = 2.5732
2024-10-30 19:40:09: [2024-10-30 19:40:09] iter = 18900, loss = 1.9963
2024-10-30 19:40:12: [2024-10-30 19:40:12] iter = 18910, loss = 1.9378
2024-10-30 19:40:15: [2024-10-30 19:40:15] iter = 18920, loss = 1.9236
2024-10-30 19:40:18: [2024-10-30 19:40:18] iter = 18930, loss = 2.5787
2024-10-30 19:40:22: [2024-10-30 19:40:22] iter = 18940, loss = 2.1114
2024-10-30 19:40:24: [2024-10-30 19:40:24] iter = 18950, loss = 1.7533
2024-10-30 19:40:27: [2024-10-30 19:40:27] iter = 18960, loss = 2.3035
2024-10-30 19:40:30: [2024-10-30 19:40:30] iter = 18970, loss = 2.0293
2024-10-30 19:40:34: [2024-10-30 19:40:34] iter = 18980, loss = 3.0370
2024-10-30 19:40:37: [2024-10-30 19:40:37] iter = 18990, loss = 2.4610
2024-10-30 19:40:41: [2024-10-30 19:40:41] iter = 19000, loss = 2.0207
2024-10-30 19:40:45: [2024-10-30 19:40:45] iter = 19010, loss = 2.1162
2024-10-30 19:40:48: [2024-10-30 19:40:48] iter = 19020, loss = 2.1603
2024-10-30 19:40:52: [2024-10-30 19:40:52] iter = 19030, loss = 2.1121
2024-10-30 19:40:55: [2024-10-30 19:40:55] iter = 19040, loss = 2.1575
2024-10-30 19:40:59: [2024-10-30 19:40:59] iter = 19050, loss = 3.2151
2024-10-30 19:41:03: [2024-10-30 19:41:03] iter = 19060, loss = 2.3487
2024-10-30 19:41:06: [2024-10-30 19:41:06] iter = 19070, loss = 3.9960
2024-10-30 19:41:10: [2024-10-30 19:41:10] iter = 19080, loss = 2.3531
2024-10-30 19:41:13: [2024-10-30 19:41:13] iter = 19090, loss = 2.2024
2024-10-30 19:41:16: [2024-10-30 19:41:16] iter = 19100, loss = 2.1843
2024-10-30 19:41:20: [2024-10-30 19:41:20] iter = 19110, loss = 1.8657
2024-10-30 19:41:22: [2024-10-30 19:41:22] iter = 19120, loss = 1.8308
2024-10-30 19:41:25: [2024-10-30 19:41:25] iter = 19130, loss = 1.9382
2024-10-30 19:41:29: [2024-10-30 19:41:29] iter = 19140, loss = 1.8435
2024-10-30 19:41:32: [2024-10-30 19:41:32] iter = 19150, loss = 1.7891
2024-10-30 19:41:35: [2024-10-30 19:41:35] iter = 19160, loss = 2.4578
2024-10-30 19:41:38: [2024-10-30 19:41:38] iter = 19170, loss = 1.7916
2024-10-30 19:41:41: [2024-10-30 19:41:41] iter = 19180, loss = 1.8785
2024-10-30 19:41:45: [2024-10-30 19:41:45] iter = 19190, loss = 1.9401
2024-10-30 19:41:49: [2024-10-30 19:41:49] iter = 19200, loss = 3.2792
2024-10-30 19:41:53: [2024-10-30 19:41:53] iter = 19210, loss = 1.9231
2024-10-30 19:41:56: [2024-10-30 19:41:56] iter = 19220, loss = 1.9038
2024-10-30 19:41:59: [2024-10-30 19:41:59] iter = 19230, loss = 3.1109
2024-10-30 19:42:03: [2024-10-30 19:42:03] iter = 19240, loss = 5.1124
2024-10-30 19:42:06: [2024-10-30 19:42:06] iter = 19250, loss = 2.8825
2024-10-30 19:42:09: [2024-10-30 19:42:09] iter = 19260, loss = 3.6489
2024-10-30 19:42:13: [2024-10-30 19:42:13] iter = 19270, loss = 2.2172
2024-10-30 19:42:15: [2024-10-30 19:42:15] iter = 19280, loss = 2.6484
2024-10-30 19:42:18: [2024-10-30 19:42:18] iter = 19290, loss = 2.7535
2024-10-30 19:42:21: [2024-10-30 19:42:21] iter = 19300, loss = 2.3660
2024-10-30 19:42:24: [2024-10-30 19:42:24] iter = 19310, loss = 2.4591
2024-10-30 19:42:28: [2024-10-30 19:42:28] iter = 19320, loss = 1.7590
2024-10-30 19:42:30: [2024-10-30 19:42:30] iter = 19330, loss = 2.1484
2024-10-30 19:42:32: [2024-10-30 19:42:32] iter = 19340, loss = 2.2131
2024-10-30 19:42:35: [2024-10-30 19:42:35] iter = 19350, loss = 2.2886
2024-10-30 19:42:39: [2024-10-30 19:42:39] iter = 19360, loss = 6.7922
2024-10-30 19:42:41: [2024-10-30 19:42:41] iter = 19370, loss = 1.8658
2024-10-30 19:42:44: [2024-10-30 19:42:44] iter = 19380, loss = 3.6738
2024-10-30 19:42:47: [2024-10-30 19:42:47] iter = 19390, loss = 2.2369
2024-10-30 19:42:50: [2024-10-30 19:42:50] iter = 19400, loss = 2.9892
2024-10-30 19:42:54: [2024-10-30 19:42:54] iter = 19410, loss = 2.2409
2024-10-30 19:42:57: [2024-10-30 19:42:57] iter = 19420, loss = 3.0737
2024-10-30 19:43:00: [2024-10-30 19:43:00] iter = 19430, loss = 2.1266
2024-10-30 19:43:04: [2024-10-30 19:43:04] iter = 19440, loss = 1.9392
2024-10-30 19:43:07: [2024-10-30 19:43:07] iter = 19450, loss = 2.5581
2024-10-30 19:43:10: [2024-10-30 19:43:10] iter = 19460, loss = 1.8562
2024-10-30 19:43:13: [2024-10-30 19:43:13] iter = 19470, loss = 1.9981
2024-10-30 19:43:17: [2024-10-30 19:43:17] iter = 19480, loss = 3.0469
2024-10-30 19:43:20: [2024-10-30 19:43:20] iter = 19490, loss = 2.1315
2024-10-30 19:43:24: [2024-10-30 19:43:24] iter = 19500, loss = 2.9985
2024-10-30 19:43:27: [2024-10-30 19:43:27] iter = 19510, loss = 2.1995
2024-10-30 19:43:30: [2024-10-30 19:43:30] iter = 19520, loss = 2.7925
2024-10-30 19:43:33: [2024-10-30 19:43:33] iter = 19530, loss = 2.5562
2024-10-30 19:43:36: [2024-10-30 19:43:36] iter = 19540, loss = 2.0875
2024-10-30 19:43:39: [2024-10-30 19:43:39] iter = 19550, loss = 2.0650
2024-10-30 19:43:43: [2024-10-30 19:43:43] iter = 19560, loss = 2.9314
2024-10-30 19:43:46: [2024-10-30 19:43:46] iter = 19570, loss = 1.8142
2024-10-30 19:43:50: [2024-10-30 19:43:50] iter = 19580, loss = 2.6656
2024-10-30 19:43:53: [2024-10-30 19:43:53] iter = 19590, loss = 2.6431
2024-10-30 19:43:57: [2024-10-30 19:43:57] iter = 19600, loss = 2.2051
2024-10-30 19:44:01: [2024-10-30 19:44:01] iter = 19610, loss = 2.9788
2024-10-30 19:44:04: [2024-10-30 19:44:04] iter = 19620, loss = 2.2382
2024-10-30 19:44:08: [2024-10-30 19:44:08] iter = 19630, loss = 2.1363
2024-10-30 19:44:11: [2024-10-30 19:44:11] iter = 19640, loss = 3.5900
2024-10-30 19:44:14: [2024-10-30 19:44:14] iter = 19650, loss = 1.7940
2024-10-30 19:44:18: [2024-10-30 19:44:18] iter = 19660, loss = 2.3386
2024-10-30 19:44:21: [2024-10-30 19:44:21] iter = 19670, loss = 1.9941
2024-10-30 19:44:24: [2024-10-30 19:44:24] iter = 19680, loss = 2.0837
2024-10-30 19:44:28: [2024-10-30 19:44:28] iter = 19690, loss = 3.0243
2024-10-30 19:44:31: [2024-10-30 19:44:31] iter = 19700, loss = 2.1416
2024-10-30 19:44:34: [2024-10-30 19:44:34] iter = 19710, loss = 2.2658
2024-10-30 19:44:38: [2024-10-30 19:44:38] iter = 19720, loss = 2.2474
2024-10-30 19:44:40: [2024-10-30 19:44:40] iter = 19730, loss = 2.9127
2024-10-30 19:44:42: [2024-10-30 19:44:42] iter = 19740, loss = 1.7651
2024-10-30 19:44:44: [2024-10-30 19:44:44] iter = 19750, loss = 1.9124
2024-10-30 19:44:46: [2024-10-30 19:44:46] iter = 19760, loss = 1.8603
2024-10-30 19:44:50: [2024-10-30 19:44:50] iter = 19770, loss = 2.1871
2024-10-30 19:44:52: [2024-10-30 19:44:52] iter = 19780, loss = 2.1128
2024-10-30 19:44:55: [2024-10-30 19:44:55] iter = 19790, loss = 3.2150
2024-10-30 19:44:59: [2024-10-30 19:44:59] iter = 19800, loss = 1.8956
2024-10-30 19:45:02: [2024-10-30 19:45:02] iter = 19810, loss = 2.4352
2024-10-30 19:45:05: [2024-10-30 19:45:05] iter = 19820, loss = 2.2936
2024-10-30 19:45:08: [2024-10-30 19:45:08] iter = 19830, loss = 2.8200
2024-10-30 19:45:12: [2024-10-30 19:45:12] iter = 19840, loss = 2.4046
2024-10-30 19:45:14: [2024-10-30 19:45:14] iter = 19850, loss = 2.3610
2024-10-30 19:45:17: [2024-10-30 19:45:17] iter = 19860, loss = 2.9356
2024-10-30 19:45:19: [2024-10-30 19:45:19] iter = 19870, loss = 2.3128
2024-10-30 19:45:22: [2024-10-30 19:45:22] iter = 19880, loss = 2.2238
2024-10-30 19:45:25: [2024-10-30 19:45:25] iter = 19890, loss = 1.8477
2024-10-30 19:45:28: [2024-10-30 19:45:28] iter = 19900, loss = 2.5445
2024-10-30 19:45:32: [2024-10-30 19:45:32] iter = 19910, loss = 2.2629
2024-10-30 19:45:34: [2024-10-30 19:45:34] iter = 19920, loss = 2.0135
2024-10-30 19:45:37: [2024-10-30 19:45:37] iter = 19930, loss = 2.4845
2024-10-30 19:45:41: [2024-10-30 19:45:41] iter = 19940, loss = 2.0796
2024-10-30 19:45:44: [2024-10-30 19:45:44] iter = 19950, loss = 2.1264
2024-10-30 19:45:48: [2024-10-30 19:45:48] iter = 19960, loss = 3.5842
2024-10-30 19:45:51: [2024-10-30 19:45:51] iter = 19970, loss = 2.9549
2024-10-30 19:45:54: [2024-10-30 19:45:54] iter = 19980, loss = 2.3181
2024-10-30 19:45:57: [2024-10-30 19:45:57] iter = 19990, loss = 1.8035
2024-10-30 19:46:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 19:46:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:46:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 61058}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:48:16: Evaluate 5 random ConvNet, ACCmean = 0.6154 ACCstd = 0.0044
-------------------------
2024-10-30 19:48:16: Evaluate 5 random ConvNet, SENmean = 0.5962 SENstd = 0.0032
-------------------------
2024-10-30 19:48:16: Evaluate 5 random ConvNet, SPEmean = 0.9608 SPEstd = 0.0004
-------------------------
2024-10-30 19:48:16: Evaluate 5 random ConvNet, F!mean = 0.5853 F!std = 0.0033
-------------------------
2024-10-30 19:48:16: Evaluate 5 random ConvNet, mean = 0.6154 std = 0.0044
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:48:16: [2024-10-30 19:48:16] iter = 20000, loss = 2.4678
2024-10-30 19:48:16: 
================== Exp 2 ==================
 
2024-10-30 19:48:16: Hyper-parameters: 
{'dataset': 'OrganSMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fa9b88fdb20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganSMNIST (INFO)>}
2024-10-30 19:48:16: Evaluation model pool: ['ConvNet']
2024-10-30 19:48:17: class c = 0: 1148 real images
2024-10-30 19:48:17: class c = 1: 630 real images
2024-10-30 19:48:17: class c = 2: 614 real images
2024-10-30 19:48:17: class c = 3: 721 real images
2024-10-30 19:48:17: class c = 4: 1132 real images
2024-10-30 19:48:17: class c = 5: 1119 real images
2024-10-30 19:48:17: class c = 6: 3464 real images
2024-10-30 19:48:17: class c = 7: 741 real images
2024-10-30 19:48:17: class c = 8: 803 real images
2024-10-30 19:48:17: class c = 9: 2004 real images
2024-10-30 19:48:17: class c = 10: 1556 real images
2024-10-30 19:48:17: real images channel 0, mean = 0.4953, std = 0.2826
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 19:48:17: initialize synthetic data from random real images
2024-10-30 19:48:17: [2024-10-30 19:48:17] training begins
2024-10-30 19:48:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 19:48:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:48:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 96746}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:50:18: Evaluate 5 random ConvNet, ACCmean = 0.4322 ACCstd = 0.0025
-------------------------
2024-10-30 19:50:18: Evaluate 5 random ConvNet, SENmean = 0.4366 SENstd = 0.0041
-------------------------
2024-10-30 19:50:18: Evaluate 5 random ConvNet, SPEmean = 0.9425 SPEstd = 0.0003
-------------------------
2024-10-30 19:50:18: Evaluate 5 random ConvNet, F!mean = 0.4170 F!std = 0.0030
-------------------------
2024-10-30 19:50:18: Evaluate 5 random ConvNet, mean = 0.4322 std = 0.0025
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:50:19: [2024-10-30 19:50:19] iter = 00000, loss = 17.7684
2024-10-30 19:50:22: [2024-10-30 19:50:22] iter = 00010, loss = 6.5041
2024-10-30 19:50:26: [2024-10-30 19:50:26] iter = 00020, loss = 4.0850
2024-10-30 19:50:30: [2024-10-30 19:50:30] iter = 00030, loss = 4.4590
2024-10-30 19:50:33: [2024-10-30 19:50:33] iter = 00040, loss = 2.5031
2024-10-30 19:50:37: [2024-10-30 19:50:37] iter = 00050, loss = 3.6913
2024-10-30 19:50:40: [2024-10-30 19:50:40] iter = 00060, loss = 6.7201
2024-10-30 19:50:43: [2024-10-30 19:50:43] iter = 00070, loss = 2.8056
2024-10-30 19:50:45: [2024-10-30 19:50:45] iter = 00080, loss = 2.6229
2024-10-30 19:50:47: [2024-10-30 19:50:47] iter = 00090, loss = 3.1276
2024-10-30 19:50:50: [2024-10-30 19:50:50] iter = 00100, loss = 2.9708
2024-10-30 19:50:53: [2024-10-30 19:50:53] iter = 00110, loss = 2.7434
2024-10-30 19:50:56: [2024-10-30 19:50:56] iter = 00120, loss = 2.7926
2024-10-30 19:51:00: [2024-10-30 19:51:00] iter = 00130, loss = 4.6258
2024-10-30 19:51:02: [2024-10-30 19:51:02] iter = 00140, loss = 2.1743
2024-10-30 19:51:04: [2024-10-30 19:51:04] iter = 00150, loss = 2.8475
2024-10-30 19:51:07: [2024-10-30 19:51:07] iter = 00160, loss = 3.6823
2024-10-30 19:51:12: [2024-10-30 19:51:12] iter = 00170, loss = 2.3204
2024-10-30 19:51:16: [2024-10-30 19:51:16] iter = 00180, loss = 2.4871
2024-10-30 19:51:19: [2024-10-30 19:51:19] iter = 00190, loss = 2.4121
2024-10-30 19:51:24: [2024-10-30 19:51:24] iter = 00200, loss = 2.9189
2024-10-30 19:51:27: [2024-10-30 19:51:27] iter = 00210, loss = 2.3886
2024-10-30 19:51:30: [2024-10-30 19:51:30] iter = 00220, loss = 2.3601
2024-10-30 19:51:34: [2024-10-30 19:51:34] iter = 00230, loss = 2.4422
2024-10-30 19:51:38: [2024-10-30 19:51:38] iter = 00240, loss = 3.7832
2024-10-30 19:51:41: [2024-10-30 19:51:41] iter = 00250, loss = 2.2620
2024-10-30 19:51:45: [2024-10-30 19:51:45] iter = 00260, loss = 2.6260
2024-10-30 19:51:47: [2024-10-30 19:51:47] iter = 00270, loss = 5.5360
2024-10-30 19:51:50: [2024-10-30 19:51:50] iter = 00280, loss = 2.8086
2024-10-30 19:51:55: [2024-10-30 19:51:55] iter = 00290, loss = 2.3577
2024-10-30 19:51:58: [2024-10-30 19:51:58] iter = 00300, loss = 2.6843
2024-10-30 19:52:01: [2024-10-30 19:52:01] iter = 00310, loss = 3.0012
2024-10-30 19:52:04: [2024-10-30 19:52:04] iter = 00320, loss = 2.7438
2024-10-30 19:52:07: [2024-10-30 19:52:07] iter = 00330, loss = 2.9067
2024-10-30 19:52:10: [2024-10-30 19:52:10] iter = 00340, loss = 2.3831
2024-10-30 19:52:13: [2024-10-30 19:52:13] iter = 00350, loss = 2.2373
2024-10-30 19:52:16: [2024-10-30 19:52:16] iter = 00360, loss = 2.9559
2024-10-30 19:52:20: [2024-10-30 19:52:20] iter = 00370, loss = 2.1658
2024-10-30 19:52:23: [2024-10-30 19:52:23] iter = 00380, loss = 2.7441
2024-10-30 19:52:26: [2024-10-30 19:52:26] iter = 00390, loss = 2.7114
2024-10-30 19:52:29: [2024-10-30 19:52:29] iter = 00400, loss = 2.9320
2024-10-30 19:52:32: [2024-10-30 19:52:32] iter = 00410, loss = 2.4256
2024-10-30 19:52:36: [2024-10-30 19:52:36] iter = 00420, loss = 1.9658
2024-10-30 19:52:39: [2024-10-30 19:52:39] iter = 00430, loss = 2.5680
2024-10-30 19:52:42: [2024-10-30 19:52:42] iter = 00440, loss = 2.9205
2024-10-30 19:52:45: [2024-10-30 19:52:45] iter = 00450, loss = 2.0894
2024-10-30 19:52:48: [2024-10-30 19:52:48] iter = 00460, loss = 2.2951
2024-10-30 19:52:52: [2024-10-30 19:52:52] iter = 00470, loss = 3.0472
2024-10-30 19:52:56: [2024-10-30 19:52:56] iter = 00480, loss = 2.4305
2024-10-30 19:53:00: [2024-10-30 19:53:00] iter = 00490, loss = 1.8702
2024-10-30 19:53:03: [2024-10-30 19:53:03] iter = 00500, loss = 2.1742
2024-10-30 19:53:07: [2024-10-30 19:53:07] iter = 00510, loss = 2.8159
2024-10-30 19:53:11: [2024-10-30 19:53:11] iter = 00520, loss = 2.4623
2024-10-30 19:53:14: [2024-10-30 19:53:14] iter = 00530, loss = 2.3408
2024-10-30 19:53:18: [2024-10-30 19:53:18] iter = 00540, loss = 2.3903
2024-10-30 19:53:22: [2024-10-30 19:53:22] iter = 00550, loss = 2.0238
2024-10-30 19:53:26: [2024-10-30 19:53:26] iter = 00560, loss = 2.6694
2024-10-30 19:53:30: [2024-10-30 19:53:30] iter = 00570, loss = 3.2763
2024-10-30 19:53:34: [2024-10-30 19:53:34] iter = 00580, loss = 2.6889
2024-10-30 19:53:37: [2024-10-30 19:53:37] iter = 00590, loss = 4.4836
2024-10-30 19:53:42: [2024-10-30 19:53:42] iter = 00600, loss = 2.8119
2024-10-30 19:53:45: [2024-10-30 19:53:45] iter = 00610, loss = 3.0127
2024-10-30 19:53:49: [2024-10-30 19:53:49] iter = 00620, loss = 2.8611
2024-10-30 19:53:53: [2024-10-30 19:53:53] iter = 00630, loss = 3.5560
2024-10-30 19:53:56: [2024-10-30 19:53:56] iter = 00640, loss = 1.9234
2024-10-30 19:53:59: [2024-10-30 19:53:58] iter = 00650, loss = 2.1423
2024-10-30 19:54:02: [2024-10-30 19:54:02] iter = 00660, loss = 2.4882
2024-10-30 19:54:05: [2024-10-30 19:54:05] iter = 00670, loss = 2.9059
2024-10-30 19:54:09: [2024-10-30 19:54:09] iter = 00680, loss = 3.4161
2024-10-30 19:54:12: [2024-10-30 19:54:12] iter = 00690, loss = 2.4342
2024-10-30 19:54:16: [2024-10-30 19:54:16] iter = 00700, loss = 2.5721
2024-10-30 19:54:19: [2024-10-30 19:54:19] iter = 00710, loss = 2.0956
2024-10-30 19:54:23: [2024-10-30 19:54:23] iter = 00720, loss = 2.2472
2024-10-30 19:54:27: [2024-10-30 19:54:27] iter = 00730, loss = 1.9678
2024-10-30 19:54:30: [2024-10-30 19:54:30] iter = 00740, loss = 2.2649
2024-10-30 19:54:33: [2024-10-30 19:54:33] iter = 00750, loss = 2.3264
2024-10-30 19:54:37: [2024-10-30 19:54:37] iter = 00760, loss = 2.1778
2024-10-30 19:54:41: [2024-10-30 19:54:41] iter = 00770, loss = 2.4336
2024-10-30 19:54:43: [2024-10-30 19:54:43] iter = 00780, loss = 2.1254
2024-10-30 19:54:46: [2024-10-30 19:54:46] iter = 00790, loss = 2.5906
2024-10-30 19:54:49: [2024-10-30 19:54:49] iter = 00800, loss = 2.5271
2024-10-30 19:54:53: [2024-10-30 19:54:53] iter = 00810, loss = 2.2556
2024-10-30 19:54:56: [2024-10-30 19:54:56] iter = 00820, loss = 2.4999
2024-10-30 19:55:00: [2024-10-30 19:55:00] iter = 00830, loss = 2.1128
2024-10-30 19:55:03: [2024-10-30 19:55:03] iter = 00840, loss = 2.3960
2024-10-30 19:55:07: [2024-10-30 19:55:07] iter = 00850, loss = 2.2975
2024-10-30 19:55:11: [2024-10-30 19:55:11] iter = 00860, loss = 2.0005
2024-10-30 19:55:15: [2024-10-30 19:55:15] iter = 00870, loss = 2.4351
2024-10-30 19:55:18: [2024-10-30 19:55:18] iter = 00880, loss = 2.5044
2024-10-30 19:55:22: [2024-10-30 19:55:22] iter = 00890, loss = 2.2818
2024-10-30 19:55:25: [2024-10-30 19:55:25] iter = 00900, loss = 2.1525
2024-10-30 19:55:28: [2024-10-30 19:55:28] iter = 00910, loss = 2.3451
2024-10-30 19:55:32: [2024-10-30 19:55:32] iter = 00920, loss = 2.2333
2024-10-30 19:55:36: [2024-10-30 19:55:36] iter = 00930, loss = 3.7704
2024-10-30 19:55:40: [2024-10-30 19:55:40] iter = 00940, loss = 2.5929
2024-10-30 19:55:42: [2024-10-30 19:55:42] iter = 00950, loss = 2.4885
2024-10-30 19:55:45: [2024-10-30 19:55:45] iter = 00960, loss = 2.4597
2024-10-30 19:55:49: [2024-10-30 19:55:49] iter = 00970, loss = 2.2758
2024-10-30 19:55:53: [2024-10-30 19:55:53] iter = 00980, loss = 2.2677
2024-10-30 19:55:56: [2024-10-30 19:55:56] iter = 00990, loss = 2.3634
2024-10-30 19:56:00: [2024-10-30 19:56:00] iter = 01000, loss = 3.7044
2024-10-30 19:56:03: [2024-10-30 19:56:03] iter = 01010, loss = 2.5859
2024-10-30 19:56:05: [2024-10-30 19:56:05] iter = 01020, loss = 2.6589
2024-10-30 19:56:08: [2024-10-30 19:56:08] iter = 01030, loss = 2.1190
2024-10-30 19:56:11: [2024-10-30 19:56:11] iter = 01040, loss = 2.5367
2024-10-30 19:56:14: [2024-10-30 19:56:14] iter = 01050, loss = 2.0527
2024-10-30 19:56:16: [2024-10-30 19:56:16] iter = 01060, loss = 2.6016
2024-10-30 19:56:19: [2024-10-30 19:56:19] iter = 01070, loss = 2.3815
2024-10-30 19:56:23: [2024-10-30 19:56:23] iter = 01080, loss = 2.0067
2024-10-30 19:56:26: [2024-10-30 19:56:26] iter = 01090, loss = 2.5563
2024-10-30 19:56:29: [2024-10-30 19:56:29] iter = 01100, loss = 2.1582
2024-10-30 19:56:33: [2024-10-30 19:56:33] iter = 01110, loss = 2.2002
2024-10-30 19:56:35: [2024-10-30 19:56:35] iter = 01120, loss = 3.6098
2024-10-30 19:56:39: [2024-10-30 19:56:39] iter = 01130, loss = 2.6286
2024-10-30 19:56:42: [2024-10-30 19:56:42] iter = 01140, loss = 2.4779
2024-10-30 19:56:45: [2024-10-30 19:56:45] iter = 01150, loss = 2.3781
2024-10-30 19:56:48: [2024-10-30 19:56:48] iter = 01160, loss = 2.2402
2024-10-30 19:56:52: [2024-10-30 19:56:52] iter = 01170, loss = 2.0097
2024-10-30 19:56:56: [2024-10-30 19:56:56] iter = 01180, loss = 1.8787
2024-10-30 19:56:58: [2024-10-30 19:56:58] iter = 01190, loss = 2.5764
2024-10-30 19:57:01: [2024-10-30 19:57:01] iter = 01200, loss = 2.0540
2024-10-30 19:57:04: [2024-10-30 19:57:04] iter = 01210, loss = 2.5515
2024-10-30 19:57:07: [2024-10-30 19:57:07] iter = 01220, loss = 2.1656
2024-10-30 19:57:10: [2024-10-30 19:57:10] iter = 01230, loss = 2.0177
2024-10-30 19:57:13: [2024-10-30 19:57:13] iter = 01240, loss = 2.1405
2024-10-30 19:57:17: [2024-10-30 19:57:17] iter = 01250, loss = 1.8199
2024-10-30 19:57:21: [2024-10-30 19:57:21] iter = 01260, loss = 2.0979
2024-10-30 19:57:24: [2024-10-30 19:57:24] iter = 01270, loss = 2.7557
2024-10-30 19:57:27: [2024-10-30 19:57:27] iter = 01280, loss = 2.6290
2024-10-30 19:57:30: [2024-10-30 19:57:30] iter = 01290, loss = 4.3017
2024-10-30 19:57:34: [2024-10-30 19:57:34] iter = 01300, loss = 1.8184
2024-10-30 19:57:38: [2024-10-30 19:57:38] iter = 01310, loss = 3.6562
2024-10-30 19:57:41: [2024-10-30 19:57:41] iter = 01320, loss = 4.2404
2024-10-30 19:57:43: [2024-10-30 19:57:43] iter = 01330, loss = 1.9673
2024-10-30 19:57:47: [2024-10-30 19:57:47] iter = 01340, loss = 2.4196
2024-10-30 19:57:50: [2024-10-30 19:57:50] iter = 01350, loss = 2.0895
2024-10-30 19:57:53: [2024-10-30 19:57:53] iter = 01360, loss = 2.4375
2024-10-30 19:57:56: [2024-10-30 19:57:56] iter = 01370, loss = 2.2143
2024-10-30 19:57:59: [2024-10-30 19:57:59] iter = 01380, loss = 2.2780
2024-10-30 19:58:03: [2024-10-30 19:58:03] iter = 01390, loss = 2.1701
2024-10-30 19:58:06: [2024-10-30 19:58:06] iter = 01400, loss = 2.3998
2024-10-30 19:58:09: [2024-10-30 19:58:09] iter = 01410, loss = 2.7861
2024-10-30 19:58:13: [2024-10-30 19:58:13] iter = 01420, loss = 2.3288
2024-10-30 19:58:17: [2024-10-30 19:58:17] iter = 01430, loss = 2.5420
2024-10-30 19:58:20: [2024-10-30 19:58:20] iter = 01440, loss = 2.1825
2024-10-30 19:58:23: [2024-10-30 19:58:23] iter = 01450, loss = 2.5347
2024-10-30 19:58:26: [2024-10-30 19:58:26] iter = 01460, loss = 1.8957
2024-10-30 19:58:29: [2024-10-30 19:58:29] iter = 01470, loss = 1.8822
2024-10-30 19:58:32: [2024-10-30 19:58:32] iter = 01480, loss = 2.1927
2024-10-30 19:58:35: [2024-10-30 19:58:35] iter = 01490, loss = 2.2192
2024-10-30 19:58:38: [2024-10-30 19:58:38] iter = 01500, loss = 2.6519
2024-10-30 19:58:40: [2024-10-30 19:58:40] iter = 01510, loss = 1.9358
2024-10-30 19:58:43: [2024-10-30 19:58:43] iter = 01520, loss = 2.3484
2024-10-30 19:58:47: [2024-10-30 19:58:47] iter = 01530, loss = 2.5451
2024-10-30 19:58:50: [2024-10-30 19:58:50] iter = 01540, loss = 2.8830
2024-10-30 19:58:52: [2024-10-30 19:58:52] iter = 01550, loss = 2.1921
2024-10-30 19:58:55: [2024-10-30 19:58:55] iter = 01560, loss = 2.9672
2024-10-30 19:58:58: [2024-10-30 19:58:58] iter = 01570, loss = 2.6898
2024-10-30 19:59:01: [2024-10-30 19:59:01] iter = 01580, loss = 2.8745
2024-10-30 19:59:04: [2024-10-30 19:59:04] iter = 01590, loss = 2.4139
2024-10-30 19:59:07: [2024-10-30 19:59:07] iter = 01600, loss = 2.6085
2024-10-30 19:59:10: [2024-10-30 19:59:10] iter = 01610, loss = 2.6545
2024-10-30 19:59:14: [2024-10-30 19:59:14] iter = 01620, loss = 1.9989
2024-10-30 19:59:17: [2024-10-30 19:59:17] iter = 01630, loss = 2.3670
2024-10-30 19:59:21: [2024-10-30 19:59:21] iter = 01640, loss = 2.2684
2024-10-30 19:59:24: [2024-10-30 19:59:24] iter = 01650, loss = 2.1008
2024-10-30 19:59:27: [2024-10-30 19:59:27] iter = 01660, loss = 2.4005
2024-10-30 19:59:31: [2024-10-30 19:59:31] iter = 01670, loss = 2.1456
2024-10-30 19:59:34: [2024-10-30 19:59:34] iter = 01680, loss = 2.3711
2024-10-30 19:59:36: [2024-10-30 19:59:36] iter = 01690, loss = 2.5349
2024-10-30 19:59:39: [2024-10-30 19:59:39] iter = 01700, loss = 2.1892
2024-10-30 19:59:42: [2024-10-30 19:59:42] iter = 01710, loss = 2.6824
2024-10-30 19:59:46: [2024-10-30 19:59:46] iter = 01720, loss = 2.7529
2024-10-30 19:59:49: [2024-10-30 19:59:49] iter = 01730, loss = 1.9982
2024-10-30 19:59:53: [2024-10-30 19:59:53] iter = 01740, loss = 2.1662
2024-10-30 19:59:55: [2024-10-30 19:59:55] iter = 01750, loss = 2.6952
2024-10-30 19:59:59: [2024-10-30 19:59:59] iter = 01760, loss = 2.0118
2024-10-30 20:00:01: [2024-10-30 20:00:01] iter = 01770, loss = 1.9842
2024-10-30 20:00:04: [2024-10-30 20:00:04] iter = 01780, loss = 2.9386
2024-10-30 20:00:07: [2024-10-30 20:00:07] iter = 01790, loss = 3.2780
2024-10-30 20:00:09: [2024-10-30 20:00:09] iter = 01800, loss = 2.4968
2024-10-30 20:00:13: [2024-10-30 20:00:13] iter = 01810, loss = 1.9770
2024-10-30 20:00:16: [2024-10-30 20:00:16] iter = 01820, loss = 2.1166
2024-10-30 20:00:19: [2024-10-30 20:00:19] iter = 01830, loss = 2.6680
2024-10-30 20:00:22: [2024-10-30 20:00:22] iter = 01840, loss = 2.4848
2024-10-30 20:00:25: [2024-10-30 20:00:25] iter = 01850, loss = 2.1554
2024-10-30 20:00:28: [2024-10-30 20:00:28] iter = 01860, loss = 2.4263
2024-10-30 20:00:32: [2024-10-30 20:00:32] iter = 01870, loss = 2.4059
2024-10-30 20:00:35: [2024-10-30 20:00:35] iter = 01880, loss = 2.9869
2024-10-30 20:00:38: [2024-10-30 20:00:37] iter = 01890, loss = 2.2586
2024-10-30 20:00:41: [2024-10-30 20:00:41] iter = 01900, loss = 6.1539
2024-10-30 20:00:43: [2024-10-30 20:00:43] iter = 01910, loss = 1.8215
2024-10-30 20:00:46: [2024-10-30 20:00:46] iter = 01920, loss = 2.3326
2024-10-30 20:00:49: [2024-10-30 20:00:49] iter = 01930, loss = 2.5356
2024-10-30 20:00:52: [2024-10-30 20:00:52] iter = 01940, loss = 1.9490
2024-10-30 20:00:56: [2024-10-30 20:00:56] iter = 01950, loss = 1.9557
2024-10-30 20:01:00: [2024-10-30 20:01:00] iter = 01960, loss = 2.3029
2024-10-30 20:01:04: [2024-10-30 20:01:04] iter = 01970, loss = 2.5121
2024-10-30 20:01:08: [2024-10-30 20:01:08] iter = 01980, loss = 2.2226
2024-10-30 20:01:10: [2024-10-30 20:01:10] iter = 01990, loss = 2.0000
2024-10-30 20:01:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 20:01:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:01:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 73515}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:03:20: Evaluate 5 random ConvNet, ACCmean = 0.6029 ACCstd = 0.0063
-------------------------
2024-10-30 20:03:20: Evaluate 5 random ConvNet, SENmean = 0.5854 SENstd = 0.0064
-------------------------
2024-10-30 20:03:20: Evaluate 5 random ConvNet, SPEmean = 0.9595 SPEstd = 0.0007
-------------------------
2024-10-30 20:03:20: Evaluate 5 random ConvNet, F!mean = 0.5751 F!std = 0.0058
-------------------------
2024-10-30 20:03:20: Evaluate 5 random ConvNet, mean = 0.6029 std = 0.0063
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:03:20: [2024-10-30 20:03:20] iter = 02000, loss = 3.6812
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:03:23: [2024-10-30 20:03:23] iter = 02010, loss = 2.3447
2024-10-30 20:03:26: [2024-10-30 20:03:26] iter = 02020, loss = 2.1129
2024-10-30 20:03:29: [2024-10-30 20:03:29] iter = 02030, loss = 2.0209
2024-10-30 20:03:32: [2024-10-30 20:03:32] iter = 02040, loss = 1.9793
2024-10-30 20:03:35: [2024-10-30 20:03:35] iter = 02050, loss = 2.2837
2024-10-30 20:03:41: [2024-10-30 20:03:41] iter = 02060, loss = 2.5391
2024-10-30 20:03:45: [2024-10-30 20:03:45] iter = 02070, loss = 2.4418
2024-10-30 20:03:48: [2024-10-30 20:03:48] iter = 02080, loss = 2.6708
2024-10-30 20:03:50: [2024-10-30 20:03:50] iter = 02090, loss = 2.0590
2024-10-30 20:03:53: [2024-10-30 20:03:53] iter = 02100, loss = 2.5250
2024-10-30 20:03:57: [2024-10-30 20:03:57] iter = 02110, loss = 2.2473
2024-10-30 20:04:00: [2024-10-30 20:04:00] iter = 02120, loss = 2.6982
2024-10-30 20:04:03: [2024-10-30 20:04:03] iter = 02130, loss = 2.2413
2024-10-30 20:04:06: [2024-10-30 20:04:06] iter = 02140, loss = 2.2904
2024-10-30 20:04:10: [2024-10-30 20:04:10] iter = 02150, loss = 3.8796
2024-10-30 20:04:14: [2024-10-30 20:04:14] iter = 02160, loss = 1.9539
2024-10-30 20:04:18: [2024-10-30 20:04:18] iter = 02170, loss = 2.3255
2024-10-30 20:04:21: [2024-10-30 20:04:21] iter = 02180, loss = 1.8567
2024-10-30 20:04:24: [2024-10-30 20:04:24] iter = 02190, loss = 2.6118
2024-10-30 20:04:26: [2024-10-30 20:04:26] iter = 02200, loss = 4.9432
2024-10-30 20:04:29: [2024-10-30 20:04:29] iter = 02210, loss = 2.3095
2024-10-30 20:04:32: [2024-10-30 20:04:32] iter = 02220, loss = 1.7627
2024-10-30 20:04:34: [2024-10-30 20:04:34] iter = 02230, loss = 1.8865
2024-10-30 20:04:37: [2024-10-30 20:04:37] iter = 02240, loss = 1.8744
2024-10-30 20:04:41: [2024-10-30 20:04:41] iter = 02250, loss = 2.2401
2024-10-30 20:04:44: [2024-10-30 20:04:44] iter = 02260, loss = 1.9594
2024-10-30 20:04:48: [2024-10-30 20:04:48] iter = 02270, loss = 1.8621
2024-10-30 20:04:52: [2024-10-30 20:04:52] iter = 02280, loss = 2.8858
2024-10-30 20:04:56: [2024-10-30 20:04:56] iter = 02290, loss = 2.2496
2024-10-30 20:04:59: [2024-10-30 20:04:59] iter = 02300, loss = 2.6919
2024-10-30 20:05:01: [2024-10-30 20:05:01] iter = 02310, loss = 2.1166
2024-10-30 20:05:04: [2024-10-30 20:05:04] iter = 02320, loss = 4.0592
2024-10-30 20:05:08: [2024-10-30 20:05:08] iter = 02330, loss = 2.5359
2024-10-30 20:05:11: [2024-10-30 20:05:11] iter = 02340, loss = 2.4880
2024-10-30 20:05:14: [2024-10-30 20:05:14] iter = 02350, loss = 1.8134
2024-10-30 20:05:18: [2024-10-30 20:05:18] iter = 02360, loss = 5.8839
2024-10-30 20:05:21: [2024-10-30 20:05:21] iter = 02370, loss = 2.2686
2024-10-30 20:05:25: [2024-10-30 20:05:25] iter = 02380, loss = 1.9474
2024-10-30 20:05:28: [2024-10-30 20:05:28] iter = 02390, loss = 3.2799
2024-10-30 20:05:31: [2024-10-30 20:05:31] iter = 02400, loss = 2.0766
2024-10-30 20:05:34: [2024-10-30 20:05:34] iter = 02410, loss = 2.1717
2024-10-30 20:05:37: [2024-10-30 20:05:37] iter = 02420, loss = 2.2474
2024-10-30 20:05:41: [2024-10-30 20:05:41] iter = 02430, loss = 3.8128
2024-10-30 20:05:44: [2024-10-30 20:05:44] iter = 02440, loss = 1.9586
2024-10-30 20:05:48: [2024-10-30 20:05:48] iter = 02450, loss = 1.7998
2024-10-30 20:05:51: [2024-10-30 20:05:51] iter = 02460, loss = 2.1453
2024-10-30 20:05:55: [2024-10-30 20:05:55] iter = 02470, loss = 2.4122
2024-10-30 20:05:58: [2024-10-30 20:05:58] iter = 02480, loss = 5.3838
2024-10-30 20:06:01: [2024-10-30 20:06:01] iter = 02490, loss = 2.6400
2024-10-30 20:06:05: [2024-10-30 20:06:05] iter = 02500, loss = 5.0276
2024-10-30 20:06:08: [2024-10-30 20:06:08] iter = 02510, loss = 2.7527
2024-10-30 20:06:12: [2024-10-30 20:06:12] iter = 02520, loss = 2.4515
2024-10-30 20:06:15: [2024-10-30 20:06:15] iter = 02530, loss = 2.2234
2024-10-30 20:06:18: [2024-10-30 20:06:18] iter = 02540, loss = 2.1111
2024-10-30 20:06:21: [2024-10-30 20:06:21] iter = 02550, loss = 2.4738
2024-10-30 20:06:24: [2024-10-30 20:06:24] iter = 02560, loss = 2.3329
2024-10-30 20:06:27: [2024-10-30 20:06:27] iter = 02570, loss = 3.5595
2024-10-30 20:06:30: [2024-10-30 20:06:30] iter = 02580, loss = 2.1212
2024-10-30 20:06:33: [2024-10-30 20:06:33] iter = 02590, loss = 2.7186
2024-10-30 20:06:37: [2024-10-30 20:06:37] iter = 02600, loss = 2.2941
2024-10-30 20:06:40: [2024-10-30 20:06:40] iter = 02610, loss = 1.9511
2024-10-30 20:06:44: [2024-10-30 20:06:44] iter = 02620, loss = 2.2875
2024-10-30 20:06:47: [2024-10-30 20:06:47] iter = 02630, loss = 2.3817
2024-10-30 20:06:51: [2024-10-30 20:06:51] iter = 02640, loss = 1.8188
2024-10-30 20:06:54: [2024-10-30 20:06:54] iter = 02650, loss = 2.1121
2024-10-30 20:06:57: [2024-10-30 20:06:57] iter = 02660, loss = 4.6601
2024-10-30 20:06:59: [2024-10-30 20:06:59] iter = 02670, loss = 2.8272
2024-10-30 20:07:02: [2024-10-30 20:07:02] iter = 02680, loss = 2.1375
2024-10-30 20:07:05: [2024-10-30 20:07:05] iter = 02690, loss = 2.7896
2024-10-30 20:07:07: [2024-10-30 20:07:07] iter = 02700, loss = 1.9452
2024-10-30 20:07:10: [2024-10-30 20:07:10] iter = 02710, loss = 4.3872
2024-10-30 20:07:13: [2024-10-30 20:07:13] iter = 02720, loss = 2.0155
2024-10-30 20:07:16: [2024-10-30 20:07:16] iter = 02730, loss = 2.4198
2024-10-30 20:07:20: [2024-10-30 20:07:20] iter = 02740, loss = 2.2433
2024-10-30 20:07:22: [2024-10-30 20:07:22] iter = 02750, loss = 3.5248
2024-10-30 20:07:25: [2024-10-30 20:07:25] iter = 02760, loss = 2.1550
2024-10-30 20:07:28: [2024-10-30 20:07:28] iter = 02770, loss = 2.3693
2024-10-30 20:07:32: [2024-10-30 20:07:32] iter = 02780, loss = 2.6821
2024-10-30 20:07:36: [2024-10-30 20:07:36] iter = 02790, loss = 2.6883
2024-10-30 20:07:39: [2024-10-30 20:07:39] iter = 02800, loss = 2.3743
2024-10-30 20:07:42: [2024-10-30 20:07:42] iter = 02810, loss = 2.0358
2024-10-30 20:07:46: [2024-10-30 20:07:46] iter = 02820, loss = 2.1339
2024-10-30 20:07:48: [2024-10-30 20:07:48] iter = 02830, loss = 2.0204
2024-10-30 20:07:52: [2024-10-30 20:07:52] iter = 02840, loss = 2.3848
2024-10-30 20:07:56: [2024-10-30 20:07:56] iter = 02850, loss = 2.6185
2024-10-30 20:07:58: [2024-10-30 20:07:58] iter = 02860, loss = 2.4073
2024-10-30 20:08:00: [2024-10-30 20:08:00] iter = 02870, loss = 3.8305
2024-10-30 20:08:03: [2024-10-30 20:08:03] iter = 02880, loss = 2.2737
2024-10-30 20:08:06: [2024-10-30 20:08:06] iter = 02890, loss = 1.9671
2024-10-30 20:08:08: [2024-10-30 20:08:08] iter = 02900, loss = 2.0103
2024-10-30 20:08:12: [2024-10-30 20:08:12] iter = 02910, loss = 2.3793
2024-10-30 20:08:16: [2024-10-30 20:08:16] iter = 02920, loss = 2.4493
2024-10-30 20:08:19: [2024-10-30 20:08:19] iter = 02930, loss = 2.9169
2024-10-30 20:08:22: [2024-10-30 20:08:22] iter = 02940, loss = 2.4827
2024-10-30 20:08:26: [2024-10-30 20:08:26] iter = 02950, loss = 1.9226
2024-10-30 20:08:29: [2024-10-30 20:08:29] iter = 02960, loss = 2.5308
2024-10-30 20:08:32: [2024-10-30 20:08:32] iter = 02970, loss = 2.3907
2024-10-30 20:08:36: [2024-10-30 20:08:36] iter = 02980, loss = 2.8401
2024-10-30 20:08:40: [2024-10-30 20:08:40] iter = 02990, loss = 2.3779
2024-10-30 20:08:43: [2024-10-30 20:08:43] iter = 03000, loss = 2.4726
2024-10-30 20:08:46: [2024-10-30 20:08:46] iter = 03010, loss = 2.4471
2024-10-30 20:08:50: [2024-10-30 20:08:50] iter = 03020, loss = 2.2549
2024-10-30 20:08:53: [2024-10-30 20:08:53] iter = 03030, loss = 2.4645
2024-10-30 20:08:56: [2024-10-30 20:08:56] iter = 03040, loss = 2.1233
2024-10-30 20:08:59: [2024-10-30 20:08:59] iter = 03050, loss = 1.8653
2024-10-30 20:09:03: [2024-10-30 20:09:03] iter = 03060, loss = 2.0540
2024-10-30 20:09:07: [2024-10-30 20:09:07] iter = 03070, loss = 2.0296
2024-10-30 20:09:10: [2024-10-30 20:09:10] iter = 03080, loss = 2.1117
2024-10-30 20:09:14: [2024-10-30 20:09:14] iter = 03090, loss = 1.9431
2024-10-30 20:09:17: [2024-10-30 20:09:17] iter = 03100, loss = 3.7589
2024-10-30 20:09:20: [2024-10-30 20:09:20] iter = 03110, loss = 2.2866
2024-10-30 20:09:23: [2024-10-30 20:09:23] iter = 03120, loss = 2.1763
2024-10-30 20:09:26: [2024-10-30 20:09:26] iter = 03130, loss = 2.1855
2024-10-30 20:09:29: [2024-10-30 20:09:29] iter = 03140, loss = 2.1646
2024-10-30 20:09:32: [2024-10-30 20:09:32] iter = 03150, loss = 2.2966
2024-10-30 20:09:34: [2024-10-30 20:09:34] iter = 03160, loss = 2.9422
2024-10-30 20:09:37: [2024-10-30 20:09:37] iter = 03170, loss = 2.0684
2024-10-30 20:09:40: [2024-10-30 20:09:40] iter = 03180, loss = 2.0587
2024-10-30 20:09:43: [2024-10-30 20:09:43] iter = 03190, loss = 9.6334
2024-10-30 20:09:46: [2024-10-30 20:09:46] iter = 03200, loss = 2.4185
2024-10-30 20:09:50: [2024-10-30 20:09:50] iter = 03210, loss = 1.8097
2024-10-30 20:09:52: [2024-10-30 20:09:52] iter = 03220, loss = 1.9987
2024-10-30 20:09:56: [2024-10-30 20:09:56] iter = 03230, loss = 2.2333
2024-10-30 20:09:59: [2024-10-30 20:09:59] iter = 03240, loss = 2.4119
2024-10-30 20:10:03: [2024-10-30 20:10:03] iter = 03250, loss = 2.4372
2024-10-30 20:10:06: [2024-10-30 20:10:06] iter = 03260, loss = 1.8677
2024-10-30 20:10:09: [2024-10-30 20:10:09] iter = 03270, loss = 2.8303
2024-10-30 20:10:12: [2024-10-30 20:10:12] iter = 03280, loss = 2.5963
2024-10-30 20:10:16: [2024-10-30 20:10:16] iter = 03290, loss = 2.6490
2024-10-30 20:10:18: [2024-10-30 20:10:18] iter = 03300, loss = 2.0485
2024-10-30 20:10:20: [2024-10-30 20:10:20] iter = 03310, loss = 7.0518
2024-10-30 20:10:23: [2024-10-30 20:10:23] iter = 03320, loss = 2.8016
2024-10-30 20:10:26: [2024-10-30 20:10:26] iter = 03330, loss = 3.5201
2024-10-30 20:10:29: [2024-10-30 20:10:29] iter = 03340, loss = 2.6877
2024-10-30 20:10:33: [2024-10-30 20:10:33] iter = 03350, loss = 2.2821
2024-10-30 20:10:36: [2024-10-30 20:10:36] iter = 03360, loss = 2.8389
2024-10-30 20:10:40: [2024-10-30 20:10:40] iter = 03370, loss = 2.0982
2024-10-30 20:10:43: [2024-10-30 20:10:43] iter = 03380, loss = 2.0376
2024-10-30 20:10:47: [2024-10-30 20:10:47] iter = 03390, loss = 2.1799
2024-10-30 20:10:51: [2024-10-30 20:10:51] iter = 03400, loss = 2.6678
2024-10-30 20:10:55: [2024-10-30 20:10:55] iter = 03410, loss = 2.3570
2024-10-30 20:10:58: [2024-10-30 20:10:58] iter = 03420, loss = 2.1376
2024-10-30 20:11:01: [2024-10-30 20:11:01] iter = 03430, loss = 3.0656
2024-10-30 20:11:04: [2024-10-30 20:11:04] iter = 03440, loss = 1.8359
2024-10-30 20:11:08: [2024-10-30 20:11:08] iter = 03450, loss = 2.6064
2024-10-30 20:11:12: [2024-10-30 20:11:12] iter = 03460, loss = 1.6886
2024-10-30 20:11:15: [2024-10-30 20:11:15] iter = 03470, loss = 2.1175
2024-10-30 20:11:18: [2024-10-30 20:11:18] iter = 03480, loss = 2.6919
2024-10-30 20:11:21: [2024-10-30 20:11:21] iter = 03490, loss = 2.0943
2024-10-30 20:11:25: [2024-10-30 20:11:25] iter = 03500, loss = 2.3927
2024-10-30 20:11:28: [2024-10-30 20:11:28] iter = 03510, loss = 4.1205
2024-10-30 20:11:31: [2024-10-30 20:11:31] iter = 03520, loss = 1.8566
2024-10-30 20:11:35: [2024-10-30 20:11:35] iter = 03530, loss = 2.1842
2024-10-30 20:11:39: [2024-10-30 20:11:39] iter = 03540, loss = 2.2831
2024-10-30 20:11:42: [2024-10-30 20:11:42] iter = 03550, loss = 3.0850
2024-10-30 20:11:45: [2024-10-30 20:11:45] iter = 03560, loss = 2.9189
2024-10-30 20:11:49: [2024-10-30 20:11:49] iter = 03570, loss = 1.8918
2024-10-30 20:11:51: [2024-10-30 20:11:51] iter = 03580, loss = 2.2178
2024-10-30 20:11:55: [2024-10-30 20:11:55] iter = 03590, loss = 2.0044
2024-10-30 20:11:58: [2024-10-30 20:11:58] iter = 03600, loss = 2.7217
2024-10-30 20:12:01: [2024-10-30 20:12:01] iter = 03610, loss = 2.1202
2024-10-30 20:12:04: [2024-10-30 20:12:04] iter = 03620, loss = 2.1320
2024-10-30 20:12:07: [2024-10-30 20:12:07] iter = 03630, loss = 1.9582
2024-10-30 20:12:10: [2024-10-30 20:12:10] iter = 03640, loss = 2.2411
2024-10-30 20:12:13: [2024-10-30 20:12:13] iter = 03650, loss = 2.1432
2024-10-30 20:12:18: [2024-10-30 20:12:18] iter = 03660, loss = 2.0170
2024-10-30 20:12:21: [2024-10-30 20:12:21] iter = 03670, loss = 3.1242
2024-10-30 20:12:24: [2024-10-30 20:12:24] iter = 03680, loss = 2.3132
2024-10-30 20:12:26: [2024-10-30 20:12:26] iter = 03690, loss = 1.8547
2024-10-30 20:12:28: [2024-10-30 20:12:28] iter = 03700, loss = 2.0975
2024-10-30 20:12:30: [2024-10-30 20:12:30] iter = 03710, loss = 2.0127
2024-10-30 20:12:32: [2024-10-30 20:12:32] iter = 03720, loss = 2.6360
2024-10-30 20:12:33: [2024-10-30 20:12:33] iter = 03730, loss = 2.7278
2024-10-30 20:12:35: [2024-10-30 20:12:35] iter = 03740, loss = 2.1144
2024-10-30 20:12:37: [2024-10-30 20:12:37] iter = 03750, loss = 2.2497
2024-10-30 20:12:41: [2024-10-30 20:12:41] iter = 03760, loss = 2.0477
2024-10-30 20:12:44: [2024-10-30 20:12:44] iter = 03770, loss = 2.0186
2024-10-30 20:12:47: [2024-10-30 20:12:47] iter = 03780, loss = 1.9934
2024-10-30 20:12:51: [2024-10-30 20:12:51] iter = 03790, loss = 2.2276
2024-10-30 20:12:56: [2024-10-30 20:12:56] iter = 03800, loss = 2.1135
2024-10-30 20:12:59: [2024-10-30 20:12:59] iter = 03810, loss = 2.4633
2024-10-30 20:13:02: [2024-10-30 20:13:02] iter = 03820, loss = 2.2401
2024-10-30 20:13:06: [2024-10-30 20:13:06] iter = 03830, loss = 2.4513
2024-10-30 20:13:08: [2024-10-30 20:13:08] iter = 03840, loss = 2.1178
2024-10-30 20:13:11: [2024-10-30 20:13:11] iter = 03850, loss = 2.0876
2024-10-30 20:13:15: [2024-10-30 20:13:15] iter = 03860, loss = 2.0122
2024-10-30 20:13:18: [2024-10-30 20:13:18] iter = 03870, loss = 1.9740
2024-10-30 20:13:22: [2024-10-30 20:13:22] iter = 03880, loss = 2.5993
2024-10-30 20:13:25: [2024-10-30 20:13:25] iter = 03890, loss = 2.6542
2024-10-30 20:13:28: [2024-10-30 20:13:28] iter = 03900, loss = 1.9881
2024-10-30 20:13:30: [2024-10-30 20:13:30] iter = 03910, loss = 2.3114
2024-10-30 20:13:34: [2024-10-30 20:13:34] iter = 03920, loss = 2.7268
2024-10-30 20:13:37: [2024-10-30 20:13:37] iter = 03930, loss = 2.2575
2024-10-30 20:13:40: [2024-10-30 20:13:40] iter = 03940, loss = 2.0668
2024-10-30 20:13:43: [2024-10-30 20:13:43] iter = 03950, loss = 3.1387
2024-10-30 20:13:46: [2024-10-30 20:13:46] iter = 03960, loss = 1.9637
2024-10-30 20:13:50: [2024-10-30 20:13:50] iter = 03970, loss = 3.2108
2024-10-30 20:13:53: [2024-10-30 20:13:53] iter = 03980, loss = 4.6797
2024-10-30 20:13:56: [2024-10-30 20:13:56] iter = 03990, loss = 1.9696
2024-10-30 20:13:59: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 20:13:59: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:13:59: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 39327}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:16:14: Evaluate 5 random ConvNet, ACCmean = 0.5976 ACCstd = 0.0037
-------------------------
2024-10-30 20:16:14: Evaluate 5 random ConvNet, SENmean = 0.5733 SENstd = 0.0051
-------------------------
2024-10-30 20:16:14: Evaluate 5 random ConvNet, SPEmean = 0.9587 SPEstd = 0.0004
-------------------------
2024-10-30 20:16:14: Evaluate 5 random ConvNet, F!mean = 0.5658 F!std = 0.0048
-------------------------
2024-10-30 20:16:14: Evaluate 5 random ConvNet, mean = 0.5976 std = 0.0037
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:16:15: [2024-10-30 20:16:15] iter = 04000, loss = 3.4676
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:16:18: [2024-10-30 20:16:18] iter = 04010, loss = 2.8796
2024-10-30 20:16:21: [2024-10-30 20:16:21] iter = 04020, loss = 1.9814
2024-10-30 20:16:24: [2024-10-30 20:16:24] iter = 04030, loss = 2.4208
2024-10-30 20:16:28: [2024-10-30 20:16:28] iter = 04040, loss = 2.6465
2024-10-30 20:16:31: [2024-10-30 20:16:31] iter = 04050, loss = 2.5214
2024-10-30 20:16:35: [2024-10-30 20:16:35] iter = 04060, loss = 1.9456
2024-10-30 20:16:38: [2024-10-30 20:16:38] iter = 04070, loss = 3.0990
2024-10-30 20:16:43: [2024-10-30 20:16:43] iter = 04080, loss = 3.0151
2024-10-30 20:16:47: [2024-10-30 20:16:47] iter = 04090, loss = 2.3415
2024-10-30 20:16:51: [2024-10-30 20:16:51] iter = 04100, loss = 3.0012
2024-10-30 20:16:55: [2024-10-30 20:16:55] iter = 04110, loss = 2.2376
2024-10-30 20:16:58: [2024-10-30 20:16:58] iter = 04120, loss = 2.1671
2024-10-30 20:17:03: [2024-10-30 20:17:03] iter = 04130, loss = 2.0722
2024-10-30 20:17:06: [2024-10-30 20:17:06] iter = 04140, loss = 1.9514
2024-10-30 20:17:10: [2024-10-30 20:17:10] iter = 04150, loss = 2.1330
2024-10-30 20:17:12: [2024-10-30 20:17:12] iter = 04160, loss = 3.1957
2024-10-30 20:17:15: [2024-10-30 20:17:15] iter = 04170, loss = 1.9081
2024-10-30 20:17:18: [2024-10-30 20:17:18] iter = 04180, loss = 1.9840
2024-10-30 20:17:21: [2024-10-30 20:17:21] iter = 04190, loss = 2.4253
2024-10-30 20:17:26: [2024-10-30 20:17:26] iter = 04200, loss = 5.1110
2024-10-30 20:17:29: [2024-10-30 20:17:29] iter = 04210, loss = 2.4489
2024-10-30 20:17:31: [2024-10-30 20:17:31] iter = 04220, loss = 2.5026
2024-10-30 20:17:35: [2024-10-30 20:17:35] iter = 04230, loss = 2.2289
2024-10-30 20:17:39: [2024-10-30 20:17:39] iter = 04240, loss = 2.3292
2024-10-30 20:17:43: [2024-10-30 20:17:43] iter = 04250, loss = 2.0086
2024-10-30 20:17:46: [2024-10-30 20:17:46] iter = 04260, loss = 2.7633
2024-10-30 20:17:49: [2024-10-30 20:17:49] iter = 04270, loss = 2.6157
2024-10-30 20:17:54: [2024-10-30 20:17:54] iter = 04280, loss = 1.8407
2024-10-30 20:17:57: [2024-10-30 20:17:57] iter = 04290, loss = 2.3092
2024-10-30 20:18:00: [2024-10-30 20:18:00] iter = 04300, loss = 5.4440
2024-10-30 20:18:03: [2024-10-30 20:18:03] iter = 04310, loss = 2.1694
2024-10-30 20:18:07: [2024-10-30 20:18:07] iter = 04320, loss = 2.9697
2024-10-30 20:18:10: [2024-10-30 20:18:10] iter = 04330, loss = 2.4575
2024-10-30 20:18:13: [2024-10-30 20:18:13] iter = 04340, loss = 2.4321
2024-10-30 20:18:15: [2024-10-30 20:18:15] iter = 04350, loss = 2.1740
2024-10-30 20:18:17: [2024-10-30 20:18:17] iter = 04360, loss = 1.9419
2024-10-30 20:18:21: [2024-10-30 20:18:21] iter = 04370, loss = 6.6221
2024-10-30 20:18:24: [2024-10-30 20:18:24] iter = 04380, loss = 2.2739
2024-10-30 20:18:28: [2024-10-30 20:18:28] iter = 04390, loss = 2.3629
2024-10-30 20:18:32: [2024-10-30 20:18:32] iter = 04400, loss = 2.0786
2024-10-30 20:18:36: [2024-10-30 20:18:36] iter = 04410, loss = 1.7989
2024-10-30 20:18:40: [2024-10-30 20:18:40] iter = 04420, loss = 2.5024
2024-10-30 20:18:43: [2024-10-30 20:18:43] iter = 04430, loss = 2.6393
2024-10-30 20:18:45: [2024-10-30 20:18:45] iter = 04440, loss = 2.3078
2024-10-30 20:18:49: [2024-10-30 20:18:49] iter = 04450, loss = 3.1254
2024-10-30 20:18:52: [2024-10-30 20:18:52] iter = 04460, loss = 2.0545
2024-10-30 20:18:56: [2024-10-30 20:18:56] iter = 04470, loss = 2.9248
2024-10-30 20:18:59: [2024-10-30 20:18:59] iter = 04480, loss = 2.0000
2024-10-30 20:19:02: [2024-10-30 20:19:02] iter = 04490, loss = 1.9702
2024-10-30 20:19:05: [2024-10-30 20:19:05] iter = 04500, loss = 1.9266
2024-10-30 20:19:08: [2024-10-30 20:19:08] iter = 04510, loss = 2.1041
2024-10-30 20:19:11: [2024-10-30 20:19:11] iter = 04520, loss = 2.4920
2024-10-30 20:19:14: [2024-10-30 20:19:14] iter = 04530, loss = 2.3741
2024-10-30 20:19:18: [2024-10-30 20:19:18] iter = 04540, loss = 2.6361
2024-10-30 20:19:21: [2024-10-30 20:19:21] iter = 04550, loss = 2.8689
2024-10-30 20:19:25: [2024-10-30 20:19:25] iter = 04560, loss = 1.9672
2024-10-30 20:19:29: [2024-10-30 20:19:29] iter = 04570, loss = 2.1675
2024-10-30 20:19:34: [2024-10-30 20:19:34] iter = 04580, loss = 2.1850
2024-10-30 20:19:37: [2024-10-30 20:19:37] iter = 04590, loss = 2.4459
2024-10-30 20:19:41: [2024-10-30 20:19:41] iter = 04600, loss = 2.2793
2024-10-30 20:19:46: [2024-10-30 20:19:46] iter = 04610, loss = 1.9076
2024-10-30 20:19:49: [2024-10-30 20:19:49] iter = 04620, loss = 2.2896
2024-10-30 20:19:54: [2024-10-30 20:19:54] iter = 04630, loss = 2.2195
2024-10-30 20:19:58: [2024-10-30 20:19:58] iter = 04640, loss = 2.1708
2024-10-30 20:20:02: [2024-10-30 20:20:02] iter = 04650, loss = 2.2369
2024-10-30 20:20:06: [2024-10-30 20:20:06] iter = 04660, loss = 2.2254
2024-10-30 20:20:10: [2024-10-30 20:20:10] iter = 04670, loss = 2.5376
2024-10-30 20:20:13: [2024-10-30 20:20:13] iter = 04680, loss = 1.7785
2024-10-30 20:20:18: [2024-10-30 20:20:18] iter = 04690, loss = 2.4643
2024-10-30 20:20:22: [2024-10-30 20:20:22] iter = 04700, loss = 1.9951
2024-10-30 20:20:27: [2024-10-30 20:20:27] iter = 04710, loss = 3.2931
2024-10-30 20:20:31: [2024-10-30 20:20:31] iter = 04720, loss = 2.2948
2024-10-30 20:20:36: [2024-10-30 20:20:36] iter = 04730, loss = 2.0906
2024-10-30 20:20:41: [2024-10-30 20:20:41] iter = 04740, loss = 1.9065
2024-10-30 20:20:45: [2024-10-30 20:20:45] iter = 04750, loss = 3.2961
2024-10-30 20:20:50: [2024-10-30 20:20:50] iter = 04760, loss = 3.1015
2024-10-30 20:20:54: [2024-10-30 20:20:54] iter = 04770, loss = 2.1125
2024-10-30 20:20:58: [2024-10-30 20:20:58] iter = 04780, loss = 2.5165
2024-10-30 20:21:01: [2024-10-30 20:21:01] iter = 04790, loss = 2.5547
2024-10-30 20:21:07: [2024-10-30 20:21:07] iter = 04800, loss = 2.2401
2024-10-30 20:21:11: [2024-10-30 20:21:11] iter = 04810, loss = 2.0155
2024-10-30 20:21:17: [2024-10-30 20:21:17] iter = 04820, loss = 3.4084
2024-10-30 20:21:21: [2024-10-30 20:21:21] iter = 04830, loss = 2.1606
2024-10-30 20:21:25: [2024-10-30 20:21:25] iter = 04840, loss = 2.7614
2024-10-30 20:21:29: [2024-10-30 20:21:29] iter = 04850, loss = 2.3321
2024-10-30 20:21:34: [2024-10-30 20:21:34] iter = 04860, loss = 2.3002
2024-10-30 20:21:39: [2024-10-30 20:21:39] iter = 04870, loss = 1.9367
2024-10-30 20:21:43: [2024-10-30 20:21:43] iter = 04880, loss = 3.8691
2024-10-30 20:21:47: [2024-10-30 20:21:47] iter = 04890, loss = 2.3441
2024-10-30 20:21:52: [2024-10-30 20:21:52] iter = 04900, loss = 2.1558
2024-10-30 20:21:56: [2024-10-30 20:21:56] iter = 04910, loss = 5.7329
2024-10-30 20:22:01: [2024-10-30 20:22:01] iter = 04920, loss = 2.2810
2024-10-30 20:22:05: [2024-10-30 20:22:05] iter = 04930, loss = 2.2438
2024-10-30 20:22:09: [2024-10-30 20:22:09] iter = 04940, loss = 1.9264
2024-10-30 20:22:14: [2024-10-30 20:22:14] iter = 04950, loss = 2.8530
2024-10-30 20:22:18: [2024-10-30 20:22:18] iter = 04960, loss = 2.1137
2024-10-30 20:22:23: [2024-10-30 20:22:23] iter = 04970, loss = 2.0812
2024-10-30 20:22:26: [2024-10-30 20:22:26] iter = 04980, loss = 2.6402
2024-10-30 20:22:33: [2024-10-30 20:22:33] iter = 04990, loss = 1.9929
2024-10-30 20:22:38: [2024-10-30 20:22:38] iter = 05000, loss = 3.0705
2024-10-30 20:22:42: [2024-10-30 20:22:42] iter = 05010, loss = 3.5784
2024-10-30 20:22:47: [2024-10-30 20:22:47] iter = 05020, loss = 2.2547
2024-10-30 20:22:51: [2024-10-30 20:22:51] iter = 05030, loss = 2.1178
2024-10-30 20:22:55: [2024-10-30 20:22:55] iter = 05040, loss = 2.5835
2024-10-30 20:22:59: [2024-10-30 20:22:59] iter = 05050, loss = 2.1893
2024-10-30 20:23:03: [2024-10-30 20:23:03] iter = 05060, loss = 3.3934
2024-10-30 20:23:08: [2024-10-30 20:23:08] iter = 05070, loss = 4.3970
2024-10-30 20:23:13: [2024-10-30 20:23:13] iter = 05080, loss = 2.0257
2024-10-30 20:23:18: [2024-10-30 20:23:18] iter = 05090, loss = 2.8208
2024-10-30 20:23:22: [2024-10-30 20:23:22] iter = 05100, loss = 2.1773
2024-10-30 20:23:26: [2024-10-30 20:23:26] iter = 05110, loss = 1.9625
2024-10-30 20:23:31: [2024-10-30 20:23:31] iter = 05120, loss = 2.3744
2024-10-30 20:23:37: [2024-10-30 20:23:37] iter = 05130, loss = 1.7523
2024-10-30 20:23:41: [2024-10-30 20:23:41] iter = 05140, loss = 2.4921
2024-10-30 20:23:45: [2024-10-30 20:23:45] iter = 05150, loss = 2.1681
2024-10-30 20:23:49: [2024-10-30 20:23:49] iter = 05160, loss = 2.1612
2024-10-30 20:23:55: [2024-10-30 20:23:55] iter = 05170, loss = 2.1904
2024-10-30 20:23:59: [2024-10-30 20:23:59] iter = 05180, loss = 1.8051
2024-10-30 20:24:04: [2024-10-30 20:24:04] iter = 05190, loss = 2.3852
2024-10-30 20:24:08: [2024-10-30 20:24:08] iter = 05200, loss = 2.1296
2024-10-30 20:24:13: [2024-10-30 20:24:13] iter = 05210, loss = 2.6000
2024-10-30 20:24:17: [2024-10-30 20:24:17] iter = 05220, loss = 1.9015
2024-10-30 20:24:22: [2024-10-30 20:24:22] iter = 05230, loss = 1.9146
2024-10-30 20:24:26: [2024-10-30 20:24:26] iter = 05240, loss = 2.2396
2024-10-30 20:24:31: [2024-10-30 20:24:31] iter = 05250, loss = 2.1967
2024-10-30 20:24:34: [2024-10-30 20:24:34] iter = 05260, loss = 2.6060
2024-10-30 20:24:39: [2024-10-30 20:24:39] iter = 05270, loss = 3.1625
2024-10-30 20:24:44: [2024-10-30 20:24:44] iter = 05280, loss = 4.0959
2024-10-30 20:24:48: [2024-10-30 20:24:48] iter = 05290, loss = 2.3870
2024-10-30 20:24:53: [2024-10-30 20:24:53] iter = 05300, loss = 2.2528
2024-10-30 20:24:57: [2024-10-30 20:24:57] iter = 05310, loss = 2.2244
2024-10-30 20:25:03: [2024-10-30 20:25:03] iter = 05320, loss = 2.2530
2024-10-30 20:25:07: [2024-10-30 20:25:07] iter = 05330, loss = 2.0998
2024-10-30 20:25:11: [2024-10-30 20:25:11] iter = 05340, loss = 2.5604
2024-10-30 20:25:16: [2024-10-30 20:25:16] iter = 05350, loss = 2.3133
2024-10-30 20:25:19: [2024-10-30 20:25:19] iter = 05360, loss = 1.9524
2024-10-30 20:25:24: [2024-10-30 20:25:24] iter = 05370, loss = 3.1772
2024-10-30 20:25:29: [2024-10-30 20:25:29] iter = 05380, loss = 3.1811
2024-10-30 20:25:33: [2024-10-30 20:25:33] iter = 05390, loss = 2.0606
2024-10-30 20:25:36: [2024-10-30 20:25:36] iter = 05400, loss = 1.9966
2024-10-30 20:25:40: [2024-10-30 20:25:40] iter = 05410, loss = 2.3310
2024-10-30 20:25:45: [2024-10-30 20:25:45] iter = 05420, loss = 2.4415
2024-10-30 20:25:48: [2024-10-30 20:25:48] iter = 05430, loss = 2.8944
2024-10-30 20:25:53: [2024-10-30 20:25:53] iter = 05440, loss = 1.9059
2024-10-30 20:25:58: [2024-10-30 20:25:58] iter = 05450, loss = 5.0491
2024-10-30 20:26:02: [2024-10-30 20:26:02] iter = 05460, loss = 2.1753
2024-10-30 20:26:07: [2024-10-30 20:26:07] iter = 05470, loss = 2.0800
2024-10-30 20:26:12: [2024-10-30 20:26:12] iter = 05480, loss = 2.1209
2024-10-30 20:26:16: [2024-10-30 20:26:16] iter = 05490, loss = 2.1670
2024-10-30 20:26:22: [2024-10-30 20:26:22] iter = 05500, loss = 2.0186
2024-10-30 20:26:27: [2024-10-30 20:26:27] iter = 05510, loss = 3.4276
2024-10-30 20:26:31: [2024-10-30 20:26:31] iter = 05520, loss = 2.7782
2024-10-30 20:26:36: [2024-10-30 20:26:36] iter = 05530, loss = 1.8281
2024-10-30 20:26:41: [2024-10-30 20:26:41] iter = 05540, loss = 1.9565
2024-10-30 20:26:44: [2024-10-30 20:26:44] iter = 05550, loss = 1.9858
2024-10-30 20:26:48: [2024-10-30 20:26:48] iter = 05560, loss = 2.6430
2024-10-30 20:26:51: [2024-10-30 20:26:51] iter = 05570, loss = 1.9070
2024-10-30 20:26:55: [2024-10-30 20:26:55] iter = 05580, loss = 2.7358
2024-10-30 20:27:00: [2024-10-30 20:27:00] iter = 05590, loss = 2.4236
2024-10-30 20:27:05: [2024-10-30 20:27:05] iter = 05600, loss = 2.2132
2024-10-30 20:27:09: [2024-10-30 20:27:09] iter = 05610, loss = 1.9520
2024-10-30 20:27:13: [2024-10-30 20:27:13] iter = 05620, loss = 3.2128
2024-10-30 20:27:17: [2024-10-30 20:27:17] iter = 05630, loss = 2.2884
2024-10-30 20:27:22: [2024-10-30 20:27:22] iter = 05640, loss = 2.6015
2024-10-30 20:27:26: [2024-10-30 20:27:26] iter = 05650, loss = 1.8768
2024-10-30 20:27:31: [2024-10-30 20:27:31] iter = 05660, loss = 4.1356
2024-10-30 20:27:35: [2024-10-30 20:27:35] iter = 05670, loss = 1.8107
2024-10-30 20:27:39: [2024-10-30 20:27:39] iter = 05680, loss = 1.9033
2024-10-30 20:27:44: [2024-10-30 20:27:44] iter = 05690, loss = 2.2587
2024-10-30 20:27:50: [2024-10-30 20:27:50] iter = 05700, loss = 2.9905
2024-10-30 20:27:53: [2024-10-30 20:27:53] iter = 05710, loss = 2.3870
2024-10-30 20:27:57: [2024-10-30 20:27:57] iter = 05720, loss = 2.0976
2024-10-30 20:28:02: [2024-10-30 20:28:02] iter = 05730, loss = 2.0105
2024-10-30 20:28:07: [2024-10-30 20:28:07] iter = 05740, loss = 3.3929
2024-10-30 20:28:10: [2024-10-30 20:28:10] iter = 05750, loss = 2.1430
2024-10-30 20:28:16: [2024-10-30 20:28:16] iter = 05760, loss = 2.1286
2024-10-30 20:28:19: [2024-10-30 20:28:19] iter = 05770, loss = 2.0596
2024-10-30 20:28:24: [2024-10-30 20:28:24] iter = 05780, loss = 2.1481
2024-10-30 20:28:28: [2024-10-30 20:28:28] iter = 05790, loss = 1.9475
2024-10-30 20:28:33: [2024-10-30 20:28:33] iter = 05800, loss = 2.1407
2024-10-30 20:28:37: [2024-10-30 20:28:37] iter = 05810, loss = 1.8071
2024-10-30 20:28:42: [2024-10-30 20:28:42] iter = 05820, loss = 1.8790
2024-10-30 20:28:46: [2024-10-30 20:28:46] iter = 05830, loss = 2.1041
2024-10-30 20:28:51: [2024-10-30 20:28:51] iter = 05840, loss = 2.5373
2024-10-30 20:28:55: [2024-10-30 20:28:55] iter = 05850, loss = 2.2071
2024-10-30 20:28:59: [2024-10-30 20:28:59] iter = 05860, loss = 2.5107
2024-10-30 20:29:03: [2024-10-30 20:29:03] iter = 05870, loss = 1.6334
2024-10-30 20:29:07: [2024-10-30 20:29:07] iter = 05880, loss = 2.2868
2024-10-30 20:29:11: [2024-10-30 20:29:11] iter = 05890, loss = 2.1042
2024-10-30 20:29:16: [2024-10-30 20:29:16] iter = 05900, loss = 2.0143
2024-10-30 20:29:21: [2024-10-30 20:29:21] iter = 05910, loss = 3.1133
2024-10-30 20:29:25: [2024-10-30 20:29:25] iter = 05920, loss = 1.7538
2024-10-30 20:29:30: [2024-10-30 20:29:30] iter = 05930, loss = 2.5674
2024-10-30 20:29:34: [2024-10-30 20:29:34] iter = 05940, loss = 2.2391
2024-10-30 20:29:38: [2024-10-30 20:29:38] iter = 05950, loss = 2.0091
2024-10-30 20:29:42: [2024-10-30 20:29:42] iter = 05960, loss = 3.1075
2024-10-30 20:29:46: [2024-10-30 20:29:46] iter = 05970, loss = 3.1351
2024-10-30 20:29:50: [2024-10-30 20:29:50] iter = 05980, loss = 2.5190
2024-10-30 20:29:55: [2024-10-30 20:29:55] iter = 05990, loss = 3.1717
2024-10-30 20:29:59: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 20:29:59: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:29:59: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 99546}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:32:48: Evaluate 5 random ConvNet, ACCmean = 0.6003 ACCstd = 0.0029
-------------------------
2024-10-30 20:32:48: Evaluate 5 random ConvNet, SENmean = 0.5847 SENstd = 0.0037
-------------------------
2024-10-30 20:32:48: Evaluate 5 random ConvNet, SPEmean = 0.9592 SPEstd = 0.0003
-------------------------
2024-10-30 20:32:48: Evaluate 5 random ConvNet, F!mean = 0.5783 F!std = 0.0027
-------------------------
2024-10-30 20:32:48: Evaluate 5 random ConvNet, mean = 0.6003 std = 0.0029
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:32:49: [2024-10-30 20:32:49] iter = 06000, loss = 2.2904
2024-10-30 20:32:54: [2024-10-30 20:32:54] iter = 06010, loss = 2.1348
2024-10-30 20:32:59: [2024-10-30 20:32:59] iter = 06020, loss = 2.8297
2024-10-30 20:33:03: [2024-10-30 20:33:03] iter = 06030, loss = 2.5003
2024-10-30 20:33:07: [2024-10-30 20:33:07] iter = 06040, loss = 2.1850
2024-10-30 20:33:11: [2024-10-30 20:33:11] iter = 06050, loss = 2.8622
2024-10-30 20:33:16: [2024-10-30 20:33:16] iter = 06060, loss = 2.4587
2024-10-30 20:33:20: [2024-10-30 20:33:20] iter = 06070, loss = 2.1320
2024-10-30 20:33:25: [2024-10-30 20:33:25] iter = 06080, loss = 3.7109
2024-10-30 20:33:30: [2024-10-30 20:33:30] iter = 06090, loss = 2.3249
2024-10-30 20:33:34: [2024-10-30 20:33:34] iter = 06100, loss = 1.9992
2024-10-30 20:33:39: [2024-10-30 20:33:39] iter = 06110, loss = 2.2063
2024-10-30 20:33:44: [2024-10-30 20:33:44] iter = 06120, loss = 2.0554
2024-10-30 20:33:48: [2024-10-30 20:33:48] iter = 06130, loss = 2.2222
2024-10-30 20:33:52: [2024-10-30 20:33:52] iter = 06140, loss = 2.8222
2024-10-30 20:33:56: [2024-10-30 20:33:56] iter = 06150, loss = 2.5651
2024-10-30 20:34:02: [2024-10-30 20:34:02] iter = 06160, loss = 2.1930
2024-10-30 20:34:07: [2024-10-30 20:34:07] iter = 06170, loss = 1.8701
2024-10-30 20:34:11: [2024-10-30 20:34:11] iter = 06180, loss = 3.0067
2024-10-30 20:34:16: [2024-10-30 20:34:16] iter = 06190, loss = 5.7330
2024-10-30 20:34:21: [2024-10-30 20:34:21] iter = 06200, loss = 2.0941
2024-10-30 20:34:26: [2024-10-30 20:34:26] iter = 06210, loss = 1.9595
2024-10-30 20:34:31: [2024-10-30 20:34:31] iter = 06220, loss = 2.2535
2024-10-30 20:34:36: [2024-10-30 20:34:36] iter = 06230, loss = 2.1506
2024-10-30 20:34:40: [2024-10-30 20:34:40] iter = 06240, loss = 6.0066
2024-10-30 20:34:45: [2024-10-30 20:34:45] iter = 06250, loss = 1.9631
2024-10-30 20:34:50: [2024-10-30 20:34:50] iter = 06260, loss = 2.0697
2024-10-30 20:34:55: [2024-10-30 20:34:55] iter = 06270, loss = 2.2267
2024-10-30 20:34:59: [2024-10-30 20:34:59] iter = 06280, loss = 1.7458
2024-10-30 20:35:04: [2024-10-30 20:35:04] iter = 06290, loss = 2.2629
2024-10-30 20:35:09: [2024-10-30 20:35:09] iter = 06300, loss = 2.3452
2024-10-30 20:35:14: [2024-10-30 20:35:14] iter = 06310, loss = 2.5280
2024-10-30 20:35:18: [2024-10-30 20:35:18] iter = 06320, loss = 2.4725
2024-10-30 20:35:23: [2024-10-30 20:35:23] iter = 06330, loss = 2.4832
2024-10-30 20:35:27: [2024-10-30 20:35:27] iter = 06340, loss = 1.7653
2024-10-30 20:35:31: [2024-10-30 20:35:31] iter = 06350, loss = 4.6596
2024-10-30 20:35:35: [2024-10-30 20:35:35] iter = 06360, loss = 3.0072
2024-10-30 20:35:39: [2024-10-30 20:35:39] iter = 06370, loss = 2.7808
2024-10-30 20:35:43: [2024-10-30 20:35:43] iter = 06380, loss = 2.4310
2024-10-30 20:35:47: [2024-10-30 20:35:47] iter = 06390, loss = 1.8918
2024-10-30 20:35:51: [2024-10-30 20:35:51] iter = 06400, loss = 2.4978
2024-10-30 20:35:56: [2024-10-30 20:35:56] iter = 06410, loss = 2.3222
2024-10-30 20:36:00: [2024-10-30 20:36:00] iter = 06420, loss = 2.1347
2024-10-30 20:36:04: [2024-10-30 20:36:04] iter = 06430, loss = 2.0471
2024-10-30 20:36:09: [2024-10-30 20:36:09] iter = 06440, loss = 2.1421
2024-10-30 20:36:12: [2024-10-30 20:36:12] iter = 06450, loss = 2.5084
2024-10-30 20:36:16: [2024-10-30 20:36:16] iter = 06460, loss = 2.3385
2024-10-30 20:36:20: [2024-10-30 20:36:20] iter = 06470, loss = 3.3983
2024-10-30 20:36:25: [2024-10-30 20:36:25] iter = 06480, loss = 3.1799
2024-10-30 20:36:29: [2024-10-30 20:36:29] iter = 06490, loss = 1.9972
2024-10-30 20:36:33: [2024-10-30 20:36:33] iter = 06500, loss = 2.3638
2024-10-30 20:36:38: [2024-10-30 20:36:38] iter = 06510, loss = 2.4183
2024-10-30 20:36:42: [2024-10-30 20:36:42] iter = 06520, loss = 1.9556
2024-10-30 20:36:47: [2024-10-30 20:36:47] iter = 06530, loss = 2.4118
2024-10-30 20:36:51: [2024-10-30 20:36:51] iter = 06540, loss = 1.7384
2024-10-30 20:36:55: [2024-10-30 20:36:55] iter = 06550, loss = 2.1233
2024-10-30 20:36:58: [2024-10-30 20:36:58] iter = 06560, loss = 4.9191
2024-10-30 20:37:02: [2024-10-30 20:37:02] iter = 06570, loss = 2.4613
2024-10-30 20:37:06: [2024-10-30 20:37:06] iter = 06580, loss = 2.1656
2024-10-30 20:37:10: [2024-10-30 20:37:10] iter = 06590, loss = 1.9333
2024-10-30 20:37:13: [2024-10-30 20:37:13] iter = 06600, loss = 2.6698
2024-10-30 20:37:17: [2024-10-30 20:37:17] iter = 06610, loss = 1.7554
2024-10-30 20:37:20: [2024-10-30 20:37:20] iter = 06620, loss = 2.4536
2024-10-30 20:37:24: [2024-10-30 20:37:24] iter = 06630, loss = 2.1957
2024-10-30 20:37:28: [2024-10-30 20:37:28] iter = 06640, loss = 2.0706
2024-10-30 20:37:31: [2024-10-30 20:37:31] iter = 06650, loss = 2.5604
2024-10-30 20:37:35: [2024-10-30 20:37:35] iter = 06660, loss = 2.1268
2024-10-30 20:37:39: [2024-10-30 20:37:39] iter = 06670, loss = 2.4189
2024-10-30 20:37:43: [2024-10-30 20:37:43] iter = 06680, loss = 2.1768
2024-10-30 20:37:46: [2024-10-30 20:37:46] iter = 06690, loss = 2.6820
2024-10-30 20:37:50: [2024-10-30 20:37:50] iter = 06700, loss = 2.6501
2024-10-30 20:37:55: [2024-10-30 20:37:55] iter = 06710, loss = 2.3807
2024-10-30 20:37:58: [2024-10-30 20:37:58] iter = 06720, loss = 2.6073
2024-10-30 20:38:01: [2024-10-30 20:38:01] iter = 06730, loss = 1.9846
2024-10-30 20:38:04: [2024-10-30 20:38:04] iter = 06740, loss = 1.8690
2024-10-30 20:38:07: [2024-10-30 20:38:07] iter = 06750, loss = 2.3277
2024-10-30 20:38:10: [2024-10-30 20:38:10] iter = 06760, loss = 2.2479
2024-10-30 20:38:14: [2024-10-30 20:38:14] iter = 06770, loss = 2.0209
2024-10-30 20:38:18: [2024-10-30 20:38:18] iter = 06780, loss = 1.8767
2024-10-30 20:38:22: [2024-10-30 20:38:22] iter = 06790, loss = 1.7481
2024-10-30 20:38:25: [2024-10-30 20:38:25] iter = 06800, loss = 2.6138
2024-10-30 20:38:29: [2024-10-30 20:38:29] iter = 06810, loss = 2.2143
2024-10-30 20:38:32: [2024-10-30 20:38:32] iter = 06820, loss = 2.4685
2024-10-30 20:38:35: [2024-10-30 20:38:35] iter = 06830, loss = 2.4185
2024-10-30 20:38:39: [2024-10-30 20:38:39] iter = 06840, loss = 1.9301
2024-10-30 20:38:43: [2024-10-30 20:38:43] iter = 06850, loss = 3.3506
2024-10-30 20:38:47: [2024-10-30 20:38:47] iter = 06860, loss = 2.0455
2024-10-30 20:38:51: [2024-10-30 20:38:51] iter = 06870, loss = 1.7885
2024-10-30 20:38:56: [2024-10-30 20:38:56] iter = 06880, loss = 2.8892
2024-10-30 20:38:59: [2024-10-30 20:38:59] iter = 06890, loss = 2.1055
2024-10-30 20:39:03: [2024-10-30 20:39:03] iter = 06900, loss = 2.6119
2024-10-30 20:39:07: [2024-10-30 20:39:07] iter = 06910, loss = 2.0905
2024-10-30 20:39:11: [2024-10-30 20:39:11] iter = 06920, loss = 2.1441
2024-10-30 20:39:15: [2024-10-30 20:39:15] iter = 06930, loss = 2.1165
2024-10-30 20:39:19: [2024-10-30 20:39:19] iter = 06940, loss = 2.3383
2024-10-30 20:39:23: [2024-10-30 20:39:23] iter = 06950, loss = 2.9406
2024-10-30 20:39:27: [2024-10-30 20:39:27] iter = 06960, loss = 1.9909
2024-10-30 20:39:30: [2024-10-30 20:39:30] iter = 06970, loss = 3.2987
2024-10-30 20:39:34: [2024-10-30 20:39:34] iter = 06980, loss = 3.1361
2024-10-30 20:39:38: [2024-10-30 20:39:38] iter = 06990, loss = 2.2266
2024-10-30 20:39:42: [2024-10-30 20:39:42] iter = 07000, loss = 2.1484
2024-10-30 20:39:46: [2024-10-30 20:39:46] iter = 07010, loss = 2.0620
2024-10-30 20:39:50: [2024-10-30 20:39:50] iter = 07020, loss = 1.8303
2024-10-30 20:39:55: [2024-10-30 20:39:55] iter = 07030, loss = 1.6471
2024-10-30 20:39:59: [2024-10-30 20:39:59] iter = 07040, loss = 2.7038
2024-10-30 20:40:03: [2024-10-30 20:40:03] iter = 07050, loss = 2.9202
2024-10-30 20:40:07: [2024-10-30 20:40:07] iter = 07060, loss = 3.0561
2024-10-30 20:40:10: [2024-10-30 20:40:10] iter = 07070, loss = 2.2104
2024-10-30 20:40:15: [2024-10-30 20:40:15] iter = 07080, loss = 2.4600
2024-10-30 20:40:18: [2024-10-30 20:40:18] iter = 07090, loss = 2.2225
2024-10-30 20:40:22: [2024-10-30 20:40:22] iter = 07100, loss = 2.1017
2024-10-30 20:40:25: [2024-10-30 20:40:25] iter = 07110, loss = 2.5465
2024-10-30 20:40:29: [2024-10-30 20:40:29] iter = 07120, loss = 2.8947
2024-10-30 20:40:33: [2024-10-30 20:40:33] iter = 07130, loss = 2.8578
2024-10-30 20:40:36: [2024-10-30 20:40:36] iter = 07140, loss = 1.7384
2024-10-30 20:40:41: [2024-10-30 20:40:41] iter = 07150, loss = 2.0857
2024-10-30 20:40:44: [2024-10-30 20:40:44] iter = 07160, loss = 2.6265
2024-10-30 20:40:48: [2024-10-30 20:40:48] iter = 07170, loss = 3.0706
2024-10-30 20:40:51: [2024-10-30 20:40:51] iter = 07180, loss = 2.1576
2024-10-30 20:40:55: [2024-10-30 20:40:55] iter = 07190, loss = 2.4457
2024-10-30 20:41:00: [2024-10-30 20:41:00] iter = 07200, loss = 3.2413
2024-10-30 20:41:04: [2024-10-30 20:41:04] iter = 07210, loss = 2.1222
2024-10-30 20:41:08: [2024-10-30 20:41:08] iter = 07220, loss = 1.9816
2024-10-30 20:41:12: [2024-10-30 20:41:12] iter = 07230, loss = 2.1752
2024-10-30 20:41:16: [2024-10-30 20:41:16] iter = 07240, loss = 2.9888
2024-10-30 20:41:19: [2024-10-30 20:41:19] iter = 07250, loss = 2.0349
2024-10-30 20:41:22: [2024-10-30 20:41:22] iter = 07260, loss = 2.0953
2024-10-30 20:41:26: [2024-10-30 20:41:26] iter = 07270, loss = 2.0561
2024-10-30 20:41:30: [2024-10-30 20:41:30] iter = 07280, loss = 2.1899
2024-10-30 20:41:34: [2024-10-30 20:41:34] iter = 07290, loss = 3.0466
2024-10-30 20:41:38: [2024-10-30 20:41:38] iter = 07300, loss = 2.6674
2024-10-30 20:41:41: [2024-10-30 20:41:41] iter = 07310, loss = 2.6963
2024-10-30 20:41:44: [2024-10-30 20:41:44] iter = 07320, loss = 1.9672
2024-10-30 20:41:48: [2024-10-30 20:41:48] iter = 07330, loss = 2.0647
2024-10-30 20:41:51: [2024-10-30 20:41:51] iter = 07340, loss = 2.4816
2024-10-30 20:41:55: [2024-10-30 20:41:55] iter = 07350, loss = 1.9038
2024-10-30 20:42:00: [2024-10-30 20:42:00] iter = 07360, loss = 2.3559
2024-10-30 20:42:04: [2024-10-30 20:42:04] iter = 07370, loss = 2.2800
2024-10-30 20:42:08: [2024-10-30 20:42:08] iter = 07380, loss = 1.9819
2024-10-30 20:42:12: [2024-10-30 20:42:12] iter = 07390, loss = 1.9438
2024-10-30 20:42:15: [2024-10-30 20:42:15] iter = 07400, loss = 2.6141
2024-10-30 20:42:19: [2024-10-30 20:42:19] iter = 07410, loss = 2.0759
2024-10-30 20:42:23: [2024-10-30 20:42:23] iter = 07420, loss = 2.5361
2024-10-30 20:42:26: [2024-10-30 20:42:26] iter = 07430, loss = 3.1202
2024-10-30 20:42:30: [2024-10-30 20:42:30] iter = 07440, loss = 4.4955
2024-10-30 20:42:34: [2024-10-30 20:42:34] iter = 07450, loss = 2.3517
2024-10-30 20:42:40: [2024-10-30 20:42:40] iter = 07460, loss = 2.6670
2024-10-30 20:42:45: [2024-10-30 20:42:45] iter = 07470, loss = 2.2026
2024-10-30 20:42:49: [2024-10-30 20:42:49] iter = 07480, loss = 1.9761
2024-10-30 20:42:53: [2024-10-30 20:42:53] iter = 07490, loss = 2.3914
2024-10-30 20:42:58: [2024-10-30 20:42:58] iter = 07500, loss = 2.0901
2024-10-30 20:43:02: [2024-10-30 20:43:02] iter = 07510, loss = 4.1374
2024-10-30 20:43:06: [2024-10-30 20:43:06] iter = 07520, loss = 2.8170
2024-10-30 20:43:09: [2024-10-30 20:43:09] iter = 07530, loss = 2.7842
2024-10-30 20:43:12: [2024-10-30 20:43:12] iter = 07540, loss = 1.9860
2024-10-30 20:43:17: [2024-10-30 20:43:17] iter = 07550, loss = 2.0523
2024-10-30 20:43:21: [2024-10-30 20:43:21] iter = 07560, loss = 1.9621
2024-10-30 20:43:25: [2024-10-30 20:43:25] iter = 07570, loss = 2.5996
2024-10-30 20:43:28: [2024-10-30 20:43:28] iter = 07580, loss = 2.5640
2024-10-30 20:43:30: [2024-10-30 20:43:30] iter = 07590, loss = 2.2591
2024-10-30 20:43:34: [2024-10-30 20:43:34] iter = 07600, loss = 4.1526
2024-10-30 20:43:37: [2024-10-30 20:43:37] iter = 07610, loss = 2.5790
2024-10-30 20:43:41: [2024-10-30 20:43:41] iter = 07620, loss = 2.2582
2024-10-30 20:43:45: [2024-10-30 20:43:45] iter = 07630, loss = 2.3489
2024-10-30 20:43:48: [2024-10-30 20:43:48] iter = 07640, loss = 2.2570
2024-10-30 20:43:52: [2024-10-30 20:43:52] iter = 07650, loss = 2.0349
2024-10-30 20:43:56: [2024-10-30 20:43:56] iter = 07660, loss = 2.2811
2024-10-30 20:44:00: [2024-10-30 20:44:00] iter = 07670, loss = 2.2703
2024-10-30 20:44:05: [2024-10-30 20:44:05] iter = 07680, loss = 2.1570
2024-10-30 20:44:09: [2024-10-30 20:44:09] iter = 07690, loss = 4.0167
2024-10-30 20:44:13: [2024-10-30 20:44:13] iter = 07700, loss = 2.2476
2024-10-30 20:44:17: [2024-10-30 20:44:17] iter = 07710, loss = 2.7013
2024-10-30 20:44:22: [2024-10-30 20:44:22] iter = 07720, loss = 1.9404
2024-10-30 20:44:26: [2024-10-30 20:44:26] iter = 07730, loss = 2.3122
2024-10-30 20:44:30: [2024-10-30 20:44:30] iter = 07740, loss = 2.0510
2024-10-30 20:44:34: [2024-10-30 20:44:34] iter = 07750, loss = 2.7236
2024-10-30 20:44:38: [2024-10-30 20:44:38] iter = 07760, loss = 2.0740
2024-10-30 20:44:40: [2024-10-30 20:44:40] iter = 07770, loss = 1.8360
2024-10-30 20:44:45: [2024-10-30 20:44:45] iter = 07780, loss = 2.3381
2024-10-30 20:44:49: [2024-10-30 20:44:49] iter = 07790, loss = 1.5935
2024-10-30 20:44:53: [2024-10-30 20:44:53] iter = 07800, loss = 1.9925
2024-10-30 20:44:57: [2024-10-30 20:44:57] iter = 07810, loss = 2.5449
2024-10-30 20:45:01: [2024-10-30 20:45:01] iter = 07820, loss = 3.2310
2024-10-30 20:45:05: [2024-10-30 20:45:05] iter = 07830, loss = 2.3557
2024-10-30 20:45:07: [2024-10-30 20:45:07] iter = 07840, loss = 1.9763
2024-10-30 20:45:11: [2024-10-30 20:45:11] iter = 07850, loss = 1.9034
2024-10-30 20:45:15: [2024-10-30 20:45:15] iter = 07860, loss = 2.3414
2024-10-30 20:45:20: [2024-10-30 20:45:20] iter = 07870, loss = 2.4541
2024-10-30 20:45:23: [2024-10-30 20:45:23] iter = 07880, loss = 2.1761
2024-10-30 20:45:27: [2024-10-30 20:45:27] iter = 07890, loss = 1.8861
2024-10-30 20:45:31: [2024-10-30 20:45:31] iter = 07900, loss = 2.0089
2024-10-30 20:45:35: [2024-10-30 20:45:35] iter = 07910, loss = 2.0045
2024-10-30 20:45:39: [2024-10-30 20:45:39] iter = 07920, loss = 1.9461
2024-10-30 20:45:41: [2024-10-30 20:45:41] iter = 07930, loss = 2.6442
2024-10-30 20:45:44: [2024-10-30 20:45:44] iter = 07940, loss = 2.0230
2024-10-30 20:45:49: [2024-10-30 20:45:49] iter = 07950, loss = 1.8972
2024-10-30 20:45:53: [2024-10-30 20:45:53] iter = 07960, loss = 1.9973
2024-10-30 20:45:57: [2024-10-30 20:45:57] iter = 07970, loss = 3.5119
2024-10-30 20:46:02: [2024-10-30 20:46:02] iter = 07980, loss = 1.9307
2024-10-30 20:46:06: [2024-10-30 20:46:06] iter = 07990, loss = 2.4218
2024-10-30 20:46:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 20:46:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:46:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 70873}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:48:41: Evaluate 5 random ConvNet, ACCmean = 0.5924 ACCstd = 0.0037
-------------------------
2024-10-30 20:48:41: Evaluate 5 random ConvNet, SENmean = 0.5776 SENstd = 0.0036
-------------------------
2024-10-30 20:48:41: Evaluate 5 random ConvNet, SPEmean = 0.9586 SPEstd = 0.0004
-------------------------
2024-10-30 20:48:41: Evaluate 5 random ConvNet, F!mean = 0.5649 F!std = 0.0041
-------------------------
2024-10-30 20:48:41: Evaluate 5 random ConvNet, mean = 0.5924 std = 0.0037
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:48:42: [2024-10-30 20:48:42] iter = 08000, loss = 3.1202
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:48:45: [2024-10-30 20:48:45] iter = 08010, loss = 2.0454
2024-10-30 20:48:48: [2024-10-30 20:48:48] iter = 08020, loss = 3.6931
2024-10-30 20:48:51: [2024-10-30 20:48:51] iter = 08030, loss = 2.9746
2024-10-30 20:48:54: [2024-10-30 20:48:54] iter = 08040, loss = 2.1623
2024-10-30 20:48:58: [2024-10-30 20:48:58] iter = 08050, loss = 1.9601
2024-10-30 20:49:02: [2024-10-30 20:49:02] iter = 08060, loss = 2.1891
2024-10-30 20:49:05: [2024-10-30 20:49:05] iter = 08070, loss = 3.6214
2024-10-30 20:49:08: [2024-10-30 20:49:08] iter = 08080, loss = 2.3942
2024-10-30 20:49:11: [2024-10-30 20:49:11] iter = 08090, loss = 2.1367
2024-10-30 20:49:14: [2024-10-30 20:49:14] iter = 08100, loss = 2.8571
2024-10-30 20:49:18: [2024-10-30 20:49:18] iter = 08110, loss = 2.0778
2024-10-30 20:49:21: [2024-10-30 20:49:21] iter = 08120, loss = 2.3264
2024-10-30 20:49:23: [2024-10-30 20:49:23] iter = 08130, loss = 2.1984
2024-10-30 20:49:27: [2024-10-30 20:49:27] iter = 08140, loss = 2.5317
2024-10-30 20:49:30: [2024-10-30 20:49:30] iter = 08150, loss = 2.0509
2024-10-30 20:49:33: [2024-10-30 20:49:33] iter = 08160, loss = 2.6706
2024-10-30 20:49:37: [2024-10-30 20:49:37] iter = 08170, loss = 5.2792
2024-10-30 20:49:41: [2024-10-30 20:49:41] iter = 08180, loss = 4.3501
2024-10-30 20:49:46: [2024-10-30 20:49:46] iter = 08190, loss = 2.6868
2024-10-30 20:49:49: [2024-10-30 20:49:49] iter = 08200, loss = 1.8206
2024-10-30 20:49:53: [2024-10-30 20:49:53] iter = 08210, loss = 2.8351
2024-10-30 20:49:57: [2024-10-30 20:49:57] iter = 08220, loss = 2.8637
2024-10-30 20:50:01: [2024-10-30 20:50:01] iter = 08230, loss = 2.1097
2024-10-30 20:50:05: [2024-10-30 20:50:05] iter = 08240, loss = 2.4732
2024-10-30 20:50:09: [2024-10-30 20:50:09] iter = 08250, loss = 1.9740
2024-10-30 20:50:12: [2024-10-30 20:50:12] iter = 08260, loss = 1.8156
2024-10-30 20:50:16: [2024-10-30 20:50:16] iter = 08270, loss = 1.8117
2024-10-30 20:50:20: [2024-10-30 20:50:20] iter = 08280, loss = 1.6385
2024-10-30 20:50:25: [2024-10-30 20:50:25] iter = 08290, loss = 2.1658
2024-10-30 20:50:29: [2024-10-30 20:50:29] iter = 08300, loss = 2.6065
2024-10-30 20:50:33: [2024-10-30 20:50:33] iter = 08310, loss = 2.7032
2024-10-30 20:50:36: [2024-10-30 20:50:36] iter = 08320, loss = 2.1824
2024-10-30 20:50:41: [2024-10-30 20:50:41] iter = 08330, loss = 2.7637
2024-10-30 20:50:45: [2024-10-30 20:50:45] iter = 08340, loss = 2.6222
2024-10-30 20:50:48: [2024-10-30 20:50:48] iter = 08350, loss = 2.3812
2024-10-30 20:50:52: [2024-10-30 20:50:52] iter = 08360, loss = 2.4710
2024-10-30 20:50:55: [2024-10-30 20:50:55] iter = 08370, loss = 2.3647
2024-10-30 20:50:59: [2024-10-30 20:50:59] iter = 08380, loss = 1.6377
2024-10-30 20:51:03: [2024-10-30 20:51:03] iter = 08390, loss = 2.5440
2024-10-30 20:51:05: [2024-10-30 20:51:05] iter = 08400, loss = 2.3933
2024-10-30 20:51:09: [2024-10-30 20:51:09] iter = 08410, loss = 2.2707
2024-10-30 20:51:12: [2024-10-30 20:51:12] iter = 08420, loss = 2.5903
2024-10-30 20:51:16: [2024-10-30 20:51:16] iter = 08430, loss = 2.2864
2024-10-30 20:51:19: [2024-10-30 20:51:19] iter = 08440, loss = 1.9472
2024-10-30 20:51:23: [2024-10-30 20:51:23] iter = 08450, loss = 2.4483
2024-10-30 20:51:27: [2024-10-30 20:51:27] iter = 08460, loss = 7.4237
2024-10-30 20:51:30: [2024-10-30 20:51:30] iter = 08470, loss = 2.5044
2024-10-30 20:51:34: [2024-10-30 20:51:34] iter = 08480, loss = 2.0486
2024-10-30 20:51:38: [2024-10-30 20:51:38] iter = 08490, loss = 2.0065
2024-10-30 20:51:42: [2024-10-30 20:51:42] iter = 08500, loss = 1.8464
2024-10-30 20:51:45: [2024-10-30 20:51:45] iter = 08510, loss = 2.3774
2024-10-30 20:51:49: [2024-10-30 20:51:49] iter = 08520, loss = 3.2360
2024-10-30 20:51:52: [2024-10-30 20:51:52] iter = 08530, loss = 2.3911
2024-10-30 20:51:57: [2024-10-30 20:51:57] iter = 08540, loss = 2.6405
2024-10-30 20:52:00: [2024-10-30 20:52:00] iter = 08550, loss = 3.2423
2024-10-30 20:52:03: [2024-10-30 20:52:03] iter = 08560, loss = 1.8958
2024-10-30 20:52:08: [2024-10-30 20:52:08] iter = 08570, loss = 1.9415
2024-10-30 20:52:11: [2024-10-30 20:52:11] iter = 08580, loss = 2.2144
2024-10-30 20:52:15: [2024-10-30 20:52:15] iter = 08590, loss = 3.3483
2024-10-30 20:52:19: [2024-10-30 20:52:19] iter = 08600, loss = 1.9878
2024-10-30 20:52:24: [2024-10-30 20:52:24] iter = 08610, loss = 1.8845
2024-10-30 20:52:28: [2024-10-30 20:52:28] iter = 08620, loss = 2.5587
2024-10-30 20:52:32: [2024-10-30 20:52:32] iter = 08630, loss = 2.0140
2024-10-30 20:52:36: [2024-10-30 20:52:36] iter = 08640, loss = 2.3931
2024-10-30 20:52:40: [2024-10-30 20:52:40] iter = 08650, loss = 2.5011
2024-10-30 20:52:43: [2024-10-30 20:52:43] iter = 08660, loss = 2.8257
2024-10-30 20:52:48: [2024-10-30 20:52:48] iter = 08670, loss = 2.3496
2024-10-30 20:52:51: [2024-10-30 20:52:51] iter = 08680, loss = 1.9066
2024-10-30 20:52:56: [2024-10-30 20:52:56] iter = 08690, loss = 2.1680
2024-10-30 20:53:00: [2024-10-30 20:53:00] iter = 08700, loss = 2.8452
2024-10-30 20:53:07: [2024-10-30 20:53:07] iter = 08710, loss = 2.7861
2024-10-30 20:53:11: [2024-10-30 20:53:11] iter = 08720, loss = 2.0210
2024-10-30 20:53:16: [2024-10-30 20:53:16] iter = 08730, loss = 2.6745
2024-10-30 20:53:21: [2024-10-30 20:53:21] iter = 08740, loss = 2.1966
2024-10-30 20:53:26: [2024-10-30 20:53:26] iter = 08750, loss = 2.0878
2024-10-30 20:53:32: [2024-10-30 20:53:32] iter = 08760, loss = 2.5573
2024-10-30 20:53:36: [2024-10-30 20:53:36] iter = 08770, loss = 2.1579
2024-10-30 20:53:41: [2024-10-30 20:53:41] iter = 08780, loss = 3.0998
2024-10-30 20:53:47: [2024-10-30 20:53:47] iter = 08790, loss = 2.1510
2024-10-30 20:53:52: [2024-10-30 20:53:52] iter = 08800, loss = 2.4963
2024-10-30 20:53:57: [2024-10-30 20:53:57] iter = 08810, loss = 2.1964
2024-10-30 20:54:03: [2024-10-30 20:54:03] iter = 08820, loss = 2.4351
2024-10-30 20:54:07: [2024-10-30 20:54:07] iter = 08830, loss = 2.5340
2024-10-30 20:54:11: [2024-10-30 20:54:11] iter = 08840, loss = 1.9290
2024-10-30 20:54:16: [2024-10-30 20:54:16] iter = 08850, loss = 2.1361
2024-10-30 20:54:22: [2024-10-30 20:54:22] iter = 08860, loss = 2.5885
2024-10-30 20:54:27: [2024-10-30 20:54:27] iter = 08870, loss = 2.5402
2024-10-30 20:54:32: [2024-10-30 20:54:32] iter = 08880, loss = 3.4154
2024-10-30 20:54:36: [2024-10-30 20:54:36] iter = 08890, loss = 2.7921
2024-10-30 20:54:40: [2024-10-30 20:54:40] iter = 08900, loss = 2.7190
2024-10-30 20:54:45: [2024-10-30 20:54:45] iter = 08910, loss = 2.2768
2024-10-30 20:54:49: [2024-10-30 20:54:49] iter = 08920, loss = 2.2453
2024-10-30 20:54:54: [2024-10-30 20:54:54] iter = 08930, loss = 2.5426
2024-10-30 20:54:57: [2024-10-30 20:54:57] iter = 08940, loss = 2.6881
2024-10-30 20:55:03: [2024-10-30 20:55:03] iter = 08950, loss = 1.9733
2024-10-30 20:55:07: [2024-10-30 20:55:07] iter = 08960, loss = 2.5166
2024-10-30 20:55:12: [2024-10-30 20:55:12] iter = 08970, loss = 2.2285
2024-10-30 20:55:16: [2024-10-30 20:55:16] iter = 08980, loss = 2.2146
2024-10-30 20:55:19: [2024-10-30 20:55:19] iter = 08990, loss = 2.4219
2024-10-30 20:55:23: [2024-10-30 20:55:23] iter = 09000, loss = 3.7024
2024-10-30 20:55:26: [2024-10-30 20:55:26] iter = 09010, loss = 2.1209
2024-10-30 20:55:30: [2024-10-30 20:55:30] iter = 09020, loss = 2.9228
2024-10-30 20:55:35: [2024-10-30 20:55:35] iter = 09030, loss = 1.9959
2024-10-30 20:55:40: [2024-10-30 20:55:40] iter = 09040, loss = 2.0316
2024-10-30 20:55:45: [2024-10-30 20:55:45] iter = 09050, loss = 2.2469
2024-10-30 20:55:48: [2024-10-30 20:55:48] iter = 09060, loss = 3.0341
2024-10-30 20:55:52: [2024-10-30 20:55:52] iter = 09070, loss = 2.3648
2024-10-30 20:55:56: [2024-10-30 20:55:56] iter = 09080, loss = 2.6193
2024-10-30 20:56:00: [2024-10-30 20:56:00] iter = 09090, loss = 2.8593
2024-10-30 20:56:04: [2024-10-30 20:56:04] iter = 09100, loss = 2.1002
2024-10-30 20:56:08: [2024-10-30 20:56:08] iter = 09110, loss = 1.9932
2024-10-30 20:56:13: [2024-10-30 20:56:13] iter = 09120, loss = 2.1941
2024-10-30 20:56:16: [2024-10-30 20:56:16] iter = 09130, loss = 1.8311
2024-10-30 20:56:19: [2024-10-30 20:56:19] iter = 09140, loss = 2.1058
2024-10-30 20:56:21: [2024-10-30 20:56:21] iter = 09150, loss = 2.3830
2024-10-30 20:56:26: [2024-10-30 20:56:26] iter = 09160, loss = 2.3210
2024-10-30 20:56:30: [2024-10-30 20:56:30] iter = 09170, loss = 2.0371
2024-10-30 20:56:34: [2024-10-30 20:56:34] iter = 09180, loss = 1.9672
2024-10-30 20:56:38: [2024-10-30 20:56:38] iter = 09190, loss = 2.2346
2024-10-30 20:56:42: [2024-10-30 20:56:42] iter = 09200, loss = 2.2826
2024-10-30 20:56:46: [2024-10-30 20:56:46] iter = 09210, loss = 3.7070
2024-10-30 20:56:50: [2024-10-30 20:56:50] iter = 09220, loss = 2.1148
2024-10-30 20:56:54: [2024-10-30 20:56:54] iter = 09230, loss = 1.9364
2024-10-30 20:56:58: [2024-10-30 20:56:58] iter = 09240, loss = 2.6238
2024-10-30 20:57:02: [2024-10-30 20:57:02] iter = 09250, loss = 2.1261
2024-10-30 20:57:05: [2024-10-30 20:57:05] iter = 09260, loss = 2.3737
2024-10-30 20:57:10: [2024-10-30 20:57:10] iter = 09270, loss = 2.2480
2024-10-30 20:57:14: [2024-10-30 20:57:14] iter = 09280, loss = 4.2479
2024-10-30 20:57:18: [2024-10-30 20:57:18] iter = 09290, loss = 1.9756
2024-10-30 20:57:22: [2024-10-30 20:57:22] iter = 09300, loss = 2.2827
2024-10-30 20:57:25: [2024-10-30 20:57:25] iter = 09310, loss = 3.9008
2024-10-30 20:57:29: [2024-10-30 20:57:29] iter = 09320, loss = 2.1708
2024-10-30 20:57:34: [2024-10-30 20:57:34] iter = 09330, loss = 2.1095
2024-10-30 20:57:38: [2024-10-30 20:57:38] iter = 09340, loss = 2.1200
2024-10-30 20:57:41: [2024-10-30 20:57:41] iter = 09350, loss = 2.4290
2024-10-30 20:57:46: [2024-10-30 20:57:46] iter = 09360, loss = 2.3236
2024-10-30 20:57:49: [2024-10-30 20:57:49] iter = 09370, loss = 2.0834
2024-10-30 20:57:54: [2024-10-30 20:57:54] iter = 09380, loss = 1.7809
2024-10-30 20:57:58: [2024-10-30 20:57:58] iter = 09390, loss = 2.3473
2024-10-30 20:58:02: [2024-10-30 20:58:02] iter = 09400, loss = 2.2600
2024-10-30 20:58:06: [2024-10-30 20:58:06] iter = 09410, loss = 2.3078
2024-10-30 20:58:09: [2024-10-30 20:58:09] iter = 09420, loss = 2.0743
2024-10-30 20:58:14: [2024-10-30 20:58:14] iter = 09430, loss = 2.4674
2024-10-30 20:58:18: [2024-10-30 20:58:18] iter = 09440, loss = 2.3754
2024-10-30 20:58:22: [2024-10-30 20:58:22] iter = 09450, loss = 2.8097
2024-10-30 20:58:25: [2024-10-30 20:58:25] iter = 09460, loss = 2.5697
2024-10-30 20:58:29: [2024-10-30 20:58:29] iter = 09470, loss = 2.0744
2024-10-30 20:58:32: [2024-10-30 20:58:32] iter = 09480, loss = 1.9045
2024-10-30 20:58:35: [2024-10-30 20:58:35] iter = 09490, loss = 2.1129
2024-10-30 20:58:40: [2024-10-30 20:58:40] iter = 09500, loss = 2.0081
2024-10-30 20:58:43: [2024-10-30 20:58:43] iter = 09510, loss = 4.0034
2024-10-30 20:58:47: [2024-10-30 20:58:47] iter = 09520, loss = 1.9654
2024-10-30 20:58:50: [2024-10-30 20:58:50] iter = 09530, loss = 2.0324
2024-10-30 20:58:53: [2024-10-30 20:58:53] iter = 09540, loss = 2.6269
2024-10-30 20:58:57: [2024-10-30 20:58:57] iter = 09550, loss = 2.4263
2024-10-30 20:59:00: [2024-10-30 20:59:00] iter = 09560, loss = 2.2969
2024-10-30 20:59:04: [2024-10-30 20:59:04] iter = 09570, loss = 2.3152
2024-10-30 20:59:07: [2024-10-30 20:59:07] iter = 09580, loss = 2.3688
2024-10-30 20:59:11: [2024-10-30 20:59:11] iter = 09590, loss = 2.2433
2024-10-30 20:59:16: [2024-10-30 20:59:16] iter = 09600, loss = 2.2203
2024-10-30 20:59:20: [2024-10-30 20:59:20] iter = 09610, loss = 1.7748
2024-10-30 20:59:24: [2024-10-30 20:59:24] iter = 09620, loss = 2.6388
2024-10-30 20:59:29: [2024-10-30 20:59:29] iter = 09630, loss = 2.1807
2024-10-30 20:59:33: [2024-10-30 20:59:33] iter = 09640, loss = 2.3694
2024-10-30 20:59:37: [2024-10-30 20:59:37] iter = 09650, loss = 5.3421
2024-10-30 20:59:41: [2024-10-30 20:59:41] iter = 09660, loss = 2.1376
2024-10-30 20:59:45: [2024-10-30 20:59:45] iter = 09670, loss = 2.0270
2024-10-30 20:59:50: [2024-10-30 20:59:50] iter = 09680, loss = 1.9687
2024-10-30 20:59:53: [2024-10-30 20:59:53] iter = 09690, loss = 2.6137
2024-10-30 20:59:58: [2024-10-30 20:59:58] iter = 09700, loss = 1.8557
2024-10-30 21:00:02: [2024-10-30 21:00:02] iter = 09710, loss = 2.4826
2024-10-30 21:00:05: [2024-10-30 21:00:05] iter = 09720, loss = 3.4317
2024-10-30 21:00:09: [2024-10-30 21:00:09] iter = 09730, loss = 3.5069
2024-10-30 21:00:14: [2024-10-30 21:00:14] iter = 09740, loss = 3.1734
2024-10-30 21:00:18: [2024-10-30 21:00:18] iter = 09750, loss = 2.5108
2024-10-30 21:00:23: [2024-10-30 21:00:23] iter = 09760, loss = 2.1277
2024-10-30 21:00:27: [2024-10-30 21:00:27] iter = 09770, loss = 3.5130
2024-10-30 21:00:31: [2024-10-30 21:00:31] iter = 09780, loss = 2.2363
2024-10-30 21:00:35: [2024-10-30 21:00:35] iter = 09790, loss = 2.5985
2024-10-30 21:00:41: [2024-10-30 21:00:41] iter = 09800, loss = 1.8183
2024-10-30 21:00:44: [2024-10-30 21:00:44] iter = 09810, loss = 1.7037
2024-10-30 21:00:48: [2024-10-30 21:00:48] iter = 09820, loss = 2.1039
2024-10-30 21:00:52: [2024-10-30 21:00:52] iter = 09830, loss = 2.7895
2024-10-30 21:00:56: [2024-10-30 21:00:56] iter = 09840, loss = 1.9849
2024-10-30 21:01:00: [2024-10-30 21:01:00] iter = 09850, loss = 2.5339
2024-10-30 21:01:04: [2024-10-30 21:01:04] iter = 09860, loss = 2.4510
2024-10-30 21:01:07: [2024-10-30 21:01:07] iter = 09870, loss = 2.2324
2024-10-30 21:01:12: [2024-10-30 21:01:12] iter = 09880, loss = 6.2523
2024-10-30 21:01:16: [2024-10-30 21:01:16] iter = 09890, loss = 3.3597
2024-10-30 21:01:20: [2024-10-30 21:01:20] iter = 09900, loss = 2.1157
2024-10-30 21:01:23: [2024-10-30 21:01:23] iter = 09910, loss = 2.2829
2024-10-30 21:01:27: [2024-10-30 21:01:27] iter = 09920, loss = 2.4238
2024-10-30 21:01:32: [2024-10-30 21:01:32] iter = 09930, loss = 2.1452
2024-10-30 21:01:35: [2024-10-30 21:01:35] iter = 09940, loss = 2.1535
2024-10-30 21:01:40: [2024-10-30 21:01:40] iter = 09950, loss = 1.9951
2024-10-30 21:01:44: [2024-10-30 21:01:44] iter = 09960, loss = 2.6544
2024-10-30 21:01:48: [2024-10-30 21:01:48] iter = 09970, loss = 2.1679
2024-10-30 21:01:52: [2024-10-30 21:01:52] iter = 09980, loss = 2.2437
2024-10-30 21:01:56: [2024-10-30 21:01:56] iter = 09990, loss = 1.8454
2024-10-30 21:02:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 21:02:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:02:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 20564}

[2024-10-30 19:07:03] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.050515 train acc = 1.0000, test acc = 0.6001, test_sen =0.5788, test_spe =0.9591, test_f1 =0.5696
[2024-10-30 19:07:30] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.007665 train acc = 1.0000, test acc = 0.6063, test_sen =0.5850, test_spe =0.9599, test_f1 =0.5772
[2024-10-30 19:08:00] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.006757 train acc = 1.0000, test acc = 0.6004, test_sen =0.5802, test_spe =0.9592, test_f1 =0.5709
[2024-10-30 19:08:27] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.084806 train acc = 0.9818, test acc = 0.6019, test_sen =0.5841, test_spe =0.9595, test_f1 =0.5743
[2024-10-30 19:20:25] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.054961 train acc = 0.9909, test acc = 0.6005, test_sen =0.5831, test_spe =0.9593, test_f1 =0.5721
[2024-10-30 19:20:51] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.010263 train acc = 1.0000, test acc = 0.6082, test_sen =0.5970, test_spe =0.9601, test_f1 =0.5860
[2024-10-30 19:21:18] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.022637 train acc = 1.0000, test acc = 0.6026, test_sen =0.5856, test_spe =0.9595, test_f1 =0.5762
[2024-10-30 19:21:43] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.008641 train acc = 1.0000, test acc = 0.6097, test_sen =0.5870, test_spe =0.9602, test_f1 =0.5804
[2024-10-30 19:22:09] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.024646 train acc = 1.0000, test acc = 0.6111, test_sen =0.5978, test_spe =0.9604, test_f1 =0.5851
[2024-10-30 19:33:43] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.067617 train acc = 0.9909, test acc = 0.6196, test_sen =0.5982, test_spe =0.9613, test_f1 =0.5878
[2024-10-30 19:34:09] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.011530 train acc = 1.0000, test acc = 0.6266, test_sen =0.6069, test_spe =0.9620, test_f1 =0.6000
[2024-10-30 19:34:30] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.028785 train acc = 1.0000, test acc = 0.6143, test_sen =0.5917, test_spe =0.9607, test_f1 =0.5862
[2024-10-30 19:34:51] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.013243 train acc = 1.0000, test acc = 0.6132, test_sen =0.5962, test_spe =0.9605, test_f1 =0.5876
[2024-10-30 19:35:18] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.012262 train acc = 1.0000, test acc = 0.6132, test_sen =0.5958, test_spe =0.9606, test_f1 =0.5898
[2024-10-30 19:46:31] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.076141 train acc = 0.9818, test acc = 0.6139, test_sen =0.5997, test_spe =0.9608, test_f1 =0.5838
[2024-10-30 19:46:58] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.038240 train acc = 1.0000, test acc = 0.6107, test_sen =0.5912, test_spe =0.9602, test_f1 =0.5820
[2024-10-30 19:47:21] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.011208 train acc = 1.0000, test acc = 0.6112, test_sen =0.5968, test_spe =0.9604, test_f1 =0.5829
[2024-10-30 19:47:47] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.116912 train acc = 0.9727, test acc = 0.6191, test_sen =0.5939, test_spe =0.9612, test_f1 =0.5868
[2024-10-30 19:48:16] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.022950 train acc = 1.0000, test acc = 0.6220, test_sen =0.5992, test_spe =0.9614, test_f1 =0.5912
[2024-10-30 19:48:40] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.003041 train acc = 1.0000, test acc = 0.4282, test_sen =0.4289, test_spe =0.9420, test_f1 =0.4115
[2024-10-30 19:49:06] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.019617 train acc = 1.0000, test acc = 0.4353, test_sen =0.4413, test_spe =0.9429, test_f1 =0.4206
[2024-10-30 19:49:28] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.007136 train acc = 1.0000, test acc = 0.4320, test_sen =0.4383, test_spe =0.9426, test_f1 =0.4183
[2024-10-30 19:49:55] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.036392 train acc = 1.0000, test acc = 0.4312, test_sen =0.4371, test_spe =0.9424, test_f1 =0.4177
[2024-10-30 19:50:18] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.014600 train acc = 1.0000, test acc = 0.4342, test_sen =0.4373, test_spe =0.9426, test_f1 =0.4172
[2024-10-30 20:01:38] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.061214 train acc = 0.9909, test acc = 0.6075, test_sen =0.5900, test_spe =0.9599, test_f1 =0.5797
[2024-10-30 20:02:00] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.047042 train acc = 0.9909, test acc = 0.6013, test_sen =0.5812, test_spe =0.9593, test_f1 =0.5710
[2024-10-30 20:02:26] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.072903 train acc = 0.9909, test acc = 0.5979, test_sen =0.5819, test_spe =0.9590, test_f1 =0.5722
[2024-10-30 20:02:49] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.056668 train acc = 1.0000, test acc = 0.5953, test_sen =0.5785, test_spe =0.9587, test_f1 =0.5688
[2024-10-30 20:03:20] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.024279 train acc = 1.0000, test acc = 0.6124, test_sen =0.5957, test_spe =0.9605, test_f1 =0.5840
[2024-10-30 20:14:23] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.013049 train acc = 1.0000, test acc = 0.6022, test_sen =0.5766, test_spe =0.9591, test_f1 =0.5716
[2024-10-30 20:14:47] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.058683 train acc = 1.0000, test acc = 0.5966, test_sen =0.5681, test_spe =0.9584, test_f1 =0.5630
[2024-10-30 20:15:16] Evaluate_02: epoch = 1000 train time = 27 s train loss = 0.055313 train acc = 1.0000, test acc = 0.5913, test_sen =0.5701, test_spe =0.9581, test_f1 =0.5608
[2024-10-30 20:15:44] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.010990 train acc = 1.0000, test acc = 0.5988, test_sen =0.5817, test_spe =0.9591, test_f1 =0.5717
[2024-10-30 20:16:14] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.008687 train acc = 1.0000, test acc = 0.5992, test_sen =0.5698, test_spe =0.9589, test_f1 =0.5620
[2024-10-30 20:30:31] Evaluate_00: epoch = 1000 train time = 31 s train loss = 0.007168 train acc = 1.0000, test acc = 0.5958, test_sen =0.5835, test_spe =0.9589, test_f1 =0.5753
[2024-10-30 20:31:04] Evaluate_01: epoch = 1000 train time = 31 s train loss = 0.033979 train acc = 0.9909, test acc = 0.6025, test_sen =0.5850, test_spe =0.9594, test_f1 =0.5788
[2024-10-30 20:31:35] Evaluate_02: epoch = 1000 train time = 29 s train loss = 0.063376 train acc = 0.9909, test acc = 0.6031, test_sen =0.5907, test_spe =0.9595, test_f1 =0.5829
[2024-10-30 20:32:11] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.069527 train acc = 0.9818, test acc = 0.5981, test_sen =0.5853, test_spe =0.9589, test_f1 =0.5785
[2024-10-30 20:32:48] Evaluate_04: epoch = 1000 train time = 35 s train loss = 0.009763 train acc = 1.0000, test acc = 0.6020, test_sen =0.5791, test_spe =0.9591, test_f1 =0.5760
[2024-10-30 20:46:41] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.046636 train acc = 1.0000, test acc = 0.5919, test_sen =0.5729, test_spe =0.9584, test_f1 =0.5583
[2024-10-30 20:47:13] Evaluate_01: epoch = 1000 train time = 31 s train loss = 0.028844 train acc = 1.0000, test acc = 0.5927, test_sen =0.5806, test_spe =0.9586, test_f1 =0.5694
[2024-10-30 20:47:42] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.020751 train acc = 1.0000, test acc = 0.5962, test_sen =0.5830, test_spe =0.9591, test_f1 =0.5692
[2024-10-30 20:48:12] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.009932 train acc = 1.0000, test acc = 0.5857, test_sen =0.5757, test_spe =0.9580, test_f1 =0.5632
[2024-10-30 20:48:41] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.066420 train acc = 0.9818, test acc = 0.5954, test_sen =0.5760, test_spe =0.9588, test_f1 =0.5646
[2024-10-30 21:02:33] Evaluate_00: epoch = 1000 train time = 31 s train loss = 0.011251 train acc = 1.0000, test acc = 0.6095, test_sen =0.5886, test_spe =0.9602, test_f1 =0.5805
[2024-10-30 21:03:03] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.056356 train acc = 1.0000, test acc = 0.6034, test_sen =0.5898, test_spe =0.9596, test_f1 =0.5799/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:04:37: Evaluate 5 random ConvNet, ACCmean = 0.6102 ACCstd = 0.0059
-------------------------
2024-10-30 21:04:37: Evaluate 5 random ConvNet, SENmean = 0.5890 SENstd = 0.0031
-------------------------
2024-10-30 21:04:37: Evaluate 5 random ConvNet, SPEmean = 0.9602 SPEstd = 0.0005
-------------------------
2024-10-30 21:04:37: Evaluate 5 random ConvNet, F!mean = 0.5816 F!std = 0.0041
-------------------------
2024-10-30 21:04:37: Evaluate 5 random ConvNet, mean = 0.6102 std = 0.0059
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:04:38: [2024-10-30 21:04:38] iter = 10000, loss = 2.8838
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:04:41: [2024-10-30 21:04:41] iter = 10010, loss = 2.4001
2024-10-30 21:04:46: [2024-10-30 21:04:46] iter = 10020, loss = 2.0760
2024-10-30 21:04:50: [2024-10-30 21:04:50] iter = 10030, loss = 1.8894
2024-10-30 21:04:54: [2024-10-30 21:04:54] iter = 10040, loss = 2.3502
2024-10-30 21:04:58: [2024-10-30 21:04:58] iter = 10050, loss = 2.9136
2024-10-30 21:05:02: [2024-10-30 21:05:02] iter = 10060, loss = 2.1200
2024-10-30 21:05:05: [2024-10-30 21:05:05] iter = 10070, loss = 2.3454
2024-10-30 21:05:07: [2024-10-30 21:05:07] iter = 10080, loss = 2.6112
2024-10-30 21:05:11: [2024-10-30 21:05:11] iter = 10090, loss = 3.5041
2024-10-30 21:05:13: [2024-10-30 21:05:13] iter = 10100, loss = 1.8706
2024-10-30 21:05:17: [2024-10-30 21:05:17] iter = 10110, loss = 2.2425
2024-10-30 21:05:21: [2024-10-30 21:05:21] iter = 10120, loss = 1.9619
2024-10-30 21:05:25: [2024-10-30 21:05:25] iter = 10130, loss = 2.2623
2024-10-30 21:05:30: [2024-10-30 21:05:30] iter = 10140, loss = 2.1872
2024-10-30 21:05:33: [2024-10-30 21:05:33] iter = 10150, loss = 2.1116
2024-10-30 21:05:37: [2024-10-30 21:05:37] iter = 10160, loss = 2.2108
2024-10-30 21:05:41: [2024-10-30 21:05:41] iter = 10170, loss = 2.0014
2024-10-30 21:05:47: [2024-10-30 21:05:47] iter = 10180, loss = 2.9437
2024-10-30 21:05:50: [2024-10-30 21:05:50] iter = 10190, loss = 1.9074
2024-10-30 21:05:54: [2024-10-30 21:05:54] iter = 10200, loss = 1.6722
2024-10-30 21:05:58: [2024-10-30 21:05:58] iter = 10210, loss = 2.5752
2024-10-30 21:06:02: [2024-10-30 21:06:02] iter = 10220, loss = 1.8337
2024-10-30 21:06:06: [2024-10-30 21:06:06] iter = 10230, loss = 1.9335
2024-10-30 21:06:09: [2024-10-30 21:06:09] iter = 10240, loss = 2.5043
2024-10-30 21:06:12: [2024-10-30 21:06:12] iter = 10250, loss = 1.9790
2024-10-30 21:06:16: [2024-10-30 21:06:16] iter = 10260, loss = 2.2947
2024-10-30 21:06:20: [2024-10-30 21:06:20] iter = 10270, loss = 2.2045
2024-10-30 21:06:24: [2024-10-30 21:06:24] iter = 10280, loss = 2.1648
2024-10-30 21:06:27: [2024-10-30 21:06:27] iter = 10290, loss = 2.6787
2024-10-30 21:06:30: [2024-10-30 21:06:30] iter = 10300, loss = 2.9574
2024-10-30 21:06:34: [2024-10-30 21:06:34] iter = 10310, loss = 2.2706
2024-10-30 21:06:37: [2024-10-30 21:06:37] iter = 10320, loss = 2.3239
2024-10-30 21:06:41: [2024-10-30 21:06:41] iter = 10330, loss = 4.4459
2024-10-30 21:06:43: [2024-10-30 21:06:43] iter = 10340, loss = 1.9550
2024-10-30 21:06:46: [2024-10-30 21:06:46] iter = 10350, loss = 2.4999
2024-10-30 21:06:50: [2024-10-30 21:06:50] iter = 10360, loss = 2.0700
2024-10-30 21:06:54: [2024-10-30 21:06:54] iter = 10370, loss = 2.1415
2024-10-30 21:06:57: [2024-10-30 21:06:57] iter = 10380, loss = 1.9670
2024-10-30 21:06:59: [2024-10-30 21:06:59] iter = 10390, loss = 2.0298
2024-10-30 21:07:03: [2024-10-30 21:07:03] iter = 10400, loss = 1.9885
2024-10-30 21:07:07: [2024-10-30 21:07:07] iter = 10410, loss = 2.7269
2024-10-30 21:07:11: [2024-10-30 21:07:11] iter = 10420, loss = 2.4083
2024-10-30 21:07:15: [2024-10-30 21:07:15] iter = 10430, loss = 2.1833
2024-10-30 21:07:18: [2024-10-30 21:07:18] iter = 10440, loss = 1.8765
2024-10-30 21:07:21: [2024-10-30 21:07:21] iter = 10450, loss = 2.6446
2024-10-30 21:07:24: [2024-10-30 21:07:24] iter = 10460, loss = 2.3339
2024-10-30 21:07:27: [2024-10-30 21:07:27] iter = 10470, loss = 3.7842
2024-10-30 21:07:31: [2024-10-30 21:07:31] iter = 10480, loss = 2.0003
2024-10-30 21:07:35: [2024-10-30 21:07:35] iter = 10490, loss = 1.9806
2024-10-30 21:07:39: [2024-10-30 21:07:39] iter = 10500, loss = 2.4469
2024-10-30 21:07:43: [2024-10-30 21:07:43] iter = 10510, loss = 3.1461
2024-10-30 21:07:47: [2024-10-30 21:07:47] iter = 10520, loss = 2.1087
2024-10-30 21:07:51: [2024-10-30 21:07:51] iter = 10530, loss = 1.9059
2024-10-30 21:07:54: [2024-10-30 21:07:54] iter = 10540, loss = 2.8426
2024-10-30 21:07:58: [2024-10-30 21:07:58] iter = 10550, loss = 2.3210
2024-10-30 21:08:01: [2024-10-30 21:08:01] iter = 10560, loss = 2.2027
2024-10-30 21:08:05: [2024-10-30 21:08:05] iter = 10570, loss = 2.6823
2024-10-30 21:08:08: [2024-10-30 21:08:08] iter = 10580, loss = 2.0633
2024-10-30 21:08:12: [2024-10-30 21:08:12] iter = 10590, loss = 1.7975
2024-10-30 21:08:16: [2024-10-30 21:08:16] iter = 10600, loss = 2.3874
2024-10-30 21:08:20: [2024-10-30 21:08:20] iter = 10610, loss = 2.1071
2024-10-30 21:08:24: [2024-10-30 21:08:24] iter = 10620, loss = 2.3524
2024-10-30 21:08:28: [2024-10-30 21:08:28] iter = 10630, loss = 1.7294
2024-10-30 21:08:31: [2024-10-30 21:08:31] iter = 10640, loss = 2.1341
2024-10-30 21:08:35: [2024-10-30 21:08:35] iter = 10650, loss = 2.2143
2024-10-30 21:08:38: [2024-10-30 21:08:38] iter = 10660, loss = 2.5174
2024-10-30 21:08:42: [2024-10-30 21:08:42] iter = 10670, loss = 2.1058
2024-10-30 21:08:45: [2024-10-30 21:08:45] iter = 10680, loss = 2.2118
2024-10-30 21:08:49: [2024-10-30 21:08:49] iter = 10690, loss = 2.5225
2024-10-30 21:08:54: [2024-10-30 21:08:54] iter = 10700, loss = 2.1466
2024-10-30 21:08:57: [2024-10-30 21:08:57] iter = 10710, loss = 2.2934
2024-10-30 21:09:00: [2024-10-30 21:09:00] iter = 10720, loss = 2.7455
2024-10-30 21:09:04: [2024-10-30 21:09:04] iter = 10730, loss = 2.0505
2024-10-30 21:09:07: [2024-10-30 21:09:07] iter = 10740, loss = 2.4817
2024-10-30 21:09:10: [2024-10-30 21:09:10] iter = 10750, loss = 2.4689
2024-10-30 21:09:13: [2024-10-30 21:09:13] iter = 10760, loss = 2.0724
2024-10-30 21:09:17: [2024-10-30 21:09:17] iter = 10770, loss = 2.2001
2024-10-30 21:09:20: [2024-10-30 21:09:20] iter = 10780, loss = 1.8335
2024-10-30 21:09:23: [2024-10-30 21:09:23] iter = 10790, loss = 2.3733
2024-10-30 21:09:26: [2024-10-30 21:09:26] iter = 10800, loss = 2.4678
2024-10-30 21:09:30: [2024-10-30 21:09:30] iter = 10810, loss = 1.8044
2024-10-30 21:09:34: [2024-10-30 21:09:34] iter = 10820, loss = 1.9461
2024-10-30 21:09:37: [2024-10-30 21:09:37] iter = 10830, loss = 1.8154
2024-10-30 21:09:42: [2024-10-30 21:09:42] iter = 10840, loss = 2.0317
2024-10-30 21:09:45: [2024-10-30 21:09:45] iter = 10850, loss = 2.4333
2024-10-30 21:09:47: [2024-10-30 21:09:47] iter = 10860, loss = 3.4477
2024-10-30 21:09:51: [2024-10-30 21:09:51] iter = 10870, loss = 2.1977
2024-10-30 21:09:54: [2024-10-30 21:09:54] iter = 10880, loss = 1.9811
2024-10-30 21:09:59: [2024-10-30 21:09:59] iter = 10890, loss = 2.6660
2024-10-30 21:10:02: [2024-10-30 21:10:02] iter = 10900, loss = 4.4649
2024-10-30 21:10:06: [2024-10-30 21:10:06] iter = 10910, loss = 1.9695
2024-10-30 21:10:09: [2024-10-30 21:10:09] iter = 10920, loss = 1.7327
2024-10-30 21:10:13: [2024-10-30 21:10:13] iter = 10930, loss = 1.8814
2024-10-30 21:10:16: [2024-10-30 21:10:16] iter = 10940, loss = 4.0727
2024-10-30 21:10:19: [2024-10-30 21:10:19] iter = 10950, loss = 2.1021
2024-10-30 21:10:22: [2024-10-30 21:10:22] iter = 10960, loss = 1.9898
2024-10-30 21:10:26: [2024-10-30 21:10:26] iter = 10970, loss = 2.5626
2024-10-30 21:10:29: [2024-10-30 21:10:29] iter = 10980, loss = 2.5702
2024-10-30 21:10:33: [2024-10-30 21:10:33] iter = 10990, loss = 2.4916
2024-10-30 21:10:35: [2024-10-30 21:10:35] iter = 11000, loss = 2.1126
2024-10-30 21:10:39: [2024-10-30 21:10:39] iter = 11010, loss = 1.8495
2024-10-30 21:10:42: [2024-10-30 21:10:42] iter = 11020, loss = 2.1229
2024-10-30 21:10:45: [2024-10-30 21:10:45] iter = 11030, loss = 1.7991
2024-10-30 21:10:48: [2024-10-30 21:10:48] iter = 11040, loss = 2.6801
2024-10-30 21:10:52: [2024-10-30 21:10:52] iter = 11050, loss = 2.5005
2024-10-30 21:10:56: [2024-10-30 21:10:56] iter = 11060, loss = 2.5002
2024-10-30 21:10:59: [2024-10-30 21:10:59] iter = 11070, loss = 2.0789
2024-10-30 21:11:02: [2024-10-30 21:11:02] iter = 11080, loss = 2.7187
2024-10-30 21:11:05: [2024-10-30 21:11:05] iter = 11090, loss = 1.9026
2024-10-30 21:11:09: [2024-10-30 21:11:09] iter = 11100, loss = 2.4609
2024-10-30 21:11:12: [2024-10-30 21:11:12] iter = 11110, loss = 2.1957
2024-10-30 21:11:16: [2024-10-30 21:11:16] iter = 11120, loss = 2.8017
2024-10-30 21:11:20: [2024-10-30 21:11:20] iter = 11130, loss = 2.7124
2024-10-30 21:11:24: [2024-10-30 21:11:24] iter = 11140, loss = 2.8007
2024-10-30 21:11:28: [2024-10-30 21:11:28] iter = 11150, loss = 2.0688
2024-10-30 21:11:31: [2024-10-30 21:11:31] iter = 11160, loss = 2.0053
2024-10-30 21:11:34: [2024-10-30 21:11:34] iter = 11170, loss = 2.4263
2024-10-30 21:11:38: [2024-10-30 21:11:38] iter = 11180, loss = 2.1602
2024-10-30 21:11:41: [2024-10-30 21:11:41] iter = 11190, loss = 2.0873
2024-10-30 21:11:44: [2024-10-30 21:11:44] iter = 11200, loss = 2.9608
2024-10-30 21:11:48: [2024-10-30 21:11:48] iter = 11210, loss = 2.1025
2024-10-30 21:11:51: [2024-10-30 21:11:51] iter = 11220, loss = 1.9582
2024-10-30 21:11:53: [2024-10-30 21:11:53] iter = 11230, loss = 1.9082
2024-10-30 21:11:57: [2024-10-30 21:11:57] iter = 11240, loss = 2.1766
2024-10-30 21:12:00: [2024-10-30 21:12:00] iter = 11250, loss = 2.2954
2024-10-30 21:12:03: [2024-10-30 21:12:03] iter = 11260, loss = 1.9865
2024-10-30 21:12:07: [2024-10-30 21:12:07] iter = 11270, loss = 1.9208
2024-10-30 21:12:10: [2024-10-30 21:12:10] iter = 11280, loss = 2.2837
2024-10-30 21:12:13: [2024-10-30 21:12:13] iter = 11290, loss = 2.8369
2024-10-30 21:12:16: [2024-10-30 21:12:16] iter = 11300, loss = 2.4090
2024-10-30 21:12:19: [2024-10-30 21:12:19] iter = 11310, loss = 1.6741
2024-10-30 21:12:23: [2024-10-30 21:12:23] iter = 11320, loss = 2.3160
2024-10-30 21:12:27: [2024-10-30 21:12:27] iter = 11330, loss = 3.0207
2024-10-30 21:12:31: [2024-10-30 21:12:31] iter = 11340, loss = 2.7511
2024-10-30 21:12:35: [2024-10-30 21:12:35] iter = 11350, loss = 2.2939
2024-10-30 21:12:39: [2024-10-30 21:12:39] iter = 11360, loss = 2.6997
2024-10-30 21:12:43: [2024-10-30 21:12:43] iter = 11370, loss = 2.2499
2024-10-30 21:12:47: [2024-10-30 21:12:47] iter = 11380, loss = 1.9137
2024-10-30 21:12:51: [2024-10-30 21:12:51] iter = 11390, loss = 2.8141
2024-10-30 21:12:53: [2024-10-30 21:12:53] iter = 11400, loss = 2.7528
2024-10-30 21:12:57: [2024-10-30 21:12:57] iter = 11410, loss = 2.0323
2024-10-30 21:13:00: [2024-10-30 21:13:00] iter = 11420, loss = 2.5864
2024-10-30 21:13:05: [2024-10-30 21:13:05] iter = 11430, loss = 2.1139
2024-10-30 21:13:09: [2024-10-30 21:13:09] iter = 11440, loss = 3.7319
2024-10-30 21:13:13: [2024-10-30 21:13:13] iter = 11450, loss = 2.5003
2024-10-30 21:13:16: [2024-10-30 21:13:16] iter = 11460, loss = 2.5260
2024-10-30 21:13:20: [2024-10-30 21:13:20] iter = 11470, loss = 1.9509
2024-10-30 21:13:24: [2024-10-30 21:13:24] iter = 11480, loss = 2.1293
2024-10-30 21:13:27: [2024-10-30 21:13:27] iter = 11490, loss = 2.0736
2024-10-30 21:13:31: [2024-10-30 21:13:31] iter = 11500, loss = 2.2470
2024-10-30 21:13:34: [2024-10-30 21:13:34] iter = 11510, loss = 2.0285
2024-10-30 21:13:38: [2024-10-30 21:13:38] iter = 11520, loss = 2.4535
2024-10-30 21:13:40: [2024-10-30 21:13:40] iter = 11530, loss = 1.9413
2024-10-30 21:13:43: [2024-10-30 21:13:43] iter = 11540, loss = 3.8601
2024-10-30 21:13:47: [2024-10-30 21:13:47] iter = 11550, loss = 2.8992
2024-10-30 21:13:50: [2024-10-30 21:13:50] iter = 11560, loss = 2.0415
2024-10-30 21:13:53: [2024-10-30 21:13:53] iter = 11570, loss = 1.9500
2024-10-30 21:13:58: [2024-10-30 21:13:58] iter = 11580, loss = 2.2274
2024-10-30 21:14:02: [2024-10-30 21:14:02] iter = 11590, loss = 3.4840
2024-10-30 21:14:06: [2024-10-30 21:14:06] iter = 11600, loss = 1.8323
2024-10-30 21:14:10: [2024-10-30 21:14:10] iter = 11610, loss = 2.4309
2024-10-30 21:14:14: [2024-10-30 21:14:14] iter = 11620, loss = 4.1307
2024-10-30 21:14:17: [2024-10-30 21:14:17] iter = 11630, loss = 2.0308
2024-10-30 21:14:20: [2024-10-30 21:14:20] iter = 11640, loss = 2.2112
2024-10-30 21:14:23: [2024-10-30 21:14:23] iter = 11650, loss = 2.3902
2024-10-30 21:14:26: [2024-10-30 21:14:26] iter = 11660, loss = 4.1245
2024-10-30 21:14:31: [2024-10-30 21:14:31] iter = 11670, loss = 2.1451
2024-10-30 21:14:34: [2024-10-30 21:14:34] iter = 11680, loss = 2.2661
2024-10-30 21:14:37: [2024-10-30 21:14:37] iter = 11690, loss = 2.7126
2024-10-30 21:14:41: [2024-10-30 21:14:41] iter = 11700, loss = 3.6391
2024-10-30 21:14:43: [2024-10-30 21:14:43] iter = 11710, loss = 2.0067
2024-10-30 21:14:46: [2024-10-30 21:14:46] iter = 11720, loss = 2.5641
2024-10-30 21:14:49: [2024-10-30 21:14:49] iter = 11730, loss = 2.4042
2024-10-30 21:14:54: [2024-10-30 21:14:54] iter = 11740, loss = 2.9548
2024-10-30 21:14:58: [2024-10-30 21:14:58] iter = 11750, loss = 1.9719
2024-10-30 21:15:01: [2024-10-30 21:15:01] iter = 11760, loss = 2.4820
2024-10-30 21:15:04: [2024-10-30 21:15:04] iter = 11770, loss = 2.0897
2024-10-30 21:15:07: [2024-10-30 21:15:07] iter = 11780, loss = 2.4516
2024-10-30 21:15:10: [2024-10-30 21:15:10] iter = 11790, loss = 4.2201
2024-10-30 21:15:14: [2024-10-30 21:15:14] iter = 11800, loss = 2.6687
2024-10-30 21:15:17: [2024-10-30 21:15:17] iter = 11810, loss = 2.8147
2024-10-30 21:15:21: [2024-10-30 21:15:21] iter = 11820, loss = 2.8362
2024-10-30 21:15:23: [2024-10-30 21:15:23] iter = 11830, loss = 2.0903
2024-10-30 21:15:27: [2024-10-30 21:15:27] iter = 11840, loss = 3.3309
2024-10-30 21:15:30: [2024-10-30 21:15:30] iter = 11850, loss = 2.3891
2024-10-30 21:15:34: [2024-10-30 21:15:34] iter = 11860, loss = 2.3040
2024-10-30 21:15:37: [2024-10-30 21:15:37] iter = 11870, loss = 3.0356
2024-10-30 21:15:41: [2024-10-30 21:15:41] iter = 11880, loss = 2.2143
2024-10-30 21:15:44: [2024-10-30 21:15:44] iter = 11890, loss = 2.3331
2024-10-30 21:15:48: [2024-10-30 21:15:48] iter = 11900, loss = 2.2690
2024-10-30 21:15:51: [2024-10-30 21:15:51] iter = 11910, loss = 2.3807
2024-10-30 21:15:54: [2024-10-30 21:15:54] iter = 11920, loss = 1.8348
2024-10-30 21:15:58: [2024-10-30 21:15:58] iter = 11930, loss = 2.0388
2024-10-30 21:16:02: [2024-10-30 21:16:02] iter = 11940, loss = 2.4812
2024-10-30 21:16:06: [2024-10-30 21:16:06] iter = 11950, loss = 2.5621
2024-10-30 21:16:09: [2024-10-30 21:16:09] iter = 11960, loss = 2.7860
2024-10-30 21:16:12: [2024-10-30 21:16:12] iter = 11970, loss = 2.4466
2024-10-30 21:16:15: [2024-10-30 21:16:15] iter = 11980, loss = 2.0060
2024-10-30 21:16:18: [2024-10-30 21:16:18] iter = 11990, loss = 1.7622
2024-10-30 21:16:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 21:16:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:16:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 82225}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:18:37: Evaluate 5 random ConvNet, ACCmean = 0.6118 ACCstd = 0.0039
-------------------------
2024-10-30 21:18:37: Evaluate 5 random ConvNet, SENmean = 0.5912 SENstd = 0.0039
-------------------------
2024-10-30 21:18:37: Evaluate 5 random ConvNet, SPEmean = 0.9603 SPEstd = 0.0004
-------------------------
2024-10-30 21:18:37: Evaluate 5 random ConvNet, F!mean = 0.5840 F!std = 0.0054
-------------------------
2024-10-30 21:18:37: Evaluate 5 random ConvNet, mean = 0.6118 std = 0.0039
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:18:37: [2024-10-30 21:18:37] iter = 12000, loss = 2.0134
2024-10-30 21:18:41: [2024-10-30 21:18:41] iter = 12010, loss = 1.9245
2024-10-30 21:18:45: [2024-10-30 21:18:45] iter = 12020, loss = 1.8434
2024-10-30 21:18:49: [2024-10-30 21:18:49] iter = 12030, loss = 2.7152
2024-10-30 21:18:52: [2024-10-30 21:18:52] iter = 12040, loss = 2.8033
2024-10-30 21:18:56: [2024-10-30 21:18:56] iter = 12050, loss = 2.0693
2024-10-30 21:19:00: [2024-10-30 21:19:00] iter = 12060, loss = 2.2916
2024-10-30 21:19:04: [2024-10-30 21:19:04] iter = 12070, loss = 2.4113
2024-10-30 21:19:07: [2024-10-30 21:19:07] iter = 12080, loss = 1.9438
2024-10-30 21:19:11: [2024-10-30 21:19:11] iter = 12090, loss = 1.8051
2024-10-30 21:19:15: [2024-10-30 21:19:15] iter = 12100, loss = 2.2713
2024-10-30 21:19:19: [2024-10-30 21:19:19] iter = 12110, loss = 1.9812
2024-10-30 21:19:23: [2024-10-30 21:19:23] iter = 12120, loss = 2.2130
2024-10-30 21:19:26: [2024-10-30 21:19:26] iter = 12130, loss = 3.0169
2024-10-30 21:19:31: [2024-10-30 21:19:31] iter = 12140, loss = 2.5636
2024-10-30 21:19:34: [2024-10-30 21:19:34] iter = 12150, loss = 3.1085
2024-10-30 21:19:37: [2024-10-30 21:19:37] iter = 12160, loss = 3.5534
2024-10-30 21:19:40: [2024-10-30 21:19:40] iter = 12170, loss = 1.9434
2024-10-30 21:19:43: [2024-10-30 21:19:43] iter = 12180, loss = 3.4501
2024-10-30 21:19:47: [2024-10-30 21:19:47] iter = 12190, loss = 2.2209
2024-10-30 21:19:50: [2024-10-30 21:19:50] iter = 12200, loss = 1.8193
2024-10-30 21:19:53: [2024-10-30 21:19:53] iter = 12210, loss = 3.2295
2024-10-30 21:19:55: [2024-10-30 21:19:55] iter = 12220, loss = 1.8056
2024-10-30 21:19:59: [2024-10-30 21:19:59] iter = 12230, loss = 2.0441
2024-10-30 21:20:02: [2024-10-30 21:20:02] iter = 12240, loss = 2.4320
2024-10-30 21:20:06: [2024-10-30 21:20:06] iter = 12250, loss = 1.8271
2024-10-30 21:20:10: [2024-10-30 21:20:10] iter = 12260, loss = 1.8229
2024-10-30 21:20:12: [2024-10-30 21:20:12] iter = 12270, loss = 2.2444
2024-10-30 21:20:15: [2024-10-30 21:20:15] iter = 12280, loss = 2.4125
2024-10-30 21:20:19: [2024-10-30 21:20:19] iter = 12290, loss = 2.2265
2024-10-30 21:20:22: [2024-10-30 21:20:22] iter = 12300, loss = 2.4496
2024-10-30 21:20:24: [2024-10-30 21:20:24] iter = 12310, loss = 2.4510
2024-10-30 21:20:27: [2024-10-30 21:20:27] iter = 12320, loss = 2.0705
2024-10-30 21:20:31: [2024-10-30 21:20:31] iter = 12330, loss = 4.3479
2024-10-30 21:20:34: [2024-10-30 21:20:34] iter = 12340, loss = 3.0077
2024-10-30 21:20:37: [2024-10-30 21:20:37] iter = 12350, loss = 1.9097
2024-10-30 21:20:41: [2024-10-30 21:20:41] iter = 12360, loss = 2.4018
2024-10-30 21:20:44: [2024-10-30 21:20:44] iter = 12370, loss = 3.4913
2024-10-30 21:20:48: [2024-10-30 21:20:48] iter = 12380, loss = 2.5640
2024-10-30 21:20:51: [2024-10-30 21:20:51] iter = 12390, loss = 2.0093
2024-10-30 21:20:55: [2024-10-30 21:20:55] iter = 12400, loss = 1.9033
2024-10-30 21:20:58: [2024-10-30 21:20:58] iter = 12410, loss = 2.7828
2024-10-30 21:21:01: [2024-10-30 21:21:01] iter = 12420, loss = 3.6657
2024-10-30 21:21:04: [2024-10-30 21:21:04] iter = 12430, loss = 2.4653
2024-10-30 21:21:08: [2024-10-30 21:21:08] iter = 12440, loss = 1.9660
2024-10-30 21:21:11: [2024-10-30 21:21:11] iter = 12450, loss = 2.9576
2024-10-30 21:21:14: [2024-10-30 21:21:14] iter = 12460, loss = 2.4271
2024-10-30 21:21:18: [2024-10-30 21:21:18] iter = 12470, loss = 2.0954
2024-10-30 21:21:22: [2024-10-30 21:21:22] iter = 12480, loss = 2.0066
2024-10-30 21:21:25: [2024-10-30 21:21:25] iter = 12490, loss = 2.1386
2024-10-30 21:21:29: [2024-10-30 21:21:29] iter = 12500, loss = 2.3190
2024-10-30 21:21:32: [2024-10-30 21:21:32] iter = 12510, loss = 1.9798
2024-10-30 21:21:36: [2024-10-30 21:21:36] iter = 12520, loss = 2.0898
2024-10-30 21:21:39: [2024-10-30 21:21:39] iter = 12530, loss = 2.3882
2024-10-30 21:21:41: [2024-10-30 21:21:41] iter = 12540, loss = 2.4428
2024-10-30 21:21:44: [2024-10-30 21:21:44] iter = 12550, loss = 2.1708
2024-10-30 21:21:47: [2024-10-30 21:21:47] iter = 12560, loss = 2.3611
2024-10-30 21:21:52: [2024-10-30 21:21:52] iter = 12570, loss = 1.8773
2024-10-30 21:21:56: [2024-10-30 21:21:56] iter = 12580, loss = 2.0835
2024-10-30 21:21:59: [2024-10-30 21:21:59] iter = 12590, loss = 2.3514
2024-10-30 21:22:02: [2024-10-30 21:22:02] iter = 12600, loss = 2.9065
2024-10-30 21:22:05: [2024-10-30 21:22:05] iter = 12610, loss = 2.0958
2024-10-30 21:22:07: [2024-10-30 21:22:07] iter = 12620, loss = 2.4639
2024-10-30 21:22:11: [2024-10-30 21:22:11] iter = 12630, loss = 2.5201
2024-10-30 21:22:15: [2024-10-30 21:22:15] iter = 12640, loss = 2.0809
2024-10-30 21:22:19: [2024-10-30 21:22:19] iter = 12650, loss = 2.4843
2024-10-30 21:22:24: [2024-10-30 21:22:24] iter = 12660, loss = 2.5275
2024-10-30 21:22:28: [2024-10-30 21:22:28] iter = 12670, loss = 1.9806
2024-10-30 21:22:32: [2024-10-30 21:22:32] iter = 12680, loss = 3.2166
2024-10-30 21:22:35: [2024-10-30 21:22:35] iter = 12690, loss = 2.6602
2024-10-30 21:22:38: [2024-10-30 21:22:38] iter = 12700, loss = 2.4176
2024-10-30 21:22:41: [2024-10-30 21:22:41] iter = 12710, loss = 2.3822
2024-10-30 21:22:44: [2024-10-30 21:22:44] iter = 12720, loss = 2.9298
2024-10-30 21:22:48: [2024-10-30 21:22:48] iter = 12730, loss = 2.1273
2024-10-30 21:22:51: [2024-10-30 21:22:51] iter = 12740, loss = 2.0981
2024-10-30 21:22:54: [2024-10-30 21:22:54] iter = 12750, loss = 2.4074
2024-10-30 21:22:58: [2024-10-30 21:22:58] iter = 12760, loss = 4.9573
2024-10-30 21:23:01: [2024-10-30 21:23:01] iter = 12770, loss = 1.9184
2024-10-30 21:23:06: [2024-10-30 21:23:06] iter = 12780, loss = 1.9026
2024-10-30 21:23:10: [2024-10-30 21:23:10] iter = 12790, loss = 3.0963
2024-10-30 21:23:14: [2024-10-30 21:23:14] iter = 12800, loss = 5.0823
2024-10-30 21:23:18: [2024-10-30 21:23:18] iter = 12810, loss = 2.6448
2024-10-30 21:23:22: [2024-10-30 21:23:22] iter = 12820, loss = 3.3700
2024-10-30 21:23:25: [2024-10-30 21:23:25] iter = 12830, loss = 3.2814
2024-10-30 21:23:29: [2024-10-30 21:23:29] iter = 12840, loss = 1.9138
2024-10-30 21:23:31: [2024-10-30 21:23:31] iter = 12850, loss = 2.7770
2024-10-30 21:23:33: [2024-10-30 21:23:33] iter = 12860, loss = 3.0848
2024-10-30 21:23:35: [2024-10-30 21:23:35] iter = 12870, loss = 2.4456
2024-10-30 21:23:39: [2024-10-30 21:23:39] iter = 12880, loss = 2.2516
2024-10-30 21:23:42: [2024-10-30 21:23:42] iter = 12890, loss = 2.2306
2024-10-30 21:23:45: [2024-10-30 21:23:45] iter = 12900, loss = 2.0102
2024-10-30 21:23:49: [2024-10-30 21:23:49] iter = 12910, loss = 2.2273
2024-10-30 21:23:51: [2024-10-30 21:23:51] iter = 12920, loss = 1.9904
2024-10-30 21:23:54: [2024-10-30 21:23:54] iter = 12930, loss = 3.8639
2024-10-30 21:23:58: [2024-10-30 21:23:58] iter = 12940, loss = 2.2540
2024-10-30 21:24:01: [2024-10-30 21:24:01] iter = 12950, loss = 3.1738
2024-10-30 21:24:04: [2024-10-30 21:24:04] iter = 12960, loss = 2.2960
2024-10-30 21:24:08: [2024-10-30 21:24:08] iter = 12970, loss = 2.4378
2024-10-30 21:24:11: [2024-10-30 21:24:11] iter = 12980, loss = 2.1927
2024-10-30 21:24:14: [2024-10-30 21:24:14] iter = 12990, loss = 1.8815
2024-10-30 21:24:18: [2024-10-30 21:24:18] iter = 13000, loss = 2.8009
2024-10-30 21:24:21: [2024-10-30 21:24:21] iter = 13010, loss = 1.8503
2024-10-30 21:24:24: [2024-10-30 21:24:24] iter = 13020, loss = 2.1128
2024-10-30 21:24:27: [2024-10-30 21:24:27] iter = 13030, loss = 2.3426
2024-10-30 21:24:31: [2024-10-30 21:24:31] iter = 13040, loss = 2.0973
2024-10-30 21:24:34: [2024-10-30 21:24:34] iter = 13050, loss = 1.9268
2024-10-30 21:24:37: [2024-10-30 21:24:37] iter = 13060, loss = 2.1668
2024-10-30 21:24:41: [2024-10-30 21:24:41] iter = 13070, loss = 1.9803
2024-10-30 21:24:45: [2024-10-30 21:24:45] iter = 13080, loss = 1.7858
2024-10-30 21:24:48: [2024-10-30 21:24:48] iter = 13090, loss = 1.9393
2024-10-30 21:24:51: [2024-10-30 21:24:51] iter = 13100, loss = 2.3978
2024-10-30 21:24:54: [2024-10-30 21:24:54] iter = 13110, loss = 2.9568
2024-10-30 21:24:57: [2024-10-30 21:24:57] iter = 13120, loss = 2.0426
2024-10-30 21:25:01: [2024-10-30 21:25:01] iter = 13130, loss = 3.3344
2024-10-30 21:25:04: [2024-10-30 21:25:04] iter = 13140, loss = 4.1515
2024-10-30 21:25:08: [2024-10-30 21:25:08] iter = 13150, loss = 2.7491
2024-10-30 21:25:11: [2024-10-30 21:25:11] iter = 13160, loss = 3.7285
2024-10-30 21:25:15: [2024-10-30 21:25:15] iter = 13170, loss = 3.7263
2024-10-30 21:25:19: [2024-10-30 21:25:19] iter = 13180, loss = 1.8271
2024-10-30 21:25:22: [2024-10-30 21:25:22] iter = 13190, loss = 1.8901
2024-10-30 21:25:25: [2024-10-30 21:25:25] iter = 13200, loss = 2.2680
2024-10-30 21:25:27: [2024-10-30 21:25:27] iter = 13210, loss = 1.7778
2024-10-30 21:25:30: [2024-10-30 21:25:30] iter = 13220, loss = 2.0192
2024-10-30 21:25:34: [2024-10-30 21:25:34] iter = 13230, loss = 2.0392
2024-10-30 21:25:37: [2024-10-30 21:25:37] iter = 13240, loss = 2.6888
2024-10-30 21:25:40: [2024-10-30 21:25:40] iter = 13250, loss = 2.0839
2024-10-30 21:25:43: [2024-10-30 21:25:43] iter = 13260, loss = 4.2120
2024-10-30 21:25:46: [2024-10-30 21:25:46] iter = 13270, loss = 1.9759
2024-10-30 21:25:49: [2024-10-30 21:25:49] iter = 13280, loss = 2.1132
2024-10-30 21:25:52: [2024-10-30 21:25:52] iter = 13290, loss = 2.4231
2024-10-30 21:25:56: [2024-10-30 21:25:56] iter = 13300, loss = 2.0635
2024-10-30 21:25:59: [2024-10-30 21:25:59] iter = 13310, loss = 2.2775
2024-10-30 21:26:02: [2024-10-30 21:26:02] iter = 13320, loss = 2.7046
2024-10-30 21:26:04: [2024-10-30 21:26:04] iter = 13330, loss = 3.7849
2024-10-30 21:26:06: [2024-10-30 21:26:06] iter = 13340, loss = 3.0976
2024-10-30 21:26:09: [2024-10-30 21:26:09] iter = 13350, loss = 2.3740
2024-10-30 21:26:13: [2024-10-30 21:26:13] iter = 13360, loss = 2.8647
2024-10-30 21:26:16: [2024-10-30 21:26:16] iter = 13370, loss = 1.7627
2024-10-30 21:26:19: [2024-10-30 21:26:19] iter = 13380, loss = 2.2294
2024-10-30 21:26:23: [2024-10-30 21:26:23] iter = 13390, loss = 1.9379
2024-10-30 21:26:27: [2024-10-30 21:26:27] iter = 13400, loss = 2.0949
2024-10-30 21:26:31: [2024-10-30 21:26:31] iter = 13410, loss = 1.8397
2024-10-30 21:26:35: [2024-10-30 21:26:35] iter = 13420, loss = 2.1729
2024-10-30 21:26:38: [2024-10-30 21:26:38] iter = 13430, loss = 2.0653
2024-10-30 21:26:41: [2024-10-30 21:26:41] iter = 13440, loss = 1.7373
2024-10-30 21:26:44: [2024-10-30 21:26:44] iter = 13450, loss = 2.1604
2024-10-30 21:26:46: [2024-10-30 21:26:46] iter = 13460, loss = 2.2625
2024-10-30 21:26:50: [2024-10-30 21:26:50] iter = 13470, loss = 2.9262
2024-10-30 21:26:54: [2024-10-30 21:26:54] iter = 13480, loss = 2.2743
2024-10-30 21:26:58: [2024-10-30 21:26:58] iter = 13490, loss = 2.0536
2024-10-30 21:27:01: [2024-10-30 21:27:01] iter = 13500, loss = 2.4253
2024-10-30 21:27:05: [2024-10-30 21:27:05] iter = 13510, loss = 3.2200
2024-10-30 21:27:08: [2024-10-30 21:27:08] iter = 13520, loss = 2.2540
2024-10-30 21:27:11: [2024-10-30 21:27:11] iter = 13530, loss = 2.1214
2024-10-30 21:27:14: [2024-10-30 21:27:14] iter = 13540, loss = 2.2675
2024-10-30 21:27:18: [2024-10-30 21:27:18] iter = 13550, loss = 3.2678
2024-10-30 21:27:22: [2024-10-30 21:27:21] iter = 13560, loss = 2.1544
2024-10-30 21:27:25: [2024-10-30 21:27:25] iter = 13570, loss = 4.5568
2024-10-30 21:27:29: [2024-10-30 21:27:29] iter = 13580, loss = 2.1144
2024-10-30 21:27:32: [2024-10-30 21:27:32] iter = 13590, loss = 2.1723
2024-10-30 21:27:36: [2024-10-30 21:27:36] iter = 13600, loss = 1.9631
2024-10-30 21:27:39: [2024-10-30 21:27:39] iter = 13610, loss = 2.7693
2024-10-30 21:27:42: [2024-10-30 21:27:42] iter = 13620, loss = 2.2568
2024-10-30 21:27:45: [2024-10-30 21:27:45] iter = 13630, loss = 1.9582
2024-10-30 21:27:49: [2024-10-30 21:27:49] iter = 13640, loss = 2.1204
2024-10-30 21:27:53: [2024-10-30 21:27:53] iter = 13650, loss = 2.0694
2024-10-30 21:27:56: [2024-10-30 21:27:56] iter = 13660, loss = 2.1469
2024-10-30 21:27:58: [2024-10-30 21:27:58] iter = 13670, loss = 1.9910
2024-10-30 21:28:01: [2024-10-30 21:28:01] iter = 13680, loss = 2.3329
2024-10-30 21:28:03: [2024-10-30 21:28:03] iter = 13690, loss = 1.8626
2024-10-30 21:28:05: [2024-10-30 21:28:05] iter = 13700, loss = 3.9235
2024-10-30 21:28:08: [2024-10-30 21:28:08] iter = 13710, loss = 2.2437
2024-10-30 21:28:11: [2024-10-30 21:28:11] iter = 13720, loss = 3.1311
2024-10-30 21:28:14: [2024-10-30 21:28:14] iter = 13730, loss = 2.0380
2024-10-30 21:28:17: [2024-10-30 21:28:17] iter = 13740, loss = 3.2455
2024-10-30 21:28:21: [2024-10-30 21:28:21] iter = 13750, loss = 2.2980
2024-10-30 21:28:25: [2024-10-30 21:28:25] iter = 13760, loss = 2.3804
2024-10-30 21:28:29: [2024-10-30 21:28:29] iter = 13770, loss = 1.6935
2024-10-30 21:28:33: [2024-10-30 21:28:33] iter = 13780, loss = 2.3924
2024-10-30 21:28:37: [2024-10-30 21:28:37] iter = 13790, loss = 5.5237
2024-10-30 21:28:42: [2024-10-30 21:28:41] iter = 13800, loss = 2.1978
2024-10-30 21:28:45: [2024-10-30 21:28:45] iter = 13810, loss = 2.4411
2024-10-30 21:28:49: [2024-10-30 21:28:49] iter = 13820, loss = 2.5950
2024-10-30 21:28:52: [2024-10-30 21:28:52] iter = 13830, loss = 2.2868
2024-10-30 21:28:56: [2024-10-30 21:28:56] iter = 13840, loss = 2.1504
2024-10-30 21:28:59: [2024-10-30 21:28:59] iter = 13850, loss = 2.6169
2024-10-30 21:29:02: [2024-10-30 21:29:02] iter = 13860, loss = 2.1327
2024-10-30 21:29:06: [2024-10-30 21:29:06] iter = 13870, loss = 2.1866
2024-10-30 21:29:09: [2024-10-30 21:29:09] iter = 13880, loss = 1.9588
2024-10-30 21:29:13: [2024-10-30 21:29:13] iter = 13890, loss = 2.0568
2024-10-30 21:29:17: [2024-10-30 21:29:17] iter = 13900, loss = 1.7563
2024-10-30 21:29:20: [2024-10-30 21:29:20] iter = 13910, loss = 2.4246
2024-10-30 21:29:24: [2024-10-30 21:29:24] iter = 13920, loss = 2.1959
2024-10-30 21:29:27: [2024-10-30 21:29:27] iter = 13930, loss = 2.0446
2024-10-30 21:29:30: [2024-10-30 21:29:30] iter = 13940, loss = 4.4742
2024-10-30 21:29:35: [2024-10-30 21:29:35] iter = 13950, loss = 1.9373
2024-10-30 21:29:38: [2024-10-30 21:29:38] iter = 13960, loss = 2.2648
2024-10-30 21:29:42: [2024-10-30 21:29:42] iter = 13970, loss = 1.9079
2024-10-30 21:29:46: [2024-10-30 21:29:46] iter = 13980, loss = 2.1555
2024-10-30 21:29:51: [2024-10-30 21:29:50] iter = 13990, loss = 2.3180
2024-10-30 21:29:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 21:29:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:29:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 93982}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:32:04: Evaluate 5 random ConvNet, ACCmean = 0.5902 ACCstd = 0.0060
-------------------------
2024-10-30 21:32:04: Evaluate 5 random ConvNet, SENmean = 0.5823 SENstd = 0.0047
-------------------------
2024-10-30 21:32:04: Evaluate 5 random ConvNet, SPEmean = 0.9584 SPEstd = 0.0006
-------------------------
2024-10-30 21:32:04: Evaluate 5 random ConvNet, F!mean = 0.5693 F!std = 0.0044
-------------------------
2024-10-30 21:32:04: Evaluate 5 random ConvNet, mean = 0.5902 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:32:04: [2024-10-30 21:32:04] iter = 14000, loss = 1.8888
2024-10-30 21:32:08: [2024-10-30 21:32:08] iter = 14010, loss = 1.7395
2024-10-30 21:32:12: [2024-10-30 21:32:12] iter = 14020, loss = 1.9138
2024-10-30 21:32:15: [2024-10-30 21:32:15] iter = 14030, loss = 2.2595
2024-10-30 21:32:18: [2024-10-30 21:32:18] iter = 14040, loss = 1.8667
2024-10-30 21:32:22: [2024-10-30 21:32:22] iter = 14050, loss = 2.0206
2024-10-30 21:32:25: [2024-10-30 21:32:25] iter = 14060, loss = 2.3928
2024-10-30 21:32:29: [2024-10-30 21:32:29] iter = 14070, loss = 2.7260
2024-10-30 21:32:32: [2024-10-30 21:32:32] iter = 14080, loss = 2.3003
2024-10-30 21:32:35: [2024-10-30 21:32:35] iter = 14090, loss = 2.0606
2024-10-30 21:32:39: [2024-10-30 21:32:39] iter = 14100, loss = 2.4026
2024-10-30 21:32:42: [2024-10-30 21:32:42] iter = 14110, loss = 2.3913
2024-10-30 21:32:45: [2024-10-30 21:32:45] iter = 14120, loss = 2.6111
2024-10-30 21:32:48: [2024-10-30 21:32:48] iter = 14130, loss = 2.1904
2024-10-30 21:32:51: [2024-10-30 21:32:51] iter = 14140, loss = 2.6753
2024-10-30 21:32:54: [2024-10-30 21:32:54] iter = 14150, loss = 3.5620
2024-10-30 21:32:57: [2024-10-30 21:32:57] iter = 14160, loss = 3.3506
2024-10-30 21:33:00: [2024-10-30 21:33:00] iter = 14170, loss = 2.0357
2024-10-30 21:33:03: [2024-10-30 21:33:03] iter = 14180, loss = 2.9836
2024-10-30 21:33:07: [2024-10-30 21:33:07] iter = 14190, loss = 2.2788
2024-10-30 21:33:10: [2024-10-30 21:33:10] iter = 14200, loss = 2.4351
2024-10-30 21:33:13: [2024-10-30 21:33:13] iter = 14210, loss = 2.9377
2024-10-30 21:33:17: [2024-10-30 21:33:17] iter = 14220, loss = 2.0346
2024-10-30 21:33:21: [2024-10-30 21:33:21] iter = 14230, loss = 2.2163
2024-10-30 21:33:24: [2024-10-30 21:33:24] iter = 14240, loss = 2.5356
2024-10-30 21:33:27: [2024-10-30 21:33:27] iter = 14250, loss = 2.2198
2024-10-30 21:33:30: [2024-10-30 21:33:30] iter = 14260, loss = 2.3754
2024-10-30 21:33:34: [2024-10-30 21:33:34] iter = 14270, loss = 2.4825
2024-10-30 21:33:38: [2024-10-30 21:33:38] iter = 14280, loss = 1.9330
2024-10-30 21:33:41: [2024-10-30 21:33:41] iter = 14290, loss = 2.9848
2024-10-30 21:33:44: [2024-10-30 21:33:44] iter = 14300, loss = 2.4901
2024-10-30 21:33:47: [2024-10-30 21:33:47] iter = 14310, loss = 3.2713
2024-10-30 21:33:51: [2024-10-30 21:33:51] iter = 14320, loss = 1.8638
2024-10-30 21:33:55: [2024-10-30 21:33:55] iter = 14330, loss = 2.0632
2024-10-30 21:33:58: [2024-10-30 21:33:58] iter = 14340, loss = 1.9932
2024-10-30 21:34:01: [2024-10-30 21:34:01] iter = 14350, loss = 2.7076
2024-10-30 21:34:04: [2024-10-30 21:34:04] iter = 14360, loss = 1.8310
2024-10-30 21:34:07: [2024-10-30 21:34:07] iter = 14370, loss = 2.0841
2024-10-30 21:34:10: [2024-10-30 21:34:10] iter = 14380, loss = 2.0963
2024-10-30 21:34:13: [2024-10-30 21:34:13] iter = 14390, loss = 2.1140
2024-10-30 21:34:18: [2024-10-30 21:34:18] iter = 14400, loss = 2.0599
2024-10-30 21:34:21: [2024-10-30 21:34:21] iter = 14410, loss = 1.9660
2024-10-30 21:34:25: [2024-10-30 21:34:25] iter = 14420, loss = 3.1658
2024-10-30 21:34:28: [2024-10-30 21:34:28] iter = 14430, loss = 2.3613
2024-10-30 21:34:30: [2024-10-30 21:34:30] iter = 14440, loss = 2.0913
2024-10-30 21:34:33: [2024-10-30 21:34:33] iter = 14450, loss = 2.3562
2024-10-30 21:34:37: [2024-10-30 21:34:37] iter = 14460, loss = 2.4330
2024-10-30 21:34:39: [2024-10-30 21:34:39] iter = 14470, loss = 1.8340
2024-10-30 21:34:43: [2024-10-30 21:34:43] iter = 14480, loss = 3.4600
2024-10-30 21:34:47: [2024-10-30 21:34:47] iter = 14490, loss = 1.8998
2024-10-30 21:34:51: [2024-10-30 21:34:51] iter = 14500, loss = 1.7183
2024-10-30 21:34:54: [2024-10-30 21:34:54] iter = 14510, loss = 1.8601
2024-10-30 21:34:57: [2024-10-30 21:34:57] iter = 14520, loss = 2.1932
2024-10-30 21:35:00: [2024-10-30 21:35:00] iter = 14530, loss = 2.4666
2024-10-30 21:35:03: [2024-10-30 21:35:03] iter = 14540, loss = 1.7787
2024-10-30 21:35:07: [2024-10-30 21:35:07] iter = 14550, loss = 2.4363
2024-10-30 21:35:10: [2024-10-30 21:35:10] iter = 14560, loss = 2.4485
2024-10-30 21:35:13: [2024-10-30 21:35:13] iter = 14570, loss = 2.1529
2024-10-30 21:35:16: [2024-10-30 21:35:16] iter = 14580, loss = 2.6465
2024-10-30 21:35:20: [2024-10-30 21:35:20] iter = 14590, loss = 2.3152
2024-10-30 21:35:22: [2024-10-30 21:35:22] iter = 14600, loss = 1.9524
2024-10-30 21:35:25: [2024-10-30 21:35:25] iter = 14610, loss = 2.4309
2024-10-30 21:35:29: [2024-10-30 21:35:29] iter = 14620, loss = 3.0543
2024-10-30 21:35:33: [2024-10-30 21:35:33] iter = 14630, loss = 2.5031
2024-10-30 21:35:36: [2024-10-30 21:35:36] iter = 14640, loss = 2.0724
2024-10-30 21:35:40: [2024-10-30 21:35:40] iter = 14650, loss = 2.0264
2024-10-30 21:35:43: [2024-10-30 21:35:43] iter = 14660, loss = 2.2549
2024-10-30 21:35:47: [2024-10-30 21:35:47] iter = 14670, loss = 2.5821
2024-10-30 21:35:50: [2024-10-30 21:35:50] iter = 14680, loss = 3.0987
2024-10-30 21:35:54: [2024-10-30 21:35:54] iter = 14690, loss = 2.2840
2024-10-30 21:35:57: [2024-10-30 21:35:57] iter = 14700, loss = 2.0037
2024-10-30 21:36:01: [2024-10-30 21:36:01] iter = 14710, loss = 2.1740
2024-10-30 21:36:04: [2024-10-30 21:36:04] iter = 14720, loss = 2.3472
2024-10-30 21:36:08: [2024-10-30 21:36:08] iter = 14730, loss = 2.1202
2024-10-30 21:36:11: [2024-10-30 21:36:11] iter = 14740, loss = 2.5494
2024-10-30 21:36:15: [2024-10-30 21:36:15] iter = 14750, loss = 2.0201
2024-10-30 21:36:17: [2024-10-30 21:36:17] iter = 14760, loss = 2.0563
2024-10-30 21:36:20: [2024-10-30 21:36:20] iter = 14770, loss = 3.3239
2024-10-30 21:36:24: [2024-10-30 21:36:24] iter = 14780, loss = 8.6622
2024-10-30 21:36:27: [2024-10-30 21:36:27] iter = 14790, loss = 2.4093
2024-10-30 21:36:31: [2024-10-30 21:36:31] iter = 14800, loss = 2.3746
2024-10-30 21:36:34: [2024-10-30 21:36:34] iter = 14810, loss = 2.4590
2024-10-30 21:36:37: [2024-10-30 21:36:37] iter = 14820, loss = 1.8006
2024-10-30 21:36:41: [2024-10-30 21:36:41] iter = 14830, loss = 2.1827
2024-10-30 21:36:45: [2024-10-30 21:36:45] iter = 14840, loss = 2.1232
2024-10-30 21:36:49: [2024-10-30 21:36:49] iter = 14850, loss = 2.1969
2024-10-30 21:36:53: [2024-10-30 21:36:53] iter = 14860, loss = 4.3354
2024-10-30 21:36:56: [2024-10-30 21:36:56] iter = 14870, loss = 2.1711
2024-10-30 21:36:59: [2024-10-30 21:36:59] iter = 14880, loss = 3.3083
2024-10-30 21:37:03: [2024-10-30 21:37:03] iter = 14890, loss = 2.2873
2024-10-30 21:37:07: [2024-10-30 21:37:07] iter = 14900, loss = 2.7812
2024-10-30 21:37:10: [2024-10-30 21:37:10] iter = 14910, loss = 1.9877
2024-10-30 21:37:14: [2024-10-30 21:37:14] iter = 14920, loss = 2.3884
2024-10-30 21:37:17: [2024-10-30 21:37:17] iter = 14930, loss = 2.8942
2024-10-30 21:37:21: [2024-10-30 21:37:21] iter = 14940, loss = 2.7809
2024-10-30 21:37:25: [2024-10-30 21:37:25] iter = 14950, loss = 2.3730
2024-10-30 21:37:29: [2024-10-30 21:37:29] iter = 14960, loss = 2.5627
2024-10-30 21:37:33: [2024-10-30 21:37:33] iter = 14970, loss = 2.3685
2024-10-30 21:37:38: [2024-10-30 21:37:38] iter = 14980, loss = 2.3921
2024-10-30 21:37:42: [2024-10-30 21:37:42] iter = 14990, loss = 2.3519
2024-10-30 21:37:46: [2024-10-30 21:37:46] iter = 15000, loss = 2.3764
2024-10-30 21:37:50: [2024-10-30 21:37:50] iter = 15010, loss = 2.8466
2024-10-30 21:37:52: [2024-10-30 21:37:52] iter = 15020, loss = 1.9835
2024-10-30 21:37:54: [2024-10-30 21:37:54] iter = 15030, loss = 2.1479
2024-10-30 21:37:57: [2024-10-30 21:37:57] iter = 15040, loss = 2.2556
2024-10-30 21:38:01: [2024-10-30 21:38:01] iter = 15050, loss = 2.7582
2024-10-30 21:38:06: [2024-10-30 21:38:06] iter = 15060, loss = 3.8281
2024-10-30 21:38:09: [2024-10-30 21:38:09] iter = 15070, loss = 1.9246
2024-10-30 21:38:11: [2024-10-30 21:38:11] iter = 15080, loss = 2.3730
2024-10-30 21:38:15: [2024-10-30 21:38:15] iter = 15090, loss = 2.0906
2024-10-30 21:38:18: [2024-10-30 21:38:18] iter = 15100, loss = 2.1681
2024-10-30 21:38:23: [2024-10-30 21:38:22] iter = 15110, loss = 2.1308
2024-10-30 21:38:25: [2024-10-30 21:38:25] iter = 15120, loss = 2.3404
2024-10-30 21:38:29: [2024-10-30 21:38:29] iter = 15130, loss = 1.9049
2024-10-30 21:38:33: [2024-10-30 21:38:33] iter = 15140, loss = 1.9214
2024-10-30 21:38:37: [2024-10-30 21:38:37] iter = 15150, loss = 2.9019
2024-10-30 21:38:40: [2024-10-30 21:38:40] iter = 15160, loss = 2.0640
2024-10-30 21:38:43: [2024-10-30 21:38:43] iter = 15170, loss = 2.4107
2024-10-30 21:38:46: [2024-10-30 21:38:46] iter = 15180, loss = 3.3140
2024-10-30 21:38:49: [2024-10-30 21:38:49] iter = 15190, loss = 3.5687
2024-10-30 21:38:52: [2024-10-30 21:38:52] iter = 15200, loss = 2.2247
2024-10-30 21:38:55: [2024-10-30 21:38:55] iter = 15210, loss = 2.3022
2024-10-30 21:38:57: [2024-10-30 21:38:57] iter = 15220, loss = 2.1171
2024-10-30 21:38:59: [2024-10-30 21:38:59] iter = 15230, loss = 2.2036
2024-10-30 21:39:02: [2024-10-30 21:39:02] iter = 15240, loss = 1.7894
2024-10-30 21:39:05: [2024-10-30 21:39:05] iter = 15250, loss = 1.8596
2024-10-30 21:39:08: [2024-10-30 21:39:08] iter = 15260, loss = 2.5417
2024-10-30 21:39:10: [2024-10-30 21:39:10] iter = 15270, loss = 2.1936
2024-10-30 21:39:14: [2024-10-30 21:39:14] iter = 15280, loss = 2.1257
2024-10-30 21:39:17: [2024-10-30 21:39:17] iter = 15290, loss = 1.7478
2024-10-30 21:39:21: [2024-10-30 21:39:21] iter = 15300, loss = 1.9436
2024-10-30 21:39:24: [2024-10-30 21:39:24] iter = 15310, loss = 2.2699
2024-10-30 21:39:27: [2024-10-30 21:39:27] iter = 15320, loss = 2.1129
2024-10-30 21:39:31: [2024-10-30 21:39:31] iter = 15330, loss = 2.4773
2024-10-30 21:39:35: [2024-10-30 21:39:35] iter = 15340, loss = 2.3254
2024-10-30 21:39:38: [2024-10-30 21:39:38] iter = 15350, loss = 2.1969
2024-10-30 21:39:42: [2024-10-30 21:39:42] iter = 15360, loss = 2.3017
2024-10-30 21:39:45: [2024-10-30 21:39:45] iter = 15370, loss = 2.3794
2024-10-30 21:39:49: [2024-10-30 21:39:49] iter = 15380, loss = 3.1304
2024-10-30 21:39:53: [2024-10-30 21:39:53] iter = 15390, loss = 2.3094
2024-10-30 21:39:56: [2024-10-30 21:39:56] iter = 15400, loss = 3.1826
2024-10-30 21:40:00: [2024-10-30 21:40:00] iter = 15410, loss = 2.6284
2024-10-30 21:40:03: [2024-10-30 21:40:03] iter = 15420, loss = 2.3664
2024-10-30 21:40:07: [2024-10-30 21:40:07] iter = 15430, loss = 1.9774
2024-10-30 21:40:11: [2024-10-30 21:40:11] iter = 15440, loss = 2.0261
2024-10-30 21:40:14: [2024-10-30 21:40:14] iter = 15450, loss = 2.2386
2024-10-30 21:40:17: [2024-10-30 21:40:17] iter = 15460, loss = 1.8026
2024-10-30 21:40:21: [2024-10-30 21:40:21] iter = 15470, loss = 3.8760
2024-10-30 21:40:24: [2024-10-30 21:40:24] iter = 15480, loss = 3.7299
2024-10-30 21:40:27: [2024-10-30 21:40:27] iter = 15490, loss = 1.9812
2024-10-30 21:40:30: [2024-10-30 21:40:30] iter = 15500, loss = 1.8132
2024-10-30 21:40:34: [2024-10-30 21:40:34] iter = 15510, loss = 2.7444
2024-10-30 21:40:37: [2024-10-30 21:40:37] iter = 15520, loss = 3.5997
2024-10-30 21:40:41: [2024-10-30 21:40:41] iter = 15530, loss = 3.2310
2024-10-30 21:40:45: [2024-10-30 21:40:45] iter = 15540, loss = 2.0986
2024-10-30 21:40:49: [2024-10-30 21:40:49] iter = 15550, loss = 1.9908
2024-10-30 21:40:52: [2024-10-30 21:40:52] iter = 15560, loss = 4.8732
2024-10-30 21:40:55: [2024-10-30 21:40:55] iter = 15570, loss = 2.0086
2024-10-30 21:40:58: [2024-10-30 21:40:58] iter = 15580, loss = 1.6671
2024-10-30 21:41:01: [2024-10-30 21:41:01] iter = 15590, loss = 3.6273
2024-10-30 21:41:05: [2024-10-30 21:41:05] iter = 15600, loss = 2.0486
2024-10-30 21:41:08: [2024-10-30 21:41:08] iter = 15610, loss = 2.0225
2024-10-30 21:41:12: [2024-10-30 21:41:12] iter = 15620, loss = 2.0068
2024-10-30 21:41:15: [2024-10-30 21:41:15] iter = 15630, loss = 2.4037
2024-10-30 21:41:19: [2024-10-30 21:41:19] iter = 15640, loss = 2.2010
2024-10-30 21:41:23: [2024-10-30 21:41:23] iter = 15650, loss = 2.0633
2024-10-30 21:41:27: [2024-10-30 21:41:27] iter = 15660, loss = 2.6367
2024-10-30 21:41:30: [2024-10-30 21:41:30] iter = 15670, loss = 2.6295
2024-10-30 21:41:34: [2024-10-30 21:41:34] iter = 15680, loss = 2.5575
2024-10-30 21:41:38: [2024-10-30 21:41:38] iter = 15690, loss = 2.5591
2024-10-30 21:41:41: [2024-10-30 21:41:41] iter = 15700, loss = 2.2237
2024-10-30 21:41:44: [2024-10-30 21:41:44] iter = 15710, loss = 2.6917
2024-10-30 21:41:48: [2024-10-30 21:41:48] iter = 15720, loss = 3.0176
2024-10-30 21:41:52: [2024-10-30 21:41:52] iter = 15730, loss = 2.3277
2024-10-30 21:41:55: [2024-10-30 21:41:55] iter = 15740, loss = 1.9167
2024-10-30 21:41:59: [2024-10-30 21:41:59] iter = 15750, loss = 2.4012
2024-10-30 21:42:02: [2024-10-30 21:42:02] iter = 15760, loss = 2.5180
2024-10-30 21:42:05: [2024-10-30 21:42:05] iter = 15770, loss = 2.1946
2024-10-30 21:42:08: [2024-10-30 21:42:08] iter = 15780, loss = 2.3506
2024-10-30 21:42:12: [2024-10-30 21:42:12] iter = 15790, loss = 2.1184
2024-10-30 21:42:17: [2024-10-30 21:42:17] iter = 15800, loss = 2.4213
2024-10-30 21:42:20: [2024-10-30 21:42:20] iter = 15810, loss = 2.5110
2024-10-30 21:42:23: [2024-10-30 21:42:23] iter = 15820, loss = 2.1822
2024-10-30 21:42:26: [2024-10-30 21:42:26] iter = 15830, loss = 2.0423
2024-10-30 21:42:29: [2024-10-30 21:42:29] iter = 15840, loss = 2.7109
2024-10-30 21:42:34: [2024-10-30 21:42:34] iter = 15850, loss = 2.3575
2024-10-30 21:42:40: [2024-10-30 21:42:40] iter = 15860, loss = 1.9733
2024-10-30 21:42:46: [2024-10-30 21:42:46] iter = 15870, loss = 1.7988
2024-10-30 21:42:51: [2024-10-30 21:42:51] iter = 15880, loss = 2.5309
2024-10-30 21:42:55: [2024-10-30 21:42:55] iter = 15890, loss = 2.3399
2024-10-30 21:42:59: [2024-10-30 21:42:59] iter = 15900, loss = 1.8834
2024-10-30 21:43:04: [2024-10-30 21:43:04] iter = 15910, loss = 2.4217
2024-10-30 21:43:09: [2024-10-30 21:43:09] iter = 15920, loss = 1.9971
2024-10-30 21:43:14: [2024-10-30 21:43:14] iter = 15930, loss = 3.1889
2024-10-30 21:43:18: [2024-10-30 21:43:18] iter = 15940, loss = 2.6887
2024-10-30 21:43:23: [2024-10-30 21:43:23] iter = 15950, loss = 2.3935
2024-10-30 21:43:29: [2024-10-30 21:43:29] iter = 15960, loss = 4.1553
2024-10-30 21:43:33: [2024-10-30 21:43:33] iter = 15970, loss = 2.9852
2024-10-30 21:43:37: [2024-10-30 21:43:37] iter = 15980, loss = 2.5124
2024-10-30 21:43:41: [2024-10-30 21:43:41] iter = 15990, loss = 2.0334
2024-10-30 21:43:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 21:43:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:43:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 25398}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:46:08: Evaluate 5 random ConvNet, ACCmean = 0.6018 ACCstd = 0.0019
-------------------------
2024-10-30 21:46:08: Evaluate 5 random ConvNet, SENmean = 0.5864 SENstd = 0.0034
-------------------------
2024-10-30 21:46:08: Evaluate 5 random ConvNet, SPEmean = 0.9594 SPEstd = 0.0002
-------------------------
2024-10-30 21:46:08: Evaluate 5 random ConvNet, F!mean = 0.5766 F!std = 0.0023
-------------------------
2024-10-30 21:46:08: Evaluate 5 random ConvNet, mean = 0.6018 std = 0.0019
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:46:09: [2024-10-30 21:46:09] iter = 16000, loss = 2.1868
2024-10-30 21:46:13: [2024-10-30 21:46:13] iter = 16010, loss = 2.1015
2024-10-30 21:46:17: [2024-10-30 21:46:17] iter = 16020, loss = 3.2806
2024-10-30 21:46:21: [2024-10-30 21:46:21] iter = 16030, loss = 2.8993
2024-10-30 21:46:26: [2024-10-30 21:46:26] iter = 16040, loss = 1.9946
2024-10-30 21:46:30: [2024-10-30 21:46:30] iter = 16050, loss = 3.1404
2024-10-30 21:46:34: [2024-10-30 21:46:34] iter = 16060, loss = 1.9387
2024-10-30 21:46:39: [2024-10-30 21:46:39] iter = 16070, loss = 2.5978
2024-10-30 21:46:42: [2024-10-30 21:46:42] iter = 16080, loss = 2.9520
2024-10-30 21:46:45: [2024-10-30 21:46:45] iter = 16090, loss = 1.8464
2024-10-30 21:46:48: [2024-10-30 21:46:48] iter = 16100, loss = 2.5580
2024-10-30 21:46:52: [2024-10-30 21:46:52] iter = 16110, loss = 1.8845
2024-10-30 21:46:55: [2024-10-30 21:46:55] iter = 16120, loss = 3.4781
2024-10-30 21:46:58: [2024-10-30 21:46:58] iter = 16130, loss = 1.8649
2024-10-30 21:47:00: [2024-10-30 21:47:00] iter = 16140, loss = 1.9592
2024-10-30 21:47:04: [2024-10-30 21:47:04] iter = 16150, loss = 1.9827
2024-10-30 21:47:07: [2024-10-30 21:47:07] iter = 16160, loss = 3.0187
2024-10-30 21:47:09: [2024-10-30 21:47:09] iter = 16170, loss = 2.0605
2024-10-30 21:47:13: [2024-10-30 21:47:13] iter = 16180, loss = 1.9271
2024-10-30 21:47:16: [2024-10-30 21:47:16] iter = 16190, loss = 2.5867
2024-10-30 21:47:20: [2024-10-30 21:47:20] iter = 16200, loss = 1.9900
2024-10-30 21:47:22: [2024-10-30 21:47:22] iter = 16210, loss = 2.5619
2024-10-30 21:47:26: [2024-10-30 21:47:26] iter = 16220, loss = 1.9623
2024-10-30 21:47:29: [2024-10-30 21:47:29] iter = 16230, loss = 4.0807
2024-10-30 21:47:32: [2024-10-30 21:47:32] iter = 16240, loss = 2.0346
2024-10-30 21:47:35: [2024-10-30 21:47:35] iter = 16250, loss = 2.7281
2024-10-30 21:47:38: [2024-10-30 21:47:38] iter = 16260, loss = 2.1371
2024-10-30 21:47:42: [2024-10-30 21:47:42] iter = 16270, loss = 1.9784
2024-10-30 21:47:45: [2024-10-30 21:47:45] iter = 16280, loss = 2.1443
2024-10-30 21:47:48: [2024-10-30 21:47:48] iter = 16290, loss = 2.0223
2024-10-30 21:47:51: [2024-10-30 21:47:51] iter = 16300, loss = 2.4767
2024-10-30 21:47:55: [2024-10-30 21:47:55] iter = 16310, loss = 3.4341
2024-10-30 21:47:59: [2024-10-30 21:47:59] iter = 16320, loss = 4.9567
2024-10-30 21:48:03: [2024-10-30 21:48:03] iter = 16330, loss = 2.7006
2024-10-30 21:48:07: [2024-10-30 21:48:07] iter = 16340, loss = 1.9853
2024-10-30 21:48:10: [2024-10-30 21:48:10] iter = 16350, loss = 2.0138
2024-10-30 21:48:14: [2024-10-30 21:48:14] iter = 16360, loss = 2.1850
2024-10-30 21:48:18: [2024-10-30 21:48:18] iter = 16370, loss = 2.3764
2024-10-30 21:48:23: [2024-10-30 21:48:23] iter = 16380, loss = 2.0279
2024-10-30 21:48:27: [2024-10-30 21:48:27] iter = 16390, loss = 2.3409
2024-10-30 21:48:32: [2024-10-30 21:48:32] iter = 16400, loss = 1.9627
2024-10-30 21:48:35: [2024-10-30 21:48:35] iter = 16410, loss = 2.0017
2024-10-30 21:48:38: [2024-10-30 21:48:38] iter = 16420, loss = 2.0003
2024-10-30 21:48:40: [2024-10-30 21:48:40] iter = 16430, loss = 2.0500
2024-10-30 21:48:43: [2024-10-30 21:48:43] iter = 16440, loss = 2.2150
2024-10-30 21:48:46: [2024-10-30 21:48:46] iter = 16450, loss = 1.9990
2024-10-30 21:48:50: [2024-10-30 21:48:50] iter = 16460, loss = 2.1058
2024-10-30 21:48:53: [2024-10-30 21:48:53] iter = 16470, loss = 2.3638
2024-10-30 21:48:56: [2024-10-30 21:48:56] iter = 16480, loss = 2.0064
2024-10-30 21:48:59: [2024-10-30 21:48:59] iter = 16490, loss = 2.2736
2024-10-30 21:49:02: [2024-10-30 21:49:02] iter = 16500, loss = 2.9866
2024-10-30 21:49:06: [2024-10-30 21:49:06] iter = 16510, loss = 2.5209
2024-10-30 21:49:09: [2024-10-30 21:49:09] iter = 16520, loss = 2.0735
2024-10-30 21:49:11: [2024-10-30 21:49:11] iter = 16530, loss = 2.2158
2024-10-30 21:49:16: [2024-10-30 21:49:16] iter = 16540, loss = 1.8011
2024-10-30 21:49:19: [2024-10-30 21:49:19] iter = 16550, loss = 2.0320
2024-10-30 21:49:23: [2024-10-30 21:49:23] iter = 16560, loss = 2.0477
2024-10-30 21:49:26: [2024-10-30 21:49:26] iter = 16570, loss = 2.4582
2024-10-30 21:49:29: [2024-10-30 21:49:29] iter = 16580, loss = 1.9717
2024-10-30 21:49:32: [2024-10-30 21:49:32] iter = 16590, loss = 2.5444
2024-10-30 21:49:35: [2024-10-30 21:49:35] iter = 16600, loss = 1.9364
2024-10-30 21:49:38: [2024-10-30 21:49:38] iter = 16610, loss = 2.1167
2024-10-30 21:49:42: [2024-10-30 21:49:42] iter = 16620, loss = 2.0090
2024-10-30 21:49:46: [2024-10-30 21:49:46] iter = 16630, loss = 1.9647
2024-10-30 21:49:49: [2024-10-30 21:49:49] iter = 16640, loss = 2.2085
2024-10-30 21:49:52: [2024-10-30 21:49:52] iter = 16650, loss = 2.5836
2024-10-30 21:49:55: [2024-10-30 21:49:55] iter = 16660, loss = 2.2285
2024-10-30 21:49:59: [2024-10-30 21:49:59] iter = 16670, loss = 3.1147
2024-10-30 21:50:01: [2024-10-30 21:50:01] iter = 16680, loss = 2.2725
2024-10-30 21:50:05: [2024-10-30 21:50:05] iter = 16690, loss = 2.4777
2024-10-30 21:50:08: [2024-10-30 21:50:08] iter = 16700, loss = 2.3440
2024-10-30 21:50:11: [2024-10-30 21:50:11] iter = 16710, loss = 2.3986
2024-10-30 21:50:15: [2024-10-30 21:50:15] iter = 16720, loss = 1.7478
2024-10-30 21:50:19: [2024-10-30 21:50:19] iter = 16730, loss = 2.6341
2024-10-30 21:50:23: [2024-10-30 21:50:23] iter = 16740, loss = 2.6585
2024-10-30 21:50:26: [2024-10-30 21:50:26] iter = 16750, loss = 2.2290
2024-10-30 21:50:29: [2024-10-30 21:50:29] iter = 16760, loss = 2.1592
2024-10-30 21:50:33: [2024-10-30 21:50:33] iter = 16770, loss = 2.1249
2024-10-30 21:50:37: [2024-10-30 21:50:37] iter = 16780, loss = 2.4792
2024-10-30 21:50:40: [2024-10-30 21:50:40] iter = 16790, loss = 2.3621
2024-10-30 21:50:44: [2024-10-30 21:50:44] iter = 16800, loss = 2.6080
2024-10-30 21:50:47: [2024-10-30 21:50:47] iter = 16810, loss = 2.2832
2024-10-30 21:50:50: [2024-10-30 21:50:50] iter = 16820, loss = 1.9642
2024-10-30 21:50:52: [2024-10-30 21:50:52] iter = 16830, loss = 4.3398
2024-10-30 21:50:56: [2024-10-30 21:50:56] iter = 16840, loss = 2.3359
2024-10-30 21:51:00: [2024-10-30 21:51:00] iter = 16850, loss = 1.9898
2024-10-30 21:51:02: [2024-10-30 21:51:02] iter = 16860, loss = 2.3870
2024-10-30 21:51:05: [2024-10-30 21:51:05] iter = 16870, loss = 2.2646
2024-10-30 21:51:08: [2024-10-30 21:51:08] iter = 16880, loss = 2.5005
2024-10-30 21:51:11: [2024-10-30 21:51:11] iter = 16890, loss = 2.2802
2024-10-30 21:51:14: [2024-10-30 21:51:14] iter = 16900, loss = 2.0733
2024-10-30 21:51:18: [2024-10-30 21:51:18] iter = 16910, loss = 2.1995
2024-10-30 21:51:21: [2024-10-30 21:51:21] iter = 16920, loss = 2.0053
2024-10-30 21:51:25: [2024-10-30 21:51:25] iter = 16930, loss = 2.5800
2024-10-30 21:51:28: [2024-10-30 21:51:28] iter = 16940, loss = 2.3564
2024-10-30 21:51:31: [2024-10-30 21:51:31] iter = 16950, loss = 2.4208
2024-10-30 21:51:35: [2024-10-30 21:51:35] iter = 16960, loss = 4.9533
2024-10-30 21:51:38: [2024-10-30 21:51:38] iter = 16970, loss = 2.4518
2024-10-30 21:51:41: [2024-10-30 21:51:41] iter = 16980, loss = 2.3729
2024-10-30 21:51:44: [2024-10-30 21:51:44] iter = 16990, loss = 2.2210
2024-10-30 21:51:47: [2024-10-30 21:51:47] iter = 17000, loss = 2.0495
2024-10-30 21:51:50: [2024-10-30 21:51:50] iter = 17010, loss = 2.1026
2024-10-30 21:51:52: [2024-10-30 21:51:52] iter = 17020, loss = 1.8262
2024-10-30 21:51:55: [2024-10-30 21:51:55] iter = 17030, loss = 2.0177
2024-10-30 21:51:59: [2024-10-30 21:51:59] iter = 17040, loss = 2.6825
2024-10-30 21:52:02: [2024-10-30 21:52:02] iter = 17050, loss = 2.3395
2024-10-30 21:52:06: [2024-10-30 21:52:06] iter = 17060, loss = 1.9746
2024-10-30 21:52:10: [2024-10-30 21:52:09] iter = 17070, loss = 2.9677
2024-10-30 21:52:13: [2024-10-30 21:52:13] iter = 17080, loss = 1.9990
2024-10-30 21:52:17: [2024-10-30 21:52:17] iter = 17090, loss = 3.0840
2024-10-30 21:52:21: [2024-10-30 21:52:21] iter = 17100, loss = 1.9448
2024-10-30 21:52:23: [2024-10-30 21:52:23] iter = 17110, loss = 2.4346
2024-10-30 21:52:27: [2024-10-30 21:52:27] iter = 17120, loss = 2.9153
2024-10-30 21:52:29: [2024-10-30 21:52:29] iter = 17130, loss = 1.8387
2024-10-30 21:52:32: [2024-10-30 21:52:32] iter = 17140, loss = 3.0466
2024-10-30 21:52:35: [2024-10-30 21:52:35] iter = 17150, loss = 2.2575
2024-10-30 21:52:38: [2024-10-30 21:52:38] iter = 17160, loss = 1.9321
2024-10-30 21:52:41: [2024-10-30 21:52:41] iter = 17170, loss = 2.1036
2024-10-30 21:52:44: [2024-10-30 21:52:44] iter = 17180, loss = 2.2120
2024-10-30 21:52:47: [2024-10-30 21:52:47] iter = 17190, loss = 2.4090
2024-10-30 21:52:51: [2024-10-30 21:52:51] iter = 17200, loss = 2.5433
2024-10-30 21:52:54: [2024-10-30 21:52:54] iter = 17210, loss = 2.4070
2024-10-30 21:52:57: [2024-10-30 21:52:57] iter = 17220, loss = 3.7081
2024-10-30 21:53:00: [2024-10-30 21:53:00] iter = 17230, loss = 1.9381
2024-10-30 21:53:03: [2024-10-30 21:53:03] iter = 17240, loss = 2.8158
2024-10-30 21:53:07: [2024-10-30 21:53:07] iter = 17250, loss = 3.1029
2024-10-30 21:53:10: [2024-10-30 21:53:10] iter = 17260, loss = 2.1491
2024-10-30 21:53:13: [2024-10-30 21:53:13] iter = 17270, loss = 2.1753
2024-10-30 21:53:17: [2024-10-30 21:53:17] iter = 17280, loss = 2.1005
2024-10-30 21:53:22: [2024-10-30 21:53:22] iter = 17290, loss = 2.8289
2024-10-30 21:53:25: [2024-10-30 21:53:25] iter = 17300, loss = 2.8501
2024-10-30 21:53:29: [2024-10-30 21:53:29] iter = 17310, loss = 1.9968
2024-10-30 21:53:32: [2024-10-30 21:53:32] iter = 17320, loss = 2.8730
2024-10-30 21:53:35: [2024-10-30 21:53:35] iter = 17330, loss = 2.2531
2024-10-30 21:53:39: [2024-10-30 21:53:39] iter = 17340, loss = 2.2482
2024-10-30 21:53:42: [2024-10-30 21:53:42] iter = 17350, loss = 1.7851
2024-10-30 21:53:45: [2024-10-30 21:53:45] iter = 17360, loss = 1.9743
2024-10-30 21:53:49: [2024-10-30 21:53:49] iter = 17370, loss = 1.8513
2024-10-30 21:53:53: [2024-10-30 21:53:53] iter = 17380, loss = 2.0272
2024-10-30 21:53:56: [2024-10-30 21:53:56] iter = 17390, loss = 1.9765
2024-10-30 21:53:59: [2024-10-30 21:53:59] iter = 17400, loss = 2.5025
2024-10-30 21:54:03: [2024-10-30 21:54:03] iter = 17410, loss = 2.2816
2024-10-30 21:54:05: [2024-10-30 21:54:05] iter = 17420, loss = 3.5045
2024-10-30 21:54:09: [2024-10-30 21:54:09] iter = 17430, loss = 2.8215
2024-10-30 21:54:12: [2024-10-30 21:54:12] iter = 17440, loss = 1.8327
2024-10-30 21:54:15: [2024-10-30 21:54:15] iter = 17450, loss = 2.3538
2024-10-30 21:54:18: [2024-10-30 21:54:18] iter = 17460, loss = 2.9285
2024-10-30 21:54:21: [2024-10-30 21:54:21] iter = 17470, loss = 2.0580
2024-10-30 21:54:24: [2024-10-30 21:54:24] iter = 17480, loss = 2.0797
2024-10-30 21:54:28: [2024-10-30 21:54:28] iter = 17490, loss = 2.0786
2024-10-30 21:54:31: [2024-10-30 21:54:31] iter = 17500, loss = 2.5682
2024-10-30 21:54:35: [2024-10-30 21:54:35] iter = 17510, loss = 2.5736
2024-10-30 21:54:38: [2024-10-30 21:54:38] iter = 17520, loss = 1.9733
2024-10-30 21:54:42: [2024-10-30 21:54:42] iter = 17530, loss = 2.1000
2024-10-30 21:54:45: [2024-10-30 21:54:45] iter = 17540, loss = 3.2512
2024-10-30 21:54:50: [2024-10-30 21:54:50] iter = 17550, loss = 1.8417
2024-10-30 21:54:55: [2024-10-30 21:54:55] iter = 17560, loss = 2.3784
2024-10-30 21:54:59: [2024-10-30 21:54:59] iter = 17570, loss = 3.6646
2024-10-30 21:55:05: [2024-10-30 21:55:05] iter = 17580, loss = 2.2507
2024-10-30 21:55:11: [2024-10-30 21:55:11] iter = 17590, loss = 2.4396
2024-10-30 21:55:15: [2024-10-30 21:55:15] iter = 17600, loss = 1.7903
2024-10-30 21:55:20: [2024-10-30 21:55:20] iter = 17610, loss = 1.7981
2024-10-30 21:55:25: [2024-10-30 21:55:25] iter = 17620, loss = 4.2867
2024-10-30 21:55:30: [2024-10-30 21:55:30] iter = 17630, loss = 3.0669
2024-10-30 21:55:36: [2024-10-30 21:55:36] iter = 17640, loss = 2.9792
2024-10-30 21:55:40: [2024-10-30 21:55:40] iter = 17650, loss = 2.0045
2024-10-30 21:55:45: [2024-10-30 21:55:45] iter = 17660, loss = 2.5237
2024-10-30 21:55:50: [2024-10-30 21:55:50] iter = 17670, loss = 2.3168
2024-10-30 21:55:56: [2024-10-30 21:55:56] iter = 17680, loss = 2.0506
2024-10-30 21:56:02: [2024-10-30 21:56:02] iter = 17690, loss = 1.9311
2024-10-30 21:56:07: [2024-10-30 21:56:07] iter = 17700, loss = 2.1119
2024-10-30 21:56:12: [2024-10-30 21:56:12] iter = 17710, loss = 4.3836
2024-10-30 21:56:16: [2024-10-30 21:56:16] iter = 17720, loss = 2.7795
2024-10-30 21:56:21: [2024-10-30 21:56:21] iter = 17730, loss = 2.3035
2024-10-30 21:56:26: [2024-10-30 21:56:26] iter = 17740, loss = 2.1437
2024-10-30 21:56:31: [2024-10-30 21:56:31] iter = 17750, loss = 2.2415
2024-10-30 21:56:36: [2024-10-30 21:56:36] iter = 17760, loss = 1.9314
2024-10-30 21:56:40: [2024-10-30 21:56:40] iter = 17770, loss = 2.3281
2024-10-30 21:56:45: [2024-10-30 21:56:45] iter = 17780, loss = 2.3913
2024-10-30 21:56:49: [2024-10-30 21:56:49] iter = 17790, loss = 2.0035
2024-10-30 21:56:54: [2024-10-30 21:56:54] iter = 17800, loss = 3.5166
2024-10-30 21:56:58: [2024-10-30 21:56:58] iter = 17810, loss = 1.9480
2024-10-30 21:57:02: [2024-10-30 21:57:02] iter = 17820, loss = 1.9591
2024-10-30 21:57:05: [2024-10-30 21:57:05] iter = 17830, loss = 6.6026
2024-10-30 21:57:09: [2024-10-30 21:57:09] iter = 17840, loss = 1.8555
2024-10-30 21:57:13: [2024-10-30 21:57:13] iter = 17850, loss = 2.0377
2024-10-30 21:57:17: [2024-10-30 21:57:17] iter = 17860, loss = 2.9323
2024-10-30 21:57:20: [2024-10-30 21:57:20] iter = 17870, loss = 3.6693
2024-10-30 21:57:23: [2024-10-30 21:57:23] iter = 17880, loss = 1.6110
2024-10-30 21:57:27: [2024-10-30 21:57:27] iter = 17890, loss = 2.5325
2024-10-30 21:57:31: [2024-10-30 21:57:31] iter = 17900, loss = 2.2018
2024-10-30 21:57:33: [2024-10-30 21:57:33] iter = 17910, loss = 1.9111
2024-10-30 21:57:37: [2024-10-30 21:57:37] iter = 17920, loss = 2.2267
2024-10-30 21:57:41: [2024-10-30 21:57:41] iter = 17930, loss = 2.3333
2024-10-30 21:57:45: [2024-10-30 21:57:45] iter = 17940, loss = 3.3562
2024-10-30 21:57:49: [2024-10-30 21:57:49] iter = 17950, loss = 2.9923
2024-10-30 21:57:55: [2024-10-30 21:57:55] iter = 17960, loss = 2.9284
2024-10-30 21:58:01: [2024-10-30 21:58:01] iter = 17970, loss = 2.9282
2024-10-30 21:58:04: [2024-10-30 21:58:04] iter = 17980, loss = 1.9991
2024-10-30 21:58:08: [2024-10-30 21:58:08] iter = 17990, loss = 2.0590
2024-10-30 21:58:11: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 21:58:11: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:58:11: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 91055}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:00:51: Evaluate 5 random ConvNet, ACCmean = 0.5983 ACCstd = 0.0014
-------------------------
2024-10-30 22:00:51: Evaluate 5 random ConvNet, SENmean = 0.5812 SENstd = 0.0028
-------------------------
2024-10-30 22:00:51: Evaluate 5 random ConvNet, SPEmean = 0.9591 SPEstd = 0.0002
-------------------------
2024-10-30 22:00:51: Evaluate 5 random ConvNet, F!mean = 0.5709 F!std = 0.0006
-------------------------
2024-10-30 22:00:51: Evaluate 5 random ConvNet, mean = 0.5983 std = 0.0014
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:00:52: [2024-10-30 22:00:52] iter = 18000, loss = 3.1362
2024-10-30 22:00:56: [2024-10-30 22:00:56] iter = 18010, loss = 2.0346
2024-10-30 22:01:00: [2024-10-30 22:01:00] iter = 18020, loss = 2.0123
2024-10-30 22:01:04: [2024-10-30 22:01:04] iter = 18030, loss = 2.0591
2024-10-30 22:01:08: [2024-10-30 22:01:08] iter = 18040, loss = 2.6539
2024-10-30 22:01:11: [2024-10-30 22:01:11] iter = 18050, loss = 3.1951
2024-10-30 22:01:15: [2024-10-30 22:01:15] iter = 18060, loss = 2.1873
2024-10-30 22:01:19: [2024-10-30 22:01:19] iter = 18070, loss = 2.8144
2024-10-30 22:01:24: [2024-10-30 22:01:24] iter = 18080, loss = 2.4636
2024-10-30 22:01:28: [2024-10-30 22:01:28] iter = 18090, loss = 2.1417
2024-10-30 22:01:32: [2024-10-30 22:01:32] iter = 18100, loss = 1.8694
2024-10-30 22:01:35: [2024-10-30 22:01:35] iter = 18110, loss = 2.1114
2024-10-30 22:01:39: [2024-10-30 22:01:39] iter = 18120, loss = 6.2780
2024-10-30 22:01:41: [2024-10-30 22:01:41] iter = 18130, loss = 1.9045
2024-10-30 22:01:44: [2024-10-30 22:01:44] iter = 18140, loss = 3.1855
2024-10-30 22:01:47: [2024-10-30 22:01:47] iter = 18150, loss = 2.1443
2024-10-30 22:01:50: [2024-10-30 22:01:50] iter = 18160, loss = 4.4408
2024-10-30 22:01:53: [2024-10-30 22:01:53] iter = 18170, loss = 1.8186
2024-10-30 22:01:57: [2024-10-30 22:01:57] iter = 18180, loss = 2.7254
2024-10-30 22:02:01: [2024-10-30 22:02:01] iter = 18190, loss = 2.1009
2024-10-30 22:02:05: [2024-10-30 22:02:05] iter = 18200, loss = 2.6027
2024-10-30 22:02:08: [2024-10-30 22:02:08] iter = 18210, loss = 2.3297
2024-10-30 22:02:11: [2024-10-30 22:02:11] iter = 18220, loss = 2.8718
2024-10-30 22:02:15: [2024-10-30 22:02:15] iter = 18230, loss = 2.0284
2024-10-30 22:02:19: [2024-10-30 22:02:19] iter = 18240, loss = 2.1796
2024-10-30 22:02:21: [2024-10-30 22:02:21] iter = 18250, loss = 2.3383
2024-10-30 22:02:25: [2024-10-30 22:02:25] iter = 18260, loss = 2.2365
2024-10-30 22:02:27: [2024-10-30 22:02:27] iter = 18270, loss = 2.3139
2024-10-30 22:02:30: [2024-10-30 22:02:30] iter = 18280, loss = 2.0689
2024-10-30 22:02:33: [2024-10-30 22:02:33] iter = 18290, loss = 2.2315
2024-10-30 22:02:37: [2024-10-30 22:02:37] iter = 18300, loss = 1.8488
2024-10-30 22:02:40: [2024-10-30 22:02:40] iter = 18310, loss = 1.8606
2024-10-30 22:02:43: [2024-10-30 22:02:43] iter = 18320, loss = 2.2450
2024-10-30 22:02:46: [2024-10-30 22:02:46] iter = 18330, loss = 1.9442
2024-10-30 22:02:49: [2024-10-30 22:02:49] iter = 18340, loss = 1.9217
2024-10-30 22:02:52: [2024-10-30 22:02:52] iter = 18350, loss = 2.3743
2024-10-30 22:02:54: [2024-10-30 22:02:54] iter = 18360, loss = 2.3605
2024-10-30 22:02:58: [2024-10-30 22:02:58] iter = 18370, loss = 2.8172
2024-10-30 22:03:01: [2024-10-30 22:03:01] iter = 18380, loss = 1.9613
2024-10-30 22:03:04: [2024-10-30 22:03:04] iter = 18390, loss = 2.1756
2024-10-30 22:03:07: [2024-10-30 22:03:07] iter = 18400, loss = 2.1253
2024-10-30 22:03:11: [2024-10-30 22:03:11] iter = 18410, loss = 1.9091
2024-10-30 22:03:14: [2024-10-30 22:03:14] iter = 18420, loss = 1.9796
2024-10-30 22:03:18: [2024-10-30 22:03:18] iter = 18430, loss = 2.1001
2024-10-30 22:03:23: [2024-10-30 22:03:23] iter = 18440, loss = 1.8853
2024-10-30 22:03:27: [2024-10-30 22:03:27] iter = 18450, loss = 3.3040
2024-10-30 22:03:29: [2024-10-30 22:03:29] iter = 18460, loss = 2.0376
2024-10-30 22:03:32: [2024-10-30 22:03:32] iter = 18470, loss = 1.9022
2024-10-30 22:03:35: [2024-10-30 22:03:35] iter = 18480, loss = 1.8585
2024-10-30 22:03:38: [2024-10-30 22:03:38] iter = 18490, loss = 2.9617
2024-10-30 22:03:42: [2024-10-30 22:03:42] iter = 18500, loss = 2.1134
2024-10-30 22:03:46: [2024-10-30 22:03:46] iter = 18510, loss = 2.3385
2024-10-30 22:03:49: [2024-10-30 22:03:49] iter = 18520, loss = 2.2616
2024-10-30 22:03:52: [2024-10-30 22:03:52] iter = 18530, loss = 2.0122
2024-10-30 22:03:55: [2024-10-30 22:03:55] iter = 18540, loss = 2.0369
2024-10-30 22:03:59: [2024-10-30 22:03:59] iter = 18550, loss = 1.9633
2024-10-30 22:04:03: [2024-10-30 22:04:03] iter = 18560, loss = 2.1626
2024-10-30 22:04:06: [2024-10-30 22:04:06] iter = 18570, loss = 2.3128
2024-10-30 22:04:09: [2024-10-30 22:04:09] iter = 18580, loss = 1.9509
2024-10-30 22:04:13: [2024-10-30 22:04:13] iter = 18590, loss = 1.9372
2024-10-30 22:04:17: [2024-10-30 22:04:17] iter = 18600, loss = 2.3548
2024-10-30 22:04:21: [2024-10-30 22:04:21] iter = 18610, loss = 1.9216
2024-10-30 22:04:24: [2024-10-30 22:04:24] iter = 18620, loss = 3.8865
2024-10-30 22:04:28: [2024-10-30 22:04:28] iter = 18630, loss = 3.6136
2024-10-30 22:04:32: [2024-10-30 22:04:32] iter = 18640, loss = 1.8433
2024-10-30 22:04:36: [2024-10-30 22:04:36] iter = 18650, loss = 1.7131
2024-10-30 22:04:39: [2024-10-30 22:04:39] iter = 18660, loss = 6.4232
2024-10-30 22:04:42: [2024-10-30 22:04:42] iter = 18670, loss = 1.7809
2024-10-30 22:04:45: [2024-10-30 22:04:45] iter = 18680, loss = 2.7263
2024-10-30 22:04:49: [2024-10-30 22:04:49] iter = 18690, loss = 2.5128
2024-10-30 22:04:52: [2024-10-30 22:04:52] iter = 18700, loss = 2.0958
2024-10-30 22:04:56: [2024-10-30 22:04:56] iter = 18710, loss = 2.2353
2024-10-30 22:04:59: [2024-10-30 22:04:59] iter = 18720, loss = 1.8769
2024-10-30 22:05:03: [2024-10-30 22:05:03] iter = 18730, loss = 2.1477
2024-10-30 22:05:07: [2024-10-30 22:05:07] iter = 18740, loss = 2.1631
2024-10-30 22:05:10: [2024-10-30 22:05:10] iter = 18750, loss = 2.7084
2024-10-30 22:05:13: [2024-10-30 22:05:13] iter = 18760, loss = 2.0517
2024-10-30 22:05:16: [2024-10-30 22:05:16] iter = 18770, loss = 2.2292
2024-10-30 22:05:19: [2024-10-30 22:05:19] iter = 18780, loss = 1.8480
2024-10-30 22:05:22: [2024-10-30 22:05:22] iter = 18790, loss = 2.4028
2024-10-30 22:05:24: [2024-10-30 22:05:24] iter = 18800, loss = 2.3935
2024-10-30 22:05:27: [2024-10-30 22:05:27] iter = 18810, loss = 2.0113
2024-10-30 22:05:31: [2024-10-30 22:05:31] iter = 18820, loss = 2.3829
2024-10-30 22:05:34: [2024-10-30 22:05:34] iter = 18830, loss = 1.9776
2024-10-30 22:05:37: [2024-10-30 22:05:37] iter = 18840, loss = 1.8786
2024-10-30 22:05:39: [2024-10-30 22:05:39] iter = 18850, loss = 2.2210
2024-10-30 22:05:42: [2024-10-30 22:05:42] iter = 18860, loss = 2.0296
2024-10-30 22:05:46: [2024-10-30 22:05:46] iter = 18870, loss = 2.1836
2024-10-30 22:05:49: [2024-10-30 22:05:49] iter = 18880, loss = 2.0026
2024-10-30 22:05:52: [2024-10-30 22:05:52] iter = 18890, loss = 2.7950
2024-10-30 22:05:55: [2024-10-30 22:05:55] iter = 18900, loss = 1.7666
2024-10-30 22:05:59: [2024-10-30 22:05:59] iter = 18910, loss = 2.0329
2024-10-30 22:06:02: [2024-10-30 22:06:02] iter = 18920, loss = 3.4680
2024-10-30 22:06:05: [2024-10-30 22:06:05] iter = 18930, loss = 2.1175
2024-10-30 22:06:08: [2024-10-30 22:06:08] iter = 18940, loss = 3.5579
2024-10-30 22:06:12: [2024-10-30 22:06:12] iter = 18950, loss = 3.1406
2024-10-30 22:06:17: [2024-10-30 22:06:17] iter = 18960, loss = 2.8390
2024-10-30 22:06:20: [2024-10-30 22:06:20] iter = 18970, loss = 1.9626
2024-10-30 22:06:25: [2024-10-30 22:06:25] iter = 18980, loss = 2.0212
2024-10-30 22:06:28: [2024-10-30 22:06:28] iter = 18990, loss = 2.8885
2024-10-30 22:06:32: [2024-10-30 22:06:32] iter = 19000, loss = 1.9701
2024-10-30 22:06:36: [2024-10-30 22:06:36] iter = 19010, loss = 2.1354
2024-10-30 22:06:40: [2024-10-30 22:06:40] iter = 19020, loss = 2.0985
2024-10-30 22:06:43: [2024-10-30 22:06:43] iter = 19030, loss = 2.9112
2024-10-30 22:06:47: [2024-10-30 22:06:47] iter = 19040, loss = 1.8908
2024-10-30 22:06:51: [2024-10-30 22:06:51] iter = 19050, loss = 2.3030
2024-10-30 22:06:54: [2024-10-30 22:06:54] iter = 19060, loss = 2.8409
2024-10-30 22:06:57: [2024-10-30 22:06:57] iter = 19070, loss = 3.4030
2024-10-30 22:07:01: [2024-10-30 22:07:01] iter = 19080, loss = 2.1534
2024-10-30 22:07:05: [2024-10-30 22:07:05] iter = 19090, loss = 2.0684
2024-10-30 22:07:09: [2024-10-30 22:07:09] iter = 19100, loss = 2.2579
2024-10-30 22:07:13: [2024-10-30 22:07:13] iter = 19110, loss = 1.6179
2024-10-30 22:07:17: [2024-10-30 22:07:17] iter = 19120, loss = 2.5960
2024-10-30 22:07:21: [2024-10-30 22:07:21] iter = 19130, loss = 1.8971
2024-10-30 22:07:24: [2024-10-30 22:07:24] iter = 19140, loss = 2.0134
2024-10-30 22:07:28: [2024-10-30 22:07:28] iter = 19150, loss = 2.2556
2024-10-30 22:07:32: [2024-10-30 22:07:32] iter = 19160, loss = 1.8317
2024-10-30 22:07:35: [2024-10-30 22:07:35] iter = 19170, loss = 4.1100
2024-10-30 22:07:38: [2024-10-30 22:07:38] iter = 19180, loss = 4.3543
2024-10-30 22:07:41: [2024-10-30 22:07:41] iter = 19190, loss = 2.1794
2024-10-30 22:07:45: [2024-10-30 22:07:45] iter = 19200, loss = 1.9967
2024-10-30 22:07:48: [2024-10-30 22:07:48] iter = 19210, loss = 2.3448
2024-10-30 22:07:52: [2024-10-30 22:07:52] iter = 19220, loss = 2.3365
2024-10-30 22:07:55: [2024-10-30 22:07:55] iter = 19230, loss = 1.8534
2024-10-30 22:07:58: [2024-10-30 22:07:58] iter = 19240, loss = 2.0182
2024-10-30 22:08:01: [2024-10-30 22:08:01] iter = 19250, loss = 4.3551
2024-10-30 22:08:05: [2024-10-30 22:08:05] iter = 19260, loss = 2.9415
2024-10-30 22:08:08: [2024-10-30 22:08:08] iter = 19270, loss = 4.1387
2024-10-30 22:08:11: [2024-10-30 22:08:11] iter = 19280, loss = 2.2490
2024-10-30 22:08:14: [2024-10-30 22:08:14] iter = 19290, loss = 1.8574
2024-10-30 22:08:18: [2024-10-30 22:08:18] iter = 19300, loss = 2.0622
2024-10-30 22:08:21: [2024-10-30 22:08:21] iter = 19310, loss = 2.0375
2024-10-30 22:08:25: [2024-10-30 22:08:25] iter = 19320, loss = 1.7493
2024-10-30 22:08:28: [2024-10-30 22:08:28] iter = 19330, loss = 2.0025
2024-10-30 22:08:32: [2024-10-30 22:08:32] iter = 19340, loss = 1.6730
2024-10-30 22:08:35: [2024-10-30 22:08:35] iter = 19350, loss = 2.0239
2024-10-30 22:08:39: [2024-10-30 22:08:39] iter = 19360, loss = 2.2587
2024-10-30 22:08:42: [2024-10-30 22:08:42] iter = 19370, loss = 1.7160
2024-10-30 22:08:46: [2024-10-30 22:08:46] iter = 19380, loss = 2.2132
2024-10-30 22:08:49: [2024-10-30 22:08:49] iter = 19390, loss = 3.3734
2024-10-30 22:08:53: [2024-10-30 22:08:53] iter = 19400, loss = 2.7291
2024-10-30 22:08:56: [2024-10-30 22:08:56] iter = 19410, loss = 2.6076
2024-10-30 22:08:59: [2024-10-30 22:08:59] iter = 19420, loss = 2.4259
2024-10-30 22:09:01: [2024-10-30 22:09:01] iter = 19430, loss = 2.7174
2024-10-30 22:09:04: [2024-10-30 22:09:04] iter = 19440, loss = 1.8989
2024-10-30 22:09:07: [2024-10-30 22:09:07] iter = 19450, loss = 1.7948
2024-10-30 22:09:12: [2024-10-30 22:09:12] iter = 19460, loss = 2.0905
2024-10-30 22:09:15: [2024-10-30 22:09:15] iter = 19470, loss = 1.9543
2024-10-30 22:09:18: [2024-10-30 22:09:18] iter = 19480, loss = 1.7225
2024-10-30 22:09:21: [2024-10-30 22:09:21] iter = 19490, loss = 3.7910
2024-10-30 22:09:24: [2024-10-30 22:09:24] iter = 19500, loss = 2.2707
2024-10-30 22:09:27: [2024-10-30 22:09:27] iter = 19510, loss = 1.9815
2024-10-30 22:09:31: [2024-10-30 22:09:31] iter = 19520, loss = 2.0096
2024-10-30 22:09:33: [2024-10-30 22:09:33] iter = 19530, loss = 2.4894
2024-10-30 22:09:37: [2024-10-30 22:09:37] iter = 19540, loss = 2.2540
2024-10-30 22:09:40: [2024-10-30 22:09:40] iter = 19550, loss = 2.7161
2024-10-30 22:09:43: [2024-10-30 22:09:43] iter = 19560, loss = 2.3090
2024-10-30 22:09:46: [2024-10-30 22:09:46] iter = 19570, loss = 2.1195
2024-10-30 22:09:50: [2024-10-30 22:09:50] iter = 19580, loss = 2.2226
2024-10-30 22:09:53: [2024-10-30 22:09:53] iter = 19590, loss = 2.2216
2024-10-30 22:09:56: [2024-10-30 22:09:56] iter = 19600, loss = 2.3192
2024-10-30 22:09:59: [2024-10-30 22:09:59] iter = 19610, loss = 2.3950
2024-10-30 22:10:03: [2024-10-30 22:10:03] iter = 19620, loss = 3.4020
2024-10-30 22:10:06: [2024-10-30 22:10:06] iter = 19630, loss = 2.5259
2024-10-30 22:10:09: [2024-10-30 22:10:09] iter = 19640, loss = 2.5874
2024-10-30 22:10:12: [2024-10-30 22:10:12] iter = 19650, loss = 2.3346
2024-10-30 22:10:16: [2024-10-30 22:10:16] iter = 19660, loss = 2.6624
2024-10-30 22:10:19: [2024-10-30 22:10:19] iter = 19670, loss = 2.2624
2024-10-30 22:10:21: [2024-10-30 22:10:21] iter = 19680, loss = 2.6601
2024-10-30 22:10:25: [2024-10-30 22:10:25] iter = 19690, loss = 2.4349
2024-10-30 22:10:28: [2024-10-30 22:10:28] iter = 19700, loss = 1.8999
2024-10-30 22:10:31: [2024-10-30 22:10:31] iter = 19710, loss = 2.5209
2024-10-30 22:10:35: [2024-10-30 22:10:35] iter = 19720, loss = 1.8169
2024-10-30 22:10:40: [2024-10-30 22:10:40] iter = 19730, loss = 2.9876
2024-10-30 22:10:43: [2024-10-30 22:10:43] iter = 19740, loss = 2.2456
2024-10-30 22:10:47: [2024-10-30 22:10:47] iter = 19750, loss = 2.2128
2024-10-30 22:10:50: [2024-10-30 22:10:50] iter = 19760, loss = 2.0316
2024-10-30 22:10:54: [2024-10-30 22:10:54] iter = 19770, loss = 2.0272
2024-10-30 22:10:57: [2024-10-30 22:10:57] iter = 19780, loss = 2.0422
2024-10-30 22:11:01: [2024-10-30 22:11:01] iter = 19790, loss = 1.9869
2024-10-30 22:11:05: [2024-10-30 22:11:05] iter = 19800, loss = 2.6407
2024-10-30 22:11:08: [2024-10-30 22:11:08] iter = 19810, loss = 2.1464
2024-10-30 22:11:12: [2024-10-30 22:11:12] iter = 19820, loss = 1.9434
2024-10-30 22:11:15: [2024-10-30 22:11:15] iter = 19830, loss = 2.0837
2024-10-30 22:11:18: [2024-10-30 22:11:18] iter = 19840, loss = 1.9334
2024-10-30 22:11:22: [2024-10-30 22:11:22] iter = 19850, loss = 1.8800
2024-10-30 22:11:26: [2024-10-30 22:11:26] iter = 19860, loss = 2.0583
2024-10-30 22:11:28: [2024-10-30 22:11:28] iter = 19870, loss = 1.8807
2024-10-30 22:11:30: [2024-10-30 22:11:30] iter = 19880, loss = 1.8754
2024-10-30 22:11:33: [2024-10-30 22:11:33] iter = 19890, loss = 2.1902
2024-10-30 22:11:36: [2024-10-30 22:11:36] iter = 19900, loss = 4.2568
2024-10-30 22:11:40: [2024-10-30 22:11:40] iter = 19910, loss = 1.9121
2024-10-30 22:11:43: [2024-10-30 22:11:43] iter = 19920, loss = 2.0485
2024-10-30 22:11:47: [2024-10-30 22:11:47] iter = 19930, loss = 2.4071
2024-10-30 22:11:50: [2024-10-30 22:11:50] iter = 19940, loss = 2.0591
2024-10-30 22:11:54: [2024-10-30 22:11:54] iter = 19950, loss = 2.1858
2024-10-30 22:11:57: [2024-10-30 22:11:57] iter = 19960, loss = 2.3724
2024-10-30 22:12:01: [2024-10-30 22:12:01] iter = 19970, loss = 2.3653
2024-10-30 22:12:04: [2024-10-30 22:12:04] iter = 19980, loss = 3.2006
2024-10-30 22:12:07: [2024-10-30 22:12:07] iter = 19990, loss = 1.8273
2024-10-30 22:12:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 22:12:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:12:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30585}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:14:20: Evaluate 5 random ConvNet, ACCmean = 0.6158 ACCstd = 0.0026
-------------------------
2024-10-30 22:14:20: Evaluate 5 random ConvNet, SENmean = 0.5905 SENstd = 0.0021
-------------------------
2024-10-30 22:14:20: Evaluate 5 random ConvNet, SPEmean = 0.9610 SPEstd = 0.0003
-------------------------
2024-10-30 22:14:20: Evaluate 5 random ConvNet, F!mean = 0.5816 F!std = 0.0023
-------------------------
2024-10-30 22:14:20: Evaluate 5 random ConvNet, mean = 0.6158 std = 0.0026
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:14:20: [2024-10-30 22:14:20] iter = 20000, loss = 2.1918
2024-10-30 22:14:20: 
================== Exp 3 ==================
 
2024-10-30 22:14:20: Hyper-parameters: 
{'dataset': 'OrganSMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fa9b88fdb20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganSMNIST (INFO)>}
2024-10-30 22:14:20: Evaluation model pool: ['ConvNet']
2024-10-30 22:14:22: class c = 0: 1148 real images
2024-10-30 22:14:22: class c = 1: 630 real images
2024-10-30 22:14:22: class c = 2: 614 real images
2024-10-30 22:14:22: class c = 3: 721 real images
2024-10-30 22:14:22: class c = 4: 1132 real images
2024-10-30 22:14:22: class c = 5: 1119 real images
2024-10-30 22:14:22: class c = 6: 3464 real images
2024-10-30 22:14:22: class c = 7: 741 real images
2024-10-30 22:14:22: class c = 8: 803 real images
2024-10-30 22:14:22: class c = 9: 2004 real images
2024-10-30 22:14:22: class c = 10: 1556 real images
2024-10-30 22:14:22: real images channel 0, mean = 0.4953, std = 0.2826
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 22:14:22: initialize synthetic data from random real images
2024-10-30 22:14:22: [2024-10-30 22:14:22] training begins
2024-10-30 22:14:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 22:14:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:14:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60867}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:16:29: Evaluate 5 random ConvNet, ACCmean = 0.4490 ACCstd = 0.0037
-------------------------
2024-10-30 22:16:29: Evaluate 5 random ConvNet, SENmean = 0.4513 SENstd = 0.0048
-------------------------
2024-10-30 22:16:29: Evaluate 5 random ConvNet, SPEmean = 0.9441 SPEstd = 0.0005
-------------------------
2024-10-30 22:16:29: Evaluate 5 random ConvNet, F!mean = 0.4467 F!std = 0.0039
-------------------------
2024-10-30 22:16:29: Evaluate 5 random ConvNet, mean = 0.4490 std = 0.0037
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:16:30: [2024-10-30 22:16:30] iter = 00000, loss = 16.2556
2024-10-30 22:16:33: [2024-10-30 22:16:33] iter = 00010, loss = 4.1780
2024-10-30 22:16:36: [2024-10-30 22:16:36] iter = 00020, loss = 3.5253
2024-10-30 22:16:39: [2024-10-30 22:16:39] iter = 00030, loss = 3.0069
2024-10-30 22:16:42: [2024-10-30 22:16:42] iter = 00040, loss = 4.2419
2024-10-30 22:16:46: [2024-10-30 22:16:46] iter = 00050, loss = 2.9295
2024-10-30 22:16:49: [2024-10-30 22:16:49] iter = 00060, loss = 4.1054
2024-10-30 22:16:53: [2024-10-30 22:16:53] iter = 00070, loss = 2.9178
2024-10-30 22:16:56: [2024-10-30 22:16:56] iter = 00080, loss = 2.6815
2024-10-30 22:16:59: [2024-10-30 22:16:59] iter = 00090, loss = 3.0622
2024-10-30 22:17:01: [2024-10-30 22:17:01] iter = 00100, loss = 2.3171
2024-10-30 22:17:06: [2024-10-30 22:17:06] iter = 00110, loss = 2.8010
2024-10-30 22:17:09: [2024-10-30 22:17:09] iter = 00120, loss = 2.6661
2024-10-30 22:17:11: [2024-10-30 22:17:11] iter = 00130, loss = 3.6137
2024-10-30 22:17:14: [2024-10-30 22:17:14] iter = 00140, loss = 2.7442
2024-10-30 22:17:17: [2024-10-30 22:17:17] iter = 00150, loss = 2.6011
2024-10-30 22:17:20: [2024-10-30 22:17:20] iter = 00160, loss = 2.9764
2024-10-30 22:17:23: [2024-10-30 22:17:23] iter = 00170, loss = 2.3907
2024-10-30 22:17:26: [2024-10-30 22:17:26] iter = 00180, loss = 2.5928
2024-10-30 22:17:29: [2024-10-30 22:17:29] iter = 00190, loss = 2.4966
2024-10-30 22:17:33: [2024-10-30 22:17:33] iter = 00200, loss = 2.6669
2024-10-30 22:17:35: [2024-10-30 22:17:35] iter = 00210, loss = 2.2180
2024-10-30 22:17:39: [2024-10-30 22:17:39] iter = 00220, loss = 2.6047
2024-10-30 22:17:41: [2024-10-30 22:17:41] iter = 00230, loss = 2.8386
2024-10-30 22:17:44: [2024-10-30 22:17:43] iter = 00240, loss = 2.2994
2024-10-30 22:17:47: [2024-10-30 22:17:47] iter = 00250, loss = 2.0896
2024-10-30 22:17:50: [2024-10-30 22:17:50] iter = 00260, loss = 2.8964
2024-10-30 22:17:53: [2024-10-30 22:17:53] iter = 00270, loss = 2.0748
2024-10-30 22:17:56: [2024-10-30 22:17:56] iter = 00280, loss = 2.5473
2024-10-30 22:17:59: [2024-10-30 22:17:59] iter = 00290, loss = 2.6415
2024-10-30 22:18:02: [2024-10-30 22:18:02] iter = 00300, loss = 3.2591
2024-10-30 22:18:05: [2024-10-30 22:18:05] iter = 00310, loss = 2.4269
2024-10-30 22:18:08: [2024-10-30 22:18:08] iter = 00320, loss = 2.2307
2024-10-30 22:18:11: [2024-10-30 22:18:11] iter = 00330, loss = 2.5423
2024-10-30 22:18:14: [2024-10-30 22:18:14] iter = 00340, loss = 2.1470
2024-10-30 22:18:16: [2024-10-30 22:18:16] iter = 00350, loss = 2.4806
2024-10-30 22:18:19: [2024-10-30 22:18:19] iter = 00360, loss = 2.1646
2024-10-30 22:18:21: [2024-10-30 22:18:21] iter = 00370, loss = 2.0487
2024-10-30 22:18:23: [2024-10-30 22:18:23] iter = 00380, loss = 2.4359
2024-10-30 22:18:24: [2024-10-30 22:18:24] iter = 00390, loss = 2.6763
2024-10-30 22:18:27: [2024-10-30 22:18:27] iter = 00400, loss = 2.7428
2024-10-30 22:18:29: [2024-10-30 22:18:29] iter = 00410, loss = 2.7141
2024-10-30 22:18:32: [2024-10-30 22:18:32] iter = 00420, loss = 2.3757
2024-10-30 22:18:35: [2024-10-30 22:18:35] iter = 00430, loss = 2.2800
2024-10-30 22:18:38: [2024-10-30 22:18:38] iter = 00440, loss = 3.1665
2024-10-30 22:18:41: [2024-10-30 22:18:41] iter = 00450, loss = 2.1760
2024-10-30 22:18:43: [2024-10-30 22:18:43] iter = 00460, loss = 5.7150
2024-10-30 22:18:45: [2024-10-30 22:18:45] iter = 00470, loss = 1.9287
2024-10-30 22:18:46: [2024-10-30 22:18:46] iter = 00480, loss = 2.3434
2024-10-30 22:18:47: [2024-10-30 22:18:47] iter = 00490, loss = 2.7296
2024-10-30 22:18:50: [2024-10-30 22:18:50] iter = 00500, loss = 2.0046
2024-10-30 22:18:52: [2024-10-30 22:18:52] iter = 00510, loss = 2.0439
2024-10-30 22:18:55: [2024-10-30 22:18:55] iter = 00520, loss = 2.0296
2024-10-30 22:18:57: [2024-10-30 22:18:57] iter = 00530, loss = 2.2640
2024-10-30 22:19:00: [2024-10-30 22:19:00] iter = 00540, loss = 3.0250
2024-10-30 22:19:02: [2024-10-30 22:19:02] iter = 00550, loss = 2.0910
2024-10-30 22:19:05: [2024-10-30 22:19:05] iter = 00560, loss = 2.2985
2024-10-30 22:19:09: [2024-10-30 22:19:09] iter = 00570, loss = 2.2707
2024-10-30 22:19:11: [2024-10-30 22:19:11] iter = 00580, loss = 2.6970
2024-10-30 22:19:14: [2024-10-30 22:19:14] iter = 00590, loss = 2.3393
2024-10-30 22:19:17: [2024-10-30 22:19:17] iter = 00600, loss = 3.0128
2024-10-30 22:19:19: [2024-10-30 22:19:19] iter = 00610, loss = 2.0386
2024-10-30 22:19:22: [2024-10-30 22:19:22] iter = 00620, loss = 2.2185
2024-10-30 22:19:24: [2024-10-30 22:19:24] iter = 00630, loss = 2.2641
2024-10-30 22:19:25: [2024-10-30 22:19:25] iter = 00640, loss = 2.2164
2024-10-30 22:19:28: [2024-10-30 22:19:28] iter = 00650, loss = 2.2103
2024-10-30 22:19:30: [2024-10-30 22:19:30] iter = 00660, loss = 2.6584
2024-10-30 22:19:32: [2024-10-30 22:19:32] iter = 00670, loss = 2.5365
2024-10-30 22:19:34: [2024-10-30 22:19:34] iter = 00680, loss = 2.3622
2024-10-30 22:19:37: [2024-10-30 22:19:37] iter = 00690, loss = 2.6997
2024-10-30 22:19:39: [2024-10-30 22:19:39] iter = 00700, loss = 2.2362
2024-10-30 22:19:42: [2024-10-30 22:19:42] iter = 00710, loss = 2.4204
2024-10-30 22:19:45: [2024-10-30 22:19:45] iter = 00720, loss = 3.0547
2024-10-30 22:19:48: [2024-10-30 22:19:48] iter = 00730, loss = 2.6372
2024-10-30 22:19:51: [2024-10-30 22:19:51] iter = 00740, loss = 2.8396
2024-10-30 22:19:54: [2024-10-30 22:19:54] iter = 00750, loss = 2.4394
2024-10-30 22:19:57: [2024-10-30 22:19:57] iter = 00760, loss = 1.9796
2024-10-30 22:20:00: [2024-10-30 22:20:00] iter = 00770, loss = 2.6207
2024-10-30 22:20:03: [2024-10-30 22:20:03] iter = 00780, loss = 2.1893
2024-10-30 22:20:06: [2024-10-30 22:20:06] iter = 00790, loss = 2.5446
2024-10-30 22:20:08: [2024-10-30 22:20:08] iter = 00800, loss = 4.3583
2024-10-30 22:20:11: [2024-10-30 22:20:11] iter = 00810, loss = 2.2843
2024-10-30 22:20:15: [2024-10-30 22:20:15] iter = 00820, loss = 2.4460
2024-10-30 22:20:18: [2024-10-30 22:20:18] iter = 00830, loss = 2.3524
2024-10-30 22:20:21: [2024-10-30 22:20:21] iter = 00840, loss = 2.8057
2024-10-30 22:20:25: [2024-10-30 22:20:25] iter = 00850, loss = 3.0135
2024-10-30 22:20:28: [2024-10-30 22:20:28] iter = 00860, loss = 1.9326
2024-10-30 22:20:30: [2024-10-30 22:20:30] iter = 00870, loss = 1.7696
2024-10-30 22:20:34: [2024-10-30 22:20:34] iter = 00880, loss = 3.3314
2024-10-30 22:20:37: [2024-10-30 22:20:37] iter = 00890, loss = 4.1918
2024-10-30 22:20:39: [2024-10-30 22:20:39] iter = 00900, loss = 2.1660
2024-10-30 22:20:42: [2024-10-30 22:20:42] iter = 00910, loss = 2.3347
2024-10-30 22:20:45: [2024-10-30 22:20:45] iter = 00920, loss = 2.3408
2024-10-30 22:20:48: [2024-10-30 22:20:48] iter = 00930, loss = 2.3200
2024-10-30 22:20:51: [2024-10-30 22:20:51] iter = 00940, loss = 2.4992
2024-10-30 22:20:55: [2024-10-30 22:20:55] iter = 00950, loss = 2.3650
2024-10-30 22:20:59: [2024-10-30 22:20:59] iter = 00960, loss = 2.1928
2024-10-30 22:21:03: [2024-10-30 22:21:03] iter = 00970, loss = 2.1601
2024-10-30 22:21:06: [2024-10-30 22:21:06] iter = 00980, loss = 2.2153
2024-10-30 22:21:09: [2024-10-30 22:21:09] iter = 00990, loss = 3.5608
2024-10-30 22:21:12: [2024-10-30 22:21:12] iter = 01000, loss = 2.5242
2024-10-30 22:21:14: [2024-10-30 22:21:14] iter = 01010, loss = 2.5113
2024-10-30 22:21:17: [2024-10-30 22:21:17] iter = 01020, loss = 2.0966
2024-10-30 22:21:20: [2024-10-30 22:21:20] iter = 01030, loss = 2.8954
2024-10-30 22:21:23: [2024-10-30 22:21:23] iter = 01040, loss = 2.3316
2024-10-30 22:21:27: [2024-10-30 22:21:27] iter = 01050, loss = 2.6879
2024-10-30 22:21:30: [2024-10-30 22:21:30] iter = 01060, loss = 2.4751
2024-10-30 22:21:33: [2024-10-30 22:21:33] iter = 01070, loss = 2.2509
2024-10-30 22:21:36: [2024-10-30 22:21:36] iter = 01080, loss = 2.8155
2024-10-30 22:21:39: [2024-10-30 22:21:39] iter = 01090, loss = 1.9806
2024-10-30 22:21:42: [2024-10-30 22:21:42] iter = 01100, loss = 3.4233
2024-10-30 22:21:45: [2024-10-30 22:21:45] iter = 01110, loss = 4.8012
2024-10-30 22:21:48: [2024-10-30 22:21:48] iter = 01120, loss = 2.3817
2024-10-30 22:21:51: [2024-10-30 22:21:51] iter = 01130, loss = 2.1632
2024-10-30 22:21:55: [2024-10-30 22:21:55] iter = 01140, loss = 2.8202
2024-10-30 22:21:59: [2024-10-30 22:21:59] iter = 01150, loss = 2.6440
2024-10-30 22:22:02: [2024-10-30 22:22:02] iter = 01160, loss = 2.4710
2024-10-30 22:22:06: [2024-10-30 22:22:06] iter = 01170, loss = 1.9069
2024-10-30 22:22:09: [2024-10-30 22:22:09] iter = 01180, loss = 1.8537
2024-10-30 22:22:11: [2024-10-30 22:22:11] iter = 01190, loss = 2.1621
2024-10-30 22:22:14: [2024-10-30 22:22:14] iter = 01200, loss = 2.4617
2024-10-30 22:22:17: [2024-10-30 22:22:17] iter = 01210, loss = 1.9404
2024-10-30 22:22:20: [2024-10-30 22:22:20] iter = 01220, loss = 2.1291
2024-10-30 22:22:23: [2024-10-30 22:22:23] iter = 01230, loss = 2.2717
2024-10-30 22:22:25: [2024-10-30 22:22:25] iter = 01240, loss = 3.2558
2024-10-30 22:22:29: [2024-10-30 22:22:29] iter = 01250, loss = 2.1039
2024-10-30 22:22:32: [2024-10-30 22:22:32] iter = 01260, loss = 2.2724
2024-10-30 22:22:36: [2024-10-30 22:22:36] iter = 01270, loss = 3.1807
2024-10-30 22:22:40: [2024-10-30 22:22:40] iter = 01280, loss = 2.0619
2024-10-30 22:22:43: [2024-10-30 22:22:43] iter = 01290, loss = 1.7314
2024-10-30 22:22:46: [2024-10-30 22:22:46] iter = 01300, loss = 2.0981
2024-10-30 22:22:49: [2024-10-30 22:22:49] iter = 01310, loss = 2.1445
2024-10-30 22:22:53: [2024-10-30 22:22:53] iter = 01320, loss = 2.2340
2024-10-30 22:22:55: [2024-10-30 22:22:55] iter = 01330, loss = 2.3020
2024-10-30 22:22:59: [2024-10-30 22:22:59] iter = 01340, loss = 3.4178
2024-10-30 22:23:03: [2024-10-30 22:23:03] iter = 01350, loss = 2.8437
2024-10-30 22:23:07: [2024-10-30 22:23:07] iter = 01360, loss = 2.2047
2024-10-30 22:23:10: [2024-10-30 22:23:10] iter = 01370, loss = 2.3142
2024-10-30 22:23:14: [2024-10-30 22:23:14] iter = 01380, loss = 2.4511
2024-10-30 22:23:17: [2024-10-30 22:23:17] iter = 01390, loss = 2.7064
2024-10-30 22:23:20: [2024-10-30 22:23:20] iter = 01400, loss = 2.6666
2024-10-30 22:23:23: [2024-10-30 22:23:23] iter = 01410, loss = 2.0930
2024-10-30 22:23:27: [2024-10-30 22:23:27] iter = 01420, loss = 2.9478
2024-10-30 22:23:30: [2024-10-30 22:23:30] iter = 01430, loss = 1.8052
2024-10-30 22:23:34: [2024-10-30 22:23:34] iter = 01440, loss = 5.1159
2024-10-30 22:23:37: [2024-10-30 22:23:37] iter = 01450, loss = 2.6299
2024-10-30 22:23:40: [2024-10-30 22:23:40] iter = 01460, loss = 2.1390
2024-10-30 22:23:44: [2024-10-30 22:23:44] iter = 01470, loss = 5.6697
2024-10-30 22:23:47: [2024-10-30 22:23:47] iter = 01480, loss = 2.0343
2024-10-30 22:23:49: [2024-10-30 22:23:49] iter = 01490, loss = 2.3457
2024-10-30 22:23:53: [2024-10-30 22:23:53] iter = 01500, loss = 2.2006
2024-10-30 22:23:56: [2024-10-30 22:23:56] iter = 01510, loss = 2.2628
2024-10-30 22:23:59: [2024-10-30 22:23:59] iter = 01520, loss = 2.5105
2024-10-30 22:24:02: [2024-10-30 22:24:02] iter = 01530, loss = 2.0760
2024-10-30 22:24:05: [2024-10-30 22:24:05] iter = 01540, loss = 2.5739
2024-10-30 22:24:09: [2024-10-30 22:24:09] iter = 01550, loss = 2.1303
2024-10-30 22:24:13: [2024-10-30 22:24:13] iter = 01560, loss = 1.7765
2024-10-30 22:24:17: [2024-10-30 22:24:17] iter = 01570, loss = 2.5893
2024-10-30 22:24:20: [2024-10-30 22:24:20] iter = 01580, loss = 4.1172
2024-10-30 22:24:23: [2024-10-30 22:24:23] iter = 01590, loss = 2.2071
2024-10-30 22:24:26: [2024-10-30 22:24:26] iter = 01600, loss = 2.3889
2024-10-30 22:24:29: [2024-10-30 22:24:29] iter = 01610, loss = 2.2927
2024-10-30 22:24:33: [2024-10-30 22:24:33] iter = 01620, loss = 2.4983
2024-10-30 22:24:37: [2024-10-30 22:24:37] iter = 01630, loss = 2.5892
2024-10-30 22:24:41: [2024-10-30 22:24:41] iter = 01640, loss = 2.0716
2024-10-30 22:24:44: [2024-10-30 22:24:44] iter = 01650, loss = 1.8112
2024-10-30 22:24:47: [2024-10-30 22:24:47] iter = 01660, loss = 2.3881
2024-10-30 22:24:50: [2024-10-30 22:24:50] iter = 01670, loss = 2.0471
2024-10-30 22:24:53: [2024-10-30 22:24:53] iter = 01680, loss = 1.9413
2024-10-30 22:24:57: [2024-10-30 22:24:57] iter = 01690, loss = 1.8238
2024-10-30 22:25:00: [2024-10-30 22:25:00] iter = 01700, loss = 1.9876
2024-10-30 22:25:04: [2024-10-30 22:25:04] iter = 01710, loss = 3.8817
2024-10-30 22:25:07: [2024-10-30 22:25:07] iter = 01720, loss = 2.1491
2024-10-30 22:25:11: [2024-10-30 22:25:11] iter = 01730, loss = 2.5728
2024-10-30 22:25:14: [2024-10-30 22:25:14] iter = 01740, loss = 3.4455
2024-10-30 22:25:17: [2024-10-30 22:25:17] iter = 01750, loss = 2.2190
2024-10-30 22:25:20: [2024-10-30 22:25:20] iter = 01760, loss = 2.2334
2024-10-30 22:25:22: [2024-10-30 22:25:22] iter = 01770, loss = 2.4403
2024-10-30 22:25:25: [2024-10-30 22:25:25] iter = 01780, loss = 2.4460
2024-10-30 22:25:29: [2024-10-30 22:25:28] iter = 01790, loss = 2.0091
2024-10-30 22:25:32: [2024-10-30 22:25:32] iter = 01800, loss = 2.3584
2024-10-30 22:25:35: [2024-10-30 22:25:35] iter = 01810, loss = 2.3698
2024-10-30 22:25:39: [2024-10-30 22:25:39] iter = 01820, loss = 2.2599
2024-10-30 22:25:44: [2024-10-30 22:25:44] iter = 01830, loss = 1.8338
2024-10-30 22:25:48: [2024-10-30 22:25:48] iter = 01840, loss = 2.0563
2024-10-30 22:25:51: [2024-10-30 22:25:51] iter = 01850, loss = 2.0616
2024-10-30 22:25:55: [2024-10-30 22:25:55] iter = 01860, loss = 1.9611
2024-10-30 22:25:59: [2024-10-30 22:25:59] iter = 01870, loss = 3.8274
2024-10-30 22:26:02: [2024-10-30 22:26:02] iter = 01880, loss = 2.1676
2024-10-30 22:26:05: [2024-10-30 22:26:05] iter = 01890, loss = 6.3937
2024-10-30 22:26:09: [2024-10-30 22:26:09] iter = 01900, loss = 2.4069
2024-10-30 22:26:12: [2024-10-30 22:26:12] iter = 01910, loss = 3.1892
2024-10-30 22:26:16: [2024-10-30 22:26:16] iter = 01920, loss = 2.4750
2024-10-30 22:26:20: [2024-10-30 22:26:20] iter = 01930, loss = 1.8030
2024-10-30 22:26:24: [2024-10-30 22:26:24] iter = 01940, loss = 2.8699
2024-10-30 22:26:28: [2024-10-30 22:26:28] iter = 01950, loss = 2.2164
2024-10-30 22:26:32: [2024-10-30 22:26:32] iter = 01960, loss = 2.4092
2024-10-30 22:26:36: [2024-10-30 22:26:36] iter = 01970, loss = 2.2348
2024-10-30 22:26:39: [2024-10-30 22:26:39] iter = 01980, loss = 2.6058
2024-10-30 22:26:43: [2024-10-30 22:26:43] iter = 01990, loss = 2.9273
2024-10-30 22:26:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 22:26:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:26:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 7148}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:28:51: Evaluate 5 random ConvNet, ACCmean = 0.5990 ACCstd = 0.0023
-------------------------
2024-10-30 22:28:51: Evaluate 5 random ConvNet, SENmean = 0.5803 SENstd = 0.0032
-------------------------
2024-10-30 22:28:51: Evaluate 5 random ConvNet, SPEmean = 0.9591 SPEstd = 0.0003
-------------------------
2024-10-30 22:28:51: Evaluate 5 random ConvNet, F!mean = 0.5726 F!std = 0.0032
-------------------------
2024-10-30 22:28:51: Evaluate 5 random ConvNet, mean = 0.5990 std = 0.0023
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:28:51: [2024-10-30 22:28:51] iter = 02000, loss = 2.2620
2024-10-30 22:28:54: [2024-10-30 22:28:54] iter = 02010, loss = 3.8463
2024-10-30 22:28:56: [2024-10-30 22:28:56] iter = 02020, loss = 3.1308
2024-10-30 22:28:59: [2024-10-30 22:28:59] iter = 02030, loss = 2.8543
2024-10-30 22:29:03: [2024-10-30 22:29:03] iter = 02040, loss = 2.1240
2024-10-30 22:29:06: [2024-10-30 22:29:06] iter = 02050, loss = 1.9089
2024-10-30 22:29:09: [2024-10-30 22:29:09] iter = 02060, loss = 2.3388
2024-10-30 22:29:13: [2024-10-30 22:29:13] iter = 02070, loss = 2.2839
2024-10-30 22:29:15: [2024-10-30 22:29:15] iter = 02080, loss = 2.4663
2024-10-30 22:29:18: [2024-10-30 22:29:18] iter = 02090, loss = 2.5129
2024-10-30 22:29:21: [2024-10-30 22:29:21] iter = 02100, loss = 3.0796
2024-10-30 22:29:24: [2024-10-30 22:29:24] iter = 02110, loss = 4.0653
2024-10-30 22:29:27: [2024-10-30 22:29:27] iter = 02120, loss = 2.2646
2024-10-30 22:29:30: [2024-10-30 22:29:30] iter = 02130, loss = 2.1640
2024-10-30 22:29:33: [2024-10-30 22:29:33] iter = 02140, loss = 2.1514
2024-10-30 22:29:36: [2024-10-30 22:29:36] iter = 02150, loss = 2.0934
2024-10-30 22:29:39: [2024-10-30 22:29:39] iter = 02160, loss = 2.2610
2024-10-30 22:29:42: [2024-10-30 22:29:42] iter = 02170, loss = 2.0370
2024-10-30 22:29:45: [2024-10-30 22:29:45] iter = 02180, loss = 3.6551
2024-10-30 22:29:49: [2024-10-30 22:29:49] iter = 02190, loss = 2.2285
2024-10-30 22:29:52: [2024-10-30 22:29:52] iter = 02200, loss = 2.3055
2024-10-30 22:29:54: [2024-10-30 22:29:54] iter = 02210, loss = 1.9350
2024-10-30 22:29:57: [2024-10-30 22:29:57] iter = 02220, loss = 3.1027
2024-10-30 22:29:59: [2024-10-30 22:29:59] iter = 02230, loss = 3.5521
2024-10-30 22:30:01: [2024-10-30 22:30:01] iter = 02240, loss = 1.9282
2024-10-30 22:30:04: [2024-10-30 22:30:04] iter = 02250, loss = 2.2785
2024-10-30 22:30:07: [2024-10-30 22:30:07] iter = 02260, loss = 2.5686
2024-10-30 22:30:10: [2024-10-30 22:30:10] iter = 02270, loss = 2.0923
2024-10-30 22:30:13: [2024-10-30 22:30:13] iter = 02280, loss = 2.0682
2024-10-30 22:30:16: [2024-10-30 22:30:16] iter = 02290, loss = 2.5669
2024-10-30 22:30:20: [2024-10-30 22:30:20] iter = 02300, loss = 1.7719
2024-10-30 22:30:23: [2024-10-30 22:30:23] iter = 02310, loss = 2.5578
2024-10-30 22:30:26: [2024-10-30 22:30:26] iter = 02320, loss = 2.2217
2024-10-30 22:30:29: [2024-10-30 22:30:29] iter = 02330, loss = 2.0103
2024-10-30 22:30:32: [2024-10-30 22:30:32] iter = 02340, loss = 2.4591
2024-10-30 22:30:35: [2024-10-30 22:30:35] iter = 02350, loss = 2.3397
2024-10-30 22:30:39: [2024-10-30 22:30:39] iter = 02360, loss = 2.0231
2024-10-30 22:30:42: [2024-10-30 22:30:42] iter = 02370, loss = 2.3773
2024-10-30 22:30:44: [2024-10-30 22:30:44] iter = 02380, loss = 2.4847
2024-10-30 22:30:48: [2024-10-30 22:30:48] iter = 02390, loss = 1.8280
2024-10-30 22:30:50: [2024-10-30 22:30:50] iter = 02400, loss = 2.5523
2024-10-30 22:30:54: [2024-10-30 22:30:54] iter = 02410, loss = 2.1324
2024-10-30 22:30:57: [2024-10-30 22:30:57] iter = 02420, loss = 2.0751
2024-10-30 22:31:00: [2024-10-30 22:31:00] iter = 02430, loss = 2.2666
2024-10-30 22:31:03: [2024-10-30 22:31:03] iter = 02440, loss = 2.3142
2024-10-30 22:31:06: [2024-10-30 22:31:06] iter = 02450, loss = 2.1809
2024-10-30 22:31:09: [2024-10-30 22:31:09] iter = 02460, loss = 2.2340
2024-10-30 22:31:12: [2024-10-30 22:31:12] iter = 02470, loss = 2.7124
2024-10-30 22:31:15: [2024-10-30 22:31:15] iter = 02480, loss = 2.5146
2024-10-30 22:31:19: [2024-10-30 22:31:19] iter = 02490, loss = 1.9611
2024-10-30 22:31:22: [2024-10-30 22:31:22] iter = 02500, loss = 2.4741
2024-10-30 22:31:25: [2024-10-30 22:31:25] iter = 02510, loss = 2.0103
2024-10-30 22:31:28: [2024-10-30 22:31:28] iter = 02520, loss = 2.2898
2024-10-30 22:31:31: [2024-10-30 22:31:31] iter = 02530, loss = 3.7986
2024-10-30 22:31:34: [2024-10-30 22:31:34] iter = 02540, loss = 2.2177
2024-10-30 22:31:38: [2024-10-30 22:31:38] iter = 02550, loss = 1.8756
2024-10-30 22:31:41: [2024-10-30 22:31:41] iter = 02560, loss = 2.5223
2024-10-30 22:31:43: [2024-10-30 22:31:43] iter = 02570, loss = 1.9339
2024-10-30 22:31:46: [2024-10-30 22:31:46] iter = 02580, loss = 9.2923
2024-10-30 22:31:50: [2024-10-30 22:31:50] iter = 02590, loss = 3.1409
2024-10-30 22:31:54: [2024-10-30 22:31:54] iter = 02600, loss = 2.8807
2024-10-30 22:31:57: [2024-10-30 22:31:57] iter = 02610, loss = 1.7621
2024-10-30 22:32:00: [2024-10-30 22:32:00] iter = 02620, loss = 2.2596
2024-10-30 22:32:02: [2024-10-30 22:32:02] iter = 02630, loss = 2.2695
2024-10-30 22:32:04: [2024-10-30 22:32:04] iter = 02640, loss = 2.1072
2024-10-30 22:32:07: [2024-10-30 22:32:07] iter = 02650, loss = 2.4236
2024-10-30 22:32:08: [2024-10-30 22:32:08] iter = 02660, loss = 4.3909
2024-10-30 22:32:11: [2024-10-30 22:32:11] iter = 02670, loss = 1.9994
2024-10-30 22:32:14: [2024-10-30 22:32:14] iter = 02680, loss = 2.2882
2024-10-30 22:32:17: [2024-10-30 22:32:17] iter = 02690, loss = 3.3877
2024-10-30 22:32:19: [2024-10-30 22:32:19] iter = 02700, loss = 2.5237
2024-10-30 22:32:22: [2024-10-30 22:32:22] iter = 02710, loss = 2.1741
2024-10-30 22:32:25: [2024-10-30 22:32:25] iter = 02720, loss = 2.3083
2024-10-30 22:32:29: [2024-10-30 22:32:29] iter = 02730, loss = 2.1605
2024-10-30 22:32:31: [2024-10-30 22:32:31] iter = 02740, loss = 2.1350
2024-10-30 22:32:34: [2024-10-30 22:32:34] iter = 02750, loss = 4.2582
2024-10-30 22:32:37: [2024-10-30 22:32:37] iter = 02760, loss = 1.9870
2024-10-30 22:32:39: [2024-10-30 22:32:39] iter = 02770, loss = 2.6302
2024-10-30 22:32:42: [2024-10-30 22:32:42] iter = 02780, loss = 3.5486
2024-10-30 22:32:46: [2024-10-30 22:32:46] iter = 02790, loss = 2.2027
2024-10-30 22:32:49: [2024-10-30 22:32:49] iter = 02800, loss = 1.9522
2024-10-30 22:32:52: [2024-10-30 22:32:52] iter = 02810, loss = 2.2626
2024-10-30 22:32:55: [2024-10-30 22:32:55] iter = 02820, loss = 3.7031
2024-10-30 22:32:57: [2024-10-30 22:32:57] iter = 02830, loss = 1.9062
2024-10-30 22:33:01: [2024-10-30 22:33:01] iter = 02840, loss = 1.9985
2024-10-30 22:33:04: [2024-10-30 22:33:04] iter = 02850, loss = 2.7210
2024-10-30 22:33:08: [2024-10-30 22:33:08] iter = 02860, loss = 2.8693
2024-10-30 22:33:11: [2024-10-30 22:33:11] iter = 02870, loss = 2.3084
2024-10-30 22:33:14: [2024-10-30 22:33:14] iter = 02880, loss = 2.0068
2024-10-30 22:33:17: [2024-10-30 22:33:17] iter = 02890, loss = 2.3873
2024-10-30 22:33:20: [2024-10-30 22:33:20] iter = 02900, loss = 2.1567
2024-10-30 22:33:23: [2024-10-30 22:33:23] iter = 02910, loss = 2.0078
2024-10-30 22:33:25: [2024-10-30 22:33:25] iter = 02920, loss = 3.4407
2024-10-30 22:33:28: [2024-10-30 22:33:28] iter = 02930, loss = 2.4775
2024-10-30 22:33:31: [2024-10-30 22:33:31] iter = 02940, loss = 2.3794
2024-10-30 22:33:34: [2024-10-30 22:33:34] iter = 02950, loss = 2.7570
2024-10-30 22:33:37: [2024-10-30 22:33:37] iter = 02960, loss = 2.0408
2024-10-30 22:33:40: [2024-10-30 22:33:40] iter = 02970, loss = 2.1150
2024-10-30 22:33:43: [2024-10-30 22:33:43] iter = 02980, loss = 2.0436
2024-10-30 22:33:46: [2024-10-30 22:33:46] iter = 02990, loss = 2.0476
2024-10-30 22:33:49: [2024-10-30 22:33:49] iter = 03000, loss = 1.9893
2024-10-30 22:33:51: [2024-10-30 22:33:51] iter = 03010, loss = 2.0262
2024-10-30 22:33:55: [2024-10-30 22:33:55] iter = 03020, loss = 4.2984
2024-10-30 22:33:58: [2024-10-30 22:33:58] iter = 03030, loss = 2.3770
2024-10-30 22:34:01: [2024-10-30 22:34:01] iter = 03040, loss = 2.1206
2024-10-30 22:34:04: [2024-10-30 22:34:04] iter = 03050, loss = 2.0434
2024-10-30 22:34:07: [2024-10-30 22:34:07] iter = 03060, loss = 2.7909
2024-10-30 22:34:10: [2024-10-30 22:34:10] iter = 03070, loss = 2.7388
2024-10-30 22:34:13: [2024-10-30 22:34:13] iter = 03080, loss = 2.5175
2024-10-30 22:34:16: [2024-10-30 22:34:16] iter = 03090, loss = 2.8309
2024-10-30 22:34:19: [2024-10-30 22:34:19] iter = 03100, loss = 2.2546
2024-10-30 22:34:22: [2024-10-30 22:34:22] iter = 03110, loss = 2.7315
2024-10-30 22:34:24: [2024-10-30 22:34:24] iter = 03120, loss = 2.1367
2024-10-30 22:34:28: [2024-10-30 22:34:28] iter = 03130, loss = 2.9030
2024-10-30 22:34:31: [2024-10-30 22:34:31] iter = 03140, loss = 1.9976
2024-10-30 22:34:33: [2024-10-30 22:34:33] iter = 03150, loss = 2.0151
2024-10-30 22:34:36: [2024-10-30 22:34:36] iter = 03160, loss = 2.4012
2024-10-30 22:34:38: [2024-10-30 22:34:38] iter = 03170, loss = 2.1663
2024-10-30 22:34:42: [2024-10-30 22:34:42] iter = 03180, loss = 2.4538
2024-10-30 22:34:45: [2024-10-30 22:34:45] iter = 03190, loss = 2.1987
2024-10-30 22:34:48: [2024-10-30 22:34:48] iter = 03200, loss = 1.7515
2024-10-30 22:34:51: [2024-10-30 22:34:51] iter = 03210, loss = 2.0572
2024-10-30 22:34:53: [2024-10-30 22:34:53] iter = 03220, loss = 2.6149
2024-10-30 22:34:57: [2024-10-30 22:34:57] iter = 03230, loss = 2.6559
2024-10-30 22:34:59: [2024-10-30 22:34:59] iter = 03240, loss = 2.5159
2024-10-30 22:35:02: [2024-10-30 22:35:02] iter = 03250, loss = 1.9577
2024-10-30 22:35:05: [2024-10-30 22:35:05] iter = 03260, loss = 1.8775
2024-10-30 22:35:08: [2024-10-30 22:35:08] iter = 03270, loss = 2.2648
2024-10-30 22:35:11: [2024-10-30 22:35:11] iter = 03280, loss = 3.0599
2024-10-30 22:35:15: [2024-10-30 22:35:14] iter = 03290, loss = 4.0951
2024-10-30 22:35:17: [2024-10-30 22:35:17] iter = 03300, loss = 2.2458
2024-10-30 22:35:20: [2024-10-30 22:35:20] iter = 03310, loss = 1.8524
2024-10-30 22:35:24: [2024-10-30 22:35:24] iter = 03320, loss = 3.4804
2024-10-30 22:35:28: [2024-10-30 22:35:28] iter = 03330, loss = 2.0009
2024-10-30 22:35:31: [2024-10-30 22:35:31] iter = 03340, loss = 1.8094
2024-10-30 22:35:35: [2024-10-30 22:35:35] iter = 03350, loss = 2.2590
2024-10-30 22:35:39: [2024-10-30 22:35:39] iter = 03360, loss = 1.9981
2024-10-30 22:35:43: [2024-10-30 22:35:43] iter = 03370, loss = 4.6947
2024-10-30 22:35:47: [2024-10-30 22:35:47] iter = 03380, loss = 1.9507
2024-10-30 22:35:50: [2024-10-30 22:35:50] iter = 03390, loss = 1.9804
2024-10-30 22:35:54: [2024-10-30 22:35:54] iter = 03400, loss = 1.9348
2024-10-30 22:35:58: [2024-10-30 22:35:58] iter = 03410, loss = 1.7824
2024-10-30 22:36:01: [2024-10-30 22:36:01] iter = 03420, loss = 2.1235
2024-10-30 22:36:04: [2024-10-30 22:36:04] iter = 03430, loss = 1.5945
2024-10-30 22:36:07: [2024-10-30 22:36:07] iter = 03440, loss = 2.6615
2024-10-30 22:36:10: [2024-10-30 22:36:10] iter = 03450, loss = 4.2530
2024-10-30 22:36:13: [2024-10-30 22:36:13] iter = 03460, loss = 1.8794
2024-10-30 22:36:16: [2024-10-30 22:36:16] iter = 03470, loss = 2.5204
2024-10-30 22:36:20: [2024-10-30 22:36:20] iter = 03480, loss = 2.0869
2024-10-30 22:36:22: [2024-10-30 22:36:22] iter = 03490, loss = 2.2721
2024-10-30 22:36:25: [2024-10-30 22:36:25] iter = 03500, loss = 2.3647
2024-10-30 22:36:27: [2024-10-30 22:36:27] iter = 03510, loss = 2.1532
2024-10-30 22:36:30: [2024-10-30 22:36:30] iter = 03520, loss = 2.0526
2024-10-30 22:36:33: [2024-10-30 22:36:33] iter = 03530, loss = 2.0441
2024-10-30 22:36:37: [2024-10-30 22:36:37] iter = 03540, loss = 2.4133
2024-10-30 22:36:40: [2024-10-30 22:36:40] iter = 03550, loss = 2.1784
2024-10-30 22:36:43: [2024-10-30 22:36:43] iter = 03560, loss = 2.7102
2024-10-30 22:36:46: [2024-10-30 22:36:46] iter = 03570, loss = 2.4149
2024-10-30 22:36:49: [2024-10-30 22:36:49] iter = 03580, loss = 2.0080
2024-10-30 22:36:53: [2024-10-30 22:36:52] iter = 03590, loss = 2.2456
2024-10-30 22:36:55: [2024-10-30 22:36:55] iter = 03600, loss = 2.8003
2024-10-30 22:36:58: [2024-10-30 22:36:58] iter = 03610, loss = 3.4500
2024-10-30 22:37:01: [2024-10-30 22:37:01] iter = 03620, loss = 2.2860
2024-10-30 22:37:04: [2024-10-30 22:37:04] iter = 03630, loss = 2.8736
2024-10-30 22:37:08: [2024-10-30 22:37:08] iter = 03640, loss = 2.0586
2024-10-30 22:37:10: [2024-10-30 22:37:10] iter = 03650, loss = 2.3378
2024-10-30 22:37:13: [2024-10-30 22:37:13] iter = 03660, loss = 2.6820
2024-10-30 22:37:17: [2024-10-30 22:37:17] iter = 03670, loss = 2.5539
2024-10-30 22:37:20: [2024-10-30 22:37:20] iter = 03680, loss = 2.2304
2024-10-30 22:37:23: [2024-10-30 22:37:23] iter = 03690, loss = 2.1958
2024-10-30 22:37:26: [2024-10-30 22:37:26] iter = 03700, loss = 2.2932
2024-10-30 22:37:30: [2024-10-30 22:37:30] iter = 03710, loss = 2.7626
2024-10-30 22:37:33: [2024-10-30 22:37:33] iter = 03720, loss = 3.6269
2024-10-30 22:37:36: [2024-10-30 22:37:36] iter = 03730, loss = 2.5182
2024-10-30 22:37:39: [2024-10-30 22:37:39] iter = 03740, loss = 2.0814
2024-10-30 22:37:41: [2024-10-30 22:37:41] iter = 03750, loss = 2.0476
2024-10-30 22:37:44: [2024-10-30 22:37:44] iter = 03760, loss = 2.1247
2024-10-30 22:37:47: [2024-10-30 22:37:47] iter = 03770, loss = 2.0747
2024-10-30 22:37:51: [2024-10-30 22:37:51] iter = 03780, loss = 2.1745
2024-10-30 22:37:54: [2024-10-30 22:37:54] iter = 03790, loss = 2.0046
2024-10-30 22:37:57: [2024-10-30 22:37:57] iter = 03800, loss = 2.1674
2024-10-30 22:38:00: [2024-10-30 22:38:00] iter = 03810, loss = 3.0044
2024-10-30 22:38:03: [2024-10-30 22:38:03] iter = 03820, loss = 2.3240
2024-10-30 22:38:06: [2024-10-30 22:38:06] iter = 03830, loss = 2.2011
2024-10-30 22:38:09: [2024-10-30 22:38:09] iter = 03840, loss = 2.7244
2024-10-30 22:38:11: [2024-10-30 22:38:11] iter = 03850, loss = 2.7706
2024-10-30 22:38:15: [2024-10-30 22:38:15] iter = 03860, loss = 2.2557
2024-10-30 22:38:18: [2024-10-30 22:38:18] iter = 03870, loss = 2.0328
2024-10-30 22:38:20: [2024-10-30 22:38:20] iter = 03880, loss = 2.7444
2024-10-30 22:38:23: [2024-10-30 22:38:23] iter = 03890, loss = 1.8404
2024-10-30 22:38:25: [2024-10-30 22:38:25] iter = 03900, loss = 2.4798
2024-10-30 22:38:28: [2024-10-30 22:38:28] iter = 03910, loss = 1.8913
2024-10-30 22:38:31: [2024-10-30 22:38:31] iter = 03920, loss = 2.3966
2024-10-30 22:38:34: [2024-10-30 22:38:34] iter = 03930, loss = 1.8815
2024-10-30 22:38:38: [2024-10-30 22:38:38] iter = 03940, loss = 1.9670
2024-10-30 22:38:41: [2024-10-30 22:38:41] iter = 03950, loss = 3.9614
2024-10-30 22:38:44: [2024-10-30 22:38:44] iter = 03960, loss = 1.9768
2024-10-30 22:38:48: [2024-10-30 22:38:48] iter = 03970, loss = 3.0805
2024-10-30 22:38:51: [2024-10-30 22:38:51] iter = 03980, loss = 2.2366
2024-10-30 22:38:55: [2024-10-30 22:38:55] iter = 03990, loss = 2.0565
2024-10-30 22:38:57: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 22:38:57: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:38:57: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 37567}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:40:57: Evaluate 5 random ConvNet, ACCmean = 0.6148 ACCstd = 0.0053
-------------------------
2024-10-30 22:40:57: Evaluate 5 random ConvNet, SENmean = 0.5990 SENstd = 0.0056
-------------------------
2024-10-30 22:40:57: Evaluate 5 random ConvNet, SPEmean = 0.9608 SPEstd = 0.0005
-------------------------
2024-10-30 22:40:57: Evaluate 5 random ConvNet, F!mean = 0.5880 F!std = 0.0060
-------------------------
2024-10-30 22:40:57: Evaluate 5 random ConvNet, mean = 0.6148 std = 0.0053
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:40:58: [2024-10-30 22:40:58] iter = 04000, loss = 2.0522
2024-10-30 22:41:01: [2024-10-30 22:41:01] iter = 04010, loss = 2.4945
2024-10-30 22:41:03: [2024-10-30 22:41:03] iter = 04020, loss = 2.3543
2024-10-30 22:41:06: [2024-10-30 22:41:06] iter = 04030, loss = 2.3570
2024-10-30 22:41:08: [2024-10-30 22:41:08] iter = 04040, loss = 2.1663
2024-10-30 22:41:11: [2024-10-30 22:41:11] iter = 04050, loss = 2.0486
2024-10-30 22:41:14: [2024-10-30 22:41:14] iter = 04060, loss = 2.9859
2024-10-30 22:41:17: [2024-10-30 22:41:17] iter = 04070, loss = 2.4723
2024-10-30 22:41:20: [2024-10-30 22:41:20] iter = 04080, loss = 3.2096
2024-10-30 22:41:23: [2024-10-30 22:41:23] iter = 04090, loss = 3.3320
2024-10-30 22:41:25: [2024-10-30 22:41:25] iter = 04100, loss = 2.1204
2024-10-30 22:41:27: [2024-10-30 22:41:27] iter = 04110, loss = 2.3922
2024-10-30 22:41:31: [2024-10-30 22:41:31] iter = 04120, loss = 2.3411
2024-10-30 22:41:34: [2024-10-30 22:41:34] iter = 04130, loss = 2.0964
2024-10-30 22:41:38: [2024-10-30 22:41:38] iter = 04140, loss = 2.5581
2024-10-30 22:41:40: [2024-10-30 22:41:40] iter = 04150, loss = 2.8379
2024-10-30 22:41:43: [2024-10-30 22:41:43] iter = 04160, loss = 2.0891
2024-10-30 22:41:46: [2024-10-30 22:41:46] iter = 04170, loss = 2.0236
2024-10-30 22:41:49: [2024-10-30 22:41:49] iter = 04180, loss = 2.2930
2024-10-30 22:41:51: [2024-10-30 22:41:51] iter = 04190, loss = 3.1507
2024-10-30 22:41:54: [2024-10-30 22:41:54] iter = 04200, loss = 2.1004
2024-10-30 22:41:56: [2024-10-30 22:41:56] iter = 04210, loss = 2.1485
2024-10-30 22:41:59: [2024-10-30 22:41:59] iter = 04220, loss = 2.1596
2024-10-30 22:42:02: [2024-10-30 22:42:02] iter = 04230, loss = 2.4112
2024-10-30 22:42:05: [2024-10-30 22:42:05] iter = 04240, loss = 2.1897
2024-10-30 22:42:08: [2024-10-30 22:42:08] iter = 04250, loss = 2.6873
2024-10-30 22:42:10: [2024-10-30 22:42:10] iter = 04260, loss = 2.7034
2024-10-30 22:42:13: [2024-10-30 22:42:13] iter = 04270, loss = 2.0165
2024-10-30 22:42:16: [2024-10-30 22:42:16] iter = 04280, loss = 2.1807
2024-10-30 22:42:20: [2024-10-30 22:42:20] iter = 04290, loss = 2.6496
2024-10-30 22:42:23: [2024-10-30 22:42:23] iter = 04300, loss = 2.1665
2024-10-30 22:42:26: [2024-10-30 22:42:26] iter = 04310, loss = 1.9315
2024-10-30 22:42:29: [2024-10-30 22:42:29] iter = 04320, loss = 1.9183
2024-10-30 22:42:32: [2024-10-30 22:42:32] iter = 04330, loss = 1.8577
2024-10-30 22:42:35: [2024-10-30 22:42:35] iter = 04340, loss = 1.9024
2024-10-30 22:42:38: [2024-10-30 22:42:38] iter = 04350, loss = 3.1314
2024-10-30 22:42:42: [2024-10-30 22:42:42] iter = 04360, loss = 3.4482
2024-10-30 22:42:45: [2024-10-30 22:42:45] iter = 04370, loss = 2.3772
2024-10-30 22:42:48: [2024-10-30 22:42:48] iter = 04380, loss = 2.3158
2024-10-30 22:42:51: [2024-10-30 22:42:51] iter = 04390, loss = 1.8540
2024-10-30 22:42:55: [2024-10-30 22:42:55] iter = 04400, loss = 1.9436
2024-10-30 22:42:57: [2024-10-30 22:42:57] iter = 04410, loss = 1.9234
2024-10-30 22:43:00: [2024-10-30 22:43:00] iter = 04420, loss = 2.3412
2024-10-30 22:43:03: [2024-10-30 22:43:03] iter = 04430, loss = 2.4588
2024-10-30 22:43:07: [2024-10-30 22:43:07] iter = 04440, loss = 1.9424
2024-10-30 22:43:10: [2024-10-30 22:43:10] iter = 04450, loss = 2.3583
2024-10-30 22:43:13: [2024-10-30 22:43:13] iter = 04460, loss = 2.4794
2024-10-30 22:43:15: [2024-10-30 22:43:15] iter = 04470, loss = 2.4291
2024-10-30 22:43:18: [2024-10-30 22:43:18] iter = 04480, loss = 2.1062
2024-10-30 22:43:22: [2024-10-30 22:43:22] iter = 04490, loss = 2.1188
2024-10-30 22:43:25: [2024-10-30 22:43:25] iter = 04500, loss = 2.9985
2024-10-30 22:43:28: [2024-10-30 22:43:28] iter = 04510, loss = 2.2711
2024-10-30 22:43:32: [2024-10-30 22:43:32] iter = 04520, loss = 2.2145
2024-10-30 22:43:35: [2024-10-30 22:43:35] iter = 04530, loss = 2.1754
2024-10-30 22:43:37: [2024-10-30 22:43:37] iter = 04540, loss = 3.1530
2024-10-30 22:43:39: [2024-10-30 22:43:39] iter = 04550, loss = 3.2787
2024-10-30 22:43:42: [2024-10-30 22:43:42] iter = 04560, loss = 1.8182
2024-10-30 22:43:45: [2024-10-30 22:43:45] iter = 04570, loss = 2.2296
2024-10-30 22:43:47: [2024-10-30 22:43:47] iter = 04580, loss = 2.0158
2024-10-30 22:43:51: [2024-10-30 22:43:51] iter = 04590, loss = 2.2539
2024-10-30 22:43:53: [2024-10-30 22:43:53] iter = 04600, loss = 2.6761
2024-10-30 22:43:56: [2024-10-30 22:43:56] iter = 04610, loss = 3.1298
2024-10-30 22:43:59: [2024-10-30 22:43:59] iter = 04620, loss = 2.1693
2024-10-30 22:44:03: [2024-10-30 22:44:03] iter = 04630, loss = 1.7875
2024-10-30 22:44:05: [2024-10-30 22:44:05] iter = 04640, loss = 3.1493
2024-10-30 22:44:07: [2024-10-30 22:44:07] iter = 04650, loss = 2.1759
2024-10-30 22:44:10: [2024-10-30 22:44:10] iter = 04660, loss = 4.7171
2024-10-30 22:44:13: [2024-10-30 22:44:13] iter = 04670, loss = 2.9967
2024-10-30 22:44:16: [2024-10-30 22:44:16] iter = 04680, loss = 2.8185
2024-10-30 22:44:19: [2024-10-30 22:44:19] iter = 04690, loss = 2.0162
2024-10-30 22:44:21: [2024-10-30 22:44:21] iter = 04700, loss = 2.7630
2024-10-30 22:44:24: [2024-10-30 22:44:24] iter = 04710, loss = 1.8652
2024-10-30 22:44:27: [2024-10-30 22:44:27] iter = 04720, loss = 2.0825
2024-10-30 22:44:29: [2024-10-30 22:44:29] iter = 04730, loss = 2.1859
2024-10-30 22:44:33: [2024-10-30 22:44:33] iter = 04740, loss = 2.4030
2024-10-30 22:44:35: [2024-10-30 22:44:35] iter = 04750, loss = 2.7093
2024-10-30 22:44:39: [2024-10-30 22:44:39] iter = 04760, loss = 2.0259
2024-10-30 22:44:42: [2024-10-30 22:44:42] iter = 04770, loss = 2.4473
2024-10-30 22:44:45: [2024-10-30 22:44:45] iter = 04780, loss = 2.0263
2024-10-30 22:44:48: [2024-10-30 22:44:48] iter = 04790, loss = 2.0394
2024-10-30 22:44:51: [2024-10-30 22:44:51] iter = 04800, loss = 3.0454
2024-10-30 22:44:55: [2024-10-30 22:44:55] iter = 04810, loss = 2.0606
2024-10-30 22:44:58: [2024-10-30 22:44:58] iter = 04820, loss = 3.7560
2024-10-30 22:45:00: [2024-10-30 22:45:00] iter = 04830, loss = 2.5052
2024-10-30 22:45:04: [2024-10-30 22:45:04] iter = 04840, loss = 1.8738
2024-10-30 22:45:07: [2024-10-30 22:45:07] iter = 04850, loss = 2.1482
2024-10-30 22:45:09: [2024-10-30 22:45:09] iter = 04860, loss = 1.8406
2024-10-30 22:45:12: [2024-10-30 22:45:12] iter = 04870, loss = 2.2103
2024-10-30 22:45:15: [2024-10-30 22:45:15] iter = 04880, loss = 3.2775
2024-10-30 22:45:18: [2024-10-30 22:45:18] iter = 04890, loss = 2.7143
2024-10-30 22:45:21: [2024-10-30 22:45:21] iter = 04900, loss = 2.4589
2024-10-30 22:45:23: [2024-10-30 22:45:23] iter = 04910, loss = 2.6428
2024-10-30 22:45:26: [2024-10-30 22:45:26] iter = 04920, loss = 1.8947
2024-10-30 22:45:29: [2024-10-30 22:45:29] iter = 04930, loss = 3.2728
2024-10-30 22:45:32: [2024-10-30 22:45:32] iter = 04940, loss = 2.0940
2024-10-30 22:45:34: [2024-10-30 22:45:34] iter = 04950, loss = 1.8880
2024-10-30 22:45:36: [2024-10-30 22:45:36] iter = 04960, loss = 2.0275
2024-10-30 22:45:39: [2024-10-30 22:45:39] iter = 04970, loss = 3.4414
2024-10-30 22:45:42: [2024-10-30 22:45:42] iter = 04980, loss = 1.9369
2024-10-30 22:45:45: [2024-10-30 22:45:45] iter = 04990, loss = 1.8960
2024-10-30 22:45:47: [2024-10-30 22:45:47] iter = 05000, loss = 3.3766
2024-10-30 22:45:51: [2024-10-30 22:45:51] iter = 05010, loss = 2.4483
2024-10-30 22:45:55: [2024-10-30 22:45:54] iter = 05020, loss = 2.2495
2024-10-30 22:45:58: [2024-10-30 22:45:58] iter = 05030, loss = 2.3767
2024-10-30 22:46:00: [2024-10-30 22:46:00] iter = 05040, loss = 2.4482
2024-10-30 22:46:03: [2024-10-30 22:46:03] iter = 05050, loss = 2.2209
2024-10-30 22:46:05: [2024-10-30 22:46:05] iter = 05060, loss = 1.8651
2024-10-30 22:46:07: [2024-10-30 22:46:07] iter = 05070, loss = 3.1548
2024-10-30 22:46:10: [2024-10-30 22:46:10] iter = 05080, loss = 2.5878
2024-10-30 22:46:13: [2024-10-30 22:46:13] iter = 05090, loss = 2.8914
2024-10-30 22:46:16: [2024-10-30 22:46:16] iter = 05100, loss = 2.1625
2024-10-30 22:46:18: [2024-10-30 22:46:18] iter = 05110, loss = 2.2221
2024-10-30 22:46:21: [2024-10-30 22:46:21] iter = 05120, loss = 1.9399
2024-10-30 22:46:25: [2024-10-30 22:46:25] iter = 05130, loss = 2.6991
2024-10-30 22:46:28: [2024-10-30 22:46:28] iter = 05140, loss = 2.0593
2024-10-30 22:46:32: [2024-10-30 22:46:32] iter = 05150, loss = 2.4456
2024-10-30 22:46:35: [2024-10-30 22:46:35] iter = 05160, loss = 1.9782
2024-10-30 22:46:37: [2024-10-30 22:46:37] iter = 05170, loss = 2.1761
2024-10-30 22:46:41: [2024-10-30 22:46:40] iter = 05180, loss = 1.8853
2024-10-30 22:46:44: [2024-10-30 22:46:44] iter = 05190, loss = 4.1671
2024-10-30 22:46:46: [2024-10-30 22:46:46] iter = 05200, loss = 2.1366
2024-10-30 22:46:48: [2024-10-30 22:46:48] iter = 05210, loss = 2.0381
2024-10-30 22:46:51: [2024-10-30 22:46:51] iter = 05220, loss = 2.2931
2024-10-30 22:46:54: [2024-10-30 22:46:54] iter = 05230, loss = 1.8848
2024-10-30 22:46:58: [2024-10-30 22:46:58] iter = 05240, loss = 2.1804
2024-10-30 22:47:01: [2024-10-30 22:47:01] iter = 05250, loss = 2.2658
2024-10-30 22:47:05: [2024-10-30 22:47:05] iter = 05260, loss = 2.4501
2024-10-30 22:47:09: [2024-10-30 22:47:09] iter = 05270, loss = 2.4452
2024-10-30 22:47:12: [2024-10-30 22:47:12] iter = 05280, loss = 2.4760
2024-10-30 22:47:15: [2024-10-30 22:47:15] iter = 05290, loss = 2.3878
2024-10-30 22:47:19: [2024-10-30 22:47:19] iter = 05300, loss = 2.1028
2024-10-30 22:47:22: [2024-10-30 22:47:22] iter = 05310, loss = 2.6062
2024-10-30 22:47:26: [2024-10-30 22:47:26] iter = 05320, loss = 1.9700
2024-10-30 22:47:29: [2024-10-30 22:47:29] iter = 05330, loss = 2.3985
2024-10-30 22:47:32: [2024-10-30 22:47:32] iter = 05340, loss = 2.2937
2024-10-30 22:47:35: [2024-10-30 22:47:35] iter = 05350, loss = 3.3489
2024-10-30 22:47:38: [2024-10-30 22:47:38] iter = 05360, loss = 2.4227
2024-10-30 22:47:41: [2024-10-30 22:47:41] iter = 05370, loss = 4.5217
2024-10-30 22:47:43: [2024-10-30 22:47:43] iter = 05380, loss = 2.4787
2024-10-30 22:47:46: [2024-10-30 22:47:46] iter = 05390, loss = 1.9709
2024-10-30 22:47:49: [2024-10-30 22:47:49] iter = 05400, loss = 2.7469
2024-10-30 22:47:53: [2024-10-30 22:47:53] iter = 05410, loss = 2.5406
2024-10-30 22:47:57: [2024-10-30 22:47:57] iter = 05420, loss = 1.9729
2024-10-30 22:48:02: [2024-10-30 22:48:02] iter = 05430, loss = 1.9027
2024-10-30 22:48:05: [2024-10-30 22:48:05] iter = 05440, loss = 2.4588
2024-10-30 22:48:09: [2024-10-30 22:48:09] iter = 05450, loss = 2.5233
2024-10-30 22:48:12: [2024-10-30 22:48:12] iter = 05460, loss = 1.8457
2024-10-30 22:48:15: [2024-10-30 22:48:15] iter = 05470, loss = 2.0316
2024-10-30 22:48:19: [2024-10-30 22:48:19] iter = 05480, loss = 2.6990
2024-10-30 22:48:22: [2024-10-30 22:48:22] iter = 05490, loss = 3.0441
2024-10-30 22:48:25: [2024-10-30 22:48:25] iter = 05500, loss = 2.7697
2024-10-30 22:48:28: [2024-10-30 22:48:28] iter = 05510, loss = 1.9791
2024-10-30 22:48:31: [2024-10-30 22:48:31] iter = 05520, loss = 2.2823
2024-10-30 22:48:33: [2024-10-30 22:48:33] iter = 05530, loss = 2.2154
2024-10-30 22:48:35: [2024-10-30 22:48:35] iter = 05540, loss = 2.1691
2024-10-30 22:48:39: [2024-10-30 22:48:39] iter = 05550, loss = 2.4230
2024-10-30 22:48:42: [2024-10-30 22:48:42] iter = 05560, loss = 2.1207
2024-10-30 22:48:46: [2024-10-30 22:48:46] iter = 05570, loss = 2.6063
2024-10-30 22:48:49: [2024-10-30 22:48:49] iter = 05580, loss = 2.3330
2024-10-30 22:48:53: [2024-10-30 22:48:53] iter = 05590, loss = 2.3186
2024-10-30 22:48:56: [2024-10-30 22:48:56] iter = 05600, loss = 2.5648
2024-10-30 22:48:59: [2024-10-30 22:48:59] iter = 05610, loss = 2.1236
2024-10-30 22:49:01: [2024-10-30 22:49:01] iter = 05620, loss = 3.1777
2024-10-30 22:49:04: [2024-10-30 22:49:04] iter = 05630, loss = 2.3457
2024-10-30 22:49:06: [2024-10-30 22:49:06] iter = 05640, loss = 2.0902
2024-10-30 22:49:09: [2024-10-30 22:49:09] iter = 05650, loss = 2.4342
2024-10-30 22:49:12: [2024-10-30 22:49:12] iter = 05660, loss = 2.0210
2024-10-30 22:49:15: [2024-10-30 22:49:15] iter = 05670, loss = 1.8686
2024-10-30 22:49:17: [2024-10-30 22:49:17] iter = 05680, loss = 2.5368
2024-10-30 22:49:21: [2024-10-30 22:49:21] iter = 05690, loss = 2.3182
2024-10-30 22:49:24: [2024-10-30 22:49:24] iter = 05700, loss = 2.0888
2024-10-30 22:49:27: [2024-10-30 22:49:27] iter = 05710, loss = 2.3137
2024-10-30 22:49:31: [2024-10-30 22:49:31] iter = 05720, loss = 2.6743
2024-10-30 22:49:34: [2024-10-30 22:49:34] iter = 05730, loss = 1.7819
2024-10-30 22:49:37: [2024-10-30 22:49:37] iter = 05740, loss = 3.6641
2024-10-30 22:49:40: [2024-10-30 22:49:40] iter = 05750, loss = 2.2676
2024-10-30 22:49:43: [2024-10-30 22:49:43] iter = 05760, loss = 3.3115
2024-10-30 22:49:46: [2024-10-30 22:49:46] iter = 05770, loss = 3.6501
2024-10-30 22:49:49: [2024-10-30 22:49:49] iter = 05780, loss = 2.5933
2024-10-30 22:49:52: [2024-10-30 22:49:52] iter = 05790, loss = 2.5149
2024-10-30 22:49:56: [2024-10-30 22:49:56] iter = 05800, loss = 2.0214
2024-10-30 22:50:00: [2024-10-30 22:50:00] iter = 05810, loss = 2.9916
2024-10-30 22:50:03: [2024-10-30 22:50:03] iter = 05820, loss = 2.2753
2024-10-30 22:50:06: [2024-10-30 22:50:06] iter = 05830, loss = 1.9618
2024-10-30 22:50:09: [2024-10-30 22:50:09] iter = 05840, loss = 1.9336
2024-10-30 22:50:12: [2024-10-30 22:50:12] iter = 05850, loss = 2.1141
2024-10-30 22:50:15: [2024-10-30 22:50:15] iter = 05860, loss = 1.9171
2024-10-30 22:50:18: [2024-10-30 22:50:18] iter = 05870, loss = 1.9023
2024-10-30 22:50:21: [2024-10-30 22:50:21] iter = 05880, loss = 3.2615
2024-10-30 22:50:24: [2024-10-30 22:50:24] iter = 05890, loss = 2.9158
2024-10-30 22:50:27: [2024-10-30 22:50:27] iter = 05900, loss = 2.3963
2024-10-30 22:50:30: [2024-10-30 22:50:30] iter = 05910, loss = 2.1289
2024-10-30 22:50:32: [2024-10-30 22:50:32] iter = 05920, loss = 2.3441
2024-10-30 22:50:34: [2024-10-30 22:50:34] iter = 05930, loss = 2.1850
2024-10-30 22:50:37: [2024-10-30 22:50:37] iter = 05940, loss = 2.0893
2024-10-30 22:50:40: [2024-10-30 22:50:40] iter = 05950, loss = 2.2798
2024-10-30 22:50:43: [2024-10-30 22:50:43] iter = 05960, loss = 3.7115
2024-10-30 22:50:46: [2024-10-30 22:50:46] iter = 05970, loss = 2.4297
2024-10-30 22:50:49: [2024-10-30 22:50:49] iter = 05980, loss = 2.6360
2024-10-30 22:50:50: [2024-10-30 22:50:50] iter = 05990, loss = 2.8973
2024-10-30 22:50:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 22:50:53: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:50:53: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53389}

[2024-10-30 21:03:35] Evaluate_02: epoch = 1000 train time = 30 s train loss = 0.046635 train acc = 1.0000, test acc = 0.6210, test_sen =0.5942, test_spe =0.9612, test_f1 =0.5896
[2024-10-30 21:04:06] Evaluate_03: epoch = 1000 train time = 29 s train loss = 0.010613 train acc = 1.0000, test acc = 0.6077, test_sen =0.5882, test_spe =0.9601, test_f1 =0.5799
[2024-10-30 21:04:37] Evaluate_04: epoch = 1000 train time = 29 s train loss = 0.011380 train acc = 1.0000, test acc = 0.6095, test_sen =0.5845, test_spe =0.9601, test_f1 =0.5779
[2024-10-30 21:16:46] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.025485 train acc = 1.0000, test acc = 0.6054, test_sen =0.5865, test_spe =0.9597, test_f1 =0.5756
[2024-10-30 21:17:14] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.013435 train acc = 1.0000, test acc = 0.6114, test_sen =0.5883, test_spe =0.9603, test_f1 =0.5818
[2024-10-30 21:17:41] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.067462 train acc = 0.9909, test acc = 0.6114, test_sen =0.5901, test_spe =0.9601, test_f1 =0.5831
[2024-10-30 21:18:08] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.007006 train acc = 1.0000, test acc = 0.6177, test_sen =0.5973, test_spe =0.9609, test_f1 =0.5915
[2024-10-30 21:18:37] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.009619 train acc = 1.0000, test acc = 0.6130, test_sen =0.5936, test_spe =0.9603, test_f1 =0.5880
[2024-10-30 21:30:19] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.049901 train acc = 1.0000, test acc = 0.5971, test_sen =0.5847, test_spe =0.9590, test_f1 =0.5736
[2024-10-30 21:30:44] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.010230 train acc = 1.0000, test acc = 0.5858, test_sen =0.5762, test_spe =0.9580, test_f1 =0.5636
[2024-10-30 21:31:08] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.018783 train acc = 1.0000, test acc = 0.5969, test_sen =0.5890, test_spe =0.9591, test_f1 =0.5742
[2024-10-30 21:31:38] Evaluate_03: epoch = 1000 train time = 28 s train loss = 0.007827 train acc = 1.0000, test acc = 0.5821, test_sen =0.5775, test_spe =0.9576, test_f1 =0.5648
[2024-10-30 21:32:04] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.011763 train acc = 1.0000, test acc = 0.5889, test_sen =0.5839, test_spe =0.9582, test_f1 =0.5701
[2024-10-30 21:44:17] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.009151 train acc = 1.0000, test acc = 0.6019, test_sen =0.5864, test_spe =0.9593, test_f1 =0.5762
[2024-10-30 21:44:47] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.007587 train acc = 1.0000, test acc = 0.6030, test_sen =0.5863, test_spe =0.9595, test_f1 =0.5754
[2024-10-30 21:45:19] Evaluate_02: epoch = 1000 train time = 31 s train loss = 0.069611 train acc = 1.0000, test acc = 0.5982, test_sen =0.5840, test_spe =0.9590, test_f1 =0.5759
[2024-10-30 21:45:43] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.032245 train acc = 1.0000, test acc = 0.6037, test_sen =0.5927, test_spe =0.9597, test_f1 =0.5810
[2024-10-30 21:46:08] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.009867 train acc = 1.0000, test acc = 0.6021, test_sen =0.5828, test_spe =0.9594, test_f1 =0.5746
[2024-10-30 21:58:38] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.010705 train acc = 1.0000, test acc = 0.5994, test_sen =0.5813, test_spe =0.9593, test_f1 =0.5705
[2024-10-30 21:59:05] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.017595 train acc = 1.0000, test acc = 0.5974, test_sen =0.5776, test_spe =0.9589, test_f1 =0.5716
[2024-10-30 21:59:43] Evaluate_02: epoch = 1000 train time = 36 s train loss = 0.044829 train acc = 1.0000, test acc = 0.5961, test_sen =0.5788, test_spe =0.9588, test_f1 =0.5710
[2024-10-30 22:00:23] Evaluate_03: epoch = 1000 train time = 38 s train loss = 0.019522 train acc = 1.0000, test acc = 0.5983, test_sen =0.5830, test_spe =0.9592, test_f1 =0.5700
[2024-10-30 22:00:51] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.062430 train acc = 1.0000, test acc = 0.6001, test_sen =0.5855, test_spe =0.9594, test_f1 =0.5711
[2024-10-30 22:12:36] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.022975 train acc = 1.0000, test acc = 0.6126, test_sen =0.5866, test_spe =0.9605, test_f1 =0.5782
[2024-10-30 22:12:59] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.009263 train acc = 1.0000, test acc = 0.6188, test_sen =0.5901, test_spe =0.9613, test_f1 =0.5809
[2024-10-30 22:13:27] Evaluate_02: epoch = 1000 train time = 26 s train loss = 0.038229 train acc = 1.0000, test acc = 0.6156, test_sen =0.5907, test_spe =0.9610, test_f1 =0.5810
[2024-10-30 22:13:54] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.008133 train acc = 1.0000, test acc = 0.6187, test_sen =0.5925, test_spe =0.9613, test_f1 =0.5830
[2024-10-30 22:14:20] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.042547 train acc = 1.0000, test acc = 0.6133, test_sen =0.5924, test_spe =0.9609, test_f1 =0.5849
[2024-10-30 22:14:50] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.003967 train acc = 1.0000, test acc = 0.4485, test_sen =0.4514, test_spe =0.9442, test_f1 =0.4470
[2024-10-30 22:15:16] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.005461 train acc = 1.0000, test acc = 0.4427, test_sen =0.4435, test_spe =0.9433, test_f1 =0.4393
[2024-10-30 22:15:40] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.038927 train acc = 1.0000, test acc = 0.4486, test_sen =0.4490, test_spe =0.9439, test_f1 =0.4476
[2024-10-30 22:16:04] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.053412 train acc = 1.0000, test acc = 0.4534, test_sen =0.4566, test_spe =0.9446, test_f1 =0.4505
[2024-10-30 22:16:29] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.006783 train acc = 1.0000, test acc = 0.4518, test_sen =0.4560, test_spe =0.9446, test_f1 =0.4492
[2024-10-30 22:27:12] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.070884 train acc = 0.9818, test acc = 0.6026, test_sen =0.5837, test_spe =0.9594, test_f1 =0.5763
[2024-10-30 22:27:38] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.056238 train acc = 0.9818, test acc = 0.6000, test_sen =0.5842, test_spe =0.9593, test_f1 =0.5749
[2024-10-30 22:28:04] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.009246 train acc = 1.0000, test acc = 0.5968, test_sen =0.5757, test_spe =0.9590, test_f1 =0.5675
[2024-10-30 22:28:29] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.031851 train acc = 1.0000, test acc = 0.5994, test_sen =0.5792, test_spe =0.9591, test_f1 =0.5738
[2024-10-30 22:28:51] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.059999 train acc = 0.9909, test acc = 0.5961, test_sen =0.5785, test_spe =0.9587, test_f1 =0.5707
[2024-10-30 22:39:21] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.039430 train acc = 1.0000, test acc = 0.6221, test_sen =0.6032, test_spe =0.9615, test_f1 =0.5932
[2024-10-30 22:39:46] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.017829 train acc = 0.9909, test acc = 0.6154, test_sen =0.6040, test_spe =0.9609, test_f1 =0.5916
[2024-10-30 22:40:08] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.009341 train acc = 1.0000, test acc = 0.6094, test_sen =0.5897, test_spe =0.9602, test_f1 =0.5787
[2024-10-30 22:40:35] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.078391 train acc = 0.9909, test acc = 0.6082, test_sen =0.5954, test_spe =0.9602, test_f1 =0.5829
[2024-10-30 22:40:57] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.034377 train acc = 1.0000, test acc = 0.6187, test_sen =0.6030, test_spe =0.9612, test_f1 =0.5933
[2024-10-30 22:51:14] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.084411 train acc = 0.9818, test acc = 0.6145, test_sen =0.5862, test_spe =0.9605, test_f1 =0.5805
[2024-10-30 22:51:40] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.020941 train acc = 1.0000, test acc = 0.6197, test_sen =0.5949, test_spe =0.9610, test_f1 =0.5895
[2024-10-30 22:52:02] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.077789 train acc = 0.9909, test acc = 0.6105, test_sen =0.5878, test_spe =0.9602, test_f1 =0.5797/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:52:52: Evaluate 5 random ConvNet, ACCmean = 0.6153 ACCstd = 0.0032
-------------------------
2024-10-30 22:52:52: Evaluate 5 random ConvNet, SENmean = 0.5924 SENstd = 0.0046
-------------------------
2024-10-30 22:52:52: Evaluate 5 random ConvNet, SPEmean = 0.9607 SPEstd = 0.0003
-------------------------
2024-10-30 22:52:52: Evaluate 5 random ConvNet, F!mean = 0.5852 F!std = 0.0051
-------------------------
2024-10-30 22:52:52: Evaluate 5 random ConvNet, mean = 0.6153 std = 0.0032
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:52:52: [2024-10-30 22:52:52] iter = 06000, loss = 2.2634
2024-10-30 22:52:55: [2024-10-30 22:52:55] iter = 06010, loss = 1.8482
2024-10-30 22:52:58: [2024-10-30 22:52:58] iter = 06020, loss = 1.9825
2024-10-30 22:53:01: [2024-10-30 22:53:01] iter = 06030, loss = 4.6269
2024-10-30 22:53:03: [2024-10-30 22:53:03] iter = 06040, loss = 2.6288
2024-10-30 22:53:06: [2024-10-30 22:53:06] iter = 06050, loss = 2.0754
2024-10-30 22:53:09: [2024-10-30 22:53:09] iter = 06060, loss = 1.9019
2024-10-30 22:53:13: [2024-10-30 22:53:13] iter = 06070, loss = 2.6598
2024-10-30 22:53:16: [2024-10-30 22:53:16] iter = 06080, loss = 2.0877
2024-10-30 22:53:19: [2024-10-30 22:53:19] iter = 06090, loss = 1.9160
2024-10-30 22:53:22: [2024-10-30 22:53:22] iter = 06100, loss = 3.2606
2024-10-30 22:53:26: [2024-10-30 22:53:26] iter = 06110, loss = 1.9877
2024-10-30 22:53:29: [2024-10-30 22:53:29] iter = 06120, loss = 2.6805
2024-10-30 22:53:32: [2024-10-30 22:53:32] iter = 06130, loss = 1.9276
2024-10-30 22:53:35: [2024-10-30 22:53:35] iter = 06140, loss = 2.0576
2024-10-30 22:53:38: [2024-10-30 22:53:38] iter = 06150, loss = 1.7752
2024-10-30 22:53:41: [2024-10-30 22:53:41] iter = 06160, loss = 2.0815
2024-10-30 22:53:45: [2024-10-30 22:53:45] iter = 06170, loss = 2.5509
2024-10-30 22:53:48: [2024-10-30 22:53:48] iter = 06180, loss = 2.1560
2024-10-30 22:53:51: [2024-10-30 22:53:51] iter = 06190, loss = 1.8699
2024-10-30 22:53:53: [2024-10-30 22:53:53] iter = 06200, loss = 2.1160
2024-10-30 22:53:56: [2024-10-30 22:53:56] iter = 06210, loss = 2.6409
2024-10-30 22:53:59: [2024-10-30 22:53:59] iter = 06220, loss = 1.8752
2024-10-30 22:54:02: [2024-10-30 22:54:02] iter = 06230, loss = 2.1963
2024-10-30 22:54:05: [2024-10-30 22:54:05] iter = 06240, loss = 2.3834
2024-10-30 22:54:09: [2024-10-30 22:54:09] iter = 06250, loss = 5.6924
2024-10-30 22:54:12: [2024-10-30 22:54:12] iter = 06260, loss = 2.2102
2024-10-30 22:54:16: [2024-10-30 22:54:16] iter = 06270, loss = 1.9181
2024-10-30 22:54:18: [2024-10-30 22:54:18] iter = 06280, loss = 2.0419
2024-10-30 22:54:21: [2024-10-30 22:54:21] iter = 06290, loss = 2.8474
2024-10-30 22:54:24: [2024-10-30 22:54:24] iter = 06300, loss = 1.7621
2024-10-30 22:54:26: [2024-10-30 22:54:26] iter = 06310, loss = 2.6950
2024-10-30 22:54:28: [2024-10-30 22:54:28] iter = 06320, loss = 2.0366
2024-10-30 22:54:30: [2024-10-30 22:54:30] iter = 06330, loss = 1.9386
2024-10-30 22:54:33: [2024-10-30 22:54:33] iter = 06340, loss = 2.2420
2024-10-30 22:54:37: [2024-10-30 22:54:37] iter = 06350, loss = 2.3965
2024-10-30 22:54:40: [2024-10-30 22:54:40] iter = 06360, loss = 2.2117
2024-10-30 22:54:44: [2024-10-30 22:54:44] iter = 06370, loss = 1.9315
2024-10-30 22:54:48: [2024-10-30 22:54:48] iter = 06380, loss = 2.0239
2024-10-30 22:54:51: [2024-10-30 22:54:51] iter = 06390, loss = 3.5289
2024-10-30 22:54:55: [2024-10-30 22:54:55] iter = 06400, loss = 2.1174
2024-10-30 22:54:59: [2024-10-30 22:54:59] iter = 06410, loss = 2.0678
2024-10-30 22:55:02: [2024-10-30 22:55:02] iter = 06420, loss = 2.4291
2024-10-30 22:55:05: [2024-10-30 22:55:05] iter = 06430, loss = 2.2231
2024-10-30 22:55:08: [2024-10-30 22:55:08] iter = 06440, loss = 2.0907
2024-10-30 22:55:11: [2024-10-30 22:55:11] iter = 06450, loss = 3.3727
2024-10-30 22:55:14: [2024-10-30 22:55:14] iter = 06460, loss = 2.2178
2024-10-30 22:55:17: [2024-10-30 22:55:17] iter = 06470, loss = 3.5076
2024-10-30 22:55:20: [2024-10-30 22:55:20] iter = 06480, loss = 2.0802
2024-10-30 22:55:23: [2024-10-30 22:55:23] iter = 06490, loss = 1.9138
2024-10-30 22:55:26: [2024-10-30 22:55:26] iter = 06500, loss = 2.3908
2024-10-30 22:55:29: [2024-10-30 22:55:29] iter = 06510, loss = 1.9230
2024-10-30 22:55:32: [2024-10-30 22:55:32] iter = 06520, loss = 2.7262
2024-10-30 22:55:34: [2024-10-30 22:55:34] iter = 06530, loss = 2.0100
2024-10-30 22:55:38: [2024-10-30 22:55:38] iter = 06540, loss = 1.7936
2024-10-30 22:55:42: [2024-10-30 22:55:42] iter = 06550, loss = 3.0128
2024-10-30 22:55:45: [2024-10-30 22:55:45] iter = 06560, loss = 2.1609
2024-10-30 22:55:48: [2024-10-30 22:55:48] iter = 06570, loss = 2.2898
2024-10-30 22:55:51: [2024-10-30 22:55:51] iter = 06580, loss = 2.1890
2024-10-30 22:55:54: [2024-10-30 22:55:54] iter = 06590, loss = 2.1607
2024-10-30 22:55:57: [2024-10-30 22:55:57] iter = 06600, loss = 2.1148
2024-10-30 22:56:00: [2024-10-30 22:56:00] iter = 06610, loss = 1.7620
2024-10-30 22:56:03: [2024-10-30 22:56:03] iter = 06620, loss = 2.8101
2024-10-30 22:56:06: [2024-10-30 22:56:06] iter = 06630, loss = 2.7061
2024-10-30 22:56:08: [2024-10-30 22:56:08] iter = 06640, loss = 2.0244
2024-10-30 22:56:11: [2024-10-30 22:56:11] iter = 06650, loss = 1.9573
2024-10-30 22:56:14: [2024-10-30 22:56:14] iter = 06660, loss = 3.2619
2024-10-30 22:56:17: [2024-10-30 22:56:17] iter = 06670, loss = 2.0213
2024-10-30 22:56:21: [2024-10-30 22:56:21] iter = 06680, loss = 2.0755
2024-10-30 22:56:24: [2024-10-30 22:56:24] iter = 06690, loss = 2.0581
2024-10-30 22:56:27: [2024-10-30 22:56:27] iter = 06700, loss = 1.7134
2024-10-30 22:56:30: [2024-10-30 22:56:30] iter = 06710, loss = 2.0827
2024-10-30 22:56:33: [2024-10-30 22:56:33] iter = 06720, loss = 2.4162
2024-10-30 22:56:36: [2024-10-30 22:56:36] iter = 06730, loss = 2.6189
2024-10-30 22:56:39: [2024-10-30 22:56:39] iter = 06740, loss = 2.0069
2024-10-30 22:56:43: [2024-10-30 22:56:42] iter = 06750, loss = 1.7949
2024-10-30 22:56:45: [2024-10-30 22:56:45] iter = 06760, loss = 2.3334
2024-10-30 22:56:47: [2024-10-30 22:56:47] iter = 06770, loss = 1.9716
2024-10-30 22:56:49: [2024-10-30 22:56:49] iter = 06780, loss = 5.9576
2024-10-30 22:56:51: [2024-10-30 22:56:51] iter = 06790, loss = 1.8801
2024-10-30 22:56:53: [2024-10-30 22:56:53] iter = 06800, loss = 2.0659
2024-10-30 22:56:56: [2024-10-30 22:56:56] iter = 06810, loss = 2.4846
2024-10-30 22:56:59: [2024-10-30 22:56:59] iter = 06820, loss = 2.2067
2024-10-30 22:57:01: [2024-10-30 22:57:01] iter = 06830, loss = 2.3297
2024-10-30 22:57:03: [2024-10-30 22:57:03] iter = 06840, loss = 2.1115
2024-10-30 22:57:06: [2024-10-30 22:57:06] iter = 06850, loss = 2.2397
2024-10-30 22:57:10: [2024-10-30 22:57:10] iter = 06860, loss = 2.3360
2024-10-30 22:57:14: [2024-10-30 22:57:14] iter = 06870, loss = 2.1536
2024-10-30 22:57:17: [2024-10-30 22:57:17] iter = 06880, loss = 1.8356
2024-10-30 22:57:20: [2024-10-30 22:57:20] iter = 06890, loss = 3.1273
2024-10-30 22:57:23: [2024-10-30 22:57:23] iter = 06900, loss = 2.8452
2024-10-30 22:57:26: [2024-10-30 22:57:26] iter = 06910, loss = 2.2997
2024-10-30 22:57:28: [2024-10-30 22:57:28] iter = 06920, loss = 2.7395
2024-10-30 22:57:31: [2024-10-30 22:57:31] iter = 06930, loss = 2.4745
2024-10-30 22:57:33: [2024-10-30 22:57:33] iter = 06940, loss = 2.1385
2024-10-30 22:57:37: [2024-10-30 22:57:37] iter = 06950, loss = 2.7128
2024-10-30 22:57:40: [2024-10-30 22:57:40] iter = 06960, loss = 2.0243
2024-10-30 22:57:43: [2024-10-30 22:57:43] iter = 06970, loss = 3.0621
2024-10-30 22:57:46: [2024-10-30 22:57:46] iter = 06980, loss = 1.7557
2024-10-30 22:57:48: [2024-10-30 22:57:48] iter = 06990, loss = 3.3856
2024-10-30 22:57:51: [2024-10-30 22:57:51] iter = 07000, loss = 1.7918
2024-10-30 22:57:53: [2024-10-30 22:57:53] iter = 07010, loss = 2.6953
2024-10-30 22:57:56: [2024-10-30 22:57:56] iter = 07020, loss = 2.1120
2024-10-30 22:57:58: [2024-10-30 22:57:58] iter = 07030, loss = 1.8758
2024-10-30 22:58:01: [2024-10-30 22:58:01] iter = 07040, loss = 1.9946
2024-10-30 22:58:03: [2024-10-30 22:58:03] iter = 07050, loss = 3.9711
2024-10-30 22:58:05: [2024-10-30 22:58:05] iter = 07060, loss = 1.9456
2024-10-30 22:58:08: [2024-10-30 22:58:08] iter = 07070, loss = 2.3806
2024-10-30 22:58:11: [2024-10-30 22:58:11] iter = 07080, loss = 1.9447
2024-10-30 22:58:14: [2024-10-30 22:58:14] iter = 07090, loss = 2.2448
2024-10-30 22:58:17: [2024-10-30 22:58:17] iter = 07100, loss = 2.1199
2024-10-30 22:58:20: [2024-10-30 22:58:20] iter = 07110, loss = 2.5722
2024-10-30 22:58:24: [2024-10-30 22:58:24] iter = 07120, loss = 1.9722
2024-10-30 22:58:26: [2024-10-30 22:58:26] iter = 07130, loss = 3.3086
2024-10-30 22:58:29: [2024-10-30 22:58:29] iter = 07140, loss = 2.2310
2024-10-30 22:58:32: [2024-10-30 22:58:32] iter = 07150, loss = 2.0060
2024-10-30 22:58:35: [2024-10-30 22:58:35] iter = 07160, loss = 2.1228
2024-10-30 22:58:38: [2024-10-30 22:58:38] iter = 07170, loss = 1.8550
2024-10-30 22:58:41: [2024-10-30 22:58:41] iter = 07180, loss = 1.9083
2024-10-30 22:58:43: [2024-10-30 22:58:43] iter = 07190, loss = 3.8374
2024-10-30 22:58:46: [2024-10-30 22:58:46] iter = 07200, loss = 3.0359
2024-10-30 22:58:50: [2024-10-30 22:58:50] iter = 07210, loss = 2.2827
2024-10-30 22:58:53: [2024-10-30 22:58:53] iter = 07220, loss = 2.2400
2024-10-30 22:58:57: [2024-10-30 22:58:57] iter = 07230, loss = 1.6664
2024-10-30 22:59:00: [2024-10-30 22:59:00] iter = 07240, loss = 2.1935
2024-10-30 22:59:03: [2024-10-30 22:59:03] iter = 07250, loss = 1.8959
2024-10-30 22:59:06: [2024-10-30 22:59:06] iter = 07260, loss = 2.4930
2024-10-30 22:59:10: [2024-10-30 22:59:10] iter = 07270, loss = 2.5686
2024-10-30 22:59:13: [2024-10-30 22:59:13] iter = 07280, loss = 2.1672
2024-10-30 22:59:16: [2024-10-30 22:59:16] iter = 07290, loss = 6.2876
2024-10-30 22:59:18: [2024-10-30 22:59:18] iter = 07300, loss = 2.6555
2024-10-30 22:59:21: [2024-10-30 22:59:21] iter = 07310, loss = 1.9398
2024-10-30 22:59:24: [2024-10-30 22:59:24] iter = 07320, loss = 2.3741
2024-10-30 22:59:26: [2024-10-30 22:59:26] iter = 07330, loss = 2.0749
2024-10-30 22:59:29: [2024-10-30 22:59:29] iter = 07340, loss = 2.2430
2024-10-30 22:59:32: [2024-10-30 22:59:32] iter = 07350, loss = 2.3071
2024-10-30 22:59:35: [2024-10-30 22:59:35] iter = 07360, loss = 2.7985
2024-10-30 22:59:38: [2024-10-30 22:59:38] iter = 07370, loss = 2.8670
2024-10-30 22:59:41: [2024-10-30 22:59:41] iter = 07380, loss = 2.5761
2024-10-30 22:59:44: [2024-10-30 22:59:44] iter = 07390, loss = 2.3397
2024-10-30 22:59:47: [2024-10-30 22:59:47] iter = 07400, loss = 2.7217
2024-10-30 22:59:50: [2024-10-30 22:59:50] iter = 07410, loss = 1.9195
2024-10-30 22:59:52: [2024-10-30 22:59:52] iter = 07420, loss = 2.5140
2024-10-30 22:59:55: [2024-10-30 22:59:55] iter = 07430, loss = 2.6198
2024-10-30 22:59:57: [2024-10-30 22:59:57] iter = 07440, loss = 2.1547
2024-10-30 22:59:59: [2024-10-30 22:59:59] iter = 07450, loss = 2.5357
2024-10-30 23:00:02: [2024-10-30 23:00:02] iter = 07460, loss = 2.5378
2024-10-30 23:00:04: [2024-10-30 23:00:04] iter = 07470, loss = 5.2302
2024-10-30 23:00:06: [2024-10-30 23:00:06] iter = 07480, loss = 1.8464
2024-10-30 23:00:08: [2024-10-30 23:00:08] iter = 07490, loss = 2.0406
2024-10-30 23:00:11: [2024-10-30 23:00:11] iter = 07500, loss = 2.4916
2024-10-30 23:00:14: [2024-10-30 23:00:14] iter = 07510, loss = 2.2550
2024-10-30 23:00:17: [2024-10-30 23:00:17] iter = 07520, loss = 2.0847
2024-10-30 23:00:20: [2024-10-30 23:00:20] iter = 07530, loss = 2.5959
2024-10-30 23:00:23: [2024-10-30 23:00:23] iter = 07540, loss = 1.7070
2024-10-30 23:00:26: [2024-10-30 23:00:26] iter = 07550, loss = 2.4762
2024-10-30 23:00:29: [2024-10-30 23:00:29] iter = 07560, loss = 2.1586
2024-10-30 23:00:31: [2024-10-30 23:00:31] iter = 07570, loss = 2.3046
2024-10-30 23:00:34: [2024-10-30 23:00:34] iter = 07580, loss = 2.1404
2024-10-30 23:00:36: [2024-10-30 23:00:36] iter = 07590, loss = 1.7441
2024-10-30 23:00:38: [2024-10-30 23:00:38] iter = 07600, loss = 3.2436
2024-10-30 23:00:41: [2024-10-30 23:00:41] iter = 07610, loss = 2.3241
2024-10-30 23:00:43: [2024-10-30 23:00:43] iter = 07620, loss = 2.8654
2024-10-30 23:00:46: [2024-10-30 23:00:46] iter = 07630, loss = 4.1010
2024-10-30 23:00:49: [2024-10-30 23:00:48] iter = 07640, loss = 2.3627
2024-10-30 23:00:52: [2024-10-30 23:00:52] iter = 07650, loss = 2.6153
2024-10-30 23:00:55: [2024-10-30 23:00:55] iter = 07660, loss = 2.1611
2024-10-30 23:00:58: [2024-10-30 23:00:58] iter = 07670, loss = 3.9211
2024-10-30 23:01:00: [2024-10-30 23:01:00] iter = 07680, loss = 2.2354
2024-10-30 23:01:03: [2024-10-30 23:01:03] iter = 07690, loss = 2.8419
2024-10-30 23:01:05: [2024-10-30 23:01:05] iter = 07700, loss = 2.8875
2024-10-30 23:01:07: [2024-10-30 23:01:07] iter = 07710, loss = 2.2747
2024-10-30 23:01:10: [2024-10-30 23:01:10] iter = 07720, loss = 2.0898
2024-10-30 23:01:12: [2024-10-30 23:01:12] iter = 07730, loss = 2.1680
2024-10-30 23:01:15: [2024-10-30 23:01:15] iter = 07740, loss = 2.3834
2024-10-30 23:01:18: [2024-10-30 23:01:18] iter = 07750, loss = 1.7980
2024-10-30 23:01:20: [2024-10-30 23:01:20] iter = 07760, loss = 2.2853
2024-10-30 23:01:23: [2024-10-30 23:01:23] iter = 07770, loss = 3.2996
2024-10-30 23:01:26: [2024-10-30 23:01:26] iter = 07780, loss = 3.1385
2024-10-30 23:01:28: [2024-10-30 23:01:28] iter = 07790, loss = 2.6646
2024-10-30 23:01:31: [2024-10-30 23:01:31] iter = 07800, loss = 3.1675
2024-10-30 23:01:34: [2024-10-30 23:01:34] iter = 07810, loss = 2.3616
2024-10-30 23:01:38: [2024-10-30 23:01:38] iter = 07820, loss = 1.8685
2024-10-30 23:01:41: [2024-10-30 23:01:41] iter = 07830, loss = 2.0898
2024-10-30 23:01:44: [2024-10-30 23:01:44] iter = 07840, loss = 2.2805
2024-10-30 23:01:48: [2024-10-30 23:01:48] iter = 07850, loss = 1.8290
2024-10-30 23:01:52: [2024-10-30 23:01:52] iter = 07860, loss = 2.4952
2024-10-30 23:01:55: [2024-10-30 23:01:55] iter = 07870, loss = 1.9330
2024-10-30 23:01:58: [2024-10-30 23:01:58] iter = 07880, loss = 4.8321
2024-10-30 23:02:01: [2024-10-30 23:02:01] iter = 07890, loss = 3.4041
2024-10-30 23:02:04: [2024-10-30 23:02:04] iter = 07900, loss = 2.7849
2024-10-30 23:02:07: [2024-10-30 23:02:07] iter = 07910, loss = 4.4177
2024-10-30 23:02:10: [2024-10-30 23:02:10] iter = 07920, loss = 2.3743
2024-10-30 23:02:14: [2024-10-30 23:02:14] iter = 07930, loss = 2.0647
2024-10-30 23:02:18: [2024-10-30 23:02:18] iter = 07940, loss = 2.6086
2024-10-30 23:02:21: [2024-10-30 23:02:21] iter = 07950, loss = 1.8657
2024-10-30 23:02:24: [2024-10-30 23:02:24] iter = 07960, loss = 1.9050
2024-10-30 23:02:28: [2024-10-30 23:02:28] iter = 07970, loss = 2.0804
2024-10-30 23:02:31: [2024-10-30 23:02:31] iter = 07980, loss = 1.8738
2024-10-30 23:02:35: [2024-10-30 23:02:35] iter = 07990, loss = 1.9298
2024-10-30 23:02:38: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 23:02:38: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:02:38: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 58619}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:04:39: Evaluate 5 random ConvNet, ACCmean = 0.6080 ACCstd = 0.0051
-------------------------
2024-10-30 23:04:39: Evaluate 5 random ConvNet, SENmean = 0.5829 SENstd = 0.0052
-------------------------
2024-10-30 23:04:39: Evaluate 5 random ConvNet, SPEmean = 0.9600 SPEstd = 0.0005
-------------------------
2024-10-30 23:04:39: Evaluate 5 random ConvNet, F!mean = 0.5754 F!std = 0.0059
-------------------------
2024-10-30 23:04:39: Evaluate 5 random ConvNet, mean = 0.6080 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:04:39: [2024-10-30 23:04:39] iter = 08000, loss = 4.5550
2024-10-30 23:04:42: [2024-10-30 23:04:42] iter = 08010, loss = 2.0241
2024-10-30 23:04:44: [2024-10-30 23:04:44] iter = 08020, loss = 1.9235
2024-10-30 23:04:47: [2024-10-30 23:04:47] iter = 08030, loss = 2.3135
2024-10-30 23:04:50: [2024-10-30 23:04:50] iter = 08040, loss = 2.3361
2024-10-30 23:04:53: [2024-10-30 23:04:53] iter = 08050, loss = 2.7874
2024-10-30 23:04:57: [2024-10-30 23:04:57] iter = 08060, loss = 2.9698
2024-10-30 23:05:01: [2024-10-30 23:05:01] iter = 08070, loss = 2.2624
2024-10-30 23:05:04: [2024-10-30 23:05:04] iter = 08080, loss = 2.1651
2024-10-30 23:05:07: [2024-10-30 23:05:07] iter = 08090, loss = 2.7396
2024-10-30 23:05:09: [2024-10-30 23:05:09] iter = 08100, loss = 2.8722
2024-10-30 23:05:12: [2024-10-30 23:05:12] iter = 08110, loss = 2.2653
2024-10-30 23:05:15: [2024-10-30 23:05:15] iter = 08120, loss = 2.1105
2024-10-30 23:05:18: [2024-10-30 23:05:18] iter = 08130, loss = 2.5115
2024-10-30 23:05:21: [2024-10-30 23:05:21] iter = 08140, loss = 2.2258
2024-10-30 23:05:24: [2024-10-30 23:05:24] iter = 08150, loss = 2.2588
2024-10-30 23:05:27: [2024-10-30 23:05:27] iter = 08160, loss = 2.7843
2024-10-30 23:05:29: [2024-10-30 23:05:29] iter = 08170, loss = 1.8816
2024-10-30 23:05:32: [2024-10-30 23:05:32] iter = 08180, loss = 2.3818
2024-10-30 23:05:35: [2024-10-30 23:05:35] iter = 08190, loss = 2.0113
2024-10-30 23:05:38: [2024-10-30 23:05:38] iter = 08200, loss = 1.8187
2024-10-30 23:05:41: [2024-10-30 23:05:41] iter = 08210, loss = 1.8878
2024-10-30 23:05:44: [2024-10-30 23:05:44] iter = 08220, loss = 2.2652
2024-10-30 23:05:47: [2024-10-30 23:05:47] iter = 08230, loss = 2.0235
2024-10-30 23:05:51: [2024-10-30 23:05:51] iter = 08240, loss = 3.4468
2024-10-30 23:05:54: [2024-10-30 23:05:54] iter = 08250, loss = 1.7635
2024-10-30 23:05:56: [2024-10-30 23:05:56] iter = 08260, loss = 2.6602
2024-10-30 23:05:59: [2024-10-30 23:05:59] iter = 08270, loss = 1.8108
2024-10-30 23:06:01: [2024-10-30 23:06:01] iter = 08280, loss = 2.5186
2024-10-30 23:06:04: [2024-10-30 23:06:04] iter = 08290, loss = 2.5128
2024-10-30 23:06:07: [2024-10-30 23:06:07] iter = 08300, loss = 3.5793
2024-10-30 23:06:10: [2024-10-30 23:06:10] iter = 08310, loss = 2.2210
2024-10-30 23:06:13: [2024-10-30 23:06:13] iter = 08320, loss = 2.3293
2024-10-30 23:06:17: [2024-10-30 23:06:17] iter = 08330, loss = 2.0063
2024-10-30 23:06:20: [2024-10-30 23:06:20] iter = 08340, loss = 2.6007
2024-10-30 23:06:24: [2024-10-30 23:06:24] iter = 08350, loss = 2.1746
2024-10-30 23:06:27: [2024-10-30 23:06:27] iter = 08360, loss = 1.9131
2024-10-30 23:06:30: [2024-10-30 23:06:30] iter = 08370, loss = 2.0016
2024-10-30 23:06:33: [2024-10-30 23:06:33] iter = 08380, loss = 2.2337
2024-10-30 23:06:36: [2024-10-30 23:06:36] iter = 08390, loss = 2.0957
2024-10-30 23:06:39: [2024-10-30 23:06:39] iter = 08400, loss = 2.0557
2024-10-30 23:06:42: [2024-10-30 23:06:42] iter = 08410, loss = 2.0004
2024-10-30 23:06:46: [2024-10-30 23:06:46] iter = 08420, loss = 2.3920
2024-10-30 23:06:49: [2024-10-30 23:06:49] iter = 08430, loss = 1.9681
2024-10-30 23:06:52: [2024-10-30 23:06:52] iter = 08440, loss = 3.8027
2024-10-30 23:06:55: [2024-10-30 23:06:55] iter = 08450, loss = 2.4110
2024-10-30 23:06:58: [2024-10-30 23:06:58] iter = 08460, loss = 2.0222
2024-10-30 23:07:00: [2024-10-30 23:07:00] iter = 08470, loss = 2.7910
2024-10-30 23:07:03: [2024-10-30 23:07:03] iter = 08480, loss = 1.9663
2024-10-30 23:07:05: [2024-10-30 23:07:05] iter = 08490, loss = 2.1417
2024-10-30 23:07:08: [2024-10-30 23:07:08] iter = 08500, loss = 5.0842
2024-10-30 23:07:11: [2024-10-30 23:07:11] iter = 08510, loss = 4.6571
2024-10-30 23:07:14: [2024-10-30 23:07:14] iter = 08520, loss = 2.2522
2024-10-30 23:07:17: [2024-10-30 23:07:17] iter = 08530, loss = 2.4495
2024-10-30 23:07:20: [2024-10-30 23:07:20] iter = 08540, loss = 2.8372
2024-10-30 23:07:23: [2024-10-30 23:07:23] iter = 08550, loss = 2.0133
2024-10-30 23:07:25: [2024-10-30 23:07:25] iter = 08560, loss = 2.5481
2024-10-30 23:07:29: [2024-10-30 23:07:29] iter = 08570, loss = 2.1989
2024-10-30 23:07:31: [2024-10-30 23:07:31] iter = 08580, loss = 2.0232
2024-10-30 23:07:34: [2024-10-30 23:07:34] iter = 08590, loss = 2.8026
2024-10-30 23:07:36: [2024-10-30 23:07:36] iter = 08600, loss = 2.2173
2024-10-30 23:07:38: [2024-10-30 23:07:38] iter = 08610, loss = 2.2952
2024-10-30 23:07:40: [2024-10-30 23:07:40] iter = 08620, loss = 1.7791
2024-10-30 23:07:42: [2024-10-30 23:07:42] iter = 08630, loss = 2.5511
2024-10-30 23:07:45: [2024-10-30 23:07:45] iter = 08640, loss = 2.0258
2024-10-30 23:07:48: [2024-10-30 23:07:48] iter = 08650, loss = 2.1091
2024-10-30 23:07:51: [2024-10-30 23:07:51] iter = 08660, loss = 1.8498
2024-10-30 23:07:54: [2024-10-30 23:07:54] iter = 08670, loss = 2.4430
2024-10-30 23:07:56: [2024-10-30 23:07:56] iter = 08680, loss = 1.9007
2024-10-30 23:07:59: [2024-10-30 23:07:59] iter = 08690, loss = 1.9960
2024-10-30 23:08:02: [2024-10-30 23:08:02] iter = 08700, loss = 2.1196
2024-10-30 23:08:04: [2024-10-30 23:08:04] iter = 08710, loss = 1.8509
2024-10-30 23:08:07: [2024-10-30 23:08:07] iter = 08720, loss = 2.0040
2024-10-30 23:08:09: [2024-10-30 23:08:09] iter = 08730, loss = 2.4754
2024-10-30 23:08:12: [2024-10-30 23:08:12] iter = 08740, loss = 2.5195
2024-10-30 23:08:15: [2024-10-30 23:08:15] iter = 08750, loss = 2.0765
2024-10-30 23:08:18: [2024-10-30 23:08:18] iter = 08760, loss = 1.9348
2024-10-30 23:08:20: [2024-10-30 23:08:20] iter = 08770, loss = 2.3587
2024-10-30 23:08:23: [2024-10-30 23:08:23] iter = 08780, loss = 2.0359
2024-10-30 23:08:26: [2024-10-30 23:08:26] iter = 08790, loss = 2.3480
2024-10-30 23:08:28: [2024-10-30 23:08:28] iter = 08800, loss = 2.6687
2024-10-30 23:08:30: [2024-10-30 23:08:30] iter = 08810, loss = 2.1119
2024-10-30 23:08:32: [2024-10-30 23:08:32] iter = 08820, loss = 2.8846
2024-10-30 23:08:35: [2024-10-30 23:08:35] iter = 08830, loss = 2.1916
2024-10-30 23:08:39: [2024-10-30 23:08:39] iter = 08840, loss = 1.9306
2024-10-30 23:08:42: [2024-10-30 23:08:42] iter = 08850, loss = 2.7533
2024-10-30 23:08:45: [2024-10-30 23:08:45] iter = 08860, loss = 2.9312
2024-10-30 23:08:49: [2024-10-30 23:08:49] iter = 08870, loss = 3.1765
2024-10-30 23:08:51: [2024-10-30 23:08:51] iter = 08880, loss = 1.8872
2024-10-30 23:08:54: [2024-10-30 23:08:54] iter = 08890, loss = 2.2584
2024-10-30 23:08:57: [2024-10-30 23:08:57] iter = 08900, loss = 2.5505
2024-10-30 23:09:00: [2024-10-30 23:09:00] iter = 08910, loss = 2.0436
2024-10-30 23:09:03: [2024-10-30 23:09:03] iter = 08920, loss = 2.4240
2024-10-30 23:09:06: [2024-10-30 23:09:06] iter = 08930, loss = 3.4416
2024-10-30 23:09:08: [2024-10-30 23:09:08] iter = 08940, loss = 2.0732
2024-10-30 23:09:11: [2024-10-30 23:09:11] iter = 08950, loss = 2.1525
2024-10-30 23:09:14: [2024-10-30 23:09:14] iter = 08960, loss = 2.0630
2024-10-30 23:09:18: [2024-10-30 23:09:18] iter = 08970, loss = 2.5155
2024-10-30 23:09:21: [2024-10-30 23:09:21] iter = 08980, loss = 3.0808
2024-10-30 23:09:25: [2024-10-30 23:09:25] iter = 08990, loss = 2.2632
2024-10-30 23:09:28: [2024-10-30 23:09:28] iter = 09000, loss = 1.8227
2024-10-30 23:09:31: [2024-10-30 23:09:31] iter = 09010, loss = 2.0748
2024-10-30 23:09:34: [2024-10-30 23:09:34] iter = 09020, loss = 2.1377
2024-10-30 23:09:38: [2024-10-30 23:09:38] iter = 09030, loss = 2.0912
2024-10-30 23:09:41: [2024-10-30 23:09:41] iter = 09040, loss = 1.9065
2024-10-30 23:09:43: [2024-10-30 23:09:43] iter = 09050, loss = 2.1770
2024-10-30 23:09:46: [2024-10-30 23:09:46] iter = 09060, loss = 2.1477
2024-10-30 23:09:49: [2024-10-30 23:09:49] iter = 09070, loss = 2.1060
2024-10-30 23:09:52: [2024-10-30 23:09:52] iter = 09080, loss = 1.7515
2024-10-30 23:09:56: [2024-10-30 23:09:56] iter = 09090, loss = 1.9748
2024-10-30 23:09:59: [2024-10-30 23:09:59] iter = 09100, loss = 2.1334
2024-10-30 23:10:03: [2024-10-30 23:10:03] iter = 09110, loss = 2.1695
2024-10-30 23:10:06: [2024-10-30 23:10:06] iter = 09120, loss = 1.7942
2024-10-30 23:10:10: [2024-10-30 23:10:10] iter = 09130, loss = 2.1496
2024-10-30 23:10:14: [2024-10-30 23:10:14] iter = 09140, loss = 2.0474
2024-10-30 23:10:17: [2024-10-30 23:10:17] iter = 09150, loss = 1.9856
2024-10-30 23:10:20: [2024-10-30 23:10:20] iter = 09160, loss = 3.1475
2024-10-30 23:10:23: [2024-10-30 23:10:23] iter = 09170, loss = 2.7285
2024-10-30 23:10:25: [2024-10-30 23:10:25] iter = 09180, loss = 2.6334
2024-10-30 23:10:27: [2024-10-30 23:10:27] iter = 09190, loss = 3.3948
2024-10-30 23:10:30: [2024-10-30 23:10:30] iter = 09200, loss = 3.6404
2024-10-30 23:10:33: [2024-10-30 23:10:33] iter = 09210, loss = 2.2975
2024-10-30 23:10:37: [2024-10-30 23:10:37] iter = 09220, loss = 3.2741
2024-10-30 23:10:40: [2024-10-30 23:10:40] iter = 09230, loss = 2.3524
2024-10-30 23:10:43: [2024-10-30 23:10:43] iter = 09240, loss = 2.0779
2024-10-30 23:10:46: [2024-10-30 23:10:46] iter = 09250, loss = 2.0935
2024-10-30 23:10:51: [2024-10-30 23:10:51] iter = 09260, loss = 3.6510
2024-10-30 23:10:55: [2024-10-30 23:10:55] iter = 09270, loss = 2.6405
2024-10-30 23:10:58: [2024-10-30 23:10:58] iter = 09280, loss = 1.8570
2024-10-30 23:11:00: [2024-10-30 23:11:00] iter = 09290, loss = 2.3658
2024-10-30 23:11:02: [2024-10-30 23:11:02] iter = 09300, loss = 1.9806
2024-10-30 23:11:04: [2024-10-30 23:11:04] iter = 09310, loss = 2.8309
2024-10-30 23:11:07: [2024-10-30 23:11:07] iter = 09320, loss = 2.2449
2024-10-30 23:11:11: [2024-10-30 23:11:11] iter = 09330, loss = 2.0476
2024-10-30 23:11:15: [2024-10-30 23:11:15] iter = 09340, loss = 1.9378
2024-10-30 23:11:18: [2024-10-30 23:11:18] iter = 09350, loss = 2.3147
2024-10-30 23:11:22: [2024-10-30 23:11:22] iter = 09360, loss = 2.7996
2024-10-30 23:11:25: [2024-10-30 23:11:25] iter = 09370, loss = 2.0292
2024-10-30 23:11:28: [2024-10-30 23:11:28] iter = 09380, loss = 1.9836
2024-10-30 23:11:30: [2024-10-30 23:11:30] iter = 09390, loss = 2.8180
2024-10-30 23:11:33: [2024-10-30 23:11:33] iter = 09400, loss = 2.2435
2024-10-30 23:11:36: [2024-10-30 23:11:36] iter = 09410, loss = 2.0871
2024-10-30 23:11:39: [2024-10-30 23:11:39] iter = 09420, loss = 2.5172
2024-10-30 23:11:42: [2024-10-30 23:11:42] iter = 09430, loss = 2.1523
2024-10-30 23:11:44: [2024-10-30 23:11:44] iter = 09440, loss = 2.0980
2024-10-30 23:11:47: [2024-10-30 23:11:47] iter = 09450, loss = 2.5359
2024-10-30 23:11:51: [2024-10-30 23:11:51] iter = 09460, loss = 1.9797
2024-10-30 23:11:53: [2024-10-30 23:11:53] iter = 09470, loss = 1.9228
2024-10-30 23:11:56: [2024-10-30 23:11:56] iter = 09480, loss = 2.2915
2024-10-30 23:11:59: [2024-10-30 23:11:59] iter = 09490, loss = 7.6964
2024-10-30 23:12:04: [2024-10-30 23:12:04] iter = 09500, loss = 2.1410
2024-10-30 23:12:07: [2024-10-30 23:12:07] iter = 09510, loss = 1.8630
2024-10-30 23:12:10: [2024-10-30 23:12:10] iter = 09520, loss = 2.5637
2024-10-30 23:12:13: [2024-10-30 23:12:13] iter = 09530, loss = 2.2718
2024-10-30 23:12:16: [2024-10-30 23:12:16] iter = 09540, loss = 2.2131
2024-10-30 23:12:20: [2024-10-30 23:12:20] iter = 09550, loss = 2.4331
2024-10-30 23:12:24: [2024-10-30 23:12:24] iter = 09560, loss = 2.0211
2024-10-30 23:12:28: [2024-10-30 23:12:28] iter = 09570, loss = 2.3865
2024-10-30 23:12:31: [2024-10-30 23:12:31] iter = 09580, loss = 2.0962
2024-10-30 23:12:34: [2024-10-30 23:12:34] iter = 09590, loss = 3.3363
2024-10-30 23:12:38: [2024-10-30 23:12:38] iter = 09600, loss = 2.5201
2024-10-30 23:12:41: [2024-10-30 23:12:41] iter = 09610, loss = 2.7724
2024-10-30 23:12:45: [2024-10-30 23:12:45] iter = 09620, loss = 2.1962
2024-10-30 23:12:49: [2024-10-30 23:12:49] iter = 09630, loss = 1.9135
2024-10-30 23:12:53: [2024-10-30 23:12:53] iter = 09640, loss = 1.8105
2024-10-30 23:12:56: [2024-10-30 23:12:56] iter = 09650, loss = 1.8371
2024-10-30 23:12:58: [2024-10-30 23:12:58] iter = 09660, loss = 1.9024
2024-10-30 23:13:01: [2024-10-30 23:13:01] iter = 09670, loss = 2.7981
2024-10-30 23:13:04: [2024-10-30 23:13:04] iter = 09680, loss = 2.0935
2024-10-30 23:13:07: [2024-10-30 23:13:07] iter = 09690, loss = 1.9869
2024-10-30 23:13:11: [2024-10-30 23:13:11] iter = 09700, loss = 1.8159
2024-10-30 23:13:14: [2024-10-30 23:13:14] iter = 09710, loss = 2.3391
2024-10-30 23:13:17: [2024-10-30 23:13:17] iter = 09720, loss = 3.1381
2024-10-30 23:13:21: [2024-10-30 23:13:21] iter = 09730, loss = 2.3000
2024-10-30 23:13:24: [2024-10-30 23:13:24] iter = 09740, loss = 1.8785
2024-10-30 23:13:26: [2024-10-30 23:13:26] iter = 09750, loss = 2.8372
2024-10-30 23:13:29: [2024-10-30 23:13:29] iter = 09760, loss = 2.8750
2024-10-30 23:13:32: [2024-10-30 23:13:32] iter = 09770, loss = 2.3554
2024-10-30 23:13:35: [2024-10-30 23:13:35] iter = 09780, loss = 1.8882
2024-10-30 23:13:38: [2024-10-30 23:13:38] iter = 09790, loss = 2.7595
2024-10-30 23:13:42: [2024-10-30 23:13:42] iter = 09800, loss = 2.3401
2024-10-30 23:13:45: [2024-10-30 23:13:45] iter = 09810, loss = 2.1929
2024-10-30 23:13:49: [2024-10-30 23:13:49] iter = 09820, loss = 3.3103
2024-10-30 23:13:52: [2024-10-30 23:13:52] iter = 09830, loss = 2.1141
2024-10-30 23:13:55: [2024-10-30 23:13:55] iter = 09840, loss = 2.0433
2024-10-30 23:13:58: [2024-10-30 23:13:58] iter = 09850, loss = 1.9015
2024-10-30 23:14:01: [2024-10-30 23:14:01] iter = 09860, loss = 1.9682
2024-10-30 23:14:04: [2024-10-30 23:14:04] iter = 09870, loss = 2.1807
2024-10-30 23:14:07: [2024-10-30 23:14:07] iter = 09880, loss = 2.2688
2024-10-30 23:14:10: [2024-10-30 23:14:10] iter = 09890, loss = 2.0327
2024-10-30 23:14:14: [2024-10-30 23:14:14] iter = 09900, loss = 1.8427
2024-10-30 23:14:17: [2024-10-30 23:14:17] iter = 09910, loss = 1.9857
2024-10-30 23:14:20: [2024-10-30 23:14:20] iter = 09920, loss = 2.0524
2024-10-30 23:14:24: [2024-10-30 23:14:24] iter = 09930, loss = 2.2890
2024-10-30 23:14:27: [2024-10-30 23:14:27] iter = 09940, loss = 1.8774
2024-10-30 23:14:29: [2024-10-30 23:14:29] iter = 09950, loss = 2.1584
2024-10-30 23:14:32: [2024-10-30 23:14:32] iter = 09960, loss = 2.3485
2024-10-30 23:14:35: [2024-10-30 23:14:35] iter = 09970, loss = 2.2299
2024-10-30 23:14:38: [2024-10-30 23:14:38] iter = 09980, loss = 2.3642
2024-10-30 23:14:41: [2024-10-30 23:14:41] iter = 09990, loss = 1.7906
2024-10-30 23:14:44: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 23:14:44: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:14:44: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 84566}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:16:40: Evaluate 5 random ConvNet, ACCmean = 0.6179 ACCstd = 0.0050
-------------------------
2024-10-30 23:16:40: Evaluate 5 random ConvNet, SENmean = 0.5984 SENstd = 0.0089
-------------------------
2024-10-30 23:16:40: Evaluate 5 random ConvNet, SPEmean = 0.9609 SPEstd = 0.0006
-------------------------
2024-10-30 23:16:40: Evaluate 5 random ConvNet, F!mean = 0.5894 F!std = 0.0061
-------------------------
2024-10-30 23:16:40: Evaluate 5 random ConvNet, mean = 0.6179 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:16:41: [2024-10-30 23:16:41] iter = 10000, loss = 2.2163
2024-10-30 23:16:44: [2024-10-30 23:16:44] iter = 10010, loss = 2.9896
2024-10-30 23:16:47: [2024-10-30 23:16:47] iter = 10020, loss = 2.1851
2024-10-30 23:16:50: [2024-10-30 23:16:50] iter = 10030, loss = 2.6213
2024-10-30 23:16:53: [2024-10-30 23:16:53] iter = 10040, loss = 3.7633
2024-10-30 23:16:57: [2024-10-30 23:16:57] iter = 10050, loss = 2.8701
2024-10-30 23:17:00: [2024-10-30 23:17:00] iter = 10060, loss = 3.9344
2024-10-30 23:17:04: [2024-10-30 23:17:04] iter = 10070, loss = 2.6114
2024-10-30 23:17:07: [2024-10-30 23:17:07] iter = 10080, loss = 3.4820
2024-10-30 23:17:10: [2024-10-30 23:17:10] iter = 10090, loss = 2.6246
2024-10-30 23:17:13: [2024-10-30 23:17:13] iter = 10100, loss = 2.0770
2024-10-30 23:17:16: [2024-10-30 23:17:16] iter = 10110, loss = 1.8803
2024-10-30 23:17:19: [2024-10-30 23:17:19] iter = 10120, loss = 2.6421
2024-10-30 23:17:21: [2024-10-30 23:17:21] iter = 10130, loss = 2.4471
2024-10-30 23:17:24: [2024-10-30 23:17:24] iter = 10140, loss = 5.5849
2024-10-30 23:17:27: [2024-10-30 23:17:27] iter = 10150, loss = 2.3105
2024-10-30 23:17:30: [2024-10-30 23:17:30] iter = 10160, loss = 1.9392
2024-10-30 23:17:33: [2024-10-30 23:17:33] iter = 10170, loss = 2.2482
2024-10-30 23:17:36: [2024-10-30 23:17:36] iter = 10180, loss = 2.3621
2024-10-30 23:17:38: [2024-10-30 23:17:38] iter = 10190, loss = 2.3752
2024-10-30 23:17:41: [2024-10-30 23:17:41] iter = 10200, loss = 1.9476
2024-10-30 23:17:43: [2024-10-30 23:17:43] iter = 10210, loss = 2.5642
2024-10-30 23:17:47: [2024-10-30 23:17:47] iter = 10220, loss = 1.9855
2024-10-30 23:17:50: [2024-10-30 23:17:50] iter = 10230, loss = 2.4739
2024-10-30 23:17:52: [2024-10-30 23:17:52] iter = 10240, loss = 1.9934
2024-10-30 23:17:56: [2024-10-30 23:17:56] iter = 10250, loss = 2.5900
2024-10-30 23:17:58: [2024-10-30 23:17:58] iter = 10260, loss = 1.9865
2024-10-30 23:18:01: [2024-10-30 23:18:01] iter = 10270, loss = 2.0623
2024-10-30 23:18:04: [2024-10-30 23:18:04] iter = 10280, loss = 2.2156
2024-10-30 23:18:07: [2024-10-30 23:18:07] iter = 10290, loss = 1.8787
2024-10-30 23:18:10: [2024-10-30 23:18:10] iter = 10300, loss = 2.3217
2024-10-30 23:18:13: [2024-10-30 23:18:13] iter = 10310, loss = 2.0870
2024-10-30 23:18:17: [2024-10-30 23:18:17] iter = 10320, loss = 1.9849
2024-10-30 23:18:20: [2024-10-30 23:18:20] iter = 10330, loss = 1.9060
2024-10-30 23:18:23: [2024-10-30 23:18:23] iter = 10340, loss = 2.0212
2024-10-30 23:18:25: [2024-10-30 23:18:25] iter = 10350, loss = 2.0153
2024-10-30 23:18:28: [2024-10-30 23:18:28] iter = 10360, loss = 2.1911
2024-10-30 23:18:30: [2024-10-30 23:18:30] iter = 10370, loss = 5.9433
2024-10-30 23:18:33: [2024-10-30 23:18:33] iter = 10380, loss = 1.8362
2024-10-30 23:18:35: [2024-10-30 23:18:35] iter = 10390, loss = 2.2749
2024-10-30 23:18:38: [2024-10-30 23:18:38] iter = 10400, loss = 2.7942
2024-10-30 23:18:41: [2024-10-30 23:18:41] iter = 10410, loss = 2.2944
2024-10-30 23:18:44: [2024-10-30 23:18:44] iter = 10420, loss = 1.9967
2024-10-30 23:18:47: [2024-10-30 23:18:47] iter = 10430, loss = 2.9313
2024-10-30 23:18:51: [2024-10-30 23:18:51] iter = 10440, loss = 3.8369
2024-10-30 23:18:54: [2024-10-30 23:18:54] iter = 10450, loss = 2.7235
2024-10-30 23:18:57: [2024-10-30 23:18:57] iter = 10460, loss = 2.4696
2024-10-30 23:18:59: [2024-10-30 23:18:59] iter = 10470, loss = 2.4418
2024-10-30 23:19:01: [2024-10-30 23:19:01] iter = 10480, loss = 3.3089
2024-10-30 23:19:04: [2024-10-30 23:19:04] iter = 10490, loss = 2.1527
2024-10-30 23:19:07: [2024-10-30 23:19:07] iter = 10500, loss = 2.3387
2024-10-30 23:19:11: [2024-10-30 23:19:11] iter = 10510, loss = 1.9882
2024-10-30 23:19:14: [2024-10-30 23:19:14] iter = 10520, loss = 2.6863
2024-10-30 23:19:17: [2024-10-30 23:19:17] iter = 10530, loss = 2.1801
2024-10-30 23:19:20: [2024-10-30 23:19:20] iter = 10540, loss = 2.0826
2024-10-30 23:19:23: [2024-10-30 23:19:23] iter = 10550, loss = 1.9831
2024-10-30 23:19:26: [2024-10-30 23:19:26] iter = 10560, loss = 1.9503
2024-10-30 23:19:30: [2024-10-30 23:19:30] iter = 10570, loss = 2.7979
2024-10-30 23:19:33: [2024-10-30 23:19:33] iter = 10580, loss = 1.7310
2024-10-30 23:19:37: [2024-10-30 23:19:37] iter = 10590, loss = 2.0300
2024-10-30 23:19:41: [2024-10-30 23:19:41] iter = 10600, loss = 2.0116
2024-10-30 23:19:44: [2024-10-30 23:19:44] iter = 10610, loss = 2.6520
2024-10-30 23:19:47: [2024-10-30 23:19:47] iter = 10620, loss = 2.2596
2024-10-30 23:19:51: [2024-10-30 23:19:51] iter = 10630, loss = 2.6343
2024-10-30 23:19:53: [2024-10-30 23:19:53] iter = 10640, loss = 1.9396
2024-10-30 23:19:57: [2024-10-30 23:19:57] iter = 10650, loss = 2.0532
2024-10-30 23:19:59: [2024-10-30 23:19:59] iter = 10660, loss = 2.6996
2024-10-30 23:20:03: [2024-10-30 23:20:03] iter = 10670, loss = 1.9918
2024-10-30 23:20:06: [2024-10-30 23:20:06] iter = 10680, loss = 1.9015
2024-10-30 23:20:09: [2024-10-30 23:20:09] iter = 10690, loss = 2.6399
2024-10-30 23:20:12: [2024-10-30 23:20:12] iter = 10700, loss = 1.9731
2024-10-30 23:20:15: [2024-10-30 23:20:15] iter = 10710, loss = 2.7796
2024-10-30 23:20:17: [2024-10-30 23:20:17] iter = 10720, loss = 3.0214
2024-10-30 23:20:20: [2024-10-30 23:20:20] iter = 10730, loss = 2.2225
2024-10-30 23:20:22: [2024-10-30 23:20:22] iter = 10740, loss = 2.2154
2024-10-30 23:20:25: [2024-10-30 23:20:25] iter = 10750, loss = 2.2696
2024-10-30 23:20:28: [2024-10-30 23:20:28] iter = 10760, loss = 4.8612
2024-10-30 23:20:30: [2024-10-30 23:20:30] iter = 10770, loss = 1.8377
2024-10-30 23:20:33: [2024-10-30 23:20:33] iter = 10780, loss = 2.2567
2024-10-30 23:20:36: [2024-10-30 23:20:36] iter = 10790, loss = 2.3045
2024-10-30 23:20:39: [2024-10-30 23:20:39] iter = 10800, loss = 1.9213
2024-10-30 23:20:42: [2024-10-30 23:20:42] iter = 10810, loss = 1.8139
2024-10-30 23:20:44: [2024-10-30 23:20:44] iter = 10820, loss = 1.9609
2024-10-30 23:20:45: [2024-10-30 23:20:45] iter = 10830, loss = 2.2009
2024-10-30 23:20:48: [2024-10-30 23:20:48] iter = 10840, loss = 2.1490
2024-10-30 23:20:51: [2024-10-30 23:20:51] iter = 10850, loss = 2.3288
2024-10-30 23:20:53: [2024-10-30 23:20:53] iter = 10860, loss = 2.6767
2024-10-30 23:20:56: [2024-10-30 23:20:56] iter = 10870, loss = 1.9006
2024-10-30 23:20:58: [2024-10-30 23:20:58] iter = 10880, loss = 2.9831
2024-10-30 23:21:00: [2024-10-30 23:21:00] iter = 10890, loss = 3.3242
2024-10-30 23:21:02: [2024-10-30 23:21:02] iter = 10900, loss = 2.1761
2024-10-30 23:21:06: [2024-10-30 23:21:06] iter = 10910, loss = 5.4793
2024-10-30 23:21:09: [2024-10-30 23:21:09] iter = 10920, loss = 2.0515
2024-10-30 23:21:12: [2024-10-30 23:21:12] iter = 10930, loss = 2.9229
2024-10-30 23:21:15: [2024-10-30 23:21:15] iter = 10940, loss = 2.6067
2024-10-30 23:21:18: [2024-10-30 23:21:18] iter = 10950, loss = 2.4723
2024-10-30 23:21:21: [2024-10-30 23:21:21] iter = 10960, loss = 2.7706
2024-10-30 23:21:24: [2024-10-30 23:21:24] iter = 10970, loss = 2.1622
2024-10-30 23:21:28: [2024-10-30 23:21:28] iter = 10980, loss = 3.3305
2024-10-30 23:21:31: [2024-10-30 23:21:31] iter = 10990, loss = 2.2901
2024-10-30 23:21:34: [2024-10-30 23:21:34] iter = 11000, loss = 2.2468
2024-10-30 23:21:36: [2024-10-30 23:21:36] iter = 11010, loss = 2.0502
2024-10-30 23:21:39: [2024-10-30 23:21:39] iter = 11020, loss = 2.2489
2024-10-30 23:21:43: [2024-10-30 23:21:43] iter = 11030, loss = 2.2470
2024-10-30 23:21:46: [2024-10-30 23:21:46] iter = 11040, loss = 2.5132
2024-10-30 23:21:49: [2024-10-30 23:21:49] iter = 11050, loss = 2.5610
2024-10-30 23:21:53: [2024-10-30 23:21:53] iter = 11060, loss = 3.9477
2024-10-30 23:21:56: [2024-10-30 23:21:56] iter = 11070, loss = 2.3214
2024-10-30 23:21:59: [2024-10-30 23:21:59] iter = 11080, loss = 2.1203
2024-10-30 23:22:01: [2024-10-30 23:22:01] iter = 11090, loss = 2.4162
2024-10-30 23:22:03: [2024-10-30 23:22:03] iter = 11100, loss = 2.2806
2024-10-30 23:22:06: [2024-10-30 23:22:06] iter = 11110, loss = 2.0770
2024-10-30 23:22:09: [2024-10-30 23:22:09] iter = 11120, loss = 3.2065
2024-10-30 23:22:13: [2024-10-30 23:22:13] iter = 11130, loss = 2.8404
2024-10-30 23:22:16: [2024-10-30 23:22:16] iter = 11140, loss = 3.0231
2024-10-30 23:22:19: [2024-10-30 23:22:19] iter = 11150, loss = 2.0005
2024-10-30 23:22:21: [2024-10-30 23:22:21] iter = 11160, loss = 2.6694
2024-10-30 23:22:24: [2024-10-30 23:22:24] iter = 11170, loss = 2.3772
2024-10-30 23:22:26: [2024-10-30 23:22:26] iter = 11180, loss = 1.7879
2024-10-30 23:22:30: [2024-10-30 23:22:30] iter = 11190, loss = 2.2811
2024-10-30 23:22:32: [2024-10-30 23:22:32] iter = 11200, loss = 2.2258
2024-10-30 23:22:35: [2024-10-30 23:22:35] iter = 11210, loss = 3.1616
2024-10-30 23:22:38: [2024-10-30 23:22:38] iter = 11220, loss = 2.2014
2024-10-30 23:22:40: [2024-10-30 23:22:40] iter = 11230, loss = 2.5241
2024-10-30 23:22:43: [2024-10-30 23:22:43] iter = 11240, loss = 2.2372
2024-10-30 23:22:45: [2024-10-30 23:22:45] iter = 11250, loss = 2.3339
2024-10-30 23:22:47: [2024-10-30 23:22:47] iter = 11260, loss = 2.0922
2024-10-30 23:22:51: [2024-10-30 23:22:51] iter = 11270, loss = 1.8847
2024-10-30 23:22:54: [2024-10-30 23:22:54] iter = 11280, loss = 2.1392
2024-10-30 23:22:57: [2024-10-30 23:22:57] iter = 11290, loss = 2.1932
2024-10-30 23:22:59: [2024-10-30 23:22:59] iter = 11300, loss = 2.4552
2024-10-30 23:23:02: [2024-10-30 23:23:02] iter = 11310, loss = 2.1485
2024-10-30 23:23:05: [2024-10-30 23:23:05] iter = 11320, loss = 2.0356
2024-10-30 23:23:08: [2024-10-30 23:23:08] iter = 11330, loss = 2.1650
2024-10-30 23:23:10: [2024-10-30 23:23:10] iter = 11340, loss = 2.6044
2024-10-30 23:23:13: [2024-10-30 23:23:13] iter = 11350, loss = 2.9250
2024-10-30 23:23:15: [2024-10-30 23:23:15] iter = 11360, loss = 2.0745
2024-10-30 23:23:18: [2024-10-30 23:23:18] iter = 11370, loss = 3.6318
2024-10-30 23:23:21: [2024-10-30 23:23:21] iter = 11380, loss = 3.1998
2024-10-30 23:23:24: [2024-10-30 23:23:24] iter = 11390, loss = 2.3352
2024-10-30 23:23:27: [2024-10-30 23:23:27] iter = 11400, loss = 2.1438
2024-10-30 23:23:30: [2024-10-30 23:23:30] iter = 11410, loss = 2.0066
2024-10-30 23:23:32: [2024-10-30 23:23:32] iter = 11420, loss = 2.1712
2024-10-30 23:23:35: [2024-10-30 23:23:35] iter = 11430, loss = 2.0820
2024-10-30 23:23:38: [2024-10-30 23:23:38] iter = 11440, loss = 2.2626
2024-10-30 23:23:41: [2024-10-30 23:23:41] iter = 11450, loss = 3.6475
2024-10-30 23:23:44: [2024-10-30 23:23:44] iter = 11460, loss = 2.4818
2024-10-30 23:23:47: [2024-10-30 23:23:47] iter = 11470, loss = 2.5452
2024-10-30 23:23:50: [2024-10-30 23:23:50] iter = 11480, loss = 2.4748
2024-10-30 23:23:53: [2024-10-30 23:23:53] iter = 11490, loss = 2.1016
2024-10-30 23:23:56: [2024-10-30 23:23:56] iter = 11500, loss = 2.3371
2024-10-30 23:23:59: [2024-10-30 23:23:59] iter = 11510, loss = 1.8531
2024-10-30 23:24:03: [2024-10-30 23:24:03] iter = 11520, loss = 1.9722
2024-10-30 23:24:06: [2024-10-30 23:24:06] iter = 11530, loss = 2.1794
2024-10-30 23:24:09: [2024-10-30 23:24:09] iter = 11540, loss = 3.0909
2024-10-30 23:24:13: [2024-10-30 23:24:13] iter = 11550, loss = 2.0044
2024-10-30 23:24:17: [2024-10-30 23:24:17] iter = 11560, loss = 1.9832
2024-10-30 23:24:21: [2024-10-30 23:24:21] iter = 11570, loss = 1.9109
2024-10-30 23:24:24: [2024-10-30 23:24:24] iter = 11580, loss = 2.2637
2024-10-30 23:24:29: [2024-10-30 23:24:29] iter = 11590, loss = 1.8170
2024-10-30 23:24:32: [2024-10-30 23:24:32] iter = 11600, loss = 2.5071
2024-10-30 23:24:36: [2024-10-30 23:24:36] iter = 11610, loss = 2.9897
2024-10-30 23:24:39: [2024-10-30 23:24:39] iter = 11620, loss = 2.6210
2024-10-30 23:24:42: [2024-10-30 23:24:42] iter = 11630, loss = 2.4235
2024-10-30 23:24:45: [2024-10-30 23:24:45] iter = 11640, loss = 2.8612
2024-10-30 23:24:48: [2024-10-30 23:24:48] iter = 11650, loss = 3.2231
2024-10-30 23:24:51: [2024-10-30 23:24:51] iter = 11660, loss = 2.0879
2024-10-30 23:24:55: [2024-10-30 23:24:54] iter = 11670, loss = 3.0114
2024-10-30 23:24:57: [2024-10-30 23:24:57] iter = 11680, loss = 2.2020
2024-10-30 23:25:00: [2024-10-30 23:25:00] iter = 11690, loss = 3.2941
2024-10-30 23:25:03: [2024-10-30 23:25:03] iter = 11700, loss = 2.1508
2024-10-30 23:25:06: [2024-10-30 23:25:05] iter = 11710, loss = 2.0500
2024-10-30 23:25:08: [2024-10-30 23:25:08] iter = 11720, loss = 2.2153
2024-10-30 23:25:11: [2024-10-30 23:25:11] iter = 11730, loss = 1.9745
2024-10-30 23:25:14: [2024-10-30 23:25:14] iter = 11740, loss = 2.0528
2024-10-30 23:25:16: [2024-10-30 23:25:16] iter = 11750, loss = 1.9775
2024-10-30 23:25:20: [2024-10-30 23:25:19] iter = 11760, loss = 1.8902
2024-10-30 23:25:23: [2024-10-30 23:25:23] iter = 11770, loss = 2.0884
2024-10-30 23:25:26: [2024-10-30 23:25:26] iter = 11780, loss = 1.6949
2024-10-30 23:25:29: [2024-10-30 23:25:29] iter = 11790, loss = 4.6976
2024-10-30 23:25:32: [2024-10-30 23:25:32] iter = 11800, loss = 2.6736
2024-10-30 23:25:35: [2024-10-30 23:25:35] iter = 11810, loss = 2.1141
2024-10-30 23:25:37: [2024-10-30 23:25:37] iter = 11820, loss = 1.7679
2024-10-30 23:25:40: [2024-10-30 23:25:40] iter = 11830, loss = 1.9454
2024-10-30 23:25:43: [2024-10-30 23:25:43] iter = 11840, loss = 3.3123
2024-10-30 23:25:47: [2024-10-30 23:25:47] iter = 11850, loss = 1.8553
2024-10-30 23:25:49: [2024-10-30 23:25:49] iter = 11860, loss = 2.7855
2024-10-30 23:25:52: [2024-10-30 23:25:52] iter = 11870, loss = 2.7814
2024-10-30 23:25:55: [2024-10-30 23:25:55] iter = 11880, loss = 1.7709
2024-10-30 23:25:58: [2024-10-30 23:25:58] iter = 11890, loss = 2.5448
2024-10-30 23:26:00: [2024-10-30 23:26:00] iter = 11900, loss = 2.2057
2024-10-30 23:26:03: [2024-10-30 23:26:03] iter = 11910, loss = 1.9604
2024-10-30 23:26:06: [2024-10-30 23:26:06] iter = 11920, loss = 2.3423
2024-10-30 23:26:09: [2024-10-30 23:26:09] iter = 11930, loss = 2.5169
2024-10-30 23:26:12: [2024-10-30 23:26:12] iter = 11940, loss = 2.4687
2024-10-30 23:26:15: [2024-10-30 23:26:15] iter = 11950, loss = 2.6244
2024-10-30 23:26:17: [2024-10-30 23:26:17] iter = 11960, loss = 2.4008
2024-10-30 23:26:20: [2024-10-30 23:26:20] iter = 11970, loss = 1.7825
2024-10-30 23:26:21: [2024-10-30 23:26:21] iter = 11980, loss = 2.1437
2024-10-30 23:26:24: [2024-10-30 23:26:24] iter = 11990, loss = 1.8132
2024-10-30 23:26:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 23:26:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:26:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87481}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:28:16: Evaluate 5 random ConvNet, ACCmean = 0.5997 ACCstd = 0.0067
-------------------------
2024-10-30 23:28:16: Evaluate 5 random ConvNet, SENmean = 0.5835 SENstd = 0.0057
-------------------------
2024-10-30 23:28:16: Evaluate 5 random ConvNet, SPEmean = 0.9591 SPEstd = 0.0006
-------------------------
2024-10-30 23:28:16: Evaluate 5 random ConvNet, F!mean = 0.5725 F!std = 0.0066
-------------------------
2024-10-30 23:28:16: Evaluate 5 random ConvNet, mean = 0.5997 std = 0.0067
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:28:17: [2024-10-30 23:28:17] iter = 12000, loss = 2.3603
2024-10-30 23:28:20: [2024-10-30 23:28:20] iter = 12010, loss = 2.1907
2024-10-30 23:28:23: [2024-10-30 23:28:23] iter = 12020, loss = 2.2008
2024-10-30 23:28:26: [2024-10-30 23:28:26] iter = 12030, loss = 3.4151
2024-10-30 23:28:30: [2024-10-30 23:28:30] iter = 12040, loss = 2.2372
2024-10-30 23:28:33: [2024-10-30 23:28:33] iter = 12050, loss = 1.8861
2024-10-30 23:28:36: [2024-10-30 23:28:36] iter = 12060, loss = 2.2253
2024-10-30 23:28:38: [2024-10-30 23:28:38] iter = 12070, loss = 1.9485
2024-10-30 23:28:41: [2024-10-30 23:28:41] iter = 12080, loss = 1.9959
2024-10-30 23:28:44: [2024-10-30 23:28:44] iter = 12090, loss = 2.1944
2024-10-30 23:28:47: [2024-10-30 23:28:47] iter = 12100, loss = 3.1634
2024-10-30 23:28:50: [2024-10-30 23:28:50] iter = 12110, loss = 1.9503
2024-10-30 23:28:52: [2024-10-30 23:28:52] iter = 12120, loss = 2.1579
2024-10-30 23:28:55: [2024-10-30 23:28:55] iter = 12130, loss = 4.0093
2024-10-30 23:28:58: [2024-10-30 23:28:58] iter = 12140, loss = 2.4448
2024-10-30 23:29:02: [2024-10-30 23:29:02] iter = 12150, loss = 2.0062
2024-10-30 23:29:05: [2024-10-30 23:29:05] iter = 12160, loss = 2.9984
2024-10-30 23:29:08: [2024-10-30 23:29:08] iter = 12170, loss = 2.3080
2024-10-30 23:29:11: [2024-10-30 23:29:11] iter = 12180, loss = 4.0699
2024-10-30 23:29:13: [2024-10-30 23:29:13] iter = 12190, loss = 1.9420
2024-10-30 23:29:16: [2024-10-30 23:29:16] iter = 12200, loss = 2.8499
2024-10-30 23:29:18: [2024-10-30 23:29:18] iter = 12210, loss = 2.1785
2024-10-30 23:29:20: [2024-10-30 23:29:20] iter = 12220, loss = 2.8265
2024-10-30 23:29:23: [2024-10-30 23:29:23] iter = 12230, loss = 2.2782
2024-10-30 23:29:26: [2024-10-30 23:29:26] iter = 12240, loss = 3.0847
2024-10-30 23:29:30: [2024-10-30 23:29:30] iter = 12250, loss = 1.8831
2024-10-30 23:29:33: [2024-10-30 23:29:33] iter = 12260, loss = 2.5860
2024-10-30 23:29:36: [2024-10-30 23:29:36] iter = 12270, loss = 3.4544
2024-10-30 23:29:39: [2024-10-30 23:29:39] iter = 12280, loss = 2.4781
2024-10-30 23:29:41: [2024-10-30 23:29:41] iter = 12290, loss = 2.0490
2024-10-30 23:29:44: [2024-10-30 23:29:44] iter = 12300, loss = 2.5182
2024-10-30 23:29:47: [2024-10-30 23:29:47] iter = 12310, loss = 1.8526
2024-10-30 23:29:49: [2024-10-30 23:29:49] iter = 12320, loss = 2.1557
2024-10-30 23:29:52: [2024-10-30 23:29:52] iter = 12330, loss = 2.3364
2024-10-30 23:29:56: [2024-10-30 23:29:56] iter = 12340, loss = 1.8290
2024-10-30 23:29:59: [2024-10-30 23:29:59] iter = 12350, loss = 1.9579
2024-10-30 23:30:02: [2024-10-30 23:30:02] iter = 12360, loss = 2.2264
2024-10-30 23:30:05: [2024-10-30 23:30:05] iter = 12370, loss = 1.9137
2024-10-30 23:30:07: [2024-10-30 23:30:07] iter = 12380, loss = 2.3630
2024-10-30 23:30:10: [2024-10-30 23:30:10] iter = 12390, loss = 2.2758
2024-10-30 23:30:13: [2024-10-30 23:30:13] iter = 12400, loss = 1.9523
2024-10-30 23:30:16: [2024-10-30 23:30:16] iter = 12410, loss = 2.1620
2024-10-30 23:30:19: [2024-10-30 23:30:19] iter = 12420, loss = 2.4499
2024-10-30 23:30:22: [2024-10-30 23:30:22] iter = 12430, loss = 1.9840
2024-10-30 23:30:25: [2024-10-30 23:30:25] iter = 12440, loss = 2.0454
2024-10-30 23:30:28: [2024-10-30 23:30:28] iter = 12450, loss = 2.0823
2024-10-30 23:30:31: [2024-10-30 23:30:31] iter = 12460, loss = 2.2260
2024-10-30 23:30:34: [2024-10-30 23:30:34] iter = 12470, loss = 2.0661
2024-10-30 23:30:37: [2024-10-30 23:30:37] iter = 12480, loss = 1.7657
2024-10-30 23:30:40: [2024-10-30 23:30:40] iter = 12490, loss = 2.1411
2024-10-30 23:30:43: [2024-10-30 23:30:43] iter = 12500, loss = 2.2583
2024-10-30 23:30:46: [2024-10-30 23:30:46] iter = 12510, loss = 2.5672
2024-10-30 23:30:49: [2024-10-30 23:30:49] iter = 12520, loss = 2.3649
2024-10-30 23:30:52: [2024-10-30 23:30:52] iter = 12530, loss = 2.0174
2024-10-30 23:30:55: [2024-10-30 23:30:55] iter = 12540, loss = 2.1075
2024-10-30 23:30:58: [2024-10-30 23:30:58] iter = 12550, loss = 1.7557
2024-10-30 23:31:00: [2024-10-30 23:31:00] iter = 12560, loss = 2.0838
2024-10-30 23:31:02: [2024-10-30 23:31:02] iter = 12570, loss = 2.2454
2024-10-30 23:31:05: [2024-10-30 23:31:05] iter = 12580, loss = 2.6509
2024-10-30 23:31:08: [2024-10-30 23:31:08] iter = 12590, loss = 2.5640
2024-10-30 23:31:10: [2024-10-30 23:31:10] iter = 12600, loss = 2.7306
2024-10-30 23:31:13: [2024-10-30 23:31:13] iter = 12610, loss = 1.9823
2024-10-30 23:31:16: [2024-10-30 23:31:16] iter = 12620, loss = 3.0589
2024-10-30 23:31:18: [2024-10-30 23:31:18] iter = 12630, loss = 1.7851
2024-10-30 23:31:21: [2024-10-30 23:31:21] iter = 12640, loss = 2.3304
2024-10-30 23:31:24: [2024-10-30 23:31:24] iter = 12650, loss = 2.7161
2024-10-30 23:31:26: [2024-10-30 23:31:26] iter = 12660, loss = 2.0620
2024-10-30 23:31:30: [2024-10-30 23:31:30] iter = 12670, loss = 2.1414
2024-10-30 23:31:33: [2024-10-30 23:31:33] iter = 12680, loss = 1.8666
2024-10-30 23:31:36: [2024-10-30 23:31:36] iter = 12690, loss = 3.0135
2024-10-30 23:31:37: [2024-10-30 23:31:37] iter = 12700, loss = 2.1288
2024-10-30 23:31:40: [2024-10-30 23:31:40] iter = 12710, loss = 1.8735
2024-10-30 23:31:42: [2024-10-30 23:31:42] iter = 12720, loss = 2.2345
2024-10-30 23:31:45: [2024-10-30 23:31:45] iter = 12730, loss = 1.7407
2024-10-30 23:31:48: [2024-10-30 23:31:48] iter = 12740, loss = 2.3331
2024-10-30 23:31:51: [2024-10-30 23:31:51] iter = 12750, loss = 2.1050
2024-10-30 23:31:54: [2024-10-30 23:31:54] iter = 12760, loss = 2.7728
2024-10-30 23:31:56: [2024-10-30 23:31:56] iter = 12770, loss = 2.7813
2024-10-30 23:31:59: [2024-10-30 23:31:59] iter = 12780, loss = 2.1539
2024-10-30 23:32:01: [2024-10-30 23:32:01] iter = 12790, loss = 3.2086
2024-10-30 23:32:04: [2024-10-30 23:32:04] iter = 12800, loss = 1.9503
2024-10-30 23:32:07: [2024-10-30 23:32:07] iter = 12810, loss = 1.8263
2024-10-30 23:32:11: [2024-10-30 23:32:11] iter = 12820, loss = 2.0276
2024-10-30 23:32:14: [2024-10-30 23:32:14] iter = 12830, loss = 1.8573
2024-10-30 23:32:17: [2024-10-30 23:32:17] iter = 12840, loss = 2.4873
2024-10-30 23:32:19: [2024-10-30 23:32:19] iter = 12850, loss = 1.9866
2024-10-30 23:32:22: [2024-10-30 23:32:22] iter = 12860, loss = 2.0377
2024-10-30 23:32:24: [2024-10-30 23:32:24] iter = 12870, loss = 1.9016
2024-10-30 23:32:26: [2024-10-30 23:32:26] iter = 12880, loss = 4.5866
2024-10-30 23:32:28: [2024-10-30 23:32:28] iter = 12890, loss = 3.2579
2024-10-30 23:32:32: [2024-10-30 23:32:32] iter = 12900, loss = 1.9032
2024-10-30 23:32:35: [2024-10-30 23:32:35] iter = 12910, loss = 2.2947
2024-10-30 23:32:37: [2024-10-30 23:32:37] iter = 12920, loss = 1.8471
2024-10-30 23:32:40: [2024-10-30 23:32:40] iter = 12930, loss = 2.8335
2024-10-30 23:32:43: [2024-10-30 23:32:43] iter = 12940, loss = 3.6149
2024-10-30 23:32:47: [2024-10-30 23:32:47] iter = 12950, loss = 2.4596
2024-10-30 23:32:49: [2024-10-30 23:32:49] iter = 12960, loss = 2.0058
2024-10-30 23:32:53: [2024-10-30 23:32:53] iter = 12970, loss = 2.2263
2024-10-30 23:32:57: [2024-10-30 23:32:57] iter = 12980, loss = 1.7961
2024-10-30 23:33:00: [2024-10-30 23:33:00] iter = 12990, loss = 2.1853
2024-10-30 23:33:03: [2024-10-30 23:33:03] iter = 13000, loss = 2.2793
2024-10-30 23:33:06: [2024-10-30 23:33:06] iter = 13010, loss = 2.2989
2024-10-30 23:33:09: [2024-10-30 23:33:09] iter = 13020, loss = 2.0311
2024-10-30 23:33:11: [2024-10-30 23:33:11] iter = 13030, loss = 4.8159
2024-10-30 23:33:14: [2024-10-30 23:33:14] iter = 13040, loss = 2.5937
2024-10-30 23:33:17: [2024-10-30 23:33:17] iter = 13050, loss = 2.2303
2024-10-30 23:33:20: [2024-10-30 23:33:20] iter = 13060, loss = 2.8154
2024-10-30 23:33:23: [2024-10-30 23:33:23] iter = 13070, loss = 1.8496
2024-10-30 23:33:25: [2024-10-30 23:33:25] iter = 13080, loss = 3.7463
2024-10-30 23:33:27: [2024-10-30 23:33:27] iter = 13090, loss = 2.1257
2024-10-30 23:33:30: [2024-10-30 23:33:30] iter = 13100, loss = 2.1478
2024-10-30 23:33:33: [2024-10-30 23:33:33] iter = 13110, loss = 2.3929
2024-10-30 23:33:36: [2024-10-30 23:33:36] iter = 13120, loss = 2.3059
2024-10-30 23:33:39: [2024-10-30 23:33:39] iter = 13130, loss = 2.1775
2024-10-30 23:33:42: [2024-10-30 23:33:42] iter = 13140, loss = 3.2106
2024-10-30 23:33:45: [2024-10-30 23:33:45] iter = 13150, loss = 2.4515
2024-10-30 23:33:49: [2024-10-30 23:33:49] iter = 13160, loss = 2.0921
2024-10-30 23:33:52: [2024-10-30 23:33:52] iter = 13170, loss = 2.5287
2024-10-30 23:33:54: [2024-10-30 23:33:54] iter = 13180, loss = 2.2589
2024-10-30 23:33:57: [2024-10-30 23:33:57] iter = 13190, loss = 3.5180
2024-10-30 23:34:01: [2024-10-30 23:34:01] iter = 13200, loss = 1.9928
2024-10-30 23:34:04: [2024-10-30 23:34:04] iter = 13210, loss = 2.0278
2024-10-30 23:34:08: [2024-10-30 23:34:08] iter = 13220, loss = 2.2800
2024-10-30 23:34:11: [2024-10-30 23:34:11] iter = 13230, loss = 2.1041
2024-10-30 23:34:15: [2024-10-30 23:34:15] iter = 13240, loss = 2.1503
2024-10-30 23:34:18: [2024-10-30 23:34:18] iter = 13250, loss = 3.2246
2024-10-30 23:34:21: [2024-10-30 23:34:21] iter = 13260, loss = 2.3918
2024-10-30 23:34:24: [2024-10-30 23:34:24] iter = 13270, loss = 2.1837
2024-10-30 23:34:27: [2024-10-30 23:34:27] iter = 13280, loss = 2.3144
2024-10-30 23:34:31: [2024-10-30 23:34:31] iter = 13290, loss = 2.2376
2024-10-30 23:34:34: [2024-10-30 23:34:34] iter = 13300, loss = 1.9900
2024-10-30 23:34:37: [2024-10-30 23:34:37] iter = 13310, loss = 1.8810
2024-10-30 23:34:39: [2024-10-30 23:34:39] iter = 13320, loss = 2.6887
2024-10-30 23:34:42: [2024-10-30 23:34:42] iter = 13330, loss = 2.2052
2024-10-30 23:34:44: [2024-10-30 23:34:44] iter = 13340, loss = 2.0654
2024-10-30 23:34:47: [2024-10-30 23:34:47] iter = 13350, loss = 2.4904
2024-10-30 23:34:49: [2024-10-30 23:34:49] iter = 13360, loss = 2.0663
2024-10-30 23:34:52: [2024-10-30 23:34:52] iter = 13370, loss = 2.6303
2024-10-30 23:34:54: [2024-10-30 23:34:54] iter = 13380, loss = 1.9703
2024-10-30 23:34:56: [2024-10-30 23:34:56] iter = 13390, loss = 2.4164
2024-10-30 23:34:59: [2024-10-30 23:34:59] iter = 13400, loss = 2.0705
2024-10-30 23:35:02: [2024-10-30 23:35:02] iter = 13410, loss = 2.7347
2024-10-30 23:35:05: [2024-10-30 23:35:05] iter = 13420, loss = 3.8105
2024-10-30 23:35:08: [2024-10-30 23:35:08] iter = 13430, loss = 2.3186
2024-10-30 23:35:12: [2024-10-30 23:35:12] iter = 13440, loss = 2.2323
2024-10-30 23:35:15: [2024-10-30 23:35:15] iter = 13450, loss = 2.5833
2024-10-30 23:35:18: [2024-10-30 23:35:18] iter = 13460, loss = 1.8781
2024-10-30 23:35:21: [2024-10-30 23:35:21] iter = 13470, loss = 2.1671
2024-10-30 23:35:23: [2024-10-30 23:35:23] iter = 13480, loss = 2.5337
2024-10-30 23:35:26: [2024-10-30 23:35:26] iter = 13490, loss = 1.8037
2024-10-30 23:35:30: [2024-10-30 23:35:30] iter = 13500, loss = 2.1859
2024-10-30 23:35:33: [2024-10-30 23:35:33] iter = 13510, loss = 2.2257
2024-10-30 23:35:36: [2024-10-30 23:35:36] iter = 13520, loss = 1.8822
2024-10-30 23:35:39: [2024-10-30 23:35:39] iter = 13530, loss = 2.0241
2024-10-30 23:35:42: [2024-10-30 23:35:42] iter = 13540, loss = 2.5523
2024-10-30 23:35:45: [2024-10-30 23:35:45] iter = 13550, loss = 3.1733
2024-10-30 23:35:49: [2024-10-30 23:35:49] iter = 13560, loss = 1.9636
2024-10-30 23:35:52: [2024-10-30 23:35:52] iter = 13570, loss = 2.4825
2024-10-30 23:35:56: [2024-10-30 23:35:56] iter = 13580, loss = 1.9709
2024-10-30 23:35:59: [2024-10-30 23:35:59] iter = 13590, loss = 2.9281
2024-10-30 23:36:02: [2024-10-30 23:36:02] iter = 13600, loss = 2.2138
2024-10-30 23:36:05: [2024-10-30 23:36:05] iter = 13610, loss = 2.2494
2024-10-30 23:36:08: [2024-10-30 23:36:08] iter = 13620, loss = 2.1394
2024-10-30 23:36:11: [2024-10-30 23:36:11] iter = 13630, loss = 1.9845
2024-10-30 23:36:13: [2024-10-30 23:36:13] iter = 13640, loss = 2.2525
2024-10-30 23:36:16: [2024-10-30 23:36:16] iter = 13650, loss = 1.9893
2024-10-30 23:36:19: [2024-10-30 23:36:19] iter = 13660, loss = 2.0928
2024-10-30 23:36:22: [2024-10-30 23:36:22] iter = 13670, loss = 1.6537
2024-10-30 23:36:26: [2024-10-30 23:36:26] iter = 13680, loss = 1.7616
2024-10-30 23:36:28: [2024-10-30 23:36:28] iter = 13690, loss = 2.0111
2024-10-30 23:36:32: [2024-10-30 23:36:32] iter = 13700, loss = 2.2600
2024-10-30 23:36:34: [2024-10-30 23:36:34] iter = 13710, loss = 2.8744
2024-10-30 23:36:37: [2024-10-30 23:36:37] iter = 13720, loss = 1.8400
2024-10-30 23:36:40: [2024-10-30 23:36:40] iter = 13730, loss = 3.2686
2024-10-30 23:36:44: [2024-10-30 23:36:44] iter = 13740, loss = 2.5830
2024-10-30 23:36:47: [2024-10-30 23:36:47] iter = 13750, loss = 3.5640
2024-10-30 23:36:51: [2024-10-30 23:36:51] iter = 13760, loss = 1.7185
2024-10-30 23:36:54: [2024-10-30 23:36:54] iter = 13770, loss = 2.3841
2024-10-30 23:36:59: [2024-10-30 23:36:59] iter = 13780, loss = 2.0672
2024-10-30 23:37:02: [2024-10-30 23:37:02] iter = 13790, loss = 2.3585
2024-10-30 23:37:06: [2024-10-30 23:37:06] iter = 13800, loss = 1.9806
2024-10-30 23:37:09: [2024-10-30 23:37:09] iter = 13810, loss = 1.9341
2024-10-30 23:37:13: [2024-10-30 23:37:13] iter = 13820, loss = 1.8513
2024-10-30 23:37:16: [2024-10-30 23:37:16] iter = 13830, loss = 2.1681
2024-10-30 23:37:18: [2024-10-30 23:37:18] iter = 13840, loss = 2.4307
2024-10-30 23:37:21: [2024-10-30 23:37:21] iter = 13850, loss = 2.4604
2024-10-30 23:37:24: [2024-10-30 23:37:24] iter = 13860, loss = 1.9861
2024-10-30 23:37:28: [2024-10-30 23:37:28] iter = 13870, loss = 2.8939
2024-10-30 23:37:31: [2024-10-30 23:37:31] iter = 13880, loss = 2.6312
2024-10-30 23:37:34: [2024-10-30 23:37:34] iter = 13890, loss = 2.8502
2024-10-30 23:37:38: [2024-10-30 23:37:38] iter = 13900, loss = 2.0185
2024-10-30 23:37:41: [2024-10-30 23:37:41] iter = 13910, loss = 2.4671
2024-10-30 23:37:43: [2024-10-30 23:37:43] iter = 13920, loss = 3.5476
2024-10-30 23:37:46: [2024-10-30 23:37:46] iter = 13930, loss = 2.2905
2024-10-30 23:37:50: [2024-10-30 23:37:50] iter = 13940, loss = 2.3098
2024-10-30 23:37:52: [2024-10-30 23:37:52] iter = 13950, loss = 2.6551
2024-10-30 23:37:55: [2024-10-30 23:37:55] iter = 13960, loss = 1.9553
2024-10-30 23:37:58: [2024-10-30 23:37:58] iter = 13970, loss = 2.0105
2024-10-30 23:38:01: [2024-10-30 23:38:01] iter = 13980, loss = 2.0620
2024-10-30 23:38:05: [2024-10-30 23:38:05] iter = 13990, loss = 3.3178
2024-10-30 23:38:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 23:38:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:38:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 88116}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:40:16: Evaluate 5 random ConvNet, ACCmean = 0.6096 ACCstd = 0.0067
-------------------------
2024-10-30 23:40:16: Evaluate 5 random ConvNet, SENmean = 0.5895 SENstd = 0.0058
-------------------------
2024-10-30 23:40:16: Evaluate 5 random ConvNet, SPEmean = 0.9601 SPEstd = 0.0007
-------------------------
2024-10-30 23:40:16: Evaluate 5 random ConvNet, F!mean = 0.5803 F!std = 0.0066
-------------------------
2024-10-30 23:40:16: Evaluate 5 random ConvNet, mean = 0.6096 std = 0.0067
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:40:16: [2024-10-30 23:40:16] iter = 14000, loss = 2.0902
2024-10-30 23:40:19: [2024-10-30 23:40:19] iter = 14010, loss = 5.1450
2024-10-30 23:40:22: [2024-10-30 23:40:22] iter = 14020, loss = 1.8409
2024-10-30 23:40:25: [2024-10-30 23:40:25] iter = 14030, loss = 2.0933
2024-10-30 23:40:27: [2024-10-30 23:40:27] iter = 14040, loss = 2.4307
2024-10-30 23:40:29: [2024-10-30 23:40:29] iter = 14050, loss = 1.8474
2024-10-30 23:40:32: [2024-10-30 23:40:32] iter = 14060, loss = 3.1873
2024-10-30 23:40:35: [2024-10-30 23:40:35] iter = 14070, loss = 2.4517
2024-10-30 23:40:37: [2024-10-30 23:40:37] iter = 14080, loss = 2.1752
2024-10-30 23:40:41: [2024-10-30 23:40:41] iter = 14090, loss = 1.8744
2024-10-30 23:40:43: [2024-10-30 23:40:43] iter = 14100, loss = 2.2032
2024-10-30 23:40:46: [2024-10-30 23:40:46] iter = 14110, loss = 2.4047
2024-10-30 23:40:49: [2024-10-30 23:40:49] iter = 14120, loss = 2.1943
2024-10-30 23:40:51: [2024-10-30 23:40:51] iter = 14130, loss = 2.1001
2024-10-30 23:40:54: [2024-10-30 23:40:54] iter = 14140, loss = 2.7895
2024-10-30 23:40:59: [2024-10-30 23:40:59] iter = 14150, loss = 2.4426
2024-10-30 23:41:02: [2024-10-30 23:41:02] iter = 14160, loss = 2.3344
2024-10-30 23:41:06: [2024-10-30 23:41:06] iter = 14170, loss = 3.2091
2024-10-30 23:41:09: [2024-10-30 23:41:09] iter = 14180, loss = 2.2670
2024-10-30 23:41:11: [2024-10-30 23:41:11] iter = 14190, loss = 2.4004
2024-10-30 23:41:13: [2024-10-30 23:41:13] iter = 14200, loss = 1.8723
2024-10-30 23:41:15: [2024-10-30 23:41:15] iter = 14210, loss = 2.9829
2024-10-30 23:41:18: [2024-10-30 23:41:18] iter = 14220, loss = 2.6212
2024-10-30 23:41:21: [2024-10-30 23:41:21] iter = 14230, loss = 1.8849
2024-10-30 23:41:25: [2024-10-30 23:41:25] iter = 14240, loss = 2.2705
2024-10-30 23:41:27: [2024-10-30 23:41:27] iter = 14250, loss = 2.6840
2024-10-30 23:41:30: [2024-10-30 23:41:30] iter = 14260, loss = 2.0777
2024-10-30 23:41:34: [2024-10-30 23:41:34] iter = 14270, loss = 2.0161
2024-10-30 23:41:37: [2024-10-30 23:41:37] iter = 14280, loss = 2.4759
2024-10-30 23:41:40: [2024-10-30 23:41:40] iter = 14290, loss = 2.3805
2024-10-30 23:41:43: [2024-10-30 23:41:43] iter = 14300, loss = 1.9900
2024-10-30 23:41:47: [2024-10-30 23:41:47] iter = 14310, loss = 2.0933
2024-10-30 23:41:50: [2024-10-30 23:41:50] iter = 14320, loss = 1.7789
2024-10-30 23:41:53: [2024-10-30 23:41:53] iter = 14330, loss = 1.9705
2024-10-30 23:41:56: [2024-10-30 23:41:56] iter = 14340, loss = 2.1051
2024-10-30 23:41:58: [2024-10-30 23:41:58] iter = 14350, loss = 2.0476
2024-10-30 23:42:02: [2024-10-30 23:42:02] iter = 14360, loss = 2.1559
2024-10-30 23:42:05: [2024-10-30 23:42:05] iter = 14370, loss = 2.1944
2024-10-30 23:42:08: [2024-10-30 23:42:08] iter = 14380, loss = 1.9803
2024-10-30 23:42:11: [2024-10-30 23:42:11] iter = 14390, loss = 1.9969
2024-10-30 23:42:14: [2024-10-30 23:42:14] iter = 14400, loss = 1.9238
2024-10-30 23:42:16: [2024-10-30 23:42:16] iter = 14410, loss = 1.9603
2024-10-30 23:42:20: [2024-10-30 23:42:20] iter = 14420, loss = 4.5820
2024-10-30 23:42:23: [2024-10-30 23:42:23] iter = 14430, loss = 2.3314
2024-10-30 23:42:25: [2024-10-30 23:42:25] iter = 14440, loss = 1.9721
2024-10-30 23:42:28: [2024-10-30 23:42:28] iter = 14450, loss = 2.5575
2024-10-30 23:42:30: [2024-10-30 23:42:30] iter = 14460, loss = 4.2793
2024-10-30 23:42:33: [2024-10-30 23:42:33] iter = 14470, loss = 1.7294
2024-10-30 23:42:36: [2024-10-30 23:42:36] iter = 14480, loss = 2.2618
2024-10-30 23:42:39: [2024-10-30 23:42:39] iter = 14490, loss = 2.3410
2024-10-30 23:42:43: [2024-10-30 23:42:43] iter = 14500, loss = 2.0781
2024-10-30 23:42:46: [2024-10-30 23:42:46] iter = 14510, loss = 2.0337
2024-10-30 23:42:49: [2024-10-30 23:42:49] iter = 14520, loss = 2.3503
2024-10-30 23:42:53: [2024-10-30 23:42:53] iter = 14530, loss = 2.9045
2024-10-30 23:42:56: [2024-10-30 23:42:56] iter = 14540, loss = 1.9267
2024-10-30 23:43:00: [2024-10-30 23:43:00] iter = 14550, loss = 2.6359
2024-10-30 23:43:03: [2024-10-30 23:43:03] iter = 14560, loss = 2.5450
2024-10-30 23:43:08: [2024-10-30 23:43:08] iter = 14570, loss = 2.3207
2024-10-30 23:43:11: [2024-10-30 23:43:11] iter = 14580, loss = 1.8776
2024-10-30 23:43:13: [2024-10-30 23:43:13] iter = 14590, loss = 2.6659
2024-10-30 23:43:16: [2024-10-30 23:43:16] iter = 14600, loss = 1.8297
2024-10-30 23:43:19: [2024-10-30 23:43:19] iter = 14610, loss = 2.3050
2024-10-30 23:43:22: [2024-10-30 23:43:22] iter = 14620, loss = 2.9011
2024-10-30 23:43:24: [2024-10-30 23:43:24] iter = 14630, loss = 2.2256
2024-10-30 23:43:27: [2024-10-30 23:43:27] iter = 14640, loss = 2.0434
2024-10-30 23:43:30: [2024-10-30 23:43:30] iter = 14650, loss = 2.0154
2024-10-30 23:43:33: [2024-10-30 23:43:33] iter = 14660, loss = 2.9627
2024-10-30 23:43:36: [2024-10-30 23:43:36] iter = 14670, loss = 1.7687
2024-10-30 23:43:39: [2024-10-30 23:43:39] iter = 14680, loss = 3.4687
2024-10-30 23:43:42: [2024-10-30 23:43:42] iter = 14690, loss = 2.2169
2024-10-30 23:43:45: [2024-10-30 23:43:45] iter = 14700, loss = 2.2918
2024-10-30 23:43:48: [2024-10-30 23:43:48] iter = 14710, loss = 2.5921
2024-10-30 23:43:50: [2024-10-30 23:43:50] iter = 14720, loss = 1.9903
2024-10-30 23:43:54: [2024-10-30 23:43:54] iter = 14730, loss = 2.0766
2024-10-30 23:43:58: [2024-10-30 23:43:58] iter = 14740, loss = 2.2713
2024-10-30 23:44:01: [2024-10-30 23:44:01] iter = 14750, loss = 2.6009
2024-10-30 23:44:04: [2024-10-30 23:44:04] iter = 14760, loss = 1.9913
2024-10-30 23:44:07: [2024-10-30 23:44:07] iter = 14770, loss = 2.0913
2024-10-30 23:44:09: [2024-10-30 23:44:09] iter = 14780, loss = 2.0085
2024-10-30 23:44:12: [2024-10-30 23:44:12] iter = 14790, loss = 4.5699
2024-10-30 23:44:15: [2024-10-30 23:44:15] iter = 14800, loss = 2.2914
2024-10-30 23:44:19: [2024-10-30 23:44:19] iter = 14810, loss = 1.9186
2024-10-30 23:44:23: [2024-10-30 23:44:23] iter = 14820, loss = 2.6246
2024-10-30 23:44:26: [2024-10-30 23:44:26] iter = 14830, loss = 2.9276
2024-10-30 23:44:30: [2024-10-30 23:44:30] iter = 14840, loss = 2.6018
2024-10-30 23:44:33: [2024-10-30 23:44:33] iter = 14850, loss = 2.1861
2024-10-30 23:44:37: [2024-10-30 23:44:37] iter = 14860, loss = 1.8974
2024-10-30 23:44:40: [2024-10-30 23:44:40] iter = 14870, loss = 1.9919
2024-10-30 23:44:44: [2024-10-30 23:44:44] iter = 14880, loss = 1.9322
2024-10-30 23:44:48: [2024-10-30 23:44:48] iter = 14890, loss = 2.0517
2024-10-30 23:44:51: [2024-10-30 23:44:51] iter = 14900, loss = 2.1741
2024-10-30 23:44:54: [2024-10-30 23:44:54] iter = 14910, loss = 2.1456
2024-10-30 23:44:58: [2024-10-30 23:44:58] iter = 14920, loss = 1.8813
2024-10-30 23:45:02: [2024-10-30 23:45:02] iter = 14930, loss = 2.0245
2024-10-30 23:45:06: [2024-10-30 23:45:06] iter = 14940, loss = 2.1375
2024-10-30 23:45:10: [2024-10-30 23:45:10] iter = 14950, loss = 2.0491
2024-10-30 23:45:13: [2024-10-30 23:45:13] iter = 14960, loss = 2.0915
2024-10-30 23:45:18: [2024-10-30 23:45:18] iter = 14970, loss = 2.1321
2024-10-30 23:45:21: [2024-10-30 23:45:21] iter = 14980, loss = 2.0741
2024-10-30 23:45:24: [2024-10-30 23:45:24] iter = 14990, loss = 2.2187
2024-10-30 23:45:27: [2024-10-30 23:45:27] iter = 15000, loss = 2.7591
2024-10-30 23:45:30: [2024-10-30 23:45:30] iter = 15010, loss = 1.9317
2024-10-30 23:45:33: [2024-10-30 23:45:33] iter = 15020, loss = 3.1515
2024-10-30 23:45:37: [2024-10-30 23:45:37] iter = 15030, loss = 1.9671
2024-10-30 23:45:40: [2024-10-30 23:45:40] iter = 15040, loss = 2.6586
2024-10-30 23:45:44: [2024-10-30 23:45:44] iter = 15050, loss = 1.8094
2024-10-30 23:45:47: [2024-10-30 23:45:47] iter = 15060, loss = 2.2759
2024-10-30 23:45:50: [2024-10-30 23:45:50] iter = 15070, loss = 2.1847
2024-10-30 23:45:53: [2024-10-30 23:45:53] iter = 15080, loss = 2.1005
2024-10-30 23:45:56: [2024-10-30 23:45:56] iter = 15090, loss = 2.6491
2024-10-30 23:46:00: [2024-10-30 23:46:00] iter = 15100, loss = 2.2050
2024-10-30 23:46:03: [2024-10-30 23:46:03] iter = 15110, loss = 2.3994
2024-10-30 23:46:06: [2024-10-30 23:46:06] iter = 15120, loss = 2.0985
2024-10-30 23:46:10: [2024-10-30 23:46:10] iter = 15130, loss = 1.8795
2024-10-30 23:46:14: [2024-10-30 23:46:14] iter = 15140, loss = 5.9909
2024-10-30 23:46:17: [2024-10-30 23:46:17] iter = 15150, loss = 2.2548
2024-10-30 23:46:20: [2024-10-30 23:46:20] iter = 15160, loss = 2.3020
2024-10-30 23:46:23: [2024-10-30 23:46:23] iter = 15170, loss = 2.2785
2024-10-30 23:46:26: [2024-10-30 23:46:26] iter = 15180, loss = 2.8505
2024-10-30 23:46:28: [2024-10-30 23:46:28] iter = 15190, loss = 2.0806
2024-10-30 23:46:32: [2024-10-30 23:46:32] iter = 15200, loss = 2.4143
2024-10-30 23:46:35: [2024-10-30 23:46:35] iter = 15210, loss = 3.2928
2024-10-30 23:46:38: [2024-10-30 23:46:38] iter = 15220, loss = 2.1259
2024-10-30 23:46:42: [2024-10-30 23:46:42] iter = 15230, loss = 3.1653
2024-10-30 23:46:46: [2024-10-30 23:46:46] iter = 15240, loss = 2.3068
2024-10-30 23:46:49: [2024-10-30 23:46:49] iter = 15250, loss = 2.5085
2024-10-30 23:46:53: [2024-10-30 23:46:53] iter = 15260, loss = 2.1077
2024-10-30 23:46:57: [2024-10-30 23:46:57] iter = 15270, loss = 2.3182
2024-10-30 23:46:59: [2024-10-30 23:46:59] iter = 15280, loss = 1.9815
2024-10-30 23:47:02: [2024-10-30 23:47:02] iter = 15290, loss = 2.5248
2024-10-30 23:47:06: [2024-10-30 23:47:06] iter = 15300, loss = 3.9537
2024-10-30 23:47:09: [2024-10-30 23:47:08] iter = 15310, loss = 2.3559
2024-10-30 23:47:12: [2024-10-30 23:47:12] iter = 15320, loss = 2.1574
2024-10-30 23:47:15: [2024-10-30 23:47:15] iter = 15330, loss = 1.8930
2024-10-30 23:47:18: [2024-10-30 23:47:18] iter = 15340, loss = 2.2240
2024-10-30 23:47:21: [2024-10-30 23:47:21] iter = 15350, loss = 2.3793
2024-10-30 23:47:24: [2024-10-30 23:47:24] iter = 15360, loss = 1.8020
2024-10-30 23:47:28: [2024-10-30 23:47:28] iter = 15370, loss = 2.5644
2024-10-30 23:47:31: [2024-10-30 23:47:31] iter = 15380, loss = 2.2512
2024-10-30 23:47:33: [2024-10-30 23:47:33] iter = 15390, loss = 2.1005
2024-10-30 23:47:36: [2024-10-30 23:47:36] iter = 15400, loss = 2.2816
2024-10-30 23:47:39: [2024-10-30 23:47:39] iter = 15410, loss = 2.0597
2024-10-30 23:47:42: [2024-10-30 23:47:42] iter = 15420, loss = 2.5182
2024-10-30 23:47:45: [2024-10-30 23:47:45] iter = 15430, loss = 1.9238
2024-10-30 23:47:48: [2024-10-30 23:47:48] iter = 15440, loss = 2.0495
2024-10-30 23:47:51: [2024-10-30 23:47:51] iter = 15450, loss = 1.7324
2024-10-30 23:47:53: [2024-10-30 23:47:53] iter = 15460, loss = 3.1342
2024-10-30 23:47:57: [2024-10-30 23:47:57] iter = 15470, loss = 2.2140
2024-10-30 23:48:00: [2024-10-30 23:48:00] iter = 15480, loss = 2.3654
2024-10-30 23:48:03: [2024-10-30 23:48:03] iter = 15490, loss = 2.1206
2024-10-30 23:48:06: [2024-10-30 23:48:06] iter = 15500, loss = 3.8685
2024-10-30 23:48:09: [2024-10-30 23:48:09] iter = 15510, loss = 1.7115
2024-10-30 23:48:11: [2024-10-30 23:48:11] iter = 15520, loss = 1.9746
2024-10-30 23:48:13: [2024-10-30 23:48:13] iter = 15530, loss = 2.7404
2024-10-30 23:48:15: [2024-10-30 23:48:15] iter = 15540, loss = 2.1242
2024-10-30 23:48:18: [2024-10-30 23:48:18] iter = 15550, loss = 2.6783
2024-10-30 23:48:22: [2024-10-30 23:48:22] iter = 15560, loss = 2.6506
2024-10-30 23:48:25: [2024-10-30 23:48:25] iter = 15570, loss = 1.8444
2024-10-30 23:48:27: [2024-10-30 23:48:27] iter = 15580, loss = 2.6662
2024-10-30 23:48:30: [2024-10-30 23:48:30] iter = 15590, loss = 2.2186
2024-10-30 23:48:33: [2024-10-30 23:48:33] iter = 15600, loss = 1.8171
2024-10-30 23:48:36: [2024-10-30 23:48:36] iter = 15610, loss = 2.1243
2024-10-30 23:48:38: [2024-10-30 23:48:38] iter = 15620, loss = 2.2637
2024-10-30 23:48:41: [2024-10-30 23:48:41] iter = 15630, loss = 3.0339
2024-10-30 23:48:44: [2024-10-30 23:48:44] iter = 15640, loss = 2.4498
2024-10-30 23:48:47: [2024-10-30 23:48:47] iter = 15650, loss = 2.6184
2024-10-30 23:48:50: [2024-10-30 23:48:50] iter = 15660, loss = 2.2297
2024-10-30 23:48:53: [2024-10-30 23:48:53] iter = 15670, loss = 1.7402
2024-10-30 23:48:56: [2024-10-30 23:48:56] iter = 15680, loss = 1.9609
2024-10-30 23:48:59: [2024-10-30 23:48:59] iter = 15690, loss = 2.0946
2024-10-30 23:49:01: [2024-10-30 23:49:01] iter = 15700, loss = 1.9850
2024-10-30 23:49:04: [2024-10-30 23:49:04] iter = 15710, loss = 2.4747
2024-10-30 23:49:07: [2024-10-30 23:49:07] iter = 15720, loss = 3.6811
2024-10-30 23:49:11: [2024-10-30 23:49:11] iter = 15730, loss = 2.6317
2024-10-30 23:49:14: [2024-10-30 23:49:14] iter = 15740, loss = 2.1577
2024-10-30 23:49:17: [2024-10-30 23:49:17] iter = 15750, loss = 2.8231
2024-10-30 23:49:21: [2024-10-30 23:49:21] iter = 15760, loss = 2.1812
2024-10-30 23:49:24: [2024-10-30 23:49:24] iter = 15770, loss = 1.9491
2024-10-30 23:49:27: [2024-10-30 23:49:27] iter = 15780, loss = 1.9823
2024-10-30 23:49:29: [2024-10-30 23:49:29] iter = 15790, loss = 2.8931
2024-10-30 23:49:32: [2024-10-30 23:49:32] iter = 15800, loss = 2.6220
2024-10-30 23:49:35: [2024-10-30 23:49:35] iter = 15810, loss = 2.1169
2024-10-30 23:49:38: [2024-10-30 23:49:38] iter = 15820, loss = 2.3513
2024-10-30 23:49:42: [2024-10-30 23:49:42] iter = 15830, loss = 2.7845
2024-10-30 23:49:46: [2024-10-30 23:49:46] iter = 15840, loss = 4.4081
2024-10-30 23:49:49: [2024-10-30 23:49:49] iter = 15850, loss = 2.4639
2024-10-30 23:49:52: [2024-10-30 23:49:52] iter = 15860, loss = 2.0137
2024-10-30 23:49:55: [2024-10-30 23:49:55] iter = 15870, loss = 2.5892
2024-10-30 23:49:58: [2024-10-30 23:49:58] iter = 15880, loss = 3.1345
2024-10-30 23:50:01: [2024-10-30 23:50:01] iter = 15890, loss = 2.1450
2024-10-30 23:50:04: [2024-10-30 23:50:04] iter = 15900, loss = 1.8441
2024-10-30 23:50:07: [2024-10-30 23:50:07] iter = 15910, loss = 2.0511
2024-10-30 23:50:10: [2024-10-30 23:50:10] iter = 15920, loss = 3.0905
2024-10-30 23:50:13: [2024-10-30 23:50:13] iter = 15930, loss = 2.0224
2024-10-30 23:50:16: [2024-10-30 23:50:16] iter = 15940, loss = 2.0985
2024-10-30 23:50:19: [2024-10-30 23:50:19] iter = 15950, loss = 2.4462
2024-10-30 23:50:22: [2024-10-30 23:50:22] iter = 15960, loss = 2.2570
2024-10-30 23:50:25: [2024-10-30 23:50:25] iter = 15970, loss = 2.1007
2024-10-30 23:50:27: [2024-10-30 23:50:27] iter = 15980, loss = 1.8777
2024-10-30 23:50:30: [2024-10-30 23:50:30] iter = 15990, loss = 2.2686
2024-10-30 23:50:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 23:50:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:50:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 32356}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:52:36: Evaluate 5 random ConvNet, ACCmean = 0.6101 ACCstd = 0.0015
-------------------------
2024-10-30 23:52:36: Evaluate 5 random ConvNet, SENmean = 0.5872 SENstd = 0.0020
-------------------------
2024-10-30 23:52:36: Evaluate 5 random ConvNet, SPEmean = 0.9601 SPEstd = 0.0001
-------------------------
2024-10-30 23:52:36: Evaluate 5 random ConvNet, F!mean = 0.5788 F!std = 0.0018
-------------------------
2024-10-30 23:52:36: Evaluate 5 random ConvNet, mean = 0.6101 std = 0.0015
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:52:37: [2024-10-30 23:52:37] iter = 16000, loss = 2.2665
2024-10-30 23:52:39: [2024-10-30 23:52:39] iter = 16010, loss = 4.7189
2024-10-30 23:52:41: [2024-10-30 23:52:41] iter = 16020, loss = 2.1611
2024-10-30 23:52:44: [2024-10-30 23:52:44] iter = 16030, loss = 2.1352
2024-10-30 23:52:46: [2024-10-30 23:52:46] iter = 16040, loss = 2.1959
2024-10-30 23:52:49: [2024-10-30 23:52:49] iter = 16050, loss = 1.9897
2024-10-30 23:52:51: [2024-10-30 23:52:51] iter = 16060, loss = 2.9886
2024-10-30 23:52:55: [2024-10-30 23:52:55] iter = 16070, loss = 1.9766
2024-10-30 23:52:58: [2024-10-30 23:52:58] iter = 16080, loss = 2.4441
2024-10-30 23:53:01: [2024-10-30 23:53:01] iter = 16090, loss = 2.9777
2024-10-30 23:53:04: [2024-10-30 23:53:04] iter = 16100, loss = 2.0725
2024-10-30 23:53:07: [2024-10-30 23:53:07] iter = 16110, loss = 2.0118
2024-10-30 23:53:10: [2024-10-30 23:53:10] iter = 16120, loss = 2.0222
2024-10-30 23:53:13: [2024-10-30 23:53:13] iter = 16130, loss = 2.2905
2024-10-30 23:53:16: [2024-10-30 23:53:16] iter = 16140, loss = 2.1973
2024-10-30 23:53:19: [2024-10-30 23:53:19] iter = 16150, loss = 2.0393
2024-10-30 23:53:22: [2024-10-30 23:53:22] iter = 16160, loss = 1.9519
2024-10-30 23:53:25: [2024-10-30 23:53:25] iter = 16170, loss = 2.1205
2024-10-30 23:53:30: [2024-10-30 23:53:30] iter = 16180, loss = 1.8885
2024-10-30 23:53:33: [2024-10-30 23:53:33] iter = 16190, loss = 4.1195
2024-10-30 23:53:36: [2024-10-30 23:53:36] iter = 16200, loss = 1.9411
2024-10-30 23:53:38: [2024-10-30 23:53:38] iter = 16210, loss = 3.9647
2024-10-30 23:53:41: [2024-10-30 23:53:41] iter = 16220, loss = 2.8774
2024-10-30 23:53:43: [2024-10-30 23:53:43] iter = 16230, loss = 3.9183
2024-10-30 23:53:47: [2024-10-30 23:53:47] iter = 16240, loss = 3.1587
2024-10-30 23:53:50: [2024-10-30 23:53:50] iter = 16250, loss = 3.8011
2024-10-30 23:53:52: [2024-10-30 23:53:52] iter = 16260, loss = 4.9395
2024-10-30 23:53:55: [2024-10-30 23:53:55] iter = 16270, loss = 2.3870
2024-10-30 23:53:58: [2024-10-30 23:53:57] iter = 16280, loss = 1.7971
2024-10-30 23:54:00: [2024-10-30 23:54:00] iter = 16290, loss = 2.3509
2024-10-30 23:54:03: [2024-10-30 23:54:03] iter = 16300, loss = 2.5904
2024-10-30 23:54:05: [2024-10-30 23:54:05] iter = 16310, loss = 2.0796
2024-10-30 23:54:08: [2024-10-30 23:54:08] iter = 16320, loss = 2.0946
2024-10-30 23:54:11: [2024-10-30 23:54:11] iter = 16330, loss = 2.3486
2024-10-30 23:54:13: [2024-10-30 23:54:13] iter = 16340, loss = 2.3707
2024-10-30 23:54:16: [2024-10-30 23:54:16] iter = 16350, loss = 1.9604
2024-10-30 23:54:19: [2024-10-30 23:54:19] iter = 16360, loss = 2.0127
2024-10-30 23:54:22: [2024-10-30 23:54:22] iter = 16370, loss = 2.0043
2024-10-30 23:54:24: [2024-10-30 23:54:24] iter = 16380, loss = 1.9885
2024-10-30 23:54:27: [2024-10-30 23:54:27] iter = 16390, loss = 2.1572
2024-10-30 23:54:30: [2024-10-30 23:54:30] iter = 16400, loss = 2.4552
2024-10-30 23:54:33: [2024-10-30 23:54:33] iter = 16410, loss = 1.9950
2024-10-30 23:54:37: [2024-10-30 23:54:37] iter = 16420, loss = 2.0033
2024-10-30 23:54:40: [2024-10-30 23:54:40] iter = 16430, loss = 2.3596
2024-10-30 23:54:42: [2024-10-30 23:54:42] iter = 16440, loss = 3.5537
2024-10-30 23:54:44: [2024-10-30 23:54:44] iter = 16450, loss = 1.5865
2024-10-30 23:54:47: [2024-10-30 23:54:47] iter = 16460, loss = 2.6360
2024-10-30 23:54:50: [2024-10-30 23:54:50] iter = 16470, loss = 2.5400
2024-10-30 23:54:54: [2024-10-30 23:54:54] iter = 16480, loss = 1.8843
2024-10-30 23:54:57: [2024-10-30 23:54:57] iter = 16490, loss = 1.9648
2024-10-30 23:55:01: [2024-10-30 23:55:01] iter = 16500, loss = 2.0132
2024-10-30 23:55:03: [2024-10-30 23:55:03] iter = 16510, loss = 2.3845
2024-10-30 23:55:06: [2024-10-30 23:55:06] iter = 16520, loss = 1.8744
2024-10-30 23:55:09: [2024-10-30 23:55:09] iter = 16530, loss = 2.2781
2024-10-30 23:55:12: [2024-10-30 23:55:12] iter = 16540, loss = 3.1350
2024-10-30 23:55:14: [2024-10-30 23:55:14] iter = 16550, loss = 1.9773
2024-10-30 23:55:17: [2024-10-30 23:55:17] iter = 16560, loss = 2.0637
2024-10-30 23:55:20: [2024-10-30 23:55:20] iter = 16570, loss = 2.3035
2024-10-30 23:55:23: [2024-10-30 23:55:23] iter = 16580, loss = 3.0602
2024-10-30 23:55:27: [2024-10-30 23:55:27] iter = 16590, loss = 1.9256
2024-10-30 23:55:30: [2024-10-30 23:55:30] iter = 16600, loss = 1.9666
2024-10-30 23:55:33: [2024-10-30 23:55:33] iter = 16610, loss = 2.2316
2024-10-30 23:55:37: [2024-10-30 23:55:37] iter = 16620, loss = 2.5518
2024-10-30 23:55:41: [2024-10-30 23:55:41] iter = 16630, loss = 2.3056
2024-10-30 23:55:44: [2024-10-30 23:55:44] iter = 16640, loss = 2.0462
2024-10-30 23:55:46: [2024-10-30 23:55:46] iter = 16650, loss = 3.0919
2024-10-30 23:55:49: [2024-10-30 23:55:49] iter = 16660, loss = 2.3580
2024-10-30 23:55:51: [2024-10-30 23:55:51] iter = 16670, loss = 2.5091
2024-10-30 23:55:54: [2024-10-30 23:55:54] iter = 16680, loss = 2.3608
2024-10-30 23:55:57: [2024-10-30 23:55:57] iter = 16690, loss = 1.7662
2024-10-30 23:56:01: [2024-10-30 23:56:01] iter = 16700, loss = 2.8506
2024-10-30 23:56:04: [2024-10-30 23:56:04] iter = 16710, loss = 3.2147
2024-10-30 23:56:07: [2024-10-30 23:56:07] iter = 16720, loss = 2.3810
2024-10-30 23:56:10: [2024-10-30 23:56:10] iter = 16730, loss = 1.8479
2024-10-30 23:56:13: [2024-10-30 23:56:13] iter = 16740, loss = 2.1954
2024-10-30 23:56:16: [2024-10-30 23:56:16] iter = 16750, loss = 2.2605
2024-10-30 23:56:20: [2024-10-30 23:56:19] iter = 16760, loss = 2.1706
2024-10-30 23:56:22: [2024-10-30 23:56:22] iter = 16770, loss = 4.5682
2024-10-30 23:56:25: [2024-10-30 23:56:25] iter = 16780, loss = 2.7939
2024-10-30 23:56:28: [2024-10-30 23:56:28] iter = 16790, loss = 2.0434
2024-10-30 23:56:32: [2024-10-30 23:56:32] iter = 16800, loss = 2.6183
2024-10-30 23:56:34: [2024-10-30 23:56:34] iter = 16810, loss = 2.0515
2024-10-30 23:56:36: [2024-10-30 23:56:36] iter = 16820, loss = 2.3797
2024-10-30 23:56:39: [2024-10-30 23:56:39] iter = 16830, loss = 2.6392
2024-10-30 23:56:42: [2024-10-30 23:56:42] iter = 16840, loss = 2.2185
2024-10-30 23:56:45: [2024-10-30 23:56:45] iter = 16850, loss = 3.4058
2024-10-30 23:56:48: [2024-10-30 23:56:48] iter = 16860, loss = 1.8914
2024-10-30 23:56:51: [2024-10-30 23:56:51] iter = 16870, loss = 2.2343
2024-10-30 23:56:54: [2024-10-30 23:56:54] iter = 16880, loss = 1.9709
2024-10-30 23:56:57: [2024-10-30 23:56:57] iter = 16890, loss = 1.8995
2024-10-30 23:57:00: [2024-10-30 23:57:00] iter = 16900, loss = 6.9059
2024-10-30 23:57:03: [2024-10-30 23:57:03] iter = 16910, loss = 2.3171
2024-10-30 23:57:06: [2024-10-30 23:57:06] iter = 16920, loss = 3.2942
2024-10-30 23:57:10: [2024-10-30 23:57:10] iter = 16930, loss = 2.3208
2024-10-30 23:57:13: [2024-10-30 23:57:13] iter = 16940, loss = 2.7126
2024-10-30 23:57:15: [2024-10-30 23:57:15] iter = 16950, loss = 2.8871
2024-10-30 23:57:17: [2024-10-30 23:57:17] iter = 16960, loss = 2.3348
2024-10-30 23:57:20: [2024-10-30 23:57:20] iter = 16970, loss = 2.9134
2024-10-30 23:57:23: [2024-10-30 23:57:23] iter = 16980, loss = 2.2186
2024-10-30 23:57:26: [2024-10-30 23:57:26] iter = 16990, loss = 2.3073
2024-10-30 23:57:29: [2024-10-30 23:57:29] iter = 17000, loss = 2.1860
2024-10-30 23:57:32: [2024-10-30 23:57:32] iter = 17010, loss = 2.2549
2024-10-30 23:57:35: [2024-10-30 23:57:35] iter = 17020, loss = 1.8270
2024-10-30 23:57:37: [2024-10-30 23:57:37] iter = 17030, loss = 1.8154
2024-10-30 23:57:40: [2024-10-30 23:57:40] iter = 17040, loss = 2.0017
2024-10-30 23:57:42: [2024-10-30 23:57:42] iter = 17050, loss = 2.0433
2024-10-30 23:57:44: [2024-10-30 23:57:44] iter = 17060, loss = 2.5001
2024-10-30 23:57:47: [2024-10-30 23:57:47] iter = 17070, loss = 3.4146
2024-10-30 23:57:50: [2024-10-30 23:57:50] iter = 17080, loss = 2.0348
2024-10-30 23:57:54: [2024-10-30 23:57:54] iter = 17090, loss = 1.8333
2024-10-30 23:57:58: [2024-10-30 23:57:58] iter = 17100, loss = 2.0376
2024-10-30 23:58:02: [2024-10-30 23:58:02] iter = 17110, loss = 1.9498
2024-10-30 23:58:04: [2024-10-30 23:58:04] iter = 17120, loss = 2.6427
2024-10-30 23:58:07: [2024-10-30 23:58:07] iter = 17130, loss = 2.4606
2024-10-30 23:58:10: [2024-10-30 23:58:10] iter = 17140, loss = 1.8866
2024-10-30 23:58:13: [2024-10-30 23:58:13] iter = 17150, loss = 2.6876
2024-10-30 23:58:17: [2024-10-30 23:58:16] iter = 17160, loss = 2.5706
2024-10-30 23:58:19: [2024-10-30 23:58:19] iter = 17170, loss = 3.1174
2024-10-30 23:58:22: [2024-10-30 23:58:22] iter = 17180, loss = 2.0027
2024-10-30 23:58:25: [2024-10-30 23:58:25] iter = 17190, loss = 2.2578
2024-10-30 23:58:28: [2024-10-30 23:58:28] iter = 17200, loss = 2.0280
2024-10-30 23:58:31: [2024-10-30 23:58:31] iter = 17210, loss = 2.1827
2024-10-30 23:58:34: [2024-10-30 23:58:34] iter = 17220, loss = 2.7758
2024-10-30 23:58:37: [2024-10-30 23:58:37] iter = 17230, loss = 2.2034
2024-10-30 23:58:39: [2024-10-30 23:58:39] iter = 17240, loss = 2.6611
2024-10-30 23:58:42: [2024-10-30 23:58:42] iter = 17250, loss = 1.9441
2024-10-30 23:58:45: [2024-10-30 23:58:45] iter = 17260, loss = 2.3149
2024-10-30 23:58:48: [2024-10-30 23:58:48] iter = 17270, loss = 2.9833
2024-10-30 23:58:51: [2024-10-30 23:58:51] iter = 17280, loss = 2.0024
2024-10-30 23:58:54: [2024-10-30 23:58:54] iter = 17290, loss = 2.4938
2024-10-30 23:58:56: [2024-10-30 23:58:56] iter = 17300, loss = 1.9871
2024-10-30 23:58:59: [2024-10-30 23:58:59] iter = 17310, loss = 1.7859
2024-10-30 23:59:02: [2024-10-30 23:59:02] iter = 17320, loss = 2.1481
2024-10-30 23:59:05: [2024-10-30 23:59:05] iter = 17330, loss = 2.8051
2024-10-30 23:59:08: [2024-10-30 23:59:08] iter = 17340, loss = 2.9372
2024-10-30 23:59:11: [2024-10-30 23:59:11] iter = 17350, loss = 2.0132
2024-10-30 23:59:14: [2024-10-30 23:59:14] iter = 17360, loss = 1.9680
2024-10-30 23:59:16: [2024-10-30 23:59:16] iter = 17370, loss = 2.1122
2024-10-30 23:59:19: [2024-10-30 23:59:19] iter = 17380, loss = 2.4288
2024-10-30 23:59:21: [2024-10-30 23:59:21] iter = 17390, loss = 2.2173
2024-10-30 23:59:24: [2024-10-30 23:59:24] iter = 17400, loss = 2.2528
2024-10-30 23:59:27: [2024-10-30 23:59:27] iter = 17410, loss = 2.3882
2024-10-30 23:59:30: [2024-10-30 23:59:30] iter = 17420, loss = 2.0215
2024-10-30 23:59:34: [2024-10-30 23:59:34] iter = 17430, loss = 2.0712
2024-10-30 23:59:37: [2024-10-30 23:59:37] iter = 17440, loss = 3.0530
2024-10-30 23:59:40: [2024-10-30 23:59:40] iter = 17450, loss = 2.1528
2024-10-30 23:59:43: [2024-10-30 23:59:43] iter = 17460, loss = 2.4409
2024-10-30 23:59:45: [2024-10-30 23:59:45] iter = 17470, loss = 2.8929
2024-10-30 23:59:47: [2024-10-30 23:59:47] iter = 17480, loss = 2.1935
2024-10-30 23:59:50: [2024-10-30 23:59:50] iter = 17490, loss = 2.0710
2024-10-30 23:59:52: [2024-10-30 23:59:52] iter = 17500, loss = 2.5748
2024-10-30 23:59:56: [2024-10-30 23:59:56] iter = 17510, loss = 2.4455
2024-10-30 23:59:59: [2024-10-30 23:59:59] iter = 17520, loss = 2.5541
2024-10-31 00:00:03: [2024-10-31 00:00:03] iter = 17530, loss = 2.2826
2024-10-31 00:00:07: [2024-10-31 00:00:07] iter = 17540, loss = 2.2250
2024-10-31 00:00:10: [2024-10-31 00:00:10] iter = 17550, loss = 2.2629
2024-10-31 00:00:13: [2024-10-31 00:00:13] iter = 17560, loss = 2.4448
2024-10-31 00:00:16: [2024-10-31 00:00:16] iter = 17570, loss = 3.8496
2024-10-31 00:00:18: [2024-10-31 00:00:18] iter = 17580, loss = 1.9950
2024-10-31 00:00:21: [2024-10-31 00:00:21] iter = 17590, loss = 2.1383
2024-10-31 00:00:25: [2024-10-31 00:00:25] iter = 17600, loss = 2.3540
2024-10-31 00:00:28: [2024-10-31 00:00:28] iter = 17610, loss = 2.1685
2024-10-31 00:00:31: [2024-10-31 00:00:31] iter = 17620, loss = 2.4854
2024-10-31 00:00:34: [2024-10-31 00:00:34] iter = 17630, loss = 2.2768
2024-10-31 00:00:36: [2024-10-31 00:00:36] iter = 17640, loss = 1.8827
2024-10-31 00:00:40: [2024-10-31 00:00:40] iter = 17650, loss = 1.8792
2024-10-31 00:00:42: [2024-10-31 00:00:42] iter = 17660, loss = 1.7451
2024-10-31 00:00:45: [2024-10-31 00:00:45] iter = 17670, loss = 2.0704
2024-10-31 00:00:48: [2024-10-31 00:00:48] iter = 17680, loss = 2.1966
2024-10-31 00:00:52: [2024-10-31 00:00:52] iter = 17690, loss = 2.0944
2024-10-31 00:00:55: [2024-10-31 00:00:55] iter = 17700, loss = 2.2659
2024-10-31 00:00:58: [2024-10-31 00:00:58] iter = 17710, loss = 2.2026
2024-10-31 00:01:00: [2024-10-31 00:01:00] iter = 17720, loss = 2.4936
2024-10-31 00:01:03: [2024-10-31 00:01:03] iter = 17730, loss = 2.2363
2024-10-31 00:01:06: [2024-10-31 00:01:06] iter = 17740, loss = 1.8788
2024-10-31 00:01:09: [2024-10-31 00:01:09] iter = 17750, loss = 2.0766
2024-10-31 00:01:11: [2024-10-31 00:01:11] iter = 17760, loss = 2.0997
2024-10-31 00:01:15: [2024-10-31 00:01:15] iter = 17770, loss = 2.0128
2024-10-31 00:01:17: [2024-10-31 00:01:17] iter = 17780, loss = 2.2024
2024-10-31 00:01:20: [2024-10-31 00:01:20] iter = 17790, loss = 1.7275
2024-10-31 00:01:22: [2024-10-31 00:01:22] iter = 17800, loss = 1.9790
2024-10-31 00:01:25: [2024-10-31 00:01:25] iter = 17810, loss = 2.3158
2024-10-31 00:01:27: [2024-10-31 00:01:27] iter = 17820, loss = 2.4417
2024-10-31 00:01:30: [2024-10-31 00:01:30] iter = 17830, loss = 2.4067
2024-10-31 00:01:33: [2024-10-31 00:01:33] iter = 17840, loss = 2.2822
2024-10-31 00:01:36: [2024-10-31 00:01:36] iter = 17850, loss = 2.6068
2024-10-31 00:01:39: [2024-10-31 00:01:39] iter = 17860, loss = 5.5414
2024-10-31 00:01:40: [2024-10-31 00:01:40] iter = 17870, loss = 3.1683
2024-10-31 00:01:43: [2024-10-31 00:01:43] iter = 17880, loss = 2.3508
2024-10-31 00:01:46: [2024-10-31 00:01:46] iter = 17890, loss = 2.7889
2024-10-31 00:01:49: [2024-10-31 00:01:49] iter = 17900, loss = 2.3204
2024-10-31 00:01:51: [2024-10-31 00:01:51] iter = 17910, loss = 2.1582
2024-10-31 00:01:54: [2024-10-31 00:01:54] iter = 17920, loss = 2.0534
2024-10-31 00:01:57: [2024-10-31 00:01:57] iter = 17930, loss = 2.0781
2024-10-31 00:02:00: [2024-10-31 00:02:00] iter = 17940, loss = 1.8437
2024-10-31 00:02:04: [2024-10-31 00:02:04] iter = 17950, loss = 3.1988
2024-10-31 00:02:06: [2024-10-31 00:02:06] iter = 17960, loss = 1.8784
2024-10-31 00:02:10: [2024-10-31 00:02:10] iter = 17970, loss = 2.0228
2024-10-31 00:02:13: [2024-10-31 00:02:13] iter = 17980, loss = 2.9670
2024-10-31 00:02:16: [2024-10-31 00:02:16] iter = 17990, loss = 2.1942
2024-10-31 00:02:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-31 00:02:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:02:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 40098}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:04:16: Evaluate 5 random ConvNet, ACCmean = 0.6040 ACCstd = 0.0049
-------------------------
2024-10-31 00:04:16: Evaluate 5 random ConvNet, SENmean = 0.5727 SENstd = 0.0072
-------------------------
2024-10-31 00:04:16: Evaluate 5 random ConvNet, SPEmean = 0.9596 SPEstd = 0.0005
-------------------------
2024-10-31 00:04:16: Evaluate 5 random ConvNet, F!mean = 0.5636 F!std = 0.0079
-------------------------
2024-10-31 00:04:16: Evaluate 5 random ConvNet, mean = 0.6040 std = 0.0049
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:04:17: [2024-10-31 00:04:17] iter = 18000, loss = 2.3774
2024-10-31 00:04:21: [2024-10-31 00:04:21] iter = 18010, loss = 2.1932
2024-10-31 00:04:24: [2024-10-31 00:04:24] iter = 18020, loss = 2.3556
2024-10-31 00:04:26: [2024-10-31 00:04:26] iter = 18030, loss = 1.8057
2024-10-31 00:04:29: [2024-10-31 00:04:29] iter = 18040, loss = 2.1457
2024-10-31 00:04:32: [2024-10-31 00:04:32] iter = 18050, loss = 1.9105
2024-10-31 00:04:36: [2024-10-31 00:04:36] iter = 18060, loss = 2.0641
2024-10-31 00:04:38: [2024-10-31 00:04:38] iter = 18070, loss = 1.9665
2024-10-31 00:04:41: [2024-10-31 00:04:41] iter = 18080, loss = 2.1595
2024-10-31 00:04:44: [2024-10-31 00:04:44] iter = 18090, loss = 4.5120
2024-10-31 00:04:46: [2024-10-31 00:04:46] iter = 18100, loss = 2.1000
2024-10-31 00:04:48: [2024-10-31 00:04:48] iter = 18110, loss = 2.1526
2024-10-31 00:04:52: [2024-10-31 00:04:52] iter = 18120, loss = 2.3726
2024-10-31 00:04:54: [2024-10-31 00:04:54] iter = 18130, loss = 2.5763
2024-10-31 00:04:56: [2024-10-31 00:04:56] iter = 18140, loss = 2.2601
2024-10-31 00:04:59: [2024-10-31 00:04:59] iter = 18150, loss = 2.9107
2024-10-31 00:05:02: [2024-10-31 00:05:02] iter = 18160, loss = 2.1004
2024-10-31 00:05:05: [2024-10-31 00:05:05] iter = 18170, loss = 3.1276
2024-10-31 00:05:09: [2024-10-31 00:05:09] iter = 18180, loss = 1.8544
2024-10-31 00:05:11: [2024-10-31 00:05:11] iter = 18190, loss = 1.7171
2024-10-31 00:05:13: [2024-10-31 00:05:13] iter = 18200, loss = 2.4452
2024-10-31 00:05:16: [2024-10-31 00:05:16] iter = 18210, loss = 1.8948
2024-10-31 00:05:19: [2024-10-31 00:05:19] iter = 18220, loss = 2.0995
2024-10-31 00:05:21: [2024-10-31 00:05:21] iter = 18230, loss = 3.0952
2024-10-31 00:05:24: [2024-10-31 00:05:24] iter = 18240, loss = 2.0160
2024-10-31 00:05:28: [2024-10-31 00:05:28] iter = 18250, loss = 2.6133
2024-10-31 00:05:30: [2024-10-31 00:05:30] iter = 18260, loss = 2.5693
2024-10-31 00:05:34: [2024-10-31 00:05:34] iter = 18270, loss = 2.0233
2024-10-31 00:05:37: [2024-10-31 00:05:37] iter = 18280, loss = 2.1655
2024-10-31 00:05:40: [2024-10-31 00:05:40] iter = 18290, loss = 2.0839
2024-10-31 00:05:42: [2024-10-31 00:05:42] iter = 18300, loss = 2.3270
2024-10-31 00:05:45: [2024-10-31 00:05:45] iter = 18310, loss = 1.7906
2024-10-31 00:05:49: [2024-10-31 00:05:49] iter = 18320, loss = 1.6943
2024-10-31 00:05:52: [2024-10-31 00:05:52] iter = 18330, loss = 2.2609
2024-10-31 00:05:56: [2024-10-31 00:05:56] iter = 18340, loss = 2.2357
2024-10-31 00:05:59: [2024-10-31 00:05:59] iter = 18350, loss = 1.8274
2024-10-31 00:06:02: [2024-10-31 00:06:02] iter = 18360, loss = 1.9616
2024-10-31 00:06:05: [2024-10-31 00:06:05] iter = 18370, loss = 2.5864
2024-10-31 00:06:08: [2024-10-31 00:06:08] iter = 18380, loss = 1.9449
2024-10-31 00:06:11: [2024-10-31 00:06:11] iter = 18390, loss = 1.7670
2024-10-31 00:06:14: [2024-10-31 00:06:14] iter = 18400, loss = 2.2660
2024-10-31 00:06:17: [2024-10-31 00:06:17] iter = 18410, loss = 2.0133
2024-10-31 00:06:21: [2024-10-31 00:06:21] iter = 18420, loss = 2.5563
2024-10-31 00:06:24: [2024-10-31 00:06:24] iter = 18430, loss = 2.5987
2024-10-31 00:06:26: [2024-10-31 00:06:26] iter = 18440, loss = 2.2863
2024-10-31 00:06:29: [2024-10-31 00:06:29] iter = 18450, loss = 1.8929
2024-10-31 00:06:32: [2024-10-31 00:06:32] iter = 18460, loss = 2.1877
2024-10-31 00:06:35: [2024-10-31 00:06:35] iter = 18470, loss = 1.6434
2024-10-31 00:06:38: [2024-10-31 00:06:38] iter = 18480, loss = 1.6967
2024-10-31 00:06:41: [2024-10-31 00:06:41] iter = 18490, loss = 2.7678
2024-10-31 00:06:44: [2024-10-31 00:06:44] iter = 18500, loss = 2.1614
2024-10-31 00:06:48: [2024-10-31 00:06:48] iter = 18510, loss = 1.8745
2024-10-31 00:06:52: [2024-10-31 00:06:52] iter = 18520, loss = 2.0127
2024-10-31 00:06:56: [2024-10-31 00:06:56] iter = 18530, loss = 2.5518
2024-10-31 00:06:59: [2024-10-31 00:06:59] iter = 18540, loss = 2.2515
2024-10-31 00:07:02: [2024-10-31 00:07:02] iter = 18550, loss = 1.8794
2024-10-31 00:07:05: [2024-10-31 00:07:05] iter = 18560, loss = 2.0217
2024-10-31 00:07:08: [2024-10-31 00:07:08] iter = 18570, loss = 2.0894
2024-10-31 00:07:12: [2024-10-31 00:07:12] iter = 18580, loss = 2.5578
2024-10-31 00:07:14: [2024-10-31 00:07:14] iter = 18590, loss = 2.4515
2024-10-31 00:07:17: [2024-10-31 00:07:17] iter = 18600, loss = 2.7423
2024-10-31 00:07:19: [2024-10-31 00:07:19] iter = 18610, loss = 2.2133
2024-10-31 00:07:23: [2024-10-31 00:07:23] iter = 18620, loss = 2.7274
2024-10-31 00:07:25: [2024-10-31 00:07:25] iter = 18630, loss = 2.1896
2024-10-31 00:07:28: [2024-10-31 00:07:28] iter = 18640, loss = 2.2523
2024-10-31 00:07:30: [2024-10-31 00:07:30] iter = 18650, loss = 2.2551
2024-10-31 00:07:33: [2024-10-31 00:07:33] iter = 18660, loss = 1.8937
2024-10-31 00:07:34: [2024-10-31 00:07:34] iter = 18670, loss = 2.7107
2024-10-31 00:07:37: [2024-10-31 00:07:37] iter = 18680, loss = 2.6065
2024-10-31 00:07:39: [2024-10-31 00:07:39] iter = 18690, loss = 2.3994
2024-10-31 00:07:42: [2024-10-31 00:07:42] iter = 18700, loss = 2.5620
2024-10-31 00:07:44: [2024-10-31 00:07:44] iter = 18710, loss = 2.9935
2024-10-31 00:07:47: [2024-10-31 00:07:47] iter = 18720, loss = 2.1956
2024-10-31 00:07:50: [2024-10-31 00:07:50] iter = 18730, loss = 2.4489
2024-10-31 00:07:52: [2024-10-31 00:07:52] iter = 18740, loss = 2.1024
2024-10-31 00:07:56: [2024-10-31 00:07:56] iter = 18750, loss = 2.4549
2024-10-31 00:07:59: [2024-10-31 00:07:59] iter = 18760, loss = 1.7777
2024-10-31 00:08:02: [2024-10-31 00:08:02] iter = 18770, loss = 2.4323
2024-10-31 00:08:05: [2024-10-31 00:08:05] iter = 18780, loss = 2.0200
2024-10-31 00:08:07: [2024-10-31 00:08:07] iter = 18790, loss = 2.4096
2024-10-31 00:08:10: [2024-10-31 00:08:10] iter = 18800, loss = 2.0489
2024-10-31 00:08:13: [2024-10-31 00:08:13] iter = 18810, loss = 2.8551
2024-10-31 00:08:15: [2024-10-31 00:08:15] iter = 18820, loss = 2.2053
2024-10-31 00:08:18: [2024-10-31 00:08:18] iter = 18830, loss = 1.9686
2024-10-31 00:08:21: [2024-10-31 00:08:21] iter = 18840, loss = 2.4444
2024-10-31 00:08:24: [2024-10-31 00:08:24] iter = 18850, loss = 2.4116
2024-10-31 00:08:26: [2024-10-31 00:08:26] iter = 18860, loss = 2.1371
2024-10-31 00:08:29: [2024-10-31 00:08:29] iter = 18870, loss = 1.8954
2024-10-31 00:08:31: [2024-10-31 00:08:31] iter = 18880, loss = 2.3310
2024-10-31 00:08:34: [2024-10-31 00:08:34] iter = 18890, loss = 2.0468
2024-10-31 00:08:37: [2024-10-31 00:08:37] iter = 18900, loss = 3.6896
2024-10-31 00:08:40: [2024-10-31 00:08:40] iter = 18910, loss = 3.1754
2024-10-31 00:08:43: [2024-10-31 00:08:43] iter = 18920, loss = 2.4994
2024-10-31 00:08:46: [2024-10-31 00:08:46] iter = 18930, loss = 1.9212
2024-10-31 00:08:48: [2024-10-31 00:08:48] iter = 18940, loss = 2.1194
2024-10-31 00:08:51: [2024-10-31 00:08:51] iter = 18950, loss = 1.9880
2024-10-31 00:08:55: [2024-10-31 00:08:55] iter = 18960, loss = 2.5970
2024-10-31 00:08:58: [2024-10-31 00:08:58] iter = 18970, loss = 2.2439
2024-10-31 00:09:01: [2024-10-31 00:09:01] iter = 18980, loss = 2.2734
2024-10-31 00:09:04: [2024-10-31 00:09:04] iter = 18990, loss = 3.4170
2024-10-31 00:09:08: [2024-10-31 00:09:08] iter = 19000, loss = 2.3234
2024-10-31 00:09:11: [2024-10-31 00:09:11] iter = 19010, loss = 2.0642
2024-10-31 00:09:14: [2024-10-31 00:09:14] iter = 19020, loss = 2.2015
2024-10-31 00:09:18: [2024-10-31 00:09:18] iter = 19030, loss = 1.9777
2024-10-31 00:09:21: [2024-10-31 00:09:21] iter = 19040, loss = 2.0976
2024-10-31 00:09:24: [2024-10-31 00:09:24] iter = 19050, loss = 4.0993
2024-10-31 00:09:27: [2024-10-31 00:09:27] iter = 19060, loss = 2.7030
2024-10-31 00:09:30: [2024-10-31 00:09:30] iter = 19070, loss = 2.1331
2024-10-31 00:09:33: [2024-10-31 00:09:33] iter = 19080, loss = 3.0206
2024-10-31 00:09:36: [2024-10-31 00:09:36] iter = 19090, loss = 1.9259
2024-10-31 00:09:39: [2024-10-31 00:09:39] iter = 19100, loss = 1.9670
2024-10-31 00:09:41: [2024-10-31 00:09:41] iter = 19110, loss = 2.4929
2024-10-31 00:09:43: [2024-10-31 00:09:43] iter = 19120, loss = 2.2099
2024-10-31 00:09:46: [2024-10-31 00:09:46] iter = 19130, loss = 4.8127
2024-10-31 00:09:50: [2024-10-31 00:09:50] iter = 19140, loss = 2.0554
2024-10-31 00:09:53: [2024-10-31 00:09:53] iter = 19150, loss = 1.9953
2024-10-31 00:09:55: [2024-10-31 00:09:55] iter = 19160, loss = 2.0481
2024-10-31 00:09:58: [2024-10-31 00:09:58] iter = 19170, loss = 3.1852
2024-10-31 00:10:01: [2024-10-31 00:10:01] iter = 19180, loss = 1.8574
2024-10-31 00:10:05: [2024-10-31 00:10:05] iter = 19190, loss = 2.0583
2024-10-31 00:10:07: [2024-10-31 00:10:07] iter = 19200, loss = 2.6562
2024-10-31 00:10:10: [2024-10-31 00:10:10] iter = 19210, loss = 1.8062
2024-10-31 00:10:13: [2024-10-31 00:10:13] iter = 19220, loss = 5.5477
2024-10-31 00:10:16: [2024-10-31 00:10:16] iter = 19230, loss = 2.1440
2024-10-31 00:10:19: [2024-10-31 00:10:19] iter = 19240, loss = 1.8713
2024-10-31 00:10:22: [2024-10-31 00:10:22] iter = 19250, loss = 2.0348
2024-10-31 00:10:26: [2024-10-31 00:10:26] iter = 19260, loss = 2.5178
2024-10-31 00:10:29: [2024-10-31 00:10:29] iter = 19270, loss = 2.5768
2024-10-31 00:10:32: [2024-10-31 00:10:32] iter = 19280, loss = 1.7160
2024-10-31 00:10:35: [2024-10-31 00:10:35] iter = 19290, loss = 1.6661
2024-10-31 00:10:38: [2024-10-31 00:10:38] iter = 19300, loss = 2.5837
2024-10-31 00:10:41: [2024-10-31 00:10:41] iter = 19310, loss = 4.7530
2024-10-31 00:10:43: [2024-10-31 00:10:43] iter = 19320, loss = 1.9697
2024-10-31 00:10:45: [2024-10-31 00:10:45] iter = 19330, loss = 1.9712
2024-10-31 00:10:48: [2024-10-31 00:10:48] iter = 19340, loss = 2.3553
2024-10-31 00:10:50: [2024-10-31 00:10:50] iter = 19350, loss = 2.0084
2024-10-31 00:10:52: [2024-10-31 00:10:52] iter = 19360, loss = 2.4221
2024-10-31 00:10:56: [2024-10-31 00:10:56] iter = 19370, loss = 2.0808
2024-10-31 00:10:59: [2024-10-31 00:10:59] iter = 19380, loss = 2.8175
2024-10-31 00:11:01: [2024-10-31 00:11:01] iter = 19390, loss = 2.0726
2024-10-31 00:11:03: [2024-10-31 00:11:03] iter = 19400, loss = 2.9133
2024-10-31 00:11:06: [2024-10-31 00:11:06] iter = 19410, loss = 2.1940
2024-10-31 00:11:09: [2024-10-31 00:11:09] iter = 19420, loss = 2.4055
2024-10-31 00:11:12: [2024-10-31 00:11:12] iter = 19430, loss = 2.2709
2024-10-31 00:11:15: [2024-10-31 00:11:15] iter = 19440, loss = 2.9692
2024-10-31 00:11:17: [2024-10-31 00:11:17] iter = 19450, loss = 2.5450
2024-10-31 00:11:20: [2024-10-31 00:11:20] iter = 19460, loss = 1.9918
2024-10-31 00:11:23: [2024-10-31 00:11:23] iter = 19470, loss = 2.3521
2024-10-31 00:11:26: [2024-10-31 00:11:26] iter = 19480, loss = 2.5021
2024-10-31 00:11:28: [2024-10-31 00:11:28] iter = 19490, loss = 2.6890
2024-10-31 00:11:31: [2024-10-31 00:11:31] iter = 19500, loss = 2.7716
2024-10-31 00:11:35: [2024-10-31 00:11:35] iter = 19510, loss = 1.9255
2024-10-31 00:11:38: [2024-10-31 00:11:38] iter = 19520, loss = 2.1980
2024-10-31 00:11:41: [2024-10-31 00:11:41] iter = 19530, loss = 2.4925
2024-10-31 00:11:44: [2024-10-31 00:11:44] iter = 19540, loss = 1.8772
2024-10-31 00:11:47: [2024-10-31 00:11:47] iter = 19550, loss = 2.3829
2024-10-31 00:11:51: [2024-10-31 00:11:51] iter = 19560, loss = 1.7333
2024-10-31 00:11:53: [2024-10-31 00:11:53] iter = 19570, loss = 2.4433
2024-10-31 00:11:55: [2024-10-31 00:11:55] iter = 19580, loss = 1.9202
2024-10-31 00:11:58: [2024-10-31 00:11:58] iter = 19590, loss = 2.4131
2024-10-31 00:12:01: [2024-10-31 00:12:01] iter = 19600, loss = 2.9016
2024-10-31 00:12:03: [2024-10-31 00:12:03] iter = 19610, loss = 3.0531
2024-10-31 00:12:06: [2024-10-31 00:12:06] iter = 19620, loss = 2.2267
2024-10-31 00:12:10: [2024-10-31 00:12:10] iter = 19630, loss = 1.8644
2024-10-31 00:12:13: [2024-10-31 00:12:13] iter = 19640, loss = 2.4907
2024-10-31 00:12:15: [2024-10-31 00:12:15] iter = 19650, loss = 2.1713
2024-10-31 00:12:17: [2024-10-31 00:12:17] iter = 19660, loss = 1.9509
2024-10-31 00:12:20: [2024-10-31 00:12:20] iter = 19670, loss = 1.9438
2024-10-31 00:12:22: [2024-10-31 00:12:22] iter = 19680, loss = 3.0252
2024-10-31 00:12:26: [2024-10-31 00:12:26] iter = 19690, loss = 2.3935
2024-10-31 00:12:28: [2024-10-31 00:12:28] iter = 19700, loss = 1.9177
2024-10-31 00:12:30: [2024-10-31 00:12:30] iter = 19710, loss = 2.4091
2024-10-31 00:12:33: [2024-10-31 00:12:33] iter = 19720, loss = 2.0408
2024-10-31 00:12:36: [2024-10-31 00:12:36] iter = 19730, loss = 2.0197
2024-10-31 00:12:39: [2024-10-31 00:12:39] iter = 19740, loss = 3.4088
2024-10-31 00:12:41: [2024-10-31 00:12:41] iter = 19750, loss = 1.9104
2024-10-31 00:12:44: [2024-10-31 00:12:44] iter = 19760, loss = 2.5588
2024-10-31 00:12:47: [2024-10-31 00:12:47] iter = 19770, loss = 2.0175
2024-10-31 00:12:51: [2024-10-31 00:12:51] iter = 19780, loss = 4.4674
2024-10-31 00:12:54: [2024-10-31 00:12:54] iter = 19790, loss = 1.7505
2024-10-31 00:12:58: [2024-10-31 00:12:58] iter = 19800, loss = 2.8262
2024-10-31 00:13:00: [2024-10-31 00:13:00] iter = 19810, loss = 2.0057
2024-10-31 00:13:04: [2024-10-31 00:13:04] iter = 19820, loss = 2.4015
2024-10-31 00:13:07: [2024-10-31 00:13:07] iter = 19830, loss = 2.3571
2024-10-31 00:13:10: [2024-10-31 00:13:10] iter = 19840, loss = 2.1936
2024-10-31 00:13:14: [2024-10-31 00:13:14] iter = 19850, loss = 2.2857
2024-10-31 00:13:17: [2024-10-31 00:13:17] iter = 19860, loss = 2.3186
2024-10-31 00:13:20: [2024-10-31 00:13:20] iter = 19870, loss = 2.7916
2024-10-31 00:13:23: [2024-10-31 00:13:23] iter = 19880, loss = 1.8838
2024-10-31 00:13:25: [2024-10-31 00:13:25] iter = 19890, loss = 2.3752
2024-10-31 00:13:28: [2024-10-31 00:13:28] iter = 19900, loss = 2.9991
2024-10-31 00:13:30: [2024-10-31 00:13:30] iter = 19910, loss = 2.4598
2024-10-31 00:13:34: [2024-10-31 00:13:34] iter = 19920, loss = 4.0907
2024-10-31 00:13:37: [2024-10-31 00:13:37] iter = 19930, loss = 2.3651
2024-10-31 00:13:40: [2024-10-31 00:13:40] iter = 19940, loss = 1.8202
2024-10-31 00:13:44: [2024-10-31 00:13:44] iter = 19950, loss = 2.2405
2024-10-31 00:13:46: [2024-10-31 00:13:46] iter = 19960, loss = 3.8370
2024-10-31 00:13:50: [2024-10-31 00:13:50] iter = 19970, loss = 2.9872
2024-10-31 00:13:53: [2024-10-31 00:13:53] iter = 19980, loss = 2.1582
2024-10-31 00:13:57: [2024-10-31 00:13:57] iter = 19990, loss = 1.9881
2024-10-31 00:13:59: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-31 00:13:59: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:13:59: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 39479}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:16:06: Evaluate 5 random ConvNet, ACCmean = 0.6062 ACCstd = 0.0070
-------------------------
2024-10-31 00:16:06: Evaluate 5 random ConvNet, SENmean = 0.5921 SENstd = 0.0069
-------------------------
2024-10-31 00:16:06: Evaluate 5 random ConvNet, SPEmean = 0.9599 SPEstd = 0.0007
-------------------------
2024-10-31 00:16:06: Evaluate 5 random ConvNet, F!mean = 0.5788 F!std = 0.0072
-------------------------
2024-10-31 00:16:06: Evaluate 5 random ConvNet, mean = 0.6062 std = 0.0070
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:16:06: [2024-10-31 00:16:06] iter = 20000, loss = 2.1454
2024-10-31 00:16:06: 
================== Exp 4 ==================
 
2024-10-31 00:16:06: Hyper-parameters: 
{'dataset': 'OrganSMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fa9b88fdb20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OrganSMNIST (INFO)>}
2024-10-31 00:16:06: Evaluation model pool: ['ConvNet']
2024-10-31 00:16:08: class c = 0: 1148 real images
2024-10-31 00:16:08: class c = 1: 630 real images
2024-10-31 00:16:08: class c = 2: 614 real images
2024-10-31 00:16:08: class c = 3: 721 real images
2024-10-31 00:16:08: class c = 4: 1132 real images
2024-10-31 00:16:08: class c = 5: 1119 real images
2024-10-31 00:16:08: class c = 6: 3464 real images
2024-10-31 00:16:08: class c = 7: 741 real images
2024-10-31 00:16:08: class c = 8: 803 real images
2024-10-31 00:16:08: class c = 9: 2004 real images
2024-10-31 00:16:08: class c = 10: 1556 real images
2024-10-31 00:16:08: real images channel 0, mean = 0.4953, std = 0.2826
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-31 00:16:08: initialize synthetic data from random real images
2024-10-31 00:16:08: [2024-10-31 00:16:08] training begins
2024-10-31 00:16:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-31 00:16:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:16:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 66732}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:18:04: Evaluate 5 random ConvNet, ACCmean = 0.4451 ACCstd = 0.0032
-------------------------
2024-10-31 00:18:04: Evaluate 5 random ConvNet, SENmean = 0.4384 SENstd = 0.0030
-------------------------
2024-10-31 00:18:04: Evaluate 5 random ConvNet, SPEmean = 0.9439 SPEstd = 0.0003
-------------------------
2024-10-31 00:18:04: Evaluate 5 random ConvNet, F!mean = 0.4260 F!std = 0.0026
-------------------------
2024-10-31 00:18:04: Evaluate 5 random ConvNet, mean = 0.4451 std = 0.0032
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:18:05: [2024-10-31 00:18:05] iter = 00000, loss = 15.4607
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:18:09: [2024-10-31 00:18:09] iter = 00010, loss = 5.3359
2024-10-31 00:18:12: [2024-10-31 00:18:12] iter = 00020, loss = 3.7081
2024-10-31 00:18:15: [2024-10-31 00:18:15] iter = 00030, loss = 4.2070
2024-10-31 00:18:18: [2024-10-31 00:18:18] iter = 00040, loss = 5.4257
2024-10-31 00:18:20: [2024-10-31 00:18:20] iter = 00050, loss = 3.1292
2024-10-31 00:18:24: [2024-10-31 00:18:24] iter = 00060, loss = 2.8153
2024-10-31 00:18:27: [2024-10-31 00:18:27] iter = 00070, loss = 3.4763
2024-10-31 00:18:30: [2024-10-31 00:18:30] iter = 00080, loss = 3.9838
2024-10-31 00:18:34: [2024-10-31 00:18:34] iter = 00090, loss = 2.9443
2024-10-31 00:18:36: [2024-10-31 00:18:36] iter = 00100, loss = 3.3678
2024-10-31 00:18:40: [2024-10-31 00:18:40] iter = 00110, loss = 2.7525
2024-10-31 00:18:43: [2024-10-31 00:18:43] iter = 00120, loss = 3.0862
2024-10-31 00:18:46: [2024-10-31 00:18:46] iter = 00130, loss = 2.8898
2024-10-31 00:18:48: [2024-10-31 00:18:48] iter = 00140, loss = 2.5901
2024-10-31 00:18:51: [2024-10-31 00:18:51] iter = 00150, loss = 2.2205
2024-10-31 00:18:54: [2024-10-31 00:18:54] iter = 00160, loss = 2.5879
2024-10-31 00:18:57: [2024-10-31 00:18:57] iter = 00170, loss = 2.3516
2024-10-31 00:19:00: [2024-10-31 00:19:00] iter = 00180, loss = 3.1779
2024-10-31 00:19:02: [2024-10-31 00:19:02] iter = 00190, loss = 2.2908
2024-10-31 00:19:05: [2024-10-31 00:19:05] iter = 00200, loss = 2.6836
2024-10-31 00:19:09: [2024-10-31 00:19:09] iter = 00210, loss = 2.6131
2024-10-31 00:19:12: [2024-10-31 00:19:12] iter = 00220, loss = 2.6983
2024-10-31 00:19:15: [2024-10-31 00:19:15] iter = 00230, loss = 2.9527
2024-10-31 00:19:18: [2024-10-31 00:19:18] iter = 00240, loss = 1.8905
2024-10-31 00:19:21: [2024-10-31 00:19:21] iter = 00250, loss = 2.6639
2024-10-31 00:19:25: [2024-10-31 00:19:25] iter = 00260, loss = 2.1292
2024-10-31 00:19:28: [2024-10-31 00:19:28] iter = 00270, loss = 3.1557
2024-10-31 00:19:31: [2024-10-31 00:19:31] iter = 00280, loss = 2.2807
2024-10-31 00:19:35: [2024-10-31 00:19:35] iter = 00290, loss = 2.5377
2024-10-31 00:19:37: [2024-10-31 00:19:37] iter = 00300, loss = 2.8486
2024-10-31 00:19:41: [2024-10-31 00:19:41] iter = 00310, loss = 2.1216
2024-10-31 00:19:44: [2024-10-31 00:19:44] iter = 00320, loss = 2.4504
2024-10-31 00:19:47: [2024-10-31 00:19:47] iter = 00330, loss = 2.8143
2024-10-31 00:19:49: [2024-10-31 00:19:49] iter = 00340, loss = 2.9536
2024-10-31 00:19:52: [2024-10-31 00:19:52] iter = 00350, loss = 2.5978
2024-10-31 00:19:54: [2024-10-31 00:19:54] iter = 00360, loss = 2.6910
2024-10-31 00:19:57: [2024-10-31 00:19:57] iter = 00370, loss = 2.9472
2024-10-31 00:20:00: [2024-10-31 00:20:00] iter = 00380, loss = 2.5569
2024-10-31 00:20:03: [2024-10-31 00:20:03] iter = 00390, loss = 2.2111
2024-10-31 00:20:06: [2024-10-31 00:20:06] iter = 00400, loss = 2.8046
2024-10-31 00:20:10: [2024-10-31 00:20:10] iter = 00410, loss = 3.0734
2024-10-31 00:20:13: [2024-10-31 00:20:13] iter = 00420, loss = 2.1510
2024-10-31 00:20:17: [2024-10-31 00:20:17] iter = 00430, loss = 2.1404
2024-10-31 00:20:19: [2024-10-31 00:20:19] iter = 00440, loss = 2.0840
2024-10-31 00:20:21: [2024-10-31 00:20:21] iter = 00450, loss = 2.4565
2024-10-31 00:20:23: [2024-10-31 00:20:23] iter = 00460, loss = 2.1328
2024-10-31 00:20:25: [2024-10-31 00:20:25] iter = 00470, loss = 3.2569
2024-10-31 00:20:28: [2024-10-31 00:20:28] iter = 00480, loss = 2.3773
2024-10-31 00:20:31: [2024-10-31 00:20:31] iter = 00490, loss = 2.2653
2024-10-31 00:20:34: [2024-10-31 00:20:34] iter = 00500, loss = 3.5286
2024-10-31 00:20:37: [2024-10-31 00:20:37] iter = 00510, loss = 2.6755
2024-10-31 00:20:40: [2024-10-31 00:20:40] iter = 00520, loss = 2.1725
2024-10-31 00:20:44: [2024-10-31 00:20:44] iter = 00530, loss = 2.2942
2024-10-31 00:20:47: [2024-10-31 00:20:47] iter = 00540, loss = 2.4639
2024-10-31 00:20:50: [2024-10-31 00:20:50] iter = 00550, loss = 2.5572
2024-10-31 00:20:53: [2024-10-31 00:20:53] iter = 00560, loss = 2.0858
2024-10-31 00:20:56: [2024-10-31 00:20:56] iter = 00570, loss = 1.8652
2024-10-31 00:21:00: [2024-10-31 00:21:00] iter = 00580, loss = 2.8899
2024-10-31 00:21:03: [2024-10-31 00:21:03] iter = 00590, loss = 3.5417
2024-10-31 00:21:05: [2024-10-31 00:21:05] iter = 00600, loss = 3.7727
2024-10-31 00:21:08: [2024-10-31 00:21:08] iter = 00610, loss = 2.7123
2024-10-31 00:21:11: [2024-10-31 00:21:11] iter = 00620, loss = 2.4457
2024-10-31 00:21:14: [2024-10-31 00:21:14] iter = 00630, loss = 2.5344
2024-10-31 00:21:17: [2024-10-31 00:21:17] iter = 00640, loss = 4.3065
2024-10-31 00:21:20: [2024-10-31 00:21:20] iter = 00650, loss = 2.1282
2024-10-31 00:21:23: [2024-10-31 00:21:23] iter = 00660, loss = 2.7022
2024-10-31 00:21:25: [2024-10-31 00:21:25] iter = 00670, loss = 2.0773
2024-10-31 00:21:28: [2024-10-31 00:21:28] iter = 00680, loss = 2.3736
2024-10-31 00:21:32: [2024-10-31 00:21:32] iter = 00690, loss = 2.5023
2024-10-31 00:21:35: [2024-10-31 00:21:35] iter = 00700, loss = 2.1623
2024-10-31 00:21:38: [2024-10-31 00:21:38] iter = 00710, loss = 2.3221
2024-10-31 00:21:40: [2024-10-31 00:21:40] iter = 00720, loss = 3.1645
2024-10-31 00:21:43: [2024-10-31 00:21:43] iter = 00730, loss = 2.3348
2024-10-31 00:21:46: [2024-10-31 00:21:46] iter = 00740, loss = 2.2685
2024-10-31 00:21:48: [2024-10-31 00:21:48] iter = 00750, loss = 2.2820
2024-10-31 00:21:50: [2024-10-31 00:21:50] iter = 00760, loss = 2.7748
2024-10-31 00:21:53: [2024-10-31 00:21:53] iter = 00770, loss = 2.4085
2024-10-31 00:21:56: [2024-10-31 00:21:56] iter = 00780, loss = 2.8322
2024-10-31 00:21:58: [2024-10-31 00:21:58] iter = 00790, loss = 2.8261
2024-10-31 00:22:01: [2024-10-31 00:22:01] iter = 00800, loss = 3.3814
2024-10-31 00:22:04: [2024-10-31 00:22:04] iter = 00810, loss = 3.2936
2024-10-31 00:22:07: [2024-10-31 00:22:07] iter = 00820, loss = 2.2907
2024-10-31 00:22:09: [2024-10-31 00:22:09] iter = 00830, loss = 2.8639
2024-10-31 00:22:12: [2024-10-31 00:22:12] iter = 00840, loss = 2.1620
2024-10-31 00:22:15: [2024-10-31 00:22:15] iter = 00850, loss = 2.0593
2024-10-31 00:22:17: [2024-10-31 00:22:17] iter = 00860, loss = 2.2443
2024-10-31 00:22:18: [2024-10-31 00:22:18] iter = 00870, loss = 2.0788
2024-10-31 00:22:21: [2024-10-31 00:22:21] iter = 00880, loss = 2.0108
2024-10-31 00:22:24: [2024-10-31 00:22:24] iter = 00890, loss = 2.4774
2024-10-31 00:22:27: [2024-10-31 00:22:27] iter = 00900, loss = 3.8194
2024-10-31 00:22:30: [2024-10-31 00:22:30] iter = 00910, loss = 2.4241
2024-10-31 00:22:32: [2024-10-31 00:22:32] iter = 00920, loss = 2.7575
2024-10-31 00:22:34: [2024-10-31 00:22:34] iter = 00930, loss = 1.9206
2024-10-31 00:22:37: [2024-10-31 00:22:37] iter = 00940, loss = 2.2026
2024-10-31 00:22:40: [2024-10-31 00:22:40] iter = 00950, loss = 2.1632
2024-10-31 00:22:44: [2024-10-31 00:22:44] iter = 00960, loss = 2.7228
2024-10-31 00:22:46: [2024-10-31 00:22:46] iter = 00970, loss = 2.5791
2024-10-31 00:22:50: [2024-10-31 00:22:50] iter = 00980, loss = 2.6396
2024-10-31 00:22:53: [2024-10-31 00:22:53] iter = 00990, loss = 2.4281
2024-10-31 00:22:56: [2024-10-31 00:22:56] iter = 01000, loss = 2.5952
2024-10-31 00:22:58: [2024-10-31 00:22:58] iter = 01010, loss = 3.6321
2024-10-31 00:23:01: [2024-10-31 00:23:01] iter = 01020, loss = 3.0139
2024-10-31 00:23:06: [2024-10-31 00:23:06] iter = 01030, loss = 2.1985
2024-10-31 00:23:09: [2024-10-31 00:23:09] iter = 01040, loss = 1.8901
2024-10-31 00:23:11: [2024-10-31 00:23:11] iter = 01050, loss = 2.9897
2024-10-31 00:23:15: [2024-10-31 00:23:15] iter = 01060, loss = 2.0129
2024-10-31 00:23:19: [2024-10-31 00:23:19] iter = 01070, loss = 2.0392
2024-10-31 00:23:21: [2024-10-31 00:23:21] iter = 01080, loss = 2.5181
2024-10-31 00:23:25: [2024-10-31 00:23:25] iter = 01090, loss = 2.3143
2024-10-31 00:23:28: [2024-10-31 00:23:28] iter = 01100, loss = 1.9842
2024-10-31 00:23:31: [2024-10-31 00:23:31] iter = 01110, loss = 2.8646
2024-10-31 00:23:35: [2024-10-31 00:23:35] iter = 01120, loss = 2.6955
2024-10-31 00:23:37: [2024-10-31 00:23:37] iter = 01130, loss = 2.1862
2024-10-31 00:23:41: [2024-10-31 00:23:41] iter = 01140, loss = 2.3543
2024-10-31 00:23:44: [2024-10-31 00:23:44] iter = 01150, loss = 2.2525
2024-10-31 00:23:46: [2024-10-31 00:23:46] iter = 01160, loss = 2.1182
2024-10-31 00:23:48: [2024-10-31 00:23:48] iter = 01170, loss = 1.8578
2024-10-31 00:23:51: [2024-10-31 00:23:51] iter = 01180, loss = 1.9348
2024-10-31 00:23:53: [2024-10-31 00:23:53] iter = 01190, loss = 3.1789
2024-10-31 00:23:55: [2024-10-31 00:23:55] iter = 01200, loss = 1.8412
2024-10-31 00:23:58: [2024-10-31 00:23:58] iter = 01210, loss = 2.6463
2024-10-31 00:24:01: [2024-10-31 00:24:01] iter = 01220, loss = 2.9846
2024-10-31 00:24:03: [2024-10-31 00:24:03] iter = 01230, loss = 1.8583
2024-10-31 00:24:05: [2024-10-31 00:24:05] iter = 01240, loss = 2.3657
2024-10-31 00:24:08: [2024-10-31 00:24:08] iter = 01250, loss = 3.3400
2024-10-31 00:24:10: [2024-10-31 00:24:10] iter = 01260, loss = 2.4526
2024-10-31 00:24:13: [2024-10-31 00:24:13] iter = 01270, loss = 3.1359
2024-10-31 00:24:16: [2024-10-31 00:24:16] iter = 01280, loss = 2.3860
2024-10-31 00:24:19: [2024-10-31 00:24:19] iter = 01290, loss = 2.0384
2024-10-31 00:24:22: [2024-10-31 00:24:22] iter = 01300, loss = 2.2364
2024-10-31 00:24:25: [2024-10-31 00:24:25] iter = 01310, loss = 2.2061
2024-10-31 00:24:27: [2024-10-31 00:24:27] iter = 01320, loss = 2.3499
2024-10-31 00:24:30: [2024-10-31 00:24:30] iter = 01330, loss = 2.3371
2024-10-31 00:24:33: [2024-10-31 00:24:33] iter = 01340, loss = 2.0235
2024-10-31 00:24:36: [2024-10-31 00:24:36] iter = 01350, loss = 2.0011
2024-10-31 00:24:40: [2024-10-31 00:24:40] iter = 01360, loss = 2.3022
2024-10-31 00:24:43: [2024-10-31 00:24:43] iter = 01370, loss = 2.5323
2024-10-31 00:24:47: [2024-10-31 00:24:47] iter = 01380, loss = 4.6545
2024-10-31 00:24:50: [2024-10-31 00:24:50] iter = 01390, loss = 2.3159
2024-10-31 00:24:53: [2024-10-31 00:24:53] iter = 01400, loss = 2.1973
2024-10-31 00:24:56: [2024-10-31 00:24:56] iter = 01410, loss = 2.1014
2024-10-31 00:24:59: [2024-10-31 00:24:59] iter = 01420, loss = 1.9714
2024-10-31 00:25:02: [2024-10-31 00:25:02] iter = 01430, loss = 2.1175
2024-10-31 00:25:06: [2024-10-31 00:25:06] iter = 01440, loss = 2.3849
2024-10-31 00:25:09: [2024-10-31 00:25:09] iter = 01450, loss = 2.7273
2024-10-31 00:25:12: [2024-10-31 00:25:12] iter = 01460, loss = 1.9358
2024-10-31 00:25:15: [2024-10-31 00:25:15] iter = 01470, loss = 3.0695
2024-10-31 00:25:18: [2024-10-31 00:25:18] iter = 01480, loss = 4.9419
2024-10-31 00:25:21: [2024-10-31 00:25:21] iter = 01490, loss = 2.0666
2024-10-31 00:25:24: [2024-10-31 00:25:24] iter = 01500, loss = 1.9662
2024-10-31 00:25:27: [2024-10-31 00:25:27] iter = 01510, loss = 2.1840
2024-10-31 00:25:30: [2024-10-31 00:25:30] iter = 01520, loss = 2.1251
2024-10-31 00:25:32: [2024-10-31 00:25:32] iter = 01530, loss = 3.8965
2024-10-31 00:25:34: [2024-10-31 00:25:34] iter = 01540, loss = 2.8087
2024-10-31 00:25:38: [2024-10-31 00:25:38] iter = 01550, loss = 1.9640
2024-10-31 00:25:41: [2024-10-31 00:25:41] iter = 01560, loss = 2.2275
2024-10-31 00:25:45: [2024-10-31 00:25:45] iter = 01570, loss = 2.6726
2024-10-31 00:25:48: [2024-10-31 00:25:48] iter = 01580, loss = 3.0212
2024-10-31 00:25:51: [2024-10-31 00:25:51] iter = 01590, loss = 2.0490
2024-10-31 00:25:55: [2024-10-31 00:25:55] iter = 01600, loss = 2.6534
2024-10-31 00:25:58: [2024-10-31 00:25:58] iter = 01610, loss = 3.0263
2024-10-31 00:26:01: [2024-10-31 00:26:01] iter = 01620, loss = 1.9646
2024-10-31 00:26:04: [2024-10-31 00:26:04] iter = 01630, loss = 2.3327
2024-10-31 00:26:06: [2024-10-31 00:26:06] iter = 01640, loss = 2.5889
2024-10-31 00:26:08: [2024-10-31 00:26:08] iter = 01650, loss = 2.5460
2024-10-31 00:26:11: [2024-10-31 00:26:11] iter = 01660, loss = 2.1873
2024-10-31 00:26:14: [2024-10-31 00:26:14] iter = 01670, loss = 2.0666
2024-10-31 00:26:17: [2024-10-31 00:26:17] iter = 01680, loss = 2.8969
2024-10-31 00:26:19: [2024-10-31 00:26:19] iter = 01690, loss = 3.1534
2024-10-31 00:26:21: [2024-10-31 00:26:21] iter = 01700, loss = 2.9109
2024-10-31 00:26:25: [2024-10-31 00:26:25] iter = 01710, loss = 1.9442
2024-10-31 00:26:27: [2024-10-31 00:26:27] iter = 01720, loss = 1.7623
2024-10-31 00:26:30: [2024-10-31 00:26:30] iter = 01730, loss = 2.5134
2024-10-31 00:26:34: [2024-10-31 00:26:34] iter = 01740, loss = 1.9279
2024-10-31 00:26:37: [2024-10-31 00:26:37] iter = 01750, loss = 3.5219
2024-10-31 00:26:40: [2024-10-31 00:26:40] iter = 01760, loss = 2.1147
2024-10-31 00:26:43: [2024-10-31 00:26:43] iter = 01770, loss = 2.0665
2024-10-31 00:26:46: [2024-10-31 00:26:46] iter = 01780, loss = 1.9126
2024-10-31 00:26:49: [2024-10-31 00:26:49] iter = 01790, loss = 3.1270
2024-10-31 00:26:53: [2024-10-31 00:26:53] iter = 01800, loss = 2.9733
2024-10-31 00:26:56: [2024-10-31 00:26:56] iter = 01810, loss = 2.1795
2024-10-31 00:27:00: [2024-10-31 00:27:00] iter = 01820, loss = 2.4179
2024-10-31 00:27:03: [2024-10-31 00:27:03] iter = 01830, loss = 3.2669
2024-10-31 00:27:05: [2024-10-31 00:27:05] iter = 01840, loss = 2.6955
2024-10-31 00:27:09: [2024-10-31 00:27:09] iter = 01850, loss = 2.2854
2024-10-31 00:27:12: [2024-10-31 00:27:12] iter = 01860, loss = 1.8745
2024-10-31 00:27:14: [2024-10-31 00:27:14] iter = 01870, loss = 2.2322
2024-10-31 00:27:17: [2024-10-31 00:27:17] iter = 01880, loss = 1.9631
2024-10-31 00:27:20: [2024-10-31 00:27:20] iter = 01890, loss = 2.4704
2024-10-31 00:27:23: [2024-10-31 00:27:23] iter = 01900, loss = 2.9069
2024-10-31 00:27:26: [2024-10-31 00:27:26] iter = 01910, loss = 1.8169
2024-10-31 00:27:30: [2024-10-31 00:27:30] iter = 01920, loss = 1.9972
2024-10-31 00:27:33: [2024-10-31 00:27:33] iter = 01930, loss = 1.9118
2024-10-31 00:27:35: [2024-10-31 00:27:35] iter = 01940, loss = 1.9947
2024-10-31 00:27:38: [2024-10-31 00:27:38] iter = 01950, loss = 2.2876
2024-10-31 00:27:41: [2024-10-31 00:27:41] iter = 01960, loss = 2.5988
2024-10-31 00:27:44: [2024-10-31 00:27:44] iter = 01970, loss = 2.4553
2024-10-31 00:27:47: [2024-10-31 00:27:47] iter = 01980, loss = 2.0881
2024-10-31 00:27:51: [2024-10-31 00:27:51] iter = 01990, loss = 2.1316
2024-10-31 00:27:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-31 00:27:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:27:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 74381}

[2024-10-30 22:52:28] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.011681 train acc = 1.0000, test acc = 0.6180, test_sen =0.5984, test_spe =0.9611, test_f1 =0.5928
[2024-10-30 22:52:52] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.009778 train acc = 1.0000, test acc = 0.6139, test_sen =0.5946, test_spe =0.9607, test_f1 =0.5834
[2024-10-30 23:03:02] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.020650 train acc = 1.0000, test acc = 0.6043, test_sen =0.5811, test_spe =0.9596, test_f1 =0.5756
[2024-10-30 23:03:27] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.038355 train acc = 1.0000, test acc = 0.6073, test_sen =0.5800, test_spe =0.9598, test_f1 =0.5725
[2024-10-30 23:03:51] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.079424 train acc = 0.9909, test acc = 0.6035, test_sen =0.5799, test_spe =0.9596, test_f1 =0.5711
[2024-10-30 23:04:18] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.012036 train acc = 1.0000, test acc = 0.6071, test_sen =0.5803, test_spe =0.9599, test_f1 =0.5708
[2024-10-30 23:04:39] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.036608 train acc = 1.0000, test acc = 0.6177, test_sen =0.5932, test_spe =0.9609, test_f1 =0.5868
[2024-10-30 23:15:09] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.076162 train acc = 0.9909, test acc = 0.6234, test_sen =0.6130, test_spe =0.9617, test_f1 =0.5985
[2024-10-30 23:15:32] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.010226 train acc = 1.0000, test acc = 0.6215, test_sen =0.5993, test_spe =0.9613, test_f1 =0.5905
[2024-10-30 23:15:54] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.010542 train acc = 1.0000, test acc = 0.6203, test_sen =0.6013, test_spe =0.9612, test_f1 =0.5922
[2024-10-30 23:16:16] Evaluate_03: epoch = 1000 train time = 21 s train loss = 0.008127 train acc = 1.0000, test acc = 0.6146, test_sen =0.5915, test_spe =0.9604, test_f1 =0.5855
[2024-10-30 23:16:40] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.075754 train acc = 0.9818, test acc = 0.6097, test_sen =0.5871, test_spe =0.9600, test_f1 =0.5804
[2024-10-30 23:26:48] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.021205 train acc = 1.0000, test acc = 0.6121, test_sen =0.5935, test_spe =0.9603, test_f1 =0.5849
[2024-10-30 23:27:12] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.033426 train acc = 1.0000, test acc = 0.5947, test_sen =0.5826, test_spe =0.9588, test_f1 =0.5700
[2024-10-30 23:27:31] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.017364 train acc = 1.0000, test acc = 0.5932, test_sen =0.5768, test_spe =0.9586, test_f1 =0.5654
[2024-10-30 23:27:55] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.095768 train acc = 0.9909, test acc = 0.6007, test_sen =0.5847, test_spe =0.9593, test_f1 =0.5727
[2024-10-30 23:28:16] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.006857 train acc = 1.0000, test acc = 0.5979, test_sen =0.5798, test_spe =0.9588, test_f1 =0.5695
[2024-10-30 23:38:34] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.012074 train acc = 1.0000, test acc = 0.6047, test_sen =0.5854, test_spe =0.9596, test_f1 =0.5724
[2024-10-30 23:38:59] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.043415 train acc = 1.0000, test acc = 0.6104, test_sen =0.5907, test_spe =0.9601, test_f1 =0.5810
[2024-10-30 23:39:24] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.011489 train acc = 1.0000, test acc = 0.6026, test_sen =0.5873, test_spe =0.9593, test_f1 =0.5773
[2024-10-30 23:39:51] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.008666 train acc = 1.0000, test acc = 0.6217, test_sen =0.6002, test_spe =0.9614, test_f1 =0.5923
[2024-10-30 23:40:16] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.012759 train acc = 1.0000, test acc = 0.6084, test_sen =0.5841, test_spe =0.9598, test_f1 =0.5787
[2024-10-30 23:50:58] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.027256 train acc = 1.0000, test acc = 0.6078, test_sen =0.5871, test_spe =0.9600, test_f1 =0.5783
[2024-10-30 23:51:24] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.070649 train acc = 1.0000, test acc = 0.6116, test_sen =0.5869, test_spe =0.9603, test_f1 =0.5800
[2024-10-30 23:51:47] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.010348 train acc = 1.0000, test acc = 0.6090, test_sen =0.5911, test_spe =0.9600, test_f1 =0.5815
[2024-10-30 23:52:12] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.035335 train acc = 1.0000, test acc = 0.6099, test_sen =0.5853, test_spe =0.9599, test_f1 =0.5775
[2024-10-30 23:52:36] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.022315 train acc = 1.0000, test acc = 0.6119, test_sen =0.5858, test_spe =0.9601, test_f1 =0.5766
[2024-10-31 00:02:43] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.008574 train acc = 1.0000, test acc = 0.6090, test_sen =0.5830, test_spe =0.9601, test_f1 =0.5757
[2024-10-31 00:03:07] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.011191 train acc = 1.0000, test acc = 0.5956, test_sen =0.5605, test_spe =0.9586, test_f1 =0.5509
[2024-10-31 00:03:30] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.010424 train acc = 1.0000, test acc = 0.6070, test_sen =0.5714, test_spe =0.9600, test_f1 =0.5622
[2024-10-31 00:03:54] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.067224 train acc = 1.0000, test acc = 0.6018, test_sen =0.5744, test_spe =0.9594, test_f1 =0.5653
[2024-10-31 00:04:16] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.008061 train acc = 1.0000, test acc = 0.6067, test_sen =0.5743, test_spe =0.9598, test_f1 =0.5640
[2024-10-31 00:14:22] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.011896 train acc = 1.0000, test acc = 0.6121, test_sen =0.5947, test_spe =0.9605, test_f1 =0.5835
[2024-10-31 00:14:48] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.036715 train acc = 1.0000, test acc = 0.6095, test_sen =0.5968, test_spe =0.9603, test_f1 =0.5838
[2024-10-31 00:15:13] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.054013 train acc = 0.9909, test acc = 0.6115, test_sen =0.5964, test_spe =0.9604, test_f1 =0.5828
[2024-10-31 00:15:37] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.061699 train acc = 0.9909, test acc = 0.6046, test_sen =0.5942, test_spe =0.9599, test_f1 =0.5792
[2024-10-31 00:16:06] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.008810 train acc = 1.0000, test acc = 0.5932, test_sen =0.5786, test_spe =0.9585, test_f1 =0.5649
[2024-10-31 00:16:33] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.003250 train acc = 1.0000, test acc = 0.4428, test_sen =0.4410, test_spe =0.9438, test_f1 =0.4292
[2024-10-31 00:16:55] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.012392 train acc = 1.0000, test acc = 0.4492, test_sen =0.4352, test_spe =0.9444, test_f1 =0.4220
[2024-10-31 00:17:20] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.044608 train acc = 0.9909, test acc = 0.4472, test_sen =0.4385, test_spe =0.9441, test_f1 =0.4279
[2024-10-31 00:17:41] Evaluate_03: epoch = 1000 train time = 21 s train loss = 0.010866 train acc = 1.0000, test acc = 0.4462, test_sen =0.4425, test_spe =0.9441, test_f1 =0.4266
[2024-10-31 00:18:04] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.004274 train acc = 1.0000, test acc = 0.4401, test_sen =0.4349, test_spe =0.9434, test_f1 =0.4243
[2024-10-31 00:28:19] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.011089 train acc = 1.0000, test acc = 0.6218, test_sen =0.5952, test_spe =0.9611, test_f1 =0.5915
[2024-10-31 00:28:42] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.029622 train acc = 1.0000, test acc = 0.6210, test_sen =0.5932, test_spe =0.9612, test_f1 =0.5871
[2024-10-31 00:29:06] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.011413 train acc = 1.0000, test acc = 0.6144, test_sen =0.5913, test_spe =0.9608, test_f1 =0.5835
[2024-10-31 00:29:31] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.010461 train acc = 1.0000, test acc = 0.6088, test_sen =0.5897, test_spe =0.9601, test_f1 =0.5791/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:29:53: Evaluate 5 random ConvNet, ACCmean = 0.6172 ACCstd = 0.0050
-------------------------
2024-10-31 00:29:53: Evaluate 5 random ConvNet, SENmean = 0.5932 SENstd = 0.0026
-------------------------
2024-10-31 00:29:53: Evaluate 5 random ConvNet, SPEmean = 0.9608 SPEstd = 0.0004
-------------------------
2024-10-31 00:29:53: Evaluate 5 random ConvNet, F!mean = 0.5859 F!std = 0.0042
-------------------------
2024-10-31 00:29:53: Evaluate 5 random ConvNet, mean = 0.6172 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:29:53: [2024-10-31 00:29:53] iter = 02000, loss = 3.3258
2024-10-31 00:29:56: [2024-10-31 00:29:56] iter = 02010, loss = 2.1735
2024-10-31 00:29:59: [2024-10-31 00:29:59] iter = 02020, loss = 1.9566
2024-10-31 00:30:02: [2024-10-31 00:30:02] iter = 02030, loss = 2.5052
2024-10-31 00:30:04: [2024-10-31 00:30:04] iter = 02040, loss = 3.9228
2024-10-31 00:30:07: [2024-10-31 00:30:07] iter = 02050, loss = 3.7039
2024-10-31 00:30:09: [2024-10-31 00:30:09] iter = 02060, loss = 2.9266
2024-10-31 00:30:11: [2024-10-31 00:30:11] iter = 02070, loss = 3.3074
2024-10-31 00:30:14: [2024-10-31 00:30:14] iter = 02080, loss = 2.2951
2024-10-31 00:30:17: [2024-10-31 00:30:17] iter = 02090, loss = 8.2174
2024-10-31 00:30:20: [2024-10-31 00:30:20] iter = 02100, loss = 2.2279
2024-10-31 00:30:24: [2024-10-31 00:30:24] iter = 02110, loss = 2.1142
2024-10-31 00:30:27: [2024-10-31 00:30:27] iter = 02120, loss = 1.7424
2024-10-31 00:30:30: [2024-10-31 00:30:30] iter = 02130, loss = 2.2845
2024-10-31 00:30:33: [2024-10-31 00:30:33] iter = 02140, loss = 3.0053
2024-10-31 00:30:36: [2024-10-31 00:30:36] iter = 02150, loss = 2.4388
2024-10-31 00:30:39: [2024-10-31 00:30:39] iter = 02160, loss = 5.0294
2024-10-31 00:30:42: [2024-10-31 00:30:42] iter = 02170, loss = 2.2558
2024-10-31 00:30:45: [2024-10-31 00:30:45] iter = 02180, loss = 2.0599
2024-10-31 00:30:48: [2024-10-31 00:30:48] iter = 02190, loss = 2.1783
2024-10-31 00:30:51: [2024-10-31 00:30:51] iter = 02200, loss = 2.3021
2024-10-31 00:30:55: [2024-10-31 00:30:55] iter = 02210, loss = 2.1570
2024-10-31 00:30:59: [2024-10-31 00:30:59] iter = 02220, loss = 2.6981
2024-10-31 00:31:01: [2024-10-31 00:31:01] iter = 02230, loss = 2.3591
2024-10-31 00:31:04: [2024-10-31 00:31:04] iter = 02240, loss = 1.9984
2024-10-31 00:31:07: [2024-10-31 00:31:07] iter = 02250, loss = 2.4332
2024-10-31 00:31:10: [2024-10-31 00:31:10] iter = 02260, loss = 2.1871
2024-10-31 00:31:13: [2024-10-31 00:31:13] iter = 02270, loss = 2.4721
2024-10-31 00:31:16: [2024-10-31 00:31:16] iter = 02280, loss = 2.1738
2024-10-31 00:31:19: [2024-10-31 00:31:19] iter = 02290, loss = 4.0696
2024-10-31 00:31:23: [2024-10-31 00:31:23] iter = 02300, loss = 2.6271
2024-10-31 00:31:26: [2024-10-31 00:31:26] iter = 02310, loss = 2.5878
2024-10-31 00:31:29: [2024-10-31 00:31:29] iter = 02320, loss = 2.2406
2024-10-31 00:31:32: [2024-10-31 00:31:32] iter = 02330, loss = 3.8108
2024-10-31 00:31:34: [2024-10-31 00:31:34] iter = 02340, loss = 2.3779
2024-10-31 00:31:37: [2024-10-31 00:31:37] iter = 02350, loss = 2.6421
2024-10-31 00:31:39: [2024-10-31 00:31:39] iter = 02360, loss = 2.0528
2024-10-31 00:31:41: [2024-10-31 00:31:41] iter = 02370, loss = 2.0147
2024-10-31 00:31:45: [2024-10-31 00:31:45] iter = 02380, loss = 2.4835
2024-10-31 00:31:48: [2024-10-31 00:31:48] iter = 02390, loss = 2.4937
2024-10-31 00:31:50: [2024-10-31 00:31:50] iter = 02400, loss = 3.9929
2024-10-31 00:31:52: [2024-10-31 00:31:52] iter = 02410, loss = 3.9398
2024-10-31 00:31:56: [2024-10-31 00:31:56] iter = 02420, loss = 2.5973
2024-10-31 00:31:58: [2024-10-31 00:31:58] iter = 02430, loss = 2.7441
2024-10-31 00:32:00: [2024-10-31 00:32:00] iter = 02440, loss = 2.9139
2024-10-31 00:32:03: [2024-10-31 00:32:03] iter = 02450, loss = 1.9671
2024-10-31 00:32:06: [2024-10-31 00:32:06] iter = 02460, loss = 2.8868
2024-10-31 00:32:09: [2024-10-31 00:32:09] iter = 02470, loss = 1.9846
2024-10-31 00:32:12: [2024-10-31 00:32:12] iter = 02480, loss = 2.2173
2024-10-31 00:32:15: [2024-10-31 00:32:15] iter = 02490, loss = 2.2190
2024-10-31 00:32:18: [2024-10-31 00:32:18] iter = 02500, loss = 2.3105
2024-10-31 00:32:20: [2024-10-31 00:32:20] iter = 02510, loss = 2.2648
2024-10-31 00:32:23: [2024-10-31 00:32:23] iter = 02520, loss = 2.0701
2024-10-31 00:32:26: [2024-10-31 00:32:26] iter = 02530, loss = 5.5823
2024-10-31 00:32:29: [2024-10-31 00:32:29] iter = 02540, loss = 2.0062
2024-10-31 00:32:33: [2024-10-31 00:32:33] iter = 02550, loss = 2.2602
2024-10-31 00:32:35: [2024-10-31 00:32:35] iter = 02560, loss = 2.2081
2024-10-31 00:32:39: [2024-10-31 00:32:39] iter = 02570, loss = 2.9818
2024-10-31 00:32:42: [2024-10-31 00:32:42] iter = 02580, loss = 2.6557
2024-10-31 00:32:45: [2024-10-31 00:32:45] iter = 02590, loss = 2.2227
2024-10-31 00:32:49: [2024-10-31 00:32:49] iter = 02600, loss = 1.9640
2024-10-31 00:32:51: [2024-10-31 00:32:51] iter = 02610, loss = 2.2341
2024-10-31 00:32:54: [2024-10-31 00:32:54] iter = 02620, loss = 1.9253
2024-10-31 00:32:56: [2024-10-31 00:32:56] iter = 02630, loss = 2.1190
2024-10-31 00:32:59: [2024-10-31 00:32:59] iter = 02640, loss = 2.5434
2024-10-31 00:33:02: [2024-10-31 00:33:02] iter = 02650, loss = 2.2599
2024-10-31 00:33:05: [2024-10-31 00:33:05] iter = 02660, loss = 2.4361
2024-10-31 00:33:07: [2024-10-31 00:33:07] iter = 02670, loss = 2.6733
2024-10-31 00:33:11: [2024-10-31 00:33:11] iter = 02680, loss = 2.6719
2024-10-31 00:33:14: [2024-10-31 00:33:14] iter = 02690, loss = 2.0392
2024-10-31 00:33:18: [2024-10-31 00:33:18] iter = 02700, loss = 2.6160
2024-10-31 00:33:21: [2024-10-31 00:33:21] iter = 02710, loss = 2.3674
2024-10-31 00:33:24: [2024-10-31 00:33:24] iter = 02720, loss = 2.0779
2024-10-31 00:33:27: [2024-10-31 00:33:27] iter = 02730, loss = 1.9660
2024-10-31 00:33:30: [2024-10-31 00:33:30] iter = 02740, loss = 2.2379
2024-10-31 00:33:33: [2024-10-31 00:33:33] iter = 02750, loss = 2.1129
2024-10-31 00:33:36: [2024-10-31 00:33:36] iter = 02760, loss = 2.2081
2024-10-31 00:33:40: [2024-10-31 00:33:40] iter = 02770, loss = 1.8718
2024-10-31 00:33:43: [2024-10-31 00:33:43] iter = 02780, loss = 2.1692
2024-10-31 00:33:45: [2024-10-31 00:33:45] iter = 02790, loss = 2.0185
2024-10-31 00:33:48: [2024-10-31 00:33:48] iter = 02800, loss = 1.9188
2024-10-31 00:33:51: [2024-10-31 00:33:51] iter = 02810, loss = 2.2137
2024-10-31 00:33:54: [2024-10-31 00:33:54] iter = 02820, loss = 2.1915
2024-10-31 00:33:56: [2024-10-31 00:33:56] iter = 02830, loss = 2.0995
2024-10-31 00:33:59: [2024-10-31 00:33:59] iter = 02840, loss = 2.1187
2024-10-31 00:34:01: [2024-10-31 00:34:01] iter = 02850, loss = 2.0336
2024-10-31 00:34:03: [2024-10-31 00:34:03] iter = 02860, loss = 4.0571
2024-10-31 00:34:06: [2024-10-31 00:34:06] iter = 02870, loss = 2.2523
2024-10-31 00:34:08: [2024-10-31 00:34:08] iter = 02880, loss = 2.2722
2024-10-31 00:34:10: [2024-10-31 00:34:10] iter = 02890, loss = 2.3473
2024-10-31 00:34:12: [2024-10-31 00:34:12] iter = 02900, loss = 2.1416
2024-10-31 00:34:15: [2024-10-31 00:34:15] iter = 02910, loss = 2.3226
2024-10-31 00:34:17: [2024-10-31 00:34:17] iter = 02920, loss = 1.8844
2024-10-31 00:34:20: [2024-10-31 00:34:20] iter = 02930, loss = 2.2523
2024-10-31 00:34:21: [2024-10-31 00:34:21] iter = 02940, loss = 2.1599
2024-10-31 00:34:24: [2024-10-31 00:34:24] iter = 02950, loss = 2.8639
2024-10-31 00:34:27: [2024-10-31 00:34:27] iter = 02960, loss = 2.4492
2024-10-31 00:34:30: [2024-10-31 00:34:30] iter = 02970, loss = 1.8568
2024-10-31 00:34:34: [2024-10-31 00:34:34] iter = 02980, loss = 1.9495
2024-10-31 00:34:37: [2024-10-31 00:34:37] iter = 02990, loss = 2.8950
2024-10-31 00:34:40: [2024-10-31 00:34:40] iter = 03000, loss = 2.2707
2024-10-31 00:34:43: [2024-10-31 00:34:43] iter = 03010, loss = 2.9438
2024-10-31 00:34:45: [2024-10-31 00:34:45] iter = 03020, loss = 2.1667
2024-10-31 00:34:48: [2024-10-31 00:34:48] iter = 03030, loss = 5.3736
2024-10-31 00:34:51: [2024-10-31 00:34:51] iter = 03040, loss = 2.7237
2024-10-31 00:34:53: [2024-10-31 00:34:53] iter = 03050, loss = 2.3749
2024-10-31 00:34:55: [2024-10-31 00:34:55] iter = 03060, loss = 2.0704
2024-10-31 00:34:58: [2024-10-31 00:34:58] iter = 03070, loss = 2.0983
2024-10-31 00:35:00: [2024-10-31 00:35:00] iter = 03080, loss = 2.3702
2024-10-31 00:35:03: [2024-10-31 00:35:03] iter = 03090, loss = 2.3764
2024-10-31 00:35:05: [2024-10-31 00:35:05] iter = 03100, loss = 2.0591
2024-10-31 00:35:09: [2024-10-31 00:35:09] iter = 03110, loss = 4.1252
2024-10-31 00:35:12: [2024-10-31 00:35:12] iter = 03120, loss = 2.0742
2024-10-31 00:35:14: [2024-10-31 00:35:14] iter = 03130, loss = 2.0493
2024-10-31 00:35:17: [2024-10-31 00:35:17] iter = 03140, loss = 2.0734
2024-10-31 00:35:20: [2024-10-31 00:35:20] iter = 03150, loss = 1.9984
2024-10-31 00:35:23: [2024-10-31 00:35:23] iter = 03160, loss = 2.5195
2024-10-31 00:35:26: [2024-10-31 00:35:26] iter = 03170, loss = 1.8754
2024-10-31 00:35:29: [2024-10-31 00:35:29] iter = 03180, loss = 1.8230
2024-10-31 00:35:32: [2024-10-31 00:35:32] iter = 03190, loss = 2.2980
2024-10-31 00:35:35: [2024-10-31 00:35:35] iter = 03200, loss = 1.8638
2024-10-31 00:35:39: [2024-10-31 00:35:39] iter = 03210, loss = 1.9359
2024-10-31 00:35:42: [2024-10-31 00:35:42] iter = 03220, loss = 2.4342
2024-10-31 00:35:45: [2024-10-31 00:35:45] iter = 03230, loss = 1.9703
2024-10-31 00:35:47: [2024-10-31 00:35:47] iter = 03240, loss = 3.8904
2024-10-31 00:35:50: [2024-10-31 00:35:50] iter = 03250, loss = 2.2136
2024-10-31 00:35:53: [2024-10-31 00:35:53] iter = 03260, loss = 2.0757
2024-10-31 00:35:56: [2024-10-31 00:35:56] iter = 03270, loss = 2.0732
2024-10-31 00:35:58: [2024-10-31 00:35:58] iter = 03280, loss = 2.0507
2024-10-31 00:36:01: [2024-10-31 00:36:01] iter = 03290, loss = 2.2293
2024-10-31 00:36:05: [2024-10-31 00:36:05] iter = 03300, loss = 2.0671
2024-10-31 00:36:07: [2024-10-31 00:36:07] iter = 03310, loss = 2.7978
2024-10-31 00:36:10: [2024-10-31 00:36:10] iter = 03320, loss = 3.6392
2024-10-31 00:36:14: [2024-10-31 00:36:14] iter = 03330, loss = 2.3034
2024-10-31 00:36:17: [2024-10-31 00:36:17] iter = 03340, loss = 1.8890
2024-10-31 00:36:20: [2024-10-31 00:36:20] iter = 03350, loss = 2.1011
2024-10-31 00:36:23: [2024-10-31 00:36:23] iter = 03360, loss = 3.0455
2024-10-31 00:36:26: [2024-10-31 00:36:26] iter = 03370, loss = 2.3007
2024-10-31 00:36:29: [2024-10-31 00:36:29] iter = 03380, loss = 1.8964
2024-10-31 00:36:31: [2024-10-31 00:36:31] iter = 03390, loss = 2.7333
2024-10-31 00:36:34: [2024-10-31 00:36:34] iter = 03400, loss = 2.0803
2024-10-31 00:36:37: [2024-10-31 00:36:37] iter = 03410, loss = 2.0204
2024-10-31 00:36:39: [2024-10-31 00:36:39] iter = 03420, loss = 2.6070
2024-10-31 00:36:41: [2024-10-31 00:36:41] iter = 03430, loss = 1.9034
2024-10-31 00:36:44: [2024-10-31 00:36:44] iter = 03440, loss = 1.8957
2024-10-31 00:36:47: [2024-10-31 00:36:47] iter = 03450, loss = 2.0200
2024-10-31 00:36:50: [2024-10-31 00:36:50] iter = 03460, loss = 2.6658
2024-10-31 00:36:53: [2024-10-31 00:36:53] iter = 03470, loss = 1.8063
2024-10-31 00:36:56: [2024-10-31 00:36:56] iter = 03480, loss = 1.9810
2024-10-31 00:36:59: [2024-10-31 00:36:59] iter = 03490, loss = 2.1888
2024-10-31 00:37:02: [2024-10-31 00:37:02] iter = 03500, loss = 2.9145
2024-10-31 00:37:04: [2024-10-31 00:37:04] iter = 03510, loss = 2.1224
2024-10-31 00:37:07: [2024-10-31 00:37:07] iter = 03520, loss = 2.0349
2024-10-31 00:37:10: [2024-10-31 00:37:10] iter = 03530, loss = 2.2504
2024-10-31 00:37:13: [2024-10-31 00:37:13] iter = 03540, loss = 2.1149
2024-10-31 00:37:16: [2024-10-31 00:37:16] iter = 03550, loss = 2.0537
2024-10-31 00:37:20: [2024-10-31 00:37:20] iter = 03560, loss = 2.2679
2024-10-31 00:37:22: [2024-10-31 00:37:22] iter = 03570, loss = 2.7279
2024-10-31 00:37:24: [2024-10-31 00:37:24] iter = 03580, loss = 1.9863
2024-10-31 00:37:27: [2024-10-31 00:37:27] iter = 03590, loss = 3.2388
2024-10-31 00:37:30: [2024-10-31 00:37:30] iter = 03600, loss = 2.1669
2024-10-31 00:37:32: [2024-10-31 00:37:32] iter = 03610, loss = 2.1589
2024-10-31 00:37:35: [2024-10-31 00:37:35] iter = 03620, loss = 2.0134
2024-10-31 00:37:37: [2024-10-31 00:37:37] iter = 03630, loss = 3.1574
2024-10-31 00:37:39: [2024-10-31 00:37:39] iter = 03640, loss = 2.2207
2024-10-31 00:37:42: [2024-10-31 00:37:42] iter = 03650, loss = 1.8450
2024-10-31 00:37:44: [2024-10-31 00:37:44] iter = 03660, loss = 2.3831
2024-10-31 00:37:47: [2024-10-31 00:37:47] iter = 03670, loss = 1.8999
2024-10-31 00:37:49: [2024-10-31 00:37:49] iter = 03680, loss = 2.2305
2024-10-31 00:37:52: [2024-10-31 00:37:52] iter = 03690, loss = 2.4321
2024-10-31 00:37:56: [2024-10-31 00:37:56] iter = 03700, loss = 1.9536
2024-10-31 00:37:59: [2024-10-31 00:37:59] iter = 03710, loss = 2.2742
2024-10-31 00:38:02: [2024-10-31 00:38:02] iter = 03720, loss = 2.0213
2024-10-31 00:38:05: [2024-10-31 00:38:05] iter = 03730, loss = 2.5957
2024-10-31 00:38:08: [2024-10-31 00:38:08] iter = 03740, loss = 3.6079
2024-10-31 00:38:11: [2024-10-31 00:38:11] iter = 03750, loss = 1.8856
2024-10-31 00:38:14: [2024-10-31 00:38:14] iter = 03760, loss = 1.9333
2024-10-31 00:38:16: [2024-10-31 00:38:16] iter = 03770, loss = 3.3204
2024-10-31 00:38:19: [2024-10-31 00:38:19] iter = 03780, loss = 2.2575
2024-10-31 00:38:22: [2024-10-31 00:38:22] iter = 03790, loss = 2.5126
2024-10-31 00:38:25: [2024-10-31 00:38:25] iter = 03800, loss = 2.3222
2024-10-31 00:38:28: [2024-10-31 00:38:28] iter = 03810, loss = 3.8744
2024-10-31 00:38:31: [2024-10-31 00:38:31] iter = 03820, loss = 2.2201
2024-10-31 00:38:35: [2024-10-31 00:38:35] iter = 03830, loss = 2.3846
2024-10-31 00:38:37: [2024-10-31 00:38:37] iter = 03840, loss = 2.1891
2024-10-31 00:38:41: [2024-10-31 00:38:41] iter = 03850, loss = 2.0343
2024-10-31 00:38:43: [2024-10-31 00:38:43] iter = 03860, loss = 2.7017
2024-10-31 00:38:45: [2024-10-31 00:38:45] iter = 03870, loss = 2.1803
2024-10-31 00:38:47: [2024-10-31 00:38:47] iter = 03880, loss = 2.4993
2024-10-31 00:38:49: [2024-10-31 00:38:49] iter = 03890, loss = 2.3976
2024-10-31 00:38:51: [2024-10-31 00:38:51] iter = 03900, loss = 1.9708
2024-10-31 00:38:54: [2024-10-31 00:38:54] iter = 03910, loss = 2.8780
2024-10-31 00:38:56: [2024-10-31 00:38:56] iter = 03920, loss = 2.1561
2024-10-31 00:38:59: [2024-10-31 00:38:59] iter = 03930, loss = 2.3398
2024-10-31 00:39:03: [2024-10-31 00:39:03] iter = 03940, loss = 2.4774
2024-10-31 00:39:06: [2024-10-31 00:39:06] iter = 03950, loss = 2.1770
2024-10-31 00:39:08: [2024-10-31 00:39:08] iter = 03960, loss = 2.1667
2024-10-31 00:39:11: [2024-10-31 00:39:11] iter = 03970, loss = 2.0530
2024-10-31 00:39:15: [2024-10-31 00:39:15] iter = 03980, loss = 3.5311
2024-10-31 00:39:18: [2024-10-31 00:39:18] iter = 03990, loss = 3.3701
2024-10-31 00:39:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-31 00:39:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:39:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60826}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:41:14: Evaluate 5 random ConvNet, ACCmean = 0.5681 ACCstd = 0.0051
-------------------------
2024-10-31 00:41:14: Evaluate 5 random ConvNet, SENmean = 0.5696 SENstd = 0.0036
-------------------------
2024-10-31 00:41:14: Evaluate 5 random ConvNet, SPEmean = 0.9560 SPEstd = 0.0005
-------------------------
2024-10-31 00:41:14: Evaluate 5 random ConvNet, F!mean = 0.5541 F!std = 0.0043
-------------------------
2024-10-31 00:41:14: Evaluate 5 random ConvNet, mean = 0.5681 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:41:15: [2024-10-31 00:41:15] iter = 04000, loss = 2.9062
2024-10-31 00:41:18: [2024-10-31 00:41:18] iter = 04010, loss = 2.0507
2024-10-31 00:41:21: [2024-10-31 00:41:21] iter = 04020, loss = 2.0239
2024-10-31 00:41:25: [2024-10-31 00:41:25] iter = 04030, loss = 2.3882
2024-10-31 00:41:29: [2024-10-31 00:41:29] iter = 04040, loss = 2.2621
2024-10-31 00:41:32: [2024-10-31 00:41:32] iter = 04050, loss = 2.5688
2024-10-31 00:41:34: [2024-10-31 00:41:34] iter = 04060, loss = 1.8064
2024-10-31 00:41:38: [2024-10-31 00:41:38] iter = 04070, loss = 2.4111
2024-10-31 00:41:40: [2024-10-31 00:41:40] iter = 04080, loss = 2.0006
2024-10-31 00:41:42: [2024-10-31 00:41:42] iter = 04090, loss = 3.2320
2024-10-31 00:41:45: [2024-10-31 00:41:45] iter = 04100, loss = 2.3454
2024-10-31 00:41:47: [2024-10-31 00:41:47] iter = 04110, loss = 2.1001
2024-10-31 00:41:49: [2024-10-31 00:41:49] iter = 04120, loss = 2.0825
2024-10-31 00:41:51: [2024-10-31 00:41:51] iter = 04130, loss = 2.4564
2024-10-31 00:41:54: [2024-10-31 00:41:54] iter = 04140, loss = 1.9847
2024-10-31 00:41:57: [2024-10-31 00:41:57] iter = 04150, loss = 2.9525
2024-10-31 00:41:59: [2024-10-31 00:41:59] iter = 04160, loss = 2.1340
2024-10-31 00:42:01: [2024-10-31 00:42:01] iter = 04170, loss = 2.2552
2024-10-31 00:42:03: [2024-10-31 00:42:03] iter = 04180, loss = 2.4479
2024-10-31 00:42:06: [2024-10-31 00:42:06] iter = 04190, loss = 2.1581
2024-10-31 00:42:09: [2024-10-31 00:42:09] iter = 04200, loss = 2.0915
2024-10-31 00:42:12: [2024-10-31 00:42:12] iter = 04210, loss = 2.3190
2024-10-31 00:42:15: [2024-10-31 00:42:15] iter = 04220, loss = 1.9918
2024-10-31 00:42:18: [2024-10-31 00:42:18] iter = 04230, loss = 2.1742
2024-10-31 00:42:20: [2024-10-31 00:42:20] iter = 04240, loss = 2.8328
2024-10-31 00:42:24: [2024-10-31 00:42:24] iter = 04250, loss = 2.0990
2024-10-31 00:42:27: [2024-10-31 00:42:27] iter = 04260, loss = 3.4333
2024-10-31 00:42:31: [2024-10-31 00:42:31] iter = 04270, loss = 5.9137
2024-10-31 00:42:34: [2024-10-31 00:42:34] iter = 04280, loss = 2.7586
2024-10-31 00:42:37: [2024-10-31 00:42:37] iter = 04290, loss = 3.3135
2024-10-31 00:42:40: [2024-10-31 00:42:40] iter = 04300, loss = 1.8097
2024-10-31 00:42:43: [2024-10-31 00:42:43] iter = 04310, loss = 2.6659
2024-10-31 00:42:46: [2024-10-31 00:42:46] iter = 04320, loss = 2.5112
2024-10-31 00:42:48: [2024-10-31 00:42:48] iter = 04330, loss = 1.8373
2024-10-31 00:42:51: [2024-10-31 00:42:51] iter = 04340, loss = 2.0357
2024-10-31 00:42:54: [2024-10-31 00:42:54] iter = 04350, loss = 2.4076
2024-10-31 00:42:57: [2024-10-31 00:42:57] iter = 04360, loss = 2.2619
2024-10-31 00:43:00: [2024-10-31 00:43:00] iter = 04370, loss = 2.0380
2024-10-31 00:43:04: [2024-10-31 00:43:04] iter = 04380, loss = 1.9597
2024-10-31 00:43:08: [2024-10-31 00:43:08] iter = 04390, loss = 1.7861
2024-10-31 00:43:12: [2024-10-31 00:43:12] iter = 04400, loss = 1.8315
2024-10-31 00:43:15: [2024-10-31 00:43:15] iter = 04410, loss = 2.0492
2024-10-31 00:43:19: [2024-10-31 00:43:19] iter = 04420, loss = 1.8226
2024-10-31 00:43:21: [2024-10-31 00:43:21] iter = 04430, loss = 2.3178
2024-10-31 00:43:24: [2024-10-31 00:43:24] iter = 04440, loss = 2.7435
2024-10-31 00:43:28: [2024-10-31 00:43:28] iter = 04450, loss = 1.8352
2024-10-31 00:43:31: [2024-10-31 00:43:31] iter = 04460, loss = 2.8407
2024-10-31 00:43:33: [2024-10-31 00:43:33] iter = 04470, loss = 2.0544
2024-10-31 00:43:35: [2024-10-31 00:43:35] iter = 04480, loss = 2.1083
2024-10-31 00:43:38: [2024-10-31 00:43:38] iter = 04490, loss = 1.8817
2024-10-31 00:43:41: [2024-10-31 00:43:41] iter = 04500, loss = 1.7535
2024-10-31 00:43:44: [2024-10-31 00:43:44] iter = 04510, loss = 1.9881
2024-10-31 00:43:47: [2024-10-31 00:43:47] iter = 04520, loss = 3.1304
2024-10-31 00:43:50: [2024-10-31 00:43:50] iter = 04530, loss = 2.1187
2024-10-31 00:43:53: [2024-10-31 00:43:53] iter = 04540, loss = 3.1405
2024-10-31 00:43:56: [2024-10-31 00:43:56] iter = 04550, loss = 2.4377
2024-10-31 00:43:58: [2024-10-31 00:43:58] iter = 04560, loss = 2.2777
2024-10-31 00:44:01: [2024-10-31 00:44:01] iter = 04570, loss = 3.1720
2024-10-31 00:44:03: [2024-10-31 00:44:03] iter = 04580, loss = 2.8651
2024-10-31 00:44:06: [2024-10-31 00:44:06] iter = 04590, loss = 2.1273
2024-10-31 00:44:09: [2024-10-31 00:44:09] iter = 04600, loss = 2.9983
2024-10-31 00:44:11: [2024-10-31 00:44:11] iter = 04610, loss = 2.2578
2024-10-31 00:44:15: [2024-10-31 00:44:15] iter = 04620, loss = 1.9200
2024-10-31 00:44:19: [2024-10-31 00:44:19] iter = 04630, loss = 2.4952
2024-10-31 00:44:22: [2024-10-31 00:44:22] iter = 04640, loss = 2.3275
2024-10-31 00:44:25: [2024-10-31 00:44:25] iter = 04650, loss = 2.2051
2024-10-31 00:44:28: [2024-10-31 00:44:28] iter = 04660, loss = 2.4197
2024-10-31 00:44:30: [2024-10-31 00:44:30] iter = 04670, loss = 2.8725
2024-10-31 00:44:33: [2024-10-31 00:44:33] iter = 04680, loss = 4.7333
2024-10-31 00:44:37: [2024-10-31 00:44:37] iter = 04690, loss = 2.0321
2024-10-31 00:44:40: [2024-10-31 00:44:40] iter = 04700, loss = 2.6057
2024-10-31 00:44:43: [2024-10-31 00:44:43] iter = 04710, loss = 2.0623
2024-10-31 00:44:46: [2024-10-31 00:44:46] iter = 04720, loss = 2.3386
2024-10-31 00:44:49: [2024-10-31 00:44:49] iter = 04730, loss = 2.1052
2024-10-31 00:44:53: [2024-10-31 00:44:53] iter = 04740, loss = 2.4327
2024-10-31 00:44:56: [2024-10-31 00:44:56] iter = 04750, loss = 1.8970
2024-10-31 00:44:58: [2024-10-31 00:44:58] iter = 04760, loss = 2.3515
2024-10-31 00:45:01: [2024-10-31 00:45:01] iter = 04770, loss = 3.1842
2024-10-31 00:45:04: [2024-10-31 00:45:04] iter = 04780, loss = 1.8277
2024-10-31 00:45:06: [2024-10-31 00:45:06] iter = 04790, loss = 1.8067
2024-10-31 00:45:10: [2024-10-31 00:45:10] iter = 04800, loss = 2.1421
2024-10-31 00:45:13: [2024-10-31 00:45:13] iter = 04810, loss = 4.1572
2024-10-31 00:45:15: [2024-10-31 00:45:15] iter = 04820, loss = 2.1826
2024-10-31 00:45:18: [2024-10-31 00:45:18] iter = 04830, loss = 2.5290
2024-10-31 00:45:22: [2024-10-31 00:45:22] iter = 04840, loss = 2.3212
2024-10-31 00:45:25: [2024-10-31 00:45:25] iter = 04850, loss = 4.0488
2024-10-31 00:45:28: [2024-10-31 00:45:28] iter = 04860, loss = 2.0932
2024-10-31 00:45:32: [2024-10-31 00:45:32] iter = 04870, loss = 2.1108
2024-10-31 00:45:35: [2024-10-31 00:45:35] iter = 04880, loss = 3.2252
2024-10-31 00:45:38: [2024-10-31 00:45:38] iter = 04890, loss = 2.0064
2024-10-31 00:45:42: [2024-10-31 00:45:42] iter = 04900, loss = 2.2382
2024-10-31 00:45:44: [2024-10-31 00:45:44] iter = 04910, loss = 2.5383
2024-10-31 00:45:47: [2024-10-31 00:45:47] iter = 04920, loss = 1.9656
2024-10-31 00:45:49: [2024-10-31 00:45:49] iter = 04930, loss = 2.0631
2024-10-31 00:45:51: [2024-10-31 00:45:51] iter = 04940, loss = 2.0604
2024-10-31 00:45:54: [2024-10-31 00:45:54] iter = 04950, loss = 2.0531
2024-10-31 00:45:58: [2024-10-31 00:45:58] iter = 04960, loss = 3.7075
2024-10-31 00:46:01: [2024-10-31 00:46:01] iter = 04970, loss = 2.0011
2024-10-31 00:46:04: [2024-10-31 00:46:04] iter = 04980, loss = 2.3387
2024-10-31 00:46:07: [2024-10-31 00:46:07] iter = 04990, loss = 1.8831
2024-10-31 00:46:10: [2024-10-31 00:46:10] iter = 05000, loss = 2.0384
2024-10-31 00:46:12: [2024-10-31 00:46:12] iter = 05010, loss = 2.2252
2024-10-31 00:46:16: [2024-10-31 00:46:16] iter = 05020, loss = 2.3401
2024-10-31 00:46:19: [2024-10-31 00:46:19] iter = 05030, loss = 2.1410
2024-10-31 00:46:22: [2024-10-31 00:46:22] iter = 05040, loss = 1.9034
2024-10-31 00:46:26: [2024-10-31 00:46:26] iter = 05050, loss = 2.0014
2024-10-31 00:46:29: [2024-10-31 00:46:29] iter = 05060, loss = 2.1102
2024-10-31 00:46:32: [2024-10-31 00:46:32] iter = 05070, loss = 2.4791
2024-10-31 00:46:36: [2024-10-31 00:46:36] iter = 05080, loss = 2.6955
2024-10-31 00:46:39: [2024-10-31 00:46:39] iter = 05090, loss = 2.2689
2024-10-31 00:46:41: [2024-10-31 00:46:41] iter = 05100, loss = 2.2595
2024-10-31 00:46:44: [2024-10-31 00:46:44] iter = 05110, loss = 2.0734
2024-10-31 00:46:47: [2024-10-31 00:46:47] iter = 05120, loss = 2.8022
2024-10-31 00:46:51: [2024-10-31 00:46:51] iter = 05130, loss = 2.8717
2024-10-31 00:46:55: [2024-10-31 00:46:55] iter = 05140, loss = 2.0983
2024-10-31 00:46:58: [2024-10-31 00:46:58] iter = 05150, loss = 2.9715
2024-10-31 00:47:01: [2024-10-31 00:47:01] iter = 05160, loss = 2.1406
2024-10-31 00:47:04: [2024-10-31 00:47:04] iter = 05170, loss = 2.0002
2024-10-31 00:47:06: [2024-10-31 00:47:06] iter = 05180, loss = 2.8606
2024-10-31 00:47:09: [2024-10-31 00:47:09] iter = 05190, loss = 2.6831
2024-10-31 00:47:12: [2024-10-31 00:47:12] iter = 05200, loss = 2.3021
2024-10-31 00:47:15: [2024-10-31 00:47:15] iter = 05210, loss = 2.2603
2024-10-31 00:47:18: [2024-10-31 00:47:18] iter = 05220, loss = 2.5400
2024-10-31 00:47:21: [2024-10-31 00:47:21] iter = 05230, loss = 2.2932
2024-10-31 00:47:24: [2024-10-31 00:47:24] iter = 05240, loss = 1.9470
2024-10-31 00:47:26: [2024-10-31 00:47:26] iter = 05250, loss = 2.4533
2024-10-31 00:47:28: [2024-10-31 00:47:28] iter = 05260, loss = 2.8163
2024-10-31 00:47:30: [2024-10-31 00:47:30] iter = 05270, loss = 1.9220
2024-10-31 00:47:33: [2024-10-31 00:47:33] iter = 05280, loss = 2.1608
2024-10-31 00:47:36: [2024-10-31 00:47:36] iter = 05290, loss = 2.4581
2024-10-31 00:47:39: [2024-10-31 00:47:39] iter = 05300, loss = 2.4095
2024-10-31 00:47:43: [2024-10-31 00:47:43] iter = 05310, loss = 1.9115
2024-10-31 00:47:45: [2024-10-31 00:47:45] iter = 05320, loss = 2.1143
2024-10-31 00:47:48: [2024-10-31 00:47:48] iter = 05330, loss = 2.3345
2024-10-31 00:47:50: [2024-10-31 00:47:50] iter = 05340, loss = 2.3488
2024-10-31 00:47:53: [2024-10-31 00:47:53] iter = 05350, loss = 1.9082
2024-10-31 00:47:57: [2024-10-31 00:47:57] iter = 05360, loss = 1.7648
2024-10-31 00:48:00: [2024-10-31 00:48:00] iter = 05370, loss = 2.9647
2024-10-31 00:48:03: [2024-10-31 00:48:03] iter = 05380, loss = 2.7731
2024-10-31 00:48:05: [2024-10-31 00:48:05] iter = 05390, loss = 2.6093
2024-10-31 00:48:08: [2024-10-31 00:48:08] iter = 05400, loss = 2.2823
2024-10-31 00:48:10: [2024-10-31 00:48:10] iter = 05410, loss = 3.4616
2024-10-31 00:48:12: [2024-10-31 00:48:12] iter = 05420, loss = 2.3054
2024-10-31 00:48:15: [2024-10-31 00:48:15] iter = 05430, loss = 3.6701
2024-10-31 00:48:19: [2024-10-31 00:48:19] iter = 05440, loss = 2.8506
2024-10-31 00:48:21: [2024-10-31 00:48:21] iter = 05450, loss = 2.4158
2024-10-31 00:48:24: [2024-10-31 00:48:24] iter = 05460, loss = 2.1587
2024-10-31 00:48:27: [2024-10-31 00:48:27] iter = 05470, loss = 1.8696
2024-10-31 00:48:30: [2024-10-31 00:48:30] iter = 05480, loss = 2.5121
2024-10-31 00:48:33: [2024-10-31 00:48:33] iter = 05490, loss = 2.0285
2024-10-31 00:48:37: [2024-10-31 00:48:37] iter = 05500, loss = 3.7872
2024-10-31 00:48:41: [2024-10-31 00:48:41] iter = 05510, loss = 2.9832
2024-10-31 00:48:44: [2024-10-31 00:48:44] iter = 05520, loss = 2.1631
2024-10-31 00:48:47: [2024-10-31 00:48:47] iter = 05530, loss = 2.2204
2024-10-31 00:48:50: [2024-10-31 00:48:50] iter = 05540, loss = 2.4515
2024-10-31 00:48:54: [2024-10-31 00:48:54] iter = 05550, loss = 3.6454
2024-10-31 00:48:57: [2024-10-31 00:48:57] iter = 05560, loss = 2.3572
2024-10-31 00:49:01: [2024-10-31 00:49:01] iter = 05570, loss = 1.9814
2024-10-31 00:49:04: [2024-10-31 00:49:04] iter = 05580, loss = 1.9194
2024-10-31 00:49:08: [2024-10-31 00:49:08] iter = 05590, loss = 2.6582
2024-10-31 00:49:11: [2024-10-31 00:49:11] iter = 05600, loss = 2.7142
2024-10-31 00:49:14: [2024-10-31 00:49:14] iter = 05610, loss = 2.7847
2024-10-31 00:49:17: [2024-10-31 00:49:17] iter = 05620, loss = 1.9264
2024-10-31 00:49:19: [2024-10-31 00:49:19] iter = 05630, loss = 2.0976
2024-10-31 00:49:22: [2024-10-31 00:49:22] iter = 05640, loss = 2.6020
2024-10-31 00:49:25: [2024-10-31 00:49:25] iter = 05650, loss = 1.9914
2024-10-31 00:49:28: [2024-10-31 00:49:28] iter = 05660, loss = 2.1910
2024-10-31 00:49:31: [2024-10-31 00:49:31] iter = 05670, loss = 4.4345
2024-10-31 00:49:35: [2024-10-31 00:49:35] iter = 05680, loss = 2.4511
2024-10-31 00:49:39: [2024-10-31 00:49:39] iter = 05690, loss = 3.6453
2024-10-31 00:49:41: [2024-10-31 00:49:41] iter = 05700, loss = 2.3432
2024-10-31 00:49:45: [2024-10-31 00:49:45] iter = 05710, loss = 2.1096
2024-10-31 00:49:48: [2024-10-31 00:49:48] iter = 05720, loss = 2.2402
2024-10-31 00:49:52: [2024-10-31 00:49:52] iter = 05730, loss = 2.5259
2024-10-31 00:49:55: [2024-10-31 00:49:55] iter = 05740, loss = 2.0720
2024-10-31 00:49:58: [2024-10-31 00:49:58] iter = 05750, loss = 2.2459
2024-10-31 00:50:00: [2024-10-31 00:50:00] iter = 05760, loss = 2.3169
2024-10-31 00:50:03: [2024-10-31 00:50:03] iter = 05770, loss = 2.0727
2024-10-31 00:50:06: [2024-10-31 00:50:06] iter = 05780, loss = 4.2059
2024-10-31 00:50:09: [2024-10-31 00:50:09] iter = 05790, loss = 4.8913
2024-10-31 00:50:12: [2024-10-31 00:50:12] iter = 05800, loss = 1.7792
2024-10-31 00:50:16: [2024-10-31 00:50:16] iter = 05810, loss = 2.1213
2024-10-31 00:50:19: [2024-10-31 00:50:19] iter = 05820, loss = 2.3887
2024-10-31 00:50:23: [2024-10-31 00:50:23] iter = 05830, loss = 3.8116
2024-10-31 00:50:26: [2024-10-31 00:50:26] iter = 05840, loss = 2.0126
2024-10-31 00:50:29: [2024-10-31 00:50:29] iter = 05850, loss = 2.6472
2024-10-31 00:50:31: [2024-10-31 00:50:31] iter = 05860, loss = 1.9222
2024-10-31 00:50:34: [2024-10-31 00:50:34] iter = 05870, loss = 2.3843
2024-10-31 00:50:37: [2024-10-31 00:50:37] iter = 05880, loss = 2.3584
2024-10-31 00:50:41: [2024-10-31 00:50:41] iter = 05890, loss = 2.7054
2024-10-31 00:50:44: [2024-10-31 00:50:43] iter = 05900, loss = 2.8641
2024-10-31 00:50:47: [2024-10-31 00:50:47] iter = 05910, loss = 2.7594
2024-10-31 00:50:50: [2024-10-31 00:50:50] iter = 05920, loss = 2.6744
2024-10-31 00:50:53: [2024-10-31 00:50:53] iter = 05930, loss = 2.2802
2024-10-31 00:50:56: [2024-10-31 00:50:56] iter = 05940, loss = 2.3492
2024-10-31 00:50:59: [2024-10-31 00:50:59] iter = 05950, loss = 2.2060
2024-10-31 00:51:02: [2024-10-31 00:51:02] iter = 05960, loss = 3.1398
2024-10-31 00:51:05: [2024-10-31 00:51:05] iter = 05970, loss = 2.5468
2024-10-31 00:51:08: [2024-10-31 00:51:08] iter = 05980, loss = 1.7821
2024-10-31 00:51:12: [2024-10-31 00:51:12] iter = 05990, loss = 2.1444
2024-10-31 00:51:15: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-31 00:51:15: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:51:15: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 75456}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:53:21: Evaluate 5 random ConvNet, ACCmean = 0.6119 ACCstd = 0.0062
-------------------------
2024-10-31 00:53:21: Evaluate 5 random ConvNet, SENmean = 0.5971 SENstd = 0.0036
-------------------------
2024-10-31 00:53:21: Evaluate 5 random ConvNet, SPEmean = 0.9605 SPEstd = 0.0006
-------------------------
2024-10-31 00:53:21: Evaluate 5 random ConvNet, F!mean = 0.5858 F!std = 0.0043
-------------------------
2024-10-31 00:53:21: Evaluate 5 random ConvNet, mean = 0.6119 std = 0.0062
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:53:21: [2024-10-31 00:53:21] iter = 06000, loss = 2.8330
2024-10-31 00:53:25: [2024-10-31 00:53:25] iter = 06010, loss = 1.8178
2024-10-31 00:53:29: [2024-10-31 00:53:29] iter = 06020, loss = 2.2261
2024-10-31 00:53:32: [2024-10-31 00:53:32] iter = 06030, loss = 3.7661
2024-10-31 00:53:35: [2024-10-31 00:53:35] iter = 06040, loss = 1.6794
2024-10-31 00:53:38: [2024-10-31 00:53:38] iter = 06050, loss = 2.0190
2024-10-31 00:53:42: [2024-10-31 00:53:42] iter = 06060, loss = 1.8958
2024-10-31 00:53:44: [2024-10-31 00:53:44] iter = 06070, loss = 1.7508
2024-10-31 00:53:47: [2024-10-31 00:53:47] iter = 06080, loss = 2.1638
2024-10-31 00:53:48: [2024-10-31 00:53:48] iter = 06090, loss = 2.0365
2024-10-31 00:53:51: [2024-10-31 00:53:51] iter = 06100, loss = 2.3068
2024-10-31 00:53:53: [2024-10-31 00:53:53] iter = 06110, loss = 2.3980
2024-10-31 00:53:56: [2024-10-31 00:53:56] iter = 06120, loss = 1.9782
2024-10-31 00:53:59: [2024-10-31 00:53:59] iter = 06130, loss = 2.4406
2024-10-31 00:54:02: [2024-10-31 00:54:02] iter = 06140, loss = 4.3461
2024-10-31 00:54:05: [2024-10-31 00:54:05] iter = 06150, loss = 1.9470
2024-10-31 00:54:07: [2024-10-31 00:54:07] iter = 06160, loss = 2.0766
2024-10-31 00:54:10: [2024-10-31 00:54:10] iter = 06170, loss = 2.1772
2024-10-31 00:54:14: [2024-10-31 00:54:14] iter = 06180, loss = 3.2424
2024-10-31 00:54:17: [2024-10-31 00:54:17] iter = 06190, loss = 1.9144
2024-10-31 00:54:20: [2024-10-31 00:54:20] iter = 06200, loss = 7.2732
2024-10-31 00:54:23: [2024-10-31 00:54:23] iter = 06210, loss = 2.0198
2024-10-31 00:54:27: [2024-10-31 00:54:27] iter = 06220, loss = 2.0549
2024-10-31 00:54:30: [2024-10-31 00:54:30] iter = 06230, loss = 2.1045
2024-10-31 00:54:34: [2024-10-31 00:54:34] iter = 06240, loss = 2.1942
2024-10-31 00:54:36: [2024-10-31 00:54:36] iter = 06250, loss = 2.6049
2024-10-31 00:54:39: [2024-10-31 00:54:39] iter = 06260, loss = 2.4395
2024-10-31 00:54:43: [2024-10-31 00:54:43] iter = 06270, loss = 2.1580
2024-10-31 00:54:46: [2024-10-31 00:54:46] iter = 06280, loss = 2.5018
2024-10-31 00:54:49: [2024-10-31 00:54:49] iter = 06290, loss = 2.2444
2024-10-31 00:54:53: [2024-10-31 00:54:53] iter = 06300, loss = 1.9472
2024-10-31 00:54:56: [2024-10-31 00:54:56] iter = 06310, loss = 2.0875
2024-10-31 00:54:59: [2024-10-31 00:54:59] iter = 06320, loss = 2.0693
2024-10-31 00:55:02: [2024-10-31 00:55:02] iter = 06330, loss = 2.1224
2024-10-31 00:55:06: [2024-10-31 00:55:06] iter = 06340, loss = 2.0265
2024-10-31 00:55:09: [2024-10-31 00:55:09] iter = 06350, loss = 3.7775
2024-10-31 00:55:12: [2024-10-31 00:55:12] iter = 06360, loss = 2.1262
2024-10-31 00:55:15: [2024-10-31 00:55:15] iter = 06370, loss = 2.2797
2024-10-31 00:55:17: [2024-10-31 00:55:17] iter = 06380, loss = 2.1753
2024-10-31 00:55:20: [2024-10-31 00:55:20] iter = 06390, loss = 4.8375
2024-10-31 00:55:23: [2024-10-31 00:55:23] iter = 06400, loss = 2.2965
2024-10-31 00:55:26: [2024-10-31 00:55:26] iter = 06410, loss = 2.2588
2024-10-31 00:55:29: [2024-10-31 00:55:29] iter = 06420, loss = 2.0799
2024-10-31 00:55:32: [2024-10-31 00:55:32] iter = 06430, loss = 2.0645
2024-10-31 00:55:35: [2024-10-31 00:55:35] iter = 06440, loss = 2.3646
2024-10-31 00:55:39: [2024-10-31 00:55:39] iter = 06450, loss = 5.2225
2024-10-31 00:55:42: [2024-10-31 00:55:42] iter = 06460, loss = 2.8713
2024-10-31 00:55:46: [2024-10-31 00:55:46] iter = 06470, loss = 3.1804
2024-10-31 00:55:49: [2024-10-31 00:55:49] iter = 06480, loss = 2.1430
2024-10-31 00:55:52: [2024-10-31 00:55:52] iter = 06490, loss = 1.9760
2024-10-31 00:55:55: [2024-10-31 00:55:55] iter = 06500, loss = 2.4404
2024-10-31 00:55:57: [2024-10-31 00:55:57] iter = 06510, loss = 2.1125
2024-10-31 00:56:00: [2024-10-31 00:56:00] iter = 06520, loss = 3.8649
2024-10-31 00:56:02: [2024-10-31 00:56:02] iter = 06530, loss = 2.2014
2024-10-31 00:56:05: [2024-10-31 00:56:05] iter = 06540, loss = 4.1812
2024-10-31 00:56:08: [2024-10-31 00:56:08] iter = 06550, loss = 1.7073
2024-10-31 00:56:11: [2024-10-31 00:56:11] iter = 06560, loss = 1.9053
2024-10-31 00:56:14: [2024-10-31 00:56:14] iter = 06570, loss = 2.1034
2024-10-31 00:56:17: [2024-10-31 00:56:17] iter = 06580, loss = 2.5938
2024-10-31 00:56:20: [2024-10-31 00:56:20] iter = 06590, loss = 2.0314
2024-10-31 00:56:24: [2024-10-31 00:56:24] iter = 06600, loss = 3.3918
2024-10-31 00:56:28: [2024-10-31 00:56:28] iter = 06610, loss = 1.9915
2024-10-31 00:56:31: [2024-10-31 00:56:31] iter = 06620, loss = 2.3534
2024-10-31 00:56:35: [2024-10-31 00:56:35] iter = 06630, loss = 2.7832
2024-10-31 00:56:38: [2024-10-31 00:56:38] iter = 06640, loss = 2.1088
2024-10-31 00:56:41: [2024-10-31 00:56:41] iter = 06650, loss = 2.0546
2024-10-31 00:56:44: [2024-10-31 00:56:44] iter = 06660, loss = 1.8052
2024-10-31 00:56:48: [2024-10-31 00:56:48] iter = 06670, loss = 2.6651
2024-10-31 00:56:51: [2024-10-31 00:56:51] iter = 06680, loss = 2.0885
2024-10-31 00:56:54: [2024-10-31 00:56:54] iter = 06690, loss = 3.2311
2024-10-31 00:56:57: [2024-10-31 00:56:57] iter = 06700, loss = 2.3228
2024-10-31 00:56:59: [2024-10-31 00:56:59] iter = 06710, loss = 2.6571
2024-10-31 00:57:03: [2024-10-31 00:57:03] iter = 06720, loss = 1.9017
2024-10-31 00:57:06: [2024-10-31 00:57:06] iter = 06730, loss = 2.6367
2024-10-31 00:57:08: [2024-10-31 00:57:08] iter = 06740, loss = 2.3194
2024-10-31 00:57:11: [2024-10-31 00:57:11] iter = 06750, loss = 2.0972
2024-10-31 00:57:14: [2024-10-31 00:57:14] iter = 06760, loss = 4.2215
2024-10-31 00:57:18: [2024-10-31 00:57:18] iter = 06770, loss = 4.0706
2024-10-31 00:57:20: [2024-10-31 00:57:20] iter = 06780, loss = 2.6529
2024-10-31 00:57:23: [2024-10-31 00:57:23] iter = 06790, loss = 2.5023
2024-10-31 00:57:25: [2024-10-31 00:57:25] iter = 06800, loss = 1.9812
2024-10-31 00:57:28: [2024-10-31 00:57:28] iter = 06810, loss = 2.7926
2024-10-31 00:57:32: [2024-10-31 00:57:32] iter = 06820, loss = 2.0658
2024-10-31 00:57:34: [2024-10-31 00:57:34] iter = 06830, loss = 2.1445
2024-10-31 00:57:37: [2024-10-31 00:57:37] iter = 06840, loss = 1.9399
2024-10-31 00:57:41: [2024-10-31 00:57:41] iter = 06850, loss = 1.8203
2024-10-31 00:57:44: [2024-10-31 00:57:44] iter = 06860, loss = 2.1486
2024-10-31 00:57:47: [2024-10-31 00:57:47] iter = 06870, loss = 1.9419
2024-10-31 00:57:51: [2024-10-31 00:57:51] iter = 06880, loss = 2.9364
2024-10-31 00:57:54: [2024-10-31 00:57:54] iter = 06890, loss = 2.5356
2024-10-31 00:57:57: [2024-10-31 00:57:57] iter = 06900, loss = 2.3471
2024-10-31 00:58:00: [2024-10-31 00:58:00] iter = 06910, loss = 2.5728
2024-10-31 00:58:04: [2024-10-31 00:58:04] iter = 06920, loss = 2.0463
2024-10-31 00:58:07: [2024-10-31 00:58:07] iter = 06930, loss = 2.5307
2024-10-31 00:58:10: [2024-10-31 00:58:10] iter = 06940, loss = 2.0535
2024-10-31 00:58:13: [2024-10-31 00:58:13] iter = 06950, loss = 3.6785
2024-10-31 00:58:16: [2024-10-31 00:58:16] iter = 06960, loss = 3.0182
2024-10-31 00:58:19: [2024-10-31 00:58:19] iter = 06970, loss = 1.9342
2024-10-31 00:58:22: [2024-10-31 00:58:22] iter = 06980, loss = 2.8612
2024-10-31 00:58:24: [2024-10-31 00:58:24] iter = 06990, loss = 3.4492
2024-10-31 00:58:27: [2024-10-31 00:58:27] iter = 07000, loss = 2.2419
2024-10-31 00:58:30: [2024-10-31 00:58:30] iter = 07010, loss = 3.1018
2024-10-31 00:58:33: [2024-10-31 00:58:33] iter = 07020, loss = 2.3314
2024-10-31 00:58:36: [2024-10-31 00:58:36] iter = 07030, loss = 4.4293
2024-10-31 00:58:39: [2024-10-31 00:58:39] iter = 07040, loss = 2.1837
2024-10-31 00:58:42: [2024-10-31 00:58:42] iter = 07050, loss = 2.6152
2024-10-31 00:58:44: [2024-10-31 00:58:44] iter = 07060, loss = 1.8813
2024-10-31 00:58:47: [2024-10-31 00:58:47] iter = 07070, loss = 2.5531
2024-10-31 00:58:50: [2024-10-31 00:58:50] iter = 07080, loss = 1.8919
2024-10-31 00:58:52: [2024-10-31 00:58:52] iter = 07090, loss = 2.0317
2024-10-31 00:58:55: [2024-10-31 00:58:55] iter = 07100, loss = 2.3860
2024-10-31 00:58:59: [2024-10-31 00:58:59] iter = 07110, loss = 2.6162
2024-10-31 00:59:02: [2024-10-31 00:59:02] iter = 07120, loss = 3.3924
2024-10-31 00:59:05: [2024-10-31 00:59:05] iter = 07130, loss = 2.3494
2024-10-31 00:59:08: [2024-10-31 00:59:08] iter = 07140, loss = 3.1792
2024-10-31 00:59:11: [2024-10-31 00:59:11] iter = 07150, loss = 2.3794
2024-10-31 00:59:14: [2024-10-31 00:59:14] iter = 07160, loss = 2.8376
2024-10-31 00:59:16: [2024-10-31 00:59:16] iter = 07170, loss = 2.8172
2024-10-31 00:59:19: [2024-10-31 00:59:19] iter = 07180, loss = 2.1147
2024-10-31 00:59:22: [2024-10-31 00:59:22] iter = 07190, loss = 3.0996
2024-10-31 00:59:25: [2024-10-31 00:59:25] iter = 07200, loss = 2.1642
2024-10-31 00:59:28: [2024-10-31 00:59:28] iter = 07210, loss = 2.0604
2024-10-31 00:59:32: [2024-10-31 00:59:32] iter = 07220, loss = 2.2844
2024-10-31 00:59:36: [2024-10-31 00:59:36] iter = 07230, loss = 4.0851
2024-10-31 00:59:39: [2024-10-31 00:59:39] iter = 07240, loss = 2.8027
2024-10-31 00:59:42: [2024-10-31 00:59:42] iter = 07250, loss = 2.1603
2024-10-31 00:59:44: [2024-10-31 00:59:44] iter = 07260, loss = 2.2818
2024-10-31 00:59:48: [2024-10-31 00:59:48] iter = 07270, loss = 2.2182
2024-10-31 00:59:52: [2024-10-31 00:59:52] iter = 07280, loss = 2.1295
2024-10-31 00:59:55: [2024-10-31 00:59:55] iter = 07290, loss = 2.2068
2024-10-31 00:59:59: [2024-10-31 00:59:59] iter = 07300, loss = 1.8413
2024-10-31 01:00:02: [2024-10-31 01:00:02] iter = 07310, loss = 2.8085
2024-10-31 01:00:05: [2024-10-31 01:00:05] iter = 07320, loss = 2.9829
2024-10-31 01:00:08: [2024-10-31 01:00:08] iter = 07330, loss = 2.0841
2024-10-31 01:00:11: [2024-10-31 01:00:11] iter = 07340, loss = 2.0461
2024-10-31 01:00:15: [2024-10-31 01:00:15] iter = 07350, loss = 2.1551
2024-10-31 01:00:18: [2024-10-31 01:00:18] iter = 07360, loss = 2.4059
2024-10-31 01:00:21: [2024-10-31 01:00:21] iter = 07370, loss = 1.9692
2024-10-31 01:00:24: [2024-10-31 01:00:24] iter = 07380, loss = 2.7330
2024-10-31 01:00:26: [2024-10-31 01:00:26] iter = 07390, loss = 2.1054
2024-10-31 01:00:29: [2024-10-31 01:00:29] iter = 07400, loss = 2.0041
2024-10-31 01:00:32: [2024-10-31 01:00:32] iter = 07410, loss = 2.5789
2024-10-31 01:00:34: [2024-10-31 01:00:34] iter = 07420, loss = 4.0954
2024-10-31 01:00:38: [2024-10-31 01:00:38] iter = 07430, loss = 2.2658
2024-10-31 01:00:40: [2024-10-31 01:00:40] iter = 07440, loss = 2.1727
2024-10-31 01:00:43: [2024-10-31 01:00:43] iter = 07450, loss = 1.9993
2024-10-31 01:00:46: [2024-10-31 01:00:46] iter = 07460, loss = 2.0155
2024-10-31 01:00:49: [2024-10-31 01:00:49] iter = 07470, loss = 2.2662
2024-10-31 01:00:51: [2024-10-31 01:00:51] iter = 07480, loss = 2.2306
2024-10-31 01:00:54: [2024-10-31 01:00:54] iter = 07490, loss = 1.9542
2024-10-31 01:00:57: [2024-10-31 01:00:57] iter = 07500, loss = 1.8167
2024-10-31 01:01:01: [2024-10-31 01:01:01] iter = 07510, loss = 2.0753
2024-10-31 01:01:04: [2024-10-31 01:01:04] iter = 07520, loss = 2.5201
2024-10-31 01:01:08: [2024-10-31 01:01:08] iter = 07530, loss = 2.4010
2024-10-31 01:01:10: [2024-10-31 01:01:10] iter = 07540, loss = 2.0934
2024-10-31 01:01:14: [2024-10-31 01:01:14] iter = 07550, loss = 2.0809
2024-10-31 01:01:18: [2024-10-31 01:01:18] iter = 07560, loss = 1.8457
2024-10-31 01:01:20: [2024-10-31 01:01:20] iter = 07570, loss = 2.6305
2024-10-31 01:01:23: [2024-10-31 01:01:23] iter = 07580, loss = 3.1843
2024-10-31 01:01:27: [2024-10-31 01:01:27] iter = 07590, loss = 2.9615
2024-10-31 01:01:31: [2024-10-31 01:01:31] iter = 07600, loss = 2.5541
2024-10-31 01:01:34: [2024-10-31 01:01:34] iter = 07610, loss = 2.9112
2024-10-31 01:01:36: [2024-10-31 01:01:36] iter = 07620, loss = 2.5014
2024-10-31 01:01:39: [2024-10-31 01:01:39] iter = 07630, loss = 2.1704
2024-10-31 01:01:43: [2024-10-31 01:01:43] iter = 07640, loss = 2.2922
2024-10-31 01:01:46: [2024-10-31 01:01:46] iter = 07650, loss = 2.2581
2024-10-31 01:01:49: [2024-10-31 01:01:49] iter = 07660, loss = 2.6614
2024-10-31 01:01:52: [2024-10-31 01:01:52] iter = 07670, loss = 2.0073
2024-10-31 01:01:55: [2024-10-31 01:01:55] iter = 07680, loss = 3.2462
2024-10-31 01:01:59: [2024-10-31 01:01:59] iter = 07690, loss = 1.9717
2024-10-31 01:02:01: [2024-10-31 01:02:01] iter = 07700, loss = 2.3444
2024-10-31 01:02:05: [2024-10-31 01:02:05] iter = 07710, loss = 2.4336
2024-10-31 01:02:07: [2024-10-31 01:02:07] iter = 07720, loss = 2.1477
2024-10-31 01:02:09: [2024-10-31 01:02:09] iter = 07730, loss = 3.0519
2024-10-31 01:02:12: [2024-10-31 01:02:12] iter = 07740, loss = 2.2562
2024-10-31 01:02:15: [2024-10-31 01:02:15] iter = 07750, loss = 2.0981
2024-10-31 01:02:18: [2024-10-31 01:02:18] iter = 07760, loss = 3.8888
2024-10-31 01:02:21: [2024-10-31 01:02:21] iter = 07770, loss = 3.3084
2024-10-31 01:02:24: [2024-10-31 01:02:24] iter = 07780, loss = 3.1341
2024-10-31 01:02:27: [2024-10-31 01:02:27] iter = 07790, loss = 2.2108
2024-10-31 01:02:31: [2024-10-31 01:02:31] iter = 07800, loss = 2.5133
2024-10-31 01:02:34: [2024-10-31 01:02:34] iter = 07810, loss = 3.9237
2024-10-31 01:02:37: [2024-10-31 01:02:37] iter = 07820, loss = 2.2684
2024-10-31 01:02:40: [2024-10-31 01:02:40] iter = 07830, loss = 2.1541
2024-10-31 01:02:44: [2024-10-31 01:02:44] iter = 07840, loss = 2.4259
2024-10-31 01:02:47: [2024-10-31 01:02:47] iter = 07850, loss = 1.8582
2024-10-31 01:02:51: [2024-10-31 01:02:51] iter = 07860, loss = 2.1315
2024-10-31 01:02:53: [2024-10-31 01:02:53] iter = 07870, loss = 2.2679
2024-10-31 01:02:57: [2024-10-31 01:02:57] iter = 07880, loss = 1.8409
2024-10-31 01:03:00: [2024-10-31 01:03:00] iter = 07890, loss = 1.9659
2024-10-31 01:03:02: [2024-10-31 01:03:02] iter = 07900, loss = 2.6879
2024-10-31 01:03:05: [2024-10-31 01:03:05] iter = 07910, loss = 3.5421
2024-10-31 01:03:08: [2024-10-31 01:03:08] iter = 07920, loss = 2.0030
2024-10-31 01:03:11: [2024-10-31 01:03:11] iter = 07930, loss = 2.1440
2024-10-31 01:03:14: [2024-10-31 01:03:14] iter = 07940, loss = 2.1407
2024-10-31 01:03:18: [2024-10-31 01:03:18] iter = 07950, loss = 2.6633
2024-10-31 01:03:21: [2024-10-31 01:03:21] iter = 07960, loss = 2.2468
2024-10-31 01:03:25: [2024-10-31 01:03:25] iter = 07970, loss = 1.8935
2024-10-31 01:03:28: [2024-10-31 01:03:28] iter = 07980, loss = 2.4162
2024-10-31 01:03:31: [2024-10-31 01:03:31] iter = 07990, loss = 2.8250
2024-10-31 01:03:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-31 01:03:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:03:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 13959}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:05:32: Evaluate 5 random ConvNet, ACCmean = 0.6094 ACCstd = 0.0048
-------------------------
2024-10-31 01:05:32: Evaluate 5 random ConvNet, SENmean = 0.5887 SENstd = 0.0031
-------------------------
2024-10-31 01:05:32: Evaluate 5 random ConvNet, SPEmean = 0.9602 SPEstd = 0.0004
-------------------------
2024-10-31 01:05:32: Evaluate 5 random ConvNet, F!mean = 0.5773 F!std = 0.0043
-------------------------
2024-10-31 01:05:32: Evaluate 5 random ConvNet, mean = 0.6094 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:05:32: [2024-10-31 01:05:32] iter = 08000, loss = 2.0091
2024-10-31 01:05:35: [2024-10-31 01:05:35] iter = 08010, loss = 4.6309
2024-10-31 01:05:38: [2024-10-31 01:05:38] iter = 08020, loss = 1.9703
2024-10-31 01:05:41: [2024-10-31 01:05:41] iter = 08030, loss = 2.2008
2024-10-31 01:05:43: [2024-10-31 01:05:43] iter = 08040, loss = 1.8820
2024-10-31 01:05:46: [2024-10-31 01:05:46] iter = 08050, loss = 9.3799
2024-10-31 01:05:49: [2024-10-31 01:05:49] iter = 08060, loss = 2.0508
2024-10-31 01:05:52: [2024-10-31 01:05:52] iter = 08070, loss = 2.1834
2024-10-31 01:05:55: [2024-10-31 01:05:55] iter = 08080, loss = 2.1710
2024-10-31 01:05:59: [2024-10-31 01:05:59] iter = 08090, loss = 2.7529
2024-10-31 01:06:02: [2024-10-31 01:06:02] iter = 08100, loss = 2.3795
2024-10-31 01:06:05: [2024-10-31 01:06:05] iter = 08110, loss = 2.0783
2024-10-31 01:06:08: [2024-10-31 01:06:08] iter = 08120, loss = 3.0167
2024-10-31 01:06:11: [2024-10-31 01:06:11] iter = 08130, loss = 3.4297
2024-10-31 01:06:15: [2024-10-31 01:06:15] iter = 08140, loss = 2.9420
2024-10-31 01:06:18: [2024-10-31 01:06:18] iter = 08150, loss = 1.8119
2024-10-31 01:06:22: [2024-10-31 01:06:22] iter = 08160, loss = 1.8532
2024-10-31 01:06:25: [2024-10-31 01:06:25] iter = 08170, loss = 2.2794
2024-10-31 01:06:28: [2024-10-31 01:06:28] iter = 08180, loss = 1.9756
2024-10-31 01:06:30: [2024-10-31 01:06:30] iter = 08190, loss = 1.9411
2024-10-31 01:06:33: [2024-10-31 01:06:33] iter = 08200, loss = 3.7074
2024-10-31 01:06:35: [2024-10-31 01:06:35] iter = 08210, loss = 1.9831
2024-10-31 01:06:38: [2024-10-31 01:06:38] iter = 08220, loss = 1.9415
2024-10-31 01:06:41: [2024-10-31 01:06:41] iter = 08230, loss = 2.5078
2024-10-31 01:06:45: [2024-10-31 01:06:45] iter = 08240, loss = 3.7951
2024-10-31 01:06:47: [2024-10-31 01:06:47] iter = 08250, loss = 2.8815
2024-10-31 01:06:50: [2024-10-31 01:06:50] iter = 08260, loss = 1.9998
2024-10-31 01:06:53: [2024-10-31 01:06:53] iter = 08270, loss = 2.3098
2024-10-31 01:06:55: [2024-10-31 01:06:55] iter = 08280, loss = 2.0830
2024-10-31 01:06:58: [2024-10-31 01:06:58] iter = 08290, loss = 1.8881
2024-10-31 01:07:01: [2024-10-31 01:07:01] iter = 08300, loss = 2.3320
2024-10-31 01:07:04: [2024-10-31 01:07:04] iter = 08310, loss = 2.0221
2024-10-31 01:07:05: [2024-10-31 01:07:05] iter = 08320, loss = 1.8891
2024-10-31 01:07:08: [2024-10-31 01:07:08] iter = 08330, loss = 2.7869
2024-10-31 01:07:12: [2024-10-31 01:07:12] iter = 08340, loss = 1.8159
2024-10-31 01:07:15: [2024-10-31 01:07:15] iter = 08350, loss = 2.7527
2024-10-31 01:07:17: [2024-10-31 01:07:17] iter = 08360, loss = 2.5958
2024-10-31 01:07:20: [2024-10-31 01:07:20] iter = 08370, loss = 2.1235
2024-10-31 01:07:24: [2024-10-31 01:07:24] iter = 08380, loss = 2.0345
2024-10-31 01:07:28: [2024-10-31 01:07:28] iter = 08390, loss = 5.3289
2024-10-31 01:07:31: [2024-10-31 01:07:31] iter = 08400, loss = 2.1303
2024-10-31 01:07:34: [2024-10-31 01:07:34] iter = 08410, loss = 1.8623
2024-10-31 01:07:37: [2024-10-31 01:07:37] iter = 08420, loss = 2.0931
2024-10-31 01:07:40: [2024-10-31 01:07:40] iter = 08430, loss = 1.7182
2024-10-31 01:07:43: [2024-10-31 01:07:43] iter = 08440, loss = 2.0617
2024-10-31 01:07:47: [2024-10-31 01:07:47] iter = 08450, loss = 2.1670
2024-10-31 01:07:50: [2024-10-31 01:07:50] iter = 08460, loss = 2.0007
2024-10-31 01:07:53: [2024-10-31 01:07:53] iter = 08470, loss = 2.1955
2024-10-31 01:07:56: [2024-10-31 01:07:56] iter = 08480, loss = 2.4147
2024-10-31 01:07:59: [2024-10-31 01:07:58] iter = 08490, loss = 3.1217
2024-10-31 01:08:02: [2024-10-31 01:08:02] iter = 08500, loss = 2.1165
2024-10-31 01:08:05: [2024-10-31 01:08:05] iter = 08510, loss = 2.0727
2024-10-31 01:08:07: [2024-10-31 01:08:07] iter = 08520, loss = 1.9673
2024-10-31 01:08:10: [2024-10-31 01:08:10] iter = 08530, loss = 1.8874
2024-10-31 01:08:15: [2024-10-31 01:08:15] iter = 08540, loss = 2.1609
2024-10-31 01:08:18: [2024-10-31 01:08:18] iter = 08550, loss = 1.8257
2024-10-31 01:08:21: [2024-10-31 01:08:21] iter = 08560, loss = 2.1608
2024-10-31 01:08:24: [2024-10-31 01:08:24] iter = 08570, loss = 3.8786
2024-10-31 01:08:27: [2024-10-31 01:08:27] iter = 08580, loss = 2.1370
2024-10-31 01:08:31: [2024-10-31 01:08:31] iter = 08590, loss = 2.5029
2024-10-31 01:08:34: [2024-10-31 01:08:34] iter = 08600, loss = 5.8600
2024-10-31 01:08:37: [2024-10-31 01:08:37] iter = 08610, loss = 9.0354
2024-10-31 01:08:41: [2024-10-31 01:08:41] iter = 08620, loss = 1.9671
2024-10-31 01:08:44: [2024-10-31 01:08:44] iter = 08630, loss = 2.0050
2024-10-31 01:08:47: [2024-10-31 01:08:47] iter = 08640, loss = 3.2709
2024-10-31 01:08:50: [2024-10-31 01:08:50] iter = 08650, loss = 2.9380
2024-10-31 01:08:53: [2024-10-31 01:08:53] iter = 08660, loss = 2.0107
2024-10-31 01:08:56: [2024-10-31 01:08:56] iter = 08670, loss = 2.3847
2024-10-31 01:09:00: [2024-10-31 01:09:00] iter = 08680, loss = 1.8914
2024-10-31 01:09:03: [2024-10-31 01:09:03] iter = 08690, loss = 2.1305
2024-10-31 01:09:07: [2024-10-31 01:09:07] iter = 08700, loss = 1.9673
2024-10-31 01:09:11: [2024-10-31 01:09:11] iter = 08710, loss = 1.8371
2024-10-31 01:09:13: [2024-10-31 01:09:13] iter = 08720, loss = 2.5765
2024-10-31 01:09:17: [2024-10-31 01:09:17] iter = 08730, loss = 2.0618
2024-10-31 01:09:20: [2024-10-31 01:09:20] iter = 08740, loss = 1.9866
2024-10-31 01:09:23: [2024-10-31 01:09:23] iter = 08750, loss = 2.2067
2024-10-31 01:09:25: [2024-10-31 01:09:25] iter = 08760, loss = 2.4200
2024-10-31 01:09:28: [2024-10-31 01:09:28] iter = 08770, loss = 2.0692
2024-10-31 01:09:31: [2024-10-31 01:09:31] iter = 08780, loss = 3.1064
2024-10-31 01:09:34: [2024-10-31 01:09:34] iter = 08790, loss = 2.7044
2024-10-31 01:09:38: [2024-10-31 01:09:38] iter = 08800, loss = 2.4017
2024-10-31 01:09:41: [2024-10-31 01:09:41] iter = 08810, loss = 2.0367
2024-10-31 01:09:45: [2024-10-31 01:09:45] iter = 08820, loss = 1.9851
2024-10-31 01:09:48: [2024-10-31 01:09:48] iter = 08830, loss = 1.9047
2024-10-31 01:09:51: [2024-10-31 01:09:51] iter = 08840, loss = 1.8658
2024-10-31 01:09:54: [2024-10-31 01:09:54] iter = 08850, loss = 1.8905
2024-10-31 01:09:57: [2024-10-31 01:09:57] iter = 08860, loss = 2.0926
2024-10-31 01:10:00: [2024-10-31 01:10:00] iter = 08870, loss = 2.1531
2024-10-31 01:10:04: [2024-10-31 01:10:04] iter = 08880, loss = 2.0680
2024-10-31 01:10:07: [2024-10-31 01:10:07] iter = 08890, loss = 1.9689
2024-10-31 01:10:10: [2024-10-31 01:10:10] iter = 08900, loss = 1.9730
2024-10-31 01:10:13: [2024-10-31 01:10:13] iter = 08910, loss = 2.6951
2024-10-31 01:10:16: [2024-10-31 01:10:15] iter = 08920, loss = 2.6485
2024-10-31 01:10:18: [2024-10-31 01:10:18] iter = 08930, loss = 4.1926
2024-10-31 01:10:20: [2024-10-31 01:10:20] iter = 08940, loss = 2.2309
2024-10-31 01:10:24: [2024-10-31 01:10:24] iter = 08950, loss = 2.5460
2024-10-31 01:10:26: [2024-10-31 01:10:26] iter = 08960, loss = 1.8719
2024-10-31 01:10:29: [2024-10-31 01:10:29] iter = 08970, loss = 2.7644
2024-10-31 01:10:31: [2024-10-31 01:10:31] iter = 08980, loss = 2.1275
2024-10-31 01:10:34: [2024-10-31 01:10:34] iter = 08990, loss = 2.9155
2024-10-31 01:10:38: [2024-10-31 01:10:38] iter = 09000, loss = 2.3839
2024-10-31 01:10:41: [2024-10-31 01:10:41] iter = 09010, loss = 2.8803
2024-10-31 01:10:44: [2024-10-31 01:10:44] iter = 09020, loss = 2.6164
2024-10-31 01:10:47: [2024-10-31 01:10:47] iter = 09030, loss = 2.4301
2024-10-31 01:10:50: [2024-10-31 01:10:50] iter = 09040, loss = 1.8190
2024-10-31 01:10:52: [2024-10-31 01:10:52] iter = 09050, loss = 3.4547
2024-10-31 01:10:55: [2024-10-31 01:10:55] iter = 09060, loss = 1.8352
2024-10-31 01:10:58: [2024-10-31 01:10:58] iter = 09070, loss = 2.0513
2024-10-31 01:11:01: [2024-10-31 01:11:01] iter = 09080, loss = 2.8056
2024-10-31 01:11:05: [2024-10-31 01:11:05] iter = 09090, loss = 2.5172
2024-10-31 01:11:08: [2024-10-31 01:11:08] iter = 09100, loss = 1.8648
2024-10-31 01:11:11: [2024-10-31 01:11:11] iter = 09110, loss = 2.3973
2024-10-31 01:11:14: [2024-10-31 01:11:14] iter = 09120, loss = 1.9770
2024-10-31 01:11:16: [2024-10-31 01:11:16] iter = 09130, loss = 1.9521
2024-10-31 01:11:19: [2024-10-31 01:11:19] iter = 09140, loss = 2.5783
2024-10-31 01:11:22: [2024-10-31 01:11:22] iter = 09150, loss = 2.0340
2024-10-31 01:11:25: [2024-10-31 01:11:25] iter = 09160, loss = 1.9337
2024-10-31 01:11:29: [2024-10-31 01:11:29] iter = 09170, loss = 2.0339
2024-10-31 01:11:30: [2024-10-31 01:11:30] iter = 09180, loss = 2.2661
2024-10-31 01:11:33: [2024-10-31 01:11:33] iter = 09190, loss = 2.7530
2024-10-31 01:11:36: [2024-10-31 01:11:36] iter = 09200, loss = 2.4690
2024-10-31 01:11:39: [2024-10-31 01:11:39] iter = 09210, loss = 2.8054
2024-10-31 01:11:42: [2024-10-31 01:11:42] iter = 09220, loss = 2.0038
2024-10-31 01:11:44: [2024-10-31 01:11:44] iter = 09230, loss = 2.1786
2024-10-31 01:11:48: [2024-10-31 01:11:48] iter = 09240, loss = 1.9400
2024-10-31 01:11:50: [2024-10-31 01:11:50] iter = 09250, loss = 3.0241
2024-10-31 01:11:54: [2024-10-31 01:11:54] iter = 09260, loss = 2.4093
2024-10-31 01:11:57: [2024-10-31 01:11:57] iter = 09270, loss = 3.2266
2024-10-31 01:12:01: [2024-10-31 01:12:01] iter = 09280, loss = 1.8389
2024-10-31 01:12:03: [2024-10-31 01:12:03] iter = 09290, loss = 3.0083
2024-10-31 01:12:06: [2024-10-31 01:12:06] iter = 09300, loss = 2.2669
2024-10-31 01:12:09: [2024-10-31 01:12:09] iter = 09310, loss = 3.3381
2024-10-31 01:12:13: [2024-10-31 01:12:13] iter = 09320, loss = 3.1574
2024-10-31 01:12:16: [2024-10-31 01:12:16] iter = 09330, loss = 2.1939
2024-10-31 01:12:19: [2024-10-31 01:12:19] iter = 09340, loss = 1.6998
2024-10-31 01:12:22: [2024-10-31 01:12:22] iter = 09350, loss = 2.2517
2024-10-31 01:12:24: [2024-10-31 01:12:24] iter = 09360, loss = 1.7936
2024-10-31 01:12:27: [2024-10-31 01:12:27] iter = 09370, loss = 3.6673
2024-10-31 01:12:31: [2024-10-31 01:12:31] iter = 09380, loss = 2.2696
2024-10-31 01:12:33: [2024-10-31 01:12:33] iter = 09390, loss = 7.4793
2024-10-31 01:12:37: [2024-10-31 01:12:37] iter = 09400, loss = 3.2619
2024-10-31 01:12:39: [2024-10-31 01:12:39] iter = 09410, loss = 2.4172
2024-10-31 01:12:42: [2024-10-31 01:12:42] iter = 09420, loss = 2.1061
2024-10-31 01:12:45: [2024-10-31 01:12:45] iter = 09430, loss = 2.0211
2024-10-31 01:12:49: [2024-10-31 01:12:49] iter = 09440, loss = 2.0558
2024-10-31 01:12:51: [2024-10-31 01:12:51] iter = 09450, loss = 2.3242
2024-10-31 01:12:54: [2024-10-31 01:12:54] iter = 09460, loss = 2.3778
2024-10-31 01:12:56: [2024-10-31 01:12:56] iter = 09470, loss = 1.8499
2024-10-31 01:12:59: [2024-10-31 01:12:59] iter = 09480, loss = 1.8031
2024-10-31 01:13:02: [2024-10-31 01:13:02] iter = 09490, loss = 2.6356
2024-10-31 01:13:06: [2024-10-31 01:13:06] iter = 09500, loss = 2.4513
2024-10-31 01:13:08: [2024-10-31 01:13:08] iter = 09510, loss = 2.1462
2024-10-31 01:13:12: [2024-10-31 01:13:12] iter = 09520, loss = 2.2300
2024-10-31 01:13:15: [2024-10-31 01:13:15] iter = 09530, loss = 2.6492
2024-10-31 01:13:19: [2024-10-31 01:13:19] iter = 09540, loss = 2.0053
2024-10-31 01:13:22: [2024-10-31 01:13:22] iter = 09550, loss = 3.1879
2024-10-31 01:13:25: [2024-10-31 01:13:25] iter = 09560, loss = 2.6045
2024-10-31 01:13:28: [2024-10-31 01:13:28] iter = 09570, loss = 2.1918
2024-10-31 01:13:32: [2024-10-31 01:13:32] iter = 09580, loss = 1.7777
2024-10-31 01:13:34: [2024-10-31 01:13:34] iter = 09590, loss = 2.6419
2024-10-31 01:13:37: [2024-10-31 01:13:37] iter = 09600, loss = 2.5403
2024-10-31 01:13:40: [2024-10-31 01:13:40] iter = 09610, loss = 1.9512
2024-10-31 01:13:43: [2024-10-31 01:13:43] iter = 09620, loss = 2.5739
2024-10-31 01:13:45: [2024-10-31 01:13:45] iter = 09630, loss = 2.9473
2024-10-31 01:13:48: [2024-10-31 01:13:48] iter = 09640, loss = 2.6325
2024-10-31 01:13:51: [2024-10-31 01:13:50] iter = 09650, loss = 2.3200
2024-10-31 01:13:53: [2024-10-31 01:13:53] iter = 09660, loss = 3.0574
2024-10-31 01:13:55: [2024-10-31 01:13:55] iter = 09670, loss = 1.9787
2024-10-31 01:13:59: [2024-10-31 01:13:59] iter = 09680, loss = 2.1510
2024-10-31 01:14:01: [2024-10-31 01:14:01] iter = 09690, loss = 2.2425
2024-10-31 01:14:05: [2024-10-31 01:14:05] iter = 09700, loss = 2.0530
2024-10-31 01:14:08: [2024-10-31 01:14:08] iter = 09710, loss = 2.0524
2024-10-31 01:14:11: [2024-10-31 01:14:11] iter = 09720, loss = 2.1633
2024-10-31 01:14:13: [2024-10-31 01:14:13] iter = 09730, loss = 2.2597
2024-10-31 01:14:16: [2024-10-31 01:14:16] iter = 09740, loss = 1.9501
2024-10-31 01:14:19: [2024-10-31 01:14:19] iter = 09750, loss = 2.2180
2024-10-31 01:14:22: [2024-10-31 01:14:22] iter = 09760, loss = 2.1193
2024-10-31 01:14:26: [2024-10-31 01:14:26] iter = 09770, loss = 1.9637
2024-10-31 01:14:29: [2024-10-31 01:14:29] iter = 09780, loss = 2.3662
2024-10-31 01:14:32: [2024-10-31 01:14:32] iter = 09790, loss = 3.4596
2024-10-31 01:14:35: [2024-10-31 01:14:35] iter = 09800, loss = 2.7433
2024-10-31 01:14:38: [2024-10-31 01:14:38] iter = 09810, loss = 2.1990
2024-10-31 01:14:41: [2024-10-31 01:14:41] iter = 09820, loss = 2.1179
2024-10-31 01:14:44: [2024-10-31 01:14:44] iter = 09830, loss = 2.1712
2024-10-31 01:14:47: [2024-10-31 01:14:47] iter = 09840, loss = 2.1663
2024-10-31 01:14:49: [2024-10-31 01:14:49] iter = 09850, loss = 2.5286
2024-10-31 01:14:53: [2024-10-31 01:14:53] iter = 09860, loss = 2.6267
2024-10-31 01:14:56: [2024-10-31 01:14:56] iter = 09870, loss = 1.9505
2024-10-31 01:14:58: [2024-10-31 01:14:58] iter = 09880, loss = 2.2010
2024-10-31 01:15:01: [2024-10-31 01:15:01] iter = 09890, loss = 2.7596
2024-10-31 01:15:04: [2024-10-31 01:15:04] iter = 09900, loss = 1.8342
2024-10-31 01:15:06: [2024-10-31 01:15:06] iter = 09910, loss = 2.8965
2024-10-31 01:15:09: [2024-10-31 01:15:09] iter = 09920, loss = 2.1074
2024-10-31 01:15:12: [2024-10-31 01:15:12] iter = 09930, loss = 1.8362
2024-10-31 01:15:16: [2024-10-31 01:15:16] iter = 09940, loss = 1.8838
2024-10-31 01:15:18: [2024-10-31 01:15:18] iter = 09950, loss = 2.0388
2024-10-31 01:15:21: [2024-10-31 01:15:21] iter = 09960, loss = 1.9971
2024-10-31 01:15:24: [2024-10-31 01:15:24] iter = 09970, loss = 2.7112
2024-10-31 01:15:28: [2024-10-31 01:15:28] iter = 09980, loss = 2.0607
2024-10-31 01:15:31: [2024-10-31 01:15:31] iter = 09990, loss = 1.9325
2024-10-31 01:15:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-31 01:15:34: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:15:34: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 34723}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:17:29: Evaluate 5 random ConvNet, ACCmean = 0.6000 ACCstd = 0.0049
-------------------------
2024-10-31 01:17:29: Evaluate 5 random ConvNet, SENmean = 0.5780 SENstd = 0.0051
-------------------------
2024-10-31 01:17:29: Evaluate 5 random ConvNet, SPEmean = 0.9592 SPEstd = 0.0005
-------------------------
2024-10-31 01:17:29: Evaluate 5 random ConvNet, F!mean = 0.5706 F!std = 0.0049
-------------------------
2024-10-31 01:17:29: Evaluate 5 random ConvNet, mean = 0.6000 std = 0.0049
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:17:30: [2024-10-31 01:17:30] iter = 10000, loss = 3.0409
2024-10-31 01:17:33: [2024-10-31 01:17:33] iter = 10010, loss = 2.3322
2024-10-31 01:17:36: [2024-10-31 01:17:36] iter = 10020, loss = 2.1940
2024-10-31 01:17:39: [2024-10-31 01:17:39] iter = 10030, loss = 1.9657
2024-10-31 01:17:42: [2024-10-31 01:17:42] iter = 10040, loss = 2.3416
2024-10-31 01:17:46: [2024-10-31 01:17:46] iter = 10050, loss = 3.0302
2024-10-31 01:17:49: [2024-10-31 01:17:49] iter = 10060, loss = 1.8301
2024-10-31 01:17:52: [2024-10-31 01:17:52] iter = 10070, loss = 2.0548
2024-10-31 01:17:55: [2024-10-31 01:17:55] iter = 10080, loss = 1.6853
2024-10-31 01:17:58: [2024-10-31 01:17:58] iter = 10090, loss = 2.4347
2024-10-31 01:18:01: [2024-10-31 01:18:01] iter = 10100, loss = 2.0955
2024-10-31 01:18:04: [2024-10-31 01:18:04] iter = 10110, loss = 2.0054
2024-10-31 01:18:07: [2024-10-31 01:18:07] iter = 10120, loss = 2.0250
2024-10-31 01:18:10: [2024-10-31 01:18:10] iter = 10130, loss = 2.0799
2024-10-31 01:18:13: [2024-10-31 01:18:13] iter = 10140, loss = 2.3246
2024-10-31 01:18:15: [2024-10-31 01:18:15] iter = 10150, loss = 1.8823
2024-10-31 01:18:18: [2024-10-31 01:18:18] iter = 10160, loss = 2.4745
2024-10-31 01:18:21: [2024-10-31 01:18:21] iter = 10170, loss = 2.4178
2024-10-31 01:18:24: [2024-10-31 01:18:24] iter = 10180, loss = 2.5662
2024-10-31 01:18:28: [2024-10-31 01:18:28] iter = 10190, loss = 1.8551
2024-10-31 01:18:31: [2024-10-31 01:18:31] iter = 10200, loss = 2.0859
2024-10-31 01:18:35: [2024-10-31 01:18:35] iter = 10210, loss = 2.7232
2024-10-31 01:18:38: [2024-10-31 01:18:38] iter = 10220, loss = 2.4458
2024-10-31 01:18:42: [2024-10-31 01:18:42] iter = 10230, loss = 2.0396
2024-10-31 01:18:45: [2024-10-31 01:18:45] iter = 10240, loss = 2.2944
2024-10-31 01:18:48: [2024-10-31 01:18:48] iter = 10250, loss = 2.5213
2024-10-31 01:18:51: [2024-10-31 01:18:51] iter = 10260, loss = 2.2856
2024-10-31 01:18:54: [2024-10-31 01:18:54] iter = 10270, loss = 2.8816
2024-10-31 01:18:58: [2024-10-31 01:18:58] iter = 10280, loss = 2.0076
2024-10-31 01:19:01: [2024-10-31 01:19:01] iter = 10290, loss = 2.9929
2024-10-31 01:19:04: [2024-10-31 01:19:04] iter = 10300, loss = 2.0149
2024-10-31 01:19:07: [2024-10-31 01:19:07] iter = 10310, loss = 2.0620
2024-10-31 01:19:10: [2024-10-31 01:19:10] iter = 10320, loss = 2.1621
2024-10-31 01:19:13: [2024-10-31 01:19:13] iter = 10330, loss = 2.0872
2024-10-31 01:19:15: [2024-10-31 01:19:15] iter = 10340, loss = 2.2742
2024-10-31 01:19:18: [2024-10-31 01:19:18] iter = 10350, loss = 2.5522
2024-10-31 01:19:21: [2024-10-31 01:19:21] iter = 10360, loss = 2.2134
2024-10-31 01:19:24: [2024-10-31 01:19:24] iter = 10370, loss = 1.9712
2024-10-31 01:19:25: [2024-10-31 01:19:25] iter = 10380, loss = 1.8178
2024-10-31 01:19:29: [2024-10-31 01:19:29] iter = 10390, loss = 2.8062
2024-10-31 01:19:33: [2024-10-31 01:19:33] iter = 10400, loss = 2.4423
2024-10-31 01:19:35: [2024-10-31 01:19:35] iter = 10410, loss = 3.5658
2024-10-31 01:19:38: [2024-10-31 01:19:38] iter = 10420, loss = 2.2031
2024-10-31 01:19:40: [2024-10-31 01:19:40] iter = 10430, loss = 1.8854
2024-10-31 01:19:43: [2024-10-31 01:19:43] iter = 10440, loss = 1.8175
2024-10-31 01:19:46: [2024-10-31 01:19:46] iter = 10450, loss = 3.2227
2024-10-31 01:19:49: [2024-10-31 01:19:49] iter = 10460, loss = 2.5045
2024-10-31 01:19:52: [2024-10-31 01:19:52] iter = 10470, loss = 2.1167
2024-10-31 01:19:55: [2024-10-31 01:19:55] iter = 10480, loss = 2.7577
2024-10-31 01:19:59: [2024-10-31 01:19:59] iter = 10490, loss = 2.8399
2024-10-31 01:20:02: [2024-10-31 01:20:02] iter = 10500, loss = 2.1379
2024-10-31 01:20:05: [2024-10-31 01:20:05] iter = 10510, loss = 2.2844
2024-10-31 01:20:08: [2024-10-31 01:20:08] iter = 10520, loss = 1.9352
2024-10-31 01:20:11: [2024-10-31 01:20:11] iter = 10530, loss = 2.0852
2024-10-31 01:20:14: [2024-10-31 01:20:14] iter = 10540, loss = 2.2080
2024-10-31 01:20:16: [2024-10-31 01:20:16] iter = 10550, loss = 4.0029
2024-10-31 01:20:19: [2024-10-31 01:20:19] iter = 10560, loss = 2.4873
2024-10-31 01:20:22: [2024-10-31 01:20:22] iter = 10570, loss = 2.1353
2024-10-31 01:20:25: [2024-10-31 01:20:25] iter = 10580, loss = 2.1586
2024-10-31 01:20:28: [2024-10-31 01:20:28] iter = 10590, loss = 2.3167
2024-10-31 01:20:31: [2024-10-31 01:20:31] iter = 10600, loss = 2.1874
2024-10-31 01:20:34: [2024-10-31 01:20:34] iter = 10610, loss = 1.9267
2024-10-31 01:20:37: [2024-10-31 01:20:37] iter = 10620, loss = 1.8720
2024-10-31 01:20:40: [2024-10-31 01:20:40] iter = 10630, loss = 2.6589
2024-10-31 01:20:43: [2024-10-31 01:20:43] iter = 10640, loss = 2.1606
2024-10-31 01:20:47: [2024-10-31 01:20:47] iter = 10650, loss = 2.2106
2024-10-31 01:20:51: [2024-10-31 01:20:51] iter = 10660, loss = 2.6279
2024-10-31 01:20:54: [2024-10-31 01:20:54] iter = 10670, loss = 2.5174
2024-10-31 01:20:56: [2024-10-31 01:20:56] iter = 10680, loss = 2.2754
2024-10-31 01:20:58: [2024-10-31 01:20:58] iter = 10690, loss = 2.0685
2024-10-31 01:21:00: [2024-10-31 01:21:00] iter = 10700, loss = 2.3455
2024-10-31 01:21:03: [2024-10-31 01:21:03] iter = 10710, loss = 1.9680
2024-10-31 01:21:06: [2024-10-31 01:21:06] iter = 10720, loss = 2.9119
2024-10-31 01:21:09: [2024-10-31 01:21:09] iter = 10730, loss = 1.8797
2024-10-31 01:21:13: [2024-10-31 01:21:13] iter = 10740, loss = 1.9215
2024-10-31 01:21:16: [2024-10-31 01:21:16] iter = 10750, loss = 2.0533
2024-10-31 01:21:19: [2024-10-31 01:21:19] iter = 10760, loss = 2.1911
2024-10-31 01:21:23: [2024-10-31 01:21:23] iter = 10770, loss = 2.1714
2024-10-31 01:21:26: [2024-10-31 01:21:26] iter = 10780, loss = 2.4498
2024-10-31 01:21:29: [2024-10-31 01:21:29] iter = 10790, loss = 2.0729
2024-10-31 01:21:32: [2024-10-31 01:21:32] iter = 10800, loss = 1.9489
2024-10-31 01:21:36: [2024-10-31 01:21:36] iter = 10810, loss = 2.1655
2024-10-31 01:21:40: [2024-10-31 01:21:40] iter = 10820, loss = 1.9739
2024-10-31 01:21:43: [2024-10-31 01:21:43] iter = 10830, loss = 2.0973
2024-10-31 01:21:47: [2024-10-31 01:21:47] iter = 10840, loss = 2.6211
2024-10-31 01:21:50: [2024-10-31 01:21:50] iter = 10850, loss = 3.0202
2024-10-31 01:21:53: [2024-10-31 01:21:53] iter = 10860, loss = 2.1169
2024-10-31 01:21:56: [2024-10-31 01:21:56] iter = 10870, loss = 1.9254
2024-10-31 01:22:00: [2024-10-31 01:22:00] iter = 10880, loss = 2.1034
2024-10-31 01:22:02: [2024-10-31 01:22:02] iter = 10890, loss = 1.7159
2024-10-31 01:22:05: [2024-10-31 01:22:05] iter = 10900, loss = 2.1917
2024-10-31 01:22:09: [2024-10-31 01:22:09] iter = 10910, loss = 2.0930
2024-10-31 01:22:13: [2024-10-31 01:22:13] iter = 10920, loss = 1.8765
2024-10-31 01:22:15: [2024-10-31 01:22:15] iter = 10930, loss = 2.1297
2024-10-31 01:22:17: [2024-10-31 01:22:17] iter = 10940, loss = 2.1487
2024-10-31 01:22:19: [2024-10-31 01:22:19] iter = 10950, loss = 1.8765
2024-10-31 01:22:22: [2024-10-31 01:22:22] iter = 10960, loss = 2.3030
2024-10-31 01:22:24: [2024-10-31 01:22:24] iter = 10970, loss = 2.3252
2024-10-31 01:22:27: [2024-10-31 01:22:27] iter = 10980, loss = 2.2852
2024-10-31 01:22:30: [2024-10-31 01:22:30] iter = 10990, loss = 5.1933
2024-10-31 01:22:34: [2024-10-31 01:22:34] iter = 11000, loss = 1.9904
2024-10-31 01:22:36: [2024-10-31 01:22:36] iter = 11010, loss = 2.1600
2024-10-31 01:22:39: [2024-10-31 01:22:39] iter = 11020, loss = 3.0258
2024-10-31 01:22:42: [2024-10-31 01:22:42] iter = 11030, loss = 2.2009
2024-10-31 01:22:45: [2024-10-31 01:22:45] iter = 11040, loss = 2.1820
2024-10-31 01:22:48: [2024-10-31 01:22:48] iter = 11050, loss = 3.4584
2024-10-31 01:22:51: [2024-10-31 01:22:51] iter = 11060, loss = 2.3083
2024-10-31 01:22:53: [2024-10-31 01:22:53] iter = 11070, loss = 2.0087
2024-10-31 01:22:56: [2024-10-31 01:22:56] iter = 11080, loss = 2.2890
2024-10-31 01:22:59: [2024-10-31 01:22:59] iter = 11090, loss = 2.1762
2024-10-31 01:23:02: [2024-10-31 01:23:02] iter = 11100, loss = 2.0188
2024-10-31 01:23:06: [2024-10-31 01:23:06] iter = 11110, loss = 2.5617
2024-10-31 01:23:09: [2024-10-31 01:23:09] iter = 11120, loss = 2.2577
2024-10-31 01:23:12: [2024-10-31 01:23:12] iter = 11130, loss = 2.4787
2024-10-31 01:23:14: [2024-10-31 01:23:14] iter = 11140, loss = 2.5362
2024-10-31 01:23:17: [2024-10-31 01:23:17] iter = 11150, loss = 2.1599
2024-10-31 01:23:20: [2024-10-31 01:23:20] iter = 11160, loss = 2.3813
2024-10-31 01:23:23: [2024-10-31 01:23:23] iter = 11170, loss = 4.5705
2024-10-31 01:23:27: [2024-10-31 01:23:27] iter = 11180, loss = 1.9163
2024-10-31 01:23:30: [2024-10-31 01:23:30] iter = 11190, loss = 2.1042
2024-10-31 01:23:34: [2024-10-31 01:23:34] iter = 11200, loss = 2.1424
2024-10-31 01:23:37: [2024-10-31 01:23:37] iter = 11210, loss = 2.6355
2024-10-31 01:23:40: [2024-10-31 01:23:40] iter = 11220, loss = 2.0914
2024-10-31 01:23:43: [2024-10-31 01:23:43] iter = 11230, loss = 2.7642
2024-10-31 01:23:45: [2024-10-31 01:23:45] iter = 11240, loss = 2.6806
2024-10-31 01:23:47: [2024-10-31 01:23:47] iter = 11250, loss = 2.0353
2024-10-31 01:23:50: [2024-10-31 01:23:50] iter = 11260, loss = 7.6392
2024-10-31 01:23:53: [2024-10-31 01:23:53] iter = 11270, loss = 2.4519
2024-10-31 01:23:55: [2024-10-31 01:23:55] iter = 11280, loss = 1.4153
2024-10-31 01:23:58: [2024-10-31 01:23:58] iter = 11290, loss = 2.0997
2024-10-31 01:24:01: [2024-10-31 01:24:01] iter = 11300, loss = 1.9202
2024-10-31 01:24:03: [2024-10-31 01:24:03] iter = 11310, loss = 2.7431
2024-10-31 01:24:06: [2024-10-31 01:24:06] iter = 11320, loss = 2.6755
2024-10-31 01:24:10: [2024-10-31 01:24:10] iter = 11330, loss = 3.3990
2024-10-31 01:24:13: [2024-10-31 01:24:13] iter = 11340, loss = 2.4701
2024-10-31 01:24:16: [2024-10-31 01:24:16] iter = 11350, loss = 1.9450
2024-10-31 01:24:19: [2024-10-31 01:24:19] iter = 11360, loss = 1.9803
2024-10-31 01:24:22: [2024-10-31 01:24:22] iter = 11370, loss = 1.9494
2024-10-31 01:24:24: [2024-10-31 01:24:24] iter = 11380, loss = 2.3690
2024-10-31 01:24:28: [2024-10-31 01:24:28] iter = 11390, loss = 1.9789
2024-10-31 01:24:31: [2024-10-31 01:24:31] iter = 11400, loss = 2.0050
2024-10-31 01:24:34: [2024-10-31 01:24:34] iter = 11410, loss = 4.0414
2024-10-31 01:24:38: [2024-10-31 01:24:38] iter = 11420, loss = 2.4445
2024-10-31 01:24:41: [2024-10-31 01:24:41] iter = 11430, loss = 1.9006
2024-10-31 01:24:44: [2024-10-31 01:24:44] iter = 11440, loss = 1.9694
2024-10-31 01:24:47: [2024-10-31 01:24:47] iter = 11450, loss = 2.2218
2024-10-31 01:24:51: [2024-10-31 01:24:51] iter = 11460, loss = 2.3321
2024-10-31 01:24:55: [2024-10-31 01:24:55] iter = 11470, loss = 3.5556
2024-10-31 01:24:58: [2024-10-31 01:24:58] iter = 11480, loss = 2.2368
2024-10-31 01:25:01: [2024-10-31 01:25:01] iter = 11490, loss = 2.2990
2024-10-31 01:25:04: [2024-10-31 01:25:04] iter = 11500, loss = 2.5731
2024-10-31 01:25:08: [2024-10-31 01:25:08] iter = 11510, loss = 2.8475
2024-10-31 01:25:11: [2024-10-31 01:25:11] iter = 11520, loss = 1.9652
2024-10-31 01:25:14: [2024-10-31 01:25:14] iter = 11530, loss = 1.8580
2024-10-31 01:25:17: [2024-10-31 01:25:17] iter = 11540, loss = 1.8730
2024-10-31 01:25:21: [2024-10-31 01:25:21] iter = 11550, loss = 1.8401
2024-10-31 01:25:24: [2024-10-31 01:25:24] iter = 11560, loss = 3.5106
2024-10-31 01:25:27: [2024-10-31 01:25:27] iter = 11570, loss = 3.2422
2024-10-31 01:25:30: [2024-10-31 01:25:30] iter = 11580, loss = 2.8513
2024-10-31 01:25:33: [2024-10-31 01:25:33] iter = 11590, loss = 2.3443
2024-10-31 01:25:36: [2024-10-31 01:25:36] iter = 11600, loss = 2.5658
2024-10-31 01:25:40: [2024-10-31 01:25:40] iter = 11610, loss = 2.8976
2024-10-31 01:25:42: [2024-10-31 01:25:42] iter = 11620, loss = 2.1946
2024-10-31 01:25:45: [2024-10-31 01:25:45] iter = 11630, loss = 1.7533
2024-10-31 01:25:49: [2024-10-31 01:25:49] iter = 11640, loss = 2.1309
2024-10-31 01:25:51: [2024-10-31 01:25:51] iter = 11650, loss = 2.7330
2024-10-31 01:25:55: [2024-10-31 01:25:55] iter = 11660, loss = 2.3704
2024-10-31 01:25:58: [2024-10-31 01:25:58] iter = 11670, loss = 1.9856
2024-10-31 01:26:01: [2024-10-31 01:26:01] iter = 11680, loss = 3.6559
2024-10-31 01:26:03: [2024-10-31 01:26:03] iter = 11690, loss = 2.2424
2024-10-31 01:26:07: [2024-10-31 01:26:07] iter = 11700, loss = 3.1814
2024-10-31 01:26:10: [2024-10-31 01:26:10] iter = 11710, loss = 1.9949
2024-10-31 01:26:13: [2024-10-31 01:26:13] iter = 11720, loss = 2.0651
2024-10-31 01:26:16: [2024-10-31 01:26:16] iter = 11730, loss = 2.0223
2024-10-31 01:26:19: [2024-10-31 01:26:19] iter = 11740, loss = 2.3297
2024-10-31 01:26:22: [2024-10-31 01:26:22] iter = 11750, loss = 2.0165
2024-10-31 01:26:25: [2024-10-31 01:26:25] iter = 11760, loss = 2.6705
2024-10-31 01:26:28: [2024-10-31 01:26:28] iter = 11770, loss = 2.2880
2024-10-31 01:26:32: [2024-10-31 01:26:32] iter = 11780, loss = 2.0611
2024-10-31 01:26:35: [2024-10-31 01:26:35] iter = 11790, loss = 2.2233
2024-10-31 01:26:38: [2024-10-31 01:26:38] iter = 11800, loss = 2.3325
2024-10-31 01:26:41: [2024-10-31 01:26:41] iter = 11810, loss = 2.3474
2024-10-31 01:26:45: [2024-10-31 01:26:45] iter = 11820, loss = 2.1551
2024-10-31 01:26:49: [2024-10-31 01:26:49] iter = 11830, loss = 2.4397
2024-10-31 01:26:53: [2024-10-31 01:26:53] iter = 11840, loss = 2.4086
2024-10-31 01:26:56: [2024-10-31 01:26:56] iter = 11850, loss = 2.5744
2024-10-31 01:26:59: [2024-10-31 01:26:59] iter = 11860, loss = 2.3735
2024-10-31 01:27:01: [2024-10-31 01:27:01] iter = 11870, loss = 2.0265
2024-10-31 01:27:05: [2024-10-31 01:27:05] iter = 11880, loss = 2.4476
2024-10-31 01:27:07: [2024-10-31 01:27:07] iter = 11890, loss = 2.3693
2024-10-31 01:27:10: [2024-10-31 01:27:10] iter = 11900, loss = 1.8499
2024-10-31 01:27:12: [2024-10-31 01:27:12] iter = 11910, loss = 2.6895
2024-10-31 01:27:16: [2024-10-31 01:27:16] iter = 11920, loss = 3.3685
2024-10-31 01:27:19: [2024-10-31 01:27:19] iter = 11930, loss = 2.4719
2024-10-31 01:27:22: [2024-10-31 01:27:22] iter = 11940, loss = 2.1773
2024-10-31 01:27:25: [2024-10-31 01:27:25] iter = 11950, loss = 2.5344
2024-10-31 01:27:27: [2024-10-31 01:27:27] iter = 11960, loss = 2.4489
2024-10-31 01:27:30: [2024-10-31 01:27:30] iter = 11970, loss = 2.0059
2024-10-31 01:27:33: [2024-10-31 01:27:33] iter = 11980, loss = 1.8793
2024-10-31 01:27:36: [2024-10-31 01:27:36] iter = 11990, loss = 1.5992
2024-10-31 01:27:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-31 01:27:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:27:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59283}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:29:48: Evaluate 5 random ConvNet, ACCmean = 0.6018 ACCstd = 0.0053
-------------------------
2024-10-31 01:29:48: Evaluate 5 random ConvNet, SENmean = 0.5834 SENstd = 0.0045
-------------------------
2024-10-31 01:29:48: Evaluate 5 random ConvNet, SPEmean = 0.9592 SPEstd = 0.0006
-------------------------
2024-10-31 01:29:48: Evaluate 5 random ConvNet, F!mean = 0.5745 F!std = 0.0039
-------------------------
2024-10-31 01:29:48: Evaluate 5 random ConvNet, mean = 0.6018 std = 0.0053
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:29:48: [2024-10-31 01:29:48] iter = 12000, loss = 2.2731
2024-10-31 01:29:52: [2024-10-31 01:29:52] iter = 12010, loss = 2.2999
2024-10-31 01:29:55: [2024-10-31 01:29:55] iter = 12020, loss = 2.0049
2024-10-31 01:29:58: [2024-10-31 01:29:58] iter = 12030, loss = 2.2495
2024-10-31 01:30:02: [2024-10-31 01:30:02] iter = 12040, loss = 2.0887
2024-10-31 01:30:05: [2024-10-31 01:30:05] iter = 12050, loss = 2.7461
2024-10-31 01:30:08: [2024-10-31 01:30:08] iter = 12060, loss = 3.1733
2024-10-31 01:30:11: [2024-10-31 01:30:11] iter = 12070, loss = 2.4432
2024-10-31 01:30:14: [2024-10-31 01:30:14] iter = 12080, loss = 2.1974
2024-10-31 01:30:18: [2024-10-31 01:30:18] iter = 12090, loss = 1.9631
2024-10-31 01:30:21: [2024-10-31 01:30:21] iter = 12100, loss = 1.9615
2024-10-31 01:30:24: [2024-10-31 01:30:24] iter = 12110, loss = 2.5044
2024-10-31 01:30:29: [2024-10-31 01:30:29] iter = 12120, loss = 2.2998
2024-10-31 01:30:31: [2024-10-31 01:30:31] iter = 12130, loss = 1.9212
2024-10-31 01:30:34: [2024-10-31 01:30:34] iter = 12140, loss = 2.1095
2024-10-31 01:30:38: [2024-10-31 01:30:38] iter = 12150, loss = 2.1334
2024-10-31 01:30:41: [2024-10-31 01:30:41] iter = 12160, loss = 2.2662
2024-10-31 01:30:45: [2024-10-31 01:30:45] iter = 12170, loss = 2.3574
2024-10-31 01:30:48: [2024-10-31 01:30:48] iter = 12180, loss = 1.8675
2024-10-31 01:30:52: [2024-10-31 01:30:52] iter = 12190, loss = 5.1626
2024-10-31 01:30:56: [2024-10-31 01:30:56] iter = 12200, loss = 3.4376
2024-10-31 01:30:59: [2024-10-31 01:30:59] iter = 12210, loss = 1.9850
2024-10-31 01:31:03: [2024-10-31 01:31:03] iter = 12220, loss = 2.3651
2024-10-31 01:31:06: [2024-10-31 01:31:06] iter = 12230, loss = 2.1034
2024-10-31 01:31:09: [2024-10-31 01:31:09] iter = 12240, loss = 1.9140
2024-10-31 01:31:13: [2024-10-31 01:31:13] iter = 12250, loss = 1.7475
2024-10-31 01:31:16: [2024-10-31 01:31:16] iter = 12260, loss = 4.0863
2024-10-31 01:31:19: [2024-10-31 01:31:19] iter = 12270, loss = 2.6334
2024-10-31 01:31:23: [2024-10-31 01:31:23] iter = 12280, loss = 1.9022
2024-10-31 01:31:25: [2024-10-31 01:31:25] iter = 12290, loss = 2.1477
2024-10-31 01:31:27: [2024-10-31 01:31:27] iter = 12300, loss = 2.8371
2024-10-31 01:31:31: [2024-10-31 01:31:31] iter = 12310, loss = 2.0744
2024-10-31 01:31:34: [2024-10-31 01:31:34] iter = 12320, loss = 2.6923
2024-10-31 01:31:37: [2024-10-31 01:31:37] iter = 12330, loss = 2.5228
2024-10-31 01:31:40: [2024-10-31 01:31:40] iter = 12340, loss = 2.6550
2024-10-31 01:31:43: [2024-10-31 01:31:43] iter = 12350, loss = 2.1766
2024-10-31 01:31:46: [2024-10-31 01:31:46] iter = 12360, loss = 2.1448
2024-10-31 01:31:50: [2024-10-31 01:31:50] iter = 12370, loss = 1.9979
2024-10-31 01:31:53: [2024-10-31 01:31:53] iter = 12380, loss = 2.1026
2024-10-31 01:31:57: [2024-10-31 01:31:57] iter = 12390, loss = 2.2966
2024-10-31 01:32:01: [2024-10-31 01:32:01] iter = 12400, loss = 1.9536
2024-10-31 01:32:04: [2024-10-31 01:32:04] iter = 12410, loss = 3.4121
2024-10-31 01:32:07: [2024-10-31 01:32:07] iter = 12420, loss = 2.8550
2024-10-31 01:32:11: [2024-10-31 01:32:11] iter = 12430, loss = 1.7816
2024-10-31 01:32:15: [2024-10-31 01:32:15] iter = 12440, loss = 1.8926
2024-10-31 01:32:19: [2024-10-31 01:32:19] iter = 12450, loss = 2.1581
2024-10-31 01:32:22: [2024-10-31 01:32:22] iter = 12460, loss = 2.6816
2024-10-31 01:32:25: [2024-10-31 01:32:25] iter = 12470, loss = 3.0915
2024-10-31 01:32:28: [2024-10-31 01:32:28] iter = 12480, loss = 1.9518
2024-10-31 01:32:32: [2024-10-31 01:32:32] iter = 12490, loss = 2.7847
2024-10-31 01:32:36: [2024-10-31 01:32:36] iter = 12500, loss = 3.3229
2024-10-31 01:32:39: [2024-10-31 01:32:39] iter = 12510, loss = 5.3690
2024-10-31 01:32:42: [2024-10-31 01:32:42] iter = 12520, loss = 2.4074
2024-10-31 01:32:44: [2024-10-31 01:32:44] iter = 12530, loss = 2.5921
2024-10-31 01:32:47: [2024-10-31 01:32:47] iter = 12540, loss = 2.2088
2024-10-31 01:32:51: [2024-10-31 01:32:51] iter = 12550, loss = 2.4193
2024-10-31 01:32:54: [2024-10-31 01:32:54] iter = 12560, loss = 2.1934
2024-10-31 01:32:57: [2024-10-31 01:32:57] iter = 12570, loss = 1.8758
2024-10-31 01:33:00: [2024-10-31 01:33:00] iter = 12580, loss = 3.0961
2024-10-31 01:33:04: [2024-10-31 01:33:04] iter = 12590, loss = 1.8821
2024-10-31 01:33:08: [2024-10-31 01:33:08] iter = 12600, loss = 2.1796
2024-10-31 01:33:12: [2024-10-31 01:33:12] iter = 12610, loss = 2.1461
2024-10-31 01:33:14: [2024-10-31 01:33:14] iter = 12620, loss = 1.8543
2024-10-31 01:33:17: [2024-10-31 01:33:17] iter = 12630, loss = 1.9375
2024-10-31 01:33:21: [2024-10-31 01:33:21] iter = 12640, loss = 3.4031
2024-10-31 01:33:24: [2024-10-31 01:33:24] iter = 12650, loss = 2.0198
2024-10-31 01:33:27: [2024-10-31 01:33:27] iter = 12660, loss = 2.3447
2024-10-31 01:33:30: [2024-10-31 01:33:30] iter = 12670, loss = 7.0987
2024-10-31 01:33:33: [2024-10-31 01:33:33] iter = 12680, loss = 2.2993
2024-10-31 01:33:36: [2024-10-31 01:33:36] iter = 12690, loss = 2.1044
2024-10-31 01:33:39: [2024-10-31 01:33:39] iter = 12700, loss = 2.6300
2024-10-31 01:33:42: [2024-10-31 01:33:42] iter = 12710, loss = 2.0949
2024-10-31 01:33:46: [2024-10-31 01:33:46] iter = 12720, loss = 1.7509
2024-10-31 01:33:49: [2024-10-31 01:33:49] iter = 12730, loss = 4.3808
2024-10-31 01:33:51: [2024-10-31 01:33:51] iter = 12740, loss = 1.8394
2024-10-31 01:33:54: [2024-10-31 01:33:54] iter = 12750, loss = 2.1391
2024-10-31 01:33:57: [2024-10-31 01:33:57] iter = 12760, loss = 4.2689
2024-10-31 01:34:01: [2024-10-31 01:34:01] iter = 12770, loss = 2.9295
2024-10-31 01:34:05: [2024-10-31 01:34:05] iter = 12780, loss = 1.9781
2024-10-31 01:34:08: [2024-10-31 01:34:08] iter = 12790, loss = 2.2932
2024-10-31 01:34:12: [2024-10-31 01:34:12] iter = 12800, loss = 2.6928
2024-10-31 01:34:16: [2024-10-31 01:34:16] iter = 12810, loss = 2.4679
2024-10-31 01:34:20: [2024-10-31 01:34:20] iter = 12820, loss = 2.1724
2024-10-31 01:34:24: [2024-10-31 01:34:24] iter = 12830, loss = 2.3769
2024-10-31 01:34:25: [2024-10-31 01:34:25] iter = 12840, loss = 2.1511
2024-10-31 01:34:29: [2024-10-31 01:34:29] iter = 12850, loss = 1.9929
2024-10-31 01:34:32: [2024-10-31 01:34:32] iter = 12860, loss = 2.7448
2024-10-31 01:34:36: [2024-10-31 01:34:36] iter = 12870, loss = 2.0445
2024-10-31 01:34:39: [2024-10-31 01:34:39] iter = 12880, loss = 2.7523
2024-10-31 01:34:42: [2024-10-31 01:34:42] iter = 12890, loss = 2.2350
2024-10-31 01:34:46: [2024-10-31 01:34:46] iter = 12900, loss = 2.8177
2024-10-31 01:34:49: [2024-10-31 01:34:49] iter = 12910, loss = 2.3291
2024-10-31 01:34:52: [2024-10-31 01:34:52] iter = 12920, loss = 1.9145
2024-10-31 01:34:55: [2024-10-31 01:34:55] iter = 12930, loss = 2.6730
2024-10-31 01:34:59: [2024-10-31 01:34:59] iter = 12940, loss = 2.0719
2024-10-31 01:35:02: [2024-10-31 01:35:02] iter = 12950, loss = 3.3704
2024-10-31 01:35:05: [2024-10-31 01:35:05] iter = 12960, loss = 2.4723
2024-10-31 01:35:09: [2024-10-31 01:35:09] iter = 12970, loss = 2.0095
2024-10-31 01:35:12: [2024-10-31 01:35:12] iter = 12980, loss = 2.3096
2024-10-31 01:35:15: [2024-10-31 01:35:15] iter = 12990, loss = 2.6501
2024-10-31 01:35:18: [2024-10-31 01:35:18] iter = 13000, loss = 1.6748
2024-10-31 01:35:22: [2024-10-31 01:35:22] iter = 13010, loss = 3.3738
2024-10-31 01:35:25: [2024-10-31 01:35:25] iter = 13020, loss = 1.8071
2024-10-31 01:35:28: [2024-10-31 01:35:28] iter = 13030, loss = 2.4137
2024-10-31 01:35:31: [2024-10-31 01:35:31] iter = 13040, loss = 4.9964
2024-10-31 01:35:35: [2024-10-31 01:35:35] iter = 13050, loss = 2.0859
2024-10-31 01:35:38: [2024-10-31 01:35:38] iter = 13060, loss = 1.8285
2024-10-31 01:35:41: [2024-10-31 01:35:41] iter = 13070, loss = 1.8206
2024-10-31 01:35:44: [2024-10-31 01:35:44] iter = 13080, loss = 2.1944
2024-10-31 01:35:47: [2024-10-31 01:35:47] iter = 13090, loss = 1.8916
2024-10-31 01:35:51: [2024-10-31 01:35:51] iter = 13100, loss = 3.6613
2024-10-31 01:35:54: [2024-10-31 01:35:54] iter = 13110, loss = 2.1153
2024-10-31 01:35:57: [2024-10-31 01:35:57] iter = 13120, loss = 2.3759
2024-10-31 01:35:59: [2024-10-31 01:35:59] iter = 13130, loss = 2.6659
2024-10-31 01:36:03: [2024-10-31 01:36:03] iter = 13140, loss = 1.9737
2024-10-31 01:36:05: [2024-10-31 01:36:05] iter = 13150, loss = 1.7434
2024-10-31 01:36:08: [2024-10-31 01:36:08] iter = 13160, loss = 2.1367
2024-10-31 01:36:12: [2024-10-31 01:36:12] iter = 13170, loss = 2.2832
2024-10-31 01:36:14: [2024-10-31 01:36:14] iter = 13180, loss = 1.9040
2024-10-31 01:36:18: [2024-10-31 01:36:18] iter = 13190, loss = 2.3742
2024-10-31 01:36:21: [2024-10-31 01:36:21] iter = 13200, loss = 2.6286
2024-10-31 01:36:25: [2024-10-31 01:36:25] iter = 13210, loss = 2.0736
2024-10-31 01:36:28: [2024-10-31 01:36:28] iter = 13220, loss = 2.0333
2024-10-31 01:36:30: [2024-10-31 01:36:30] iter = 13230, loss = 2.0680
2024-10-31 01:36:33: [2024-10-31 01:36:33] iter = 13240, loss = 2.2956
2024-10-31 01:36:36: [2024-10-31 01:36:36] iter = 13250, loss = 1.9131
2024-10-31 01:36:40: [2024-10-31 01:36:40] iter = 13260, loss = 2.6738
2024-10-31 01:36:44: [2024-10-31 01:36:44] iter = 13270, loss = 2.2651
2024-10-31 01:36:48: [2024-10-31 01:36:48] iter = 13280, loss = 3.3982
2024-10-31 01:36:51: [2024-10-31 01:36:51] iter = 13290, loss = 2.5392
2024-10-31 01:36:55: [2024-10-31 01:36:55] iter = 13300, loss = 2.0550
2024-10-31 01:36:58: [2024-10-31 01:36:58] iter = 13310, loss = 1.9538
2024-10-31 01:37:01: [2024-10-31 01:37:01] iter = 13320, loss = 2.0186
2024-10-31 01:37:04: [2024-10-31 01:37:04] iter = 13330, loss = 2.1707
2024-10-31 01:37:07: [2024-10-31 01:37:07] iter = 13340, loss = 2.0680
2024-10-31 01:37:09: [2024-10-31 01:37:09] iter = 13350, loss = 2.0070
2024-10-31 01:37:13: [2024-10-31 01:37:13] iter = 13360, loss = 2.8922
2024-10-31 01:37:16: [2024-10-31 01:37:16] iter = 13370, loss = 2.2001
2024-10-31 01:37:20: [2024-10-31 01:37:20] iter = 13380, loss = 2.5197
2024-10-31 01:37:24: [2024-10-31 01:37:24] iter = 13390, loss = 1.9819
2024-10-31 01:37:27: [2024-10-31 01:37:27] iter = 13400, loss = 2.1686
2024-10-31 01:37:31: [2024-10-31 01:37:30] iter = 13410, loss = 3.0954
2024-10-31 01:37:34: [2024-10-31 01:37:34] iter = 13420, loss = 2.0492
2024-10-31 01:37:36: [2024-10-31 01:37:36] iter = 13430, loss = 2.0923
2024-10-31 01:37:39: [2024-10-31 01:37:39] iter = 13440, loss = 2.1415
2024-10-31 01:37:43: [2024-10-31 01:37:43] iter = 13450, loss = 2.3177
2024-10-31 01:37:45: [2024-10-31 01:37:45] iter = 13460, loss = 2.0944
2024-10-31 01:37:49: [2024-10-31 01:37:49] iter = 13470, loss = 1.9943
2024-10-31 01:37:51: [2024-10-31 01:37:51] iter = 13480, loss = 3.9743
2024-10-31 01:37:54: [2024-10-31 01:37:54] iter = 13490, loss = 2.0465
2024-10-31 01:37:57: [2024-10-31 01:37:57] iter = 13500, loss = 2.1166
2024-10-31 01:38:00: [2024-10-31 01:38:00] iter = 13510, loss = 1.9997
2024-10-31 01:38:04: [2024-10-31 01:38:04] iter = 13520, loss = 1.8158
2024-10-31 01:38:07: [2024-10-31 01:38:07] iter = 13530, loss = 3.6343
2024-10-31 01:38:10: [2024-10-31 01:38:10] iter = 13540, loss = 1.9829
2024-10-31 01:38:13: [2024-10-31 01:38:13] iter = 13550, loss = 2.4687
2024-10-31 01:38:17: [2024-10-31 01:38:17] iter = 13560, loss = 2.3553
2024-10-31 01:38:20: [2024-10-31 01:38:20] iter = 13570, loss = 2.1363
2024-10-31 01:38:23: [2024-10-31 01:38:23] iter = 13580, loss = 3.7432
2024-10-31 01:38:27: [2024-10-31 01:38:27] iter = 13590, loss = 2.9009
2024-10-31 01:38:30: [2024-10-31 01:38:29] iter = 13600, loss = 2.2156
2024-10-31 01:38:33: [2024-10-31 01:38:33] iter = 13610, loss = 1.8842
2024-10-31 01:38:36: [2024-10-31 01:38:36] iter = 13620, loss = 2.3748
2024-10-31 01:38:39: [2024-10-31 01:38:39] iter = 13630, loss = 4.3252
2024-10-31 01:38:42: [2024-10-31 01:38:42] iter = 13640, loss = 2.6557
2024-10-31 01:38:45: [2024-10-31 01:38:45] iter = 13650, loss = 2.0701
2024-10-31 01:38:49: [2024-10-31 01:38:49] iter = 13660, loss = 2.3205
2024-10-31 01:38:52: [2024-10-31 01:38:52] iter = 13670, loss = 2.5987
2024-10-31 01:38:56: [2024-10-31 01:38:56] iter = 13680, loss = 2.6731
2024-10-31 01:38:58: [2024-10-31 01:38:58] iter = 13690, loss = 3.1231
2024-10-31 01:39:01: [2024-10-31 01:39:01] iter = 13700, loss = 1.8887
2024-10-31 01:39:04: [2024-10-31 01:39:04] iter = 13710, loss = 2.6489
2024-10-31 01:39:07: [2024-10-31 01:39:07] iter = 13720, loss = 1.8409
2024-10-31 01:39:11: [2024-10-31 01:39:11] iter = 13730, loss = 1.8017
2024-10-31 01:39:14: [2024-10-31 01:39:14] iter = 13740, loss = 1.8311
2024-10-31 01:39:18: [2024-10-31 01:39:18] iter = 13750, loss = 1.8499
2024-10-31 01:39:21: [2024-10-31 01:39:21] iter = 13760, loss = 2.4707
2024-10-31 01:39:24: [2024-10-31 01:39:24] iter = 13770, loss = 1.9359
2024-10-31 01:39:27: [2024-10-31 01:39:27] iter = 13780, loss = 2.2868
2024-10-31 01:39:31: [2024-10-31 01:39:31] iter = 13790, loss = 2.2126
2024-10-31 01:39:33: [2024-10-31 01:39:33] iter = 13800, loss = 3.1806
2024-10-31 01:39:37: [2024-10-31 01:39:37] iter = 13810, loss = 6.1894
2024-10-31 01:39:40: [2024-10-31 01:39:40] iter = 13820, loss = 1.9708
2024-10-31 01:39:44: [2024-10-31 01:39:44] iter = 13830, loss = 2.1942
2024-10-31 01:39:48: [2024-10-31 01:39:48] iter = 13840, loss = 2.6038
2024-10-31 01:39:52: [2024-10-31 01:39:52] iter = 13850, loss = 2.1460
2024-10-31 01:39:55: [2024-10-31 01:39:55] iter = 13860, loss = 2.3822
2024-10-31 01:39:59: [2024-10-31 01:39:59] iter = 13870, loss = 2.0321
2024-10-31 01:40:02: [2024-10-31 01:40:02] iter = 13880, loss = 2.2047
2024-10-31 01:40:06: [2024-10-31 01:40:06] iter = 13890, loss = 1.9952
2024-10-31 01:40:09: [2024-10-31 01:40:09] iter = 13900, loss = 2.9308
2024-10-31 01:40:13: [2024-10-31 01:40:13] iter = 13910, loss = 2.7375
2024-10-31 01:40:17: [2024-10-31 01:40:17] iter = 13920, loss = 2.2317
2024-10-31 01:40:20: [2024-10-31 01:40:20] iter = 13930, loss = 2.1907
2024-10-31 01:40:24: [2024-10-31 01:40:24] iter = 13940, loss = 3.4214
2024-10-31 01:40:26: [2024-10-31 01:40:26] iter = 13950, loss = 1.8960
2024-10-31 01:40:29: [2024-10-31 01:40:29] iter = 13960, loss = 2.9387
2024-10-31 01:40:32: [2024-10-31 01:40:32] iter = 13970, loss = 1.8982
2024-10-31 01:40:35: [2024-10-31 01:40:35] iter = 13980, loss = 1.9114
2024-10-31 01:40:39: [2024-10-31 01:40:38] iter = 13990, loss = 2.1798
2024-10-31 01:40:41: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-31 01:40:41: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:40:41: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 41834}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:42:47: Evaluate 5 random ConvNet, ACCmean = 0.6028 ACCstd = 0.0064
-------------------------
2024-10-31 01:42:47: Evaluate 5 random ConvNet, SENmean = 0.5862 SENstd = 0.0059
-------------------------
2024-10-31 01:42:47: Evaluate 5 random ConvNet, SPEmean = 0.9595 SPEstd = 0.0007
-------------------------
2024-10-31 01:42:47: Evaluate 5 random ConvNet, F!mean = 0.5760 F!std = 0.0051
-------------------------
2024-10-31 01:42:47: Evaluate 5 random ConvNet, mean = 0.6028 std = 0.0064
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:42:47: [2024-10-31 01:42:47] iter = 14000, loss = 2.6166
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:42:51: [2024-10-31 01:42:51] iter = 14010, loss = 2.4291
2024-10-31 01:42:53: [2024-10-31 01:42:53] iter = 14020, loss = 2.7648
2024-10-31 01:42:57: [2024-10-31 01:42:57] iter = 14030, loss = 2.9100
2024-10-31 01:43:00: [2024-10-31 01:43:00] iter = 14040, loss = 1.8557
2024-10-31 01:43:03: [2024-10-31 01:43:03] iter = 14050, loss = 2.3774
2024-10-31 01:43:05: [2024-10-31 01:43:05] iter = 14060, loss = 1.9833
2024-10-31 01:43:08: [2024-10-31 01:43:08] iter = 14070, loss = 1.9666
2024-10-31 01:43:11: [2024-10-31 01:43:11] iter = 14080, loss = 2.6042
2024-10-31 01:43:13: [2024-10-31 01:43:13] iter = 14090, loss = 2.5654
2024-10-31 01:43:16: [2024-10-31 01:43:16] iter = 14100, loss = 3.4686
2024-10-31 01:43:19: [2024-10-31 01:43:19] iter = 14110, loss = 2.2881
2024-10-31 01:43:23: [2024-10-31 01:43:23] iter = 14120, loss = 2.0059
2024-10-31 01:43:25: [2024-10-31 01:43:25] iter = 14130, loss = 2.5086
2024-10-31 01:43:28: [2024-10-31 01:43:28] iter = 14140, loss = 2.0073
2024-10-31 01:43:31: [2024-10-31 01:43:31] iter = 14150, loss = 1.8338
2024-10-31 01:43:34: [2024-10-31 01:43:34] iter = 14160, loss = 2.2127
2024-10-31 01:43:37: [2024-10-31 01:43:37] iter = 14170, loss = 1.9734
2024-10-31 01:43:40: [2024-10-31 01:43:40] iter = 14180, loss = 1.9553
2024-10-31 01:43:43: [2024-10-31 01:43:43] iter = 14190, loss = 2.6233
2024-10-31 01:43:46: [2024-10-31 01:43:46] iter = 14200, loss = 1.8712
2024-10-31 01:43:49: [2024-10-31 01:43:49] iter = 14210, loss = 5.0956
2024-10-31 01:43:52: [2024-10-31 01:43:52] iter = 14220, loss = 2.4497
2024-10-31 01:43:55: [2024-10-31 01:43:55] iter = 14230, loss = 2.6403
2024-10-31 01:43:57: [2024-10-31 01:43:57] iter = 14240, loss = 2.2143
2024-10-31 01:44:01: [2024-10-31 01:44:01] iter = 14250, loss = 2.2214
2024-10-31 01:44:04: [2024-10-31 01:44:04] iter = 14260, loss = 2.2561
2024-10-31 01:44:06: [2024-10-31 01:44:06] iter = 14270, loss = 2.4392
2024-10-31 01:44:09: [2024-10-31 01:44:09] iter = 14280, loss = 2.0769
2024-10-31 01:44:13: [2024-10-31 01:44:13] iter = 14290, loss = 2.3277
2024-10-31 01:44:16: [2024-10-31 01:44:16] iter = 14300, loss = 2.8084
2024-10-31 01:44:19: [2024-10-31 01:44:19] iter = 14310, loss = 1.9240
2024-10-31 01:44:23: [2024-10-31 01:44:23] iter = 14320, loss = 1.7089
2024-10-31 01:44:27: [2024-10-31 01:44:27] iter = 14330, loss = 2.2428
2024-10-31 01:44:30: [2024-10-31 01:44:30] iter = 14340, loss = 2.1750
2024-10-31 01:44:33: [2024-10-31 01:44:33] iter = 14350, loss = 2.3928
2024-10-31 01:44:35: [2024-10-31 01:44:35] iter = 14360, loss = 1.9771
2024-10-31 01:44:38: [2024-10-31 01:44:38] iter = 14370, loss = 2.6034
2024-10-31 01:44:41: [2024-10-31 01:44:41] iter = 14380, loss = 2.0445
2024-10-31 01:44:44: [2024-10-31 01:44:44] iter = 14390, loss = 3.4922
2024-10-31 01:44:48: [2024-10-31 01:44:48] iter = 14400, loss = 2.2144
2024-10-31 01:44:51: [2024-10-31 01:44:51] iter = 14410, loss = 2.5902
2024-10-31 01:44:55: [2024-10-31 01:44:55] iter = 14420, loss = 2.1849
2024-10-31 01:44:59: [2024-10-31 01:44:59] iter = 14430, loss = 1.8019
2024-10-31 01:45:02: [2024-10-31 01:45:02] iter = 14440, loss = 2.3238
2024-10-31 01:45:05: [2024-10-31 01:45:05] iter = 14450, loss = 2.5336
2024-10-31 01:45:08: [2024-10-31 01:45:08] iter = 14460, loss = 2.1831
2024-10-31 01:45:11: [2024-10-31 01:45:11] iter = 14470, loss = 2.2061
2024-10-31 01:45:15: [2024-10-31 01:45:15] iter = 14480, loss = 2.4771
2024-10-31 01:45:19: [2024-10-31 01:45:19] iter = 14490, loss = 1.8979
2024-10-31 01:45:22: [2024-10-31 01:45:22] iter = 14500, loss = 2.0602
2024-10-31 01:45:25: [2024-10-31 01:45:25] iter = 14510, loss = 3.1670
2024-10-31 01:45:29: [2024-10-31 01:45:29] iter = 14520, loss = 1.7811
2024-10-31 01:45:32: [2024-10-31 01:45:32] iter = 14530, loss = 1.9367
2024-10-31 01:45:35: [2024-10-31 01:45:35] iter = 14540, loss = 1.9781
2024-10-31 01:45:38: [2024-10-31 01:45:38] iter = 14550, loss = 2.0270
2024-10-31 01:45:41: [2024-10-31 01:45:41] iter = 14560, loss = 1.8630
2024-10-31 01:45:43: [2024-10-31 01:45:43] iter = 14570, loss = 1.9330
2024-10-31 01:45:46: [2024-10-31 01:45:46] iter = 14580, loss = 2.2717
2024-10-31 01:45:49: [2024-10-31 01:45:49] iter = 14590, loss = 1.7740
2024-10-31 01:45:52: [2024-10-31 01:45:52] iter = 14600, loss = 2.3317
2024-10-31 01:45:56: [2024-10-31 01:45:56] iter = 14610, loss = 3.9409
2024-10-31 01:45:59: [2024-10-31 01:45:59] iter = 14620, loss = 2.5340
2024-10-31 01:46:03: [2024-10-31 01:46:03] iter = 14630, loss = 2.7578
2024-10-31 01:46:06: [2024-10-31 01:46:06] iter = 14640, loss = 2.5034
2024-10-31 01:46:10: [2024-10-31 01:46:10] iter = 14650, loss = 2.5221
2024-10-31 01:46:13: [2024-10-31 01:46:13] iter = 14660, loss = 2.4376
2024-10-31 01:46:16: [2024-10-31 01:46:16] iter = 14670, loss = 2.6974
2024-10-31 01:46:19: [2024-10-31 01:46:19] iter = 14680, loss = 1.9238
2024-10-31 01:46:21: [2024-10-31 01:46:21] iter = 14690, loss = 3.9264
2024-10-31 01:46:24: [2024-10-31 01:46:24] iter = 14700, loss = 2.5989
2024-10-31 01:46:28: [2024-10-31 01:46:28] iter = 14710, loss = 2.6188
2024-10-31 01:46:32: [2024-10-31 01:46:32] iter = 14720, loss = 2.5651
2024-10-31 01:46:36: [2024-10-31 01:46:36] iter = 14730, loss = 2.4775
2024-10-31 01:46:39: [2024-10-31 01:46:39] iter = 14740, loss = 2.4581
2024-10-31 01:46:42: [2024-10-31 01:46:42] iter = 14750, loss = 2.6331
2024-10-31 01:46:46: [2024-10-31 01:46:46] iter = 14760, loss = 1.9231
2024-10-31 01:46:50: [2024-10-31 01:46:50] iter = 14770, loss = 2.0353
2024-10-31 01:46:53: [2024-10-31 01:46:53] iter = 14780, loss = 2.5478
2024-10-31 01:46:57: [2024-10-31 01:46:57] iter = 14790, loss = 2.5873
2024-10-31 01:46:59: [2024-10-31 01:46:59] iter = 14800, loss = 2.1570
2024-10-31 01:47:03: [2024-10-31 01:47:03] iter = 14810, loss = 1.9345
2024-10-31 01:47:06: [2024-10-31 01:47:06] iter = 14820, loss = 3.8401
2024-10-31 01:47:11: [2024-10-31 01:47:11] iter = 14830, loss = 2.5054
2024-10-31 01:47:14: [2024-10-31 01:47:14] iter = 14840, loss = 2.2736
2024-10-31 01:47:18: [2024-10-31 01:47:18] iter = 14850, loss = 1.8595
2024-10-31 01:47:22: [2024-10-31 01:47:22] iter = 14860, loss = 1.9797
2024-10-31 01:47:26: [2024-10-31 01:47:26] iter = 14870, loss = 2.2498
2024-10-31 01:47:29: [2024-10-31 01:47:29] iter = 14880, loss = 2.0860
2024-10-31 01:47:34: [2024-10-31 01:47:34] iter = 14890, loss = 1.8294
2024-10-31 01:47:38: [2024-10-31 01:47:38] iter = 14900, loss = 1.6638
2024-10-31 01:47:42: [2024-10-31 01:47:42] iter = 14910, loss = 1.7176
2024-10-31 01:47:45: [2024-10-31 01:47:45] iter = 14920, loss = 2.7076
2024-10-31 01:47:49: [2024-10-31 01:47:49] iter = 14930, loss = 2.5590
2024-10-31 01:47:52: [2024-10-31 01:47:52] iter = 14940, loss = 2.4120
2024-10-31 01:47:56: [2024-10-31 01:47:56] iter = 14950, loss = 2.3003
2024-10-31 01:47:58: [2024-10-31 01:47:58] iter = 14960, loss = 2.0486
2024-10-31 01:48:01: [2024-10-31 01:48:01] iter = 14970, loss = 2.2322
2024-10-31 01:48:04: [2024-10-31 01:48:04] iter = 14980, loss = 2.2986
2024-10-31 01:48:08: [2024-10-31 01:48:08] iter = 14990, loss = 2.8560
2024-10-31 01:48:11: [2024-10-31 01:48:11] iter = 15000, loss = 2.1547
2024-10-31 01:48:15: [2024-10-31 01:48:15] iter = 15010, loss = 1.9892
2024-10-31 01:48:19: [2024-10-31 01:48:19] iter = 15020, loss = 3.1206
2024-10-31 01:48:23: [2024-10-31 01:48:23] iter = 15030, loss = 2.0356
2024-10-31 01:48:27: [2024-10-31 01:48:27] iter = 15040, loss = 2.2397
2024-10-31 01:48:30: [2024-10-31 01:48:30] iter = 15050, loss = 2.1645
2024-10-31 01:48:33: [2024-10-31 01:48:33] iter = 15060, loss = 2.4364
2024-10-31 01:48:36: [2024-10-31 01:48:36] iter = 15070, loss = 4.0244
2024-10-31 01:48:39: [2024-10-31 01:48:39] iter = 15080, loss = 1.9830
2024-10-31 01:48:42: [2024-10-31 01:48:42] iter = 15090, loss = 2.3181
2024-10-31 01:48:47: [2024-10-31 01:48:47] iter = 15100, loss = 2.3489
2024-10-31 01:48:50: [2024-10-31 01:48:50] iter = 15110, loss = 2.1302
2024-10-31 01:48:53: [2024-10-31 01:48:53] iter = 15120, loss = 2.1530
2024-10-31 01:48:57: [2024-10-31 01:48:57] iter = 15130, loss = 2.2383
2024-10-31 01:49:01: [2024-10-31 01:49:01] iter = 15140, loss = 2.0222
2024-10-31 01:49:05: [2024-10-31 01:49:05] iter = 15150, loss = 1.9647
2024-10-31 01:49:09: [2024-10-31 01:49:09] iter = 15160, loss = 2.1334
2024-10-31 01:49:11: [2024-10-31 01:49:11] iter = 15170, loss = 2.1516
2024-10-31 01:49:15: [2024-10-31 01:49:15] iter = 15180, loss = 2.3214
2024-10-31 01:49:17: [2024-10-31 01:49:17] iter = 15190, loss = 2.0846
2024-10-31 01:49:20: [2024-10-31 01:49:20] iter = 15200, loss = 1.9329
2024-10-31 01:49:23: [2024-10-31 01:49:23] iter = 15210, loss = 1.8034
2024-10-31 01:49:27: [2024-10-31 01:49:27] iter = 15220, loss = 1.9344
2024-10-31 01:49:30: [2024-10-31 01:49:30] iter = 15230, loss = 2.0848
2024-10-31 01:49:33: [2024-10-31 01:49:33] iter = 15240, loss = 2.8330
2024-10-31 01:49:37: [2024-10-31 01:49:37] iter = 15250, loss = 2.4528
2024-10-31 01:49:39: [2024-10-31 01:49:39] iter = 15260, loss = 2.5344
2024-10-31 01:49:42: [2024-10-31 01:49:42] iter = 15270, loss = 1.8549
2024-10-31 01:49:45: [2024-10-31 01:49:45] iter = 15280, loss = 2.2033
2024-10-31 01:49:48: [2024-10-31 01:49:48] iter = 15290, loss = 2.6471
2024-10-31 01:49:51: [2024-10-31 01:49:51] iter = 15300, loss = 2.0653
2024-10-31 01:49:54: [2024-10-31 01:49:54] iter = 15310, loss = 2.0115
2024-10-31 01:49:57: [2024-10-31 01:49:57] iter = 15320, loss = 2.9569
2024-10-31 01:50:00: [2024-10-31 01:50:00] iter = 15330, loss = 2.2139
2024-10-31 01:50:04: [2024-10-31 01:50:04] iter = 15340, loss = 2.2772
2024-10-31 01:50:07: [2024-10-31 01:50:07] iter = 15350, loss = 2.1411
2024-10-31 01:50:10: [2024-10-31 01:50:10] iter = 15360, loss = 2.3099
2024-10-31 01:50:13: [2024-10-31 01:50:13] iter = 15370, loss = 2.4613
2024-10-31 01:50:16: [2024-10-31 01:50:16] iter = 15380, loss = 4.1850
2024-10-31 01:50:20: [2024-10-31 01:50:20] iter = 15390, loss = 2.5545
2024-10-31 01:50:23: [2024-10-31 01:50:23] iter = 15400, loss = 2.1579
2024-10-31 01:50:26: [2024-10-31 01:50:26] iter = 15410, loss = 2.5097
2024-10-31 01:50:30: [2024-10-31 01:50:30] iter = 15420, loss = 2.2167
2024-10-31 01:50:33: [2024-10-31 01:50:33] iter = 15430, loss = 1.9267
2024-10-31 01:50:36: [2024-10-31 01:50:36] iter = 15440, loss = 1.7964
2024-10-31 01:50:39: [2024-10-31 01:50:39] iter = 15450, loss = 2.2681
2024-10-31 01:50:42: [2024-10-31 01:50:42] iter = 15460, loss = 1.9561
2024-10-31 01:50:45: [2024-10-31 01:50:45] iter = 15470, loss = 3.2572
2024-10-31 01:50:48: [2024-10-31 01:50:48] iter = 15480, loss = 2.5240
2024-10-31 01:50:52: [2024-10-31 01:50:52] iter = 15490, loss = 2.0263
2024-10-31 01:50:55: [2024-10-31 01:50:55] iter = 15500, loss = 1.9493
2024-10-31 01:50:58: [2024-10-31 01:50:58] iter = 15510, loss = 4.1118
2024-10-31 01:51:01: [2024-10-31 01:51:01] iter = 15520, loss = 2.3226
2024-10-31 01:51:04: [2024-10-31 01:51:04] iter = 15530, loss = 4.3590
2024-10-31 01:51:07: [2024-10-31 01:51:07] iter = 15540, loss = 2.2111
2024-10-31 01:51:10: [2024-10-31 01:51:10] iter = 15550, loss = 2.0457
2024-10-31 01:51:15: [2024-10-31 01:51:15] iter = 15560, loss = 2.5358
2024-10-31 01:51:18: [2024-10-31 01:51:18] iter = 15570, loss = 2.4403
2024-10-31 01:51:21: [2024-10-31 01:51:21] iter = 15580, loss = 1.8975
2024-10-31 01:51:24: [2024-10-31 01:51:24] iter = 15590, loss = 1.8805
2024-10-31 01:51:28: [2024-10-31 01:51:28] iter = 15600, loss = 2.3040
2024-10-31 01:51:30: [2024-10-31 01:51:30] iter = 15610, loss = 2.8329
2024-10-31 01:51:32: [2024-10-31 01:51:32] iter = 15620, loss = 2.4888
2024-10-31 01:51:35: [2024-10-31 01:51:35] iter = 15630, loss = 1.9605
2024-10-31 01:51:38: [2024-10-31 01:51:38] iter = 15640, loss = 1.9148
2024-10-31 01:51:41: [2024-10-31 01:51:41] iter = 15650, loss = 2.1380
2024-10-31 01:51:44: [2024-10-31 01:51:44] iter = 15660, loss = 2.6113
2024-10-31 01:51:47: [2024-10-31 01:51:47] iter = 15670, loss = 2.9274
2024-10-31 01:51:50: [2024-10-31 01:51:50] iter = 15680, loss = 2.2412
2024-10-31 01:51:54: [2024-10-31 01:51:54] iter = 15690, loss = 2.4061
2024-10-31 01:51:58: [2024-10-31 01:51:58] iter = 15700, loss = 3.2940
2024-10-31 01:52:00: [2024-10-31 01:52:00] iter = 15710, loss = 1.9266
2024-10-31 01:52:03: [2024-10-31 01:52:03] iter = 15720, loss = 6.9158
2024-10-31 01:52:06: [2024-10-31 01:52:06] iter = 15730, loss = 1.7170
2024-10-31 01:52:10: [2024-10-31 01:52:10] iter = 15740, loss = 2.9911
2024-10-31 01:52:14: [2024-10-31 01:52:14] iter = 15750, loss = 2.3289
2024-10-31 01:52:18: [2024-10-31 01:52:17] iter = 15760, loss = 3.6496
2024-10-31 01:52:20: [2024-10-31 01:52:20] iter = 15770, loss = 2.4503
2024-10-31 01:52:23: [2024-10-31 01:52:23] iter = 15780, loss = 1.9924
2024-10-31 01:52:27: [2024-10-31 01:52:27] iter = 15790, loss = 1.8598
2024-10-31 01:52:30: [2024-10-31 01:52:30] iter = 15800, loss = 2.5707
2024-10-31 01:52:34: [2024-10-31 01:52:34] iter = 15810, loss = 2.2659
2024-10-31 01:52:37: [2024-10-31 01:52:37] iter = 15820, loss = 1.8524
2024-10-31 01:52:39: [2024-10-31 01:52:39] iter = 15830, loss = 2.4210
2024-10-31 01:52:42: [2024-10-31 01:52:42] iter = 15840, loss = 1.8699
2024-10-31 01:52:44: [2024-10-31 01:52:44] iter = 15850, loss = 1.9001
2024-10-31 01:52:47: [2024-10-31 01:52:47] iter = 15860, loss = 3.6537
2024-10-31 01:52:50: [2024-10-31 01:52:50] iter = 15870, loss = 4.5049
2024-10-31 01:52:54: [2024-10-31 01:52:54] iter = 15880, loss = 2.5136
2024-10-31 01:52:57: [2024-10-31 01:52:57] iter = 15890, loss = 3.0748
2024-10-31 01:53:01: [2024-10-31 01:53:01] iter = 15900, loss = 2.6042
2024-10-31 01:53:04: [2024-10-31 01:53:04] iter = 15910, loss = 2.2366
2024-10-31 01:53:07: [2024-10-31 01:53:07] iter = 15920, loss = 2.1763
2024-10-31 01:53:10: [2024-10-31 01:53:10] iter = 15930, loss = 1.8514
2024-10-31 01:53:12: [2024-10-31 01:53:12] iter = 15940, loss = 2.0124
2024-10-31 01:53:16: [2024-10-31 01:53:16] iter = 15950, loss = 2.5870
2024-10-31 01:53:19: [2024-10-31 01:53:19] iter = 15960, loss = 2.7886
2024-10-31 01:53:23: [2024-10-31 01:53:23] iter = 15970, loss = 2.0536
2024-10-31 01:53:26: [2024-10-31 01:53:26] iter = 15980, loss = 2.3215
2024-10-31 01:53:29: [2024-10-31 01:53:29] iter = 15990, loss = 2.2729
2024-10-31 01:53:31: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-31 01:53:31: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:53:31: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 11759}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:55:42: Evaluate 5 random ConvNet, ACCmean = 0.6065 ACCstd = 0.0031
-------------------------
2024-10-31 01:55:42: Evaluate 5 random ConvNet, SENmean = 0.5932 SENstd = 0.0059
-------------------------
2024-10-31 01:55:42: Evaluate 5 random ConvNet, SPEmean = 0.9598 SPEstd = 0.0004
-------------------------
2024-10-31 01:55:42: Evaluate 5 random ConvNet, F!mean = 0.5801 F!std = 0.0055
-------------------------
2024-10-31 01:55:42: Evaluate 5 random ConvNet, mean = 0.6065 std = 0.0031
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:55:43: [2024-10-31 01:55:43] iter = 16000, loss = 2.0052
2024-10-31 01:55:46: [2024-10-31 01:55:46] iter = 16010, loss = 2.3330
2024-10-31 01:55:49: [2024-10-31 01:55:49] iter = 16020, loss = 2.0305
2024-10-31 01:55:52: [2024-10-31 01:55:52] iter = 16030, loss = 2.7926
2024-10-31 01:55:55: [2024-10-31 01:55:55] iter = 16040, loss = 2.9705
2024-10-31 01:55:58: [2024-10-31 01:55:58] iter = 16050, loss = 2.1734
2024-10-31 01:56:02: [2024-10-31 01:56:02] iter = 16060, loss = 2.0416
2024-10-31 01:56:05: [2024-10-31 01:56:05] iter = 16070, loss = 2.1210
2024-10-31 01:56:09: [2024-10-31 01:56:09] iter = 16080, loss = 4.7672
2024-10-31 01:56:13: [2024-10-31 01:56:13] iter = 16090, loss = 3.5205
2024-10-31 01:56:16: [2024-10-31 01:56:16] iter = 16100, loss = 2.8024
2024-10-31 01:56:20: [2024-10-31 01:56:20] iter = 16110, loss = 3.1729
2024-10-31 01:56:24: [2024-10-31 01:56:24] iter = 16120, loss = 3.3684
2024-10-31 01:56:27: [2024-10-31 01:56:27] iter = 16130, loss = 2.7069
2024-10-31 01:56:30: [2024-10-31 01:56:30] iter = 16140, loss = 1.9749
2024-10-31 01:56:34: [2024-10-31 01:56:34] iter = 16150, loss = 2.0907
2024-10-31 01:56:37: [2024-10-31 01:56:37] iter = 16160, loss = 1.9778
2024-10-31 01:56:42: [2024-10-31 01:56:42] iter = 16170, loss = 2.2659
2024-10-31 01:56:45: [2024-10-31 01:56:45] iter = 16180, loss = 2.3938
2024-10-31 01:56:47: [2024-10-31 01:56:47] iter = 16190, loss = 1.8575
2024-10-31 01:56:50: [2024-10-31 01:56:50] iter = 16200, loss = 2.2525
2024-10-31 01:56:54: [2024-10-31 01:56:54] iter = 16210, loss = 1.9448
2024-10-31 01:56:58: [2024-10-31 01:56:58] iter = 16220, loss = 1.8673
2024-10-31 01:57:01: [2024-10-31 01:57:01] iter = 16230, loss = 1.9529
2024-10-31 01:57:04: [2024-10-31 01:57:04] iter = 16240, loss = 2.6274
2024-10-31 01:57:08: [2024-10-31 01:57:08] iter = 16250, loss = 2.1161
2024-10-31 01:57:11: [2024-10-31 01:57:11] iter = 16260, loss = 1.8783
2024-10-31 01:57:15: [2024-10-31 01:57:15] iter = 16270, loss = 2.0626
2024-10-31 01:57:19: [2024-10-31 01:57:19] iter = 16280, loss = 1.9690
2024-10-31 01:57:22: [2024-10-31 01:57:22] iter = 16290, loss = 2.2768
2024-10-31 01:57:25: [2024-10-31 01:57:25] iter = 16300, loss = 2.3679
2024-10-31 01:57:29: [2024-10-31 01:57:29] iter = 16310, loss = 2.3021
2024-10-31 01:57:33: [2024-10-31 01:57:33] iter = 16320, loss = 1.9955
2024-10-31 01:57:37: [2024-10-31 01:57:37] iter = 16330, loss = 2.0888
2024-10-31 01:57:40: [2024-10-31 01:57:40] iter = 16340, loss = 1.7183
2024-10-31 01:57:43: [2024-10-31 01:57:43] iter = 16350, loss = 2.2172
2024-10-31 01:57:46: [2024-10-31 01:57:46] iter = 16360, loss = 2.3560
2024-10-31 01:57:48: [2024-10-31 01:57:48] iter = 16370, loss = 3.5540
2024-10-31 01:57:51: [2024-10-31 01:57:51] iter = 16380, loss = 2.7262
2024-10-31 01:57:54: [2024-10-31 01:57:54] iter = 16390, loss = 1.9873
2024-10-31 01:57:57: [2024-10-31 01:57:57] iter = 16400, loss = 2.6931
2024-10-31 01:57:59: [2024-10-31 01:57:59] iter = 16410, loss = 2.1733
2024-10-31 01:58:01: [2024-10-31 01:58:01] iter = 16420, loss = 1.9353
2024-10-31 01:58:04: [2024-10-31 01:58:04] iter = 16430, loss = 3.2153
2024-10-31 01:58:06: [2024-10-31 01:58:06] iter = 16440, loss = 1.9186
2024-10-31 01:58:08: [2024-10-31 01:58:08] iter = 16450, loss = 2.4714
2024-10-31 01:58:11: [2024-10-31 01:58:11] iter = 16460, loss = 3.1394
2024-10-31 01:58:15: [2024-10-31 01:58:15] iter = 16470, loss = 5.1443
2024-10-31 01:58:19: [2024-10-31 01:58:19] iter = 16480, loss = 2.9313
2024-10-31 01:58:22: [2024-10-31 01:58:22] iter = 16490, loss = 2.1806
2024-10-31 01:58:26: [2024-10-31 01:58:26] iter = 16500, loss = 1.8670
2024-10-31 01:58:29: [2024-10-31 01:58:29] iter = 16510, loss = 2.3534
2024-10-31 01:58:33: [2024-10-31 01:58:33] iter = 16520, loss = 2.2389
2024-10-31 01:58:37: [2024-10-31 01:58:37] iter = 16530, loss = 2.0117
2024-10-31 01:58:40: [2024-10-31 01:58:40] iter = 16540, loss = 2.0819
2024-10-31 01:58:43: [2024-10-31 01:58:43] iter = 16550, loss = 2.3853
2024-10-31 01:58:47: [2024-10-31 01:58:47] iter = 16560, loss = 2.1256
2024-10-31 01:58:50: [2024-10-31 01:58:50] iter = 16570, loss = 2.1012
2024-10-31 01:58:54: [2024-10-31 01:58:54] iter = 16580, loss = 1.8493
2024-10-31 01:58:57: [2024-10-31 01:58:57] iter = 16590, loss = 2.6551
2024-10-31 01:59:00: [2024-10-31 01:59:00] iter = 16600, loss = 2.0910
2024-10-31 01:59:02: [2024-10-31 01:59:02] iter = 16610, loss = 1.9751
2024-10-31 01:59:06: [2024-10-31 01:59:06] iter = 16620, loss = 2.7760
2024-10-31 01:59:09: [2024-10-31 01:59:09] iter = 16630, loss = 2.1087
2024-10-31 01:59:12: [2024-10-31 01:59:12] iter = 16640, loss = 2.0287
2024-10-31 01:59:15: [2024-10-31 01:59:15] iter = 16650, loss = 1.9589
2024-10-31 01:59:18: [2024-10-31 01:59:18] iter = 16660, loss = 2.4826
2024-10-31 01:59:22: [2024-10-31 01:59:22] iter = 16670, loss = 2.0506
2024-10-31 01:59:25: [2024-10-31 01:59:25] iter = 16680, loss = 1.9594
2024-10-31 01:59:28: [2024-10-31 01:59:28] iter = 16690, loss = 2.2275
2024-10-31 01:59:33: [2024-10-31 01:59:33] iter = 16700, loss = 2.0944
2024-10-31 01:59:36: [2024-10-31 01:59:36] iter = 16710, loss = 1.9771
2024-10-31 01:59:39: [2024-10-31 01:59:39] iter = 16720, loss = 2.2717
2024-10-31 01:59:43: [2024-10-31 01:59:43] iter = 16730, loss = 2.7114
2024-10-31 01:59:46: [2024-10-31 01:59:46] iter = 16740, loss = 1.8843
2024-10-31 01:59:49: [2024-10-31 01:59:49] iter = 16750, loss = 2.2051
2024-10-31 01:59:53: [2024-10-31 01:59:53] iter = 16760, loss = 3.1350
2024-10-31 01:59:56: [2024-10-31 01:59:56] iter = 16770, loss = 2.4305
2024-10-31 02:00:00: [2024-10-31 02:00:00] iter = 16780, loss = 2.5313
2024-10-31 02:00:03: [2024-10-31 02:00:03] iter = 16790, loss = 1.9828
2024-10-31 02:00:06: [2024-10-31 02:00:06] iter = 16800, loss = 2.3720
2024-10-31 02:00:09: [2024-10-31 02:00:09] iter = 16810, loss = 2.2831
2024-10-31 02:00:13: [2024-10-31 02:00:13] iter = 16820, loss = 3.3970
2024-10-31 02:00:16: [2024-10-31 02:00:16] iter = 16830, loss = 1.9166
2024-10-31 02:00:20: [2024-10-31 02:00:20] iter = 16840, loss = 2.1399
2024-10-31 02:00:24: [2024-10-31 02:00:24] iter = 16850, loss = 1.9721
2024-10-31 02:00:27: [2024-10-31 02:00:27] iter = 16860, loss = 2.4023
2024-10-31 02:00:31: [2024-10-31 02:00:31] iter = 16870, loss = 2.0173
2024-10-31 02:00:34: [2024-10-31 02:00:34] iter = 16880, loss = 2.1971
2024-10-31 02:00:37: [2024-10-31 02:00:37] iter = 16890, loss = 2.2259
2024-10-31 02:00:40: [2024-10-31 02:00:40] iter = 16900, loss = 2.8162
2024-10-31 02:00:44: [2024-10-31 02:00:44] iter = 16910, loss = 2.0631
2024-10-31 02:00:46: [2024-10-31 02:00:46] iter = 16920, loss = 2.0154
2024-10-31 02:00:49: [2024-10-31 02:00:49] iter = 16930, loss = 2.1972
2024-10-31 02:00:52: [2024-10-31 02:00:52] iter = 16940, loss = 1.9905
2024-10-31 02:00:55: [2024-10-31 02:00:55] iter = 16950, loss = 1.9973
2024-10-31 02:00:59: [2024-10-31 02:00:59] iter = 16960, loss = 2.6016
2024-10-31 02:01:03: [2024-10-31 02:01:03] iter = 16970, loss = 1.8657
2024-10-31 02:01:05: [2024-10-31 02:01:05] iter = 16980, loss = 2.5804
2024-10-31 02:01:08: [2024-10-31 02:01:08] iter = 16990, loss = 2.0256
2024-10-31 02:01:12: [2024-10-31 02:01:12] iter = 17000, loss = 2.8770
2024-10-31 02:01:14: [2024-10-31 02:01:14] iter = 17010, loss = 3.0915
2024-10-31 02:01:18: [2024-10-31 02:01:18] iter = 17020, loss = 2.1041
2024-10-31 02:01:20: [2024-10-31 02:01:20] iter = 17030, loss = 2.1019
2024-10-31 02:01:23: [2024-10-31 02:01:23] iter = 17040, loss = 2.2159
2024-10-31 02:01:26: [2024-10-31 02:01:26] iter = 17050, loss = 2.3660
2024-10-31 02:01:29: [2024-10-31 02:01:29] iter = 17060, loss = 1.7998
2024-10-31 02:01:33: [2024-10-31 02:01:33] iter = 17070, loss = 2.3084
2024-10-31 02:01:36: [2024-10-31 02:01:36] iter = 17080, loss = 2.6464
2024-10-31 02:01:39: [2024-10-31 02:01:39] iter = 17090, loss = 1.9811
2024-10-31 02:01:42: [2024-10-31 02:01:42] iter = 17100, loss = 1.8983
2024-10-31 02:01:45: [2024-10-31 02:01:45] iter = 17110, loss = 2.4688
2024-10-31 02:01:48: [2024-10-31 02:01:48] iter = 17120, loss = 2.0889
2024-10-31 02:01:52: [2024-10-31 02:01:52] iter = 17130, loss = 1.9960
2024-10-31 02:01:54: [2024-10-31 02:01:54] iter = 17140, loss = 4.8849
2024-10-31 02:01:58: [2024-10-31 02:01:58] iter = 17150, loss = 1.9768
2024-10-31 02:02:01: [2024-10-31 02:02:01] iter = 17160, loss = 2.2886
2024-10-31 02:02:04: [2024-10-31 02:02:04] iter = 17170, loss = 2.1245
2024-10-31 02:02:08: [2024-10-31 02:02:08] iter = 17180, loss = 2.3720
2024-10-31 02:02:11: [2024-10-31 02:02:11] iter = 17190, loss = 1.8722
2024-10-31 02:02:15: [2024-10-31 02:02:15] iter = 17200, loss = 2.0039
2024-10-31 02:02:17: [2024-10-31 02:02:17] iter = 17210, loss = 2.7575
2024-10-31 02:02:19: [2024-10-31 02:02:19] iter = 17220, loss = 2.4383
2024-10-31 02:02:22: [2024-10-31 02:02:22] iter = 17230, loss = 2.1954
2024-10-31 02:02:24: [2024-10-31 02:02:24] iter = 17240, loss = 2.3944
2024-10-31 02:02:27: [2024-10-31 02:02:27] iter = 17250, loss = 2.2024
2024-10-31 02:02:30: [2024-10-31 02:02:30] iter = 17260, loss = 1.9326
2024-10-31 02:02:33: [2024-10-31 02:02:33] iter = 17270, loss = 2.3347
2024-10-31 02:02:37: [2024-10-31 02:02:37] iter = 17280, loss = 1.8688
2024-10-31 02:02:40: [2024-10-31 02:02:40] iter = 17290, loss = 2.6167
2024-10-31 02:02:43: [2024-10-31 02:02:43] iter = 17300, loss = 2.0036
2024-10-31 02:02:46: [2024-10-31 02:02:46] iter = 17310, loss = 1.7331
2024-10-31 02:02:49: [2024-10-31 02:02:49] iter = 17320, loss = 2.1901
2024-10-31 02:02:53: [2024-10-31 02:02:53] iter = 17330, loss = 1.6507
2024-10-31 02:02:57: [2024-10-31 02:02:57] iter = 17340, loss = 2.5707
2024-10-31 02:03:00: [2024-10-31 02:03:00] iter = 17350, loss = 2.3774
2024-10-31 02:03:02: [2024-10-31 02:03:02] iter = 17360, loss = 2.4104
2024-10-31 02:03:06: [2024-10-31 02:03:06] iter = 17370, loss = 2.6201
2024-10-31 02:03:09: [2024-10-31 02:03:09] iter = 17380, loss = 2.3381
2024-10-31 02:03:13: [2024-10-31 02:03:13] iter = 17390, loss = 2.0137
2024-10-31 02:03:16: [2024-10-31 02:03:16] iter = 17400, loss = 2.2784
2024-10-31 02:03:20: [2024-10-31 02:03:20] iter = 17410, loss = 2.0356
2024-10-31 02:03:24: [2024-10-31 02:03:24] iter = 17420, loss = 2.7129
2024-10-31 02:03:28: [2024-10-31 02:03:28] iter = 17430, loss = 2.6100
2024-10-31 02:03:31: [2024-10-31 02:03:31] iter = 17440, loss = 2.1024
2024-10-31 02:03:34: [2024-10-31 02:03:34] iter = 17450, loss = 2.1453
2024-10-31 02:03:37: [2024-10-31 02:03:37] iter = 17460, loss = 2.0429
2024-10-31 02:03:39: [2024-10-31 02:03:39] iter = 17470, loss = 2.2036
2024-10-31 02:03:42: [2024-10-31 02:03:42] iter = 17480, loss = 1.7985
2024-10-31 02:03:46: [2024-10-31 02:03:46] iter = 17490, loss = 2.0986
2024-10-31 02:03:49: [2024-10-31 02:03:49] iter = 17500, loss = 2.4538
2024-10-31 02:03:52: [2024-10-31 02:03:52] iter = 17510, loss = 1.8899
2024-10-31 02:03:55: [2024-10-31 02:03:55] iter = 17520, loss = 3.1411
2024-10-31 02:03:58: [2024-10-31 02:03:58] iter = 17530, loss = 2.0820
2024-10-31 02:04:01: [2024-10-31 02:04:01] iter = 17540, loss = 2.9034
2024-10-31 02:04:04: [2024-10-31 02:04:04] iter = 17550, loss = 3.1156
2024-10-31 02:04:07: [2024-10-31 02:04:07] iter = 17560, loss = 2.1686
2024-10-31 02:04:09: [2024-10-31 02:04:09] iter = 17570, loss = 1.8586
2024-10-31 02:04:12: [2024-10-31 02:04:12] iter = 17580, loss = 2.2729
2024-10-31 02:04:15: [2024-10-31 02:04:15] iter = 17590, loss = 2.3656
2024-10-31 02:04:18: [2024-10-31 02:04:18] iter = 17600, loss = 2.1183
2024-10-31 02:04:21: [2024-10-31 02:04:21] iter = 17610, loss = 2.3171
2024-10-31 02:04:23: [2024-10-31 02:04:23] iter = 17620, loss = 1.9347
2024-10-31 02:04:26: [2024-10-31 02:04:26] iter = 17630, loss = 2.0248
2024-10-31 02:04:29: [2024-10-31 02:04:29] iter = 17640, loss = 2.0840
2024-10-31 02:04:32: [2024-10-31 02:04:32] iter = 17650, loss = 2.2996
2024-10-31 02:04:35: [2024-10-31 02:04:35] iter = 17660, loss = 1.8581
2024-10-31 02:04:39: [2024-10-31 02:04:39] iter = 17670, loss = 2.0553
2024-10-31 02:04:42: [2024-10-31 02:04:42] iter = 17680, loss = 2.9570
2024-10-31 02:04:45: [2024-10-31 02:04:45] iter = 17690, loss = 2.7076
2024-10-31 02:04:49: [2024-10-31 02:04:49] iter = 17700, loss = 1.8666
2024-10-31 02:04:52: [2024-10-31 02:04:52] iter = 17710, loss = 2.8596
2024-10-31 02:04:55: [2024-10-31 02:04:55] iter = 17720, loss = 2.9459
2024-10-31 02:04:57: [2024-10-31 02:04:57] iter = 17730, loss = 2.5122
2024-10-31 02:05:00: [2024-10-31 02:05:00] iter = 17740, loss = 2.3699
2024-10-31 02:05:03: [2024-10-31 02:05:03] iter = 17750, loss = 1.9319
2024-10-31 02:05:07: [2024-10-31 02:05:07] iter = 17760, loss = 2.2596
2024-10-31 02:05:10: [2024-10-31 02:05:10] iter = 17770, loss = 1.9189
2024-10-31 02:05:14: [2024-10-31 02:05:14] iter = 17780, loss = 2.3765
2024-10-31 02:05:16: [2024-10-31 02:05:16] iter = 17790, loss = 2.6130
2024-10-31 02:05:19: [2024-10-31 02:05:19] iter = 17800, loss = 2.0518
2024-10-31 02:05:22: [2024-10-31 02:05:22] iter = 17810, loss = 1.7348
2024-10-31 02:05:25: [2024-10-31 02:05:25] iter = 17820, loss = 1.9455
2024-10-31 02:05:29: [2024-10-31 02:05:29] iter = 17830, loss = 2.3199
2024-10-31 02:05:33: [2024-10-31 02:05:33] iter = 17840, loss = 2.2736
2024-10-31 02:05:37: [2024-10-31 02:05:37] iter = 17850, loss = 1.9531
2024-10-31 02:05:41: [2024-10-31 02:05:41] iter = 17860, loss = 2.1313
2024-10-31 02:05:45: [2024-10-31 02:05:45] iter = 17870, loss = 2.0055
2024-10-31 02:05:49: [2024-10-31 02:05:49] iter = 17880, loss = 4.3368
2024-10-31 02:05:52: [2024-10-31 02:05:52] iter = 17890, loss = 2.2199
2024-10-31 02:05:55: [2024-10-31 02:05:55] iter = 17900, loss = 3.2229
2024-10-31 02:05:59: [2024-10-31 02:05:59] iter = 17910, loss = 2.2901
2024-10-31 02:06:02: [2024-10-31 02:06:02] iter = 17920, loss = 1.9895
2024-10-31 02:06:06: [2024-10-31 02:06:06] iter = 17930, loss = 2.2168
2024-10-31 02:06:09: [2024-10-31 02:06:09] iter = 17940, loss = 2.5601
2024-10-31 02:06:12: [2024-10-31 02:06:12] iter = 17950, loss = 2.3022
2024-10-31 02:06:16: [2024-10-31 02:06:16] iter = 17960, loss = 2.4450
2024-10-31 02:06:19: [2024-10-31 02:06:19] iter = 17970, loss = 2.4477
2024-10-31 02:06:22: [2024-10-31 02:06:22] iter = 17980, loss = 2.2406
2024-10-31 02:06:26: [2024-10-31 02:06:26] iter = 17990, loss = 1.9868
2024-10-31 02:06:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-31 02:06:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:06:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 89403}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:08:37: Evaluate 5 random ConvNet, ACCmean = 0.6162 ACCstd = 0.0047
-------------------------
2024-10-31 02:08:37: Evaluate 5 random ConvNet, SENmean = 0.5991 SENstd = 0.0033
-------------------------
2024-10-31 02:08:37: Evaluate 5 random ConvNet, SPEmean = 0.9609 SPEstd = 0.0004
-------------------------
2024-10-31 02:08:37: Evaluate 5 random ConvNet, F!mean = 0.5886 F!std = 0.0038
-------------------------
2024-10-31 02:08:37: Evaluate 5 random ConvNet, mean = 0.6162 std = 0.0047
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:08:37: [2024-10-31 02:08:37] iter = 18000, loss = 1.9040
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:08:39: [2024-10-31 02:08:39] iter = 18010, loss = 2.8061
2024-10-31 02:08:42: [2024-10-31 02:08:42] iter = 18020, loss = 2.0775
2024-10-31 02:08:44: [2024-10-31 02:08:44] iter = 18030, loss = 2.4621
2024-10-31 02:08:47: [2024-10-31 02:08:47] iter = 18040, loss = 2.0904
2024-10-31 02:08:50: [2024-10-31 02:08:50] iter = 18050, loss = 2.3286
2024-10-31 02:08:52: [2024-10-31 02:08:52] iter = 18060, loss = 2.2425
2024-10-31 02:08:55: [2024-10-31 02:08:55] iter = 18070, loss = 2.1242
2024-10-31 02:08:57: [2024-10-31 02:08:57] iter = 18080, loss = 2.6443
2024-10-31 02:09:00: [2024-10-31 02:09:00] iter = 18090, loss = 1.7750
2024-10-31 02:09:03: [2024-10-31 02:09:03] iter = 18100, loss = 1.9424
2024-10-31 02:09:06: [2024-10-31 02:09:06] iter = 18110, loss = 2.0821
2024-10-31 02:09:09: [2024-10-31 02:09:09] iter = 18120, loss = 3.1958
2024-10-31 02:09:12: [2024-10-31 02:09:12] iter = 18130, loss = 2.3503
2024-10-31 02:09:15: [2024-10-31 02:09:15] iter = 18140, loss = 2.2938
2024-10-31 02:09:18: [2024-10-31 02:09:18] iter = 18150, loss = 2.7189
2024-10-31 02:09:21: [2024-10-31 02:09:21] iter = 18160, loss = 2.5895
2024-10-31 02:09:24: [2024-10-31 02:09:24] iter = 18170, loss = 2.1771
2024-10-31 02:09:28: [2024-10-31 02:09:28] iter = 18180, loss = 1.7657
2024-10-31 02:09:31: [2024-10-31 02:09:31] iter = 18190, loss = 3.1465
2024-10-31 02:09:35: [2024-10-31 02:09:35] iter = 18200, loss = 2.5063
2024-10-31 02:09:38: [2024-10-31 02:09:38] iter = 18210, loss = 2.4393
2024-10-31 02:09:42: [2024-10-31 02:09:42] iter = 18220, loss = 1.8194
2024-10-31 02:09:45: [2024-10-31 02:09:45] iter = 18230, loss = 2.4188
2024-10-31 02:09:48: [2024-10-31 02:09:48] iter = 18240, loss = 2.2726
2024-10-31 02:09:52: [2024-10-31 02:09:52] iter = 18250, loss = 2.0736
2024-10-31 02:09:54: [2024-10-31 02:09:54] iter = 18260, loss = 1.9718
2024-10-31 02:09:57: [2024-10-31 02:09:57] iter = 18270, loss = 2.6046
2024-10-31 02:09:59: [2024-10-31 02:09:59] iter = 18280, loss = 2.3579
2024-10-31 02:10:02: [2024-10-31 02:10:02] iter = 18290, loss = 2.3421
2024-10-31 02:10:06: [2024-10-31 02:10:06] iter = 18300, loss = 2.6147
2024-10-31 02:10:09: [2024-10-31 02:10:09] iter = 18310, loss = 2.7011
2024-10-31 02:10:12: [2024-10-31 02:10:12] iter = 18320, loss = 2.4384
2024-10-31 02:10:16: [2024-10-31 02:10:16] iter = 18330, loss = 2.1731
2024-10-31 02:10:19: [2024-10-31 02:10:19] iter = 18340, loss = 2.2378
2024-10-31 02:10:22: [2024-10-31 02:10:22] iter = 18350, loss = 2.2480
2024-10-31 02:10:25: [2024-10-31 02:10:25] iter = 18360, loss = 2.0505
2024-10-31 02:10:28: [2024-10-31 02:10:28] iter = 18370, loss = 1.7313
2024-10-31 02:10:31: [2024-10-31 02:10:31] iter = 18380, loss = 1.6527
2024-10-31 02:10:35: [2024-10-31 02:10:35] iter = 18390, loss = 2.1115
2024-10-31 02:10:38: [2024-10-31 02:10:38] iter = 18400, loss = 1.9414
2024-10-31 02:10:41: [2024-10-31 02:10:41] iter = 18410, loss = 2.1869
2024-10-31 02:10:45: [2024-10-31 02:10:45] iter = 18420, loss = 1.9500
2024-10-31 02:10:48: [2024-10-31 02:10:48] iter = 18430, loss = 2.1227
2024-10-31 02:10:51: [2024-10-31 02:10:51] iter = 18440, loss = 2.1395
2024-10-31 02:10:55: [2024-10-31 02:10:55] iter = 18450, loss = 1.7392
2024-10-31 02:10:58: [2024-10-31 02:10:58] iter = 18460, loss = 2.6385
2024-10-31 02:11:01: [2024-10-31 02:11:01] iter = 18470, loss = 3.9425
2024-10-31 02:11:04: [2024-10-31 02:11:04] iter = 18480, loss = 2.1490
2024-10-31 02:11:08: [2024-10-31 02:11:08] iter = 18490, loss = 2.3248
2024-10-31 02:11:11: [2024-10-31 02:11:11] iter = 18500, loss = 2.3031
2024-10-31 02:11:15: [2024-10-31 02:11:15] iter = 18510, loss = 1.9493
2024-10-31 02:11:18: [2024-10-31 02:11:18] iter = 18520, loss = 2.0523
2024-10-31 02:11:21: [2024-10-31 02:11:21] iter = 18530, loss = 1.8905
2024-10-31 02:11:24: [2024-10-31 02:11:24] iter = 18540, loss = 2.0030
2024-10-31 02:11:27: [2024-10-31 02:11:27] iter = 18550, loss = 3.1753
2024-10-31 02:11:31: [2024-10-31 02:11:31] iter = 18560, loss = 2.0458
2024-10-31 02:11:36: [2024-10-31 02:11:36] iter = 18570, loss = 1.8536
2024-10-31 02:11:39: [2024-10-31 02:11:39] iter = 18580, loss = 2.7153
2024-10-31 02:11:43: [2024-10-31 02:11:43] iter = 18590, loss = 1.9063
2024-10-31 02:11:46: [2024-10-31 02:11:46] iter = 18600, loss = 2.0159
2024-10-31 02:11:50: [2024-10-31 02:11:50] iter = 18610, loss = 2.8174
2024-10-31 02:11:53: [2024-10-31 02:11:53] iter = 18620, loss = 2.5232
2024-10-31 02:11:56: [2024-10-31 02:11:56] iter = 18630, loss = 2.2211
2024-10-31 02:12:00: [2024-10-31 02:12:00] iter = 18640, loss = 2.1871
2024-10-31 02:12:03: [2024-10-31 02:12:03] iter = 18650, loss = 1.9112
2024-10-31 02:12:05: [2024-10-31 02:12:05] iter = 18660, loss = 2.6195
2024-10-31 02:12:08: [2024-10-31 02:12:08] iter = 18670, loss = 4.7628
2024-10-31 02:12:11: [2024-10-31 02:12:11] iter = 18680, loss = 2.4480
2024-10-31 02:12:14: [2024-10-31 02:12:14] iter = 18690, loss = 2.1349
2024-10-31 02:12:18: [2024-10-31 02:12:18] iter = 18700, loss = 1.9776
2024-10-31 02:12:21: [2024-10-31 02:12:21] iter = 18710, loss = 1.8363
2024-10-31 02:12:25: [2024-10-31 02:12:25] iter = 18720, loss = 2.4169
2024-10-31 02:12:28: [2024-10-31 02:12:28] iter = 18730, loss = 2.0140
2024-10-31 02:12:32: [2024-10-31 02:12:32] iter = 18740, loss = 2.0538
2024-10-31 02:12:35: [2024-10-31 02:12:35] iter = 18750, loss = 1.8405
2024-10-31 02:12:39: [2024-10-31 02:12:39] iter = 18760, loss = 3.2512
2024-10-31 02:12:42: [2024-10-31 02:12:42] iter = 18770, loss = 2.0043
2024-10-31 02:12:45: [2024-10-31 02:12:45] iter = 18780, loss = 2.3498
2024-10-31 02:12:49: [2024-10-31 02:12:49] iter = 18790, loss = 3.1102
2024-10-31 02:12:52: [2024-10-31 02:12:52] iter = 18800, loss = 2.2200
2024-10-31 02:12:55: [2024-10-31 02:12:55] iter = 18810, loss = 2.1376
2024-10-31 02:12:57: [2024-10-31 02:12:57] iter = 18820, loss = 2.0241
2024-10-31 02:12:59: [2024-10-31 02:12:59] iter = 18830, loss = 1.9040
2024-10-31 02:13:02: [2024-10-31 02:13:02] iter = 18840, loss = 2.0270
2024-10-31 02:13:05: [2024-10-31 02:13:05] iter = 18850, loss = 5.2337
2024-10-31 02:13:09: [2024-10-31 02:13:09] iter = 18860, loss = 4.6741
2024-10-31 02:13:12: [2024-10-31 02:13:12] iter = 18870, loss = 2.1160
2024-10-31 02:13:14: [2024-10-31 02:13:14] iter = 18880, loss = 1.9645
2024-10-31 02:13:15: [2024-10-31 02:13:15] iter = 18890, loss = 1.7810
2024-10-31 02:13:18: [2024-10-31 02:13:18] iter = 18900, loss = 1.8657
2024-10-31 02:13:20: [2024-10-31 02:13:20] iter = 18910, loss = 2.0015
2024-10-31 02:13:23: [2024-10-31 02:13:23] iter = 18920, loss = 1.9126
2024-10-31 02:13:27: [2024-10-31 02:13:27] iter = 18930, loss = 2.4193
2024-10-31 02:13:29: [2024-10-31 02:13:29] iter = 18940, loss = 1.9465
2024-10-31 02:13:32: [2024-10-31 02:13:32] iter = 18950, loss = 1.7303
2024-10-31 02:13:35: [2024-10-31 02:13:35] iter = 18960, loss = 2.3540
2024-10-31 02:13:38: [2024-10-31 02:13:38] iter = 18970, loss = 2.8825
2024-10-31 02:13:40: [2024-10-31 02:13:40] iter = 18980, loss = 2.6025
2024-10-31 02:13:43: [2024-10-31 02:13:43] iter = 18990, loss = 4.3680
2024-10-31 02:13:45: [2024-10-31 02:13:45] iter = 19000, loss = 2.4303
2024-10-31 02:13:49: [2024-10-31 02:13:49] iter = 19010, loss = 1.9560
2024-10-31 02:13:51: [2024-10-31 02:13:51] iter = 19020, loss = 1.9434
2024-10-31 02:13:54: [2024-10-31 02:13:54] iter = 19030, loss = 3.8103
2024-10-31 02:13:56: [2024-10-31 02:13:56] iter = 19040, loss = 2.1846
2024-10-31 02:13:58: [2024-10-31 02:13:58] iter = 19050, loss = 2.0648
2024-10-31 02:14:01: [2024-10-31 02:14:01] iter = 19060, loss = 2.2291
2024-10-31 02:14:04: [2024-10-31 02:14:04] iter = 19070, loss = 2.6563
2024-10-31 02:14:06: [2024-10-31 02:14:06] iter = 19080, loss = 2.0385
2024-10-31 02:14:09: [2024-10-31 02:14:09] iter = 19090, loss = 1.7134
2024-10-31 02:14:12: [2024-10-31 02:14:12] iter = 19100, loss = 1.7854
2024-10-31 02:14:14: [2024-10-31 02:14:14] iter = 19110, loss = 1.9338
2024-10-31 02:14:17: [2024-10-31 02:14:17] iter = 19120, loss = 2.1034
2024-10-31 02:14:21: [2024-10-31 02:14:21] iter = 19130, loss = 2.1089
2024-10-31 02:14:24: [2024-10-31 02:14:24] iter = 19140, loss = 2.0916
2024-10-31 02:14:26: [2024-10-31 02:14:26] iter = 19150, loss = 2.3861
2024-10-31 02:14:28: [2024-10-31 02:14:28] iter = 19160, loss = 2.0940
2024-10-31 02:14:31: [2024-10-31 02:14:31] iter = 19170, loss = 2.3721
2024-10-31 02:14:33: [2024-10-31 02:14:33] iter = 19180, loss = 2.1683
2024-10-31 02:14:36: [2024-10-31 02:14:36] iter = 19190, loss = 2.0105
2024-10-31 02:14:38: [2024-10-31 02:14:38] iter = 19200, loss = 2.0105
2024-10-31 02:14:41: [2024-10-31 02:14:41] iter = 19210, loss = 2.2876
2024-10-31 02:14:44: [2024-10-31 02:14:44] iter = 19220, loss = 2.2789
2024-10-31 02:14:47: [2024-10-31 02:14:47] iter = 19230, loss = 2.1797
2024-10-31 02:14:50: [2024-10-31 02:14:50] iter = 19240, loss = 2.8851
2024-10-31 02:14:53: [2024-10-31 02:14:53] iter = 19250, loss = 2.1866
2024-10-31 02:14:56: [2024-10-31 02:14:56] iter = 19260, loss = 1.7824
2024-10-31 02:14:59: [2024-10-31 02:14:59] iter = 19270, loss = 1.9356
2024-10-31 02:15:02: [2024-10-31 02:15:02] iter = 19280, loss = 1.9558
2024-10-31 02:15:05: [2024-10-31 02:15:05] iter = 19290, loss = 3.2141
2024-10-31 02:15:08: [2024-10-31 02:15:08] iter = 19300, loss = 2.2763
2024-10-31 02:15:11: [2024-10-31 02:15:11] iter = 19310, loss = 1.9760
2024-10-31 02:15:14: [2024-10-31 02:15:14] iter = 19320, loss = 1.9781
2024-10-31 02:15:17: [2024-10-31 02:15:17] iter = 19330, loss = 2.4171
2024-10-31 02:15:19: [2024-10-31 02:15:19] iter = 19340, loss = 2.5836
2024-10-31 02:15:22: [2024-10-31 02:15:22] iter = 19350, loss = 1.8589
2024-10-31 02:15:25: [2024-10-31 02:15:25] iter = 19360, loss = 2.5947
2024-10-31 02:15:28: [2024-10-31 02:15:28] iter = 19370, loss = 2.3307
2024-10-31 02:15:30: [2024-10-31 02:15:30] iter = 19380, loss = 1.9926
2024-10-31 02:15:32: [2024-10-31 02:15:32] iter = 19390, loss = 2.3130
2024-10-31 02:15:35: [2024-10-31 02:15:35] iter = 19400, loss = 4.3707
2024-10-31 02:15:37: [2024-10-31 02:15:37] iter = 19410, loss = 2.5892
2024-10-31 02:15:40: [2024-10-31 02:15:40] iter = 19420, loss = 3.2660
2024-10-31 02:15:43: [2024-10-31 02:15:43] iter = 19430, loss = 2.1561
2024-10-31 02:15:45: [2024-10-31 02:15:45] iter = 19440, loss = 2.1490
2024-10-31 02:15:48: [2024-10-31 02:15:48] iter = 19450, loss = 3.0022
2024-10-31 02:15:51: [2024-10-31 02:15:51] iter = 19460, loss = 2.6004
2024-10-31 02:15:53: [2024-10-31 02:15:53] iter = 19470, loss = 2.3665
2024-10-31 02:15:56: [2024-10-31 02:15:56] iter = 19480, loss = 1.9275
2024-10-31 02:15:59: [2024-10-31 02:15:59] iter = 19490, loss = 1.8642
2024-10-31 02:16:02: [2024-10-31 02:16:02] iter = 19500, loss = 2.4939
2024-10-31 02:16:04: [2024-10-31 02:16:04] iter = 19510, loss = 1.9585
2024-10-31 02:16:06: [2024-10-31 02:16:06] iter = 19520, loss = 2.1236
2024-10-31 02:16:09: [2024-10-31 02:16:09] iter = 19530, loss = 1.8918
2024-10-31 02:16:12: [2024-10-31 02:16:12] iter = 19540, loss = 2.0017
2024-10-31 02:16:15: [2024-10-31 02:16:15] iter = 19550, loss = 3.0418
2024-10-31 02:16:18: [2024-10-31 02:16:18] iter = 19560, loss = 1.7921
2024-10-31 02:16:21: [2024-10-31 02:16:21] iter = 19570, loss = 2.5044
2024-10-31 02:16:24: [2024-10-31 02:16:24] iter = 19580, loss = 2.0526
2024-10-31 02:16:27: [2024-10-31 02:16:27] iter = 19590, loss = 1.9167
2024-10-31 02:16:29: [2024-10-31 02:16:29] iter = 19600, loss = 2.2486
2024-10-31 02:16:31: [2024-10-31 02:16:31] iter = 19610, loss = 1.9386
2024-10-31 02:16:34: [2024-10-31 02:16:34] iter = 19620, loss = 1.8479
2024-10-31 02:16:36: [2024-10-31 02:16:36] iter = 19630, loss = 3.5722
2024-10-31 02:16:39: [2024-10-31 02:16:39] iter = 19640, loss = 2.2190
2024-10-31 02:16:42: [2024-10-31 02:16:42] iter = 19650, loss = 2.4070
2024-10-31 02:16:45: [2024-10-31 02:16:45] iter = 19660, loss = 2.7398
2024-10-31 02:16:47: [2024-10-31 02:16:47] iter = 19670, loss = 2.1359
2024-10-31 02:16:50: [2024-10-31 02:16:50] iter = 19680, loss = 2.6126
2024-10-31 02:16:53: [2024-10-31 02:16:53] iter = 19690, loss = 2.1463
2024-10-31 02:16:56: [2024-10-31 02:16:56] iter = 19700, loss = 2.4090
2024-10-31 02:17:00: [2024-10-31 02:17:00] iter = 19710, loss = 1.9392
2024-10-31 02:17:03: [2024-10-31 02:17:03] iter = 19720, loss = 1.9066
2024-10-31 02:17:05: [2024-10-31 02:17:05] iter = 19730, loss = 1.9165
2024-10-31 02:17:08: [2024-10-31 02:17:08] iter = 19740, loss = 6.1297
2024-10-31 02:17:11: [2024-10-31 02:17:11] iter = 19750, loss = 1.9176
2024-10-31 02:17:13: [2024-10-31 02:17:13] iter = 19760, loss = 2.1345
2024-10-31 02:17:17: [2024-10-31 02:17:17] iter = 19770, loss = 2.0958
2024-10-31 02:17:19: [2024-10-31 02:17:19] iter = 19780, loss = 2.1135
2024-10-31 02:17:21: [2024-10-31 02:17:21] iter = 19790, loss = 3.3012
2024-10-31 02:17:23: [2024-10-31 02:17:23] iter = 19800, loss = 2.1408
2024-10-31 02:17:26: [2024-10-31 02:17:26] iter = 19810, loss = 1.8393
2024-10-31 02:17:28: [2024-10-31 02:17:28] iter = 19820, loss = 2.0276
2024-10-31 02:17:31: [2024-10-31 02:17:31] iter = 19830, loss = 1.8628
2024-10-31 02:17:33: [2024-10-31 02:17:33] iter = 19840, loss = 1.8277
2024-10-31 02:17:36: [2024-10-31 02:17:36] iter = 19850, loss = 2.8889
2024-10-31 02:17:38: [2024-10-31 02:17:38] iter = 19860, loss = 2.2929
2024-10-31 02:17:41: [2024-10-31 02:17:41] iter = 19870, loss = 2.7233
2024-10-31 02:17:44: [2024-10-31 02:17:44] iter = 19880, loss = 3.5794
2024-10-31 02:17:46: [2024-10-31 02:17:46] iter = 19890, loss = 2.2598
2024-10-31 02:17:49: [2024-10-31 02:17:49] iter = 19900, loss = 2.4330
2024-10-31 02:17:51: [2024-10-31 02:17:51] iter = 19910, loss = 1.7888
2024-10-31 02:17:53: [2024-10-31 02:17:53] iter = 19920, loss = 2.1497
2024-10-31 02:17:55: [2024-10-31 02:17:55] iter = 19930, loss = 2.0470
2024-10-31 02:17:57: [2024-10-31 02:17:57] iter = 19940, loss = 2.3749
2024-10-31 02:18:00: [2024-10-31 02:18:00] iter = 19950, loss = 1.9539
2024-10-31 02:18:02: [2024-10-31 02:18:02] iter = 19960, loss = 1.8804
2024-10-31 02:18:05: [2024-10-31 02:18:05] iter = 19970, loss = 1.9325
2024-10-31 02:18:08: [2024-10-31 02:18:08] iter = 19980, loss = 2.6124
2024-10-31 02:18:11: [2024-10-31 02:18:11] iter = 19990, loss = 3.5994
2024-10-31 02:18:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-31 02:18:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:18:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 93424}

[2024-10-31 00:29:53] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.032057 train acc = 1.0000, test acc = 0.6200, test_sen =0.5968, test_spe =0.9611, test_f1 =0.5881
[2024-10-31 00:39:43] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.008880 train acc = 1.0000, test acc = 0.5610, test_sen =0.5659, test_spe =0.9554, test_f1 =0.5507
[2024-10-31 00:40:06] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.053028 train acc = 1.0000, test acc = 0.5646, test_sen =0.5650, test_spe =0.9555, test_f1 =0.5493
[2024-10-31 00:40:28] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.008815 train acc = 1.0000, test acc = 0.5702, test_sen =0.5709, test_spe =0.9562, test_f1 =0.5567
[2024-10-31 00:40:50] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.009407 train acc = 1.0000, test acc = 0.5686, test_sen =0.5716, test_spe =0.9561, test_f1 =0.5526
[2024-10-31 00:41:14] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.038521 train acc = 1.0000, test acc = 0.5761, test_sen =0.5745, test_spe =0.9567, test_f1 =0.5610
[2024-10-31 00:51:38] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.025184 train acc = 1.0000, test acc = 0.6145, test_sen =0.5980, test_spe =0.9607, test_f1 =0.5861
[2024-10-31 00:52:03] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.049966 train acc = 1.0000, test acc = 0.6097, test_sen =0.5984, test_spe =0.9602, test_f1 =0.5868
[2024-10-31 00:52:30] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.023900 train acc = 1.0000, test acc = 0.6187, test_sen =0.5998, test_spe =0.9611, test_f1 =0.5905
[2024-10-31 00:52:55] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.008765 train acc = 1.0000, test acc = 0.6009, test_sen =0.5899, test_spe =0.9594, test_f1 =0.5777
[2024-10-31 00:53:21] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.012418 train acc = 1.0000, test acc = 0.6157, test_sen =0.5992, test_spe =0.9608, test_f1 =0.5881
[2024-10-31 01:04:00] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.056667 train acc = 0.9909, test acc = 0.6031, test_sen =0.5858, test_spe =0.9595, test_f1 =0.5724
[2024-10-31 01:04:24] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.084060 train acc = 1.0000, test acc = 0.6094, test_sen =0.5871, test_spe =0.9601, test_f1 =0.5759
[2024-10-31 01:04:48] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.006581 train acc = 1.0000, test acc = 0.6128, test_sen =0.5931, test_spe =0.9606, test_f1 =0.5811
[2024-10-31 01:05:11] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.012306 train acc = 1.0000, test acc = 0.6164, test_sen =0.5917, test_spe =0.9607, test_f1 =0.5835
[2024-10-31 01:05:32] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.040709 train acc = 1.0000, test acc = 0.6054, test_sen =0.5857, test_spe =0.9599, test_f1 =0.5734
[2024-10-31 01:15:57] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.014583 train acc = 1.0000, test acc = 0.5985, test_sen =0.5735, test_spe =0.9590, test_f1 =0.5671
[2024-10-31 01:16:21] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.050416 train acc = 0.9909, test acc = 0.6061, test_sen =0.5835, test_spe =0.9598, test_f1 =0.5762
[2024-10-31 01:16:43] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.009336 train acc = 1.0000, test acc = 0.5960, test_sen =0.5757, test_spe =0.9588, test_f1 =0.5691
[2024-10-31 01:17:04] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.060972 train acc = 1.0000, test acc = 0.6054, test_sen =0.5848, test_spe =0.9597, test_f1 =0.5766
[2024-10-31 01:17:29] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.007484 train acc = 1.0000, test acc = 0.5940, test_sen =0.5726, test_spe =0.9585, test_f1 =0.5643
[2024-10-31 01:28:06] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.030170 train acc = 1.0000, test acc = 0.6026, test_sen =0.5872, test_spe =0.9594, test_f1 =0.5768
[2024-10-31 01:28:33] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.039060 train acc = 1.0000, test acc = 0.5930, test_sen =0.5761, test_spe =0.9583, test_f1 =0.5684
[2024-10-31 01:28:54] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.037403 train acc = 1.0000, test acc = 0.6060, test_sen =0.5820, test_spe =0.9597, test_f1 =0.5747
[2024-10-31 01:29:19] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.063099 train acc = 1.0000, test acc = 0.5996, test_sen =0.5828, test_spe =0.9589, test_f1 =0.5725
[2024-10-31 01:29:48] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.011481 train acc = 1.0000, test acc = 0.6079, test_sen =0.5889, test_spe =0.9599, test_f1 =0.5800
[2024-10-31 01:41:04] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.055924 train acc = 1.0000, test acc = 0.6088, test_sen =0.5911, test_spe =0.9601, test_f1 =0.5807
[2024-10-31 01:41:30] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.006443 train acc = 1.0000, test acc = 0.6036, test_sen =0.5878, test_spe =0.9597, test_f1 =0.5751
[2024-10-31 01:41:56] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.033366 train acc = 1.0000, test acc = 0.5940, test_sen =0.5775, test_spe =0.9586, test_f1 =0.5698
[2024-10-31 01:42:22] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.052451 train acc = 0.9909, test acc = 0.6104, test_sen =0.5933, test_spe =0.9604, test_f1 =0.5829
[2024-10-31 01:42:47] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.046410 train acc = 1.0000, test acc = 0.5970, test_sen =0.5814, test_spe =0.9589, test_f1 =0.5716
[2024-10-31 01:53:58] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.012209 train acc = 1.0000, test acc = 0.6046, test_sen =0.5902, test_spe =0.9596, test_f1 =0.5772
[2024-10-31 01:54:27] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.008510 train acc = 1.0000, test acc = 0.6039, test_sen =0.5888, test_spe =0.9595, test_f1 =0.5754
[2024-10-31 01:54:53] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.011859 train acc = 1.0000, test acc = 0.6039, test_sen =0.5865, test_spe =0.9595, test_f1 =0.5743
[2024-10-31 01:55:18] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.009240 train acc = 1.0000, test acc = 0.6118, test_sen =0.6016, test_spe =0.9605, test_f1 =0.5876
[2024-10-31 01:55:42] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.081402 train acc = 0.9909, test acc = 0.6081, test_sen =0.5988, test_spe =0.9600, test_f1 =0.5857
[2024-10-31 02:06:53] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.010812 train acc = 1.0000, test acc = 0.6071, test_sen =0.5934, test_spe =0.9600, test_f1 =0.5816
[2024-10-31 02:07:16] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.049135 train acc = 1.0000, test acc = 0.6201, test_sen =0.5997, test_spe =0.9611, test_f1 =0.5929
[2024-10-31 02:07:42] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.072590 train acc = 0.9909, test acc = 0.6164, test_sen =0.6032, test_spe =0.9611, test_f1 =0.5896
[2024-10-31 02:08:10] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.082748 train acc = 0.9909, test acc = 0.6178, test_sen =0.5980, test_spe =0.9610, test_f1 =0.5897
[2024-10-31 02:08:37] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.010238 train acc = 1.0000, test acc = 0.6193, test_sen =0.6009, test_spe =0.9611, test_f1 =0.5894
[2024-10-31 02:18:31] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.027472 train acc = 1.0000, test acc = 0.6224, test_sen =0.6077, test_spe =0.9614, test_f1 =0.6013
[2024-10-31 02:18:51] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.040902 train acc = 1.0000, test acc = 0.6016, test_sen =0.5892, test_spe =0.9593, test_f1 =0.5802
[2024-10-31 02:19:12] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.068120 train acc = 0.9909, test acc = 0.6119, test_sen =0.5956, test_spe =0.9604, test_f1 =0.5859
[2024-10-31 02:19:31] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.040744 train acc = 1.0000, test acc = 0.6182, test_sen =0.6054, test_spe =0.9611, test_f1 =0.5960
[2024-10-31 02:19:52] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.055629 train acc = 1.0000, test acc = 0.6079, test_sen =0.5999, test_spe =0.9601, test_f1 =0.5889/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:19:52: Evaluate 5 random ConvNet, ACCmean = 0.6124 ACCstd = 0.0074
-------------------------
2024-10-31 02:19:52: Evaluate 5 random ConvNet, SENmean = 0.5996 SENstd = 0.0067
-------------------------
2024-10-31 02:19:52: Evaluate 5 random ConvNet, SPEmean = 0.9604 SPEstd = 0.0008
-------------------------
2024-10-31 02:19:52: Evaluate 5 random ConvNet, F!mean = 0.5904 F!std = 0.0075
-------------------------
2024-10-31 02:19:52: Evaluate 5 random ConvNet, mean = 0.6124 std = 0.0074
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:19:52: [2024-10-31 02:19:52] iter = 20000, loss = 2.0266
2024-10-31 02:19:52: 
==================== Final Results ====================

2024-10-31 02:19:52: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 60.92%  std = 0.89%

