nohup: ignoring input
2024-11-21 18:20:32: eval_it_pool: [0, 500, 1000]
2024-11-21 18:20:33: 
================== Exp 0 ==================
 
2024-11-21 18:20:33: Hyper-parameters: 
{'method': 'DC', 'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f8c4dd3ea60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_ChestMNIST (INFO)>}
2024-11-21 18:20:33: Evaluation model pool: ['ConvNet']
2024-11-21 18:20:36: class c = 0: 70472 real images
2024-11-21 18:20:36: class c = 1: 7996 real images
2024-11-21 18:20:36: real images channel 0, mean = 0.4936, std = 0.2380
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_base.py:125: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 18:20:36: initialize synthetic data from random noise
2024-11-21 18:20:36: [2024-11-21 18:20:36] training begins
2024-11-21 18:20:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 18:20:36: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 18:20:46: Evaluate 5 random ConvNet, ACCmean = 0.2709 ACCstd = 0.1465
-------------------------
2024-11-21 18:20:46: Evaluate 5 random ConvNet, F1mean = 0.2454 F!std = 0.0961
-------------------------
2024-11-21 18:20:48: [2024-11-21 18:20:48] iter = 0000, loss = 327.4738
2024-11-21 18:21:11: [2024-11-21 18:21:11] iter = 0010, loss = 149.5928
2024-11-21 18:21:33: [2024-11-21 18:21:33] iter = 0020, loss = 106.9134
2024-11-21 18:21:56: [2024-11-21 18:21:56] iter = 0030, loss = 64.3167
2024-11-21 18:22:18: [2024-11-21 18:22:18] iter = 0040, loss = 56.8897
2024-11-21 18:22:41: [2024-11-21 18:22:41] iter = 0050, loss = 53.7341
2024-11-21 18:23:03: [2024-11-21 18:23:03] iter = 0060, loss = 48.2049
2024-11-21 18:23:25: [2024-11-21 18:23:25] iter = 0070, loss = 43.1980
2024-11-21 18:23:47: [2024-11-21 18:23:47] iter = 0080, loss = 40.6966
2024-11-21 18:24:10: [2024-11-21 18:24:10] iter = 0090, loss = 44.9911
2024-11-21 18:24:32: [2024-11-21 18:24:32] iter = 0100, loss = 37.2408
2024-11-21 18:24:55: [2024-11-21 18:24:55] iter = 0110, loss = 36.3185
2024-11-21 18:25:17: [2024-11-21 18:25:17] iter = 0120, loss = 39.2275
2024-11-21 18:25:38: [2024-11-21 18:25:38] iter = 0130, loss = 40.0940
2024-11-21 18:26:00: [2024-11-21 18:26:00] iter = 0140, loss = 35.0546
2024-11-21 18:26:23: [2024-11-21 18:26:23] iter = 0150, loss = 42.4728
2024-11-21 18:26:46: [2024-11-21 18:26:46] iter = 0160, loss = 36.2861
2024-11-21 18:27:09: [2024-11-21 18:27:09] iter = 0170, loss = 37.5120
2024-11-21 18:27:31: [2024-11-21 18:27:31] iter = 0180, loss = 36.3351
2024-11-21 18:27:54: [2024-11-21 18:27:54] iter = 0190, loss = 40.5198
2024-11-21 18:28:16: [2024-11-21 18:28:16] iter = 0200, loss = 40.8530
2024-11-21 18:28:39: [2024-11-21 18:28:39] iter = 0210, loss = 32.2028
2024-11-21 18:29:01: [2024-11-21 18:29:01] iter = 0220, loss = 37.5419
2024-11-21 18:29:23: [2024-11-21 18:29:23] iter = 0230, loss = 37.0539
2024-11-21 18:29:46: [2024-11-21 18:29:46] iter = 0240, loss = 35.5654
2024-11-21 18:30:08: [2024-11-21 18:30:08] iter = 0250, loss = 34.7784
2024-11-21 18:30:31: [2024-11-21 18:30:31] iter = 0260, loss = 29.4435
2024-11-21 18:30:52: [2024-11-21 18:30:52] iter = 0270, loss = 31.4170
2024-11-21 18:31:15: [2024-11-21 18:31:15] iter = 0280, loss = 35.7947
2024-11-21 18:31:38: [2024-11-21 18:31:38] iter = 0290, loss = 38.0460
2024-11-21 18:32:01: [2024-11-21 18:32:01] iter = 0300, loss = 36.9107
2024-11-21 18:32:22: [2024-11-21 18:32:22] iter = 0310, loss = 39.5998
2024-11-21 18:32:45: [2024-11-21 18:32:45] iter = 0320, loss = 27.7147
2024-11-21 18:33:08: [2024-11-21 18:33:08] iter = 0330, loss = 32.7657
2024-11-21 18:33:30: [2024-11-21 18:33:30] iter = 0340, loss = 32.3921
2024-11-21 18:33:53: [2024-11-21 18:33:53] iter = 0350, loss = 32.1254
2024-11-21 18:34:15: [2024-11-21 18:34:15] iter = 0360, loss = 32.4815
2024-11-21 18:34:37: [2024-11-21 18:34:37] iter = 0370, loss = 33.0999
2024-11-21 18:35:00: [2024-11-21 18:35:00] iter = 0380, loss = 35.3334
2024-11-21 18:35:23: [2024-11-21 18:35:23] iter = 0390, loss = 32.3101
2024-11-21 18:35:45: [2024-11-21 18:35:45] iter = 0400, loss = 31.7452
2024-11-21 18:36:08: [2024-11-21 18:36:08] iter = 0410, loss = 34.7519
2024-11-21 18:36:30: [2024-11-21 18:36:30] iter = 0420, loss = 37.8575
2024-11-21 18:36:52: [2024-11-21 18:36:52] iter = 0430, loss = 34.4475
2024-11-21 18:37:14: [2024-11-21 18:37:14] iter = 0440, loss = 34.6067
2024-11-21 18:37:36: [2024-11-21 18:37:36] iter = 0450, loss = 36.9030
2024-11-21 18:37:59: [2024-11-21 18:37:59] iter = 0460, loss = 35.0565
2024-11-21 18:38:21: [2024-11-21 18:38:21] iter = 0470, loss = 39.2432
2024-11-21 18:38:43: [2024-11-21 18:38:43] iter = 0480, loss = 32.9074
2024-11-21 18:39:06: [2024-11-21 18:39:06] iter = 0490, loss = 39.0542
2024-11-21 18:39:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 18:39:26: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 18:39:34: Evaluate 5 random ConvNet, ACCmean = 0.2016 ACCstd = 0.0211
-------------------------
2024-11-21 18:39:34: Evaluate 5 random ConvNet, F1mean = 0.2011 F!std = 0.0210
-------------------------
2024-11-21 18:39:36: [2024-11-21 18:39:36] iter = 0500, loss = 37.6385
2024-11-21 18:39:59: [2024-11-21 18:39:59] iter = 0510, loss = 35.6489
2024-11-21 18:40:21: [2024-11-21 18:40:21] iter = 0520, loss = 36.7816
2024-11-21 18:40:44: [2024-11-21 18:40:44] iter = 0530, loss = 37.6466
2024-11-21 18:41:06: [2024-11-21 18:41:06] iter = 0540, loss = 32.8914
2024-11-21 18:41:28: [2024-11-21 18:41:28] iter = 0550, loss = 37.9209
2024-11-21 18:41:51: [2024-11-21 18:41:51] iter = 0560, loss = 36.1816
2024-11-21 18:42:14: [2024-11-21 18:42:14] iter = 0570, loss = 32.8592
2024-11-21 18:42:37: [2024-11-21 18:42:37] iter = 0580, loss = 36.8136
2024-11-21 18:43:00: [2024-11-21 18:43:00] iter = 0590, loss = 35.7720
2024-11-21 18:43:22: [2024-11-21 18:43:22] iter = 0600, loss = 38.2738
2024-11-21 18:43:45: [2024-11-21 18:43:45] iter = 0610, loss = 35.3584
2024-11-21 18:44:07: [2024-11-21 18:44:07] iter = 0620, loss = 37.0228
2024-11-21 18:44:29: [2024-11-21 18:44:29] iter = 0630, loss = 41.9073
2024-11-21 18:44:50: [2024-11-21 18:44:50] iter = 0640, loss = 37.8785
2024-11-21 18:45:12: [2024-11-21 18:45:12] iter = 0650, loss = 41.2215
2024-11-21 18:45:35: [2024-11-21 18:45:35] iter = 0660, loss = 41.4821
2024-11-21 18:45:58: [2024-11-21 18:45:58] iter = 0670, loss = 36.5959
2024-11-21 18:46:20: [2024-11-21 18:46:20] iter = 0680, loss = 38.3454
2024-11-21 18:46:43: [2024-11-21 18:46:43] iter = 0690, loss = 36.7040
2024-11-21 18:47:06: [2024-11-21 18:47:06] iter = 0700, loss = 39.9347
2024-11-21 18:47:28: [2024-11-21 18:47:28] iter = 0710, loss = 38.7624
2024-11-21 18:47:51: [2024-11-21 18:47:51] iter = 0720, loss = 37.6651
2024-11-21 18:48:13: [2024-11-21 18:48:13] iter = 0730, loss = 38.8224
2024-11-21 18:48:35: [2024-11-21 18:48:35] iter = 0740, loss = 40.6007
2024-11-21 18:48:58: [2024-11-21 18:48:58] iter = 0750, loss = 44.4597
2024-11-21 18:49:18: [2024-11-21 18:49:18] iter = 0760, loss = 42.4202
2024-11-21 18:49:41: [2024-11-21 18:49:41] iter = 0770, loss = 38.1954
2024-11-21 18:50:03: [2024-11-21 18:50:03] iter = 0780, loss = 40.9000
2024-11-21 18:50:26: [2024-11-21 18:50:26] iter = 0790, loss = 43.6868
2024-11-21 18:50:48: [2024-11-21 18:50:48] iter = 0800, loss = 41.2377
2024-11-21 18:51:11: [2024-11-21 18:51:11] iter = 0810, loss = 41.3473
2024-11-21 18:51:32: [2024-11-21 18:51:32] iter = 0820, loss = 41.9855
2024-11-21 18:51:54: [2024-11-21 18:51:54] iter = 0830, loss = 41.9045
2024-11-21 18:52:17: [2024-11-21 18:52:17] iter = 0840, loss = 46.2809
2024-11-21 18:52:39: [2024-11-21 18:52:39] iter = 0850, loss = 44.7538
2024-11-21 18:53:01: [2024-11-21 18:53:01] iter = 0860, loss = 39.9186
2024-11-21 18:53:23: [2024-11-21 18:53:23] iter = 0870, loss = 48.0285
2024-11-21 18:53:46: [2024-11-21 18:53:46] iter = 0880, loss = 44.5280
2024-11-21 18:54:09: [2024-11-21 18:54:09] iter = 0890, loss = 39.9966
2024-11-21 18:54:31: [2024-11-21 18:54:31] iter = 0900, loss = 41.0938
2024-11-21 18:54:53: [2024-11-21 18:54:53] iter = 0910, loss = 45.4972
2024-11-21 18:55:15: [2024-11-21 18:55:15] iter = 0920, loss = 41.0789
2024-11-21 18:55:37: [2024-11-21 18:55:37] iter = 0930, loss = 39.4272
2024-11-21 18:55:59: [2024-11-21 18:55:59] iter = 0940, loss = 40.8923
2024-11-21 18:56:22: [2024-11-21 18:56:22] iter = 0950, loss = 40.2266
2024-11-21 18:56:45: [2024-11-21 18:56:45] iter = 0960, loss = 39.5985
2024-11-21 18:57:07: [2024-11-21 18:57:07] iter = 0970, loss = 42.9281
2024-11-21 18:57:31: [2024-11-21 18:57:31] iter = 0980, loss = 43.9044
2024-11-21 18:57:53: [2024-11-21 18:57:53] iter = 0990, loss = 42.3211
2024-11-21 18:58:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 18:58:13: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 18:58:22: Evaluate 5 random ConvNet, ACCmean = 0.4555 ACCstd = 0.0464
-------------------------
2024-11-21 18:58:22: Evaluate 5 random ConvNet, F1mean = 0.3947 F!std = 0.0272
-------------------------
2024-11-21 18:58:24: [2024-11-21 18:58:24] iter = 1000, loss = 44.0395
2024-11-21 18:58:24: 
================== Exp 1 ==================
 
2024-11-21 18:58:24: Hyper-parameters: 
{'method': 'DC', 'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f8c4dd3ea60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_ChestMNIST (INFO)>, 'dc_aug_param': None}
2024-11-21 18:58:24: Evaluation model pool: ['ConvNet']
2024-11-21 18:58:26: class c = 0: 70472 real images
2024-11-21 18:58:26: class c = 1: 7996 real images
2024-11-21 18:58:26: real images channel 0, mean = 0.4936, std = 0.2380
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 18:58:26: initialize synthetic data from random noise
2024-11-21 18:58:26: [2024-11-21 18:58:26] training begins
2024-11-21 18:58:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 18:58:26: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 18:58:35: Evaluate 5 random ConvNet, ACCmean = 0.1864 ACCstd = 0.0971
-------------------------
2024-11-21 18:58:35: Evaluate 5 random ConvNet, F1mean = 0.1754 F!std = 0.0856
-------------------------
2024-11-21 18:58:37: [2024-11-21 18:58:37] iter = 0000, loss = 321.2536
2024-11-21 18:58:59: [2024-11-21 18:58:59] iter = 0010, loss = 165.4301
2024-11-21 18:59:20: [2024-11-21 18:59:20] iter = 0020, loss = 91.5493
2024-11-21 18:59:43: [2024-11-21 18:59:43] iter = 0030, loss = 60.3253
2024-11-21 19:00:05: [2024-11-21 19:00:05] iter = 0040, loss = 55.5942
2024-11-21 19:00:28: [2024-11-21 19:00:28] iter = 0050, loss = 51.4214
2024-11-21 19:00:50: [2024-11-21 19:00:50] iter = 0060, loss = 50.4497
2024-11-21 19:01:12: [2024-11-21 19:01:12] iter = 0070, loss = 45.3702
2024-11-21 19:01:35: [2024-11-21 19:01:35] iter = 0080, loss = 52.0967
2024-11-21 19:01:58: [2024-11-21 19:01:58] iter = 0090, loss = 40.3581
2024-11-21 19:02:20: [2024-11-21 19:02:20] iter = 0100, loss = 42.1121
2024-11-21 19:02:43: [2024-11-21 19:02:43] iter = 0110, loss = 40.8246
2024-11-21 19:03:06: [2024-11-21 19:03:06] iter = 0120, loss = 36.8709
2024-11-21 19:03:28: [2024-11-21 19:03:28] iter = 0130, loss = 35.8178
2024-11-21 19:03:51: [2024-11-21 19:03:51] iter = 0140, loss = 41.5432
2024-11-21 19:04:14: [2024-11-21 19:04:14] iter = 0150, loss = 37.2114
2024-11-21 19:04:36: [2024-11-21 19:04:36] iter = 0160, loss = 36.4654
2024-11-21 19:04:59: [2024-11-21 19:04:59] iter = 0170, loss = 36.6524
2024-11-21 19:05:21: [2024-11-21 19:05:21] iter = 0180, loss = 42.6039
2024-11-21 19:05:44: [2024-11-21 19:05:44] iter = 0190, loss = 47.7937
2024-11-21 19:06:06: [2024-11-21 19:06:06] iter = 0200, loss = 46.8679
2024-11-21 19:06:30: [2024-11-21 19:06:30] iter = 0210, loss = 40.1881
2024-11-21 19:06:51: [2024-11-21 19:06:51] iter = 0220, loss = 39.7045
2024-11-21 19:07:13: [2024-11-21 19:07:13] iter = 0230, loss = 35.0170
2024-11-21 19:07:35: [2024-11-21 19:07:35] iter = 0240, loss = 37.3418
2024-11-21 19:07:57: [2024-11-21 19:07:57] iter = 0250, loss = 35.4436
2024-11-21 19:08:19: [2024-11-21 19:08:19] iter = 0260, loss = 30.3516
2024-11-21 19:08:42: [2024-11-21 19:08:42] iter = 0270, loss = 36.3721
2024-11-21 19:09:05: [2024-11-21 19:09:05] iter = 0280, loss = 31.5296
2024-11-21 19:09:29: [2024-11-21 19:09:29] iter = 0290, loss = 29.3838
2024-11-21 19:09:52: [2024-11-21 19:09:52] iter = 0300, loss = 31.9956
2024-11-21 19:10:14: [2024-11-21 19:10:14] iter = 0310, loss = 29.4608
2024-11-21 19:10:36: [2024-11-21 19:10:36] iter = 0320, loss = 32.1041
2024-11-21 19:10:59: [2024-11-21 19:10:59] iter = 0330, loss = 30.2587
2024-11-21 19:11:21: [2024-11-21 19:11:21] iter = 0340, loss = 40.0953
2024-11-21 19:11:43: [2024-11-21 19:11:43] iter = 0350, loss = 34.3356
2024-11-21 19:12:06: [2024-11-21 19:12:06] iter = 0360, loss = 34.3070
2024-11-21 19:12:28: [2024-11-21 19:12:28] iter = 0370, loss = 36.4380
2024-11-21 19:12:51: [2024-11-21 19:12:51] iter = 0380, loss = 34.3292
2024-11-21 19:13:13: [2024-11-21 19:13:13] iter = 0390, loss = 33.3434
2024-11-21 19:13:35: [2024-11-21 19:13:35] iter = 0400, loss = 30.6046
2024-11-21 19:13:58: [2024-11-21 19:13:58] iter = 0410, loss = 35.9173
2024-11-21 19:14:20: [2024-11-21 19:14:20] iter = 0420, loss = 34.5617
2024-11-21 19:14:43: [2024-11-21 19:14:43] iter = 0430, loss = 35.1024
2024-11-21 19:15:05: [2024-11-21 19:15:05] iter = 0440, loss = 34.8685
2024-11-21 19:15:28: [2024-11-21 19:15:28] iter = 0450, loss = 35.2804
2024-11-21 19:15:50: [2024-11-21 19:15:50] iter = 0460, loss = 33.1852
2024-11-21 19:16:12: [2024-11-21 19:16:12] iter = 0470, loss = 42.6423
2024-11-21 19:16:35: [2024-11-21 19:16:35] iter = 0480, loss = 34.3027
2024-11-21 19:16:57: [2024-11-21 19:16:57] iter = 0490, loss = 32.4252
2024-11-21 19:17:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 19:17:17: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 19:17:26: Evaluate 5 random ConvNet, ACCmean = 0.2169 ACCstd = 0.0310
-------------------------
2024-11-21 19:17:26: Evaluate 5 random ConvNet, F1mean = 0.2158 F!std = 0.0303
-------------------------
2024-11-21 19:17:28: [2024-11-21 19:17:28] iter = 0500, loss = 36.3342
2024-11-21 19:17:49: [2024-11-21 19:17:49] iter = 0510, loss = 35.0644
2024-11-21 19:18:13: [2024-11-21 19:18:13] iter = 0520, loss = 31.3156
2024-11-21 19:18:35: [2024-11-21 19:18:35] iter = 0530, loss = 36.4664
2024-11-21 19:18:57: [2024-11-21 19:18:57] iter = 0540, loss = 36.6979
2024-11-21 19:19:20: [2024-11-21 19:19:20] iter = 0550, loss = 35.7965
2024-11-21 19:19:42: [2024-11-21 19:19:42] iter = 0560, loss = 36.0108
2024-11-21 19:20:04: [2024-11-21 19:20:04] iter = 0570, loss = 34.8545
2024-11-21 19:20:27: [2024-11-21 19:20:27] iter = 0580, loss = 36.1008
2024-11-21 19:20:49: [2024-11-21 19:20:49] iter = 0590, loss = 41.0541
2024-11-21 19:21:11: [2024-11-21 19:21:11] iter = 0600, loss = 38.5939
2024-11-21 19:21:34: [2024-11-21 19:21:34] iter = 0610, loss = 38.6927
2024-11-21 19:21:57: [2024-11-21 19:21:57] iter = 0620, loss = 41.8577
2024-11-21 19:22:20: [2024-11-21 19:22:20] iter = 0630, loss = 44.5198
2024-11-21 19:22:42: [2024-11-21 19:22:42] iter = 0640, loss = 40.7664
2024-11-21 19:23:04: [2024-11-21 19:23:04] iter = 0650, loss = 37.5917
2024-11-21 19:23:26: [2024-11-21 19:23:26] iter = 0660, loss = 41.6445
2024-11-21 19:23:48: [2024-11-21 19:23:48] iter = 0670, loss = 38.7127
2024-11-21 19:24:10: [2024-11-21 19:24:10] iter = 0680, loss = 38.8385
2024-11-21 19:24:33: [2024-11-21 19:24:33] iter = 0690, loss = 34.0563
2024-11-21 19:24:56: [2024-11-21 19:24:56] iter = 0700, loss = 37.7986
2024-11-21 19:25:18: [2024-11-21 19:25:18] iter = 0710, loss = 46.4946
2024-11-21 19:25:39: [2024-11-21 19:25:39] iter = 0720, loss = 38.8134
2024-11-21 19:26:02: [2024-11-21 19:26:02] iter = 0730, loss = 43.8026
2024-11-21 19:26:23: [2024-11-21 19:26:23] iter = 0740, loss = 38.1856
2024-11-21 19:26:45: [2024-11-21 19:26:45] iter = 0750, loss = 44.7450
2024-11-21 19:27:08: [2024-11-21 19:27:08] iter = 0760, loss = 43.6455
2024-11-21 19:27:29: [2024-11-21 19:27:29] iter = 0770, loss = 39.3385
2024-11-21 19:27:52: [2024-11-21 19:27:52] iter = 0780, loss = 38.6994
2024-11-21 19:28:14: [2024-11-21 19:28:14] iter = 0790, loss = 40.9931
2024-11-21 19:28:36: [2024-11-21 19:28:36] iter = 0800, loss = 36.4485
2024-11-21 19:28:59: [2024-11-21 19:28:59] iter = 0810, loss = 39.1579
2024-11-21 19:29:21: [2024-11-21 19:29:21] iter = 0820, loss = 45.4975
2024-11-21 19:29:43: [2024-11-21 19:29:43] iter = 0830, loss = 36.4140
2024-11-21 19:30:05: [2024-11-21 19:30:05] iter = 0840, loss = 42.3060
2024-11-21 19:30:28: [2024-11-21 19:30:28] iter = 0850, loss = 37.6801
2024-11-21 19:30:50: [2024-11-21 19:30:50] iter = 0860, loss = 46.1859
2024-11-21 19:31:12: [2024-11-21 19:31:12] iter = 0870, loss = 46.8139
2024-11-21 19:31:35: [2024-11-21 19:31:35] iter = 0880, loss = 40.9654
2024-11-21 19:31:57: [2024-11-21 19:31:57] iter = 0890, loss = 45.9813
2024-11-21 19:32:19: [2024-11-21 19:32:19] iter = 0900, loss = 47.4503
2024-11-21 19:32:42: [2024-11-21 19:32:42] iter = 0910, loss = 41.1687
2024-11-21 19:33:04: [2024-11-21 19:33:04] iter = 0920, loss = 43.9191
2024-11-21 19:33:27: [2024-11-21 19:33:27] iter = 0930, loss = 40.0179
2024-11-21 19:33:49: [2024-11-21 19:33:49] iter = 0940, loss = 39.1015
2024-11-21 19:34:11: [2024-11-21 19:34:11] iter = 0950, loss = 47.0315
2024-11-21 19:34:33: [2024-11-21 19:34:33] iter = 0960, loss = 49.4199
2024-11-21 19:34:55: [2024-11-21 19:34:55] iter = 0970, loss = 39.7368
2024-11-21 19:35:19: [2024-11-21 19:35:19] iter = 0980, loss = 45.1773
2024-11-21 19:35:41: [2024-11-21 19:35:41] iter = 0990, loss = 45.9533
2024-11-21 19:36:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 19:36:01: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 19:36:10: Evaluate 5 random ConvNet, ACCmean = 0.4150 ACCstd = 0.0398
-------------------------
2024-11-21 19:36:10: Evaluate 5 random ConvNet, F1mean = 0.3760 F!std = 0.0269
-------------------------
2024-11-21 19:36:12: [2024-11-21 19:36:12] iter = 1000, loss = 45.1026
2024-11-21 19:36:12: 
================== Exp 2 ==================
 
2024-11-21 19:36:12: Hyper-parameters: 
{'method': 'DC', 'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f8c4dd3ea60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_ChestMNIST (INFO)>, 'dc_aug_param': None}
2024-11-21 19:36:12: Evaluation model pool: ['ConvNet']
2024-11-21 19:36:15: class c = 0: 70472 real images
2024-11-21 19:36:15: class c = 1: 7996 real images
2024-11-21 19:36:15: real images channel 0, mean = 0.4936, std = 0.2380
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 19:36:15: initialize synthetic data from random noise
2024-11-21 19:36:15: [2024-11-21 19:36:15] training begins
2024-11-21 19:36:15: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 19:36:15: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 19:36:24: Evaluate 5 random ConvNet, ACCmean = 0.6827 ACCstd = 0.0556
-------------------------
2024-11-21 19:36:24: Evaluate 5 random ConvNet, F1mean = 0.5053 F!std = 0.0172
-------------------------
2024-11-21 19:36:26: [2024-11-21 19:36:26] iter = 0000, loss = 322.3705
2024-11-21 19:36:47: [2024-11-21 19:36:47] iter = 0010, loss = 160.0876
2024-11-21 19:37:10: [2024-11-21 19:37:10] iter = 0020, loss = 106.5971
2024-11-21 19:37:32: [2024-11-21 19:37:32] iter = 0030, loss = 49.9683
2024-11-21 19:37:54: [2024-11-21 19:37:54] iter = 0040, loss = 55.7576
2024-11-21 19:38:16: [2024-11-21 19:38:16] iter = 0050, loss = 44.5234
2024-11-21 19:38:39: [2024-11-21 19:38:39] iter = 0060, loss = 38.6507
2024-11-21 19:39:01: [2024-11-21 19:39:01] iter = 0070, loss = 38.4317
2024-11-21 19:39:23: [2024-11-21 19:39:23] iter = 0080, loss = 41.6054
2024-11-21 19:39:46: [2024-11-21 19:39:46] iter = 0090, loss = 41.8889
2024-11-21 19:40:07: [2024-11-21 19:40:07] iter = 0100, loss = 38.4673
2024-11-21 19:40:30: [2024-11-21 19:40:30] iter = 0110, loss = 36.9769
2024-11-21 19:40:52: [2024-11-21 19:40:52] iter = 0120, loss = 45.8709
2024-11-21 19:41:14: [2024-11-21 19:41:14] iter = 0130, loss = 35.5513
2024-11-21 19:41:37: [2024-11-21 19:41:37] iter = 0140, loss = 36.8087
2024-11-21 19:41:59: [2024-11-21 19:41:59] iter = 0150, loss = 36.5957
2024-11-21 19:42:21: [2024-11-21 19:42:21] iter = 0160, loss = 42.8733
2024-11-21 19:42:44: [2024-11-21 19:42:44] iter = 0170, loss = 37.8708
2024-11-21 19:43:06: [2024-11-21 19:43:06] iter = 0180, loss = 35.9831
2024-11-21 19:43:29: [2024-11-21 19:43:29] iter = 0190, loss = 31.9074
2024-11-21 19:43:51: [2024-11-21 19:43:51] iter = 0200, loss = 36.7803
2024-11-21 19:44:13: [2024-11-21 19:44:13] iter = 0210, loss = 36.3123
2024-11-21 19:44:36: [2024-11-21 19:44:36] iter = 0220, loss = 34.8298
2024-11-21 19:44:58: [2024-11-21 19:44:58] iter = 0230, loss = 36.7465
2024-11-21 19:45:20: [2024-11-21 19:45:20] iter = 0240, loss = 34.9109
2024-11-21 19:45:42: [2024-11-21 19:45:42] iter = 0250, loss = 36.7421
2024-11-21 19:46:05: [2024-11-21 19:46:05] iter = 0260, loss = 34.4712
2024-11-21 19:46:28: [2024-11-21 19:46:28] iter = 0270, loss = 38.0997
2024-11-21 19:46:51: [2024-11-21 19:46:51] iter = 0280, loss = 35.8037
2024-11-21 19:47:13: [2024-11-21 19:47:13] iter = 0290, loss = 38.3288
2024-11-21 19:47:36: [2024-11-21 19:47:36] iter = 0300, loss = 32.9174
2024-11-21 19:47:58: [2024-11-21 19:47:58] iter = 0310, loss = 35.9081
2024-11-21 19:48:20: [2024-11-21 19:48:20] iter = 0320, loss = 41.0671
2024-11-21 19:48:42: [2024-11-21 19:48:42] iter = 0330, loss = 38.3685
2024-11-21 19:49:04: [2024-11-21 19:49:04] iter = 0340, loss = 32.3199
2024-11-21 19:49:27: [2024-11-21 19:49:27] iter = 0350, loss = 40.0437
2024-11-21 19:49:49: [2024-11-21 19:49:49] iter = 0360, loss = 33.8729
2024-11-21 19:50:11: [2024-11-21 19:50:11] iter = 0370, loss = 35.8882
2024-11-21 19:50:35: [2024-11-21 19:50:35] iter = 0380, loss = 36.3317
2024-11-21 19:50:57: [2024-11-21 19:50:57] iter = 0390, loss = 39.7171
2024-11-21 19:51:19: [2024-11-21 19:51:19] iter = 0400, loss = 33.8573
2024-11-21 19:51:41: [2024-11-21 19:51:41] iter = 0410, loss = 33.1343
2024-11-21 19:52:03: [2024-11-21 19:52:03] iter = 0420, loss = 40.2006
2024-11-21 19:52:26: [2024-11-21 19:52:26] iter = 0430, loss = 37.0391
2024-11-21 19:52:49: [2024-11-21 19:52:49] iter = 0440, loss = 34.1400
2024-11-21 19:53:11: [2024-11-21 19:53:11] iter = 0450, loss = 35.7406
2024-11-21 19:53:34: [2024-11-21 19:53:34] iter = 0460, loss = 35.3157
2024-11-21 19:53:57: [2024-11-21 19:53:57] iter = 0470, loss = 34.4818
2024-11-21 19:54:19: [2024-11-21 19:54:19] iter = 0480, loss = 37.5668
2024-11-21 19:54:41: [2024-11-21 19:54:41] iter = 0490, loss = 40.7574
2024-11-21 19:55:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 19:55:01: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 19:55:09: Evaluate 5 random ConvNet, ACCmean = 0.2934 ACCstd = 0.0254
-------------------------
2024-11-21 19:55:09: Evaluate 5 random ConvNet, F1mean = 0.2861 F!std = 0.0211
-------------------------
2024-11-21 19:55:12: [2024-11-21 19:55:12] iter = 0500, loss = 37.1641
2024-11-21 19:55:34: [2024-11-21 19:55:34] iter = 0510, loss = 37.0581
2024-11-21 19:55:56: [2024-11-21 19:55:56] iter = 0520, loss = 39.4764
2024-11-21 19:56:19: [2024-11-21 19:56:19] iter = 0530, loss = 33.2540
2024-11-21 19:56:41: [2024-11-21 19:56:41] iter = 0540, loss = 37.4611
2024-11-21 19:57:04: [2024-11-21 19:57:04] iter = 0550, loss = 36.5965
2024-11-21 19:57:26: [2024-11-21 19:57:26] iter = 0560, loss = 44.6130
2024-11-21 19:57:48: [2024-11-21 19:57:48] iter = 0570, loss = 33.7567
2024-11-21 19:58:11: [2024-11-21 19:58:11] iter = 0580, loss = 40.0856
2024-11-21 19:58:34: [2024-11-21 19:58:34] iter = 0590, loss = 37.8602
2024-11-21 19:58:56: [2024-11-21 19:58:56] iter = 0600, loss = 40.0803
2024-11-21 19:59:19: [2024-11-21 19:59:19] iter = 0610, loss = 40.2443
2024-11-21 19:59:40: [2024-11-21 19:59:40] iter = 0620, loss = 40.3566
2024-11-21 20:00:03: [2024-11-21 20:00:03] iter = 0630, loss = 39.4407
2024-11-21 20:00:25: [2024-11-21 20:00:25] iter = 0640, loss = 44.6902
2024-11-21 20:00:48: [2024-11-21 20:00:48] iter = 0650, loss = 38.1577
2024-11-21 20:01:10: [2024-11-21 20:01:10] iter = 0660, loss = 43.2090
2024-11-21 20:01:33: [2024-11-21 20:01:33] iter = 0670, loss = 43.8143
2024-11-21 20:01:53: [2024-11-21 20:01:53] iter = 0680, loss = 37.2816
2024-11-21 20:02:16: [2024-11-21 20:02:16] iter = 0690, loss = 41.9521
2024-11-21 20:02:37: [2024-11-21 20:02:37] iter = 0700, loss = 41.2861
2024-11-21 20:02:59: [2024-11-21 20:02:59] iter = 0710, loss = 45.8658
2024-11-21 20:03:21: [2024-11-21 20:03:21] iter = 0720, loss = 45.2443
2024-11-21 20:03:43: [2024-11-21 20:03:43] iter = 0730, loss = 41.2511
2024-11-21 20:04:05: [2024-11-21 20:04:05] iter = 0740, loss = 41.0473
2024-11-21 20:04:27: [2024-11-21 20:04:27] iter = 0750, loss = 45.0070
2024-11-21 20:04:49: [2024-11-21 20:04:49] iter = 0760, loss = 43.1478
2024-11-21 20:05:11: [2024-11-21 20:05:11] iter = 0770, loss = 47.1829
2024-11-21 20:05:34: [2024-11-21 20:05:34] iter = 0780, loss = 39.5029
2024-11-21 20:05:57: [2024-11-21 20:05:57] iter = 0790, loss = 41.2733
2024-11-21 20:06:19: [2024-11-21 20:06:19] iter = 0800, loss = 39.5583
2024-11-21 20:06:41: [2024-11-21 20:06:41] iter = 0810, loss = 44.1538
2024-11-21 20:07:03: [2024-11-21 20:07:03] iter = 0820, loss = 48.2931
2024-11-21 20:07:25: [2024-11-21 20:07:25] iter = 0830, loss = 44.2427
2024-11-21 20:07:47: [2024-11-21 20:07:47] iter = 0840, loss = 48.3338
2024-11-21 20:08:09: [2024-11-21 20:08:09] iter = 0850, loss = 48.1056
2024-11-21 20:08:32: [2024-11-21 20:08:32] iter = 0860, loss = 45.8869
2024-11-21 20:08:53: [2024-11-21 20:08:53] iter = 0870, loss = 51.0413
2024-11-21 20:09:15: [2024-11-21 20:09:15] iter = 0880, loss = 52.0022
2024-11-21 20:09:37: [2024-11-21 20:09:37] iter = 0890, loss = 45.2716
2024-11-21 20:09:59: [2024-11-21 20:09:59] iter = 0900, loss = 47.3724
2024-11-21 20:10:21: [2024-11-21 20:10:21] iter = 0910, loss = 50.4564
2024-11-21 20:10:43: [2024-11-21 20:10:43] iter = 0920, loss = 44.9676
2024-11-21 20:11:05: [2024-11-21 20:11:05] iter = 0930, loss = 48.4428
2024-11-21 20:11:28: [2024-11-21 20:11:28] iter = 0940, loss = 48.0917
2024-11-21 20:11:50: [2024-11-21 20:11:50] iter = 0950, loss = 45.1240
2024-11-21 20:12:13: [2024-11-21 20:12:13] iter = 0960, loss = 48.2458
2024-11-21 20:12:35: [2024-11-21 20:12:35] iter = 0970, loss = 45.3157
2024-11-21 20:12:57: [2024-11-21 20:12:57] iter = 0980, loss = 44.5331
2024-11-21 20:13:19: [2024-11-21 20:13:19] iter = 0990, loss = 50.4571
2024-11-21 20:13:40: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 20:13:40: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/chestmnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/chestmnist.npz
Loaded the dataset:ChestMNIST
[2024-11-21 18:20:39] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.000200 train acc = 1.0000, test acc = 0.2031, test_sen =0.5100, test_spe =0.5100, test_f1 =0.2030
[2024-11-21 18:20:41] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000190 train acc = 1.0000, test acc = 0.1893, test_sen =0.5068, test_spe =0.5068, test_f1 =0.1892
[2024-11-21 18:20:42] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000211 train acc = 1.0000, test acc = 0.1828, test_sen =0.4989, test_spe =0.4989, test_f1 =0.1827
[2024-11-21 18:20:44] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000218 train acc = 1.0000, test acc = 0.2163, test_sen =0.5070, test_spe =0.5070, test_f1 =0.2158
[2024-11-21 18:20:46] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000216 train acc = 1.0000, test acc = 0.5629, test_sen =0.4969, test_spe =0.4969, test_f1 =0.4363
[2024-11-21 18:39:27] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000679 train acc = 1.0000, test acc = 0.1881, test_sen =0.5352, test_spe =0.5352, test_f1 =0.1877
[2024-11-21 18:39:29] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000707 train acc = 1.0000, test acc = 0.1804, test_sen =0.5327, test_spe =0.5327, test_f1 =0.1796
[2024-11-21 18:39:31] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000767 train acc = 1.0000, test acc = 0.1896, test_sen =0.5318, test_spe =0.5318, test_f1 =0.1893
[2024-11-21 18:39:33] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000861 train acc = 1.0000, test acc = 0.2383, test_sen =0.5484, test_spe =0.5484, test_f1 =0.2374
[2024-11-21 18:39:34] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000742 train acc = 1.0000, test acc = 0.2114, test_sen =0.5451, test_spe =0.5451, test_f1 =0.2114
[2024-11-21 18:58:15] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000935 train acc = 1.0000, test acc = 0.4578, test_sen =0.5350, test_spe =0.5350, test_f1 =0.3954
[2024-11-21 18:58:17] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000961 train acc = 1.0000, test acc = 0.4856, test_sen =0.5588, test_spe =0.5588, test_f1 =0.4162
[2024-11-21 18:58:18] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000886 train acc = 1.0000, test acc = 0.3908, test_sen =0.5458, test_spe =0.5458, test_f1 =0.3566
[2024-11-21 18:58:20] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000829 train acc = 1.0000, test acc = 0.4210, test_sen =0.5342, test_spe =0.5342, test_f1 =0.3738
[2024-11-21 18:58:22] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000881 train acc = 1.0000, test acc = 0.5224, test_sen =0.5429, test_spe =0.5429, test_f1 =0.4316
[2024-11-21 18:58:28] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000196 train acc = 1.0000, test acc = 0.3779, test_sen =0.5102, test_spe =0.5102, test_f1 =0.3427
[2024-11-21 18:58:30] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000208 train acc = 1.0000, test acc = 0.1516, test_sen =0.5098, test_spe =0.5098, test_f1 =0.1488
[2024-11-21 18:58:31] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000150 train acc = 1.0000, test acc = 0.1592, test_sen =0.5170, test_spe =0.5170, test_f1 =0.1571
[2024-11-21 18:58:33] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000210 train acc = 1.0000, test acc = 0.1145, test_sen =0.5012, test_spe =0.5012, test_f1 =0.1056
[2024-11-21 18:58:35] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000201 train acc = 1.0000, test acc = 0.1288, test_sen =0.5035, test_spe =0.5035, test_f1 =0.1227
[2024-11-21 19:17:19] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000807 train acc = 1.0000, test acc = 0.1725, test_sen =0.5253, test_spe =0.5253, test_f1 =0.1713
[2024-11-21 19:17:21] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000762 train acc = 1.0000, test acc = 0.2586, test_sen =0.5473, test_spe =0.5473, test_f1 =0.2559
[2024-11-21 19:17:22] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000729 train acc = 1.0000, test acc = 0.2447, test_sen =0.5463, test_spe =0.5463, test_f1 =0.2432
[2024-11-21 19:17:24] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000718 train acc = 1.0000, test acc = 0.2029, test_sen =0.5358, test_spe =0.5358, test_f1 =0.2029
[2024-11-21 19:17:26] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000729 train acc = 1.0000, test acc = 0.2057, test_sen =0.5343, test_spe =0.5343, test_f1 =0.2057
[2024-11-21 19:36:03] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000823 train acc = 1.0000, test acc = 0.4635, test_sen =0.5832, test_spe =0.5832, test_f1 =0.4086
[2024-11-21 19:36:05] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000745 train acc = 1.0000, test acc = 0.3719, test_sen =0.5684, test_spe =0.5684, test_f1 =0.3470
[2024-11-21 19:36:06] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000764 train acc = 1.0000, test acc = 0.3823, test_sen =0.5643, test_spe =0.5643, test_f1 =0.3537
[2024-11-21 19:36:08] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000765 train acc = 1.0000, test acc = 0.4623, test_sen =0.5855, test_spe =0.5855, test_f1 =0.4083
[2024-11-21 19:36:10] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000846 train acc = 1.0000, test acc = 0.3951, test_sen =0.5642, test_spe =0.5642, test_f1 =0.3623
[2024-11-21 19:36:17] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000214 train acc = 1.0000, test acc = 0.6405, test_sen =0.5620, test_spe =0.5620, test_f1 =0.4919
[2024-11-21 19:36:18] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000241 train acc = 1.0000, test acc = 0.7423, test_sen =0.5470, test_spe =0.5470, test_f1 =0.5231
[2024-11-21 19:36:20] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000235 train acc = 1.0000, test acc = 0.6705, test_sen =0.5587, test_spe =0.5587, test_f1 =0.5029
[2024-11-21 19:36:22] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000229 train acc = 1.0000, test acc = 0.7505, test_sen =0.5485, test_spe =0.5485, test_f1 =0.5266
[2024-11-21 19:36:24] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000238 train acc = 1.0000, test acc = 0.6096, test_sen =0.5732, test_spe =0.5732, test_f1 =0.4823
[2024-11-21 19:55:03] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000851 train acc = 1.0000, test acc = 0.2646, test_sen =0.5528, test_spe =0.5528, test_f1 =0.2613
[2024-11-21 19:55:04] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000694 train acc = 1.0000, test acc = 0.2745, test_sen =0.5570, test_spe =0.5570, test_f1 =0.2702
[2024-11-21 19:55:06] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000723 train acc = 1.0000, test acc = 0.3011, test_sen =0.5660, test_spe =0.5660, test_f1 =0.2931
[2024-11-21 19:55:08] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.001027 train acc = 1.0000, test acc = 0.3376, test_sen =0.5708, test_spe =0.5708, test_f1 =0.3223
[2024-11-21 19:55:09] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000817 train acc = 1.0000, test acc = 0.2893, test_sen =0.5662, test_spe =0.5662, test_f1 =0.2833
[2024-11-21 20:13:42] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000740 train acc = 1.0000, test acc = 0.4232, test_sen =0.5627, test_spe =0.5627, test_f1 =0.3802
[2024-11-21 20:13:44] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000806 train acc = 1.0000, test acc = 0.4933, test_sen =0.5930, test_spe =0.5930, test_f1 =0.4280
[2024-11-21 20:13:45] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000871 train acc = 1.0000, test acc = 0.5361, test_sen =0.5802, test_spe =0.5802, test_f1 =0.4484
[2024-11-21 20:13:47] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000731 train acc = 1.0000, test acc = 0.4591, test_sen =0.5766, test_spe =0.5766, test_f1 =0.4047
[2024-11-21 20:13:49] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000871 train acc = 1.0000, test acc = 0.4032, test_sen =0.5763, test_spe =0.5763, test_f1 =0.36952024-11-21 20:13:49: Evaluate 5 random ConvNet, ACCmean = 0.4630 ACCstd = 0.0478
-------------------------
2024-11-21 20:13:49: Evaluate 5 random ConvNet, F1mean = 0.4061 F!std = 0.0292
-------------------------
2024-11-21 20:13:51: [2024-11-21 20:13:51] iter = 1000, loss = 47.5933
2024-11-21 20:13:51: 
================== Exp 3 ==================
 
2024-11-21 20:13:51: Hyper-parameters: 
{'method': 'DC', 'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f8c4dd3ea60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_ChestMNIST (INFO)>, 'dc_aug_param': None}
2024-11-21 20:13:51: Evaluation model pool: ['ConvNet']
2024-11-21 20:13:53: class c = 0: 70472 real images
2024-11-21 20:13:53: class c = 1: 7996 real images
2024-11-21 20:13:53: real images channel 0, mean = 0.4936, std = 0.2380
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 20:13:53: initialize synthetic data from random noise
2024-11-21 20:13:53: [2024-11-21 20:13:53] training begins
2024-11-21 20:13:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 20:13:53: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 20:14:02: Evaluate 5 random ConvNet, ACCmean = 0.5804 ACCstd = 0.1135
-------------------------
2024-11-21 20:14:02: Evaluate 5 random ConvNet, F1mean = 0.4277 F!std = 0.0410
-------------------------
2024-11-21 20:14:04: [2024-11-21 20:14:04] iter = 0000, loss = 322.5567
2024-11-21 20:14:26: [2024-11-21 20:14:26] iter = 0010, loss = 155.2591
2024-11-21 20:14:49: [2024-11-21 20:14:49] iter = 0020, loss = 100.0189
2024-11-21 20:15:11: [2024-11-21 20:15:11] iter = 0030, loss = 58.2016
2024-11-21 20:15:34: [2024-11-21 20:15:34] iter = 0040, loss = 55.9984
2024-11-21 20:15:56: [2024-11-21 20:15:56] iter = 0050, loss = 54.2379
2024-11-21 20:16:17: [2024-11-21 20:16:17] iter = 0060, loss = 51.5120
2024-11-21 20:16:39: [2024-11-21 20:16:39] iter = 0070, loss = 43.6985
2024-11-21 20:17:02: [2024-11-21 20:17:02] iter = 0080, loss = 49.0910
2024-11-21 20:17:24: [2024-11-21 20:17:24] iter = 0090, loss = 45.5061
2024-11-21 20:17:48: [2024-11-21 20:17:48] iter = 0100, loss = 41.9578
2024-11-21 20:18:11: [2024-11-21 20:18:11] iter = 0110, loss = 39.1203
2024-11-21 20:18:33: [2024-11-21 20:18:33] iter = 0120, loss = 38.9189
2024-11-21 20:18:55: [2024-11-21 20:18:55] iter = 0130, loss = 36.0241
2024-11-21 20:19:18: [2024-11-21 20:19:18] iter = 0140, loss = 35.9517
2024-11-21 20:19:40: [2024-11-21 20:19:40] iter = 0150, loss = 40.8635
2024-11-21 20:20:03: [2024-11-21 20:20:03] iter = 0160, loss = 41.8080
2024-11-21 20:20:25: [2024-11-21 20:20:25] iter = 0170, loss = 36.9735
2024-11-21 20:20:47: [2024-11-21 20:20:47] iter = 0180, loss = 38.5243
2024-11-21 20:21:10: [2024-11-21 20:21:10] iter = 0190, loss = 35.4956
2024-11-21 20:21:33: [2024-11-21 20:21:33] iter = 0200, loss = 36.9416
2024-11-21 20:21:56: [2024-11-21 20:21:56] iter = 0210, loss = 35.4230
2024-11-21 20:22:19: [2024-11-21 20:22:19] iter = 0220, loss = 31.1802
2024-11-21 20:22:42: [2024-11-21 20:22:42] iter = 0230, loss = 38.9186
2024-11-21 20:23:05: [2024-11-21 20:23:05] iter = 0240, loss = 32.9792
2024-11-21 20:23:27: [2024-11-21 20:23:27] iter = 0250, loss = 35.3807
2024-11-21 20:23:50: [2024-11-21 20:23:50] iter = 0260, loss = 38.6198
2024-11-21 20:24:13: [2024-11-21 20:24:13] iter = 0270, loss = 33.2853
2024-11-21 20:24:35: [2024-11-21 20:24:35] iter = 0280, loss = 30.8644
2024-11-21 20:24:57: [2024-11-21 20:24:57] iter = 0290, loss = 28.5982
2024-11-21 20:25:20: [2024-11-21 20:25:20] iter = 0300, loss = 35.4080
2024-11-21 20:25:42: [2024-11-21 20:25:42] iter = 0310, loss = 29.9811
2024-11-21 20:26:03: [2024-11-21 20:26:03] iter = 0320, loss = 33.9745
2024-11-21 20:26:26: [2024-11-21 20:26:26] iter = 0330, loss = 32.3249
2024-11-21 20:26:48: [2024-11-21 20:26:48] iter = 0340, loss = 35.8002
2024-11-21 20:27:10: [2024-11-21 20:27:10] iter = 0350, loss = 37.2898
2024-11-21 20:27:32: [2024-11-21 20:27:32] iter = 0360, loss = 33.7668
2024-11-21 20:27:55: [2024-11-21 20:27:55] iter = 0370, loss = 34.4524
2024-11-21 20:28:17: [2024-11-21 20:28:17] iter = 0380, loss = 35.7198
2024-11-21 20:28:40: [2024-11-21 20:28:40] iter = 0390, loss = 31.2616
2024-11-21 20:29:02: [2024-11-21 20:29:02] iter = 0400, loss = 32.8335
2024-11-21 20:29:25: [2024-11-21 20:29:25] iter = 0410, loss = 35.4528
2024-11-21 20:29:48: [2024-11-21 20:29:48] iter = 0420, loss = 32.5575
2024-11-21 20:30:10: [2024-11-21 20:30:10] iter = 0430, loss = 41.2963
2024-11-21 20:30:33: [2024-11-21 20:30:33] iter = 0440, loss = 35.6952
2024-11-21 20:30:55: [2024-11-21 20:30:55] iter = 0450, loss = 33.5742
2024-11-21 20:31:18: [2024-11-21 20:31:18] iter = 0460, loss = 30.8036
2024-11-21 20:31:41: [2024-11-21 20:31:41] iter = 0470, loss = 33.2877
2024-11-21 20:32:03: [2024-11-21 20:32:03] iter = 0480, loss = 33.4885
2024-11-21 20:32:25: [2024-11-21 20:32:25] iter = 0490, loss = 32.8650
2024-11-21 20:32:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 20:32:45: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 20:32:54: Evaluate 5 random ConvNet, ACCmean = 0.1498 ACCstd = 0.0145
-------------------------
2024-11-21 20:32:54: Evaluate 5 random ConvNet, F1mean = 0.1465 F!std = 0.0161
-------------------------
2024-11-21 20:32:56: [2024-11-21 20:32:56] iter = 0500, loss = 39.4656
2024-11-21 20:33:19: [2024-11-21 20:33:19] iter = 0510, loss = 35.5716
2024-11-21 20:33:41: [2024-11-21 20:33:41] iter = 0520, loss = 40.6622
2024-11-21 20:34:04: [2024-11-21 20:34:04] iter = 0530, loss = 39.2357
2024-11-21 20:34:26: [2024-11-21 20:34:26] iter = 0540, loss = 31.2266
2024-11-21 20:34:49: [2024-11-21 20:34:49] iter = 0550, loss = 42.1902
2024-11-21 20:35:11: [2024-11-21 20:35:11] iter = 0560, loss = 37.4533
2024-11-21 20:35:33: [2024-11-21 20:35:33] iter = 0570, loss = 37.5860
2024-11-21 20:35:56: [2024-11-21 20:35:56] iter = 0580, loss = 38.0004
2024-11-21 20:36:18: [2024-11-21 20:36:18] iter = 0590, loss = 32.8244
2024-11-21 20:36:40: [2024-11-21 20:36:40] iter = 0600, loss = 29.0616
2024-11-21 20:37:03: [2024-11-21 20:37:03] iter = 0610, loss = 33.5626
2024-11-21 20:37:25: [2024-11-21 20:37:25] iter = 0620, loss = 36.1642
2024-11-21 20:37:48: [2024-11-21 20:37:48] iter = 0630, loss = 35.0762
2024-11-21 20:38:11: [2024-11-21 20:38:11] iter = 0640, loss = 34.4187
2024-11-21 20:38:33: [2024-11-21 20:38:33] iter = 0650, loss = 35.4668
2024-11-21 20:38:53: [2024-11-21 20:38:53] iter = 0660, loss = 38.6603
2024-11-21 20:39:15: [2024-11-21 20:39:15] iter = 0670, loss = 37.9441
2024-11-21 20:39:39: [2024-11-21 20:39:39] iter = 0680, loss = 43.2058
2024-11-21 20:40:09: [2024-11-21 20:40:09] iter = 0690, loss = 35.5852
2024-11-21 20:40:37: [2024-11-21 20:40:37] iter = 0700, loss = 36.8968
2024-11-21 20:41:06: [2024-11-21 20:41:06] iter = 0710, loss = 40.4245
2024-11-21 20:41:33: [2024-11-21 20:41:33] iter = 0720, loss = 39.5315
2024-11-21 20:41:59: [2024-11-21 20:41:59] iter = 0730, loss = 41.3742
2024-11-21 20:42:25: [2024-11-21 20:42:25] iter = 0740, loss = 35.2205
2024-11-21 20:42:55: [2024-11-21 20:42:55] iter = 0750, loss = 45.4268
2024-11-21 20:43:28: [2024-11-21 20:43:28] iter = 0760, loss = 42.2271
2024-11-21 20:44:01: [2024-11-21 20:44:01] iter = 0770, loss = 36.5182
2024-11-21 20:44:33: [2024-11-21 20:44:33] iter = 0780, loss = 45.5133
2024-11-21 20:45:02: [2024-11-21 20:45:02] iter = 0790, loss = 41.1865
2024-11-21 20:45:35: [2024-11-21 20:45:35] iter = 0800, loss = 45.6532
2024-11-21 20:46:07: [2024-11-21 20:46:07] iter = 0810, loss = 42.0494
2024-11-21 20:46:49: [2024-11-21 20:46:49] iter = 0820, loss = 46.6467
2024-11-21 20:47:42: [2024-11-21 20:47:42] iter = 0830, loss = 41.6055
2024-11-21 20:48:37: [2024-11-21 20:48:37] iter = 0840, loss = 46.1637
2024-11-21 20:49:28: [2024-11-21 20:49:28] iter = 0850, loss = 47.2109
2024-11-21 20:50:20: [2024-11-21 20:50:20] iter = 0860, loss = 43.5381
2024-11-21 20:51:15: [2024-11-21 20:51:15] iter = 0870, loss = 43.2266
2024-11-21 20:52:14: [2024-11-21 20:52:14] iter = 0880, loss = 40.9162
2024-11-21 20:53:13: [2024-11-21 20:53:13] iter = 0890, loss = 41.1566
2024-11-21 20:54:08: [2024-11-21 20:54:08] iter = 0900, loss = 45.2639
2024-11-21 20:55:00: [2024-11-21 20:55:00] iter = 0910, loss = 48.0739
2024-11-21 20:55:50: [2024-11-21 20:55:50] iter = 0920, loss = 42.5681
2024-11-21 20:56:40: [2024-11-21 20:56:40] iter = 0930, loss = 44.1637
2024-11-21 20:57:37: [2024-11-21 20:57:37] iter = 0940, loss = 51.2466
2024-11-21 20:58:29: [2024-11-21 20:58:29] iter = 0950, loss = 42.4012
2024-11-21 20:59:24: [2024-11-21 20:59:24] iter = 0960, loss = 45.6409
2024-11-21 21:00:18: [2024-11-21 21:00:18] iter = 0970, loss = 42.4682
2024-11-21 21:01:08: [2024-11-21 21:01:08] iter = 0980, loss = 46.9239
2024-11-21 21:02:05: [2024-11-21 21:02:05] iter = 0990, loss = 50.5624
2024-11-21 21:02:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 21:02:54: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 21:03:21: Evaluate 5 random ConvNet, ACCmean = 0.6491 ACCstd = 0.0237
-------------------------
2024-11-21 21:03:21: Evaluate 5 random ConvNet, F1mean = 0.5011 F!std = 0.0097
-------------------------
2024-11-21 21:03:26: [2024-11-21 21:03:26] iter = 1000, loss = 50.3512
2024-11-21 21:03:26: 
================== Exp 4 ==================
 
2024-11-21 21:03:26: Hyper-parameters: 
{'method': 'DC', 'dataset': 'ChestMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 0.1, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'None', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f8c4dd3ea60>, 'dsa': False, 'mode': 'GM', 'logger': <Logger GM_IPC_10_limg_0.1_Data_ChestMNIST (INFO)>, 'dc_aug_param': None}
2024-11-21 21:03:26: Evaluation model pool: ['ConvNet']
2024-11-21 21:03:34: class c = 0: 70472 real images
2024-11-21 21:03:34: class c = 1: 7996 real images
2024-11-21 21:03:34: real images channel 0, mean = 0.4936, std = 0.2380
main_base.py:125: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-11-21 21:03:34: initialize synthetic data from random noise
2024-11-21 21:03:34: [2024-11-21 21:03:34] training begins
2024-11-21 21:03:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-11-21 21:03:34: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 21:04:04: Evaluate 5 random ConvNet, ACCmean = 0.6471 ACCstd = 0.0500
-------------------------
2024-11-21 21:04:04: Evaluate 5 random ConvNet, F1mean = 0.4884 F!std = 0.0187
-------------------------
2024-11-21 21:04:10: [2024-11-21 21:04:10] iter = 0000, loss = 323.9523
2024-11-21 21:05:02: [2024-11-21 21:05:02] iter = 0010, loss = 163.2640
2024-11-21 21:05:53: [2024-11-21 21:05:53] iter = 0020, loss = 96.3859
2024-11-21 21:06:45: [2024-11-21 21:06:45] iter = 0030, loss = 54.7539
2024-11-21 21:07:38: [2024-11-21 21:07:38] iter = 0040, loss = 54.3719
2024-11-21 21:08:29: [2024-11-21 21:08:29] iter = 0050, loss = 43.0594
2024-11-21 21:09:20: [2024-11-21 21:09:20] iter = 0060, loss = 43.4688
2024-11-21 21:10:18: [2024-11-21 21:10:18] iter = 0070, loss = 47.0449
2024-11-21 21:11:11: [2024-11-21 21:11:11] iter = 0080, loss = 43.2378
2024-11-21 21:12:05: [2024-11-21 21:12:05] iter = 0090, loss = 39.9449
2024-11-21 21:12:59: [2024-11-21 21:12:59] iter = 0100, loss = 42.1435
2024-11-21 21:13:51: [2024-11-21 21:13:51] iter = 0110, loss = 39.3444
2024-11-21 21:14:48: [2024-11-21 21:14:48] iter = 0120, loss = 43.7050
2024-11-21 21:15:38: [2024-11-21 21:15:37] iter = 0130, loss = 39.4447
2024-11-21 21:16:32: [2024-11-21 21:16:32] iter = 0140, loss = 36.8121
2024-11-21 21:17:29: [2024-11-21 21:17:29] iter = 0150, loss = 41.7024
2024-11-21 21:18:24: [2024-11-21 21:18:24] iter = 0160, loss = 33.1215
2024-11-21 21:19:20: [2024-11-21 21:19:20] iter = 0170, loss = 30.4523
2024-11-21 21:20:13: [2024-11-21 21:20:13] iter = 0180, loss = 36.8430
2024-11-21 21:21:02: [2024-11-21 21:21:02] iter = 0190, loss = 36.6837
2024-11-21 21:21:53: [2024-11-21 21:21:53] iter = 0200, loss = 34.3664
2024-11-21 21:22:38: [2024-11-21 21:22:38] iter = 0210, loss = 38.8299
2024-11-21 21:23:31: [2024-11-21 21:23:31] iter = 0220, loss = 33.1338
2024-11-21 21:24:22: [2024-11-21 21:24:22] iter = 0230, loss = 33.7535
2024-11-21 21:25:15: [2024-11-21 21:25:15] iter = 0240, loss = 35.3787
2024-11-21 21:26:06: [2024-11-21 21:26:06] iter = 0250, loss = 33.4087
2024-11-21 21:26:53: [2024-11-21 21:26:53] iter = 0260, loss = 33.2019
2024-11-21 21:27:42: [2024-11-21 21:27:42] iter = 0270, loss = 32.6585
2024-11-21 21:28:33: [2024-11-21 21:28:33] iter = 0280, loss = 31.5514
2024-11-21 21:29:25: [2024-11-21 21:29:25] iter = 0290, loss = 36.0029
2024-11-21 21:30:14: [2024-11-21 21:30:14] iter = 0300, loss = 35.4062
2024-11-21 21:31:07: [2024-11-21 21:31:07] iter = 0310, loss = 28.7879
2024-11-21 21:31:59: [2024-11-21 21:31:59] iter = 0320, loss = 39.9754
2024-11-21 21:32:46: [2024-11-21 21:32:46] iter = 0330, loss = 33.5126
2024-11-21 21:33:39: [2024-11-21 21:33:39] iter = 0340, loss = 35.0278
2024-11-21 21:34:28: [2024-11-21 21:34:28] iter = 0350, loss = 35.6787
2024-11-21 21:35:18: [2024-11-21 21:35:18] iter = 0360, loss = 30.9102
2024-11-21 21:36:08: [2024-11-21 21:36:08] iter = 0370, loss = 30.6432
2024-11-21 21:37:01: [2024-11-21 21:37:01] iter = 0380, loss = 39.1223
2024-11-21 21:37:52: [2024-11-21 21:37:52] iter = 0390, loss = 38.8232
2024-11-21 21:38:35: [2024-11-21 21:38:35] iter = 0400, loss = 34.9773
2024-11-21 21:39:28: [2024-11-21 21:39:28] iter = 0410, loss = 34.7110
2024-11-21 21:40:22: [2024-11-21 21:40:22] iter = 0420, loss = 38.5473
2024-11-21 21:41:10: [2024-11-21 21:41:10] iter = 0430, loss = 38.2713
2024-11-21 21:42:00: [2024-11-21 21:42:00] iter = 0440, loss = 36.4936
2024-11-21 21:42:55: [2024-11-21 21:42:55] iter = 0450, loss = 36.4847
2024-11-21 21:43:47: [2024-11-21 21:43:47] iter = 0460, loss = 33.7961
2024-11-21 21:44:42: [2024-11-21 21:44:42] iter = 0470, loss = 39.2868
2024-11-21 21:45:30: [2024-11-21 21:45:30] iter = 0480, loss = 36.8701
2024-11-21 21:46:23: [2024-11-21 21:46:23] iter = 0490, loss = 32.1739
2024-11-21 21:47:15: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
2024-11-21 21:47:15: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 21:47:42: Evaluate 5 random ConvNet, ACCmean = 0.7526 ACCstd = 0.0244
-------------------------
2024-11-21 21:47:42: Evaluate 5 random ConvNet, F1mean = 0.5281 F!std = 0.0097
-------------------------
2024-11-21 21:47:48: [2024-11-21 21:47:48] iter = 0500, loss = 39.0668
2024-11-21 21:48:40: [2024-11-21 21:48:40] iter = 0510, loss = 36.4252
2024-11-21 21:49:30: [2024-11-21 21:49:30] iter = 0520, loss = 36.8527
2024-11-21 21:50:17: [2024-11-21 21:50:17] iter = 0530, loss = 36.1239
2024-11-21 21:51:09: [2024-11-21 21:51:09] iter = 0540, loss = 36.1847
2024-11-21 21:51:56: [2024-11-21 21:51:56] iter = 0550, loss = 41.0583
2024-11-21 21:52:40: [2024-11-21 21:52:40] iter = 0560, loss = 38.5911
2024-11-21 21:53:32: [2024-11-21 21:53:32] iter = 0570, loss = 35.8729
2024-11-21 21:54:25: [2024-11-21 21:54:25] iter = 0580, loss = 34.7714
2024-11-21 21:55:16: [2024-11-21 21:55:16] iter = 0590, loss = 39.8150
2024-11-21 21:56:06: [2024-11-21 21:56:06] iter = 0600, loss = 40.0859
2024-11-21 21:56:58: [2024-11-21 21:56:58] iter = 0610, loss = 42.6234
2024-11-21 21:57:47: [2024-11-21 21:57:47] iter = 0620, loss = 34.3337
2024-11-21 21:58:43: [2024-11-21 21:58:43] iter = 0630, loss = 38.1753
2024-11-21 21:59:34: [2024-11-21 21:59:34] iter = 0640, loss = 37.4005
2024-11-21 22:00:25: [2024-11-21 22:00:25] iter = 0650, loss = 37.4303
2024-11-21 22:01:17: [2024-11-21 22:01:17] iter = 0660, loss = 40.6729
2024-11-21 22:02:09: [2024-11-21 22:02:09] iter = 0670, loss = 37.0091
2024-11-21 22:03:01: [2024-11-21 22:03:01] iter = 0680, loss = 35.9152
2024-11-21 22:03:55: [2024-11-21 22:03:55] iter = 0690, loss = 39.2661
2024-11-21 22:04:41: [2024-11-21 22:04:41] iter = 0700, loss = 36.1830
2024-11-21 22:05:31: [2024-11-21 22:05:31] iter = 0710, loss = 40.4684
2024-11-21 22:06:19: [2024-11-21 22:06:19] iter = 0720, loss = 38.0037
2024-11-21 22:07:06: [2024-11-21 22:07:06] iter = 0730, loss = 39.9160
2024-11-21 22:07:55: [2024-11-21 22:07:55] iter = 0740, loss = 41.1207
2024-11-21 22:08:47: [2024-11-21 22:08:47] iter = 0750, loss = 45.3191
2024-11-21 22:09:40: [2024-11-21 22:09:40] iter = 0760, loss = 44.8180
2024-11-21 22:10:28: [2024-11-21 22:10:28] iter = 0770, loss = 41.8934
2024-11-21 22:11:20: [2024-11-21 22:11:20] iter = 0780, loss = 41.4338
2024-11-21 22:12:12: [2024-11-21 22:12:12] iter = 0790, loss = 37.8084
2024-11-21 22:13:03: [2024-11-21 22:13:03] iter = 0800, loss = 46.2079
2024-11-21 22:13:55: [2024-11-21 22:13:55] iter = 0810, loss = 41.7313
2024-11-21 22:14:48: [2024-11-21 22:14:48] iter = 0820, loss = 40.0253
2024-11-21 22:15:39: [2024-11-21 22:15:39] iter = 0830, loss = 41.7719
2024-11-21 22:16:28: [2024-11-21 22:16:28] iter = 0840, loss = 40.4958
2024-11-21 22:17:15: [2024-11-21 22:17:15] iter = 0850, loss = 45.7038
2024-11-21 22:18:05: [2024-11-21 22:18:05] iter = 0860, loss = 45.2697
2024-11-21 22:18:56: [2024-11-21 22:18:56] iter = 0870, loss = 46.3367
2024-11-21 22:19:49: [2024-11-21 22:19:49] iter = 0880, loss = 48.2672
2024-11-21 22:20:41: [2024-11-21 22:20:41] iter = 0890, loss = 45.1331
2024-11-21 22:21:31: [2024-11-21 22:21:31] iter = 0900, loss = 46.6967
2024-11-21 22:22:24: [2024-11-21 22:22:24] iter = 0910, loss = 44.6820
2024-11-21 22:23:17: [2024-11-21 22:23:17] iter = 0920, loss = 43.6661
2024-11-21 22:24:12: [2024-11-21 22:24:12] iter = 0930, loss = 46.0066
2024-11-21 22:25:04: [2024-11-21 22:25:04] iter = 0940, loss = 45.5705
2024-11-21 22:25:53: [2024-11-21 22:25:53] iter = 0950, loss = 47.1952
2024-11-21 22:26:44: [2024-11-21 22:26:44] iter = 0960, loss = 47.5404
2024-11-21 22:27:36: [2024-11-21 22:27:36] iter = 0970, loss = 45.0622
2024-11-21 22:28:27: [2024-11-21 22:28:27] iter = 0980, loss = 42.2903
2024-11-21 22:29:19: [2024-11-21 22:29:19] iter = 0990, loss = 50.5809
2024-11-21 22:30:05: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
2024-11-21 22:30:05: DC augmentation parameters: 
{'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
2024-11-21 22:30:31: Evaluate 5 random ConvNet, ACCmean = 0.4971 ACCstd = 0.0203
-------------------------
2024-11-21 22:30:31: Evaluate 5 random ConvNet, F1mean = 0.4273 F!std = 0.0114
-------------------------
2024-11-21 22:30:36: [2024-11-21 22:30:36] iter = 1000, loss = 45.8278
2024-11-21 22:30:36: 
==================== Final Results ====================

2024-11-21 22:30:36: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 49.59%  std = 8.91%

[2024-11-21 20:13:55] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000196 train acc = 1.0000, test acc = 0.4899, test_sen =0.4749, test_spe =0.4749, test_f1 =0.3975
[2024-11-21 20:13:56] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000239 train acc = 1.0000, test acc = 0.6061, test_sen =0.4790, test_spe =0.4790, test_f1 =0.4459
[2024-11-21 20:13:58] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000246 train acc = 1.0000, test acc = 0.7450, test_sen =0.4775, test_spe =0.4775, test_f1 =0.4774
[2024-11-21 20:14:00] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000234 train acc = 1.0000, test acc = 0.6389, test_sen =0.4732, test_spe =0.4732, test_f1 =0.4536
[2024-11-21 20:14:02] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000167 train acc = 1.0000, test acc = 0.4220, test_sen =0.4828, test_spe =0.4828, test_f1 =0.3644
[2024-11-21 20:32:47] Evaluate_00: epoch = 0300 train time = 1 s train loss = 0.000895 train acc = 1.0000, test acc = 0.1320, test_sen =0.5063, test_spe =0.5063, test_f1 =0.1264
[2024-11-21 20:32:49] Evaluate_01: epoch = 0300 train time = 1 s train loss = 0.000860 train acc = 1.0000, test acc = 0.1422, test_sen =0.5074, test_spe =0.5074, test_f1 =0.1382
[2024-11-21 20:32:50] Evaluate_02: epoch = 0300 train time = 1 s train loss = 0.000823 train acc = 1.0000, test acc = 0.1410, test_sen =0.5064, test_spe =0.5064, test_f1 =0.1369
[2024-11-21 20:32:52] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000919 train acc = 1.0000, test acc = 0.1689, test_sen =0.5164, test_spe =0.5164, test_f1 =0.1677
[2024-11-21 20:32:54] Evaluate_04: epoch = 0300 train time = 1 s train loss = 0.000785 train acc = 1.0000, test acc = 0.1650, test_sen =0.5169, test_spe =0.5169, test_f1 =0.1634
[2024-11-21 21:02:59] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.000835 train acc = 1.0000, test acc = 0.6317, test_sen =0.5704, test_spe =0.5704, test_f1 =0.4912
[2024-11-21 21:03:06] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.000787 train acc = 1.0000, test acc = 0.6362, test_sen =0.5738, test_spe =0.5738, test_f1 =0.4944
[2024-11-21 21:03:11] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.000931 train acc = 1.0000, test acc = 0.6621, test_sen =0.5814, test_spe =0.5814, test_f1 =0.5086
[2024-11-21 21:03:16] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.000863 train acc = 1.0000, test acc = 0.6894, test_sen =0.5724, test_spe =0.5724, test_f1 =0.5164
[2024-11-21 21:03:21] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.000938 train acc = 1.0000, test acc = 0.6260, test_sen =0.5888, test_spe =0.5888, test_f1 =0.4950
[2024-11-21 21:03:40] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.000224 train acc = 1.0000, test acc = 0.5977, test_sen =0.5524, test_spe =0.5524, test_f1 =0.4699
[2024-11-21 21:03:46] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.000232 train acc = 1.0000, test acc = 0.6942, test_sen =0.5483, test_spe =0.5483, test_f1 =0.5072
[2024-11-21 21:03:52] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.000225 train acc = 1.0000, test acc = 0.5913, test_sen =0.5564, test_spe =0.5564, test_f1 =0.4684
[2024-11-21 21:03:58] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.000241 train acc = 1.0000, test acc = 0.7153, test_sen =0.5459, test_spe =0.5459, test_f1 =0.5134
[2024-11-21 21:04:04] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.000224 train acc = 1.0000, test acc = 0.6371, test_sen =0.5436, test_spe =0.5436, test_f1 =0.4833
[2024-11-21 21:47:21] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.000763 train acc = 1.0000, test acc = 0.7227, test_sen =0.5529, test_spe =0.5529, test_f1 =0.5197
[2024-11-21 21:47:26] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.000797 train acc = 1.0000, test acc = 0.7506, test_sen =0.5466, test_spe =0.5466, test_f1 =0.5255
[2024-11-21 21:47:32] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.000733 train acc = 1.0000, test acc = 0.7519, test_sen =0.5407, test_spe =0.5407, test_f1 =0.5222
[2024-11-21 21:47:36] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.000681 train acc = 1.0000, test acc = 0.7411, test_sen =0.5532, test_spe =0.5532, test_f1 =0.5262
[2024-11-21 21:47:42] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.000739 train acc = 1.0000, test acc = 0.7966, test_sen =0.5571, test_spe =0.5571, test_f1 =0.5470
[2024-11-21 22:30:12] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.000823 train acc = 1.0000, test acc = 0.5110, test_sen =0.5934, test_spe =0.5934, test_f1 =0.4381
[2024-11-21 22:30:17] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.000860 train acc = 1.0000, test acc = 0.5305, test_sen =0.5743, test_spe =0.5743, test_f1 =0.4439
[2024-11-21 22:30:23] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.000782 train acc = 1.0000, test acc = 0.4811, test_sen =0.5889, test_spe =0.5889, test_f1 =0.4201
[2024-11-21 22:30:27] Evaluate_03: epoch = 0300 train time = 1 s train loss = 0.000754 train acc = 1.0000, test acc = 0.4785, test_sen =0.5782, test_spe =0.5782, test_f1 =0.4164
[2024-11-21 22:30:31] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.000810 train acc = 1.0000, test acc = 0.4844, test_sen =0.5699, test_spe =0.5699, test_f1 =0.4179
