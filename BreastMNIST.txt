nohup: ignoring input
2024-10-30 14:20:07: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
Downloading https://zenodo.org/records/10519652/files/breastmnist.npz?download=1 to /data/users/xiongyuxuan/.medmnist/breastmnist.npz
  0%|          | 0/559580 [00:00<?, ?it/s]  6%|▌         | 32768/559580 [00:00<00:03, 157762.92it/s] 12%|█▏        | 65536/559580 [00:00<00:03, 156600.52it/s] 23%|██▎       | 131072/559580 [00:00<00:01, 228346.70it/s] 47%|████▋     | 262144/559580 [00:00<00:00, 457147.27it/s] 88%|████████▊ | 491520/559580 [00:00<00:00, 848667.90it/s]100%|██████████| 559580/559580 [00:00<00:00, 580151.62it/s]
2024-10-30 14:20:10: 
================== Exp 0 ==================
 
2024-10-30 14:20:10: Hyper-parameters: 
{'dataset': 'BreastMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ff878e0ab20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_BreastMNIST (INFO)>}
2024-10-30 14:20:10: Evaluation model pool: ['ConvNet']
2024-10-30 14:20:12: class c = 0: 147 real images
2024-10-30 14:20:12: class c = 1: 399 real images
2024-10-30 14:20:12: real images channel 0, mean = 0.3276, std = 0.2057
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 14:20:12: initialize synthetic data from random real images
2024-10-30 14:20:12: [2024-10-30 14:20:12] training begins
2024-10-30 14:20:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 14:20:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:20:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:21:09: Evaluate 5 random ConvNet, ACCmean = 0.5987 ACCstd = 0.0428
-------------------------
2024-10-30 14:21:09: Evaluate 5 random ConvNet, SENmean = 0.6382 SENstd = 0.0393
-------------------------
2024-10-30 14:21:09: Evaluate 5 random ConvNet, SPEmean = 0.6382 SPEstd = 0.0393
-------------------------
2024-10-30 14:21:09: Evaluate 5 random ConvNet, F!mean = 0.5805 F!std = 0.0400
-------------------------
2024-10-30 14:21:09: Evaluate 5 random ConvNet, mean = 0.5987 std = 0.0428
-------------------------
2024-10-30 14:21:09: [2024-10-30 14:21:09] iter = 00000, loss = 17.8871
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:21:10: [2024-10-30 14:21:09] iter = 00010, loss = 16.6321
2024-10-30 14:21:10: [2024-10-30 14:21:10] iter = 00020, loss = 8.7109
2024-10-30 14:21:10: [2024-10-30 14:21:10] iter = 00030, loss = 3.0578
2024-10-30 14:21:11: [2024-10-30 14:21:11] iter = 00040, loss = 5.1455
2024-10-30 14:21:11: [2024-10-30 14:21:11] iter = 00050, loss = 2.7049
2024-10-30 14:21:12: [2024-10-30 14:21:12] iter = 00060, loss = 8.4657
2024-10-30 14:21:12: [2024-10-30 14:21:12] iter = 00070, loss = 2.5385
2024-10-30 14:21:13: [2024-10-30 14:21:13] iter = 00080, loss = 9.3226
2024-10-30 14:21:13: [2024-10-30 14:21:13] iter = 00090, loss = 1.9726
2024-10-30 14:21:14: [2024-10-30 14:21:14] iter = 00100, loss = 4.3239
2024-10-30 14:21:15: [2024-10-30 14:21:15] iter = 00110, loss = 1.9097
2024-10-30 14:21:16: [2024-10-30 14:21:16] iter = 00120, loss = 2.0103
2024-10-30 14:21:16: [2024-10-30 14:21:16] iter = 00130, loss = 1.4478
2024-10-30 14:21:17: [2024-10-30 14:21:17] iter = 00140, loss = 1.0341
2024-10-30 14:21:18: [2024-10-30 14:21:18] iter = 00150, loss = 49.0220
2024-10-30 14:21:18: [2024-10-30 14:21:18] iter = 00160, loss = 2.1289
2024-10-30 14:21:19: [2024-10-30 14:21:19] iter = 00170, loss = 10.8580
2024-10-30 14:21:19: [2024-10-30 14:21:19] iter = 00180, loss = 2.3259
2024-10-30 14:21:20: [2024-10-30 14:21:20] iter = 00190, loss = 1.1889
2024-10-30 14:21:20: [2024-10-30 14:21:20] iter = 00200, loss = 1.6064
2024-10-30 14:21:21: [2024-10-30 14:21:21] iter = 00210, loss = 2.7650
2024-10-30 14:21:21: [2024-10-30 14:21:21] iter = 00220, loss = 12.4683
2024-10-30 14:21:22: [2024-10-30 14:21:22] iter = 00230, loss = 3.7053
2024-10-30 14:21:23: [2024-10-30 14:21:23] iter = 00240, loss = 1.8974
2024-10-30 14:21:23: [2024-10-30 14:21:23] iter = 00250, loss = 1.4703
2024-10-30 14:21:24: [2024-10-30 14:21:24] iter = 00260, loss = 1.7172
2024-10-30 14:21:25: [2024-10-30 14:21:25] iter = 00270, loss = 2.3716
2024-10-30 14:21:25: [2024-10-30 14:21:25] iter = 00280, loss = 2.2083
2024-10-30 14:21:26: [2024-10-30 14:21:26] iter = 00290, loss = 28.5321
2024-10-30 14:21:27: [2024-10-30 14:21:27] iter = 00300, loss = 10.1060
2024-10-30 14:21:28: [2024-10-30 14:21:28] iter = 00310, loss = 40.4458
2024-10-30 14:21:28: [2024-10-30 14:21:28] iter = 00320, loss = 38.3504
2024-10-30 14:21:29: [2024-10-30 14:21:29] iter = 00330, loss = 1.6013
2024-10-30 14:21:29: [2024-10-30 14:21:29] iter = 00340, loss = 4.2752
2024-10-30 14:21:30: [2024-10-30 14:21:30] iter = 00350, loss = 1.6990
2024-10-30 14:21:30: [2024-10-30 14:21:30] iter = 00360, loss = 5.2242
2024-10-30 14:21:31: [2024-10-30 14:21:31] iter = 00370, loss = 5.1937
2024-10-30 14:21:31: [2024-10-30 14:21:31] iter = 00380, loss = 17.0501
2024-10-30 14:21:32: [2024-10-30 14:21:32] iter = 00390, loss = 2.2478
2024-10-30 14:21:32: [2024-10-30 14:21:32] iter = 00400, loss = 1.4735
2024-10-30 14:21:33: [2024-10-30 14:21:33] iter = 00410, loss = 5.4987
2024-10-30 14:21:33: [2024-10-30 14:21:33] iter = 00420, loss = 34.4631
2024-10-30 14:21:34: [2024-10-30 14:21:34] iter = 00430, loss = 14.7104
2024-10-30 14:21:34: [2024-10-30 14:21:34] iter = 00440, loss = 1.7540
2024-10-30 14:21:35: [2024-10-30 14:21:35] iter = 00450, loss = 3.4100
2024-10-30 14:21:35: [2024-10-30 14:21:35] iter = 00460, loss = 19.6905
2024-10-30 14:21:36: [2024-10-30 14:21:36] iter = 00470, loss = 3.2778
2024-10-30 14:21:36: [2024-10-30 14:21:36] iter = 00480, loss = 1.3570
2024-10-30 14:21:37: [2024-10-30 14:21:37] iter = 00490, loss = 1.2969
2024-10-30 14:21:38: [2024-10-30 14:21:38] iter = 00500, loss = 4.7291
2024-10-30 14:21:38: [2024-10-30 14:21:38] iter = 00510, loss = 9.9320
2024-10-30 14:21:39: [2024-10-30 14:21:39] iter = 00520, loss = 12.8653
2024-10-30 14:21:39: [2024-10-30 14:21:39] iter = 00530, loss = 2.7570
2024-10-30 14:21:39: [2024-10-30 14:21:39] iter = 00540, loss = 2.8344
2024-10-30 14:21:40: [2024-10-30 14:21:40] iter = 00550, loss = 1.6389
2024-10-30 14:21:40: [2024-10-30 14:21:40] iter = 00560, loss = 4.2775
2024-10-30 14:21:41: [2024-10-30 14:21:41] iter = 00570, loss = 1.5681
2024-10-30 14:21:41: [2024-10-30 14:21:41] iter = 00580, loss = 2.9530
2024-10-30 14:21:42: [2024-10-30 14:21:42] iter = 00590, loss = 1.4265
2024-10-30 14:21:42: [2024-10-30 14:21:42] iter = 00600, loss = 1.5660
2024-10-30 14:21:43: [2024-10-30 14:21:43] iter = 00610, loss = 2.1865
2024-10-30 14:21:43: [2024-10-30 14:21:43] iter = 00620, loss = 2.3507
2024-10-30 14:21:44: [2024-10-30 14:21:44] iter = 00630, loss = 15.9653
2024-10-30 14:21:44: [2024-10-30 14:21:44] iter = 00640, loss = 1.7216
2024-10-30 14:21:45: [2024-10-30 14:21:45] iter = 00650, loss = 3.0780
2024-10-30 14:21:45: [2024-10-30 14:21:45] iter = 00660, loss = 5.4040
2024-10-30 14:21:45: [2024-10-30 14:21:45] iter = 00670, loss = 1.4275
2024-10-30 14:21:46: [2024-10-30 14:21:46] iter = 00680, loss = 1.5520
2024-10-30 14:21:46: [2024-10-30 14:21:46] iter = 00690, loss = 1.6684
2024-10-30 14:21:47: [2024-10-30 14:21:47] iter = 00700, loss = 1.2039
2024-10-30 14:21:47: [2024-10-30 14:21:47] iter = 00710, loss = 2.3767
2024-10-30 14:21:48: [2024-10-30 14:21:48] iter = 00720, loss = 8.6860
2024-10-30 14:21:48: [2024-10-30 14:21:48] iter = 00730, loss = 26.8766
2024-10-30 14:21:49: [2024-10-30 14:21:49] iter = 00740, loss = 5.6235
2024-10-30 14:21:49: [2024-10-30 14:21:49] iter = 00750, loss = 14.1235
2024-10-30 14:21:50: [2024-10-30 14:21:50] iter = 00760, loss = 2.4816
2024-10-30 14:21:50: [2024-10-30 14:21:50] iter = 00770, loss = 6.9987
2024-10-30 14:21:51: [2024-10-30 14:21:51] iter = 00780, loss = 2.4196
2024-10-30 14:21:52: [2024-10-30 14:21:52] iter = 00790, loss = 12.2926
2024-10-30 14:21:53: [2024-10-30 14:21:53] iter = 00800, loss = 1.8557
2024-10-30 14:21:53: [2024-10-30 14:21:53] iter = 00810, loss = 4.6539
2024-10-30 14:21:54: [2024-10-30 14:21:54] iter = 00820, loss = 6.2585
2024-10-30 14:21:54: [2024-10-30 14:21:54] iter = 00830, loss = 12.1711
2024-10-30 14:21:55: [2024-10-30 14:21:55] iter = 00840, loss = 2.5541
2024-10-30 14:21:55: [2024-10-30 14:21:55] iter = 00850, loss = 15.0523
2024-10-30 14:21:56: [2024-10-30 14:21:56] iter = 00860, loss = 1.2604
2024-10-30 14:21:57: [2024-10-30 14:21:57] iter = 00870, loss = 1.1100
2024-10-30 14:21:57: [2024-10-30 14:21:57] iter = 00880, loss = 1.1460
2024-10-30 14:21:57: [2024-10-30 14:21:57] iter = 00890, loss = 5.1436
2024-10-30 14:21:58: [2024-10-30 14:21:58] iter = 00900, loss = 4.0123
2024-10-30 14:21:58: [2024-10-30 14:21:58] iter = 00910, loss = 1.9331
2024-10-30 14:21:59: [2024-10-30 14:21:59] iter = 00920, loss = 1.8608
2024-10-30 14:21:59: [2024-10-30 14:21:59] iter = 00930, loss = 3.3120
2024-10-30 14:21:59: [2024-10-30 14:21:59] iter = 00940, loss = 5.3486
2024-10-30 14:22:00: [2024-10-30 14:22:00] iter = 00950, loss = 9.2182
2024-10-30 14:22:00: [2024-10-30 14:22:00] iter = 00960, loss = 3.0231
2024-10-30 14:22:01: [2024-10-30 14:22:01] iter = 00970, loss = 7.9182
2024-10-30 14:22:01: [2024-10-30 14:22:01] iter = 00980, loss = 28.5023
2024-10-30 14:22:02: [2024-10-30 14:22:02] iter = 00990, loss = 1.7893
2024-10-30 14:22:02: [2024-10-30 14:22:02] iter = 01000, loss = 1.7165
2024-10-30 14:22:02: [2024-10-30 14:22:02] iter = 01010, loss = 2.0548
2024-10-30 14:22:02: [2024-10-30 14:22:02] iter = 01020, loss = 2.1980
2024-10-30 14:22:03: [2024-10-30 14:22:03] iter = 01030, loss = 3.4482
2024-10-30 14:22:03: [2024-10-30 14:22:03] iter = 01040, loss = 4.3612
2024-10-30 14:22:04: [2024-10-30 14:22:04] iter = 01050, loss = 8.3031
2024-10-30 14:22:04: [2024-10-30 14:22:04] iter = 01060, loss = 2.8936
2024-10-30 14:22:05: [2024-10-30 14:22:05] iter = 01070, loss = 4.6634
2024-10-30 14:22:05: [2024-10-30 14:22:05] iter = 01080, loss = 7.5872
2024-10-30 14:22:06: [2024-10-30 14:22:06] iter = 01090, loss = 2.0254
2024-10-30 14:22:07: [2024-10-30 14:22:07] iter = 01100, loss = 0.9956
2024-10-30 14:22:07: [2024-10-30 14:22:07] iter = 01110, loss = 1.5284
2024-10-30 14:22:08: [2024-10-30 14:22:08] iter = 01120, loss = 13.7795
2024-10-30 14:22:08: [2024-10-30 14:22:08] iter = 01130, loss = 1.5376
2024-10-30 14:22:09: [2024-10-30 14:22:09] iter = 01140, loss = 18.9835
2024-10-30 14:22:09: [2024-10-30 14:22:09] iter = 01150, loss = 3.3039
2024-10-30 14:22:10: [2024-10-30 14:22:10] iter = 01160, loss = 1.3145
2024-10-30 14:22:10: [2024-10-30 14:22:10] iter = 01170, loss = 1.4150
2024-10-30 14:22:11: [2024-10-30 14:22:11] iter = 01180, loss = 16.1445
2024-10-30 14:22:11: [2024-10-30 14:22:11] iter = 01190, loss = 1.8980
2024-10-30 14:22:12: [2024-10-30 14:22:12] iter = 01200, loss = 2.1538
2024-10-30 14:22:13: [2024-10-30 14:22:13] iter = 01210, loss = 1.5397
2024-10-30 14:22:13: [2024-10-30 14:22:13] iter = 01220, loss = 5.5838
2024-10-30 14:22:14: [2024-10-30 14:22:14] iter = 01230, loss = 2.9964
2024-10-30 14:22:14: [2024-10-30 14:22:14] iter = 01240, loss = 5.0364
2024-10-30 14:22:15: [2024-10-30 14:22:15] iter = 01250, loss = 1.4057
2024-10-30 14:22:16: [2024-10-30 14:22:16] iter = 01260, loss = 2.0722
2024-10-30 14:22:16: [2024-10-30 14:22:16] iter = 01270, loss = 0.9451
2024-10-30 14:22:16: [2024-10-30 14:22:16] iter = 01280, loss = 6.2984
2024-10-30 14:22:17: [2024-10-30 14:22:17] iter = 01290, loss = 1.8636
2024-10-30 14:22:17: [2024-10-30 14:22:17] iter = 01300, loss = 17.2490
2024-10-30 14:22:18: [2024-10-30 14:22:18] iter = 01310, loss = 2.2236
2024-10-30 14:22:18: [2024-10-30 14:22:18] iter = 01320, loss = 1.3461
2024-10-30 14:22:19: [2024-10-30 14:22:19] iter = 01330, loss = 1.2767
2024-10-30 14:22:19: [2024-10-30 14:22:19] iter = 01340, loss = 3.1662
2024-10-30 14:22:20: [2024-10-30 14:22:20] iter = 01350, loss = 2.1635
2024-10-30 14:22:20: [2024-10-30 14:22:20] iter = 01360, loss = 1.0858
2024-10-30 14:22:21: [2024-10-30 14:22:21] iter = 01370, loss = 3.2535
2024-10-30 14:22:21: [2024-10-30 14:22:21] iter = 01380, loss = 1.5254
2024-10-30 14:22:22: [2024-10-30 14:22:22] iter = 01390, loss = 10.7778
2024-10-30 14:22:22: [2024-10-30 14:22:22] iter = 01400, loss = 5.2883
2024-10-30 14:22:22: [2024-10-30 14:22:22] iter = 01410, loss = 4.5115
2024-10-30 14:22:23: [2024-10-30 14:22:23] iter = 01420, loss = 1.8679
2024-10-30 14:22:23: [2024-10-30 14:22:23] iter = 01430, loss = 4.1114
2024-10-30 14:22:24: [2024-10-30 14:22:24] iter = 01440, loss = 20.6109
2024-10-30 14:22:24: [2024-10-30 14:22:24] iter = 01450, loss = 2.0536
2024-10-30 14:22:24: [2024-10-30 14:22:24] iter = 01460, loss = 2.4653
2024-10-30 14:22:25: [2024-10-30 14:22:25] iter = 01470, loss = 2.8988
2024-10-30 14:22:25: [2024-10-30 14:22:25] iter = 01480, loss = 1.7739
2024-10-30 14:22:26: [2024-10-30 14:22:26] iter = 01490, loss = 2.9359
2024-10-30 14:22:26: [2024-10-30 14:22:26] iter = 01500, loss = 2.7506
2024-10-30 14:22:27: [2024-10-30 14:22:27] iter = 01510, loss = 2.4159
2024-10-30 14:22:27: [2024-10-30 14:22:27] iter = 01520, loss = 5.2588
2024-10-30 14:22:27: [2024-10-30 14:22:27] iter = 01530, loss = 5.3946
2024-10-30 14:22:28: [2024-10-30 14:22:28] iter = 01540, loss = 1.6069
2024-10-30 14:22:28: [2024-10-30 14:22:28] iter = 01550, loss = 1.1691
2024-10-30 14:22:29: [2024-10-30 14:22:29] iter = 01560, loss = 1.2013
2024-10-30 14:22:29: [2024-10-30 14:22:29] iter = 01570, loss = 5.9074
2024-10-30 14:22:29: [2024-10-30 14:22:29] iter = 01580, loss = 3.1042
2024-10-30 14:22:30: [2024-10-30 14:22:30] iter = 01590, loss = 1.2475
2024-10-30 14:22:31: [2024-10-30 14:22:31] iter = 01600, loss = 27.7604
2024-10-30 14:22:31: [2024-10-30 14:22:31] iter = 01610, loss = 6.2202
2024-10-30 14:22:31: [2024-10-30 14:22:31] iter = 01620, loss = 17.6120
2024-10-30 14:22:32: [2024-10-30 14:22:32] iter = 01630, loss = 7.2869
2024-10-30 14:22:32: [2024-10-30 14:22:32] iter = 01640, loss = 2.0351
2024-10-30 14:22:33: [2024-10-30 14:22:33] iter = 01650, loss = 3.3798
2024-10-30 14:22:33: [2024-10-30 14:22:33] iter = 01660, loss = 1.6018
2024-10-30 14:22:34: [2024-10-30 14:22:34] iter = 01670, loss = 3.3110
2024-10-30 14:22:34: [2024-10-30 14:22:34] iter = 01680, loss = 5.9418
2024-10-30 14:22:35: [2024-10-30 14:22:35] iter = 01690, loss = 3.3089
2024-10-30 14:22:35: [2024-10-30 14:22:35] iter = 01700, loss = 3.1444
2024-10-30 14:22:35: [2024-10-30 14:22:35] iter = 01710, loss = 1.8128
2024-10-30 14:22:36: [2024-10-30 14:22:36] iter = 01720, loss = 5.0189
2024-10-30 14:22:37: [2024-10-30 14:22:37] iter = 01730, loss = 1.6731
2024-10-30 14:22:37: [2024-10-30 14:22:37] iter = 01740, loss = 1.1082
2024-10-30 14:22:37: [2024-10-30 14:22:37] iter = 01750, loss = 4.7241
2024-10-30 14:22:38: [2024-10-30 14:22:38] iter = 01760, loss = 1.3666
2024-10-30 14:22:38: [2024-10-30 14:22:38] iter = 01770, loss = 1.0937
2024-10-30 14:22:39: [2024-10-30 14:22:39] iter = 01780, loss = 2.0518
2024-10-30 14:22:39: [2024-10-30 14:22:39] iter = 01790, loss = 1.7130
2024-10-30 14:22:40: [2024-10-30 14:22:40] iter = 01800, loss = 1.8330
2024-10-30 14:22:41: [2024-10-30 14:22:41] iter = 01810, loss = 5.8263
2024-10-30 14:22:41: [2024-10-30 14:22:41] iter = 01820, loss = 3.0789
2024-10-30 14:22:41: [2024-10-30 14:22:41] iter = 01830, loss = 5.8392
2024-10-30 14:22:42: [2024-10-30 14:22:42] iter = 01840, loss = 2.9073
2024-10-30 14:22:42: [2024-10-30 14:22:42] iter = 01850, loss = 1.6959
2024-10-30 14:22:42: [2024-10-30 14:22:42] iter = 01860, loss = 1.4468
2024-10-30 14:22:43: [2024-10-30 14:22:43] iter = 01870, loss = 1.6571
2024-10-30 14:22:43: [2024-10-30 14:22:43] iter = 01880, loss = 2.3200
2024-10-30 14:22:44: [2024-10-30 14:22:44] iter = 01890, loss = 4.6844
2024-10-30 14:22:44: [2024-10-30 14:22:44] iter = 01900, loss = 2.7489
2024-10-30 14:22:45: [2024-10-30 14:22:45] iter = 01910, loss = 1.4681
2024-10-30 14:22:45: [2024-10-30 14:22:45] iter = 01920, loss = 1.6989
2024-10-30 14:22:46: [2024-10-30 14:22:46] iter = 01930, loss = 1.4584
2024-10-30 14:22:46: [2024-10-30 14:22:46] iter = 01940, loss = 3.8871
2024-10-30 14:22:47: [2024-10-30 14:22:47] iter = 01950, loss = 2.6701
2024-10-30 14:22:47: [2024-10-30 14:22:47] iter = 01960, loss = 7.2898
2024-10-30 14:22:48: [2024-10-30 14:22:48] iter = 01970, loss = 2.0418
2024-10-30 14:22:48: [2024-10-30 14:22:48] iter = 01980, loss = 22.8953
2024-10-30 14:22:49: [2024-10-30 14:22:49] iter = 01990, loss = 4.3015
2024-10-30 14:22:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 14:22:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:22:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 69519}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:23:33: Evaluate 5 random ConvNet, ACCmean = 0.7795 ACCstd = 0.0150
-------------------------
2024-10-30 14:23:33: Evaluate 5 random ConvNet, SENmean = 0.6957 SENstd = 0.0195
-------------------------
2024-10-30 14:23:33: Evaluate 5 random ConvNet, SPEmean = 0.6957 SPEstd = 0.0195
-------------------------
2024-10-30 14:23:33: Evaluate 5 random ConvNet, F!mean = 0.7048 F!std = 0.0198
-------------------------
2024-10-30 14:23:33: Evaluate 5 random ConvNet, mean = 0.7795 std = 0.0150
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:23:33: [2024-10-30 14:23:33] iter = 02000, loss = 3.2740
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:23:33: [2024-10-30 14:23:33] iter = 02010, loss = 19.8809
2024-10-30 14:23:34: [2024-10-30 14:23:34] iter = 02020, loss = 7.1478
2024-10-30 14:23:34: [2024-10-30 14:23:34] iter = 02030, loss = 1.2579
2024-10-30 14:23:34: [2024-10-30 14:23:34] iter = 02040, loss = 17.1611
2024-10-30 14:23:35: [2024-10-30 14:23:35] iter = 02050, loss = 7.3742
2024-10-30 14:23:35: [2024-10-30 14:23:35] iter = 02060, loss = 4.4458
2024-10-30 14:23:35: [2024-10-30 14:23:35] iter = 02070, loss = 1.3106
2024-10-30 14:23:36: [2024-10-30 14:23:36] iter = 02080, loss = 1.2353
2024-10-30 14:23:36: [2024-10-30 14:23:36] iter = 02090, loss = 19.0872
2024-10-30 14:23:37: [2024-10-30 14:23:37] iter = 02100, loss = 1.5435
2024-10-30 14:23:37: [2024-10-30 14:23:37] iter = 02110, loss = 4.4693
2024-10-30 14:23:38: [2024-10-30 14:23:38] iter = 02120, loss = 3.6758
2024-10-30 14:23:38: [2024-10-30 14:23:38] iter = 02130, loss = 1.9041
2024-10-30 14:23:39: [2024-10-30 14:23:39] iter = 02140, loss = 1.7350
2024-10-30 14:23:39: [2024-10-30 14:23:39] iter = 02150, loss = 29.8592
2024-10-30 14:23:40: [2024-10-30 14:23:40] iter = 02160, loss = 1.6576
2024-10-30 14:23:40: [2024-10-30 14:23:40] iter = 02170, loss = 3.0598
2024-10-30 14:23:41: [2024-10-30 14:23:41] iter = 02180, loss = 9.2457
2024-10-30 14:23:41: [2024-10-30 14:23:41] iter = 02190, loss = 4.5843
2024-10-30 14:23:41: [2024-10-30 14:23:41] iter = 02200, loss = 1.6766
2024-10-30 14:23:42: [2024-10-30 14:23:42] iter = 02210, loss = 11.8580
2024-10-30 14:23:42: [2024-10-30 14:23:42] iter = 02220, loss = 1.7323
2024-10-30 14:23:43: [2024-10-30 14:23:43] iter = 02230, loss = 3.6761
2024-10-30 14:23:43: [2024-10-30 14:23:43] iter = 02240, loss = 2.2282
2024-10-30 14:23:44: [2024-10-30 14:23:44] iter = 02250, loss = 3.7923
2024-10-30 14:23:44: [2024-10-30 14:23:44] iter = 02260, loss = 2.4163
2024-10-30 14:23:45: [2024-10-30 14:23:45] iter = 02270, loss = 2.5580
2024-10-30 14:23:45: [2024-10-30 14:23:45] iter = 02280, loss = 1.9256
2024-10-30 14:23:46: [2024-10-30 14:23:46] iter = 02290, loss = 1.1406
2024-10-30 14:23:47: [2024-10-30 14:23:47] iter = 02300, loss = 3.0057
2024-10-30 14:23:47: [2024-10-30 14:23:47] iter = 02310, loss = 1.6153
2024-10-30 14:23:48: [2024-10-30 14:23:48] iter = 02320, loss = 1.2582
2024-10-30 14:23:49: [2024-10-30 14:23:49] iter = 02330, loss = 2.4172
2024-10-30 14:23:49: [2024-10-30 14:23:49] iter = 02340, loss = 2.0733
2024-10-30 14:23:50: [2024-10-30 14:23:50] iter = 02350, loss = 9.9795
2024-10-30 14:23:50: [2024-10-30 14:23:50] iter = 02360, loss = 1.7801
2024-10-30 14:23:50: [2024-10-30 14:23:50] iter = 02370, loss = 15.3019
2024-10-30 14:23:51: [2024-10-30 14:23:51] iter = 02380, loss = 3.0631
2024-10-30 14:23:52: [2024-10-30 14:23:52] iter = 02390, loss = 1.6416
2024-10-30 14:23:52: [2024-10-30 14:23:52] iter = 02400, loss = 1.7138
2024-10-30 14:23:53: [2024-10-30 14:23:53] iter = 02410, loss = 4.4320
2024-10-30 14:23:53: [2024-10-30 14:23:53] iter = 02420, loss = 1.9113
2024-10-30 14:23:53: [2024-10-30 14:23:53] iter = 02430, loss = 2.0217
2024-10-30 14:23:54: [2024-10-30 14:23:54] iter = 02440, loss = 1.2536
2024-10-30 14:23:54: [2024-10-30 14:23:54] iter = 02450, loss = 8.9182
2024-10-30 14:23:55: [2024-10-30 14:23:55] iter = 02460, loss = 3.4334
2024-10-30 14:23:55: [2024-10-30 14:23:55] iter = 02470, loss = 3.6144
2024-10-30 14:23:55: [2024-10-30 14:23:55] iter = 02480, loss = 13.4622
2024-10-30 14:23:56: [2024-10-30 14:23:56] iter = 02490, loss = 6.7330
2024-10-30 14:23:56: [2024-10-30 14:23:56] iter = 02500, loss = 10.2953
2024-10-30 14:23:57: [2024-10-30 14:23:57] iter = 02510, loss = 7.4317
2024-10-30 14:23:57: [2024-10-30 14:23:57] iter = 02520, loss = 21.9310
2024-10-30 14:23:58: [2024-10-30 14:23:58] iter = 02530, loss = 2.1863
2024-10-30 14:23:58: [2024-10-30 14:23:58] iter = 02540, loss = 1.6082
2024-10-30 14:23:58: [2024-10-30 14:23:58] iter = 02550, loss = 9.8863
2024-10-30 14:23:58: [2024-10-30 14:23:58] iter = 02560, loss = 1.5861
2024-10-30 14:23:59: [2024-10-30 14:23:59] iter = 02570, loss = 3.5003
2024-10-30 14:23:59: [2024-10-30 14:23:59] iter = 02580, loss = 1.4883
2024-10-30 14:23:59: [2024-10-30 14:23:59] iter = 02590, loss = 12.4425
2024-10-30 14:24:00: [2024-10-30 14:24:00] iter = 02600, loss = 4.9612
2024-10-30 14:24:00: [2024-10-30 14:24:00] iter = 02610, loss = 2.8103
2024-10-30 14:24:00: [2024-10-30 14:24:00] iter = 02620, loss = 6.0589
2024-10-30 14:24:01: [2024-10-30 14:24:01] iter = 02630, loss = 1.5764
2024-10-30 14:24:01: [2024-10-30 14:24:01] iter = 02640, loss = 1.3443
2024-10-30 14:24:02: [2024-10-30 14:24:02] iter = 02650, loss = 4.3276
2024-10-30 14:24:02: [2024-10-30 14:24:02] iter = 02660, loss = 1.8789
2024-10-30 14:24:03: [2024-10-30 14:24:03] iter = 02670, loss = 1.9945
2024-10-30 14:24:03: [2024-10-30 14:24:03] iter = 02680, loss = 2.9770
2024-10-30 14:24:03: [2024-10-30 14:24:03] iter = 02690, loss = 1.0087
2024-10-30 14:24:04: [2024-10-30 14:24:04] iter = 02700, loss = 1.2466
2024-10-30 14:24:04: [2024-10-30 14:24:04] iter = 02710, loss = 1.6832
2024-10-30 14:24:05: [2024-10-30 14:24:05] iter = 02720, loss = 1.5637
2024-10-30 14:24:05: [2024-10-30 14:24:05] iter = 02730, loss = 8.4917
2024-10-30 14:24:06: [2024-10-30 14:24:06] iter = 02740, loss = 2.3961
2024-10-30 14:24:06: [2024-10-30 14:24:06] iter = 02750, loss = 2.9649
2024-10-30 14:24:06: [2024-10-30 14:24:06] iter = 02760, loss = 2.8272
2024-10-30 14:24:07: [2024-10-30 14:24:07] iter = 02770, loss = 1.5838
2024-10-30 14:24:07: [2024-10-30 14:24:07] iter = 02780, loss = 2.9586
2024-10-30 14:24:08: [2024-10-30 14:24:08] iter = 02790, loss = 6.4134
2024-10-30 14:24:09: [2024-10-30 14:24:09] iter = 02800, loss = 2.2982
2024-10-30 14:24:09: [2024-10-30 14:24:09] iter = 02810, loss = 2.5100
2024-10-30 14:24:10: [2024-10-30 14:24:10] iter = 02820, loss = 10.5748
2024-10-30 14:24:10: [2024-10-30 14:24:10] iter = 02830, loss = 3.9181
2024-10-30 14:24:11: [2024-10-30 14:24:11] iter = 02840, loss = 2.1425
2024-10-30 14:24:11: [2024-10-30 14:24:11] iter = 02850, loss = 1.2630
2024-10-30 14:24:12: [2024-10-30 14:24:12] iter = 02860, loss = 6.4172
2024-10-30 14:24:12: [2024-10-30 14:24:12] iter = 02870, loss = 1.6528
2024-10-30 14:24:13: [2024-10-30 14:24:13] iter = 02880, loss = 1.0419
2024-10-30 14:24:13: [2024-10-30 14:24:13] iter = 02890, loss = 2.4712
2024-10-30 14:24:14: [2024-10-30 14:24:14] iter = 02900, loss = 24.5672
2024-10-30 14:24:14: [2024-10-30 14:24:14] iter = 02910, loss = 1.8120
2024-10-30 14:24:15: [2024-10-30 14:24:15] iter = 02920, loss = 1.6486
2024-10-30 14:24:15: [2024-10-30 14:24:15] iter = 02930, loss = 10.7036
2024-10-30 14:24:16: [2024-10-30 14:24:16] iter = 02940, loss = 1.3417
2024-10-30 14:24:16: [2024-10-30 14:24:16] iter = 02950, loss = 7.4560
2024-10-30 14:24:17: [2024-10-30 14:24:17] iter = 02960, loss = 3.0077
2024-10-30 14:24:17: [2024-10-30 14:24:17] iter = 02970, loss = 1.4957
2024-10-30 14:24:18: [2024-10-30 14:24:18] iter = 02980, loss = 44.2570
2024-10-30 14:24:18: [2024-10-30 14:24:18] iter = 02990, loss = 22.6898
2024-10-30 14:24:19: [2024-10-30 14:24:19] iter = 03000, loss = 3.3487
2024-10-30 14:24:19: [2024-10-30 14:24:19] iter = 03010, loss = 2.4529
2024-10-30 14:24:20: [2024-10-30 14:24:20] iter = 03020, loss = 1.3374
2024-10-30 14:24:20: [2024-10-30 14:24:20] iter = 03030, loss = 13.0452
2024-10-30 14:24:21: [2024-10-30 14:24:21] iter = 03040, loss = 4.7190
2024-10-30 14:24:21: [2024-10-30 14:24:21] iter = 03050, loss = 3.3946
2024-10-30 14:24:22: [2024-10-30 14:24:22] iter = 03060, loss = 2.0070
2024-10-30 14:24:22: [2024-10-30 14:24:22] iter = 03070, loss = 2.0325
2024-10-30 14:24:23: [2024-10-30 14:24:23] iter = 03080, loss = 2.4681
2024-10-30 14:24:23: [2024-10-30 14:24:23] iter = 03090, loss = 5.1932
2024-10-30 14:24:24: [2024-10-30 14:24:24] iter = 03100, loss = 3.3050
2024-10-30 14:24:24: [2024-10-30 14:24:24] iter = 03110, loss = 8.2422
2024-10-30 14:24:25: [2024-10-30 14:24:25] iter = 03120, loss = 5.4167
2024-10-30 14:24:25: [2024-10-30 14:24:25] iter = 03130, loss = 1.4544
2024-10-30 14:24:26: [2024-10-30 14:24:26] iter = 03140, loss = 45.7416
2024-10-30 14:24:26: [2024-10-30 14:24:26] iter = 03150, loss = 2.6703
2024-10-30 14:24:26: [2024-10-30 14:24:26] iter = 03160, loss = 1.6520
2024-10-30 14:24:27: [2024-10-30 14:24:27] iter = 03170, loss = 5.5833
2024-10-30 14:24:28: [2024-10-30 14:24:28] iter = 03180, loss = 4.5925
2024-10-30 14:24:29: [2024-10-30 14:24:29] iter = 03190, loss = 11.7888
2024-10-30 14:24:29: [2024-10-30 14:24:29] iter = 03200, loss = 3.2336
2024-10-30 14:24:30: [2024-10-30 14:24:30] iter = 03210, loss = 2.3567
2024-10-30 14:24:30: [2024-10-30 14:24:30] iter = 03220, loss = 5.6926
2024-10-30 14:24:31: [2024-10-30 14:24:31] iter = 03230, loss = 43.2327
2024-10-30 14:24:31: [2024-10-30 14:24:31] iter = 03240, loss = 2.0734
2024-10-30 14:24:32: [2024-10-30 14:24:32] iter = 03250, loss = 1.4227
2024-10-30 14:24:33: [2024-10-30 14:24:33] iter = 03260, loss = 1.6194
2024-10-30 14:24:33: [2024-10-30 14:24:33] iter = 03270, loss = 4.7355
2024-10-30 14:24:34: [2024-10-30 14:24:34] iter = 03280, loss = 5.9080
2024-10-30 14:24:34: [2024-10-30 14:24:34] iter = 03290, loss = 2.7406
2024-10-30 14:24:34: [2024-10-30 14:24:34] iter = 03300, loss = 5.7074
2024-10-30 14:24:35: [2024-10-30 14:24:35] iter = 03310, loss = 7.1242
2024-10-30 14:24:35: [2024-10-30 14:24:35] iter = 03320, loss = 2.4078
2024-10-30 14:24:36: [2024-10-30 14:24:36] iter = 03330, loss = 4.3681
2024-10-30 14:24:36: [2024-10-30 14:24:36] iter = 03340, loss = 2.2008
2024-10-30 14:24:37: [2024-10-30 14:24:37] iter = 03350, loss = 4.4694
2024-10-30 14:24:37: [2024-10-30 14:24:37] iter = 03360, loss = 3.6071
2024-10-30 14:24:38: [2024-10-30 14:24:38] iter = 03370, loss = 3.7977
2024-10-30 14:24:38: [2024-10-30 14:24:38] iter = 03380, loss = 4.4414
2024-10-30 14:24:39: [2024-10-30 14:24:39] iter = 03390, loss = 8.0370
2024-10-30 14:24:39: [2024-10-30 14:24:39] iter = 03400, loss = 2.2632
2024-10-30 14:24:40: [2024-10-30 14:24:40] iter = 03410, loss = 17.6439
2024-10-30 14:24:40: [2024-10-30 14:24:40] iter = 03420, loss = 3.4370
2024-10-30 14:24:41: [2024-10-30 14:24:41] iter = 03430, loss = 3.2216
2024-10-30 14:24:41: [2024-10-30 14:24:41] iter = 03440, loss = 9.4621
2024-10-30 14:24:42: [2024-10-30 14:24:42] iter = 03450, loss = 2.7564
2024-10-30 14:24:42: [2024-10-30 14:24:42] iter = 03460, loss = 1.5225
2024-10-30 14:24:43: [2024-10-30 14:24:43] iter = 03470, loss = 3.3008
2024-10-30 14:24:43: [2024-10-30 14:24:43] iter = 03480, loss = 1.8838
2024-10-30 14:24:44: [2024-10-30 14:24:44] iter = 03490, loss = 1.5787
2024-10-30 14:24:45: [2024-10-30 14:24:45] iter = 03500, loss = 1.2881
2024-10-30 14:24:45: [2024-10-30 14:24:45] iter = 03510, loss = 3.2888
2024-10-30 14:24:46: [2024-10-30 14:24:46] iter = 03520, loss = 16.2139
2024-10-30 14:24:46: [2024-10-30 14:24:46] iter = 03530, loss = 1.9900
2024-10-30 14:24:47: [2024-10-30 14:24:47] iter = 03540, loss = 5.1935
2024-10-30 14:24:47: [2024-10-30 14:24:47] iter = 03550, loss = 9.6484
2024-10-30 14:24:48: [2024-10-30 14:24:48] iter = 03560, loss = 3.5279
2024-10-30 14:24:48: [2024-10-30 14:24:48] iter = 03570, loss = 1.7456
2024-10-30 14:24:49: [2024-10-30 14:24:49] iter = 03580, loss = 2.9151
2024-10-30 14:24:49: [2024-10-30 14:24:49] iter = 03590, loss = 2.3443
2024-10-30 14:24:50: [2024-10-30 14:24:50] iter = 03600, loss = 6.6251
2024-10-30 14:24:51: [2024-10-30 14:24:51] iter = 03610, loss = 1.5473
2024-10-30 14:24:51: [2024-10-30 14:24:51] iter = 03620, loss = 24.7357
2024-10-30 14:24:52: [2024-10-30 14:24:52] iter = 03630, loss = 2.6595
2024-10-30 14:24:52: [2024-10-30 14:24:52] iter = 03640, loss = 25.4794
2024-10-30 14:24:52: [2024-10-30 14:24:52] iter = 03650, loss = 3.0240
2024-10-30 14:24:53: [2024-10-30 14:24:53] iter = 03660, loss = 3.8801
2024-10-30 14:24:53: [2024-10-30 14:24:53] iter = 03670, loss = 6.4674
2024-10-30 14:24:54: [2024-10-30 14:24:54] iter = 03680, loss = 5.9495
2024-10-30 14:24:54: [2024-10-30 14:24:54] iter = 03690, loss = 4.1600
2024-10-30 14:24:55: [2024-10-30 14:24:55] iter = 03700, loss = 1.2688
2024-10-30 14:24:55: [2024-10-30 14:24:55] iter = 03710, loss = 4.6053
2024-10-30 14:24:56: [2024-10-30 14:24:56] iter = 03720, loss = 2.3453
2024-10-30 14:24:56: [2024-10-30 14:24:56] iter = 03730, loss = 4.5402
2024-10-30 14:24:57: [2024-10-30 14:24:57] iter = 03740, loss = 3.6253
2024-10-30 14:24:58: [2024-10-30 14:24:58] iter = 03750, loss = 1.9313
2024-10-30 14:24:58: [2024-10-30 14:24:58] iter = 03760, loss = 2.6168
2024-10-30 14:24:59: [2024-10-30 14:24:59] iter = 03770, loss = 1.1593
2024-10-30 14:24:59: [2024-10-30 14:24:59] iter = 03780, loss = 5.1763
2024-10-30 14:25:00: [2024-10-30 14:25:00] iter = 03790, loss = 3.1812
2024-10-30 14:25:01: [2024-10-30 14:25:01] iter = 03800, loss = 3.6257
2024-10-30 14:25:01: [2024-10-30 14:25:01] iter = 03810, loss = 1.8397
2024-10-30 14:25:02: [2024-10-30 14:25:02] iter = 03820, loss = 1.1549
2024-10-30 14:25:02: [2024-10-30 14:25:02] iter = 03830, loss = 1.2254
2024-10-30 14:25:03: [2024-10-30 14:25:02] iter = 03840, loss = 1.3550
2024-10-30 14:25:03: [2024-10-30 14:25:03] iter = 03850, loss = 1.4568
2024-10-30 14:25:04: [2024-10-30 14:25:04] iter = 03860, loss = 3.3173
2024-10-30 14:25:04: [2024-10-30 14:25:04] iter = 03870, loss = 6.7604
2024-10-30 14:25:04: [2024-10-30 14:25:04] iter = 03880, loss = 2.2172
2024-10-30 14:25:05: [2024-10-30 14:25:05] iter = 03890, loss = 8.3738
2024-10-30 14:25:05: [2024-10-30 14:25:05] iter = 03900, loss = 1.3331
2024-10-30 14:25:06: [2024-10-30 14:25:06] iter = 03910, loss = 3.4656
2024-10-30 14:25:06: [2024-10-30 14:25:06] iter = 03920, loss = 1.6625
2024-10-30 14:25:07: [2024-10-30 14:25:07] iter = 03930, loss = 2.5088
2024-10-30 14:25:07: [2024-10-30 14:25:07] iter = 03940, loss = 1.2535
2024-10-30 14:25:07: [2024-10-30 14:25:07] iter = 03950, loss = 1.6705
2024-10-30 14:25:07: [2024-10-30 14:25:07] iter = 03960, loss = 3.0168
2024-10-30 14:25:08: [2024-10-30 14:25:08] iter = 03970, loss = 1.2924
2024-10-30 14:25:08: [2024-10-30 14:25:08] iter = 03980, loss = 3.2733
2024-10-30 14:25:09: [2024-10-30 14:25:09] iter = 03990, loss = 2.1042
2024-10-30 14:25:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 14:25:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:25:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 9633}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:25:55: Evaluate 5 random ConvNet, ACCmean = 0.7846 ACCstd = 0.0051
-------------------------
2024-10-30 14:25:55: Evaluate 5 random ConvNet, SENmean = 0.7429 SENstd = 0.0100
-------------------------
2024-10-30 14:25:55: Evaluate 5 random ConvNet, SPEmean = 0.7429 SPEstd = 0.0100
-------------------------
2024-10-30 14:25:55: Evaluate 5 random ConvNet, F!mean = 0.7347 F!std = 0.0075
-------------------------
2024-10-30 14:25:55: Evaluate 5 random ConvNet, mean = 0.7846 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:25:55: [2024-10-30 14:25:55] iter = 04000, loss = 1.8629
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:25:55: [2024-10-30 14:25:55] iter = 04010, loss = 1.4473
2024-10-30 14:25:56: [2024-10-30 14:25:56] iter = 04020, loss = 1.7044
2024-10-30 14:25:56: [2024-10-30 14:25:56] iter = 04030, loss = 2.4692
2024-10-30 14:25:57: [2024-10-30 14:25:56] iter = 04040, loss = 2.6450
2024-10-30 14:25:57: [2024-10-30 14:25:57] iter = 04050, loss = 1.4419
2024-10-30 14:25:57: [2024-10-30 14:25:57] iter = 04060, loss = 1.4173
2024-10-30 14:25:58: [2024-10-30 14:25:58] iter = 04070, loss = 2.3945
2024-10-30 14:25:58: [2024-10-30 14:25:58] iter = 04080, loss = 15.0773
2024-10-30 14:25:59: [2024-10-30 14:25:59] iter = 04090, loss = 1.4699
2024-10-30 14:25:59: [2024-10-30 14:25:59] iter = 04100, loss = 1.3864
2024-10-30 14:26:00: [2024-10-30 14:26:00] iter = 04110, loss = 1.3807
2024-10-30 14:26:01: [2024-10-30 14:26:01] iter = 04120, loss = 2.8645
2024-10-30 14:26:01: [2024-10-30 14:26:01] iter = 04130, loss = 1.6320
2024-10-30 14:26:02: [2024-10-30 14:26:02] iter = 04140, loss = 2.1230
2024-10-30 14:26:02: [2024-10-30 14:26:02] iter = 04150, loss = 4.3380
2024-10-30 14:26:03: [2024-10-30 14:26:03] iter = 04160, loss = 1.3854
2024-10-30 14:26:03: [2024-10-30 14:26:03] iter = 04170, loss = 1.5830
2024-10-30 14:26:04: [2024-10-30 14:26:04] iter = 04180, loss = 16.4813
2024-10-30 14:26:04: [2024-10-30 14:26:04] iter = 04190, loss = 9.0694
2024-10-30 14:26:05: [2024-10-30 14:26:05] iter = 04200, loss = 5.2173
2024-10-30 14:26:05: [2024-10-30 14:26:05] iter = 04210, loss = 4.5191
2024-10-30 14:26:06: [2024-10-30 14:26:06] iter = 04220, loss = 1.8963
2024-10-30 14:26:06: [2024-10-30 14:26:06] iter = 04230, loss = 5.9068
2024-10-30 14:26:07: [2024-10-30 14:26:07] iter = 04240, loss = 2.0128
2024-10-30 14:26:08: [2024-10-30 14:26:08] iter = 04250, loss = 1.2684
2024-10-30 14:26:08: [2024-10-30 14:26:08] iter = 04260, loss = 1.9607
2024-10-30 14:26:09: [2024-10-30 14:26:09] iter = 04270, loss = 2.0756
2024-10-30 14:26:09: [2024-10-30 14:26:09] iter = 04280, loss = 16.8882
2024-10-30 14:26:10: [2024-10-30 14:26:10] iter = 04290, loss = 4.8851
2024-10-30 14:26:10: [2024-10-30 14:26:10] iter = 04300, loss = 17.5716
2024-10-30 14:26:11: [2024-10-30 14:26:11] iter = 04310, loss = 1.8278
2024-10-30 14:26:11: [2024-10-30 14:26:11] iter = 04320, loss = 7.9625
2024-10-30 14:26:12: [2024-10-30 14:26:12] iter = 04330, loss = 21.5500
2024-10-30 14:26:12: [2024-10-30 14:26:12] iter = 04340, loss = 5.9650
2024-10-30 14:26:12: [2024-10-30 14:26:12] iter = 04350, loss = 2.3618
2024-10-30 14:26:13: [2024-10-30 14:26:13] iter = 04360, loss = 5.6645
2024-10-30 14:26:13: [2024-10-30 14:26:13] iter = 04370, loss = 10.5712
2024-10-30 14:26:13: [2024-10-30 14:26:13] iter = 04380, loss = 3.5472
2024-10-30 14:26:14: [2024-10-30 14:26:14] iter = 04390, loss = 4.5675
2024-10-30 14:26:14: [2024-10-30 14:26:14] iter = 04400, loss = 4.0338
2024-10-30 14:26:15: [2024-10-30 14:26:15] iter = 04410, loss = 2.9581
2024-10-30 14:26:15: [2024-10-30 14:26:15] iter = 04420, loss = 1.7581
2024-10-30 14:26:16: [2024-10-30 14:26:16] iter = 04430, loss = 3.5561
2024-10-30 14:26:16: [2024-10-30 14:26:16] iter = 04440, loss = 1.6145
2024-10-30 14:26:17: [2024-10-30 14:26:17] iter = 04450, loss = 6.3178
2024-10-30 14:26:17: [2024-10-30 14:26:17] iter = 04460, loss = 6.3779
2024-10-30 14:26:18: [2024-10-30 14:26:18] iter = 04470, loss = 2.4781
2024-10-30 14:26:18: [2024-10-30 14:26:18] iter = 04480, loss = 5.6668
2024-10-30 14:26:19: [2024-10-30 14:26:19] iter = 04490, loss = 2.0459
2024-10-30 14:26:19: [2024-10-30 14:26:19] iter = 04500, loss = 24.7234
2024-10-30 14:26:20: [2024-10-30 14:26:20] iter = 04510, loss = 4.8301
2024-10-30 14:26:20: [2024-10-30 14:26:20] iter = 04520, loss = 6.6344
2024-10-30 14:26:20: [2024-10-30 14:26:20] iter = 04530, loss = 1.8779
2024-10-30 14:26:21: [2024-10-30 14:26:21] iter = 04540, loss = 4.6664
2024-10-30 14:26:21: [2024-10-30 14:26:21] iter = 04550, loss = 1.2015
2024-10-30 14:26:22: [2024-10-30 14:26:22] iter = 04560, loss = 7.9690
2024-10-30 14:26:22: [2024-10-30 14:26:22] iter = 04570, loss = 1.4186
2024-10-30 14:26:22: [2024-10-30 14:26:22] iter = 04580, loss = 3.0120
2024-10-30 14:26:23: [2024-10-30 14:26:23] iter = 04590, loss = 3.2145
2024-10-30 14:26:23: [2024-10-30 14:26:23] iter = 04600, loss = 4.1667
2024-10-30 14:26:24: [2024-10-30 14:26:24] iter = 04610, loss = 16.2188
2024-10-30 14:26:24: [2024-10-30 14:26:24] iter = 04620, loss = 2.9681
2024-10-30 14:26:25: [2024-10-30 14:26:25] iter = 04630, loss = 25.2233
2024-10-30 14:26:25: [2024-10-30 14:26:25] iter = 04640, loss = 2.6134
2024-10-30 14:26:26: [2024-10-30 14:26:26] iter = 04650, loss = 14.2424
2024-10-30 14:26:27: [2024-10-30 14:26:27] iter = 04660, loss = 25.9670
2024-10-30 14:26:27: [2024-10-30 14:26:27] iter = 04670, loss = 1.7415
2024-10-30 14:26:28: [2024-10-30 14:26:28] iter = 04680, loss = 3.1445
2024-10-30 14:26:28: [2024-10-30 14:26:28] iter = 04690, loss = 1.2629
2024-10-30 14:26:29: [2024-10-30 14:26:29] iter = 04700, loss = 2.4672
2024-10-30 14:26:29: [2024-10-30 14:26:29] iter = 04710, loss = 1.9440
2024-10-30 14:26:30: [2024-10-30 14:26:30] iter = 04720, loss = 3.9009
2024-10-30 14:26:30: [2024-10-30 14:26:30] iter = 04730, loss = 4.3484
2024-10-30 14:26:31: [2024-10-30 14:26:31] iter = 04740, loss = 5.1929
2024-10-30 14:26:31: [2024-10-30 14:26:31] iter = 04750, loss = 2.7273
2024-10-30 14:26:32: [2024-10-30 14:26:32] iter = 04760, loss = 2.3881
2024-10-30 14:26:32: [2024-10-30 14:26:32] iter = 04770, loss = 3.9771
2024-10-30 14:26:33: [2024-10-30 14:26:33] iter = 04780, loss = 1.3781
2024-10-30 14:26:33: [2024-10-30 14:26:33] iter = 04790, loss = 1.7601
2024-10-30 14:26:34: [2024-10-30 14:26:34] iter = 04800, loss = 15.8458
2024-10-30 14:26:34: [2024-10-30 14:26:34] iter = 04810, loss = 1.8255
2024-10-30 14:26:35: [2024-10-30 14:26:35] iter = 04820, loss = 10.6445
2024-10-30 14:26:35: [2024-10-30 14:26:35] iter = 04830, loss = 1.8330
2024-10-30 14:26:36: [2024-10-30 14:26:36] iter = 04840, loss = 5.0542
2024-10-30 14:26:36: [2024-10-30 14:26:36] iter = 04850, loss = 17.5319
2024-10-30 14:26:37: [2024-10-30 14:26:37] iter = 04860, loss = 2.0431
2024-10-30 14:26:37: [2024-10-30 14:26:37] iter = 04870, loss = 3.3303
2024-10-30 14:26:37: [2024-10-30 14:26:37] iter = 04880, loss = 1.4133
2024-10-30 14:26:38: [2024-10-30 14:26:38] iter = 04890, loss = 1.4286
2024-10-30 14:26:38: [2024-10-30 14:26:38] iter = 04900, loss = 4.0232
2024-10-30 14:26:39: [2024-10-30 14:26:39] iter = 04910, loss = 1.9098
2024-10-30 14:26:39: [2024-10-30 14:26:39] iter = 04920, loss = 1.2773
2024-10-30 14:26:40: [2024-10-30 14:26:40] iter = 04930, loss = 1.4449
2024-10-30 14:26:40: [2024-10-30 14:26:40] iter = 04940, loss = 4.4832
2024-10-30 14:26:41: [2024-10-30 14:26:41] iter = 04950, loss = 3.7148
2024-10-30 14:26:41: [2024-10-30 14:26:41] iter = 04960, loss = 1.6552
2024-10-30 14:26:41: [2024-10-30 14:26:41] iter = 04970, loss = 1.6051
2024-10-30 14:26:42: [2024-10-30 14:26:42] iter = 04980, loss = 1.4119
2024-10-30 14:26:42: [2024-10-30 14:26:42] iter = 04990, loss = 1.8424
2024-10-30 14:26:43: [2024-10-30 14:26:43] iter = 05000, loss = 4.5777
2024-10-30 14:26:43: [2024-10-30 14:26:43] iter = 05010, loss = 2.7774
2024-10-30 14:26:44: [2024-10-30 14:26:44] iter = 05020, loss = 17.4854
2024-10-30 14:26:44: [2024-10-30 14:26:44] iter = 05030, loss = 1.2297
2024-10-30 14:26:45: [2024-10-30 14:26:45] iter = 05040, loss = 25.2698
2024-10-30 14:26:45: [2024-10-30 14:26:45] iter = 05050, loss = 3.9724
2024-10-30 14:26:46: [2024-10-30 14:26:46] iter = 05060, loss = 3.1501
2024-10-30 14:26:46: [2024-10-30 14:26:46] iter = 05070, loss = 7.6519
2024-10-30 14:26:47: [2024-10-30 14:26:47] iter = 05080, loss = 3.6937
2024-10-30 14:26:47: [2024-10-30 14:26:47] iter = 05090, loss = 1.3221
2024-10-30 14:26:48: [2024-10-30 14:26:48] iter = 05100, loss = 21.7522
2024-10-30 14:26:48: [2024-10-30 14:26:48] iter = 05110, loss = 1.9320
2024-10-30 14:26:49: [2024-10-30 14:26:49] iter = 05120, loss = 1.8787
2024-10-30 14:26:49: [2024-10-30 14:26:49] iter = 05130, loss = 1.5024
2024-10-30 14:26:50: [2024-10-30 14:26:50] iter = 05140, loss = 1.9967
2024-10-30 14:26:50: [2024-10-30 14:26:50] iter = 05150, loss = 5.0491
2024-10-30 14:26:51: [2024-10-30 14:26:51] iter = 05160, loss = 5.9140
2024-10-30 14:26:51: [2024-10-30 14:26:51] iter = 05170, loss = 4.1083
2024-10-30 14:26:52: [2024-10-30 14:26:52] iter = 05180, loss = 2.0175
2024-10-30 14:26:52: [2024-10-30 14:26:52] iter = 05190, loss = 1.2595
2024-10-30 14:26:53: [2024-10-30 14:26:53] iter = 05200, loss = 1.6427
2024-10-30 14:26:53: [2024-10-30 14:26:53] iter = 05210, loss = 1.6626
2024-10-30 14:26:54: [2024-10-30 14:26:54] iter = 05220, loss = 2.2770
2024-10-30 14:26:54: [2024-10-30 14:26:54] iter = 05230, loss = 4.7377
2024-10-30 14:26:55: [2024-10-30 14:26:55] iter = 05240, loss = 1.2432
2024-10-30 14:26:56: [2024-10-30 14:26:56] iter = 05250, loss = 3.8606
2024-10-30 14:26:56: [2024-10-30 14:26:56] iter = 05260, loss = 4.9740
2024-10-30 14:26:57: [2024-10-30 14:26:57] iter = 05270, loss = 2.4383
2024-10-30 14:26:57: [2024-10-30 14:26:57] iter = 05280, loss = 7.6834
2024-10-30 14:26:58: [2024-10-30 14:26:58] iter = 05290, loss = 10.4566
2024-10-30 14:26:58: [2024-10-30 14:26:58] iter = 05300, loss = 3.2614
2024-10-30 14:26:59: [2024-10-30 14:26:58] iter = 05310, loss = 12.1967
2024-10-30 14:26:59: [2024-10-30 14:26:59] iter = 05320, loss = 4.4571
2024-10-30 14:27:00: [2024-10-30 14:27:00] iter = 05330, loss = 23.8710
2024-10-30 14:27:00: [2024-10-30 14:27:00] iter = 05340, loss = 2.2984
2024-10-30 14:27:01: [2024-10-30 14:27:01] iter = 05350, loss = 4.3388
2024-10-30 14:27:01: [2024-10-30 14:27:01] iter = 05360, loss = 2.0887
2024-10-30 14:27:02: [2024-10-30 14:27:02] iter = 05370, loss = 1.3091
2024-10-30 14:27:02: [2024-10-30 14:27:02] iter = 05380, loss = 1.3667
2024-10-30 14:27:03: [2024-10-30 14:27:03] iter = 05390, loss = 5.1676
2024-10-30 14:27:03: [2024-10-30 14:27:03] iter = 05400, loss = 2.3600
2024-10-30 14:27:04: [2024-10-30 14:27:04] iter = 05410, loss = 1.0665
2024-10-30 14:27:04: [2024-10-30 14:27:04] iter = 05420, loss = 4.6116
2024-10-30 14:27:04: [2024-10-30 14:27:04] iter = 05430, loss = 2.0186
2024-10-30 14:27:05: [2024-10-30 14:27:05] iter = 05440, loss = 1.5147
2024-10-30 14:27:05: [2024-10-30 14:27:05] iter = 05450, loss = 2.4408
2024-10-30 14:27:06: [2024-10-30 14:27:06] iter = 05460, loss = 1.7031
2024-10-30 14:27:06: [2024-10-30 14:27:06] iter = 05470, loss = 10.9359
2024-10-30 14:27:06: [2024-10-30 14:27:06] iter = 05480, loss = 1.8086
2024-10-30 14:27:07: [2024-10-30 14:27:07] iter = 05490, loss = 2.3849
2024-10-30 14:27:07: [2024-10-30 14:27:07] iter = 05500, loss = 2.1267
2024-10-30 14:27:08: [2024-10-30 14:27:08] iter = 05510, loss = 1.0794
2024-10-30 14:27:08: [2024-10-30 14:27:08] iter = 05520, loss = 11.9760
2024-10-30 14:27:09: [2024-10-30 14:27:09] iter = 05530, loss = 29.3262
2024-10-30 14:27:09: [2024-10-30 14:27:09] iter = 05540, loss = 1.2877
2024-10-30 14:27:10: [2024-10-30 14:27:10] iter = 05550, loss = 1.3251
2024-10-30 14:27:10: [2024-10-30 14:27:10] iter = 05560, loss = 4.1088
2024-10-30 14:27:11: [2024-10-30 14:27:11] iter = 05570, loss = 2.7414
2024-10-30 14:27:11: [2024-10-30 14:27:11] iter = 05580, loss = 24.3012
2024-10-30 14:27:12: [2024-10-30 14:27:12] iter = 05590, loss = 1.9876
2024-10-30 14:27:12: [2024-10-30 14:27:12] iter = 05600, loss = 5.4755
2024-10-30 14:27:12: [2024-10-30 14:27:12] iter = 05610, loss = 1.4535
2024-10-30 14:27:13: [2024-10-30 14:27:13] iter = 05620, loss = 3.9391
2024-10-30 14:27:13: [2024-10-30 14:27:13] iter = 05630, loss = 6.3305
2024-10-30 14:27:13: [2024-10-30 14:27:13] iter = 05640, loss = 4.7641
2024-10-30 14:27:14: [2024-10-30 14:27:14] iter = 05650, loss = 4.1186
2024-10-30 14:27:14: [2024-10-30 14:27:14] iter = 05660, loss = 2.7372
2024-10-30 14:27:15: [2024-10-30 14:27:15] iter = 05670, loss = 3.8919
2024-10-30 14:27:15: [2024-10-30 14:27:15] iter = 05680, loss = 1.4104
2024-10-30 14:27:16: [2024-10-30 14:27:16] iter = 05690, loss = 4.6683
2024-10-30 14:27:17: [2024-10-30 14:27:17] iter = 05700, loss = 2.7509
2024-10-30 14:27:17: [2024-10-30 14:27:17] iter = 05710, loss = 6.0864
2024-10-30 14:27:17: [2024-10-30 14:27:17] iter = 05720, loss = 2.6228
2024-10-30 14:27:18: [2024-10-30 14:27:18] iter = 05730, loss = 1.5467
2024-10-30 14:27:18: [2024-10-30 14:27:18] iter = 05740, loss = 5.6281
2024-10-30 14:27:18: [2024-10-30 14:27:18] iter = 05750, loss = 3.8407
2024-10-30 14:27:19: [2024-10-30 14:27:19] iter = 05760, loss = 2.7487
2024-10-30 14:27:20: [2024-10-30 14:27:20] iter = 05770, loss = 5.1548
2024-10-30 14:27:20: [2024-10-30 14:27:20] iter = 05780, loss = 25.5076
2024-10-30 14:27:21: [2024-10-30 14:27:21] iter = 05790, loss = 4.6562
2024-10-30 14:27:21: [2024-10-30 14:27:21] iter = 05800, loss = 22.8406
2024-10-30 14:27:21: [2024-10-30 14:27:21] iter = 05810, loss = 3.1612
2024-10-30 14:27:22: [2024-10-30 14:27:22] iter = 05820, loss = 2.7853
2024-10-30 14:27:22: [2024-10-30 14:27:22] iter = 05830, loss = 2.3804
2024-10-30 14:27:22: [2024-10-30 14:27:22] iter = 05840, loss = 7.3408
2024-10-30 14:27:23: [2024-10-30 14:27:23] iter = 05850, loss = 1.4463
2024-10-30 14:27:23: [2024-10-30 14:27:23] iter = 05860, loss = 1.2336
2024-10-30 14:27:24: [2024-10-30 14:27:24] iter = 05870, loss = 1.2426
2024-10-30 14:27:24: [2024-10-30 14:27:24] iter = 05880, loss = 3.6868
2024-10-30 14:27:24: [2024-10-30 14:27:24] iter = 05890, loss = 2.5656
2024-10-30 14:27:25: [2024-10-30 14:27:25] iter = 05900, loss = 2.2274
2024-10-30 14:27:25: [2024-10-30 14:27:25] iter = 05910, loss = 1.1449
2024-10-30 14:27:26: [2024-10-30 14:27:26] iter = 05920, loss = 1.1597
2024-10-30 14:27:26: [2024-10-30 14:27:26] iter = 05930, loss = 4.1217
2024-10-30 14:27:27: [2024-10-30 14:27:27] iter = 05940, loss = 6.2053
2024-10-30 14:27:28: [2024-10-30 14:27:28] iter = 05950, loss = 13.0170
2024-10-30 14:27:28: [2024-10-30 14:27:28] iter = 05960, loss = 1.8884
2024-10-30 14:27:28: [2024-10-30 14:27:28] iter = 05970, loss = 23.1595
2024-10-30 14:27:29: [2024-10-30 14:27:29] iter = 05980, loss = 2.8343
2024-10-30 14:27:29: [2024-10-30 14:27:29] iter = 05990, loss = 10.3757
2024-10-30 14:27:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 14:27:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:27:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49652}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:28:14: Evaluate 5 random ConvNet, ACCmean = 0.7577 ACCstd = 0.0159
-------------------------
2024-10-30 14:28:14: Evaluate 5 random ConvNet, SENmean = 0.7335 SENstd = 0.0117
-------------------------
2024-10-30 14:28:14: Evaluate 5 random ConvNet, SPEmean = 0.7335 SPEstd = 0.0117
-------------------------
2024-10-30 14:28:14: Evaluate 5 random ConvNet, F!mean = 0.7141 F!std = 0.0148
-------------------------
2024-10-30 14:28:14: Evaluate 5 random ConvNet, mean = 0.7577 std = 0.0159
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:28:14: [2024-10-30 14:28:14] iter = 06000, loss = 2.6217
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:28:14: [2024-10-30 14:28:14] iter = 06010, loss = 1.2045
2024-10-30 14:28:15: [2024-10-30 14:28:15] iter = 06020, loss = 8.2602
2024-10-30 14:28:15: [2024-10-30 14:28:15] iter = 06030, loss = 15.7370
2024-10-30 14:28:16: [2024-10-30 14:28:16] iter = 06040, loss = 1.8612
2024-10-30 14:28:17: [2024-10-30 14:28:17] iter = 06050, loss = 1.5791
2024-10-30 14:28:17: [2024-10-30 14:28:17] iter = 06060, loss = 1.4619
2024-10-30 14:28:17: [2024-10-30 14:28:17] iter = 06070, loss = 1.8734
2024-10-30 14:28:18: [2024-10-30 14:28:18] iter = 06080, loss = 1.4082
2024-10-30 14:28:18: [2024-10-30 14:28:18] iter = 06090, loss = 7.3646
2024-10-30 14:28:19: [2024-10-30 14:28:19] iter = 06100, loss = 10.4158
2024-10-30 14:28:19: [2024-10-30 14:28:19] iter = 06110, loss = 1.3526
2024-10-30 14:28:20: [2024-10-30 14:28:20] iter = 06120, loss = 1.0928
2024-10-30 14:28:20: [2024-10-30 14:28:20] iter = 06130, loss = 1.0543
2024-10-30 14:28:21: [2024-10-30 14:28:21] iter = 06140, loss = 3.2681
2024-10-30 14:28:21: [2024-10-30 14:28:21] iter = 06150, loss = 1.8195
2024-10-30 14:28:22: [2024-10-30 14:28:22] iter = 06160, loss = 3.2899
2024-10-30 14:28:22: [2024-10-30 14:28:22] iter = 06170, loss = 2.3682
2024-10-30 14:28:22: [2024-10-30 14:28:22] iter = 06180, loss = 1.7002
2024-10-30 14:28:23: [2024-10-30 14:28:23] iter = 06190, loss = 30.8035
2024-10-30 14:28:24: [2024-10-30 14:28:24] iter = 06200, loss = 1.7515
2024-10-30 14:28:24: [2024-10-30 14:28:24] iter = 06210, loss = 1.9421
2024-10-30 14:28:25: [2024-10-30 14:28:25] iter = 06220, loss = 2.4185
2024-10-30 14:28:25: [2024-10-30 14:28:25] iter = 06230, loss = 5.6009
2024-10-30 14:28:25: [2024-10-30 14:28:25] iter = 06240, loss = 1.3227
2024-10-30 14:28:26: [2024-10-30 14:28:26] iter = 06250, loss = 1.1819
2024-10-30 14:28:27: [2024-10-30 14:28:27] iter = 06260, loss = 2.4767
2024-10-30 14:28:27: [2024-10-30 14:28:27] iter = 06270, loss = 1.5471
2024-10-30 14:28:28: [2024-10-30 14:28:28] iter = 06280, loss = 2.9347
2024-10-30 14:28:28: [2024-10-30 14:28:28] iter = 06290, loss = 2.1203
2024-10-30 14:28:29: [2024-10-30 14:28:29] iter = 06300, loss = 1.3975
2024-10-30 14:28:29: [2024-10-30 14:28:29] iter = 06310, loss = 3.6801
2024-10-30 14:28:30: [2024-10-30 14:28:30] iter = 06320, loss = 12.5424
2024-10-30 14:28:30: [2024-10-30 14:28:30] iter = 06330, loss = 2.0215
2024-10-30 14:28:31: [2024-10-30 14:28:31] iter = 06340, loss = 1.8782
2024-10-30 14:28:31: [2024-10-30 14:28:31] iter = 06350, loss = 1.0674
2024-10-30 14:28:31: [2024-10-30 14:28:31] iter = 06360, loss = 1.5051
2024-10-30 14:28:32: [2024-10-30 14:28:32] iter = 06370, loss = 21.9731
2024-10-30 14:28:32: [2024-10-30 14:28:32] iter = 06380, loss = 2.1298
2024-10-30 14:28:33: [2024-10-30 14:28:33] iter = 06390, loss = 5.1794
2024-10-30 14:28:33: [2024-10-30 14:28:33] iter = 06400, loss = 5.5023
2024-10-30 14:28:33: [2024-10-30 14:28:33] iter = 06410, loss = 3.7654
2024-10-30 14:28:34: [2024-10-30 14:28:34] iter = 06420, loss = 1.9532
2024-10-30 14:28:34: [2024-10-30 14:28:34] iter = 06430, loss = 4.7915
2024-10-30 14:28:35: [2024-10-30 14:28:35] iter = 06440, loss = 9.5643
2024-10-30 14:28:35: [2024-10-30 14:28:35] iter = 06450, loss = 2.2046
2024-10-30 14:28:35: [2024-10-30 14:28:35] iter = 06460, loss = 2.2049
2024-10-30 14:28:36: [2024-10-30 14:28:36] iter = 06470, loss = 1.5125
2024-10-30 14:28:36: [2024-10-30 14:28:36] iter = 06480, loss = 2.7214
2024-10-30 14:28:37: [2024-10-30 14:28:37] iter = 06490, loss = 2.5166
2024-10-30 14:28:37: [2024-10-30 14:28:37] iter = 06500, loss = 1.6331
2024-10-30 14:28:38: [2024-10-30 14:28:38] iter = 06510, loss = 1.4921
2024-10-30 14:28:38: [2024-10-30 14:28:38] iter = 06520, loss = 3.2734
2024-10-30 14:28:38: [2024-10-30 14:28:38] iter = 06530, loss = 1.8743
2024-10-30 14:28:39: [2024-10-30 14:28:39] iter = 06540, loss = 2.1329
2024-10-30 14:28:39: [2024-10-30 14:28:39] iter = 06550, loss = 7.9675
2024-10-30 14:28:40: [2024-10-30 14:28:40] iter = 06560, loss = 8.0849
2024-10-30 14:28:40: [2024-10-30 14:28:40] iter = 06570, loss = 1.7424
2024-10-30 14:28:40: [2024-10-30 14:28:40] iter = 06580, loss = 1.4558
2024-10-30 14:28:41: [2024-10-30 14:28:41] iter = 06590, loss = 7.3056
2024-10-30 14:28:41: [2024-10-30 14:28:41] iter = 06600, loss = 4.3444
2024-10-30 14:28:42: [2024-10-30 14:28:42] iter = 06610, loss = 1.9883
2024-10-30 14:28:42: [2024-10-30 14:28:42] iter = 06620, loss = 1.8600
2024-10-30 14:28:42: [2024-10-30 14:28:42] iter = 06630, loss = 5.5464
2024-10-30 14:28:43: [2024-10-30 14:28:43] iter = 06640, loss = 1.4222
2024-10-30 14:28:43: [2024-10-30 14:28:43] iter = 06650, loss = 56.8448
2024-10-30 14:28:43: [2024-10-30 14:28:43] iter = 06660, loss = 9.2774
2024-10-30 14:28:44: [2024-10-30 14:28:44] iter = 06670, loss = 34.4724
2024-10-30 14:28:44: [2024-10-30 14:28:44] iter = 06680, loss = 19.9487
2024-10-30 14:28:45: [2024-10-30 14:28:45] iter = 06690, loss = 1.8027
2024-10-30 14:28:45: [2024-10-30 14:28:45] iter = 06700, loss = 4.4500
2024-10-30 14:28:45: [2024-10-30 14:28:45] iter = 06710, loss = 4.3366
2024-10-30 14:28:46: [2024-10-30 14:28:46] iter = 06720, loss = 1.3873
2024-10-30 14:28:46: [2024-10-30 14:28:46] iter = 06730, loss = 1.4907
2024-10-30 14:28:47: [2024-10-30 14:28:47] iter = 06740, loss = 4.2856
2024-10-30 14:28:47: [2024-10-30 14:28:47] iter = 06750, loss = 7.4735
2024-10-30 14:28:47: [2024-10-30 14:28:47] iter = 06760, loss = 7.2771
2024-10-30 14:28:48: [2024-10-30 14:28:48] iter = 06770, loss = 10.0975
2024-10-30 14:28:49: [2024-10-30 14:28:49] iter = 06780, loss = 1.4033
2024-10-30 14:28:49: [2024-10-30 14:28:49] iter = 06790, loss = 4.4874
2024-10-30 14:28:49: [2024-10-30 14:28:49] iter = 06800, loss = 4.4981
2024-10-30 14:28:50: [2024-10-30 14:28:50] iter = 06810, loss = 3.3327
2024-10-30 14:28:50: [2024-10-30 14:28:50] iter = 06820, loss = 6.2390
2024-10-30 14:28:50: [2024-10-30 14:28:50] iter = 06830, loss = 1.4609
2024-10-30 14:28:51: [2024-10-30 14:28:51] iter = 06840, loss = 1.0098
2024-10-30 14:28:51: [2024-10-30 14:28:51] iter = 06850, loss = 3.3415
2024-10-30 14:28:52: [2024-10-30 14:28:52] iter = 06860, loss = 2.4117
2024-10-30 14:28:52: [2024-10-30 14:28:52] iter = 06870, loss = 1.4529
2024-10-30 14:28:53: [2024-10-30 14:28:53] iter = 06880, loss = 1.7078
2024-10-30 14:28:53: [2024-10-30 14:28:53] iter = 06890, loss = 17.2037
2024-10-30 14:28:53: [2024-10-30 14:28:53] iter = 06900, loss = 4.2732
2024-10-30 14:28:54: [2024-10-30 14:28:54] iter = 06910, loss = 1.6579
2024-10-30 14:28:54: [2024-10-30 14:28:54] iter = 06920, loss = 1.5644
2024-10-30 14:28:54: [2024-10-30 14:28:54] iter = 06930, loss = 2.6396
2024-10-30 14:28:55: [2024-10-30 14:28:55] iter = 06940, loss = 2.1876
2024-10-30 14:28:55: [2024-10-30 14:28:55] iter = 06950, loss = 1.3433
2024-10-30 14:28:56: [2024-10-30 14:28:56] iter = 06960, loss = 2.0295
2024-10-30 14:28:56: [2024-10-30 14:28:56] iter = 06970, loss = 2.1915
2024-10-30 14:28:57: [2024-10-30 14:28:57] iter = 06980, loss = 5.4552
2024-10-30 14:28:57: [2024-10-30 14:28:57] iter = 06990, loss = 2.5481
2024-10-30 14:28:58: [2024-10-30 14:28:58] iter = 07000, loss = 2.7744
2024-10-30 14:28:59: [2024-10-30 14:28:59] iter = 07010, loss = 5.7074
2024-10-30 14:28:59: [2024-10-30 14:28:59] iter = 07020, loss = 1.6700
2024-10-30 14:29:00: [2024-10-30 14:29:00] iter = 07030, loss = 3.5221
2024-10-30 14:29:00: [2024-10-30 14:29:00] iter = 07040, loss = 2.4012
2024-10-30 14:29:01: [2024-10-30 14:29:01] iter = 07050, loss = 1.4761
2024-10-30 14:29:01: [2024-10-30 14:29:01] iter = 07060, loss = 0.9969
2024-10-30 14:29:01: [2024-10-30 14:29:01] iter = 07070, loss = 5.3725
2024-10-30 14:29:02: [2024-10-30 14:29:02] iter = 07080, loss = 2.2717
2024-10-30 14:29:02: [2024-10-30 14:29:02] iter = 07090, loss = 2.0001
2024-10-30 14:29:03: [2024-10-30 14:29:03] iter = 07100, loss = 1.3634
2024-10-30 14:29:03: [2024-10-30 14:29:03] iter = 07110, loss = 1.5163
2024-10-30 14:29:04: [2024-10-30 14:29:04] iter = 07120, loss = 15.9012
2024-10-30 14:29:04: [2024-10-30 14:29:04] iter = 07130, loss = 4.8197
2024-10-30 14:29:04: [2024-10-30 14:29:04] iter = 07140, loss = 1.7296
2024-10-30 14:29:05: [2024-10-30 14:29:05] iter = 07150, loss = 2.0023
2024-10-30 14:29:05: [2024-10-30 14:29:05] iter = 07160, loss = 45.6591
2024-10-30 14:29:06: [2024-10-30 14:29:06] iter = 07170, loss = 3.0497
2024-10-30 14:29:06: [2024-10-30 14:29:06] iter = 07180, loss = 2.1663
2024-10-30 14:29:07: [2024-10-30 14:29:07] iter = 07190, loss = 1.5932
2024-10-30 14:29:07: [2024-10-30 14:29:07] iter = 07200, loss = 1.0988
2024-10-30 14:29:08: [2024-10-30 14:29:08] iter = 07210, loss = 9.3231
2024-10-30 14:29:08: [2024-10-30 14:29:08] iter = 07220, loss = 2.0755
2024-10-30 14:29:09: [2024-10-30 14:29:09] iter = 07230, loss = 5.0314
2024-10-30 14:29:09: [2024-10-30 14:29:09] iter = 07240, loss = 1.6723
2024-10-30 14:29:09: [2024-10-30 14:29:09] iter = 07250, loss = 2.5456
2024-10-30 14:29:10: [2024-10-30 14:29:10] iter = 07260, loss = 1.5660
2024-10-30 14:29:10: [2024-10-30 14:29:10] iter = 07270, loss = 3.4793
2024-10-30 14:29:11: [2024-10-30 14:29:11] iter = 07280, loss = 2.3253
2024-10-30 14:29:11: [2024-10-30 14:29:11] iter = 07290, loss = 7.7009
2024-10-30 14:29:12: [2024-10-30 14:29:12] iter = 07300, loss = 9.4701
2024-10-30 14:29:12: [2024-10-30 14:29:12] iter = 07310, loss = 7.0175
2024-10-30 14:29:13: [2024-10-30 14:29:13] iter = 07320, loss = 1.7146
2024-10-30 14:29:13: [2024-10-30 14:29:13] iter = 07330, loss = 12.7752
2024-10-30 14:29:14: [2024-10-30 14:29:14] iter = 07340, loss = 1.8791
2024-10-30 14:29:14: [2024-10-30 14:29:14] iter = 07350, loss = 4.8157
2024-10-30 14:29:14: [2024-10-30 14:29:14] iter = 07360, loss = 1.8427
2024-10-30 14:29:15: [2024-10-30 14:29:15] iter = 07370, loss = 16.9864
2024-10-30 14:29:15: [2024-10-30 14:29:15] iter = 07380, loss = 1.5574
2024-10-30 14:29:16: [2024-10-30 14:29:16] iter = 07390, loss = 3.1626
2024-10-30 14:29:17: [2024-10-30 14:29:17] iter = 07400, loss = 1.2612
2024-10-30 14:29:17: [2024-10-30 14:29:17] iter = 07410, loss = 2.2442
2024-10-30 14:29:18: [2024-10-30 14:29:18] iter = 07420, loss = 1.1739
2024-10-30 14:29:18: [2024-10-30 14:29:18] iter = 07430, loss = 1.1592
2024-10-30 14:29:19: [2024-10-30 14:29:19] iter = 07440, loss = 1.9795
2024-10-30 14:29:19: [2024-10-30 14:29:19] iter = 07450, loss = 1.8444
2024-10-30 14:29:19: [2024-10-30 14:29:19] iter = 07460, loss = 2.4254
2024-10-30 14:29:20: [2024-10-30 14:29:20] iter = 07470, loss = 1.9742
2024-10-30 14:29:20: [2024-10-30 14:29:20] iter = 07480, loss = 1.2430
2024-10-30 14:29:21: [2024-10-30 14:29:21] iter = 07490, loss = 2.6183
2024-10-30 14:29:22: [2024-10-30 14:29:22] iter = 07500, loss = 6.8349
2024-10-30 14:29:22: [2024-10-30 14:29:22] iter = 07510, loss = 1.4912
2024-10-30 14:29:23: [2024-10-30 14:29:23] iter = 07520, loss = 2.3759
2024-10-30 14:29:23: [2024-10-30 14:29:23] iter = 07530, loss = 2.1658
2024-10-30 14:29:24: [2024-10-30 14:29:24] iter = 07540, loss = 3.0173
2024-10-30 14:29:24: [2024-10-30 14:29:24] iter = 07550, loss = 4.0764
2024-10-30 14:29:25: [2024-10-30 14:29:25] iter = 07560, loss = 7.3955
2024-10-30 14:29:25: [2024-10-30 14:29:25] iter = 07570, loss = 8.7804
2024-10-30 14:29:26: [2024-10-30 14:29:26] iter = 07580, loss = 7.3068
2024-10-30 14:29:26: [2024-10-30 14:29:26] iter = 07590, loss = 9.1134
2024-10-30 14:29:27: [2024-10-30 14:29:27] iter = 07600, loss = 2.0970
2024-10-30 14:29:28: [2024-10-30 14:29:28] iter = 07610, loss = 3.4314
2024-10-30 14:29:28: [2024-10-30 14:29:28] iter = 07620, loss = 9.9740
2024-10-30 14:29:29: [2024-10-30 14:29:29] iter = 07630, loss = 1.7506
2024-10-30 14:29:29: [2024-10-30 14:29:29] iter = 07640, loss = 1.0289
2024-10-30 14:29:30: [2024-10-30 14:29:30] iter = 07650, loss = 5.7413
2024-10-30 14:29:30: [2024-10-30 14:29:30] iter = 07660, loss = 3.2143
2024-10-30 14:29:31: [2024-10-30 14:29:31] iter = 07670, loss = 5.3586
2024-10-30 14:29:31: [2024-10-30 14:29:31] iter = 07680, loss = 7.3908
2024-10-30 14:29:32: [2024-10-30 14:29:32] iter = 07690, loss = 3.7505
2024-10-30 14:29:32: [2024-10-30 14:29:32] iter = 07700, loss = 3.8193
2024-10-30 14:29:33: [2024-10-30 14:29:33] iter = 07710, loss = 11.2914
2024-10-30 14:29:33: [2024-10-30 14:29:33] iter = 07720, loss = 1.2956
2024-10-30 14:29:34: [2024-10-30 14:29:34] iter = 07730, loss = 3.5133
2024-10-30 14:29:34: [2024-10-30 14:29:34] iter = 07740, loss = 4.8069
2024-10-30 14:29:35: [2024-10-30 14:29:35] iter = 07750, loss = 3.0326
2024-10-30 14:29:35: [2024-10-30 14:29:35] iter = 07760, loss = 1.6075
2024-10-30 14:29:35: [2024-10-30 14:29:35] iter = 07770, loss = 2.6789
2024-10-30 14:29:36: [2024-10-30 14:29:36] iter = 07780, loss = 1.3037
2024-10-30 14:29:36: [2024-10-30 14:29:36] iter = 07790, loss = 9.2338
2024-10-30 14:29:37: [2024-10-30 14:29:37] iter = 07800, loss = 6.2306
2024-10-30 14:29:37: [2024-10-30 14:29:37] iter = 07810, loss = 47.9572
2024-10-30 14:29:38: [2024-10-30 14:29:38] iter = 07820, loss = 1.9311
2024-10-30 14:29:38: [2024-10-30 14:29:38] iter = 07830, loss = 3.5834
2024-10-30 14:29:39: [2024-10-30 14:29:39] iter = 07840, loss = 7.2730
2024-10-30 14:29:39: [2024-10-30 14:29:39] iter = 07850, loss = 1.4802
2024-10-30 14:29:40: [2024-10-30 14:29:39] iter = 07860, loss = 3.7549
2024-10-30 14:29:40: [2024-10-30 14:29:40] iter = 07870, loss = 2.1815
2024-10-30 14:29:40: [2024-10-30 14:29:40] iter = 07880, loss = 1.3902
2024-10-30 14:29:40: [2024-10-30 14:29:40] iter = 07890, loss = 1.4680
2024-10-30 14:29:41: [2024-10-30 14:29:41] iter = 07900, loss = 8.0299
2024-10-30 14:29:41: [2024-10-30 14:29:41] iter = 07910, loss = 2.4671
2024-10-30 14:29:41: [2024-10-30 14:29:41] iter = 07920, loss = 1.4179
2024-10-30 14:29:42: [2024-10-30 14:29:42] iter = 07930, loss = 6.2553
2024-10-30 14:29:42: [2024-10-30 14:29:42] iter = 07940, loss = 1.4694
2024-10-30 14:29:42: [2024-10-30 14:29:42] iter = 07950, loss = 3.1990
2024-10-30 14:29:43: [2024-10-30 14:29:43] iter = 07960, loss = 9.3846
2024-10-30 14:29:43: [2024-10-30 14:29:43] iter = 07970, loss = 2.5128
2024-10-30 14:29:44: [2024-10-30 14:29:44] iter = 07980, loss = 1.4752
2024-10-30 14:29:44: [2024-10-30 14:29:44] iter = 07990, loss = 5.1695
2024-10-30 14:29:45: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 14:29:45: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:29:45: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 85249}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:30:32: Evaluate 5 random ConvNet, ACCmean = 0.6462 ACCstd = 0.0267
-------------------------
2024-10-30 14:30:32: Evaluate 5 random ConvNet, SENmean = 0.7113 SENstd = 0.0210
-------------------------
2024-10-30 14:30:32: Evaluate 5 random ConvNet, SPEmean = 0.7113 SPEstd = 0.0210
-------------------------
2024-10-30 14:30:32: Evaluate 5 random ConvNet, F!mean = 0.6333 F!std = 0.0244
-------------------------
2024-10-30 14:30:32: Evaluate 5 random ConvNet, mean = 0.6462 std = 0.0267
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:30:33: [2024-10-30 14:30:33] iter = 08000, loss = 6.9749
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:30:33: [2024-10-30 14:30:33] iter = 08010, loss = 6.9182
2024-10-30 14:30:33: [2024-10-30 14:30:33] iter = 08020, loss = 10.0105
2024-10-30 14:30:34: [2024-10-30 14:30:34] iter = 08030, loss = 1.8825
2024-10-30 14:30:35: [2024-10-30 14:30:35] iter = 08040, loss = 5.4252
2024-10-30 14:30:35: [2024-10-30 14:30:35] iter = 08050, loss = 1.6048
2024-10-30 14:30:36: [2024-10-30 14:30:36] iter = 08060, loss = 2.1050
2024-10-30 14:30:36: [2024-10-30 14:30:36] iter = 08070, loss = 7.4792
2024-10-30 14:30:36: [2024-10-30 14:30:36] iter = 08080, loss = 1.6007
2024-10-30 14:30:37: [2024-10-30 14:30:37] iter = 08090, loss = 1.4965
2024-10-30 14:30:37: [2024-10-30 14:30:37] iter = 08100, loss = 3.7840
2024-10-30 14:30:38: [2024-10-30 14:30:38] iter = 08110, loss = 4.4003
2024-10-30 14:30:38: [2024-10-30 14:30:38] iter = 08120, loss = 11.5833
2024-10-30 14:30:39: [2024-10-30 14:30:39] iter = 08130, loss = 2.3142
2024-10-30 14:30:39: [2024-10-30 14:30:39] iter = 08140, loss = 5.0219
2024-10-30 14:30:39: [2024-10-30 14:30:39] iter = 08150, loss = 2.0273
2024-10-30 14:30:40: [2024-10-30 14:30:40] iter = 08160, loss = 2.9807
2024-10-30 14:30:40: [2024-10-30 14:30:40] iter = 08170, loss = 16.6198
2024-10-30 14:30:41: [2024-10-30 14:30:41] iter = 08180, loss = 1.2287
2024-10-30 14:30:41: [2024-10-30 14:30:41] iter = 08190, loss = 33.4428
2024-10-30 14:30:42: [2024-10-30 14:30:42] iter = 08200, loss = 4.3309
2024-10-30 14:30:42: [2024-10-30 14:30:42] iter = 08210, loss = 4.7628
2024-10-30 14:30:42: [2024-10-30 14:30:42] iter = 08220, loss = 5.5230
2024-10-30 14:30:43: [2024-10-30 14:30:43] iter = 08230, loss = 2.7605
2024-10-30 14:30:43: [2024-10-30 14:30:43] iter = 08240, loss = 7.9384
2024-10-30 14:30:44: [2024-10-30 14:30:44] iter = 08250, loss = 2.2524
2024-10-30 14:30:44: [2024-10-30 14:30:44] iter = 08260, loss = 3.5701
2024-10-30 14:30:45: [2024-10-30 14:30:45] iter = 08270, loss = 1.8285
2024-10-30 14:30:46: [2024-10-30 14:30:46] iter = 08280, loss = 1.6633
2024-10-30 14:30:46: [2024-10-30 14:30:46] iter = 08290, loss = 3.9137
2024-10-30 14:30:46: [2024-10-30 14:30:46] iter = 08300, loss = 3.7734
2024-10-30 14:30:47: [2024-10-30 14:30:47] iter = 08310, loss = 11.7391
2024-10-30 14:30:47: [2024-10-30 14:30:47] iter = 08320, loss = 45.6958
2024-10-30 14:30:48: [2024-10-30 14:30:48] iter = 08330, loss = 7.1402
2024-10-30 14:30:48: [2024-10-30 14:30:48] iter = 08340, loss = 3.4935
2024-10-30 14:30:49: [2024-10-30 14:30:49] iter = 08350, loss = 13.0901
2024-10-30 14:30:49: [2024-10-30 14:30:49] iter = 08360, loss = 16.8295
2024-10-30 14:30:50: [2024-10-30 14:30:50] iter = 08370, loss = 3.5952
2024-10-30 14:30:50: [2024-10-30 14:30:50] iter = 08380, loss = 2.4598
2024-10-30 14:30:51: [2024-10-30 14:30:51] iter = 08390, loss = 3.5107
2024-10-30 14:30:51: [2024-10-30 14:30:51] iter = 08400, loss = 2.3880
2024-10-30 14:30:52: [2024-10-30 14:30:52] iter = 08410, loss = 3.1024
2024-10-30 14:30:52: [2024-10-30 14:30:52] iter = 08420, loss = 4.4690
2024-10-30 14:30:53: [2024-10-30 14:30:53] iter = 08430, loss = 8.7566
2024-10-30 14:30:54: [2024-10-30 14:30:54] iter = 08440, loss = 1.2695
2024-10-30 14:30:54: [2024-10-30 14:30:54] iter = 08450, loss = 1.4054
2024-10-30 14:30:55: [2024-10-30 14:30:55] iter = 08460, loss = 1.4919
2024-10-30 14:30:55: [2024-10-30 14:30:55] iter = 08470, loss = 1.7522
2024-10-30 14:30:56: [2024-10-30 14:30:56] iter = 08480, loss = 3.5079
2024-10-30 14:30:57: [2024-10-30 14:30:57] iter = 08490, loss = 1.3011
2024-10-30 14:30:57: [2024-10-30 14:30:57] iter = 08500, loss = 1.1812
2024-10-30 14:30:58: [2024-10-30 14:30:58] iter = 08510, loss = 2.8702
2024-10-30 14:30:58: [2024-10-30 14:30:58] iter = 08520, loss = 5.7875
2024-10-30 14:30:59: [2024-10-30 14:30:59] iter = 08530, loss = 2.1138
2024-10-30 14:30:59: [2024-10-30 14:30:59] iter = 08540, loss = 1.4476
2024-10-30 14:31:00: [2024-10-30 14:31:00] iter = 08550, loss = 4.7073
2024-10-30 14:31:00: [2024-10-30 14:31:00] iter = 08560, loss = 1.3154
2024-10-30 14:31:00: [2024-10-30 14:31:00] iter = 08570, loss = 1.3322
2024-10-30 14:31:01: [2024-10-30 14:31:01] iter = 08580, loss = 3.5949
2024-10-30 14:31:01: [2024-10-30 14:31:01] iter = 08590, loss = 3.5637
2024-10-30 14:31:02: [2024-10-30 14:31:02] iter = 08600, loss = 1.5678
2024-10-30 14:31:02: [2024-10-30 14:31:02] iter = 08610, loss = 5.0091
2024-10-30 14:31:02: [2024-10-30 14:31:02] iter = 08620, loss = 15.3565
2024-10-30 14:31:03: [2024-10-30 14:31:03] iter = 08630, loss = 1.9992
2024-10-30 14:31:03: [2024-10-30 14:31:03] iter = 08640, loss = 4.8986
2024-10-30 14:31:03: [2024-10-30 14:31:03] iter = 08650, loss = 2.4717
2024-10-30 14:31:04: [2024-10-30 14:31:04] iter = 08660, loss = 5.9509
2024-10-30 14:31:04: [2024-10-30 14:31:04] iter = 08670, loss = 3.1088
2024-10-30 14:31:05: [2024-10-30 14:31:05] iter = 08680, loss = 3.4122
2024-10-30 14:31:05: [2024-10-30 14:31:05] iter = 08690, loss = 1.4348
2024-10-30 14:31:06: [2024-10-30 14:31:06] iter = 08700, loss = 4.6163
2024-10-30 14:31:06: [2024-10-30 14:31:06] iter = 08710, loss = 5.7300
2024-10-30 14:31:07: [2024-10-30 14:31:07] iter = 08720, loss = 2.0518
2024-10-30 14:31:07: [2024-10-30 14:31:07] iter = 08730, loss = 11.1841
2024-10-30 14:31:08: [2024-10-30 14:31:08] iter = 08740, loss = 3.0969
2024-10-30 14:31:08: [2024-10-30 14:31:08] iter = 08750, loss = 3.0066
2024-10-30 14:31:09: [2024-10-30 14:31:09] iter = 08760, loss = 5.6023
2024-10-30 14:31:09: [2024-10-30 14:31:09] iter = 08770, loss = 1.7790
2024-10-30 14:31:10: [2024-10-30 14:31:10] iter = 08780, loss = 1.7298
2024-10-30 14:31:10: [2024-10-30 14:31:10] iter = 08790, loss = 1.7069
2024-10-30 14:31:11: [2024-10-30 14:31:11] iter = 08800, loss = 14.9242
2024-10-30 14:31:11: [2024-10-30 14:31:11] iter = 08810, loss = 4.6262
2024-10-30 14:31:11: [2024-10-30 14:31:11] iter = 08820, loss = 1.7185
2024-10-30 14:31:12: [2024-10-30 14:31:12] iter = 08830, loss = 1.3826
2024-10-30 14:31:13: [2024-10-30 14:31:13] iter = 08840, loss = 4.9287
2024-10-30 14:31:13: [2024-10-30 14:31:13] iter = 08850, loss = 1.9194
2024-10-30 14:31:14: [2024-10-30 14:31:14] iter = 08860, loss = 9.4004
2024-10-30 14:31:14: [2024-10-30 14:31:14] iter = 08870, loss = 1.7396
2024-10-30 14:31:15: [2024-10-30 14:31:15] iter = 08880, loss = 13.5828
2024-10-30 14:31:15: [2024-10-30 14:31:15] iter = 08890, loss = 9.5081
2024-10-30 14:31:15: [2024-10-30 14:31:15] iter = 08900, loss = 2.2289
2024-10-30 14:31:16: [2024-10-30 14:31:16] iter = 08910, loss = 8.1472
2024-10-30 14:31:16: [2024-10-30 14:31:16] iter = 08920, loss = 6.2904
2024-10-30 14:31:17: [2024-10-30 14:31:17] iter = 08930, loss = 2.8690
2024-10-30 14:31:17: [2024-10-30 14:31:17] iter = 08940, loss = 17.6904
2024-10-30 14:31:18: [2024-10-30 14:31:18] iter = 08950, loss = 2.0138
2024-10-30 14:31:18: [2024-10-30 14:31:18] iter = 08960, loss = 1.7866
2024-10-30 14:31:19: [2024-10-30 14:31:19] iter = 08970, loss = 5.6041
2024-10-30 14:31:20: [2024-10-30 14:31:20] iter = 08980, loss = 2.6112
2024-10-30 14:31:20: [2024-10-30 14:31:20] iter = 08990, loss = 3.4787
2024-10-30 14:31:21: [2024-10-30 14:31:21] iter = 09000, loss = 2.3853
2024-10-30 14:31:21: [2024-10-30 14:31:21] iter = 09010, loss = 9.4609
2024-10-30 14:31:22: [2024-10-30 14:31:22] iter = 09020, loss = 4.1606
2024-10-30 14:31:22: [2024-10-30 14:31:22] iter = 09030, loss = 13.7431
2024-10-30 14:31:23: [2024-10-30 14:31:23] iter = 09040, loss = 4.2863
2024-10-30 14:31:23: [2024-10-30 14:31:23] iter = 09050, loss = 11.8745
2024-10-30 14:31:23: [2024-10-30 14:31:23] iter = 09060, loss = 33.7598
2024-10-30 14:31:24: [2024-10-30 14:31:24] iter = 09070, loss = 14.9989
2024-10-30 14:31:24: [2024-10-30 14:31:24] iter = 09080, loss = 12.6389
2024-10-30 14:31:25: [2024-10-30 14:31:25] iter = 09090, loss = 4.5655
2024-10-30 14:31:25: [2024-10-30 14:31:25] iter = 09100, loss = 2.0420
2024-10-30 14:31:26: [2024-10-30 14:31:26] iter = 09110, loss = 13.3678
2024-10-30 14:31:26: [2024-10-30 14:31:26] iter = 09120, loss = 2.1110
2024-10-30 14:31:26: [2024-10-30 14:31:26] iter = 09130, loss = 1.8327
2024-10-30 14:31:27: [2024-10-30 14:31:27] iter = 09140, loss = 5.0738
2024-10-30 14:31:27: [2024-10-30 14:31:27] iter = 09150, loss = 1.4010
2024-10-30 14:31:28: [2024-10-30 14:31:28] iter = 09160, loss = 1.4732
2024-10-30 14:31:28: [2024-10-30 14:31:28] iter = 09170, loss = 1.4040
2024-10-30 14:31:28: [2024-10-30 14:31:28] iter = 09180, loss = 3.0172
2024-10-30 14:31:29: [2024-10-30 14:31:29] iter = 09190, loss = 5.8053
2024-10-30 14:31:29: [2024-10-30 14:31:29] iter = 09200, loss = 4.8424
2024-10-30 14:31:30: [2024-10-30 14:31:30] iter = 09210, loss = 4.9239
2024-10-30 14:31:30: [2024-10-30 14:31:30] iter = 09220, loss = 5.4100
2024-10-30 14:31:30: [2024-10-30 14:31:30] iter = 09230, loss = 15.0308
2024-10-30 14:31:31: [2024-10-30 14:31:31] iter = 09240, loss = 25.2555
2024-10-30 14:31:31: [2024-10-30 14:31:31] iter = 09250, loss = 3.4842
2024-10-30 14:31:32: [2024-10-30 14:31:32] iter = 09260, loss = 1.6259
2024-10-30 14:31:32: [2024-10-30 14:31:32] iter = 09270, loss = 1.6558
2024-10-30 14:31:33: [2024-10-30 14:31:33] iter = 09280, loss = 2.4546
2024-10-30 14:31:33: [2024-10-30 14:31:33] iter = 09290, loss = 2.7801
2024-10-30 14:31:34: [2024-10-30 14:31:34] iter = 09300, loss = 1.2901
2024-10-30 14:31:34: [2024-10-30 14:31:34] iter = 09310, loss = 7.6109
2024-10-30 14:31:35: [2024-10-30 14:31:35] iter = 09320, loss = 1.8464
2024-10-30 14:31:35: [2024-10-30 14:31:35] iter = 09330, loss = 6.2364
2024-10-30 14:31:36: [2024-10-30 14:31:36] iter = 09340, loss = 1.6764
2024-10-30 14:31:36: [2024-10-30 14:31:36] iter = 09350, loss = 1.6774
2024-10-30 14:31:36: [2024-10-30 14:31:36] iter = 09360, loss = 2.1459
2024-10-30 14:31:37: [2024-10-30 14:31:37] iter = 09370, loss = 1.1782
2024-10-30 14:31:37: [2024-10-30 14:31:37] iter = 09380, loss = 1.0294
2024-10-30 14:31:38: [2024-10-30 14:31:38] iter = 09390, loss = 2.1915
2024-10-30 14:31:38: [2024-10-30 14:31:38] iter = 09400, loss = 2.1492
2024-10-30 14:31:39: [2024-10-30 14:31:39] iter = 09410, loss = 5.2159
2024-10-30 14:31:39: [2024-10-30 14:31:39] iter = 09420, loss = 1.5456
2024-10-30 14:31:40: [2024-10-30 14:31:40] iter = 09430, loss = 1.7426
2024-10-30 14:31:40: [2024-10-30 14:31:40] iter = 09440, loss = 2.3596
2024-10-30 14:31:41: [2024-10-30 14:31:41] iter = 09450, loss = 2.7492
2024-10-30 14:31:42: [2024-10-30 14:31:42] iter = 09460, loss = 1.5968
2024-10-30 14:31:42: [2024-10-30 14:31:42] iter = 09470, loss = 4.2245
2024-10-30 14:31:42: [2024-10-30 14:31:42] iter = 09480, loss = 2.5076
2024-10-30 14:31:43: [2024-10-30 14:31:43] iter = 09490, loss = 11.1965
2024-10-30 14:31:44: [2024-10-30 14:31:43] iter = 09500, loss = 1.6926
2024-10-30 14:31:44: [2024-10-30 14:31:44] iter = 09510, loss = 2.1346
2024-10-30 14:31:45: [2024-10-30 14:31:45] iter = 09520, loss = 3.9309
2024-10-30 14:31:45: [2024-10-30 14:31:45] iter = 09530, loss = 1.6846
2024-10-30 14:31:45: [2024-10-30 14:31:45] iter = 09540, loss = 9.2200
2024-10-30 14:31:46: [2024-10-30 14:31:46] iter = 09550, loss = 2.1594
2024-10-30 14:31:46: [2024-10-30 14:31:46] iter = 09560, loss = 3.2930
2024-10-30 14:31:47: [2024-10-30 14:31:47] iter = 09570, loss = 2.7201
2024-10-30 14:31:47: [2024-10-30 14:31:47] iter = 09580, loss = 3.0279
2024-10-30 14:31:48: [2024-10-30 14:31:48] iter = 09590, loss = 1.5690
2024-10-30 14:31:48: [2024-10-30 14:31:48] iter = 09600, loss = 2.3407
2024-10-30 14:31:49: [2024-10-30 14:31:49] iter = 09610, loss = 2.5722
2024-10-30 14:31:49: [2024-10-30 14:31:49] iter = 09620, loss = 6.2065
2024-10-30 14:31:50: [2024-10-30 14:31:50] iter = 09630, loss = 1.8094
2024-10-30 14:31:50: [2024-10-30 14:31:50] iter = 09640, loss = 11.9474
2024-10-30 14:31:51: [2024-10-30 14:31:51] iter = 09650, loss = 10.4987
2024-10-30 14:31:51: [2024-10-30 14:31:51] iter = 09660, loss = 4.1346
2024-10-30 14:31:52: [2024-10-30 14:31:52] iter = 09670, loss = 1.3736
2024-10-30 14:31:52: [2024-10-30 14:31:52] iter = 09680, loss = 7.6821
2024-10-30 14:31:53: [2024-10-30 14:31:53] iter = 09690, loss = 2.2940
2024-10-30 14:31:53: [2024-10-30 14:31:53] iter = 09700, loss = 1.4241
2024-10-30 14:31:54: [2024-10-30 14:31:54] iter = 09710, loss = 2.4474
2024-10-30 14:31:54: [2024-10-30 14:31:54] iter = 09720, loss = 1.9948
2024-10-30 14:31:55: [2024-10-30 14:31:55] iter = 09730, loss = 2.2304
2024-10-30 14:31:55: [2024-10-30 14:31:55] iter = 09740, loss = 3.0464
2024-10-30 14:31:55: [2024-10-30 14:31:55] iter = 09750, loss = 2.6594
2024-10-30 14:31:56: [2024-10-30 14:31:56] iter = 09760, loss = 1.3286
2024-10-30 14:31:56: [2024-10-30 14:31:56] iter = 09770, loss = 4.0166
2024-10-30 14:31:57: [2024-10-30 14:31:57] iter = 09780, loss = 2.7205
2024-10-30 14:31:58: [2024-10-30 14:31:58] iter = 09790, loss = 2.8693
2024-10-30 14:31:58: [2024-10-30 14:31:58] iter = 09800, loss = 35.5765
2024-10-30 14:31:59: [2024-10-30 14:31:59] iter = 09810, loss = 1.0197
2024-10-30 14:31:59: [2024-10-30 14:31:59] iter = 09820, loss = 2.0495
2024-10-30 14:32:00: [2024-10-30 14:32:00] iter = 09830, loss = 11.4747
2024-10-30 14:32:00: [2024-10-30 14:32:00] iter = 09840, loss = 5.2210
2024-10-30 14:32:01: [2024-10-30 14:32:01] iter = 09850, loss = 1.7554
2024-10-30 14:32:01: [2024-10-30 14:32:01] iter = 09860, loss = 2.4190
2024-10-30 14:32:02: [2024-10-30 14:32:02] iter = 09870, loss = 1.8807
2024-10-30 14:32:03: [2024-10-30 14:32:03] iter = 09880, loss = 1.3826
2024-10-30 14:32:03: [2024-10-30 14:32:03] iter = 09890, loss = 15.8851
2024-10-30 14:32:03: [2024-10-30 14:32:03] iter = 09900, loss = 5.5603
2024-10-30 14:32:04: [2024-10-30 14:32:04] iter = 09910, loss = 4.0915
2024-10-30 14:32:04: [2024-10-30 14:32:04] iter = 09920, loss = 3.3046
2024-10-30 14:32:05: [2024-10-30 14:32:05] iter = 09930, loss = 4.8729
2024-10-30 14:32:05: [2024-10-30 14:32:05] iter = 09940, loss = 1.5653
2024-10-30 14:32:05: [2024-10-30 14:32:05] iter = 09950, loss = 1.6040
2024-10-30 14:32:06: [2024-10-30 14:32:06] iter = 09960, loss = 6.5464
2024-10-30 14:32:06: [2024-10-30 14:32:06] iter = 09970, loss = 3.1513
2024-10-30 14:32:07: [2024-10-30 14:32:07] iter = 09980, loss = 2.3056
2024-10-30 14:32:07: [2024-10-30 14:32:07] iter = 09990, loss = 2.8929
2024-10-30 14:32:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 14:32:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:32:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 28038}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:32:55: Evaluate 5 random ConvNet, ACCmean = 0.7256 ACCstd = 0.0094
-------------------------
2024-10-30 14:32:55: Evaluate 5 random ConvNet, SENmean = 0.6454 SENstd = 0.0134
-------------------------
2024-10-30 14:32:55: Evaluate 5 random ConvNet, SPEmean = 0.6454 SPEstd = 0.0134
-------------------------
2024-10-30 14:32:55: Evaluate 5 random ConvNet, F!mean = 0.6468 F!std = 0.0122
-------------------------
2024-10-30 14:32:55: Evaluate 5 random ConvNet, mean = 0.7256 std = 0.0094
-------------------------
2024-10-30 14:32:55: [2024-10-30 14:32:55] iter = 10000, loss = 2.8567
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:32:55: [2024-10-30 14:32:55] iter = 10010, loss = 7.2119
2024-10-30 14:32:56: [2024-10-30 14:32:56] iter = 10020, loss = 3.0876
2024-10-30 14:32:56: [2024-10-30 14:32:56] iter = 10030, loss = 2.8268
2024-10-30 14:32:57: [2024-10-30 14:32:57] iter = 10040, loss = 5.1522
2024-10-30 14:32:57: [2024-10-30 14:32:57] iter = 10050, loss = 2.8368
2024-10-30 14:32:58: [2024-10-30 14:32:58] iter = 10060, loss = 2.6277
2024-10-30 14:32:58: [2024-10-30 14:32:58] iter = 10070, loss = 1.6484
2024-10-30 14:32:58: [2024-10-30 14:32:58] iter = 10080, loss = 1.9901
2024-10-30 14:32:59: [2024-10-30 14:32:59] iter = 10090, loss = 26.2529
2024-10-30 14:32:59: [2024-10-30 14:32:59] iter = 10100, loss = 2.4686
2024-10-30 14:33:00: [2024-10-30 14:33:00] iter = 10110, loss = 1.5643
2024-10-30 14:33:00: [2024-10-30 14:33:00] iter = 10120, loss = 1.4045
2024-10-30 14:33:01: [2024-10-30 14:33:01] iter = 10130, loss = 1.4244
2024-10-30 14:33:01: [2024-10-30 14:33:01] iter = 10140, loss = 4.9606
2024-10-30 14:33:02: [2024-10-30 14:33:02] iter = 10150, loss = 2.9705
2024-10-30 14:33:02: [2024-10-30 14:33:02] iter = 10160, loss = 9.6242
2024-10-30 14:33:03: [2024-10-30 14:33:03] iter = 10170, loss = 3.2602
2024-10-30 14:33:04: [2024-10-30 14:33:04] iter = 10180, loss = 7.1713
2024-10-30 14:33:04: [2024-10-30 14:33:04] iter = 10190, loss = 11.2849
2024-10-30 14:33:05: [2024-10-30 14:33:05] iter = 10200, loss = 2.6142
2024-10-30 14:33:05: [2024-10-30 14:33:05] iter = 10210, loss = 4.6412
2024-10-30 14:33:06: [2024-10-30 14:33:06] iter = 10220, loss = 3.3580
2024-10-30 14:33:06: [2024-10-30 14:33:06] iter = 10230, loss = 11.4836
2024-10-30 14:33:06: [2024-10-30 14:33:06] iter = 10240, loss = 4.2074
2024-10-30 14:33:07: [2024-10-30 14:33:07] iter = 10250, loss = 1.6506
2024-10-30 14:33:07: [2024-10-30 14:33:07] iter = 10260, loss = 1.3446
2024-10-30 14:33:08: [2024-10-30 14:33:08] iter = 10270, loss = 1.5347
2024-10-30 14:33:08: [2024-10-30 14:33:08] iter = 10280, loss = 1.3800
2024-10-30 14:33:08: [2024-10-30 14:33:08] iter = 10290, loss = 4.2009
2024-10-30 14:33:09: [2024-10-30 14:33:09] iter = 10300, loss = 5.3335
2024-10-30 14:33:09: [2024-10-30 14:33:09] iter = 10310, loss = 2.0285
2024-10-30 14:33:10: [2024-10-30 14:33:10] iter = 10320, loss = 1.0563
2024-10-30 14:33:10: [2024-10-30 14:33:10] iter = 10330, loss = 2.0581
2024-10-30 14:33:10: [2024-10-30 14:33:10] iter = 10340, loss = 2.9263
2024-10-30 14:33:11: [2024-10-30 14:33:11] iter = 10350, loss = 2.2156
2024-10-30 14:33:11: [2024-10-30 14:33:11] iter = 10360, loss = 8.3138
2024-10-30 14:33:12: [2024-10-30 14:33:12] iter = 10370, loss = 5.8517
2024-10-30 14:33:12: [2024-10-30 14:33:12] iter = 10380, loss = 1.5425
2024-10-30 14:33:13: [2024-10-30 14:33:13] iter = 10390, loss = 2.4172
2024-10-30 14:33:13: [2024-10-30 14:33:13] iter = 10400, loss = 6.8762
2024-10-30 14:33:13: [2024-10-30 14:33:13] iter = 10410, loss = 4.8326
2024-10-30 14:33:14: [2024-10-30 14:33:14] iter = 10420, loss = 1.5137
2024-10-30 14:33:14: [2024-10-30 14:33:14] iter = 10430, loss = 1.3658
2024-10-30 14:33:15: [2024-10-30 14:33:15] iter = 10440, loss = 2.3435
2024-10-30 14:33:15: [2024-10-30 14:33:15] iter = 10450, loss = 2.7842
2024-10-30 14:33:15: [2024-10-30 14:33:15] iter = 10460, loss = 2.3521
2024-10-30 14:33:16: [2024-10-30 14:33:16] iter = 10470, loss = 5.1860
2024-10-30 14:33:16: [2024-10-30 14:33:16] iter = 10480, loss = 2.0299
2024-10-30 14:33:17: [2024-10-30 14:33:17] iter = 10490, loss = 1.9553
2024-10-30 14:33:17: [2024-10-30 14:33:17] iter = 10500, loss = 2.2644
2024-10-30 14:33:18: [2024-10-30 14:33:18] iter = 10510, loss = 1.6145
2024-10-30 14:33:18: [2024-10-30 14:33:18] iter = 10520, loss = 3.4380
2024-10-30 14:33:19: [2024-10-30 14:33:19] iter = 10530, loss = 1.5285
2024-10-30 14:33:19: [2024-10-30 14:33:19] iter = 10540, loss = 2.2568
2024-10-30 14:33:20: [2024-10-30 14:33:20] iter = 10550, loss = 1.7283
2024-10-30 14:33:20: [2024-10-30 14:33:20] iter = 10560, loss = 1.0491
2024-10-30 14:33:20: [2024-10-30 14:33:20] iter = 10570, loss = 1.6039
2024-10-30 14:33:21: [2024-10-30 14:33:21] iter = 10580, loss = 15.6672
2024-10-30 14:33:21: [2024-10-30 14:33:21] iter = 10590, loss = 2.8879
2024-10-30 14:33:22: [2024-10-30 14:33:22] iter = 10600, loss = 5.4950
2024-10-30 14:33:22: [2024-10-30 14:33:22] iter = 10610, loss = 8.0293
2024-10-30 14:33:23: [2024-10-30 14:33:23] iter = 10620, loss = 2.0947
2024-10-30 14:33:23: [2024-10-30 14:33:23] iter = 10630, loss = 5.5951
2024-10-30 14:33:24: [2024-10-30 14:33:24] iter = 10640, loss = 26.3683
2024-10-30 14:33:24: [2024-10-30 14:33:24] iter = 10650, loss = 11.6251
2024-10-30 14:33:25: [2024-10-30 14:33:25] iter = 10660, loss = 1.8415
2024-10-30 14:33:25: [2024-10-30 14:33:25] iter = 10670, loss = 3.6595
2024-10-30 14:33:26: [2024-10-30 14:33:26] iter = 10680, loss = 5.6128
2024-10-30 14:33:26: [2024-10-30 14:33:26] iter = 10690, loss = 1.9547
2024-10-30 14:33:27: [2024-10-30 14:33:27] iter = 10700, loss = 2.2610
2024-10-30 14:33:27: [2024-10-30 14:33:27] iter = 10710, loss = 1.4746
2024-10-30 14:33:28: [2024-10-30 14:33:28] iter = 10720, loss = 1.5231
2024-10-30 14:33:28: [2024-10-30 14:33:28] iter = 10730, loss = 17.8787
2024-10-30 14:33:29: [2024-10-30 14:33:29] iter = 10740, loss = 2.0797
2024-10-30 14:33:29: [2024-10-30 14:33:29] iter = 10750, loss = 9.9485
2024-10-30 14:33:30: [2024-10-30 14:33:30] iter = 10760, loss = 1.6547
2024-10-30 14:33:30: [2024-10-30 14:33:30] iter = 10770, loss = 16.0489
2024-10-30 14:33:31: [2024-10-30 14:33:31] iter = 10780, loss = 2.4240
2024-10-30 14:33:31: [2024-10-30 14:33:31] iter = 10790, loss = 1.5082
2024-10-30 14:33:32: [2024-10-30 14:33:32] iter = 10800, loss = 2.5541
2024-10-30 14:33:32: [2024-10-30 14:33:32] iter = 10810, loss = 4.6923
2024-10-30 14:33:32: [2024-10-30 14:33:32] iter = 10820, loss = 3.6703
2024-10-30 14:33:33: [2024-10-30 14:33:33] iter = 10830, loss = 2.3104
2024-10-30 14:33:33: [2024-10-30 14:33:33] iter = 10840, loss = 1.4067
2024-10-30 14:33:33: [2024-10-30 14:33:33] iter = 10850, loss = 2.4593
2024-10-30 14:33:34: [2024-10-30 14:33:34] iter = 10860, loss = 34.5852
2024-10-30 14:33:34: [2024-10-30 14:33:34] iter = 10870, loss = 3.6456
2024-10-30 14:33:35: [2024-10-30 14:33:35] iter = 10880, loss = 1.3074
2024-10-30 14:33:35: [2024-10-30 14:33:35] iter = 10890, loss = 1.4395
2024-10-30 14:33:35: [2024-10-30 14:33:35] iter = 10900, loss = 5.9515
2024-10-30 14:33:36: [2024-10-30 14:33:36] iter = 10910, loss = 1.6375
2024-10-30 14:33:36: [2024-10-30 14:33:36] iter = 10920, loss = 2.6501
2024-10-30 14:33:37: [2024-10-30 14:33:37] iter = 10930, loss = 1.6485
2024-10-30 14:33:38: [2024-10-30 14:33:38] iter = 10940, loss = 1.6381
2024-10-30 14:33:38: [2024-10-30 14:33:38] iter = 10950, loss = 17.1094
2024-10-30 14:33:39: [2024-10-30 14:33:39] iter = 10960, loss = 12.0570
2024-10-30 14:33:39: [2024-10-30 14:33:39] iter = 10970, loss = 3.9215
2024-10-30 14:33:40: [2024-10-30 14:33:40] iter = 10980, loss = 1.9654
2024-10-30 14:33:40: [2024-10-30 14:33:40] iter = 10990, loss = 1.5772
2024-10-30 14:33:41: [2024-10-30 14:33:41] iter = 11000, loss = 1.2986
2024-10-30 14:33:41: [2024-10-30 14:33:41] iter = 11010, loss = 1.7972
2024-10-30 14:33:42: [2024-10-30 14:33:42] iter = 11020, loss = 1.3579
2024-10-30 14:33:42: [2024-10-30 14:33:42] iter = 11030, loss = 28.5113
2024-10-30 14:33:43: [2024-10-30 14:33:43] iter = 11040, loss = 2.1177
2024-10-30 14:33:44: [2024-10-30 14:33:44] iter = 11050, loss = 2.1908
2024-10-30 14:33:44: [2024-10-30 14:33:44] iter = 11060, loss = 1.4321
2024-10-30 14:33:45: [2024-10-30 14:33:45] iter = 11070, loss = 1.7659
2024-10-30 14:33:45: [2024-10-30 14:33:45] iter = 11080, loss = 2.1139
2024-10-30 14:33:46: [2024-10-30 14:33:46] iter = 11090, loss = 3.9458
2024-10-30 14:33:46: [2024-10-30 14:33:46] iter = 11100, loss = 2.9627
2024-10-30 14:33:47: [2024-10-30 14:33:47] iter = 11110, loss = 3.3376
2024-10-30 14:33:47: [2024-10-30 14:33:47] iter = 11120, loss = 15.7713
2024-10-30 14:33:48: [2024-10-30 14:33:48] iter = 11130, loss = 1.1591
2024-10-30 14:33:48: [2024-10-30 14:33:48] iter = 11140, loss = 4.3605
2024-10-30 14:33:49: [2024-10-30 14:33:49] iter = 11150, loss = 2.6106
2024-10-30 14:33:49: [2024-10-30 14:33:49] iter = 11160, loss = 3.9146
2024-10-30 14:33:50: [2024-10-30 14:33:50] iter = 11170, loss = 16.2138
2024-10-30 14:33:50: [2024-10-30 14:33:50] iter = 11180, loss = 2.7906
2024-10-30 14:33:51: [2024-10-30 14:33:51] iter = 11190, loss = 2.7670
2024-10-30 14:33:51: [2024-10-30 14:33:51] iter = 11200, loss = 4.3740
2024-10-30 14:33:52: [2024-10-30 14:33:52] iter = 11210, loss = 1.6709
2024-10-30 14:33:52: [2024-10-30 14:33:52] iter = 11220, loss = 1.6496
2024-10-30 14:33:52: [2024-10-30 14:33:52] iter = 11230, loss = 6.8991
2024-10-30 14:33:53: [2024-10-30 14:33:53] iter = 11240, loss = 3.7744
2024-10-30 14:33:53: [2024-10-30 14:33:53] iter = 11250, loss = 1.9822
2024-10-30 14:33:54: [2024-10-30 14:33:54] iter = 11260, loss = 1.1383
2024-10-30 14:33:54: [2024-10-30 14:33:54] iter = 11270, loss = 1.4578
2024-10-30 14:33:55: [2024-10-30 14:33:55] iter = 11280, loss = 1.9349
2024-10-30 14:33:55: [2024-10-30 14:33:55] iter = 11290, loss = 1.7637
2024-10-30 14:33:56: [2024-10-30 14:33:55] iter = 11300, loss = 15.3369
2024-10-30 14:33:56: [2024-10-30 14:33:56] iter = 11310, loss = 3.1395
2024-10-30 14:33:57: [2024-10-30 14:33:57] iter = 11320, loss = 2.6784
2024-10-30 14:33:57: [2024-10-30 14:33:57] iter = 11330, loss = 2.6381
2024-10-30 14:33:58: [2024-10-30 14:33:58] iter = 11340, loss = 1.0801
2024-10-30 14:33:59: [2024-10-30 14:33:59] iter = 11350, loss = 4.6241
2024-10-30 14:33:59: [2024-10-30 14:33:59] iter = 11360, loss = 1.8901
2024-10-30 14:34:00: [2024-10-30 14:34:00] iter = 11370, loss = 1.8881
2024-10-30 14:34:00: [2024-10-30 14:34:00] iter = 11380, loss = 2.5643
2024-10-30 14:34:00: [2024-10-30 14:34:00] iter = 11390, loss = 1.8893
2024-10-30 14:34:01: [2024-10-30 14:34:01] iter = 11400, loss = 6.5245
2024-10-30 14:34:01: [2024-10-30 14:34:01] iter = 11410, loss = 46.1989
2024-10-30 14:34:02: [2024-10-30 14:34:02] iter = 11420, loss = 2.5413
2024-10-30 14:34:02: [2024-10-30 14:34:02] iter = 11430, loss = 7.4494
2024-10-30 14:34:03: [2024-10-30 14:34:03] iter = 11440, loss = 1.5146
2024-10-30 14:34:04: [2024-10-30 14:34:04] iter = 11450, loss = 1.5408
2024-10-30 14:34:04: [2024-10-30 14:34:04] iter = 11460, loss = 2.2946
2024-10-30 14:34:05: [2024-10-30 14:34:05] iter = 11470, loss = 1.0016
2024-10-30 14:34:05: [2024-10-30 14:34:05] iter = 11480, loss = 4.4092
2024-10-30 14:34:06: [2024-10-30 14:34:06] iter = 11490, loss = 28.2725
2024-10-30 14:34:06: [2024-10-30 14:34:06] iter = 11500, loss = 1.4423
2024-10-30 14:34:07: [2024-10-30 14:34:07] iter = 11510, loss = 1.5160
2024-10-30 14:34:07: [2024-10-30 14:34:07] iter = 11520, loss = 1.3389
2024-10-30 14:34:08: [2024-10-30 14:34:08] iter = 11530, loss = 1.9079
2024-10-30 14:34:09: [2024-10-30 14:34:09] iter = 11540, loss = 1.9809
2024-10-30 14:34:09: [2024-10-30 14:34:09] iter = 11550, loss = 1.3184
2024-10-30 14:34:10: [2024-10-30 14:34:10] iter = 11560, loss = 12.8052
2024-10-30 14:34:10: [2024-10-30 14:34:10] iter = 11570, loss = 3.1889
2024-10-30 14:34:11: [2024-10-30 14:34:11] iter = 11580, loss = 11.4673
2024-10-30 14:34:11: [2024-10-30 14:34:11] iter = 11590, loss = 6.5586
2024-10-30 14:34:12: [2024-10-30 14:34:12] iter = 11600, loss = 1.5249
2024-10-30 14:34:12: [2024-10-30 14:34:12] iter = 11610, loss = 2.9748
2024-10-30 14:34:13: [2024-10-30 14:34:13] iter = 11620, loss = 26.7889
2024-10-30 14:34:13: [2024-10-30 14:34:13] iter = 11630, loss = 1.4886
2024-10-30 14:34:14: [2024-10-30 14:34:14] iter = 11640, loss = 2.6770
2024-10-30 14:34:15: [2024-10-30 14:34:15] iter = 11650, loss = 1.7336
2024-10-30 14:34:15: [2024-10-30 14:34:15] iter = 11660, loss = 3.8789
2024-10-30 14:34:16: [2024-10-30 14:34:16] iter = 11670, loss = 2.2947
2024-10-30 14:34:16: [2024-10-30 14:34:16] iter = 11680, loss = 6.2942
2024-10-30 14:34:17: [2024-10-30 14:34:17] iter = 11690, loss = 1.3619
2024-10-30 14:34:17: [2024-10-30 14:34:17] iter = 11700, loss = 1.1244
2024-10-30 14:34:18: [2024-10-30 14:34:18] iter = 11710, loss = 13.1738
2024-10-30 14:34:18: [2024-10-30 14:34:18] iter = 11720, loss = 1.6470
2024-10-30 14:34:19: [2024-10-30 14:34:19] iter = 11730, loss = 19.1588
2024-10-30 14:34:19: [2024-10-30 14:34:19] iter = 11740, loss = 2.3205
2024-10-30 14:34:19: [2024-10-30 14:34:19] iter = 11750, loss = 2.3706
2024-10-30 14:34:20: [2024-10-30 14:34:20] iter = 11760, loss = 13.9651
2024-10-30 14:34:20: [2024-10-30 14:34:20] iter = 11770, loss = 2.2220
2024-10-30 14:34:21: [2024-10-30 14:34:21] iter = 11780, loss = 5.7157
2024-10-30 14:34:21: [2024-10-30 14:34:21] iter = 11790, loss = 4.9059
2024-10-30 14:34:22: [2024-10-30 14:34:22] iter = 11800, loss = 1.7225
2024-10-30 14:34:23: [2024-10-30 14:34:23] iter = 11810, loss = 4.0707
2024-10-30 14:34:23: [2024-10-30 14:34:23] iter = 11820, loss = 2.4990
2024-10-30 14:34:24: [2024-10-30 14:34:24] iter = 11830, loss = 1.2569
2024-10-30 14:34:24: [2024-10-30 14:34:24] iter = 11840, loss = 17.8663
2024-10-30 14:34:25: [2024-10-30 14:34:25] iter = 11850, loss = 12.1926
2024-10-30 14:34:25: [2024-10-30 14:34:25] iter = 11860, loss = 1.6648
2024-10-30 14:34:26: [2024-10-30 14:34:26] iter = 11870, loss = 2.0336
2024-10-30 14:34:27: [2024-10-30 14:34:27] iter = 11880, loss = 3.0808
2024-10-30 14:34:27: [2024-10-30 14:34:27] iter = 11890, loss = 2.2461
2024-10-30 14:34:28: [2024-10-30 14:34:28] iter = 11900, loss = 1.5104
2024-10-30 14:34:28: [2024-10-30 14:34:28] iter = 11910, loss = 6.5846
2024-10-30 14:34:29: [2024-10-30 14:34:29] iter = 11920, loss = 9.0335
2024-10-30 14:34:29: [2024-10-30 14:34:29] iter = 11930, loss = 5.7532
2024-10-30 14:34:30: [2024-10-30 14:34:30] iter = 11940, loss = 1.8266
2024-10-30 14:34:30: [2024-10-30 14:34:30] iter = 11950, loss = 2.2957
2024-10-30 14:34:31: [2024-10-30 14:34:31] iter = 11960, loss = 2.1561
2024-10-30 14:34:31: [2024-10-30 14:34:31] iter = 11970, loss = 2.6904
2024-10-30 14:34:32: [2024-10-30 14:34:32] iter = 11980, loss = 2.1385
2024-10-30 14:34:32: [2024-10-30 14:34:32] iter = 11990, loss = 2.5322
2024-10-30 14:34:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 14:34:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:34:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 72840}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:35:18: Evaluate 5 random ConvNet, ACCmean = 0.6872 ACCstd = 0.0304
-------------------------
2024-10-30 14:35:18: Evaluate 5 random ConvNet, SENmean = 0.7318 SENstd = 0.0168
-------------------------
2024-10-30 14:35:18: Evaluate 5 random ConvNet, SPEmean = 0.7318 SPEstd = 0.0168
-------------------------
2024-10-30 14:35:18: Evaluate 5 random ConvNet, F!mean = 0.6678 F!std = 0.0260
-------------------------
2024-10-30 14:35:18: Evaluate 5 random ConvNet, mean = 0.6872 std = 0.0304
-------------------------
2024-10-30 14:35:18: [2024-10-30 14:35:18] iter = 12000, loss = 7.0659
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:35:18: [2024-10-30 14:35:18] iter = 12010, loss = 1.7218
2024-10-30 14:35:19: [2024-10-30 14:35:19] iter = 12020, loss = 1.1242
2024-10-30 14:35:19: [2024-10-30 14:35:19] iter = 12030, loss = 1.8039
2024-10-30 14:35:20: [2024-10-30 14:35:20] iter = 12040, loss = 1.8678
2024-10-30 14:35:20: [2024-10-30 14:35:20] iter = 12050, loss = 2.6236
2024-10-30 14:35:20: [2024-10-30 14:35:20] iter = 12060, loss = 1.5454
2024-10-30 14:35:21: [2024-10-30 14:35:21] iter = 12070, loss = 10.9204
2024-10-30 14:35:21: [2024-10-30 14:35:21] iter = 12080, loss = 2.0265
2024-10-30 14:35:21: [2024-10-30 14:35:21] iter = 12090, loss = 2.4347
2024-10-30 14:35:22: [2024-10-30 14:35:22] iter = 12100, loss = 3.4669
2024-10-30 14:35:22: [2024-10-30 14:35:22] iter = 12110, loss = 2.3990
2024-10-30 14:35:22: [2024-10-30 14:35:22] iter = 12120, loss = 1.6172
2024-10-30 14:35:23: [2024-10-30 14:35:23] iter = 12130, loss = 1.0365
2024-10-30 14:35:23: [2024-10-30 14:35:23] iter = 12140, loss = 6.2491
2024-10-30 14:35:24: [2024-10-30 14:35:24] iter = 12150, loss = 21.1411
2024-10-30 14:35:24: [2024-10-30 14:35:24] iter = 12160, loss = 1.8045
2024-10-30 14:35:25: [2024-10-30 14:35:25] iter = 12170, loss = 1.6745
2024-10-30 14:35:25: [2024-10-30 14:35:25] iter = 12180, loss = 10.1611
2024-10-30 14:35:25: [2024-10-30 14:35:25] iter = 12190, loss = 3.4247
2024-10-30 14:35:26: [2024-10-30 14:35:26] iter = 12200, loss = 1.2023
2024-10-30 14:35:26: [2024-10-30 14:35:26] iter = 12210, loss = 3.1653
2024-10-30 14:35:26: [2024-10-30 14:35:26] iter = 12220, loss = 1.8054
2024-10-30 14:35:27: [2024-10-30 14:35:27] iter = 12230, loss = 1.2771
2024-10-30 14:35:27: [2024-10-30 14:35:27] iter = 12240, loss = 21.6368
2024-10-30 14:35:27: [2024-10-30 14:35:27] iter = 12250, loss = 1.7403
2024-10-30 14:35:28: [2024-10-30 14:35:28] iter = 12260, loss = 16.3152
2024-10-30 14:35:28: [2024-10-30 14:35:28] iter = 12270, loss = 13.7503
2024-10-30 14:35:29: [2024-10-30 14:35:29] iter = 12280, loss = 2.5453
2024-10-30 14:35:29: [2024-10-30 14:35:29] iter = 12290, loss = 1.3514
2024-10-30 14:35:29: [2024-10-30 14:35:29] iter = 12300, loss = 2.1019
2024-10-30 14:35:30: [2024-10-30 14:35:30] iter = 12310, loss = 6.5875
2024-10-30 14:35:30: [2024-10-30 14:35:30] iter = 12320, loss = 8.8626
2024-10-30 14:35:30: [2024-10-30 14:35:30] iter = 12330, loss = 1.9276
2024-10-30 14:35:31: [2024-10-30 14:35:31] iter = 12340, loss = 1.8658
2024-10-30 14:35:31: [2024-10-30 14:35:31] iter = 12350, loss = 5.6325
2024-10-30 14:35:31: [2024-10-30 14:35:31] iter = 12360, loss = 21.5853
2024-10-30 14:35:32: [2024-10-30 14:35:32] iter = 12370, loss = 1.5918
2024-10-30 14:35:32: [2024-10-30 14:35:32] iter = 12380, loss = 9.5948
2024-10-30 14:35:32: [2024-10-30 14:35:32] iter = 12390, loss = 1.5012
2024-10-30 14:35:33: [2024-10-30 14:35:33] iter = 12400, loss = 8.0299
2024-10-30 14:35:33: [2024-10-30 14:35:33] iter = 12410, loss = 2.2603
2024-10-30 14:35:34: [2024-10-30 14:35:34] iter = 12420, loss = 2.1949
2024-10-30 14:35:35: [2024-10-30 14:35:35] iter = 12430, loss = 2.7850
2024-10-30 14:35:35: [2024-10-30 14:35:35] iter = 12440, loss = 6.6524
2024-10-30 14:35:35: [2024-10-30 14:35:35] iter = 12450, loss = 4.6096
2024-10-30 14:35:36: [2024-10-30 14:35:36] iter = 12460, loss = 3.0964
2024-10-30 14:35:36: [2024-10-30 14:35:36] iter = 12470, loss = 1.6018
2024-10-30 14:35:37: [2024-10-30 14:35:37] iter = 12480, loss = 7.2090
2024-10-30 14:35:37: [2024-10-30 14:35:37] iter = 12490, loss = 3.6371
2024-10-30 14:35:38: [2024-10-30 14:35:38] iter = 12500, loss = 4.8013
2024-10-30 14:35:38: [2024-10-30 14:35:38] iter = 12510, loss = 5.9776
2024-10-30 14:35:39: [2024-10-30 14:35:39] iter = 12520, loss = 1.7263
2024-10-30 14:35:39: [2024-10-30 14:35:39] iter = 12530, loss = 3.3895
2024-10-30 14:35:40: [2024-10-30 14:35:40] iter = 12540, loss = 4.1857
2024-10-30 14:35:40: [2024-10-30 14:35:40] iter = 12550, loss = 2.4835
2024-10-30 14:35:40: [2024-10-30 14:35:40] iter = 12560, loss = 36.7121
2024-10-30 14:35:41: [2024-10-30 14:35:41] iter = 12570, loss = 2.7534
2024-10-30 14:35:41: [2024-10-30 14:35:41] iter = 12580, loss = 42.6715
2024-10-30 14:35:42: [2024-10-30 14:35:42] iter = 12590, loss = 1.8839
2024-10-30 14:35:42: [2024-10-30 14:35:42] iter = 12600, loss = 6.3958
2024-10-30 14:35:43: [2024-10-30 14:35:43] iter = 12610, loss = 4.8066
2024-10-30 14:35:43: [2024-10-30 14:35:43] iter = 12620, loss = 1.4859
2024-10-30 14:35:43: [2024-10-30 14:35:43] iter = 12630, loss = 4.0272
2024-10-30 14:35:44: [2024-10-30 14:35:44] iter = 12640, loss = 4.0585
2024-10-30 14:35:44: [2024-10-30 14:35:44] iter = 12650, loss = 20.7560
2024-10-30 14:35:45: [2024-10-30 14:35:45] iter = 12660, loss = 11.1350
2024-10-30 14:35:45: [2024-10-30 14:35:45] iter = 12670, loss = 1.7498
2024-10-30 14:35:46: [2024-10-30 14:35:46] iter = 12680, loss = 6.9480
2024-10-30 14:35:47: [2024-10-30 14:35:47] iter = 12690, loss = 2.8004
2024-10-30 14:35:47: [2024-10-30 14:35:47] iter = 12700, loss = 1.7222
2024-10-30 14:35:48: [2024-10-30 14:35:48] iter = 12710, loss = 2.1399
2024-10-30 14:35:48: [2024-10-30 14:35:48] iter = 12720, loss = 1.4771
2024-10-30 14:35:49: [2024-10-30 14:35:49] iter = 12730, loss = 1.2326
2024-10-30 14:35:50: [2024-10-30 14:35:50] iter = 12740, loss = 10.1472
2024-10-30 14:35:50: [2024-10-30 14:35:50] iter = 12750, loss = 1.3833
2024-10-30 14:35:51: [2024-10-30 14:35:51] iter = 12760, loss = 4.2433
2024-10-30 14:35:51: [2024-10-30 14:35:51] iter = 12770, loss = 1.4944
2024-10-30 14:35:52: [2024-10-30 14:35:52] iter = 12780, loss = 9.7986
2024-10-30 14:35:52: [2024-10-30 14:35:52] iter = 12790, loss = 3.5142
2024-10-30 14:35:53: [2024-10-30 14:35:53] iter = 12800, loss = 1.6069
2024-10-30 14:35:53: [2024-10-30 14:35:53] iter = 12810, loss = 14.6045
2024-10-30 14:35:54: [2024-10-30 14:35:54] iter = 12820, loss = 2.1138
2024-10-30 14:35:54: [2024-10-30 14:35:54] iter = 12830, loss = 1.9094
2024-10-30 14:35:55: [2024-10-30 14:35:55] iter = 12840, loss = 1.1747
2024-10-30 14:35:56: [2024-10-30 14:35:56] iter = 12850, loss = 12.0186
2024-10-30 14:35:56: [2024-10-30 14:35:56] iter = 12860, loss = 1.5286
2024-10-30 14:35:57: [2024-10-30 14:35:57] iter = 12870, loss = 1.4416
2024-10-30 14:35:57: [2024-10-30 14:35:57] iter = 12880, loss = 22.1408
2024-10-30 14:35:58: [2024-10-30 14:35:58] iter = 12890, loss = 18.8379
2024-10-30 14:35:58: [2024-10-30 14:35:58] iter = 12900, loss = 2.9320
2024-10-30 14:35:59: [2024-10-30 14:35:59] iter = 12910, loss = 11.2356
2024-10-30 14:35:59: [2024-10-30 14:35:59] iter = 12920, loss = 3.5724
2024-10-30 14:36:00: [2024-10-30 14:36:00] iter = 12930, loss = 1.2334
2024-10-30 14:36:00: [2024-10-30 14:36:00] iter = 12940, loss = 1.8174
2024-10-30 14:36:00: [2024-10-30 14:36:00] iter = 12950, loss = 3.3409
2024-10-30 14:36:01: [2024-10-30 14:36:01] iter = 12960, loss = 7.1313
2024-10-30 14:36:01: [2024-10-30 14:36:01] iter = 12970, loss = 8.6406
2024-10-30 14:36:01: [2024-10-30 14:36:01] iter = 12980, loss = 3.4605
2024-10-30 14:36:02: [2024-10-30 14:36:02] iter = 12990, loss = 11.0558
2024-10-30 14:36:02: [2024-10-30 14:36:02] iter = 13000, loss = 2.2623
2024-10-30 14:36:03: [2024-10-30 14:36:03] iter = 13010, loss = 1.6901
2024-10-30 14:36:03: [2024-10-30 14:36:03] iter = 13020, loss = 1.5556
2024-10-30 14:36:04: [2024-10-30 14:36:04] iter = 13030, loss = 1.2581
2024-10-30 14:36:04: [2024-10-30 14:36:04] iter = 13040, loss = 1.1369
2024-10-30 14:36:04: [2024-10-30 14:36:04] iter = 13050, loss = 5.7639
2024-10-30 14:36:05: [2024-10-30 14:36:05] iter = 13060, loss = 2.6330
2024-10-30 14:36:06: [2024-10-30 14:36:06] iter = 13070, loss = 3.0348
2024-10-30 14:36:06: [2024-10-30 14:36:06] iter = 13080, loss = 5.1066
2024-10-30 14:36:07: [2024-10-30 14:36:07] iter = 13090, loss = 5.9253
2024-10-30 14:36:07: [2024-10-30 14:36:07] iter = 13100, loss = 1.4568
2024-10-30 14:36:07: [2024-10-30 14:36:07] iter = 13110, loss = 1.8061
2024-10-30 14:36:08: [2024-10-30 14:36:08] iter = 13120, loss = 1.6186
2024-10-30 14:36:08: [2024-10-30 14:36:08] iter = 13130, loss = 1.3379
2024-10-30 14:36:09: [2024-10-30 14:36:09] iter = 13140, loss = 1.6874
2024-10-30 14:36:09: [2024-10-30 14:36:09] iter = 13150, loss = 16.8395
2024-10-30 14:36:10: [2024-10-30 14:36:10] iter = 13160, loss = 1.8615
2024-10-30 14:36:10: [2024-10-30 14:36:10] iter = 13170, loss = 3.2898
2024-10-30 14:36:11: [2024-10-30 14:36:11] iter = 13180, loss = 6.2441
2024-10-30 14:36:11: [2024-10-30 14:36:11] iter = 13190, loss = 1.4868
2024-10-30 14:36:12: [2024-10-30 14:36:12] iter = 13200, loss = 14.4920
2024-10-30 14:36:12: [2024-10-30 14:36:12] iter = 13210, loss = 9.1208
2024-10-30 14:36:13: [2024-10-30 14:36:13] iter = 13220, loss = 2.4375
2024-10-30 14:36:13: [2024-10-30 14:36:13] iter = 13230, loss = 3.0739
2024-10-30 14:36:14: [2024-10-30 14:36:14] iter = 13240, loss = 1.5159
2024-10-30 14:36:14: [2024-10-30 14:36:14] iter = 13250, loss = 5.3892
2024-10-30 14:36:15: [2024-10-30 14:36:15] iter = 13260, loss = 2.9324
2024-10-30 14:36:15: [2024-10-30 14:36:15] iter = 13270, loss = 28.4518
2024-10-30 14:36:16: [2024-10-30 14:36:16] iter = 13280, loss = 4.0828
2024-10-30 14:36:16: [2024-10-30 14:36:16] iter = 13290, loss = 3.4283
2024-10-30 14:36:16: [2024-10-30 14:36:16] iter = 13300, loss = 1.7800
2024-10-30 14:36:17: [2024-10-30 14:36:17] iter = 13310, loss = 3.1555
2024-10-30 14:36:17: [2024-10-30 14:36:17] iter = 13320, loss = 6.5519
2024-10-30 14:36:18: [2024-10-30 14:36:18] iter = 13330, loss = 2.0230
2024-10-30 14:36:18: [2024-10-30 14:36:18] iter = 13340, loss = 2.2603
2024-10-30 14:36:19: [2024-10-30 14:36:19] iter = 13350, loss = 6.2484
2024-10-30 14:36:19: [2024-10-30 14:36:19] iter = 13360, loss = 4.1711
2024-10-30 14:36:20: [2024-10-30 14:36:20] iter = 13370, loss = 1.5045
2024-10-30 14:36:20: [2024-10-30 14:36:20] iter = 13380, loss = 2.6631
2024-10-30 14:36:21: [2024-10-30 14:36:21] iter = 13390, loss = 3.6008
2024-10-30 14:36:21: [2024-10-30 14:36:21] iter = 13400, loss = 1.2900
2024-10-30 14:36:22: [2024-10-30 14:36:22] iter = 13410, loss = 31.1698
2024-10-30 14:36:22: [2024-10-30 14:36:22] iter = 13420, loss = 1.7646
2024-10-30 14:36:22: [2024-10-30 14:36:22] iter = 13430, loss = 1.7397
2024-10-30 14:36:23: [2024-10-30 14:36:23] iter = 13440, loss = 2.0004
2024-10-30 14:36:23: [2024-10-30 14:36:23] iter = 13450, loss = 1.3582
2024-10-30 14:36:24: [2024-10-30 14:36:24] iter = 13460, loss = 8.2493
2024-10-30 14:36:24: [2024-10-30 14:36:24] iter = 13470, loss = 3.0178
2024-10-30 14:36:25: [2024-10-30 14:36:25] iter = 13480, loss = 2.9368
2024-10-30 14:36:25: [2024-10-30 14:36:25] iter = 13490, loss = 1.6615
2024-10-30 14:36:25: [2024-10-30 14:36:25] iter = 13500, loss = 2.8870
2024-10-30 14:36:26: [2024-10-30 14:36:26] iter = 13510, loss = 1.9811
2024-10-30 14:36:26: [2024-10-30 14:36:26] iter = 13520, loss = 2.7216
2024-10-30 14:36:27: [2024-10-30 14:36:27] iter = 13530, loss = 2.2066
2024-10-30 14:36:27: [2024-10-30 14:36:27] iter = 13540, loss = 2.2788
2024-10-30 14:36:28: [2024-10-30 14:36:28] iter = 13550, loss = 3.4198
2024-10-30 14:36:28: [2024-10-30 14:36:28] iter = 13560, loss = 8.1233
2024-10-30 14:36:28: [2024-10-30 14:36:28] iter = 13570, loss = 7.5743
2024-10-30 14:36:29: [2024-10-30 14:36:29] iter = 13580, loss = 1.9041
2024-10-30 14:36:29: [2024-10-30 14:36:29] iter = 13590, loss = 2.5405
2024-10-30 14:36:29: [2024-10-30 14:36:29] iter = 13600, loss = 8.4012
2024-10-30 14:36:30: [2024-10-30 14:36:30] iter = 13610, loss = 2.0967
2024-10-30 14:36:30: [2024-10-30 14:36:30] iter = 13620, loss = 3.9362
2024-10-30 14:36:30: [2024-10-30 14:36:30] iter = 13630, loss = 1.0469
2024-10-30 14:36:31: [2024-10-30 14:36:31] iter = 13640, loss = 1.4648
2024-10-30 14:36:31: [2024-10-30 14:36:31] iter = 13650, loss = 1.2662
2024-10-30 14:36:32: [2024-10-30 14:36:32] iter = 13660, loss = 1.7766
2024-10-30 14:36:32: [2024-10-30 14:36:32] iter = 13670, loss = 2.2737
2024-10-30 14:36:33: [2024-10-30 14:36:33] iter = 13680, loss = 8.1285
2024-10-30 14:36:33: [2024-10-30 14:36:33] iter = 13690, loss = 4.6210
2024-10-30 14:36:34: [2024-10-30 14:36:34] iter = 13700, loss = 4.5847
2024-10-30 14:36:34: [2024-10-30 14:36:34] iter = 13710, loss = 1.3529
2024-10-30 14:36:34: [2024-10-30 14:36:34] iter = 13720, loss = 1.6398
2024-10-30 14:36:35: [2024-10-30 14:36:35] iter = 13730, loss = 3.9260
2024-10-30 14:36:35: [2024-10-30 14:36:35] iter = 13740, loss = 0.9772
2024-10-30 14:36:36: [2024-10-30 14:36:36] iter = 13750, loss = 1.7106
2024-10-30 14:36:36: [2024-10-30 14:36:36] iter = 13760, loss = 1.4382
2024-10-30 14:36:37: [2024-10-30 14:36:37] iter = 13770, loss = 4.9629
2024-10-30 14:36:37: [2024-10-30 14:36:37] iter = 13780, loss = 2.3292
2024-10-30 14:36:37: [2024-10-30 14:36:37] iter = 13790, loss = 1.0473
2024-10-30 14:36:38: [2024-10-30 14:36:38] iter = 13800, loss = 3.6455
2024-10-30 14:36:38: [2024-10-30 14:36:38] iter = 13810, loss = 2.3279
2024-10-30 14:36:39: [2024-10-30 14:36:39] iter = 13820, loss = 2.5537
2024-10-30 14:36:39: [2024-10-30 14:36:39] iter = 13830, loss = 1.5841
2024-10-30 14:36:40: [2024-10-30 14:36:40] iter = 13840, loss = 1.4652
2024-10-30 14:36:41: [2024-10-30 14:36:41] iter = 13850, loss = 3.9366
2024-10-30 14:36:41: [2024-10-30 14:36:41] iter = 13860, loss = 3.9241
2024-10-30 14:36:41: [2024-10-30 14:36:41] iter = 13870, loss = 2.6603
2024-10-30 14:36:42: [2024-10-30 14:36:42] iter = 13880, loss = 2.5656
2024-10-30 14:36:42: [2024-10-30 14:36:42] iter = 13890, loss = 6.7051
2024-10-30 14:36:42: [2024-10-30 14:36:42] iter = 13900, loss = 1.3381
2024-10-30 14:36:43: [2024-10-30 14:36:43] iter = 13910, loss = 1.6354
2024-10-30 14:36:43: [2024-10-30 14:36:43] iter = 13920, loss = 10.0761
2024-10-30 14:36:44: [2024-10-30 14:36:44] iter = 13930, loss = 2.3889
2024-10-30 14:36:44: [2024-10-30 14:36:44] iter = 13940, loss = 5.1860
2024-10-30 14:36:44: [2024-10-30 14:36:44] iter = 13950, loss = 1.9148
2024-10-30 14:36:45: [2024-10-30 14:36:45] iter = 13960, loss = 1.6632
2024-10-30 14:36:45: [2024-10-30 14:36:45] iter = 13970, loss = 7.7080
2024-10-30 14:36:46: [2024-10-30 14:36:46] iter = 13980, loss = 8.3559
2024-10-30 14:36:46: [2024-10-30 14:36:46] iter = 13990, loss = 17.9163
2024-10-30 14:36:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 14:36:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:36:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 7223}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:37:31: Evaluate 5 random ConvNet, ACCmean = 0.7846 ACCstd = 0.0209
-------------------------
2024-10-30 14:37:31: Evaluate 5 random ConvNet, SENmean = 0.7308 SENstd = 0.0229
-------------------------
2024-10-30 14:37:31: Evaluate 5 random ConvNet, SPEmean = 0.7308 SPEstd = 0.0229
-------------------------
2024-10-30 14:37:31: Evaluate 5 random ConvNet, F!mean = 0.7289 F!std = 0.0244
-------------------------
2024-10-30 14:37:31: Evaluate 5 random ConvNet, mean = 0.7846 std = 0.0209
-------------------------
2024-10-30 14:37:31: [2024-10-30 14:37:31] iter = 14000, loss = 4.3211
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:37:32: [2024-10-30 14:37:32] iter = 14010, loss = 1.6685
2024-10-30 14:37:33: [2024-10-30 14:37:33] iter = 14020, loss = 2.5194
2024-10-30 14:37:33: [2024-10-30 14:37:33] iter = 14030, loss = 2.7479
2024-10-30 14:37:33: [2024-10-30 14:37:33] iter = 14040, loss = 5.7323
2024-10-30 14:37:34: [2024-10-30 14:37:34] iter = 14050, loss = 8.6780
2024-10-30 14:37:35: [2024-10-30 14:37:35] iter = 14060, loss = 1.2316
2024-10-30 14:37:35: [2024-10-30 14:37:35] iter = 14070, loss = 1.7428
2024-10-30 14:37:36: [2024-10-30 14:37:36] iter = 14080, loss = 2.7827
2024-10-30 14:37:36: [2024-10-30 14:37:36] iter = 14090, loss = 3.5484
2024-10-30 14:37:36: [2024-10-30 14:37:36] iter = 14100, loss = 3.8166
2024-10-30 14:37:37: [2024-10-30 14:37:37] iter = 14110, loss = 11.6694
2024-10-30 14:37:37: [2024-10-30 14:37:37] iter = 14120, loss = 1.1121
2024-10-30 14:37:38: [2024-10-30 14:37:38] iter = 14130, loss = 18.8018
2024-10-30 14:37:38: [2024-10-30 14:37:38] iter = 14140, loss = 5.0421
2024-10-30 14:37:38: [2024-10-30 14:37:38] iter = 14150, loss = 6.9130
2024-10-30 14:37:39: [2024-10-30 14:37:39] iter = 14160, loss = 3.1835
2024-10-30 14:37:39: [2024-10-30 14:37:39] iter = 14170, loss = 1.5772
2024-10-30 14:37:40: [2024-10-30 14:37:40] iter = 14180, loss = 19.4432
2024-10-30 14:37:40: [2024-10-30 14:37:40] iter = 14190, loss = 3.6510
2024-10-30 14:37:40: [2024-10-30 14:37:40] iter = 14200, loss = 9.5298
2024-10-30 14:37:41: [2024-10-30 14:37:41] iter = 14210, loss = 4.3828
2024-10-30 14:37:41: [2024-10-30 14:37:41] iter = 14220, loss = 4.0051
2024-10-30 14:37:41: [2024-10-30 14:37:41] iter = 14230, loss = 1.4830
2024-10-30 14:37:42: [2024-10-30 14:37:42] iter = 14240, loss = 2.6479
2024-10-30 14:37:42: [2024-10-30 14:37:42] iter = 14250, loss = 1.8627
2024-10-30 14:37:43: [2024-10-30 14:37:43] iter = 14260, loss = 1.4759
2024-10-30 14:37:43: [2024-10-30 14:37:43] iter = 14270, loss = 1.5906
2024-10-30 14:37:43: [2024-10-30 14:37:43] iter = 14280, loss = 4.3347
2024-10-30 14:37:44: [2024-10-30 14:37:44] iter = 14290, loss = 1.2970
2024-10-30 14:37:44: [2024-10-30 14:37:44] iter = 14300, loss = 4.0164
2024-10-30 14:37:45: [2024-10-30 14:37:45] iter = 14310, loss = 8.8444
2024-10-30 14:37:45: [2024-10-30 14:37:45] iter = 14320, loss = 4.0664
2024-10-30 14:37:45: [2024-10-30 14:37:45] iter = 14330, loss = 3.8408
2024-10-30 14:37:46: [2024-10-30 14:37:46] iter = 14340, loss = 8.5083
2024-10-30 14:37:46: [2024-10-30 14:37:46] iter = 14350, loss = 6.0745
2024-10-30 14:37:47: [2024-10-30 14:37:47] iter = 14360, loss = 2.0447
2024-10-30 14:37:47: [2024-10-30 14:37:47] iter = 14370, loss = 8.3872
2024-10-30 14:37:48: [2024-10-30 14:37:48] iter = 14380, loss = 22.6549
2024-10-30 14:37:48: [2024-10-30 14:37:48] iter = 14390, loss = 7.3536
2024-10-30 14:37:49: [2024-10-30 14:37:49] iter = 14400, loss = 5.4296
2024-10-30 14:37:49: [2024-10-30 14:37:49] iter = 14410, loss = 4.4155
2024-10-30 14:37:49: [2024-10-30 14:37:49] iter = 14420, loss = 3.0576
2024-10-30 14:37:50: [2024-10-30 14:37:50] iter = 14430, loss = 1.7778
2024-10-30 14:37:51: [2024-10-30 14:37:51] iter = 14440, loss = 15.1354
2024-10-30 14:37:51: [2024-10-30 14:37:51] iter = 14450, loss = 4.2363
2024-10-30 14:37:52: [2024-10-30 14:37:52] iter = 14460, loss = 6.9772
2024-10-30 14:37:52: [2024-10-30 14:37:52] iter = 14470, loss = 1.2618
2024-10-30 14:37:53: [2024-10-30 14:37:53] iter = 14480, loss = 5.8130
2024-10-30 14:37:53: [2024-10-30 14:37:53] iter = 14490, loss = 1.8445
2024-10-30 14:37:53: [2024-10-30 14:37:53] iter = 14500, loss = 5.9475
2024-10-30 14:37:54: [2024-10-30 14:37:54] iter = 14510, loss = 3.0673
2024-10-30 14:37:55: [2024-10-30 14:37:55] iter = 14520, loss = 8.8024
2024-10-30 14:37:55: [2024-10-30 14:37:55] iter = 14530, loss = 1.4497
2024-10-30 14:37:56: [2024-10-30 14:37:56] iter = 14540, loss = 3.1661
2024-10-30 14:37:56: [2024-10-30 14:37:56] iter = 14550, loss = 5.1054
2024-10-30 14:37:57: [2024-10-30 14:37:57] iter = 14560, loss = 14.6506
2024-10-30 14:37:57: [2024-10-30 14:37:57] iter = 14570, loss = 2.2496
2024-10-30 14:37:58: [2024-10-30 14:37:58] iter = 14580, loss = 24.3505
2024-10-30 14:37:58: [2024-10-30 14:37:58] iter = 14590, loss = 2.8078
2024-10-30 14:37:59: [2024-10-30 14:37:59] iter = 14600, loss = 8.2218
2024-10-30 14:37:59: [2024-10-30 14:37:59] iter = 14610, loss = 1.1947
2024-10-30 14:37:59: [2024-10-30 14:37:59] iter = 14620, loss = 1.2838
2024-10-30 14:38:00: [2024-10-30 14:38:00] iter = 14630, loss = 41.7774
2024-10-30 14:38:00: [2024-10-30 14:38:00] iter = 14640, loss = 3.4016
2024-10-30 14:38:01: [2024-10-30 14:38:01] iter = 14650, loss = 3.1790
2024-10-30 14:38:01: [2024-10-30 14:38:01] iter = 14660, loss = 1.2968
2024-10-30 14:38:02: [2024-10-30 14:38:02] iter = 14670, loss = 0.9789
2024-10-30 14:38:03: [2024-10-30 14:38:03] iter = 14680, loss = 1.6204
2024-10-30 14:38:03: [2024-10-30 14:38:03] iter = 14690, loss = 1.3497
2024-10-30 14:38:04: [2024-10-30 14:38:04] iter = 14700, loss = 5.8831
2024-10-30 14:38:04: [2024-10-30 14:38:04] iter = 14710, loss = 2.1278
2024-10-30 14:38:05: [2024-10-30 14:38:05] iter = 14720, loss = 26.9456
2024-10-30 14:38:05: [2024-10-30 14:38:05] iter = 14730, loss = 6.6443
2024-10-30 14:38:06: [2024-10-30 14:38:06] iter = 14740, loss = 1.6066
2024-10-30 14:38:07: [2024-10-30 14:38:07] iter = 14750, loss = 8.4688
2024-10-30 14:38:07: [2024-10-30 14:38:07] iter = 14760, loss = 3.5915
2024-10-30 14:38:08: [2024-10-30 14:38:08] iter = 14770, loss = 1.3480
2024-10-30 14:38:08: [2024-10-30 14:38:08] iter = 14780, loss = 1.2122
2024-10-30 14:38:09: [2024-10-30 14:38:09] iter = 14790, loss = 3.6629
2024-10-30 14:38:09: [2024-10-30 14:38:09] iter = 14800, loss = 2.7462
2024-10-30 14:38:09: [2024-10-30 14:38:09] iter = 14810, loss = 1.4947
2024-10-30 14:38:10: [2024-10-30 14:38:10] iter = 14820, loss = 0.9495
2024-10-30 14:38:10: [2024-10-30 14:38:10] iter = 14830, loss = 1.0307
2024-10-30 14:38:11: [2024-10-30 14:38:11] iter = 14840, loss = 1.9304
2024-10-30 14:38:11: [2024-10-30 14:38:11] iter = 14850, loss = 1.1430
2024-10-30 14:38:11: [2024-10-30 14:38:11] iter = 14860, loss = 10.4483
2024-10-30 14:38:12: [2024-10-30 14:38:12] iter = 14870, loss = 6.2468
2024-10-30 14:38:12: [2024-10-30 14:38:12] iter = 14880, loss = 4.4594
2024-10-30 14:38:13: [2024-10-30 14:38:13] iter = 14890, loss = 3.8270
2024-10-30 14:38:13: [2024-10-30 14:38:13] iter = 14900, loss = 9.0556
2024-10-30 14:38:14: [2024-10-30 14:38:14] iter = 14910, loss = 1.6622
2024-10-30 14:38:15: [2024-10-30 14:38:15] iter = 14920, loss = 2.5881
2024-10-30 14:38:15: [2024-10-30 14:38:15] iter = 14930, loss = 3.7854
2024-10-30 14:38:15: [2024-10-30 14:38:15] iter = 14940, loss = 7.5064
2024-10-30 14:38:16: [2024-10-30 14:38:16] iter = 14950, loss = 2.3360
2024-10-30 14:38:16: [2024-10-30 14:38:16] iter = 14960, loss = 5.0235
2024-10-30 14:38:17: [2024-10-30 14:38:17] iter = 14970, loss = 18.7017
2024-10-30 14:38:17: [2024-10-30 14:38:17] iter = 14980, loss = 22.2065
2024-10-30 14:38:18: [2024-10-30 14:38:18] iter = 14990, loss = 4.9996
2024-10-30 14:38:18: [2024-10-30 14:38:18] iter = 15000, loss = 6.4418
2024-10-30 14:38:19: [2024-10-30 14:38:19] iter = 15010, loss = 3.5650
2024-10-30 14:38:19: [2024-10-30 14:38:19] iter = 15020, loss = 2.3114
2024-10-30 14:38:20: [2024-10-30 14:38:20] iter = 15030, loss = 2.7272
2024-10-30 14:38:20: [2024-10-30 14:38:20] iter = 15040, loss = 1.2217
2024-10-30 14:38:20: [2024-10-30 14:38:20] iter = 15050, loss = 9.1969
2024-10-30 14:38:21: [2024-10-30 14:38:21] iter = 15060, loss = 8.1731
2024-10-30 14:38:21: [2024-10-30 14:38:21] iter = 15070, loss = 2.6875
2024-10-30 14:38:22: [2024-10-30 14:38:22] iter = 15080, loss = 10.5354
2024-10-30 14:38:22: [2024-10-30 14:38:22] iter = 15090, loss = 2.0535
2024-10-30 14:38:22: [2024-10-30 14:38:22] iter = 15100, loss = 12.2743
2024-10-30 14:38:23: [2024-10-30 14:38:23] iter = 15110, loss = 1.5728
2024-10-30 14:38:23: [2024-10-30 14:38:23] iter = 15120, loss = 1.9944
2024-10-30 14:38:24: [2024-10-30 14:38:24] iter = 15130, loss = 2.8690
2024-10-30 14:38:24: [2024-10-30 14:38:24] iter = 15140, loss = 1.9498
2024-10-30 14:38:25: [2024-10-30 14:38:25] iter = 15150, loss = 4.2854
2024-10-30 14:38:25: [2024-10-30 14:38:25] iter = 15160, loss = 24.0048
2024-10-30 14:38:25: [2024-10-30 14:38:25] iter = 15170, loss = 2.3426
2024-10-30 14:38:26: [2024-10-30 14:38:26] iter = 15180, loss = 1.6493
2024-10-30 14:38:27: [2024-10-30 14:38:27] iter = 15190, loss = 11.0456
2024-10-30 14:38:27: [2024-10-30 14:38:27] iter = 15200, loss = 2.9306
2024-10-30 14:38:28: [2024-10-30 14:38:28] iter = 15210, loss = 1.2763
2024-10-30 14:38:28: [2024-10-30 14:38:28] iter = 15220, loss = 2.9229
2024-10-30 14:38:28: [2024-10-30 14:38:28] iter = 15230, loss = 2.1321
2024-10-30 14:38:29: [2024-10-30 14:38:29] iter = 15240, loss = 2.1970
2024-10-30 14:38:29: [2024-10-30 14:38:29] iter = 15250, loss = 1.8474
2024-10-30 14:38:30: [2024-10-30 14:38:30] iter = 15260, loss = 2.9092
2024-10-30 14:38:30: [2024-10-30 14:38:30] iter = 15270, loss = 14.7099
2024-10-30 14:38:31: [2024-10-30 14:38:31] iter = 15280, loss = 2.1903
2024-10-30 14:38:31: [2024-10-30 14:38:31] iter = 15290, loss = 1.4131
2024-10-30 14:38:32: [2024-10-30 14:38:32] iter = 15300, loss = 1.3309
2024-10-30 14:38:32: [2024-10-30 14:38:32] iter = 15310, loss = 14.5475
2024-10-30 14:38:32: [2024-10-30 14:38:32] iter = 15320, loss = 1.5975
2024-10-30 14:38:33: [2024-10-30 14:38:33] iter = 15330, loss = 2.7089
2024-10-30 14:38:33: [2024-10-30 14:38:33] iter = 15340, loss = 3.1589
2024-10-30 14:38:34: [2024-10-30 14:38:34] iter = 15350, loss = 5.5996
2024-10-30 14:38:34: [2024-10-30 14:38:34] iter = 15360, loss = 26.5496
2024-10-30 14:38:35: [2024-10-30 14:38:35] iter = 15370, loss = 7.8763
2024-10-30 14:38:35: [2024-10-30 14:38:35] iter = 15380, loss = 2.5237
2024-10-30 14:38:35: [2024-10-30 14:38:35] iter = 15390, loss = 14.8009
2024-10-30 14:38:36: [2024-10-30 14:38:36] iter = 15400, loss = 3.6843
2024-10-30 14:38:36: [2024-10-30 14:38:36] iter = 15410, loss = 1.3571
2024-10-30 14:38:36: [2024-10-30 14:38:36] iter = 15420, loss = 1.3655
2024-10-30 14:38:37: [2024-10-30 14:38:37] iter = 15430, loss = 3.6542
2024-10-30 14:38:37: [2024-10-30 14:38:37] iter = 15440, loss = 1.6423
2024-10-30 14:38:38: [2024-10-30 14:38:38] iter = 15450, loss = 2.1754
2024-10-30 14:38:38: [2024-10-30 14:38:38] iter = 15460, loss = 44.9430
2024-10-30 14:38:39: [2024-10-30 14:38:39] iter = 15470, loss = 3.9102
2024-10-30 14:38:39: [2024-10-30 14:38:39] iter = 15480, loss = 1.8362
2024-10-30 14:38:39: [2024-10-30 14:38:39] iter = 15490, loss = 15.1230
2024-10-30 14:38:40: [2024-10-30 14:38:40] iter = 15500, loss = 1.3464
2024-10-30 14:38:40: [2024-10-30 14:38:40] iter = 15510, loss = 1.5466
2024-10-30 14:38:41: [2024-10-30 14:38:41] iter = 15520, loss = 23.2501
2024-10-30 14:38:41: [2024-10-30 14:38:41] iter = 15530, loss = 8.3120
2024-10-30 14:38:41: [2024-10-30 14:38:41] iter = 15540, loss = 4.2357
2024-10-30 14:38:42: [2024-10-30 14:38:42] iter = 15550, loss = 1.5849
2024-10-30 14:38:42: [2024-10-30 14:38:42] iter = 15560, loss = 5.2847
2024-10-30 14:38:43: [2024-10-30 14:38:43] iter = 15570, loss = 5.4812
2024-10-30 14:38:43: [2024-10-30 14:38:43] iter = 15580, loss = 4.1521
2024-10-30 14:38:43: [2024-10-30 14:38:43] iter = 15590, loss = 7.7482
2024-10-30 14:38:44: [2024-10-30 14:38:44] iter = 15600, loss = 7.0856
2024-10-30 14:38:44: [2024-10-30 14:38:44] iter = 15610, loss = 15.7465
2024-10-30 14:38:45: [2024-10-30 14:38:45] iter = 15620, loss = 3.2105
2024-10-30 14:38:45: [2024-10-30 14:38:45] iter = 15630, loss = 3.3761
2024-10-30 14:38:45: [2024-10-30 14:38:45] iter = 15640, loss = 4.0040
2024-10-30 14:38:45: [2024-10-30 14:38:45] iter = 15650, loss = 5.2793
2024-10-30 14:38:46: [2024-10-30 14:38:46] iter = 15660, loss = 1.4941
2024-10-30 14:38:46: [2024-10-30 14:38:46] iter = 15670, loss = 1.6930
2024-10-30 14:38:47: [2024-10-30 14:38:47] iter = 15680, loss = 7.6562
2024-10-30 14:38:48: [2024-10-30 14:38:48] iter = 15690, loss = 8.9621
2024-10-30 14:38:48: [2024-10-30 14:38:48] iter = 15700, loss = 4.3410
2024-10-30 14:38:48: [2024-10-30 14:38:48] iter = 15710, loss = 1.8228
2024-10-30 14:38:49: [2024-10-30 14:38:49] iter = 15720, loss = 4.3152
2024-10-30 14:38:49: [2024-10-30 14:38:49] iter = 15730, loss = 4.2381
2024-10-30 14:38:50: [2024-10-30 14:38:50] iter = 15740, loss = 1.9709
2024-10-30 14:38:50: [2024-10-30 14:38:50] iter = 15750, loss = 1.6135
2024-10-30 14:38:51: [2024-10-30 14:38:51] iter = 15760, loss = 1.5826
2024-10-30 14:38:51: [2024-10-30 14:38:51] iter = 15770, loss = 4.4058
2024-10-30 14:38:52: [2024-10-30 14:38:52] iter = 15780, loss = 5.2542
2024-10-30 14:38:52: [2024-10-30 14:38:52] iter = 15790, loss = 1.1546
2024-10-30 14:38:52: [2024-10-30 14:38:52] iter = 15800, loss = 2.0644
2024-10-30 14:38:53: [2024-10-30 14:38:53] iter = 15810, loss = 4.5162
2024-10-30 14:38:53: [2024-10-30 14:38:53] iter = 15820, loss = 7.3116
2024-10-30 14:38:54: [2024-10-30 14:38:54] iter = 15830, loss = 1.7826
2024-10-30 14:38:54: [2024-10-30 14:38:54] iter = 15840, loss = 4.0842
2024-10-30 14:38:54: [2024-10-30 14:38:54] iter = 15850, loss = 3.5931
2024-10-30 14:38:55: [2024-10-30 14:38:55] iter = 15860, loss = 2.9130
2024-10-30 14:38:55: [2024-10-30 14:38:55] iter = 15870, loss = 1.2514
2024-10-30 14:38:56: [2024-10-30 14:38:56] iter = 15880, loss = 1.2820
2024-10-30 14:38:56: [2024-10-30 14:38:56] iter = 15890, loss = 3.5846
2024-10-30 14:38:57: [2024-10-30 14:38:57] iter = 15900, loss = 2.5551
2024-10-30 14:38:57: [2024-10-30 14:38:57] iter = 15910, loss = 3.6002
2024-10-30 14:38:58: [2024-10-30 14:38:58] iter = 15920, loss = 2.3809
2024-10-30 14:38:58: [2024-10-30 14:38:58] iter = 15930, loss = 4.9379
2024-10-30 14:38:59: [2024-10-30 14:38:59] iter = 15940, loss = 5.0959
2024-10-30 14:38:59: [2024-10-30 14:38:59] iter = 15950, loss = 1.7161
2024-10-30 14:39:00: [2024-10-30 14:39:00] iter = 15960, loss = 3.0922
2024-10-30 14:39:00: [2024-10-30 14:39:00] iter = 15970, loss = 1.1828
2024-10-30 14:39:01: [2024-10-30 14:39:01] iter = 15980, loss = 1.2843
2024-10-30 14:39:01: [2024-10-30 14:39:01] iter = 15990, loss = 1.4683
2024-10-30 14:39:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 14:39:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:39:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 41799}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:39:43: Evaluate 5 random ConvNet, ACCmean = 0.7744 ACCstd = 0.0094
-------------------------
2024-10-30 14:39:43: Evaluate 5 random ConvNet, SENmean = 0.6742 SENstd = 0.0189
-------------------------
2024-10-30 14:39:43: Evaluate 5 random ConvNet, SPEmean = 0.6742 SPEstd = 0.0189
-------------------------
2024-10-30 14:39:43: Evaluate 5 random ConvNet, F!mean = 0.6866 F!std = 0.0182
-------------------------
2024-10-30 14:39:43: Evaluate 5 random ConvNet, mean = 0.7744 std = 0.0094
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:39:43: [2024-10-30 14:39:43] iter = 16000, loss = 2.2617
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:39:44: [2024-10-30 14:39:44] iter = 16010, loss = 1.9506
2024-10-30 14:39:44: [2024-10-30 14:39:44] iter = 16020, loss = 6.0658
2024-10-30 14:39:45: [2024-10-30 14:39:45] iter = 16030, loss = 4.6485
2024-10-30 14:39:45: [2024-10-30 14:39:45] iter = 16040, loss = 38.9152
2024-10-30 14:39:45: [2024-10-30 14:39:45] iter = 16050, loss = 7.2069
2024-10-30 14:39:46: [2024-10-30 14:39:46] iter = 16060, loss = 1.2957
2024-10-30 14:39:46: [2024-10-30 14:39:46] iter = 16070, loss = 19.3431
2024-10-30 14:39:46: [2024-10-30 14:39:46] iter = 16080, loss = 7.6590
2024-10-30 14:39:47: [2024-10-30 14:39:47] iter = 16090, loss = 1.7266
2024-10-30 14:39:47: [2024-10-30 14:39:47] iter = 16100, loss = 1.1038
2024-10-30 14:39:48: [2024-10-30 14:39:48] iter = 16110, loss = 3.0265
2024-10-30 14:39:48: [2024-10-30 14:39:48] iter = 16120, loss = 1.5923
2024-10-30 14:39:49: [2024-10-30 14:39:49] iter = 16130, loss = 1.9952
2024-10-30 14:39:49: [2024-10-30 14:39:49] iter = 16140, loss = 1.0123
2024-10-30 14:39:50: [2024-10-30 14:39:50] iter = 16150, loss = 23.9087
2024-10-30 14:39:50: [2024-10-30 14:39:50] iter = 16160, loss = 3.0441
2024-10-30 14:39:51: [2024-10-30 14:39:51] iter = 16170, loss = 4.3587
2024-10-30 14:39:51: [2024-10-30 14:39:51] iter = 16180, loss = 4.3414
2024-10-30 14:39:52: [2024-10-30 14:39:52] iter = 16190, loss = 3.2661
2024-10-30 14:39:52: [2024-10-30 14:39:52] iter = 16200, loss = 6.4098
2024-10-30 14:39:53: [2024-10-30 14:39:53] iter = 16210, loss = 3.4939
2024-10-30 14:39:53: [2024-10-30 14:39:53] iter = 16220, loss = 1.7703
2024-10-30 14:39:53: [2024-10-30 14:39:53] iter = 16230, loss = 1.6485
2024-10-30 14:39:54: [2024-10-30 14:39:54] iter = 16240, loss = 4.6024
2024-10-30 14:39:54: [2024-10-30 14:39:54] iter = 16250, loss = 12.0326
2024-10-30 14:39:54: [2024-10-30 14:39:54] iter = 16260, loss = 1.6213
2024-10-30 14:39:55: [2024-10-30 14:39:55] iter = 16270, loss = 1.9897
2024-10-30 14:39:55: [2024-10-30 14:39:55] iter = 16280, loss = 3.5597
2024-10-30 14:39:56: [2024-10-30 14:39:56] iter = 16290, loss = 1.3771
2024-10-30 14:39:56: [2024-10-30 14:39:56] iter = 16300, loss = 2.5686
2024-10-30 14:39:56: [2024-10-30 14:39:56] iter = 16310, loss = 6.1915
2024-10-30 14:39:57: [2024-10-30 14:39:57] iter = 16320, loss = 1.7761
2024-10-30 14:39:57: [2024-10-30 14:39:57] iter = 16330, loss = 1.7007
2024-10-30 14:39:58: [2024-10-30 14:39:58] iter = 16340, loss = 2.5084
2024-10-30 14:39:58: [2024-10-30 14:39:58] iter = 16350, loss = 4.0063
2024-10-30 14:39:59: [2024-10-30 14:39:59] iter = 16360, loss = 1.8762
2024-10-30 14:39:59: [2024-10-30 14:39:59] iter = 16370, loss = 1.6494
2024-10-30 14:40:00: [2024-10-30 14:40:00] iter = 16380, loss = 25.8433
2024-10-30 14:40:00: [2024-10-30 14:40:00] iter = 16390, loss = 9.8249
2024-10-30 14:40:01: [2024-10-30 14:40:01] iter = 16400, loss = 14.3972
2024-10-30 14:40:01: [2024-10-30 14:40:01] iter = 16410, loss = 4.5123
2024-10-30 14:40:02: [2024-10-30 14:40:02] iter = 16420, loss = 17.4810
2024-10-30 14:40:02: [2024-10-30 14:40:02] iter = 16430, loss = 2.1522
2024-10-30 14:40:03: [2024-10-30 14:40:03] iter = 16440, loss = 3.6170
2024-10-30 14:40:03: [2024-10-30 14:40:03] iter = 16450, loss = 38.1130
2024-10-30 14:40:04: [2024-10-30 14:40:04] iter = 16460, loss = 2.5439
2024-10-30 14:40:04: [2024-10-30 14:40:04] iter = 16470, loss = 10.2225
2024-10-30 14:40:05: [2024-10-30 14:40:05] iter = 16480, loss = 11.3721
2024-10-30 14:40:05: [2024-10-30 14:40:05] iter = 16490, loss = 14.6891
2024-10-30 14:40:06: [2024-10-30 14:40:06] iter = 16500, loss = 3.4498
2024-10-30 14:40:06: [2024-10-30 14:40:06] iter = 16510, loss = 2.4366
2024-10-30 14:40:07: [2024-10-30 14:40:07] iter = 16520, loss = 2.5532
2024-10-30 14:40:07: [2024-10-30 14:40:07] iter = 16530, loss = 10.1796
2024-10-30 14:40:07: [2024-10-30 14:40:07] iter = 16540, loss = 3.2635
2024-10-30 14:40:08: [2024-10-30 14:40:08] iter = 16550, loss = 8.0731
2024-10-30 14:40:08: [2024-10-30 14:40:08] iter = 16560, loss = 5.5957
2024-10-30 14:40:08: [2024-10-30 14:40:08] iter = 16570, loss = 5.6472
2024-10-30 14:40:09: [2024-10-30 14:40:09] iter = 16580, loss = 3.4467
2024-10-30 14:40:09: [2024-10-30 14:40:09] iter = 16590, loss = 24.0606
2024-10-30 14:40:09: [2024-10-30 14:40:09] iter = 16600, loss = 2.8146
2024-10-30 14:40:10: [2024-10-30 14:40:10] iter = 16610, loss = 1.9191
2024-10-30 14:40:10: [2024-10-30 14:40:10] iter = 16620, loss = 2.6122
2024-10-30 14:40:11: [2024-10-30 14:40:11] iter = 16630, loss = 2.2912
2024-10-30 14:40:11: [2024-10-30 14:40:11] iter = 16640, loss = 4.7781
2024-10-30 14:40:11: [2024-10-30 14:40:11] iter = 16650, loss = 1.2040
2024-10-30 14:40:12: [2024-10-30 14:40:12] iter = 16660, loss = 2.3295
2024-10-30 14:40:12: [2024-10-30 14:40:12] iter = 16670, loss = 7.2666
2024-10-30 14:40:12: [2024-10-30 14:40:12] iter = 16680, loss = 3.0091
2024-10-30 14:40:13: [2024-10-30 14:40:13] iter = 16690, loss = 7.2092
2024-10-30 14:40:13: [2024-10-30 14:40:13] iter = 16700, loss = 2.6552
2024-10-30 14:40:14: [2024-10-30 14:40:14] iter = 16710, loss = 1.5358
2024-10-30 14:40:14: [2024-10-30 14:40:14] iter = 16720, loss = 1.9693
2024-10-30 14:40:15: [2024-10-30 14:40:15] iter = 16730, loss = 2.3829
2024-10-30 14:40:15: [2024-10-30 14:40:15] iter = 16740, loss = 4.4568
2024-10-30 14:40:16: [2024-10-30 14:40:16] iter = 16750, loss = 4.0132
2024-10-30 14:40:16: [2024-10-30 14:40:16] iter = 16760, loss = 1.6656
2024-10-30 14:40:17: [2024-10-30 14:40:17] iter = 16770, loss = 18.4857
2024-10-30 14:40:17: [2024-10-30 14:40:17] iter = 16780, loss = 3.5474
2024-10-30 14:40:18: [2024-10-30 14:40:18] iter = 16790, loss = 2.8991
2024-10-30 14:40:18: [2024-10-30 14:40:18] iter = 16800, loss = 5.1105
2024-10-30 14:40:18: [2024-10-30 14:40:18] iter = 16810, loss = 2.5515
2024-10-30 14:40:19: [2024-10-30 14:40:19] iter = 16820, loss = 2.1105
2024-10-30 14:40:19: [2024-10-30 14:40:19] iter = 16830, loss = 6.0038
2024-10-30 14:40:19: [2024-10-30 14:40:19] iter = 16840, loss = 2.4398
2024-10-30 14:40:20: [2024-10-30 14:40:20] iter = 16850, loss = 1.6824
2024-10-30 14:40:20: [2024-10-30 14:40:20] iter = 16860, loss = 1.0834
2024-10-30 14:40:21: [2024-10-30 14:40:21] iter = 16870, loss = 4.0026
2024-10-30 14:40:21: [2024-10-30 14:40:21] iter = 16880, loss = 4.0425
2024-10-30 14:40:22: [2024-10-30 14:40:22] iter = 16890, loss = 2.8270
2024-10-30 14:40:22: [2024-10-30 14:40:22] iter = 16900, loss = 3.1613
2024-10-30 14:40:22: [2024-10-30 14:40:22] iter = 16910, loss = 3.6732
2024-10-30 14:40:23: [2024-10-30 14:40:23] iter = 16920, loss = 5.2277
2024-10-30 14:40:24: [2024-10-30 14:40:24] iter = 16930, loss = 7.1774
2024-10-30 14:40:24: [2024-10-30 14:40:24] iter = 16940, loss = 3.9471
2024-10-30 14:40:24: [2024-10-30 14:40:24] iter = 16950, loss = 1.7717
2024-10-30 14:40:25: [2024-10-30 14:40:25] iter = 16960, loss = 14.3236
2024-10-30 14:40:25: [2024-10-30 14:40:25] iter = 16970, loss = 1.8598
2024-10-30 14:40:26: [2024-10-30 14:40:26] iter = 16980, loss = 3.9565
2024-10-30 14:40:26: [2024-10-30 14:40:26] iter = 16990, loss = 2.3538
2024-10-30 14:40:27: [2024-10-30 14:40:27] iter = 17000, loss = 3.6410
2024-10-30 14:40:27: [2024-10-30 14:40:27] iter = 17010, loss = 2.6128
2024-10-30 14:40:28: [2024-10-30 14:40:28] iter = 17020, loss = 3.2896
2024-10-30 14:40:28: [2024-10-30 14:40:28] iter = 17030, loss = 26.6756
2024-10-30 14:40:28: [2024-10-30 14:40:28] iter = 17040, loss = 3.4134
2024-10-30 14:40:29: [2024-10-30 14:40:29] iter = 17050, loss = 1.3988
2024-10-30 14:40:29: [2024-10-30 14:40:29] iter = 17060, loss = 5.5119
2024-10-30 14:40:30: [2024-10-30 14:40:30] iter = 17070, loss = 10.3647
2024-10-30 14:40:30: [2024-10-30 14:40:30] iter = 17080, loss = 37.9505
2024-10-30 14:40:31: [2024-10-30 14:40:31] iter = 17090, loss = 2.2569
2024-10-30 14:40:31: [2024-10-30 14:40:31] iter = 17100, loss = 1.5384
2024-10-30 14:40:31: [2024-10-30 14:40:31] iter = 17110, loss = 1.1949
2024-10-30 14:40:31: [2024-10-30 14:40:31] iter = 17120, loss = 2.1665
2024-10-30 14:40:32: [2024-10-30 14:40:32] iter = 17130, loss = 1.0498
2024-10-30 14:40:32: [2024-10-30 14:40:32] iter = 17140, loss = 2.6349
2024-10-30 14:40:32: [2024-10-30 14:40:32] iter = 17150, loss = 8.6665
2024-10-30 14:40:33: [2024-10-30 14:40:33] iter = 17160, loss = 2.8430
2024-10-30 14:40:33: [2024-10-30 14:40:33] iter = 17170, loss = 1.4955
2024-10-30 14:40:34: [2024-10-30 14:40:34] iter = 17180, loss = 6.1159
2024-10-30 14:40:34: [2024-10-30 14:40:34] iter = 17190, loss = 2.7544
2024-10-30 14:40:34: [2024-10-30 14:40:34] iter = 17200, loss = 2.5412
2024-10-30 14:40:35: [2024-10-30 14:40:35] iter = 17210, loss = 3.5458
2024-10-30 14:40:35: [2024-10-30 14:40:35] iter = 17220, loss = 2.5093
2024-10-30 14:40:35: [2024-10-30 14:40:35] iter = 17230, loss = 1.8759
2024-10-30 14:40:36: [2024-10-30 14:40:36] iter = 17240, loss = 9.2736
2024-10-30 14:40:36: [2024-10-30 14:40:36] iter = 17250, loss = 8.0973
2024-10-30 14:40:37: [2024-10-30 14:40:37] iter = 17260, loss = 12.9880
2024-10-30 14:40:37: [2024-10-30 14:40:37] iter = 17270, loss = 2.5585
2024-10-30 14:40:37: [2024-10-30 14:40:37] iter = 17280, loss = 1.0688
2024-10-30 14:40:38: [2024-10-30 14:40:38] iter = 17290, loss = 6.9052
2024-10-30 14:40:38: [2024-10-30 14:40:38] iter = 17300, loss = 1.4951
2024-10-30 14:40:39: [2024-10-30 14:40:39] iter = 17310, loss = 4.3597
2024-10-30 14:40:39: [2024-10-30 14:40:39] iter = 17320, loss = 1.1220
2024-10-30 14:40:39: [2024-10-30 14:40:39] iter = 17330, loss = 6.9444
2024-10-30 14:40:40: [2024-10-30 14:40:40] iter = 17340, loss = 3.5154
2024-10-30 14:40:40: [2024-10-30 14:40:40] iter = 17350, loss = 3.3976
2024-10-30 14:40:40: [2024-10-30 14:40:40] iter = 17360, loss = 2.4033
2024-10-30 14:40:41: [2024-10-30 14:40:41] iter = 17370, loss = 4.4585
2024-10-30 14:40:41: [2024-10-30 14:40:41] iter = 17380, loss = 3.6401
2024-10-30 14:40:42: [2024-10-30 14:40:42] iter = 17390, loss = 13.7320
2024-10-30 14:40:42: [2024-10-30 14:40:42] iter = 17400, loss = 1.5865
2024-10-30 14:40:42: [2024-10-30 14:40:42] iter = 17410, loss = 3.9085
2024-10-30 14:40:43: [2024-10-30 14:40:43] iter = 17420, loss = 1.9355
2024-10-30 14:40:43: [2024-10-30 14:40:43] iter = 17430, loss = 1.5684
2024-10-30 14:40:44: [2024-10-30 14:40:44] iter = 17440, loss = 2.0936
2024-10-30 14:40:44: [2024-10-30 14:40:44] iter = 17450, loss = 2.2847
2024-10-30 14:40:44: [2024-10-30 14:40:44] iter = 17460, loss = 1.5560
2024-10-30 14:40:45: [2024-10-30 14:40:45] iter = 17470, loss = 1.4046
2024-10-30 14:40:46: [2024-10-30 14:40:46] iter = 17480, loss = 1.3271
2024-10-30 14:40:46: [2024-10-30 14:40:46] iter = 17490, loss = 1.7988
2024-10-30 14:40:46: [2024-10-30 14:40:46] iter = 17500, loss = 4.0764
2024-10-30 14:40:47: [2024-10-30 14:40:47] iter = 17510, loss = 16.0215
2024-10-30 14:40:47: [2024-10-30 14:40:47] iter = 17520, loss = 3.1476
2024-10-30 14:40:48: [2024-10-30 14:40:48] iter = 17530, loss = 1.9518
2024-10-30 14:40:48: [2024-10-30 14:40:48] iter = 17540, loss = 1.9665
2024-10-30 14:40:49: [2024-10-30 14:40:49] iter = 17550, loss = 3.9177
2024-10-30 14:40:49: [2024-10-30 14:40:49] iter = 17560, loss = 1.3730
2024-10-30 14:40:50: [2024-10-30 14:40:50] iter = 17570, loss = 1.9853
2024-10-30 14:40:51: [2024-10-30 14:40:51] iter = 17580, loss = 4.4030
2024-10-30 14:40:51: [2024-10-30 14:40:51] iter = 17590, loss = 1.5791
2024-10-30 14:40:51: [2024-10-30 14:40:51] iter = 17600, loss = 30.1951
2024-10-30 14:40:52: [2024-10-30 14:40:52] iter = 17610, loss = 5.9157
2024-10-30 14:40:52: [2024-10-30 14:40:52] iter = 17620, loss = 1.5194
2024-10-30 14:40:53: [2024-10-30 14:40:53] iter = 17630, loss = 2.5220
2024-10-30 14:40:53: [2024-10-30 14:40:53] iter = 17640, loss = 2.7718
2024-10-30 14:40:53: [2024-10-30 14:40:53] iter = 17650, loss = 1.5096
2024-10-30 14:40:54: [2024-10-30 14:40:54] iter = 17660, loss = 10.2578
2024-10-30 14:40:55: [2024-10-30 14:40:55] iter = 17670, loss = 4.2276
2024-10-30 14:40:55: [2024-10-30 14:40:55] iter = 17680, loss = 2.1998
2024-10-30 14:40:56: [2024-10-30 14:40:56] iter = 17690, loss = 3.6427
2024-10-30 14:40:56: [2024-10-30 14:40:56] iter = 17700, loss = 13.7862
2024-10-30 14:40:57: [2024-10-30 14:40:57] iter = 17710, loss = 2.3015
2024-10-30 14:40:58: [2024-10-30 14:40:58] iter = 17720, loss = 2.2119
2024-10-30 14:40:58: [2024-10-30 14:40:58] iter = 17730, loss = 2.3920
2024-10-30 14:40:58: [2024-10-30 14:40:58] iter = 17740, loss = 5.4436
2024-10-30 14:40:59: [2024-10-30 14:40:59] iter = 17750, loss = 1.9387
2024-10-30 14:41:00: [2024-10-30 14:41:00] iter = 17760, loss = 25.7166
2024-10-30 14:41:00: [2024-10-30 14:41:00] iter = 17770, loss = 6.3179
2024-10-30 14:41:01: [2024-10-30 14:41:01] iter = 17780, loss = 1.9439
2024-10-30 14:41:02: [2024-10-30 14:41:02] iter = 17790, loss = 1.8978
2024-10-30 14:41:02: [2024-10-30 14:41:02] iter = 17800, loss = 5.4385
2024-10-30 14:41:03: [2024-10-30 14:41:03] iter = 17810, loss = 1.6275
2024-10-30 14:41:03: [2024-10-30 14:41:03] iter = 17820, loss = 13.7271
2024-10-30 14:41:04: [2024-10-30 14:41:04] iter = 17830, loss = 3.6668
2024-10-30 14:41:04: [2024-10-30 14:41:04] iter = 17840, loss = 1.7596
2024-10-30 14:41:05: [2024-10-30 14:41:05] iter = 17850, loss = 5.6149
2024-10-30 14:41:05: [2024-10-30 14:41:05] iter = 17860, loss = 1.7120
2024-10-30 14:41:06: [2024-10-30 14:41:06] iter = 17870, loss = 1.2240
2024-10-30 14:41:06: [2024-10-30 14:41:06] iter = 17880, loss = 10.7077
2024-10-30 14:41:07: [2024-10-30 14:41:07] iter = 17890, loss = 6.2737
2024-10-30 14:41:07: [2024-10-30 14:41:07] iter = 17900, loss = 2.1689
2024-10-30 14:41:08: [2024-10-30 14:41:08] iter = 17910, loss = 6.3308
2024-10-30 14:41:09: [2024-10-30 14:41:09] iter = 17920, loss = 5.4003
2024-10-30 14:41:09: [2024-10-30 14:41:09] iter = 17930, loss = 1.8428
2024-10-30 14:41:10: [2024-10-30 14:41:10] iter = 17940, loss = 4.3277
2024-10-30 14:41:10: [2024-10-30 14:41:10] iter = 17950, loss = 2.8217
2024-10-30 14:41:10: [2024-10-30 14:41:10] iter = 17960, loss = 1.7125
2024-10-30 14:41:11: [2024-10-30 14:41:11] iter = 17970, loss = 1.2757
2024-10-30 14:41:12: [2024-10-30 14:41:12] iter = 17980, loss = 2.3738
2024-10-30 14:41:12: [2024-10-30 14:41:12] iter = 17990, loss = 1.1207
2024-10-30 14:41:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 14:41:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:41:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 72888}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/breastmnist.npz
Loaded the dataset:BreastMNIST
[2024-10-30 14:20:27] Evaluate_00: epoch = 1000 train time = 14 s train loss = 0.000143 train acc = 1.0000, test acc = 0.6154, test_sen =0.6466, test_spe =0.6466, test_f1 =0.5938
[2024-10-30 14:20:36] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.000705 train acc = 1.0000, test acc = 0.5833, test_sen =0.6172, test_spe =0.6172, test_f1 =0.5638
[2024-10-30 14:20:47] Evaluate_02: epoch = 1000 train time = 10 s train loss = 0.000364 train acc = 1.0000, test acc = 0.6538, test_sen =0.6955, test_spe =0.6955, test_f1 =0.6344
[2024-10-30 14:20:57] Evaluate_03: epoch = 1000 train time = 9 s train loss = 0.001777 train acc = 1.0000, test acc = 0.5256, test_sen =0.5777, test_spe =0.5777, test_f1 =0.5141
[2024-10-30 14:21:09] Evaluate_04: epoch = 1000 train time = 12 s train loss = 0.003059 train acc = 1.0000, test acc = 0.6154, test_sen =0.6541, test_spe =0.6541, test_f1 =0.5962
[2024-10-30 14:22:58] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.007941 train acc = 1.0000, test acc = 0.8013, test_sen =0.7137, test_spe =0.7137, test_f1 =0.7279
[2024-10-30 14:23:05] Evaluate_01: epoch = 1000 train time = 7 s train loss = 0.000588 train acc = 1.0000, test acc = 0.7885, test_sen =0.7199, test_spe =0.7199, test_f1 =0.7249
[2024-10-30 14:23:15] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.000043 train acc = 1.0000, test acc = 0.7756, test_sen =0.6811, test_spe =0.6811, test_f1 =0.6928
[2024-10-30 14:23:24] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.004881 train acc = 1.0000, test acc = 0.7756, test_sen =0.6961, test_spe =0.6961, test_f1 =0.7034
[2024-10-30 14:23:33] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.000432 train acc = 1.0000, test acc = 0.7564, test_sen =0.6679, test_spe =0.6679, test_f1 =0.6752
[2024-10-30 14:25:18] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.027690 train acc = 1.0000, test acc = 0.7885, test_sen =0.7575, test_spe =0.7575, test_f1 =0.7440
[2024-10-30 14:25:26] Evaluate_01: epoch = 1000 train time = 8 s train loss = 0.000194 train acc = 1.0000, test acc = 0.7821, test_sen =0.7456, test_spe =0.7456, test_f1 =0.7345
[2024-10-30 14:25:36] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.015204 train acc = 1.0000, test acc = 0.7885, test_sen =0.7425, test_spe =0.7425, test_f1 =0.7370
[2024-10-30 14:25:45] Evaluate_03: epoch = 1000 train time = 9 s train loss = 0.000581 train acc = 1.0000, test acc = 0.7756, test_sen =0.7262, test_spe =0.7262, test_f1 =0.7211
[2024-10-30 14:25:54] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.000145 train acc = 1.0000, test acc = 0.7885, test_sen =0.7425, test_spe =0.7425, test_f1 =0.7370
[2024-10-30 14:27:38] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.000342 train acc = 1.0000, test acc = 0.7564, test_sen =0.7356, test_spe =0.7356, test_f1 =0.7141
[2024-10-30 14:27:48] Evaluate_01: epoch = 1000 train time = 10 s train loss = 0.002379 train acc = 1.0000, test acc = 0.7756, test_sen =0.7412, test_spe =0.7412, test_f1 =0.7285
[2024-10-30 14:27:57] Evaluate_02: epoch = 1000 train time = 8 s train loss = 0.000615 train acc = 1.0000, test acc = 0.7756, test_sen =0.7487, test_spe =0.7487, test_f1 =0.7319
[2024-10-30 14:28:06] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.000191 train acc = 1.0000, test acc = 0.7372, test_sen =0.7149, test_spe =0.7149, test_f1 =0.6933
[2024-10-30 14:28:14] Evaluate_04: epoch = 1000 train time = 7 s train loss = 0.000751 train acc = 1.0000, test acc = 0.7436, test_sen =0.7268, test_spe =0.7268, test_f1 =0.7025
[2024-10-30 14:29:55] Evaluate_00: epoch = 1000 train time = 9 s train loss = 0.000455 train acc = 1.0000, test acc = 0.6667, test_sen =0.7193, test_spe =0.7193, test_f1 =0.6500
[2024-10-30 14:30:04] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.001072 train acc = 1.0000, test acc = 0.6731, test_sen =0.7312, test_spe =0.7312, test_f1 =0.6578
[2024-10-30 14:30:14] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.003923 train acc = 1.0000, test acc = 0.6603, test_sen =0.7299, test_spe =0.7299, test_f1 =0.6481
[2024-10-30 14:30:23] Evaluate_03: epoch = 1000 train time = 9 s train loss = 0.000234 train acc = 1.0000, test acc = 0.6282, test_sen =0.7005, test_spe =0.7005, test_f1 =0.6176
[2024-10-30 14:30:32] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.000287 train acc = 1.0000, test acc = 0.6026, test_sen =0.6754, test_spe =0.6754, test_f1 =0.5929
[2024-10-30 14:32:16] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.008856 train acc = 1.0000, test acc = 0.7372, test_sen =0.6623, test_spe =0.6623, test_f1 =0.6635
[2024-10-30 14:32:26] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.001075 train acc = 1.0000, test acc = 0.7115, test_sen =0.6447, test_spe =0.6447, test_f1 =0.6414
[2024-10-30 14:32:36] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.001433 train acc = 1.0000, test acc = 0.7179, test_sen =0.6266, test_spe =0.6266, test_f1 =0.6302
[2024-10-30 14:32:46] Evaluate_03: epoch = 1000 train time = 10 s train loss = 0.000121 train acc = 1.0000, test acc = 0.7308, test_sen =0.6579, test_spe =0.6579, test_f1 =0.6579
[2024-10-30 14:32:55] Evaluate_04: epoch = 1000 train time = 8 s train loss = 0.000525 train acc = 1.0000, test acc = 0.7308, test_sen =0.6353, test_spe =0.6353, test_f1 =0.6410
[2024-10-30 14:34:42] Evaluate_00: epoch = 1000 train time = 9 s train loss = 0.000206 train acc = 1.0000, test acc = 0.6987, test_sen =0.7337, test_spe =0.7337, test_f1 =0.6764
[2024-10-30 14:34:51] Evaluate_01: epoch = 1000 train time = 8 s train loss = 0.000411 train acc = 1.0000, test acc = 0.7115, test_sen =0.7425, test_spe =0.7425, test_f1 =0.6878
[2024-10-30 14:35:00] Evaluate_02: epoch = 1000 train time = 8 s train loss = 0.084672 train acc = 0.9500, test acc = 0.7179, test_sen =0.7544, test_spe =0.7544, test_f1 =0.6959
[2024-10-30 14:35:08] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.001545 train acc = 1.0000, test acc = 0.6346, test_sen =0.7049, test_spe =0.7049, test_f1 =0.6233
[2024-10-30 14:35:18] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.001318 train acc = 1.0000, test acc = 0.6731, test_sen =0.7237, test_spe =0.7237, test_f1 =0.6557
[2024-10-30 14:36:55] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.000463 train acc = 1.0000, test acc = 0.7949, test_sen =0.7393, test_spe =0.7393, test_f1 =0.7393
[2024-10-30 14:37:04] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.007687 train acc = 1.0000, test acc = 0.7692, test_sen =0.7143, test_spe =0.7143, test_f1 =0.7111
[2024-10-30 14:37:13] Evaluate_02: epoch = 1000 train time = 8 s train loss = 0.001710 train acc = 1.0000, test acc = 0.7628, test_sen =0.7099, test_spe =0.7099, test_f1 =0.7051
[2024-10-30 14:37:22] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.001459 train acc = 1.0000, test acc = 0.7756, test_sen =0.7187, test_spe =0.7187, test_f1 =0.7170
[2024-10-30 14:37:31] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.005033 train acc = 1.0000, test acc = 0.8205, test_sen =0.7719, test_spe =0.7719, test_f1 =0.7719
[2024-10-30 14:39:11] Evaluate_00: epoch = 1000 train time = 9 s train loss = 0.001199 train acc = 1.0000, test acc = 0.7821, test_sen =0.6855, test_spe =0.6855, test_f1 =0.6988
[2024-10-30 14:39:19] Evaluate_01: epoch = 1000 train time = 8 s train loss = 0.000338 train acc = 1.0000, test acc = 0.7692, test_sen =0.6541, test_spe =0.6541, test_f1 =0.6685
[2024-10-30 14:39:27] Evaluate_02: epoch = 1000 train time = 7 s train loss = 0.000056 train acc = 1.0000, test acc = 0.7628, test_sen =0.6573, test_spe =0.6573, test_f1 =0.6692
[2024-10-30 14:39:35] Evaluate_03: epoch = 1000 train time = 7 s train loss = 0.000652 train acc = 1.0000, test acc = 0.7885, test_sen =0.7049, test_spe =0.7049, test_f1 =0.7155
[2024-10-30 14:39:43] Evaluate_04: epoch = 1000 train time = 8 s train loss = 0.125976 train acc = 0.9500, test acc = 0.7692, test_sen =0.6692, test_spe =0.6692, test_f1 =0.6811
[2024-10-30 14:41:21] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.000291 train acc = 1.0000, test acc = 0.6026, test_sen =0.6754, test_spe =0.6754, test_f1 =0.5929/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:41:59: Evaluate 5 random ConvNet, ACCmean = 0.6346 ACCstd = 0.0324
-------------------------
2024-10-30 14:41:59: Evaluate 5 random ConvNet, SENmean = 0.6898 SENstd = 0.0169
-------------------------
2024-10-30 14:41:59: Evaluate 5 random ConvNet, SPEmean = 0.6898 SPEstd = 0.0169
-------------------------
2024-10-30 14:41:59: Evaluate 5 random ConvNet, F!mean = 0.6193 F!std = 0.0273
-------------------------
2024-10-30 14:41:59: Evaluate 5 random ConvNet, mean = 0.6346 std = 0.0324
-------------------------
2024-10-30 14:41:59: [2024-10-30 14:41:59] iter = 18000, loss = 1.8615
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:41:59: [2024-10-30 14:41:59] iter = 18010, loss = 1.8674
2024-10-30 14:42:00: [2024-10-30 14:42:00] iter = 18020, loss = 1.7791
2024-10-30 14:42:01: [2024-10-30 14:42:01] iter = 18030, loss = 5.3661
2024-10-30 14:42:01: [2024-10-30 14:42:01] iter = 18040, loss = 1.8071
2024-10-30 14:42:02: [2024-10-30 14:42:02] iter = 18050, loss = 2.0633
2024-10-30 14:42:03: [2024-10-30 14:42:03] iter = 18060, loss = 1.4984
2024-10-30 14:42:03: [2024-10-30 14:42:03] iter = 18070, loss = 2.8928
2024-10-30 14:42:04: [2024-10-30 14:42:04] iter = 18080, loss = 8.7947
2024-10-30 14:42:04: [2024-10-30 14:42:04] iter = 18090, loss = 1.3768
2024-10-30 14:42:05: [2024-10-30 14:42:05] iter = 18100, loss = 27.5028
2024-10-30 14:42:05: [2024-10-30 14:42:05] iter = 18110, loss = 5.3037
2024-10-30 14:42:05: [2024-10-30 14:42:05] iter = 18120, loss = 1.8618
2024-10-30 14:42:06: [2024-10-30 14:42:06] iter = 18130, loss = 4.1939
2024-10-30 14:42:06: [2024-10-30 14:42:06] iter = 18140, loss = 1.6108
2024-10-30 14:42:06: [2024-10-30 14:42:06] iter = 18150, loss = 2.2581
2024-10-30 14:42:07: [2024-10-30 14:42:07] iter = 18160, loss = 1.9567
2024-10-30 14:42:08: [2024-10-30 14:42:08] iter = 18170, loss = 1.7029
2024-10-30 14:42:08: [2024-10-30 14:42:08] iter = 18180, loss = 5.6710
2024-10-30 14:42:09: [2024-10-30 14:42:09] iter = 18190, loss = 1.4173
2024-10-30 14:42:10: [2024-10-30 14:42:10] iter = 18200, loss = 1.1337
2024-10-30 14:42:10: [2024-10-30 14:42:10] iter = 18210, loss = 17.2133
2024-10-30 14:42:11: [2024-10-30 14:42:11] iter = 18220, loss = 3.0185
2024-10-30 14:42:11: [2024-10-30 14:42:11] iter = 18230, loss = 7.6209
2024-10-30 14:42:12: [2024-10-30 14:42:12] iter = 18240, loss = 2.2908
2024-10-30 14:42:13: [2024-10-30 14:42:13] iter = 18250, loss = 5.0146
2024-10-30 14:42:13: [2024-10-30 14:42:13] iter = 18260, loss = 1.2976
2024-10-30 14:42:14: [2024-10-30 14:42:14] iter = 18270, loss = 3.8152
2024-10-30 14:42:14: [2024-10-30 14:42:14] iter = 18280, loss = 17.6639
2024-10-30 14:42:15: [2024-10-30 14:42:15] iter = 18290, loss = 7.5055
2024-10-30 14:42:16: [2024-10-30 14:42:16] iter = 18300, loss = 10.3238
2024-10-30 14:42:16: [2024-10-30 14:42:16] iter = 18310, loss = 7.2164
2024-10-30 14:42:17: [2024-10-30 14:42:17] iter = 18320, loss = 2.8089
2024-10-30 14:42:17: [2024-10-30 14:42:17] iter = 18330, loss = 4.5790
2024-10-30 14:42:18: [2024-10-30 14:42:18] iter = 18340, loss = 10.7493
2024-10-30 14:42:18: [2024-10-30 14:42:18] iter = 18350, loss = 8.9095
2024-10-30 14:42:18: [2024-10-30 14:42:18] iter = 18360, loss = 2.0399
2024-10-30 14:42:19: [2024-10-30 14:42:19] iter = 18370, loss = 1.2168
2024-10-30 14:42:19: [2024-10-30 14:42:19] iter = 18380, loss = 1.5828
2024-10-30 14:42:20: [2024-10-30 14:42:20] iter = 18390, loss = 1.2655
2024-10-30 14:42:20: [2024-10-30 14:42:20] iter = 18400, loss = 3.8932
2024-10-30 14:42:21: [2024-10-30 14:42:21] iter = 18410, loss = 7.8953
2024-10-30 14:42:21: [2024-10-30 14:42:21] iter = 18420, loss = 3.9093
2024-10-30 14:42:22: [2024-10-30 14:42:22] iter = 18430, loss = 6.2516
2024-10-30 14:42:22: [2024-10-30 14:42:22] iter = 18440, loss = 1.8330
2024-10-30 14:42:23: [2024-10-30 14:42:23] iter = 18450, loss = 4.3306
2024-10-30 14:42:23: [2024-10-30 14:42:23] iter = 18460, loss = 5.1560
2024-10-30 14:42:24: [2024-10-30 14:42:24] iter = 18470, loss = 3.2428
2024-10-30 14:42:24: [2024-10-30 14:42:24] iter = 18480, loss = 1.8918
2024-10-30 14:42:24: [2024-10-30 14:42:24] iter = 18490, loss = 1.6229
2024-10-30 14:42:25: [2024-10-30 14:42:25] iter = 18500, loss = 1.1426
2024-10-30 14:42:25: [2024-10-30 14:42:25] iter = 18510, loss = 3.4531
2024-10-30 14:42:26: [2024-10-30 14:42:26] iter = 18520, loss = 1.3062
2024-10-30 14:42:27: [2024-10-30 14:42:26] iter = 18530, loss = 1.4774
2024-10-30 14:42:27: [2024-10-30 14:42:27] iter = 18540, loss = 3.3019
2024-10-30 14:42:27: [2024-10-30 14:42:27] iter = 18550, loss = 4.2501
2024-10-30 14:42:28: [2024-10-30 14:42:28] iter = 18560, loss = 3.4642
2024-10-30 14:42:28: [2024-10-30 14:42:28] iter = 18570, loss = 11.8715
2024-10-30 14:42:29: [2024-10-30 14:42:29] iter = 18580, loss = 12.3352
2024-10-30 14:42:30: [2024-10-30 14:42:30] iter = 18590, loss = 1.7749
2024-10-30 14:42:30: [2024-10-30 14:42:30] iter = 18600, loss = 1.6252
2024-10-30 14:42:31: [2024-10-30 14:42:31] iter = 18610, loss = 4.2415
2024-10-30 14:42:32: [2024-10-30 14:42:32] iter = 18620, loss = 5.4139
2024-10-30 14:42:32: [2024-10-30 14:42:32] iter = 18630, loss = 4.1660
2024-10-30 14:42:33: [2024-10-30 14:42:33] iter = 18640, loss = 2.3094
2024-10-30 14:42:34: [2024-10-30 14:42:34] iter = 18650, loss = 3.5222
2024-10-30 14:42:34: [2024-10-30 14:42:34] iter = 18660, loss = 1.8366
2024-10-30 14:42:35: [2024-10-30 14:42:35] iter = 18670, loss = 5.7791
2024-10-30 14:42:35: [2024-10-30 14:42:35] iter = 18680, loss = 3.2546
2024-10-30 14:42:36: [2024-10-30 14:42:36] iter = 18690, loss = 3.6812
2024-10-30 14:42:36: [2024-10-30 14:42:36] iter = 18700, loss = 3.0674
2024-10-30 14:42:37: [2024-10-30 14:42:37] iter = 18710, loss = 3.5209
2024-10-30 14:42:37: [2024-10-30 14:42:37] iter = 18720, loss = 2.3046
2024-10-30 14:42:37: [2024-10-30 14:42:37] iter = 18730, loss = 12.1243
2024-10-30 14:42:38: [2024-10-30 14:42:38] iter = 18740, loss = 3.1226
2024-10-30 14:42:38: [2024-10-30 14:42:38] iter = 18750, loss = 15.1367
2024-10-30 14:42:38: [2024-10-30 14:42:38] iter = 18760, loss = 2.9866
2024-10-30 14:42:39: [2024-10-30 14:42:39] iter = 18770, loss = 2.1888
2024-10-30 14:42:39: [2024-10-30 14:42:39] iter = 18780, loss = 1.8639
2024-10-30 14:42:39: [2024-10-30 14:42:39] iter = 18790, loss = 7.6989
2024-10-30 14:42:40: [2024-10-30 14:42:40] iter = 18800, loss = 2.0703
2024-10-30 14:42:40: [2024-10-30 14:42:40] iter = 18810, loss = 5.1095
2024-10-30 14:42:41: [2024-10-30 14:42:41] iter = 18820, loss = 11.2624
2024-10-30 14:42:41: [2024-10-30 14:42:41] iter = 18830, loss = 2.8078
2024-10-30 14:42:42: [2024-10-30 14:42:42] iter = 18840, loss = 2.1417
2024-10-30 14:42:43: [2024-10-30 14:42:43] iter = 18850, loss = 3.4838
2024-10-30 14:42:43: [2024-10-30 14:42:43] iter = 18860, loss = 2.7271
2024-10-30 14:42:44: [2024-10-30 14:42:44] iter = 18870, loss = 5.2002
2024-10-30 14:42:44: [2024-10-30 14:42:44] iter = 18880, loss = 2.8141
2024-10-30 14:42:45: [2024-10-30 14:42:45] iter = 18890, loss = 10.1972
2024-10-30 14:42:46: [2024-10-30 14:42:46] iter = 18900, loss = 1.5157
2024-10-30 14:42:46: [2024-10-30 14:42:46] iter = 18910, loss = 2.0692
2024-10-30 14:42:46: [2024-10-30 14:42:46] iter = 18920, loss = 14.1574
2024-10-30 14:42:47: [2024-10-30 14:42:47] iter = 18930, loss = 5.2300
2024-10-30 14:42:48: [2024-10-30 14:42:48] iter = 18940, loss = 1.3055
2024-10-30 14:42:48: [2024-10-30 14:42:48] iter = 18950, loss = 2.9554
2024-10-30 14:42:48: [2024-10-30 14:42:48] iter = 18960, loss = 2.8120
2024-10-30 14:42:49: [2024-10-30 14:42:49] iter = 18970, loss = 2.2780
2024-10-30 14:42:50: [2024-10-30 14:42:50] iter = 18980, loss = 2.1729
2024-10-30 14:42:50: [2024-10-30 14:42:50] iter = 18990, loss = 6.3013
2024-10-30 14:42:51: [2024-10-30 14:42:51] iter = 19000, loss = 2.0948
2024-10-30 14:42:51: [2024-10-30 14:42:51] iter = 19010, loss = 3.9163
2024-10-30 14:42:52: [2024-10-30 14:42:52] iter = 19020, loss = 1.4318
2024-10-30 14:42:53: [2024-10-30 14:42:53] iter = 19030, loss = 5.6004
2024-10-30 14:42:53: [2024-10-30 14:42:53] iter = 19040, loss = 3.3071
2024-10-30 14:42:54: [2024-10-30 14:42:54] iter = 19050, loss = 6.7659
2024-10-30 14:42:54: [2024-10-30 14:42:54] iter = 19060, loss = 2.5945
2024-10-30 14:42:54: [2024-10-30 14:42:54] iter = 19070, loss = 4.4876
2024-10-30 14:42:55: [2024-10-30 14:42:55] iter = 19080, loss = 4.9940
2024-10-30 14:42:55: [2024-10-30 14:42:55] iter = 19090, loss = 2.1416
2024-10-30 14:42:56: [2024-10-30 14:42:56] iter = 19100, loss = 9.0461
2024-10-30 14:42:56: [2024-10-30 14:42:56] iter = 19110, loss = 2.2655
2024-10-30 14:42:57: [2024-10-30 14:42:57] iter = 19120, loss = 1.9008
2024-10-30 14:42:57: [2024-10-30 14:42:57] iter = 19130, loss = 1.8823
2024-10-30 14:42:57: [2024-10-30 14:42:57] iter = 19140, loss = 3.0101
2024-10-30 14:42:58: [2024-10-30 14:42:58] iter = 19150, loss = 16.9616
2024-10-30 14:42:58: [2024-10-30 14:42:58] iter = 19160, loss = 2.9131
2024-10-30 14:42:58: [2024-10-30 14:42:58] iter = 19170, loss = 1.3324
2024-10-30 14:42:59: [2024-10-30 14:42:59] iter = 19180, loss = 10.2779
2024-10-30 14:42:59: [2024-10-30 14:42:59] iter = 19190, loss = 1.7862
2024-10-30 14:42:59: [2024-10-30 14:42:59] iter = 19200, loss = 1.7857
2024-10-30 14:43:00: [2024-10-30 14:43:00] iter = 19210, loss = 4.1942
2024-10-30 14:43:00: [2024-10-30 14:43:00] iter = 19220, loss = 3.1712
2024-10-30 14:43:01: [2024-10-30 14:43:01] iter = 19230, loss = 3.5755
2024-10-30 14:43:01: [2024-10-30 14:43:01] iter = 19240, loss = 30.0604
2024-10-30 14:43:02: [2024-10-30 14:43:02] iter = 19250, loss = 2.3601
2024-10-30 14:43:02: [2024-10-30 14:43:02] iter = 19260, loss = 1.4502
2024-10-30 14:43:03: [2024-10-30 14:43:03] iter = 19270, loss = 5.0506
2024-10-30 14:43:03: [2024-10-30 14:43:03] iter = 19280, loss = 4.8260
2024-10-30 14:43:03: [2024-10-30 14:43:03] iter = 19290, loss = 3.5120
2024-10-30 14:43:04: [2024-10-30 14:43:04] iter = 19300, loss = 2.0050
2024-10-30 14:43:04: [2024-10-30 14:43:04] iter = 19310, loss = 28.7652
2024-10-30 14:43:05: [2024-10-30 14:43:05] iter = 19320, loss = 1.5300
2024-10-30 14:43:05: [2024-10-30 14:43:05] iter = 19330, loss = 4.4835
2024-10-30 14:43:05: [2024-10-30 14:43:05] iter = 19340, loss = 2.6255
2024-10-30 14:43:06: [2024-10-30 14:43:06] iter = 19350, loss = 2.3421
2024-10-30 14:43:06: [2024-10-30 14:43:06] iter = 19360, loss = 6.5047
2024-10-30 14:43:07: [2024-10-30 14:43:07] iter = 19370, loss = 2.2855
2024-10-30 14:43:08: [2024-10-30 14:43:08] iter = 19380, loss = 3.5948
2024-10-30 14:43:08: [2024-10-30 14:43:08] iter = 19390, loss = 2.1090
2024-10-30 14:43:09: [2024-10-30 14:43:09] iter = 19400, loss = 1.9247
2024-10-30 14:43:09: [2024-10-30 14:43:09] iter = 19410, loss = 2.1300
2024-10-30 14:43:10: [2024-10-30 14:43:10] iter = 19420, loss = 5.1632
2024-10-30 14:43:10: [2024-10-30 14:43:10] iter = 19430, loss = 1.2010
2024-10-30 14:43:10: [2024-10-30 14:43:10] iter = 19440, loss = 1.7729
2024-10-30 14:43:11: [2024-10-30 14:43:11] iter = 19450, loss = 4.5433
2024-10-30 14:43:11: [2024-10-30 14:43:11] iter = 19460, loss = 1.2875
2024-10-30 14:43:11: [2024-10-30 14:43:11] iter = 19470, loss = 4.5542
2024-10-30 14:43:12: [2024-10-30 14:43:12] iter = 19480, loss = 12.4936
2024-10-30 14:43:12: [2024-10-30 14:43:12] iter = 19490, loss = 4.3188
2024-10-30 14:43:13: [2024-10-30 14:43:13] iter = 19500, loss = 1.5150
2024-10-30 14:43:13: [2024-10-30 14:43:13] iter = 19510, loss = 2.9307
2024-10-30 14:43:13: [2024-10-30 14:43:13] iter = 19520, loss = 20.7257
2024-10-30 14:43:14: [2024-10-30 14:43:14] iter = 19530, loss = 2.5334
2024-10-30 14:43:14: [2024-10-30 14:43:14] iter = 19540, loss = 1.0710
2024-10-30 14:43:15: [2024-10-30 14:43:15] iter = 19550, loss = 3.2142
2024-10-30 14:43:15: [2024-10-30 14:43:15] iter = 19560, loss = 3.4941
2024-10-30 14:43:16: [2024-10-30 14:43:16] iter = 19570, loss = 3.9666
2024-10-30 14:43:16: [2024-10-30 14:43:16] iter = 19580, loss = 1.9456
2024-10-30 14:43:16: [2024-10-30 14:43:16] iter = 19590, loss = 19.0032
2024-10-30 14:43:17: [2024-10-30 14:43:17] iter = 19600, loss = 2.5274
2024-10-30 14:43:17: [2024-10-30 14:43:17] iter = 19610, loss = 2.0311
2024-10-30 14:43:18: [2024-10-30 14:43:18] iter = 19620, loss = 2.1398
2024-10-30 14:43:18: [2024-10-30 14:43:18] iter = 19630, loss = 8.0302
2024-10-30 14:43:18: [2024-10-30 14:43:18] iter = 19640, loss = 4.1923
2024-10-30 14:43:19: [2024-10-30 14:43:19] iter = 19650, loss = 1.9216
2024-10-30 14:43:19: [2024-10-30 14:43:19] iter = 19660, loss = 4.0935
2024-10-30 14:43:20: [2024-10-30 14:43:20] iter = 19670, loss = 1.6109
2024-10-30 14:43:20: [2024-10-30 14:43:20] iter = 19680, loss = 2.4262
2024-10-30 14:43:20: [2024-10-30 14:43:20] iter = 19690, loss = 1.2344
2024-10-30 14:43:21: [2024-10-30 14:43:21] iter = 19700, loss = 3.3947
2024-10-30 14:43:21: [2024-10-30 14:43:21] iter = 19710, loss = 6.3095
2024-10-30 14:43:22: [2024-10-30 14:43:22] iter = 19720, loss = 2.6926
2024-10-30 14:43:23: [2024-10-30 14:43:23] iter = 19730, loss = 1.2868
2024-10-30 14:43:23: [2024-10-30 14:43:23] iter = 19740, loss = 2.0496
2024-10-30 14:43:23: [2024-10-30 14:43:23] iter = 19750, loss = 4.1699
2024-10-30 14:43:24: [2024-10-30 14:43:24] iter = 19760, loss = 1.1690
2024-10-30 14:43:24: [2024-10-30 14:43:24] iter = 19770, loss = 1.4430
2024-10-30 14:43:25: [2024-10-30 14:43:25] iter = 19780, loss = 1.7005
2024-10-30 14:43:26: [2024-10-30 14:43:26] iter = 19790, loss = 2.1852
2024-10-30 14:43:26: [2024-10-30 14:43:26] iter = 19800, loss = 10.8392
2024-10-30 14:43:26: [2024-10-30 14:43:26] iter = 19810, loss = 3.5425
2024-10-30 14:43:27: [2024-10-30 14:43:27] iter = 19820, loss = 1.9825
2024-10-30 14:43:27: [2024-10-30 14:43:27] iter = 19830, loss = 1.9351
2024-10-30 14:43:28: [2024-10-30 14:43:28] iter = 19840, loss = 2.4986
2024-10-30 14:43:28: [2024-10-30 14:43:28] iter = 19850, loss = 3.5389
2024-10-30 14:43:28: [2024-10-30 14:43:28] iter = 19860, loss = 1.3229
2024-10-30 14:43:29: [2024-10-30 14:43:29] iter = 19870, loss = 1.5423
2024-10-30 14:43:29: [2024-10-30 14:43:29] iter = 19880, loss = 2.3002
2024-10-30 14:43:30: [2024-10-30 14:43:30] iter = 19890, loss = 1.2916
2024-10-30 14:43:30: [2024-10-30 14:43:30] iter = 19900, loss = 1.2936
2024-10-30 14:43:31: [2024-10-30 14:43:31] iter = 19910, loss = 1.6115
2024-10-30 14:43:31: [2024-10-30 14:43:31] iter = 19920, loss = 1.4555
2024-10-30 14:43:32: [2024-10-30 14:43:32] iter = 19930, loss = 8.8960
2024-10-30 14:43:32: [2024-10-30 14:43:32] iter = 19940, loss = 1.5614
2024-10-30 14:43:33: [2024-10-30 14:43:33] iter = 19950, loss = 2.5248
2024-10-30 14:43:33: [2024-10-30 14:43:33] iter = 19960, loss = 7.9697
2024-10-30 14:43:34: [2024-10-30 14:43:34] iter = 19970, loss = 1.4808
2024-10-30 14:43:34: [2024-10-30 14:43:34] iter = 19980, loss = 2.7025
2024-10-30 14:43:34: [2024-10-30 14:43:34] iter = 19990, loss = 1.7426
2024-10-30 14:43:35: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 14:43:35: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:43:35: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 15276}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:44:17: Evaluate 5 random ConvNet, ACCmean = 0.7859 ACCstd = 0.0104
-------------------------
2024-10-30 14:44:17: Evaluate 5 random ConvNet, SENmean = 0.6881 SENstd = 0.0207
-------------------------
2024-10-30 14:44:17: Evaluate 5 random ConvNet, SPEmean = 0.6881 SPEstd = 0.0207
-------------------------
2024-10-30 14:44:17: Evaluate 5 random ConvNet, F!mean = 0.7018 F!std = 0.0188
-------------------------
2024-10-30 14:44:17: Evaluate 5 random ConvNet, mean = 0.7859 std = 0.0104
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:44:17: [2024-10-30 14:44:17] iter = 20000, loss = 3.3509
2024-10-30 14:44:17: 
================== Exp 1 ==================
 
2024-10-30 14:44:17: Hyper-parameters: 
{'dataset': 'BreastMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ff878e0ab20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_BreastMNIST (INFO)>}
2024-10-30 14:44:17: Evaluation model pool: ['ConvNet']
2024-10-30 14:44:17: class c = 0: 147 real images
2024-10-30 14:44:17: class c = 1: 399 real images
2024-10-30 14:44:17: real images channel 0, mean = 0.3276, std = 0.2057
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 14:44:17: initialize synthetic data from random real images
2024-10-30 14:44:17: [2024-10-30 14:44:17] training begins
2024-10-30 14:44:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 14:44:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:44:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57221}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:44:56: Evaluate 5 random ConvNet, ACCmean = 0.6462 ACCstd = 0.0245
-------------------------
2024-10-30 14:44:56: Evaluate 5 random ConvNet, SENmean = 0.6271 SENstd = 0.0290
-------------------------
2024-10-30 14:44:56: Evaluate 5 random ConvNet, SPEmean = 0.6271 SPEstd = 0.0290
-------------------------
2024-10-30 14:44:56: Evaluate 5 random ConvNet, F!mean = 0.6025 F!std = 0.0257
-------------------------
2024-10-30 14:44:56: Evaluate 5 random ConvNet, mean = 0.6462 std = 0.0245
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:44:56: [2024-10-30 14:44:56] iter = 00000, loss = 9.4039
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:44:57: [2024-10-30 14:44:57] iter = 00010, loss = 20.3639
2024-10-30 14:44:57: [2024-10-30 14:44:57] iter = 00020, loss = 4.3759
2024-10-30 14:44:58: [2024-10-30 14:44:58] iter = 00030, loss = 5.5703
2024-10-30 14:44:58: [2024-10-30 14:44:58] iter = 00040, loss = 1.9039
2024-10-30 14:44:59: [2024-10-30 14:44:59] iter = 00050, loss = 2.3156
2024-10-30 14:44:59: [2024-10-30 14:44:59] iter = 00060, loss = 1.5849
2024-10-30 14:44:59: [2024-10-30 14:44:59] iter = 00070, loss = 2.7987
2024-10-30 14:45:00: [2024-10-30 14:45:00] iter = 00080, loss = 2.4638
2024-10-30 14:45:00: [2024-10-30 14:45:00] iter = 00090, loss = 1.3709
2024-10-30 14:45:00: [2024-10-30 14:45:00] iter = 00100, loss = 6.1509
2024-10-30 14:45:01: [2024-10-30 14:45:01] iter = 00110, loss = 1.5782
2024-10-30 14:45:01: [2024-10-30 14:45:01] iter = 00120, loss = 2.9292
2024-10-30 14:45:02: [2024-10-30 14:45:02] iter = 00130, loss = 4.1054
2024-10-30 14:45:02: [2024-10-30 14:45:02] iter = 00140, loss = 2.3136
2024-10-30 14:45:02: [2024-10-30 14:45:02] iter = 00150, loss = 11.6227
2024-10-30 14:45:03: [2024-10-30 14:45:03] iter = 00160, loss = 2.9006
2024-10-30 14:45:03: [2024-10-30 14:45:03] iter = 00170, loss = 2.2595
2024-10-30 14:45:03: [2024-10-30 14:45:03] iter = 00180, loss = 1.4316
2024-10-30 14:45:04: [2024-10-30 14:45:04] iter = 00190, loss = 1.2850
2024-10-30 14:45:04: [2024-10-30 14:45:04] iter = 00200, loss = 1.5251
2024-10-30 14:45:04: [2024-10-30 14:45:04] iter = 00210, loss = 1.6047
2024-10-30 14:45:05: [2024-10-30 14:45:05] iter = 00220, loss = 1.6023
2024-10-30 14:45:05: [2024-10-30 14:45:05] iter = 00230, loss = 11.5006
2024-10-30 14:45:06: [2024-10-30 14:45:06] iter = 00240, loss = 1.9950
2024-10-30 14:45:06: [2024-10-30 14:45:06] iter = 00250, loss = 3.3991
2024-10-30 14:45:06: [2024-10-30 14:45:06] iter = 00260, loss = 3.4053
2024-10-30 14:45:07: [2024-10-30 14:45:07] iter = 00270, loss = 1.7892
2024-10-30 14:45:07: [2024-10-30 14:45:07] iter = 00280, loss = 12.0422
2024-10-30 14:45:08: [2024-10-30 14:45:08] iter = 00290, loss = 7.3161
2024-10-30 14:45:08: [2024-10-30 14:45:08] iter = 00300, loss = 2.5114
2024-10-30 14:45:08: [2024-10-30 14:45:08] iter = 00310, loss = 2.2953
2024-10-30 14:45:09: [2024-10-30 14:45:09] iter = 00320, loss = 1.4270
2024-10-30 14:45:09: [2024-10-30 14:45:09] iter = 00330, loss = 1.5187
2024-10-30 14:45:09: [2024-10-30 14:45:09] iter = 00340, loss = 2.3671
2024-10-30 14:45:10: [2024-10-30 14:45:10] iter = 00350, loss = 3.8699
2024-10-30 14:45:10: [2024-10-30 14:45:10] iter = 00360, loss = 4.8369
2024-10-30 14:45:10: [2024-10-30 14:45:10] iter = 00370, loss = 2.0774
2024-10-30 14:45:11: [2024-10-30 14:45:11] iter = 00380, loss = 3.1521
2024-10-30 14:45:11: [2024-10-30 14:45:11] iter = 00390, loss = 2.3316
2024-10-30 14:45:11: [2024-10-30 14:45:11] iter = 00400, loss = 6.6248
2024-10-30 14:45:12: [2024-10-30 14:45:12] iter = 00410, loss = 16.8778
2024-10-30 14:45:12: [2024-10-30 14:45:12] iter = 00420, loss = 5.0908
2024-10-30 14:45:12: [2024-10-30 14:45:12] iter = 00430, loss = 2.5266
2024-10-30 14:45:12: [2024-10-30 14:45:12] iter = 00440, loss = 4.6988
2024-10-30 14:45:13: [2024-10-30 14:45:13] iter = 00450, loss = 19.9126
2024-10-30 14:45:13: [2024-10-30 14:45:13] iter = 00460, loss = 3.2826
2024-10-30 14:45:14: [2024-10-30 14:45:14] iter = 00470, loss = 9.4811
2024-10-30 14:45:14: [2024-10-30 14:45:14] iter = 00480, loss = 4.3299
2024-10-30 14:45:15: [2024-10-30 14:45:15] iter = 00490, loss = 2.7782
2024-10-30 14:45:15: [2024-10-30 14:45:15] iter = 00500, loss = 2.7958
2024-10-30 14:45:15: [2024-10-30 14:45:15] iter = 00510, loss = 1.5712
2024-10-30 14:45:16: [2024-10-30 14:45:16] iter = 00520, loss = 5.1728
2024-10-30 14:45:16: [2024-10-30 14:45:16] iter = 00530, loss = 3.5301
2024-10-30 14:45:17: [2024-10-30 14:45:17] iter = 00540, loss = 1.5335
2024-10-30 14:45:17: [2024-10-30 14:45:17] iter = 00550, loss = 2.9322
2024-10-30 14:45:18: [2024-10-30 14:45:18] iter = 00560, loss = 6.1484
2024-10-30 14:45:18: [2024-10-30 14:45:18] iter = 00570, loss = 3.4052
2024-10-30 14:45:18: [2024-10-30 14:45:18] iter = 00580, loss = 7.5789
2024-10-30 14:45:19: [2024-10-30 14:45:19] iter = 00590, loss = 3.8538
2024-10-30 14:45:19: [2024-10-30 14:45:19] iter = 00600, loss = 1.8932
2024-10-30 14:45:20: [2024-10-30 14:45:20] iter = 00610, loss = 2.1651
2024-10-30 14:45:21: [2024-10-30 14:45:21] iter = 00620, loss = 4.1007
2024-10-30 14:45:21: [2024-10-30 14:45:21] iter = 00630, loss = 7.8653
2024-10-30 14:45:21: [2024-10-30 14:45:21] iter = 00640, loss = 4.7152
2024-10-30 14:45:22: [2024-10-30 14:45:22] iter = 00650, loss = 5.4305
2024-10-30 14:45:23: [2024-10-30 14:45:23] iter = 00660, loss = 1.8360
2024-10-30 14:45:23: [2024-10-30 14:45:23] iter = 00670, loss = 10.0199
2024-10-30 14:45:24: [2024-10-30 14:45:24] iter = 00680, loss = 3.3032
2024-10-30 14:45:24: [2024-10-30 14:45:24] iter = 00690, loss = 2.1353
2024-10-30 14:45:25: [2024-10-30 14:45:25] iter = 00700, loss = 8.7414
2024-10-30 14:45:25: [2024-10-30 14:45:25] iter = 00710, loss = 4.7540
2024-10-30 14:45:25: [2024-10-30 14:45:25] iter = 00720, loss = 2.0526
2024-10-30 14:45:25: [2024-10-30 14:45:25] iter = 00730, loss = 4.1965
2024-10-30 14:45:26: [2024-10-30 14:45:26] iter = 00740, loss = 3.3633
2024-10-30 14:45:26: [2024-10-30 14:45:26] iter = 00750, loss = 6.5349
2024-10-30 14:45:27: [2024-10-30 14:45:27] iter = 00760, loss = 13.8788
2024-10-30 14:45:27: [2024-10-30 14:45:27] iter = 00770, loss = 1.6984
2024-10-30 14:45:28: [2024-10-30 14:45:28] iter = 00780, loss = 11.3184
2024-10-30 14:45:28: [2024-10-30 14:45:28] iter = 00790, loss = 2.7328
2024-10-30 14:45:28: [2024-10-30 14:45:28] iter = 00800, loss = 21.7351
2024-10-30 14:45:29: [2024-10-30 14:45:29] iter = 00810, loss = 1.8798
2024-10-30 14:45:29: [2024-10-30 14:45:29] iter = 00820, loss = 2.9113
2024-10-30 14:45:30: [2024-10-30 14:45:30] iter = 00830, loss = 1.5766
2024-10-30 14:45:30: [2024-10-30 14:45:30] iter = 00840, loss = 1.4845
2024-10-30 14:45:31: [2024-10-30 14:45:31] iter = 00850, loss = 2.2241
2024-10-30 14:45:31: [2024-10-30 14:45:31] iter = 00860, loss = 2.0301
2024-10-30 14:45:31: [2024-10-30 14:45:31] iter = 00870, loss = 2.1280
2024-10-30 14:45:32: [2024-10-30 14:45:32] iter = 00880, loss = 3.8259
2024-10-30 14:45:32: [2024-10-30 14:45:32] iter = 00890, loss = 20.1163
2024-10-30 14:45:33: [2024-10-30 14:45:33] iter = 00900, loss = 8.4162
2024-10-30 14:45:33: [2024-10-30 14:45:33] iter = 00910, loss = 1.7515
2024-10-30 14:45:34: [2024-10-30 14:45:34] iter = 00920, loss = 4.9490
2024-10-30 14:45:34: [2024-10-30 14:45:34] iter = 00930, loss = 5.5635
2024-10-30 14:45:35: [2024-10-30 14:45:35] iter = 00940, loss = 7.9402
2024-10-30 14:45:35: [2024-10-30 14:45:35] iter = 00950, loss = 2.8953
2024-10-30 14:45:36: [2024-10-30 14:45:36] iter = 00960, loss = 8.2685
2024-10-30 14:45:37: [2024-10-30 14:45:37] iter = 00970, loss = 1.3507
2024-10-30 14:45:37: [2024-10-30 14:45:37] iter = 00980, loss = 2.3220
2024-10-30 14:45:38: [2024-10-30 14:45:38] iter = 00990, loss = 1.7126
2024-10-30 14:45:39: [2024-10-30 14:45:39] iter = 01000, loss = 1.2446
2024-10-30 14:45:39: [2024-10-30 14:45:39] iter = 01010, loss = 2.5836
2024-10-30 14:45:40: [2024-10-30 14:45:40] iter = 01020, loss = 3.9856
2024-10-30 14:45:40: [2024-10-30 14:45:40] iter = 01030, loss = 4.3592
2024-10-30 14:45:41: [2024-10-30 14:45:41] iter = 01040, loss = 6.8326
2024-10-30 14:45:41: [2024-10-30 14:45:41] iter = 01050, loss = 11.1410
2024-10-30 14:45:42: [2024-10-30 14:45:42] iter = 01060, loss = 6.4532
2024-10-30 14:45:42: [2024-10-30 14:45:42] iter = 01070, loss = 4.0660
2024-10-30 14:45:43: [2024-10-30 14:45:43] iter = 01080, loss = 11.2470
2024-10-30 14:45:43: [2024-10-30 14:45:43] iter = 01090, loss = 2.3762
2024-10-30 14:45:44: [2024-10-30 14:45:44] iter = 01100, loss = 1.2211
2024-10-30 14:45:44: [2024-10-30 14:45:44] iter = 01110, loss = 3.8368
2024-10-30 14:45:44: [2024-10-30 14:45:44] iter = 01120, loss = 17.1740
2024-10-30 14:45:45: [2024-10-30 14:45:45] iter = 01130, loss = 2.8149
2024-10-30 14:45:45: [2024-10-30 14:45:45] iter = 01140, loss = 2.7493
2024-10-30 14:45:46: [2024-10-30 14:45:46] iter = 01150, loss = 1.6018
2024-10-30 14:45:46: [2024-10-30 14:45:46] iter = 01160, loss = 9.7222
2024-10-30 14:45:47: [2024-10-30 14:45:47] iter = 01170, loss = 8.3293
2024-10-30 14:45:47: [2024-10-30 14:45:47] iter = 01180, loss = 2.6993
2024-10-30 14:45:47: [2024-10-30 14:45:47] iter = 01190, loss = 2.9872
2024-10-30 14:45:48: [2024-10-30 14:45:48] iter = 01200, loss = 3.7361
2024-10-30 14:45:48: [2024-10-30 14:45:48] iter = 01210, loss = 1.9268
2024-10-30 14:45:49: [2024-10-30 14:45:49] iter = 01220, loss = 1.8073
2024-10-30 14:45:49: [2024-10-30 14:45:49] iter = 01230, loss = 2.4156
2024-10-30 14:45:50: [2024-10-30 14:45:50] iter = 01240, loss = 1.8110
2024-10-30 14:45:50: [2024-10-30 14:45:50] iter = 01250, loss = 2.0888
2024-10-30 14:45:50: [2024-10-30 14:45:50] iter = 01260, loss = 1.5632
2024-10-30 14:45:51: [2024-10-30 14:45:51] iter = 01270, loss = 13.9437
2024-10-30 14:45:51: [2024-10-30 14:45:51] iter = 01280, loss = 2.0087
2024-10-30 14:45:52: [2024-10-30 14:45:52] iter = 01290, loss = 2.8678
2024-10-30 14:45:52: [2024-10-30 14:45:52] iter = 01300, loss = 2.1246
2024-10-30 14:45:53: [2024-10-30 14:45:53] iter = 01310, loss = 3.2754
2024-10-30 14:45:53: [2024-10-30 14:45:53] iter = 01320, loss = 14.4052
2024-10-30 14:45:53: [2024-10-30 14:45:53] iter = 01330, loss = 3.9354
2024-10-30 14:45:54: [2024-10-30 14:45:54] iter = 01340, loss = 6.3076
2024-10-30 14:45:54: [2024-10-30 14:45:54] iter = 01350, loss = 16.2864
2024-10-30 14:45:55: [2024-10-30 14:45:55] iter = 01360, loss = 3.3346
2024-10-30 14:45:55: [2024-10-30 14:45:55] iter = 01370, loss = 2.3059
2024-10-30 14:45:55: [2024-10-30 14:45:55] iter = 01380, loss = 16.4578
2024-10-30 14:45:56: [2024-10-30 14:45:56] iter = 01390, loss = 3.0991
2024-10-30 14:45:56: [2024-10-30 14:45:56] iter = 01400, loss = 1.9029
2024-10-30 14:45:57: [2024-10-30 14:45:57] iter = 01410, loss = 2.0118
2024-10-30 14:45:58: [2024-10-30 14:45:58] iter = 01420, loss = 3.2229
2024-10-30 14:45:58: [2024-10-30 14:45:58] iter = 01430, loss = 4.3110
2024-10-30 14:45:59: [2024-10-30 14:45:59] iter = 01440, loss = 2.0249
2024-10-30 14:45:59: [2024-10-30 14:45:59] iter = 01450, loss = 2.4791
2024-10-30 14:46:00: [2024-10-30 14:46:00] iter = 01460, loss = 1.3125
2024-10-30 14:46:00: [2024-10-30 14:46:00] iter = 01470, loss = 2.0024
2024-10-30 14:46:01: [2024-10-30 14:46:01] iter = 01480, loss = 31.2707
2024-10-30 14:46:01: [2024-10-30 14:46:01] iter = 01490, loss = 1.8381
2024-10-30 14:46:02: [2024-10-30 14:46:02] iter = 01500, loss = 3.2633
2024-10-30 14:46:02: [2024-10-30 14:46:02] iter = 01510, loss = 4.6777
2024-10-30 14:46:02: [2024-10-30 14:46:02] iter = 01520, loss = 2.0879
2024-10-30 14:46:03: [2024-10-30 14:46:03] iter = 01530, loss = 28.0124
2024-10-30 14:46:03: [2024-10-30 14:46:03] iter = 01540, loss = 1.5612
2024-10-30 14:46:04: [2024-10-30 14:46:04] iter = 01550, loss = 4.4420
2024-10-30 14:46:04: [2024-10-30 14:46:04] iter = 01560, loss = 3.1816
2024-10-30 14:46:05: [2024-10-30 14:46:05] iter = 01570, loss = 1.9152
2024-10-30 14:46:05: [2024-10-30 14:46:05] iter = 01580, loss = 2.2118
2024-10-30 14:46:06: [2024-10-30 14:46:06] iter = 01590, loss = 4.1202
2024-10-30 14:46:06: [2024-10-30 14:46:06] iter = 01600, loss = 2.3643
2024-10-30 14:46:06: [2024-10-30 14:46:06] iter = 01610, loss = 3.6663
2024-10-30 14:46:07: [2024-10-30 14:46:07] iter = 01620, loss = 11.4172
2024-10-30 14:46:07: [2024-10-30 14:46:07] iter = 01630, loss = 1.5802
2024-10-30 14:46:08: [2024-10-30 14:46:08] iter = 01640, loss = 1.6041
2024-10-30 14:46:08: [2024-10-30 14:46:08] iter = 01650, loss = 16.4544
2024-10-30 14:46:09: [2024-10-30 14:46:09] iter = 01660, loss = 2.2501
2024-10-30 14:46:09: [2024-10-30 14:46:09] iter = 01670, loss = 2.4242
2024-10-30 14:46:09: [2024-10-30 14:46:09] iter = 01680, loss = 2.0573
2024-10-30 14:46:10: [2024-10-30 14:46:10] iter = 01690, loss = 1.6721
2024-10-30 14:46:10: [2024-10-30 14:46:10] iter = 01700, loss = 3.0535
2024-10-30 14:46:11: [2024-10-30 14:46:11] iter = 01710, loss = 8.9339
2024-10-30 14:46:11: [2024-10-30 14:46:11] iter = 01720, loss = 3.2778
2024-10-30 14:46:11: [2024-10-30 14:46:11] iter = 01730, loss = 2.3408
2024-10-30 14:46:12: [2024-10-30 14:46:12] iter = 01740, loss = 1.4836
2024-10-30 14:46:12: [2024-10-30 14:46:12] iter = 01750, loss = 1.8270
2024-10-30 14:46:13: [2024-10-30 14:46:13] iter = 01760, loss = 1.2411
2024-10-30 14:46:13: [2024-10-30 14:46:13] iter = 01770, loss = 3.9161
2024-10-30 14:46:14: [2024-10-30 14:46:14] iter = 01780, loss = 6.8988
2024-10-30 14:46:14: [2024-10-30 14:46:14] iter = 01790, loss = 1.5131
2024-10-30 14:46:15: [2024-10-30 14:46:15] iter = 01800, loss = 5.6260
2024-10-30 14:46:15: [2024-10-30 14:46:15] iter = 01810, loss = 11.3837
2024-10-30 14:46:15: [2024-10-30 14:46:15] iter = 01820, loss = 1.2682
2024-10-30 14:46:16: [2024-10-30 14:46:16] iter = 01830, loss = 1.2685
2024-10-30 14:46:16: [2024-10-30 14:46:16] iter = 01840, loss = 1.4124
2024-10-30 14:46:17: [2024-10-30 14:46:17] iter = 01850, loss = 4.4181
2024-10-30 14:46:17: [2024-10-30 14:46:17] iter = 01860, loss = 2.2261
2024-10-30 14:46:17: [2024-10-30 14:46:17] iter = 01870, loss = 1.7070
2024-10-30 14:46:18: [2024-10-30 14:46:18] iter = 01880, loss = 1.7443
2024-10-30 14:46:18: [2024-10-30 14:46:18] iter = 01890, loss = 4.6352
2024-10-30 14:46:19: [2024-10-30 14:46:19] iter = 01900, loss = 3.0793
2024-10-30 14:46:19: [2024-10-30 14:46:19] iter = 01910, loss = 4.2437
2024-10-30 14:46:20: [2024-10-30 14:46:20] iter = 01920, loss = 2.0207
2024-10-30 14:46:21: [2024-10-30 14:46:21] iter = 01930, loss = 1.4216
2024-10-30 14:46:21: [2024-10-30 14:46:21] iter = 01940, loss = 4.4075
2024-10-30 14:46:21: [2024-10-30 14:46:21] iter = 01950, loss = 1.8806
2024-10-30 14:46:22: [2024-10-30 14:46:22] iter = 01960, loss = 2.5108
2024-10-30 14:46:22: [2024-10-30 14:46:22] iter = 01970, loss = 1.5959
2024-10-30 14:46:23: [2024-10-30 14:46:23] iter = 01980, loss = 2.1420
2024-10-30 14:46:23: [2024-10-30 14:46:23] iter = 01990, loss = 5.3621
2024-10-30 14:46:23: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 14:46:23: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:46:23: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 83904}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:47:03: Evaluate 5 random ConvNet, ACCmean = 0.5192 ACCstd = 0.0190
-------------------------
2024-10-30 14:47:03: Evaluate 5 random ConvNet, SENmean = 0.6259 SENstd = 0.0163
-------------------------
2024-10-30 14:47:03: Evaluate 5 random ConvNet, SPEmean = 0.6259 SPEstd = 0.0163
-------------------------
2024-10-30 14:47:03: Evaluate 5 random ConvNet, F!mean = 0.5175 F!std = 0.0183
-------------------------
2024-10-30 14:47:03: Evaluate 5 random ConvNet, mean = 0.5192 std = 0.0190
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:47:03: [2024-10-30 14:47:03] iter = 02000, loss = 5.9666
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:47:04: [2024-10-30 14:47:04] iter = 02010, loss = 3.2207
2024-10-30 14:47:04: [2024-10-30 14:47:04] iter = 02020, loss = 2.4711
2024-10-30 14:47:04: [2024-10-30 14:47:04] iter = 02030, loss = 1.5959
2024-10-30 14:47:05: [2024-10-30 14:47:05] iter = 02040, loss = 2.1955
2024-10-30 14:47:05: [2024-10-30 14:47:05] iter = 02050, loss = 2.3733
2024-10-30 14:47:05: [2024-10-30 14:47:05] iter = 02060, loss = 7.0606
2024-10-30 14:47:06: [2024-10-30 14:47:06] iter = 02070, loss = 1.5312
2024-10-30 14:47:06: [2024-10-30 14:47:06] iter = 02080, loss = 2.4400
2024-10-30 14:47:07: [2024-10-30 14:47:07] iter = 02090, loss = 24.0059
2024-10-30 14:47:07: [2024-10-30 14:47:07] iter = 02100, loss = 2.5148
2024-10-30 14:47:07: [2024-10-30 14:47:07] iter = 02110, loss = 2.6782
2024-10-30 14:47:08: [2024-10-30 14:47:08] iter = 02120, loss = 1.2532
2024-10-30 14:47:08: [2024-10-30 14:47:08] iter = 02130, loss = 14.3897
2024-10-30 14:47:09: [2024-10-30 14:47:09] iter = 02140, loss = 5.1773
2024-10-30 14:47:09: [2024-10-30 14:47:09] iter = 02150, loss = 6.2641
2024-10-30 14:47:10: [2024-10-30 14:47:10] iter = 02160, loss = 1.3288
2024-10-30 14:47:10: [2024-10-30 14:47:10] iter = 02170, loss = 7.6987
2024-10-30 14:47:10: [2024-10-30 14:47:10] iter = 02180, loss = 3.3265
2024-10-30 14:47:11: [2024-10-30 14:47:11] iter = 02190, loss = 2.4208
2024-10-30 14:47:11: [2024-10-30 14:47:11] iter = 02200, loss = 2.2645
2024-10-30 14:47:12: [2024-10-30 14:47:12] iter = 02210, loss = 2.0793
2024-10-30 14:47:12: [2024-10-30 14:47:12] iter = 02220, loss = 1.9678
2024-10-30 14:47:13: [2024-10-30 14:47:13] iter = 02230, loss = 1.6793
2024-10-30 14:47:13: [2024-10-30 14:47:13] iter = 02240, loss = 2.1912
2024-10-30 14:47:14: [2024-10-30 14:47:14] iter = 02250, loss = 1.1259
2024-10-30 14:47:14: [2024-10-30 14:47:14] iter = 02260, loss = 2.1681
2024-10-30 14:47:15: [2024-10-30 14:47:15] iter = 02270, loss = 10.4994
2024-10-30 14:47:15: [2024-10-30 14:47:15] iter = 02280, loss = 2.1585
2024-10-30 14:47:16: [2024-10-30 14:47:15] iter = 02290, loss = 1.4375
2024-10-30 14:47:16: [2024-10-30 14:47:16] iter = 02300, loss = 1.3461
2024-10-30 14:47:16: [2024-10-30 14:47:16] iter = 02310, loss = 1.4206
2024-10-30 14:47:17: [2024-10-30 14:47:17] iter = 02320, loss = 4.1584
2024-10-30 14:47:17: [2024-10-30 14:47:17] iter = 02330, loss = 2.6257
2024-10-30 14:47:18: [2024-10-30 14:47:17] iter = 02340, loss = 8.0901
2024-10-30 14:47:18: [2024-10-30 14:47:18] iter = 02350, loss = 1.8501
2024-10-30 14:47:18: [2024-10-30 14:47:18] iter = 02360, loss = 7.1464
2024-10-30 14:47:19: [2024-10-30 14:47:19] iter = 02370, loss = 2.7304
2024-10-30 14:47:19: [2024-10-30 14:47:19] iter = 02380, loss = 1.8127
2024-10-30 14:47:20: [2024-10-30 14:47:20] iter = 02390, loss = 7.0140
2024-10-30 14:47:20: [2024-10-30 14:47:20] iter = 02400, loss = 4.0526
2024-10-30 14:47:20: [2024-10-30 14:47:20] iter = 02410, loss = 2.2620
2024-10-30 14:47:21: [2024-10-30 14:47:21] iter = 02420, loss = 1.2405
2024-10-30 14:47:21: [2024-10-30 14:47:21] iter = 02430, loss = 2.9052
2024-10-30 14:47:22: [2024-10-30 14:47:22] iter = 02440, loss = 2.1428
2024-10-30 14:47:22: [2024-10-30 14:47:22] iter = 02450, loss = 1.0529
2024-10-30 14:47:23: [2024-10-30 14:47:23] iter = 02460, loss = 5.0737
2024-10-30 14:47:23: [2024-10-30 14:47:23] iter = 02470, loss = 2.0999
2024-10-30 14:47:24: [2024-10-30 14:47:24] iter = 02480, loss = 9.0332
2024-10-30 14:47:24: [2024-10-30 14:47:24] iter = 02490, loss = 5.1431
2024-10-30 14:47:24: [2024-10-30 14:47:24] iter = 02500, loss = 1.6484
2024-10-30 14:47:25: [2024-10-30 14:47:25] iter = 02510, loss = 3.1981
2024-10-30 14:47:25: [2024-10-30 14:47:25] iter = 02520, loss = 4.4632
2024-10-30 14:47:26: [2024-10-30 14:47:26] iter = 02530, loss = 3.3803
2024-10-30 14:47:27: [2024-10-30 14:47:27] iter = 02540, loss = 10.8082
2024-10-30 14:47:27: [2024-10-30 14:47:27] iter = 02550, loss = 3.1082
2024-10-30 14:47:28: [2024-10-30 14:47:28] iter = 02560, loss = 3.4432
2024-10-30 14:47:28: [2024-10-30 14:47:28] iter = 02570, loss = 2.1889
2024-10-30 14:47:29: [2024-10-30 14:47:29] iter = 02580, loss = 1.7627
2024-10-30 14:47:29: [2024-10-30 14:47:29] iter = 02590, loss = 7.1242
2024-10-30 14:47:29: [2024-10-30 14:47:29] iter = 02600, loss = 2.3275
2024-10-30 14:47:30: [2024-10-30 14:47:30] iter = 02610, loss = 3.9232
2024-10-30 14:47:30: [2024-10-30 14:47:30] iter = 02620, loss = 18.3781
2024-10-30 14:47:31: [2024-10-30 14:47:31] iter = 02630, loss = 2.1636
2024-10-30 14:47:31: [2024-10-30 14:47:31] iter = 02640, loss = 4.8033
2024-10-30 14:47:32: [2024-10-30 14:47:32] iter = 02650, loss = 5.8659
2024-10-30 14:47:32: [2024-10-30 14:47:32] iter = 02660, loss = 1.8263
2024-10-30 14:47:32: [2024-10-30 14:47:32] iter = 02670, loss = 1.8915
2024-10-30 14:47:33: [2024-10-30 14:47:33] iter = 02680, loss = 20.9877
2024-10-30 14:47:33: [2024-10-30 14:47:33] iter = 02690, loss = 3.8242
2024-10-30 14:47:34: [2024-10-30 14:47:34] iter = 02700, loss = 1.4113
2024-10-30 14:47:34: [2024-10-30 14:47:34] iter = 02710, loss = 1.4180
2024-10-30 14:47:34: [2024-10-30 14:47:34] iter = 02720, loss = 3.2695
2024-10-30 14:47:35: [2024-10-30 14:47:35] iter = 02730, loss = 4.5360
2024-10-30 14:47:35: [2024-10-30 14:47:35] iter = 02740, loss = 1.6015
2024-10-30 14:47:36: [2024-10-30 14:47:36] iter = 02750, loss = 4.0678
2024-10-30 14:47:36: [2024-10-30 14:47:36] iter = 02760, loss = 1.5294
2024-10-30 14:47:36: [2024-10-30 14:47:36] iter = 02770, loss = 3.2694
2024-10-30 14:47:37: [2024-10-30 14:47:37] iter = 02780, loss = 2.0877
2024-10-30 14:47:37: [2024-10-30 14:47:37] iter = 02790, loss = 4.0429
2024-10-30 14:47:38: [2024-10-30 14:47:38] iter = 02800, loss = 6.1239
2024-10-30 14:47:38: [2024-10-30 14:47:38] iter = 02810, loss = 1.3119
2024-10-30 14:47:38: [2024-10-30 14:47:38] iter = 02820, loss = 2.4493
2024-10-30 14:47:38: [2024-10-30 14:47:38] iter = 02830, loss = 1.7344
2024-10-30 14:47:39: [2024-10-30 14:47:39] iter = 02840, loss = 15.7074
2024-10-30 14:47:39: [2024-10-30 14:47:39] iter = 02850, loss = 1.9303
2024-10-30 14:47:39: [2024-10-30 14:47:39] iter = 02860, loss = 1.8830
2024-10-30 14:47:40: [2024-10-30 14:47:40] iter = 02870, loss = 1.4292
2024-10-30 14:47:40: [2024-10-30 14:47:40] iter = 02880, loss = 1.2929
2024-10-30 14:47:40: [2024-10-30 14:47:40] iter = 02890, loss = 12.5615
2024-10-30 14:47:41: [2024-10-30 14:47:41] iter = 02900, loss = 4.1095
2024-10-30 14:47:41: [2024-10-30 14:47:41] iter = 02910, loss = 6.3434
2024-10-30 14:47:41: [2024-10-30 14:47:41] iter = 02920, loss = 26.0585
2024-10-30 14:47:42: [2024-10-30 14:47:42] iter = 02930, loss = 4.1728
2024-10-30 14:47:42: [2024-10-30 14:47:42] iter = 02940, loss = 11.6552
2024-10-30 14:47:42: [2024-10-30 14:47:42] iter = 02950, loss = 12.6648
2024-10-30 14:47:42: [2024-10-30 14:47:42] iter = 02960, loss = 13.3043
2024-10-30 14:47:43: [2024-10-30 14:47:43] iter = 02970, loss = 1.5899
2024-10-30 14:47:43: [2024-10-30 14:47:43] iter = 02980, loss = 2.8597
2024-10-30 14:47:44: [2024-10-30 14:47:44] iter = 02990, loss = 2.5589
2024-10-30 14:47:44: [2024-10-30 14:47:44] iter = 03000, loss = 7.9084
2024-10-30 14:47:45: [2024-10-30 14:47:44] iter = 03010, loss = 3.6690
2024-10-30 14:47:45: [2024-10-30 14:47:45] iter = 03020, loss = 1.8891
2024-10-30 14:47:45: [2024-10-30 14:47:45] iter = 03030, loss = 2.6803
2024-10-30 14:47:46: [2024-10-30 14:47:46] iter = 03040, loss = 1.4201
2024-10-30 14:47:46: [2024-10-30 14:47:46] iter = 03050, loss = 1.5044
2024-10-30 14:47:47: [2024-10-30 14:47:47] iter = 03060, loss = 13.3585
2024-10-30 14:47:47: [2024-10-30 14:47:47] iter = 03070, loss = 5.3720
2024-10-30 14:47:48: [2024-10-30 14:47:48] iter = 03080, loss = 4.6200
2024-10-30 14:47:48: [2024-10-30 14:47:48] iter = 03090, loss = 1.5205
2024-10-30 14:47:49: [2024-10-30 14:47:49] iter = 03100, loss = 1.1942
2024-10-30 14:47:49: [2024-10-30 14:47:49] iter = 03110, loss = 1.4830
2024-10-30 14:47:50: [2024-10-30 14:47:50] iter = 03120, loss = 1.4491
2024-10-30 14:47:50: [2024-10-30 14:47:50] iter = 03130, loss = 3.5304
2024-10-30 14:47:50: [2024-10-30 14:47:50] iter = 03140, loss = 7.9499
2024-10-30 14:47:51: [2024-10-30 14:47:51] iter = 03150, loss = 4.1319
2024-10-30 14:47:51: [2024-10-30 14:47:51] iter = 03160, loss = 4.2959
2024-10-30 14:47:52: [2024-10-30 14:47:52] iter = 03170, loss = 3.8745
2024-10-30 14:47:52: [2024-10-30 14:47:52] iter = 03180, loss = 3.0151
2024-10-30 14:47:52: [2024-10-30 14:47:52] iter = 03190, loss = 4.7038
2024-10-30 14:47:53: [2024-10-30 14:47:53] iter = 03200, loss = 2.9537
2024-10-30 14:47:53: [2024-10-30 14:47:53] iter = 03210, loss = 1.2299
2024-10-30 14:47:54: [2024-10-30 14:47:54] iter = 03220, loss = 2.0550
2024-10-30 14:47:54: [2024-10-30 14:47:54] iter = 03230, loss = 6.4638
2024-10-30 14:47:55: [2024-10-30 14:47:55] iter = 03240, loss = 2.6087
2024-10-30 14:47:55: [2024-10-30 14:47:55] iter = 03250, loss = 3.5555
2024-10-30 14:47:56: [2024-10-30 14:47:56] iter = 03260, loss = 7.0473
2024-10-30 14:47:56: [2024-10-30 14:47:56] iter = 03270, loss = 2.0027
2024-10-30 14:47:57: [2024-10-30 14:47:57] iter = 03280, loss = 16.4226
2024-10-30 14:47:57: [2024-10-30 14:47:57] iter = 03290, loss = 4.3945
2024-10-30 14:47:58: [2024-10-30 14:47:58] iter = 03300, loss = 2.0253
2024-10-30 14:47:58: [2024-10-30 14:47:58] iter = 03310, loss = 1.3503
2024-10-30 14:47:59: [2024-10-30 14:47:59] iter = 03320, loss = 2.4848
2024-10-30 14:47:59: [2024-10-30 14:47:59] iter = 03330, loss = 31.3824
2024-10-30 14:48:00: [2024-10-30 14:48:00] iter = 03340, loss = 32.3464
2024-10-30 14:48:00: [2024-10-30 14:48:00] iter = 03350, loss = 8.1544
2024-10-30 14:48:01: [2024-10-30 14:48:01] iter = 03360, loss = 1.8352
2024-10-30 14:48:01: [2024-10-30 14:48:01] iter = 03370, loss = 2.7136
2024-10-30 14:48:02: [2024-10-30 14:48:02] iter = 03380, loss = 2.2256
2024-10-30 14:48:02: [2024-10-30 14:48:02] iter = 03390, loss = 2.4128
2024-10-30 14:48:03: [2024-10-30 14:48:03] iter = 03400, loss = 7.1034
2024-10-30 14:48:03: [2024-10-30 14:48:03] iter = 03410, loss = 1.5412
2024-10-30 14:48:04: [2024-10-30 14:48:04] iter = 03420, loss = 2.0126
2024-10-30 14:48:04: [2024-10-30 14:48:04] iter = 03430, loss = 5.6564
2024-10-30 14:48:05: [2024-10-30 14:48:05] iter = 03440, loss = 4.1743
2024-10-30 14:48:05: [2024-10-30 14:48:05] iter = 03450, loss = 10.2942
2024-10-30 14:48:05: [2024-10-30 14:48:05] iter = 03460, loss = 3.5027
2024-10-30 14:48:06: [2024-10-30 14:48:06] iter = 03470, loss = 2.8177
2024-10-30 14:48:06: [2024-10-30 14:48:06] iter = 03480, loss = 6.2835
2024-10-30 14:48:07: [2024-10-30 14:48:07] iter = 03490, loss = 9.2209
2024-10-30 14:48:08: [2024-10-30 14:48:08] iter = 03500, loss = 3.6501
2024-10-30 14:48:08: [2024-10-30 14:48:08] iter = 03510, loss = 1.7049
2024-10-30 14:48:08: [2024-10-30 14:48:08] iter = 03520, loss = 1.5414
2024-10-30 14:48:09: [2024-10-30 14:48:09] iter = 03530, loss = 4.3892
2024-10-30 14:48:09: [2024-10-30 14:48:09] iter = 03540, loss = 26.1335
2024-10-30 14:48:09: [2024-10-30 14:48:09] iter = 03550, loss = 3.7932
2024-10-30 14:48:10: [2024-10-30 14:48:10] iter = 03560, loss = 2.9468
2024-10-30 14:48:10: [2024-10-30 14:48:10] iter = 03570, loss = 3.5314
2024-10-30 14:48:11: [2024-10-30 14:48:11] iter = 03580, loss = 7.5488
2024-10-30 14:48:11: [2024-10-30 14:48:11] iter = 03590, loss = 6.4116
2024-10-30 14:48:12: [2024-10-30 14:48:12] iter = 03600, loss = 37.5531
2024-10-30 14:48:12: [2024-10-30 14:48:12] iter = 03610, loss = 2.4524
2024-10-30 14:48:13: [2024-10-30 14:48:13] iter = 03620, loss = 6.8124
2024-10-30 14:48:13: [2024-10-30 14:48:13] iter = 03630, loss = 4.2248
2024-10-30 14:48:14: [2024-10-30 14:48:14] iter = 03640, loss = 5.6698
2024-10-30 14:48:14: [2024-10-30 14:48:14] iter = 03650, loss = 1.2856
2024-10-30 14:48:15: [2024-10-30 14:48:15] iter = 03660, loss = 72.5423
2024-10-30 14:48:15: [2024-10-30 14:48:15] iter = 03670, loss = 35.1125
2024-10-30 14:48:15: [2024-10-30 14:48:15] iter = 03680, loss = 10.0127
2024-10-30 14:48:16: [2024-10-30 14:48:16] iter = 03690, loss = 3.0751
2024-10-30 14:48:16: [2024-10-30 14:48:16] iter = 03700, loss = 2.9430
2024-10-30 14:48:17: [2024-10-30 14:48:17] iter = 03710, loss = 16.0756
2024-10-30 14:48:17: [2024-10-30 14:48:17] iter = 03720, loss = 1.4636
2024-10-30 14:48:18: [2024-10-30 14:48:18] iter = 03730, loss = 1.2986
2024-10-30 14:48:18: [2024-10-30 14:48:18] iter = 03740, loss = 2.1193
2024-10-30 14:48:19: [2024-10-30 14:48:19] iter = 03750, loss = 17.6679
2024-10-30 14:48:19: [2024-10-30 14:48:19] iter = 03760, loss = 2.9719
2024-10-30 14:48:20: [2024-10-30 14:48:20] iter = 03770, loss = 1.6726
2024-10-30 14:48:20: [2024-10-30 14:48:20] iter = 03780, loss = 1.9568
2024-10-30 14:48:21: [2024-10-30 14:48:21] iter = 03790, loss = 4.9382
2024-10-30 14:48:21: [2024-10-30 14:48:21] iter = 03800, loss = 1.3478
2024-10-30 14:48:22: [2024-10-30 14:48:22] iter = 03810, loss = 2.5424
2024-10-30 14:48:22: [2024-10-30 14:48:22] iter = 03820, loss = 4.2960
2024-10-30 14:48:23: [2024-10-30 14:48:23] iter = 03830, loss = 5.2761
2024-10-30 14:48:23: [2024-10-30 14:48:23] iter = 03840, loss = 5.7153
2024-10-30 14:48:23: [2024-10-30 14:48:23] iter = 03850, loss = 5.9696
2024-10-30 14:48:24: [2024-10-30 14:48:24] iter = 03860, loss = 2.6812
2024-10-30 14:48:24: [2024-10-30 14:48:24] iter = 03870, loss = 13.5192
2024-10-30 14:48:25: [2024-10-30 14:48:25] iter = 03880, loss = 2.1592
2024-10-30 14:48:25: [2024-10-30 14:48:25] iter = 03890, loss = 1.2592
2024-10-30 14:48:26: [2024-10-30 14:48:26] iter = 03900, loss = 2.2841
2024-10-30 14:48:26: [2024-10-30 14:48:26] iter = 03910, loss = 1.2961
2024-10-30 14:48:26: [2024-10-30 14:48:26] iter = 03920, loss = 1.5256
2024-10-30 14:48:27: [2024-10-30 14:48:27] iter = 03930, loss = 2.1537
2024-10-30 14:48:27: [2024-10-30 14:48:27] iter = 03940, loss = 4.5692
2024-10-30 14:48:28: [2024-10-30 14:48:28] iter = 03950, loss = 2.1879
2024-10-30 14:48:28: [2024-10-30 14:48:28] iter = 03960, loss = 6.5339
2024-10-30 14:48:29: [2024-10-30 14:48:29] iter = 03970, loss = 7.8956
2024-10-30 14:48:29: [2024-10-30 14:48:29] iter = 03980, loss = 2.8989
2024-10-30 14:48:29: [2024-10-30 14:48:29] iter = 03990, loss = 2.4236
2024-10-30 14:48:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 14:48:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:48:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10140}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:49:15: Evaluate 5 random ConvNet, ACCmean = 0.7449 ACCstd = 0.0085
-------------------------
2024-10-30 14:49:15: Evaluate 5 random ConvNet, SENmean = 0.5442 SENstd = 0.0158
-------------------------
2024-10-30 14:49:15: Evaluate 5 random ConvNet, SPEmean = 0.5442 SPEstd = 0.0158
-------------------------
2024-10-30 14:49:15: Evaluate 5 random ConvNet, F!mean = 0.5174 F!std = 0.0279
-------------------------
2024-10-30 14:49:15: Evaluate 5 random ConvNet, mean = 0.7449 std = 0.0085
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:49:16: [2024-10-30 14:49:16] iter = 04000, loss = 5.8377
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:49:16: [2024-10-30 14:49:16] iter = 04010, loss = 19.8085
2024-10-30 14:49:16: [2024-10-30 14:49:16] iter = 04020, loss = 14.4909
2024-10-30 14:49:17: [2024-10-30 14:49:17] iter = 04030, loss = 2.7187
2024-10-30 14:49:17: [2024-10-30 14:49:17] iter = 04040, loss = 1.9827
2024-10-30 14:49:18: [2024-10-30 14:49:18] iter = 04050, loss = 1.4734
2024-10-30 14:49:18: [2024-10-30 14:49:18] iter = 04060, loss = 2.9164
2024-10-30 14:49:18: [2024-10-30 14:49:18] iter = 04070, loss = 1.1382
2024-10-30 14:49:19: [2024-10-30 14:49:19] iter = 04080, loss = 4.0868
2024-10-30 14:49:19: [2024-10-30 14:49:19] iter = 04090, loss = 1.6658
2024-10-30 14:49:19: [2024-10-30 14:49:19] iter = 04100, loss = 1.0150
2024-10-30 14:49:20: [2024-10-30 14:49:20] iter = 04110, loss = 2.5953
2024-10-30 14:49:20: [2024-10-30 14:49:20] iter = 04120, loss = 7.0320
2024-10-30 14:49:21: [2024-10-30 14:49:21] iter = 04130, loss = 2.5658
2024-10-30 14:49:21: [2024-10-30 14:49:21] iter = 04140, loss = 2.0874
2024-10-30 14:49:22: [2024-10-30 14:49:21] iter = 04150, loss = 11.1271
2024-10-30 14:49:22: [2024-10-30 14:49:22] iter = 04160, loss = 1.6731
2024-10-30 14:49:22: [2024-10-30 14:49:22] iter = 04170, loss = 1.6573
2024-10-30 14:49:23: [2024-10-30 14:49:23] iter = 04180, loss = 5.2068
2024-10-30 14:49:23: [2024-10-30 14:49:23] iter = 04190, loss = 7.0757
2024-10-30 14:49:24: [2024-10-30 14:49:24] iter = 04200, loss = 1.3205
2024-10-30 14:49:24: [2024-10-30 14:49:24] iter = 04210, loss = 15.6692
2024-10-30 14:49:24: [2024-10-30 14:49:24] iter = 04220, loss = 3.3614
2024-10-30 14:49:25: [2024-10-30 14:49:25] iter = 04230, loss = 2.8036
2024-10-30 14:49:25: [2024-10-30 14:49:25] iter = 04240, loss = 2.3623
2024-10-30 14:49:26: [2024-10-30 14:49:26] iter = 04250, loss = 4.3718
2024-10-30 14:49:26: [2024-10-30 14:49:26] iter = 04260, loss = 7.4622
2024-10-30 14:49:26: [2024-10-30 14:49:26] iter = 04270, loss = 3.6042
2024-10-30 14:49:27: [2024-10-30 14:49:27] iter = 04280, loss = 2.8730
2024-10-30 14:49:28: [2024-10-30 14:49:28] iter = 04290, loss = 13.6152
2024-10-30 14:49:28: [2024-10-30 14:49:28] iter = 04300, loss = 2.4138
2024-10-30 14:49:29: [2024-10-30 14:49:29] iter = 04310, loss = 10.0615
2024-10-30 14:49:29: [2024-10-30 14:49:29] iter = 04320, loss = 1.4494
2024-10-30 14:49:29: [2024-10-30 14:49:29] iter = 04330, loss = 1.2966
2024-10-30 14:49:30: [2024-10-30 14:49:30] iter = 04340, loss = 1.3812
2024-10-30 14:49:30: [2024-10-30 14:49:30] iter = 04350, loss = 1.3345
2024-10-30 14:49:31: [2024-10-30 14:49:31] iter = 04360, loss = 8.7109
2024-10-30 14:49:31: [2024-10-30 14:49:31] iter = 04370, loss = 24.3618
2024-10-30 14:49:32: [2024-10-30 14:49:32] iter = 04380, loss = 2.4324
2024-10-30 14:49:32: [2024-10-30 14:49:32] iter = 04390, loss = 2.4334
2024-10-30 14:49:33: [2024-10-30 14:49:33] iter = 04400, loss = 1.4213
2024-10-30 14:49:33: [2024-10-30 14:49:33] iter = 04410, loss = 1.7009
2024-10-30 14:49:33: [2024-10-30 14:49:33] iter = 04420, loss = 16.2452
2024-10-30 14:49:34: [2024-10-30 14:49:34] iter = 04430, loss = 1.9153
2024-10-30 14:49:34: [2024-10-30 14:49:34] iter = 04440, loss = 3.2088
2024-10-30 14:49:34: [2024-10-30 14:49:34] iter = 04450, loss = 2.4432
2024-10-30 14:49:35: [2024-10-30 14:49:35] iter = 04460, loss = 6.1032
2024-10-30 14:49:35: [2024-10-30 14:49:35] iter = 04470, loss = 4.1455
2024-10-30 14:49:36: [2024-10-30 14:49:36] iter = 04480, loss = 11.1746
2024-10-30 14:49:36: [2024-10-30 14:49:36] iter = 04490, loss = 1.7646
2024-10-30 14:49:37: [2024-10-30 14:49:37] iter = 04500, loss = 1.6149
2024-10-30 14:49:37: [2024-10-30 14:49:37] iter = 04510, loss = 2.2645
2024-10-30 14:49:38: [2024-10-30 14:49:38] iter = 04520, loss = 1.5256
2024-10-30 14:49:39: [2024-10-30 14:49:39] iter = 04530, loss = 8.1936
2024-10-30 14:49:39: [2024-10-30 14:49:39] iter = 04540, loss = 13.4199
2024-10-30 14:49:40: [2024-10-30 14:49:40] iter = 04550, loss = 17.6785
2024-10-30 14:49:40: [2024-10-30 14:49:40] iter = 04560, loss = 5.8434
2024-10-30 14:49:40: [2024-10-30 14:49:40] iter = 04570, loss = 16.7328
2024-10-30 14:49:41: [2024-10-30 14:49:41] iter = 04580, loss = 3.8911
2024-10-30 14:49:41: [2024-10-30 14:49:41] iter = 04590, loss = 2.9925
2024-10-30 14:49:42: [2024-10-30 14:49:42] iter = 04600, loss = 2.6568
2024-10-30 14:49:42: [2024-10-30 14:49:42] iter = 04610, loss = 7.9994
2024-10-30 14:49:43: [2024-10-30 14:49:43] iter = 04620, loss = 3.6846
2024-10-30 14:49:43: [2024-10-30 14:49:43] iter = 04630, loss = 3.8709
2024-10-30 14:49:44: [2024-10-30 14:49:44] iter = 04640, loss = 1.4336
2024-10-30 14:49:44: [2024-10-30 14:49:44] iter = 04650, loss = 1.9598
2024-10-30 14:49:45: [2024-10-30 14:49:45] iter = 04660, loss = 1.4893
2024-10-30 14:49:45: [2024-10-30 14:49:45] iter = 04670, loss = 1.0982
2024-10-30 14:49:46: [2024-10-30 14:49:46] iter = 04680, loss = 0.8287
2024-10-30 14:49:46: [2024-10-30 14:49:46] iter = 04690, loss = 8.4939
2024-10-30 14:49:46: [2024-10-30 14:49:46] iter = 04700, loss = 2.6980
2024-10-30 14:49:47: [2024-10-30 14:49:47] iter = 04710, loss = 1.2578
2024-10-30 14:49:47: [2024-10-30 14:49:47] iter = 04720, loss = 7.9745
2024-10-30 14:49:48: [2024-10-30 14:49:48] iter = 04730, loss = 2.0411
2024-10-30 14:49:48: [2024-10-30 14:49:48] iter = 04740, loss = 1.6728
2024-10-30 14:49:49: [2024-10-30 14:49:49] iter = 04750, loss = 1.6419
2024-10-30 14:49:49: [2024-10-30 14:49:49] iter = 04760, loss = 10.5232
2024-10-30 14:49:49: [2024-10-30 14:49:49] iter = 04770, loss = 4.0155
2024-10-30 14:49:50: [2024-10-30 14:49:50] iter = 04780, loss = 2.1675
2024-10-30 14:49:50: [2024-10-30 14:49:50] iter = 04790, loss = 4.7012
2024-10-30 14:49:51: [2024-10-30 14:49:51] iter = 04800, loss = 6.6929
2024-10-30 14:49:51: [2024-10-30 14:49:51] iter = 04810, loss = 9.9105
2024-10-30 14:49:52: [2024-10-30 14:49:52] iter = 04820, loss = 4.6515
2024-10-30 14:49:52: [2024-10-30 14:49:52] iter = 04830, loss = 3.5609
2024-10-30 14:49:53: [2024-10-30 14:49:53] iter = 04840, loss = 3.9678
2024-10-30 14:49:53: [2024-10-30 14:49:53] iter = 04850, loss = 1.8687
2024-10-30 14:49:54: [2024-10-30 14:49:54] iter = 04860, loss = 2.1968
2024-10-30 14:49:54: [2024-10-30 14:49:54] iter = 04870, loss = 2.4691
2024-10-30 14:49:55: [2024-10-30 14:49:55] iter = 04880, loss = 1.5616
2024-10-30 14:49:56: [2024-10-30 14:49:56] iter = 04890, loss = 1.3329
2024-10-30 14:49:56: [2024-10-30 14:49:56] iter = 04900, loss = 3.2574
2024-10-30 14:49:57: [2024-10-30 14:49:57] iter = 04910, loss = 2.2073
2024-10-30 14:49:57: [2024-10-30 14:49:57] iter = 04920, loss = 1.9753
2024-10-30 14:49:58: [2024-10-30 14:49:58] iter = 04930, loss = 1.7373
2024-10-30 14:49:58: [2024-10-30 14:49:58] iter = 04940, loss = 5.5575
2024-10-30 14:49:59: [2024-10-30 14:49:59] iter = 04950, loss = 15.8977
2024-10-30 14:50:00: [2024-10-30 14:50:00] iter = 04960, loss = 2.2051
2024-10-30 14:50:00: [2024-10-30 14:50:00] iter = 04970, loss = 0.8550
2024-10-30 14:50:01: [2024-10-30 14:50:01] iter = 04980, loss = 1.3169
2024-10-30 14:50:02: [2024-10-30 14:50:02] iter = 04990, loss = 1.7045
2024-10-30 14:50:02: [2024-10-30 14:50:02] iter = 05000, loss = 7.9683
2024-10-30 14:50:03: [2024-10-30 14:50:03] iter = 05010, loss = 1.5465
2024-10-30 14:50:03: [2024-10-30 14:50:03] iter = 05020, loss = 4.4102
2024-10-30 14:50:04: [2024-10-30 14:50:04] iter = 05030, loss = 3.3181
2024-10-30 14:50:04: [2024-10-30 14:50:04] iter = 05040, loss = 9.0319
2024-10-30 14:50:05: [2024-10-30 14:50:05] iter = 05050, loss = 1.7368
2024-10-30 14:50:05: [2024-10-30 14:50:05] iter = 05060, loss = 2.5388
2024-10-30 14:50:06: [2024-10-30 14:50:06] iter = 05070, loss = 8.2888
2024-10-30 14:50:07: [2024-10-30 14:50:07] iter = 05080, loss = 1.3435
2024-10-30 14:50:07: [2024-10-30 14:50:07] iter = 05090, loss = 2.4210
2024-10-30 14:50:08: [2024-10-30 14:50:08] iter = 05100, loss = 2.9707
2024-10-30 14:50:08: [2024-10-30 14:50:08] iter = 05110, loss = 1.6906
2024-10-30 14:50:09: [2024-10-30 14:50:09] iter = 05120, loss = 5.9282
2024-10-30 14:50:10: [2024-10-30 14:50:10] iter = 05130, loss = 4.9469
2024-10-30 14:50:10: [2024-10-30 14:50:10] iter = 05140, loss = 6.4181
2024-10-30 14:50:11: [2024-10-30 14:50:11] iter = 05150, loss = 1.5672
2024-10-30 14:50:11: [2024-10-30 14:50:11] iter = 05160, loss = 3.8384
2024-10-30 14:50:12: [2024-10-30 14:50:12] iter = 05170, loss = 11.3002
2024-10-30 14:50:13: [2024-10-30 14:50:13] iter = 05180, loss = 2.3322
2024-10-30 14:50:13: [2024-10-30 14:50:13] iter = 05190, loss = 6.0944
2024-10-30 14:50:14: [2024-10-30 14:50:14] iter = 05200, loss = 3.3650
2024-10-30 14:50:14: [2024-10-30 14:50:14] iter = 05210, loss = 24.8662
2024-10-30 14:50:15: [2024-10-30 14:50:15] iter = 05220, loss = 4.5533
2024-10-30 14:50:15: [2024-10-30 14:50:15] iter = 05230, loss = 5.5317
2024-10-30 14:50:16: [2024-10-30 14:50:16] iter = 05240, loss = 2.2538
2024-10-30 14:50:16: [2024-10-30 14:50:16] iter = 05250, loss = 41.4620
2024-10-30 14:50:16: [2024-10-30 14:50:16] iter = 05260, loss = 2.5915
2024-10-30 14:50:17: [2024-10-30 14:50:17] iter = 05270, loss = 1.2970
2024-10-30 14:50:18: [2024-10-30 14:50:18] iter = 05280, loss = 1.7688
2024-10-30 14:50:18: [2024-10-30 14:50:18] iter = 05290, loss = 4.3939
2024-10-30 14:50:19: [2024-10-30 14:50:19] iter = 05300, loss = 1.3335
2024-10-30 14:50:19: [2024-10-30 14:50:19] iter = 05310, loss = 3.2224
2024-10-30 14:50:20: [2024-10-30 14:50:20] iter = 05320, loss = 1.3329
2024-10-30 14:50:20: [2024-10-30 14:50:20] iter = 05330, loss = 1.9158
2024-10-30 14:50:21: [2024-10-30 14:50:21] iter = 05340, loss = 1.3153
2024-10-30 14:50:21: [2024-10-30 14:50:21] iter = 05350, loss = 2.3842
2024-10-30 14:50:21: [2024-10-30 14:50:21] iter = 05360, loss = 2.2831
2024-10-30 14:50:22: [2024-10-30 14:50:22] iter = 05370, loss = 1.2373
2024-10-30 14:50:23: [2024-10-30 14:50:23] iter = 05380, loss = 1.2082
2024-10-30 14:50:23: [2024-10-30 14:50:23] iter = 05390, loss = 2.5890
2024-10-30 14:50:24: [2024-10-30 14:50:24] iter = 05400, loss = 12.4231
2024-10-30 14:50:25: [2024-10-30 14:50:25] iter = 05410, loss = 4.4194
2024-10-30 14:50:25: [2024-10-30 14:50:25] iter = 05420, loss = 1.5603
2024-10-30 14:50:26: [2024-10-30 14:50:26] iter = 05430, loss = 1.1473
2024-10-30 14:50:26: [2024-10-30 14:50:26] iter = 05440, loss = 13.4937
2024-10-30 14:50:27: [2024-10-30 14:50:27] iter = 05450, loss = 2.5668
2024-10-30 14:50:28: [2024-10-30 14:50:28] iter = 05460, loss = 2.3726
2024-10-30 14:50:29: [2024-10-30 14:50:29] iter = 05470, loss = 21.9105
2024-10-30 14:50:29: [2024-10-30 14:50:29] iter = 05480, loss = 1.7019
2024-10-30 14:50:30: [2024-10-30 14:50:30] iter = 05490, loss = 4.7936
2024-10-30 14:50:30: [2024-10-30 14:50:30] iter = 05500, loss = 4.2821
2024-10-30 14:50:31: [2024-10-30 14:50:31] iter = 05510, loss = 3.2005
2024-10-30 14:50:31: [2024-10-30 14:50:31] iter = 05520, loss = 9.0019
2024-10-30 14:50:32: [2024-10-30 14:50:32] iter = 05530, loss = 2.3888
2024-10-30 14:50:33: [2024-10-30 14:50:33] iter = 05540, loss = 1.1754
2024-10-30 14:50:33: [2024-10-30 14:50:33] iter = 05550, loss = 2.7704
2024-10-30 14:50:34: [2024-10-30 14:50:34] iter = 05560, loss = 3.1674
2024-10-30 14:50:35: [2024-10-30 14:50:35] iter = 05570, loss = 2.2762
2024-10-30 14:50:35: [2024-10-30 14:50:35] iter = 05580, loss = 3.7510
2024-10-30 14:50:36: [2024-10-30 14:50:36] iter = 05590, loss = 1.8440
2024-10-30 14:50:37: [2024-10-30 14:50:37] iter = 05600, loss = 2.4191
2024-10-30 14:50:37: [2024-10-30 14:50:37] iter = 05610, loss = 14.8544
2024-10-30 14:50:37: [2024-10-30 14:50:37] iter = 05620, loss = 3.6347
2024-10-30 14:50:38: [2024-10-30 14:50:38] iter = 05630, loss = 5.2641
2024-10-30 14:50:38: [2024-10-30 14:50:38] iter = 05640, loss = 2.8417
2024-10-30 14:50:39: [2024-10-30 14:50:39] iter = 05650, loss = 1.7450
2024-10-30 14:50:39: [2024-10-30 14:50:39] iter = 05660, loss = 1.3623
2024-10-30 14:50:40: [2024-10-30 14:50:40] iter = 05670, loss = 4.9471
2024-10-30 14:50:40: [2024-10-30 14:50:40] iter = 05680, loss = 4.7330
2024-10-30 14:50:41: [2024-10-30 14:50:41] iter = 05690, loss = 1.3528
2024-10-30 14:50:41: [2024-10-30 14:50:41] iter = 05700, loss = 1.7459
2024-10-30 14:50:41: [2024-10-30 14:50:41] iter = 05710, loss = 43.9178
2024-10-30 14:50:42: [2024-10-30 14:50:42] iter = 05720, loss = 2.8454
2024-10-30 14:50:42: [2024-10-30 14:50:42] iter = 05730, loss = 3.1389
2024-10-30 14:50:43: [2024-10-30 14:50:43] iter = 05740, loss = 1.5695
2024-10-30 14:50:44: [2024-10-30 14:50:44] iter = 05750, loss = 3.6935
2024-10-30 14:50:44: [2024-10-30 14:50:44] iter = 05760, loss = 1.3110
2024-10-30 14:50:45: [2024-10-30 14:50:45] iter = 05770, loss = 2.1583
2024-10-30 14:50:45: [2024-10-30 14:50:45] iter = 05780, loss = 1.7847
2024-10-30 14:50:46: [2024-10-30 14:50:46] iter = 05790, loss = 3.3145
2024-10-30 14:50:47: [2024-10-30 14:50:47] iter = 05800, loss = 3.6436
2024-10-30 14:50:48: [2024-10-30 14:50:48] iter = 05810, loss = 15.9026
2024-10-30 14:50:48: [2024-10-30 14:50:48] iter = 05820, loss = 3.5749
2024-10-30 14:50:49: [2024-10-30 14:50:49] iter = 05830, loss = 14.3609
2024-10-30 14:50:49: [2024-10-30 14:50:49] iter = 05840, loss = 1.4614
2024-10-30 14:50:50: [2024-10-30 14:50:50] iter = 05850, loss = 2.3719
2024-10-30 14:50:51: [2024-10-30 14:50:51] iter = 05860, loss = 11.7619
2024-10-30 14:50:51: [2024-10-30 14:50:51] iter = 05870, loss = 3.0114
2024-10-30 14:50:52: [2024-10-30 14:50:52] iter = 05880, loss = 14.5144
2024-10-30 14:50:52: [2024-10-30 14:50:52] iter = 05890, loss = 1.7102
2024-10-30 14:50:53: [2024-10-30 14:50:53] iter = 05900, loss = 1.1597
2024-10-30 14:50:53: [2024-10-30 14:50:53] iter = 05910, loss = 8.4953
2024-10-30 14:50:54: [2024-10-30 14:50:54] iter = 05920, loss = 5.2111
2024-10-30 14:50:54: [2024-10-30 14:50:54] iter = 05930, loss = 1.8682
2024-10-30 14:50:55: [2024-10-30 14:50:55] iter = 05940, loss = 14.9376
2024-10-30 14:50:55: [2024-10-30 14:50:55] iter = 05950, loss = 2.5510
2024-10-30 14:50:56: [2024-10-30 14:50:56] iter = 05960, loss = 1.8507
2024-10-30 14:50:57: [2024-10-30 14:50:57] iter = 05970, loss = 5.8396
2024-10-30 14:50:58: [2024-10-30 14:50:58] iter = 05980, loss = 7.4710
2024-10-30 14:50:58: [2024-10-30 14:50:58] iter = 05990, loss = 2.8336
2024-10-30 14:50:58: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 14:50:58: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:50:58: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 58958}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:51:52: Evaluate 5 random ConvNet, ACCmean = 0.7692 ACCstd = 0.0157
-------------------------
2024-10-30 14:51:52: Evaluate 5 random ConvNet, SENmean = 0.7068 SENstd = 0.0158
-------------------------
2024-10-30 14:51:52: Evaluate 5 random ConvNet, SPEmean = 0.7068 SPEstd = 0.0158
-------------------------
2024-10-30 14:51:52: Evaluate 5 random ConvNet, F!mean = 0.7068 F!std = 0.0172
-------------------------
2024-10-30 14:51:52: Evaluate 5 random ConvNet, mean = 0.7692 std = 0.0157
-------------------------
2024-10-30 14:51:52: [2024-10-30 14:51:52] iter = 06000, loss = 4.3702
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:51:52: [2024-10-30 14:51:52] iter = 06010, loss = 3.4126
2024-10-30 14:51:53: [2024-10-30 14:51:53] iter = 06020, loss = 5.0054
2024-10-30 14:51:53: [2024-10-30 14:51:53] iter = 06030, loss = 6.2846
2024-10-30 14:51:54: [2024-10-30 14:51:54] iter = 06040, loss = 9.8535
2024-10-30 14:51:54: [2024-10-30 14:51:54] iter = 06050, loss = 22.8624
2024-10-30 14:51:55: [2024-10-30 14:51:55] iter = 06060, loss = 1.7067
2024-10-30 14:51:56: [2024-10-30 14:51:56] iter = 06070, loss = 2.2649
2024-10-30 14:51:56: [2024-10-30 14:51:56] iter = 06080, loss = 1.8617
2024-10-30 14:51:57: [2024-10-30 14:51:57] iter = 06090, loss = 8.0226
2024-10-30 14:51:58: [2024-10-30 14:51:58] iter = 06100, loss = 1.8567
2024-10-30 14:51:58: [2024-10-30 14:51:58] iter = 06110, loss = 6.2671
2024-10-30 14:51:59: [2024-10-30 14:51:59] iter = 06120, loss = 2.4296
2024-10-30 14:51:59: [2024-10-30 14:51:59] iter = 06130, loss = 2.9037
2024-10-30 14:51:59: [2024-10-30 14:51:59] iter = 06140, loss = 1.8824
2024-10-30 14:52:00: [2024-10-30 14:52:00] iter = 06150, loss = 2.0987
2024-10-30 14:52:00: [2024-10-30 14:52:00] iter = 06160, loss = 1.5577
2024-10-30 14:52:01: [2024-10-30 14:52:01] iter = 06170, loss = 4.6398
2024-10-30 14:52:01: [2024-10-30 14:52:01] iter = 06180, loss = 2.9859
2024-10-30 14:52:02: [2024-10-30 14:52:02] iter = 06190, loss = 5.6923
2024-10-30 14:52:02: [2024-10-30 14:52:02] iter = 06200, loss = 5.2960
2024-10-30 14:52:03: [2024-10-30 14:52:03] iter = 06210, loss = 2.8078
2024-10-30 14:52:04: [2024-10-30 14:52:04] iter = 06220, loss = 2.9608
2024-10-30 14:52:04: [2024-10-30 14:52:04] iter = 06230, loss = 1.7409
2024-10-30 14:52:05: [2024-10-30 14:52:05] iter = 06240, loss = 3.3557
2024-10-30 14:52:05: [2024-10-30 14:52:05] iter = 06250, loss = 2.6119
2024-10-30 14:52:06: [2024-10-30 14:52:06] iter = 06260, loss = 4.4889
2024-10-30 14:52:07: [2024-10-30 14:52:07] iter = 06270, loss = 2.3985
2024-10-30 14:52:07: [2024-10-30 14:52:07] iter = 06280, loss = 6.5708
2024-10-30 14:52:08: [2024-10-30 14:52:08] iter = 06290, loss = 6.4579
2024-10-30 14:52:09: [2024-10-30 14:52:09] iter = 06300, loss = 4.1983
2024-10-30 14:52:09: [2024-10-30 14:52:09] iter = 06310, loss = 3.1037
2024-10-30 14:52:10: [2024-10-30 14:52:10] iter = 06320, loss = 2.5168
2024-10-30 14:52:10: [2024-10-30 14:52:10] iter = 06330, loss = 2.0268
2024-10-30 14:52:11: [2024-10-30 14:52:11] iter = 06340, loss = 1.5763
2024-10-30 14:52:12: [2024-10-30 14:52:12] iter = 06350, loss = 3.9082
2024-10-30 14:52:12: [2024-10-30 14:52:12] iter = 06360, loss = 1.3668
2024-10-30 14:52:13: [2024-10-30 14:52:13] iter = 06370, loss = 1.4028
2024-10-30 14:52:13: [2024-10-30 14:52:13] iter = 06380, loss = 4.3905
2024-10-30 14:52:14: [2024-10-30 14:52:14] iter = 06390, loss = 2.7257
2024-10-30 14:52:15: [2024-10-30 14:52:15] iter = 06400, loss = 29.6935
2024-10-30 14:52:15: [2024-10-30 14:52:15] iter = 06410, loss = 3.3105
2024-10-30 14:52:16: [2024-10-30 14:52:16] iter = 06420, loss = 3.5933
2024-10-30 14:52:17: [2024-10-30 14:52:17] iter = 06430, loss = 14.7753
2024-10-30 14:52:17: [2024-10-30 14:52:17] iter = 06440, loss = 3.0902
2024-10-30 14:52:18: [2024-10-30 14:52:18] iter = 06450, loss = 2.1631
2024-10-30 14:52:18: [2024-10-30 14:52:18] iter = 06460, loss = 1.6556
2024-10-30 14:52:19: [2024-10-30 14:52:19] iter = 06470, loss = 1.6796
2024-10-30 14:52:20: [2024-10-30 14:52:20] iter = 06480, loss = 7.6437
2024-10-30 14:52:21: [2024-10-30 14:52:21] iter = 06490, loss = 2.3723
2024-10-30 14:52:21: [2024-10-30 14:52:21] iter = 06500, loss = 16.7448
2024-10-30 14:52:22: [2024-10-30 14:52:22] iter = 06510, loss = 1.9677
2024-10-30 14:52:23: [2024-10-30 14:52:23] iter = 06520, loss = 1.4752
2024-10-30 14:52:23: [2024-10-30 14:52:23] iter = 06530, loss = 9.4644
2024-10-30 14:52:24: [2024-10-30 14:52:24] iter = 06540, loss = 10.7998
2024-10-30 14:52:24: [2024-10-30 14:52:24] iter = 06550, loss = 2.7692
2024-10-30 14:52:25: [2024-10-30 14:52:25] iter = 06560, loss = 1.2591
2024-10-30 14:52:25: [2024-10-30 14:52:25] iter = 06570, loss = 1.3318
2024-10-30 14:52:26: [2024-10-30 14:52:26] iter = 06580, loss = 2.0160
2024-10-30 14:52:27: [2024-10-30 14:52:27] iter = 06590, loss = 1.6378
2024-10-30 14:52:28: [2024-10-30 14:52:28] iter = 06600, loss = 2.1231
2024-10-30 14:52:28: [2024-10-30 14:52:28] iter = 06610, loss = 3.1354
2024-10-30 14:52:29: [2024-10-30 14:52:29] iter = 06620, loss = 4.9670
2024-10-30 14:52:29: [2024-10-30 14:52:29] iter = 06630, loss = 1.5146
2024-10-30 14:52:30: [2024-10-30 14:52:30] iter = 06640, loss = 1.2328
2024-10-30 14:52:31: [2024-10-30 14:52:31] iter = 06650, loss = 5.2736
2024-10-30 14:52:31: [2024-10-30 14:52:31] iter = 06660, loss = 5.8815
2024-10-30 14:52:32: [2024-10-30 14:52:32] iter = 06670, loss = 22.9515
2024-10-30 14:52:33: [2024-10-30 14:52:33] iter = 06680, loss = 8.0916
2024-10-30 14:52:33: [2024-10-30 14:52:33] iter = 06690, loss = 2.7493
2024-10-30 14:52:34: [2024-10-30 14:52:34] iter = 06700, loss = 6.1298
2024-10-30 14:52:35: [2024-10-30 14:52:35] iter = 06710, loss = 1.4616
2024-10-30 14:52:35: [2024-10-30 14:52:35] iter = 06720, loss = 0.8976
2024-10-30 14:52:36: [2024-10-30 14:52:36] iter = 06730, loss = 2.5031
2024-10-30 14:52:36: [2024-10-30 14:52:36] iter = 06740, loss = 1.3715
2024-10-30 14:52:36: [2024-10-30 14:52:36] iter = 06750, loss = 14.5401
2024-10-30 14:52:37: [2024-10-30 14:52:37] iter = 06760, loss = 1.7274
2024-10-30 14:52:37: [2024-10-30 14:52:37] iter = 06770, loss = 11.8807
2024-10-30 14:52:38: [2024-10-30 14:52:38] iter = 06780, loss = 8.4443
2024-10-30 14:52:38: [2024-10-30 14:52:38] iter = 06790, loss = 1.9393
2024-10-30 14:52:39: [2024-10-30 14:52:39] iter = 06800, loss = 16.2607
2024-10-30 14:52:39: [2024-10-30 14:52:39] iter = 06810, loss = 2.0534
2024-10-30 14:52:40: [2024-10-30 14:52:40] iter = 06820, loss = 4.6037
2024-10-30 14:52:40: [2024-10-30 14:52:40] iter = 06830, loss = 4.4810
2024-10-30 14:52:41: [2024-10-30 14:52:41] iter = 06840, loss = 2.2618
2024-10-30 14:52:41: [2024-10-30 14:52:41] iter = 06850, loss = 4.8550
2024-10-30 14:52:42: [2024-10-30 14:52:42] iter = 06860, loss = 4.8368
2024-10-30 14:52:42: [2024-10-30 14:52:42] iter = 06870, loss = 22.1979
2024-10-30 14:52:43: [2024-10-30 14:52:43] iter = 06880, loss = 1.8314
2024-10-30 14:52:44: [2024-10-30 14:52:44] iter = 06890, loss = 2.3814
2024-10-30 14:52:44: [2024-10-30 14:52:44] iter = 06900, loss = 4.1420
2024-10-30 14:52:45: [2024-10-30 14:52:45] iter = 06910, loss = 5.6033
2024-10-30 14:52:46: [2024-10-30 14:52:46] iter = 06920, loss = 4.0793
2024-10-30 14:52:46: [2024-10-30 14:52:46] iter = 06930, loss = 2.1068
2024-10-30 14:52:47: [2024-10-30 14:52:47] iter = 06940, loss = 1.3581
2024-10-30 14:52:48: [2024-10-30 14:52:48] iter = 06950, loss = 1.8327
2024-10-30 14:52:48: [2024-10-30 14:52:48] iter = 06960, loss = 4.7810
2024-10-30 14:52:49: [2024-10-30 14:52:49] iter = 06970, loss = 1.5738
2024-10-30 14:52:49: [2024-10-30 14:52:49] iter = 06980, loss = 2.0579
2024-10-30 14:52:50: [2024-10-30 14:52:50] iter = 06990, loss = 1.7053
2024-10-30 14:52:50: [2024-10-30 14:52:50] iter = 07000, loss = 5.0471
2024-10-30 14:52:51: [2024-10-30 14:52:51] iter = 07010, loss = 10.9602
2024-10-30 14:52:52: [2024-10-30 14:52:52] iter = 07020, loss = 2.2804
2024-10-30 14:52:52: [2024-10-30 14:52:52] iter = 07030, loss = 1.4590
2024-10-30 14:52:53: [2024-10-30 14:52:53] iter = 07040, loss = 22.5321
2024-10-30 14:52:54: [2024-10-30 14:52:54] iter = 07050, loss = 2.2323
2024-10-30 14:52:54: [2024-10-30 14:52:54] iter = 07060, loss = 1.5747
2024-10-30 14:52:55: [2024-10-30 14:52:55] iter = 07070, loss = 3.0027
2024-10-30 14:52:55: [2024-10-30 14:52:55] iter = 07080, loss = 1.7213
2024-10-30 14:52:56: [2024-10-30 14:52:56] iter = 07090, loss = 1.3640
2024-10-30 14:52:57: [2024-10-30 14:52:57] iter = 07100, loss = 1.2313
2024-10-30 14:52:57: [2024-10-30 14:52:57] iter = 07110, loss = 3.9235
2024-10-30 14:52:58: [2024-10-30 14:52:58] iter = 07120, loss = 1.4984
2024-10-30 14:52:58: [2024-10-30 14:52:58] iter = 07130, loss = 2.6589
2024-10-30 14:52:59: [2024-10-30 14:52:59] iter = 07140, loss = 2.9086
2024-10-30 14:53:00: [2024-10-30 14:53:00] iter = 07150, loss = 28.9998
2024-10-30 14:53:00: [2024-10-30 14:53:00] iter = 07160, loss = 2.3999
2024-10-30 14:53:01: [2024-10-30 14:53:01] iter = 07170, loss = 3.0842
2024-10-30 14:53:01: [2024-10-30 14:53:01] iter = 07180, loss = 1.4965
2024-10-30 14:53:02: [2024-10-30 14:53:02] iter = 07190, loss = 1.5329
2024-10-30 14:53:02: [2024-10-30 14:53:02] iter = 07200, loss = 1.4416
2024-10-30 14:53:03: [2024-10-30 14:53:03] iter = 07210, loss = 5.6027
2024-10-30 14:53:03: [2024-10-30 14:53:03] iter = 07220, loss = 5.1743
2024-10-30 14:53:04: [2024-10-30 14:53:04] iter = 07230, loss = 1.5603
2024-10-30 14:53:04: [2024-10-30 14:53:04] iter = 07240, loss = 1.8554
2024-10-30 14:53:05: [2024-10-30 14:53:05] iter = 07250, loss = 1.9535
2024-10-30 14:53:06: [2024-10-30 14:53:06] iter = 07260, loss = 1.7636
2024-10-30 14:53:07: [2024-10-30 14:53:07] iter = 07270, loss = 3.6606
2024-10-30 14:53:07: [2024-10-30 14:53:07] iter = 07280, loss = 1.6632
2024-10-30 14:53:08: [2024-10-30 14:53:08] iter = 07290, loss = 1.6560
2024-10-30 14:53:09: [2024-10-30 14:53:09] iter = 07300, loss = 3.5122
2024-10-30 14:53:10: [2024-10-30 14:53:10] iter = 07310, loss = 9.4684
2024-10-30 14:53:11: [2024-10-30 14:53:11] iter = 07320, loss = 1.6215
2024-10-30 14:53:11: [2024-10-30 14:53:11] iter = 07330, loss = 1.1797
2024-10-30 14:53:12: [2024-10-30 14:53:12] iter = 07340, loss = 1.1282
2024-10-30 14:53:13: [2024-10-30 14:53:13] iter = 07350, loss = 2.7798
2024-10-30 14:53:14: [2024-10-30 14:53:14] iter = 07360, loss = 4.8661
2024-10-30 14:53:14: [2024-10-30 14:53:14] iter = 07370, loss = 1.2755
2024-10-30 14:53:15: [2024-10-30 14:53:15] iter = 07380, loss = 47.1661
2024-10-30 14:53:15: [2024-10-30 14:53:15] iter = 07390, loss = 11.7543
2024-10-30 14:53:16: [2024-10-30 14:53:16] iter = 07400, loss = 24.8358
2024-10-30 14:53:17: [2024-10-30 14:53:17] iter = 07410, loss = 37.4725
2024-10-30 14:53:17: [2024-10-30 14:53:17] iter = 07420, loss = 5.7129
2024-10-30 14:53:18: [2024-10-30 14:53:18] iter = 07430, loss = 3.8002
2024-10-30 14:53:18: [2024-10-30 14:53:18] iter = 07440, loss = 11.6611
2024-10-30 14:53:19: [2024-10-30 14:53:19] iter = 07450, loss = 3.5380
2024-10-30 14:53:19: [2024-10-30 14:53:19] iter = 07460, loss = 4.2029
2024-10-30 14:53:20: [2024-10-30 14:53:20] iter = 07470, loss = 2.1120
2024-10-30 14:53:20: [2024-10-30 14:53:20] iter = 07480, loss = 9.8460
2024-10-30 14:53:21: [2024-10-30 14:53:21] iter = 07490, loss = 1.7282
2024-10-30 14:53:22: [2024-10-30 14:53:22] iter = 07500, loss = 1.6294
2024-10-30 14:53:22: [2024-10-30 14:53:22] iter = 07510, loss = 4.0614
2024-10-30 14:53:23: [2024-10-30 14:53:23] iter = 07520, loss = 1.8043
2024-10-30 14:53:23: [2024-10-30 14:53:23] iter = 07530, loss = 6.1077
2024-10-30 14:53:24: [2024-10-30 14:53:24] iter = 07540, loss = 3.3577
2024-10-30 14:53:25: [2024-10-30 14:53:25] iter = 07550, loss = 2.3511
2024-10-30 14:53:25: [2024-10-30 14:53:25] iter = 07560, loss = 21.0116
2024-10-30 14:53:26: [2024-10-30 14:53:26] iter = 07570, loss = 1.7798
2024-10-30 14:53:26: [2024-10-30 14:53:26] iter = 07580, loss = 1.7562
2024-10-30 14:53:27: [2024-10-30 14:53:27] iter = 07590, loss = 1.4187
2024-10-30 14:53:27: [2024-10-30 14:53:27] iter = 07600, loss = 1.2940
2024-10-30 14:53:28: [2024-10-30 14:53:28] iter = 07610, loss = 22.0955
2024-10-30 14:53:28: [2024-10-30 14:53:28] iter = 07620, loss = 10.4661
2024-10-30 14:53:28: [2024-10-30 14:53:28] iter = 07630, loss = 10.1129
2024-10-30 14:53:29: [2024-10-30 14:53:29] iter = 07640, loss = 1.8069
2024-10-30 14:53:29: [2024-10-30 14:53:29] iter = 07650, loss = 2.1903
2024-10-30 14:53:30: [2024-10-30 14:53:30] iter = 07660, loss = 1.9344
2024-10-30 14:53:31: [2024-10-30 14:53:31] iter = 07670, loss = 1.1336
2024-10-30 14:53:31: [2024-10-30 14:53:31] iter = 07680, loss = 1.4595
2024-10-30 14:53:32: [2024-10-30 14:53:32] iter = 07690, loss = 9.1283
2024-10-30 14:53:32: [2024-10-30 14:53:32] iter = 07700, loss = 1.9875
2024-10-30 14:53:33: [2024-10-30 14:53:33] iter = 07710, loss = 1.7994
2024-10-30 14:53:34: [2024-10-30 14:53:34] iter = 07720, loss = 2.3864
2024-10-30 14:53:34: [2024-10-30 14:53:34] iter = 07730, loss = 12.3453
2024-10-30 14:53:35: [2024-10-30 14:53:35] iter = 07740, loss = 4.2869
2024-10-30 14:53:35: [2024-10-30 14:53:35] iter = 07750, loss = 2.9456
2024-10-30 14:53:36: [2024-10-30 14:53:36] iter = 07760, loss = 1.8648
2024-10-30 14:53:36: [2024-10-30 14:53:36] iter = 07770, loss = 2.6638
2024-10-30 14:53:37: [2024-10-30 14:53:37] iter = 07780, loss = 3.9505
2024-10-30 14:53:37: [2024-10-30 14:53:37] iter = 07790, loss = 1.5819
2024-10-30 14:53:37: [2024-10-30 14:53:37] iter = 07800, loss = 1.2427
2024-10-30 14:53:38: [2024-10-30 14:53:38] iter = 07810, loss = 1.7368
2024-10-30 14:53:39: [2024-10-30 14:53:39] iter = 07820, loss = 3.1806
2024-10-30 14:53:40: [2024-10-30 14:53:40] iter = 07830, loss = 2.6874
2024-10-30 14:53:40: [2024-10-30 14:53:40] iter = 07840, loss = 2.1717
2024-10-30 14:53:41: [2024-10-30 14:53:41] iter = 07850, loss = 1.3872
2024-10-30 14:53:41: [2024-10-30 14:53:41] iter = 07860, loss = 1.4792
2024-10-30 14:53:42: [2024-10-30 14:53:42] iter = 07870, loss = 3.9395
2024-10-30 14:53:42: [2024-10-30 14:53:42] iter = 07880, loss = 1.1932
2024-10-30 14:53:43: [2024-10-30 14:53:43] iter = 07890, loss = 3.8086
2024-10-30 14:53:44: [2024-10-30 14:53:44] iter = 07900, loss = 5.0356
2024-10-30 14:53:44: [2024-10-30 14:53:44] iter = 07910, loss = 12.5365
2024-10-30 14:53:45: [2024-10-30 14:53:45] iter = 07920, loss = 1.5373
2024-10-30 14:53:46: [2024-10-30 14:53:46] iter = 07930, loss = 9.1180
2024-10-30 14:53:46: [2024-10-30 14:53:46] iter = 07940, loss = 1.6901
2024-10-30 14:53:47: [2024-10-30 14:53:47] iter = 07950, loss = 8.2040
2024-10-30 14:53:48: [2024-10-30 14:53:48] iter = 07960, loss = 9.9783
2024-10-30 14:53:49: [2024-10-30 14:53:49] iter = 07970, loss = 31.3616
2024-10-30 14:53:49: [2024-10-30 14:53:49] iter = 07980, loss = 2.1231
2024-10-30 14:53:50: [2024-10-30 14:53:50] iter = 07990, loss = 3.1423
2024-10-30 14:53:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 14:53:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:53:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30731}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:54:53: Evaluate 5 random ConvNet, ACCmean = 0.6795 ACCstd = 0.0215
-------------------------
2024-10-30 14:54:53: Evaluate 5 random ConvNet, SENmean = 0.7281 SENstd = 0.0202
-------------------------
2024-10-30 14:54:53: Evaluate 5 random ConvNet, SPEmean = 0.7281 SPEstd = 0.0202
-------------------------
2024-10-30 14:54:53: Evaluate 5 random ConvNet, F!mean = 0.6614 F!std = 0.0202
-------------------------
2024-10-30 14:54:53: Evaluate 5 random ConvNet, mean = 0.6795 std = 0.0215
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:54:53: [2024-10-30 14:54:53] iter = 08000, loss = 1.9191
2024-10-30 14:54:54: [2024-10-30 14:54:54] iter = 08010, loss = 2.4401
2024-10-30 14:54:55: [2024-10-30 14:54:55] iter = 08020, loss = 1.3227
2024-10-30 14:54:55: [2024-10-30 14:54:55] iter = 08030, loss = 1.4931
2024-10-30 14:54:56: [2024-10-30 14:54:56] iter = 08040, loss = 2.5723
2024-10-30 14:54:56: [2024-10-30 14:54:56] iter = 08050, loss = 1.0031
2024-10-30 14:54:57: [2024-10-30 14:54:57] iter = 08060, loss = 1.8225
2024-10-30 14:54:58: [2024-10-30 14:54:57] iter = 08070, loss = 2.1870
2024-10-30 14:54:58: [2024-10-30 14:54:58] iter = 08080, loss = 2.0676
2024-10-30 14:54:59: [2024-10-30 14:54:59] iter = 08090, loss = 1.7418
2024-10-30 14:54:59: [2024-10-30 14:54:59] iter = 08100, loss = 1.5244
2024-10-30 14:55:00: [2024-10-30 14:55:00] iter = 08110, loss = 4.9743
2024-10-30 14:55:00: [2024-10-30 14:55:00] iter = 08120, loss = 27.1412
2024-10-30 14:55:01: [2024-10-30 14:55:01] iter = 08130, loss = 17.5131
2024-10-30 14:55:01: [2024-10-30 14:55:01] iter = 08140, loss = 5.3275
2024-10-30 14:55:02: [2024-10-30 14:55:02] iter = 08150, loss = 5.6455
2024-10-30 14:55:02: [2024-10-30 14:55:02] iter = 08160, loss = 7.5307
2024-10-30 14:55:03: [2024-10-30 14:55:03] iter = 08170, loss = 2.1770
2024-10-30 14:55:04: [2024-10-30 14:55:04] iter = 08180, loss = 4.4828
2024-10-30 14:55:04: [2024-10-30 14:55:04] iter = 08190, loss = 2.2045
2024-10-30 14:55:05: [2024-10-30 14:55:05] iter = 08200, loss = 3.9460
2024-10-30 14:55:05: [2024-10-30 14:55:05] iter = 08210, loss = 2.2700
2024-10-30 14:55:05: [2024-10-30 14:55:05] iter = 08220, loss = 8.7625
2024-10-30 14:55:06: [2024-10-30 14:55:06] iter = 08230, loss = 1.9702
2024-10-30 14:55:07: [2024-10-30 14:55:07] iter = 08240, loss = 3.8266
2024-10-30 14:55:07: [2024-10-30 14:55:07] iter = 08250, loss = 3.6259
2024-10-30 14:55:08: [2024-10-30 14:55:08] iter = 08260, loss = 4.7174
2024-10-30 14:55:08: [2024-10-30 14:55:08] iter = 08270, loss = 2.7987
2024-10-30 14:55:09: [2024-10-30 14:55:08] iter = 08280, loss = 1.5111
2024-10-30 14:55:09: [2024-10-30 14:55:09] iter = 08290, loss = 1.6426
2024-10-30 14:55:10: [2024-10-30 14:55:10] iter = 08300, loss = 5.4793
2024-10-30 14:55:10: [2024-10-30 14:55:10] iter = 08310, loss = 5.5145
2024-10-30 14:55:10: [2024-10-30 14:55:10] iter = 08320, loss = 4.5034
2024-10-30 14:55:11: [2024-10-30 14:55:11] iter = 08330, loss = 3.4576
2024-10-30 14:55:12: [2024-10-30 14:55:12] iter = 08340, loss = 12.4688
2024-10-30 14:55:12: [2024-10-30 14:55:12] iter = 08350, loss = 1.9845
2024-10-30 14:55:13: [2024-10-30 14:55:13] iter = 08360, loss = 1.7917
2024-10-30 14:55:13: [2024-10-30 14:55:13] iter = 08370, loss = 2.5416
2024-10-30 14:55:14: [2024-10-30 14:55:14] iter = 08380, loss = 2.0275
2024-10-30 14:55:14: [2024-10-30 14:55:14] iter = 08390, loss = 1.6709
2024-10-30 14:55:15: [2024-10-30 14:55:15] iter = 08400, loss = 8.4843
2024-10-30 14:55:15: [2024-10-30 14:55:15] iter = 08410, loss = 7.5075
2024-10-30 14:55:15: [2024-10-30 14:55:15] iter = 08420, loss = 1.5397
2024-10-30 14:55:16: [2024-10-30 14:55:16] iter = 08430, loss = 2.5855
2024-10-30 14:55:16: [2024-10-30 14:55:16] iter = 08440, loss = 3.7421
2024-10-30 14:55:17: [2024-10-30 14:55:17] iter = 08450, loss = 2.9564
2024-10-30 14:55:17: [2024-10-30 14:55:17] iter = 08460, loss = 1.8182
2024-10-30 14:55:18: [2024-10-30 14:55:18] iter = 08470, loss = 1.5322
2024-10-30 14:55:18: [2024-10-30 14:55:18] iter = 08480, loss = 11.7710
2024-10-30 14:55:18: [2024-10-30 14:55:18] iter = 08490, loss = 8.9313
2024-10-30 14:55:19: [2024-10-30 14:55:19] iter = 08500, loss = 3.4853
2024-10-30 14:55:19: [2024-10-30 14:55:19] iter = 08510, loss = 2.2023
2024-10-30 14:55:20: [2024-10-30 14:55:20] iter = 08520, loss = 1.3620
2024-10-30 14:55:20: [2024-10-30 14:55:20] iter = 08530, loss = 1.4768
2024-10-30 14:55:21: [2024-10-30 14:55:21] iter = 08540, loss = 3.3592
2024-10-30 14:55:21: [2024-10-30 14:55:21] iter = 08550, loss = 2.1322
2024-10-30 14:55:22: [2024-10-30 14:55:22] iter = 08560, loss = 1.4857
2024-10-30 14:55:22: [2024-10-30 14:55:22] iter = 08570, loss = 3.2965
2024-10-30 14:55:23: [2024-10-30 14:55:23] iter = 08580, loss = 7.2603
2024-10-30 14:55:23: [2024-10-30 14:55:23] iter = 08590, loss = 4.3365
2024-10-30 14:55:23: [2024-10-30 14:55:23] iter = 08600, loss = 8.0256
2024-10-30 14:55:24: [2024-10-30 14:55:24] iter = 08610, loss = 9.1079
2024-10-30 14:55:24: [2024-10-30 14:55:24] iter = 08620, loss = 11.2835
2024-10-30 14:55:24: [2024-10-30 14:55:24] iter = 08630, loss = 5.3444
2024-10-30 14:55:25: [2024-10-30 14:55:25] iter = 08640, loss = 5.5231
2024-10-30 14:55:25: [2024-10-30 14:55:25] iter = 08650, loss = 1.1316
2024-10-30 14:55:26: [2024-10-30 14:55:26] iter = 08660, loss = 5.4364
2024-10-30 14:55:26: [2024-10-30 14:55:26] iter = 08670, loss = 3.4930
2024-10-30 14:55:27: [2024-10-30 14:55:27] iter = 08680, loss = 7.3943
2024-10-30 14:55:27: [2024-10-30 14:55:27] iter = 08690, loss = 3.5067
2024-10-30 14:55:28: [2024-10-30 14:55:28] iter = 08700, loss = 1.9541
2024-10-30 14:55:28: [2024-10-30 14:55:28] iter = 08710, loss = 3.5633
2024-10-30 14:55:29: [2024-10-30 14:55:29] iter = 08720, loss = 3.5715
2024-10-30 14:55:29: [2024-10-30 14:55:29] iter = 08730, loss = 2.1596
2024-10-30 14:55:30: [2024-10-30 14:55:30] iter = 08740, loss = 1.2163
2024-10-30 14:55:31: [2024-10-30 14:55:31] iter = 08750, loss = 4.6918
2024-10-30 14:55:31: [2024-10-30 14:55:31] iter = 08760, loss = 1.2197
2024-10-30 14:55:32: [2024-10-30 14:55:32] iter = 08770, loss = 8.1494
2024-10-30 14:55:32: [2024-10-30 14:55:32] iter = 08780, loss = 1.9023
2024-10-30 14:55:33: [2024-10-30 14:55:33] iter = 08790, loss = 4.8609
2024-10-30 14:55:33: [2024-10-30 14:55:33] iter = 08800, loss = 2.6557
2024-10-30 14:55:34: [2024-10-30 14:55:34] iter = 08810, loss = 8.0831
2024-10-30 14:55:35: [2024-10-30 14:55:35] iter = 08820, loss = 1.7275
2024-10-30 14:55:35: [2024-10-30 14:55:35] iter = 08830, loss = 4.2998
2024-10-30 14:55:36: [2024-10-30 14:55:36] iter = 08840, loss = 2.3353
2024-10-30 14:55:36: [2024-10-30 14:55:36] iter = 08850, loss = 1.1222
2024-10-30 14:55:37: [2024-10-30 14:55:37] iter = 08860, loss = 12.1099
2024-10-30 14:55:37: [2024-10-30 14:55:37] iter = 08870, loss = 1.6973
2024-10-30 14:55:38: [2024-10-30 14:55:38] iter = 08880, loss = 2.7030
2024-10-30 14:55:38: [2024-10-30 14:55:38] iter = 08890, loss = 4.1589
2024-10-30 14:55:39: [2024-10-30 14:55:39] iter = 08900, loss = 4.2114
2024-10-30 14:55:39: [2024-10-30 14:55:39] iter = 08910, loss = 2.8144
2024-10-30 14:55:40: [2024-10-30 14:55:40] iter = 08920, loss = 1.5564
2024-10-30 14:55:40: [2024-10-30 14:55:40] iter = 08930, loss = 16.3549
2024-10-30 14:55:41: [2024-10-30 14:55:41] iter = 08940, loss = 2.8581
2024-10-30 14:55:41: [2024-10-30 14:55:41] iter = 08950, loss = 4.2370
2024-10-30 14:55:42: [2024-10-30 14:55:42] iter = 08960, loss = 2.6972
2024-10-30 14:55:42: [2024-10-30 14:55:42] iter = 08970, loss = 2.4818
2024-10-30 14:55:42: [2024-10-30 14:55:42] iter = 08980, loss = 1.2714
2024-10-30 14:55:43: [2024-10-30 14:55:43] iter = 08990, loss = 5.2194
2024-10-30 14:55:43: [2024-10-30 14:55:43] iter = 09000, loss = 1.5857
2024-10-30 14:55:44: [2024-10-30 14:55:44] iter = 09010, loss = 2.7660
2024-10-30 14:55:44: [2024-10-30 14:55:44] iter = 09020, loss = 2.6985
2024-10-30 14:55:45: [2024-10-30 14:55:45] iter = 09030, loss = 4.7312
2024-10-30 14:55:45: [2024-10-30 14:55:45] iter = 09040, loss = 1.9209
2024-10-30 14:55:46: [2024-10-30 14:55:46] iter = 09050, loss = 1.4242
2024-10-30 14:55:46: [2024-10-30 14:55:46] iter = 09060, loss = 1.7716
2024-10-30 14:55:46: [2024-10-30 14:55:46] iter = 09070, loss = 2.1179
2024-10-30 14:55:47: [2024-10-30 14:55:47] iter = 09080, loss = 1.3897
2024-10-30 14:55:47: [2024-10-30 14:55:47] iter = 09090, loss = 1.0580
2024-10-30 14:55:48: [2024-10-30 14:55:48] iter = 09100, loss = 4.2632
2024-10-30 14:55:48: [2024-10-30 14:55:48] iter = 09110, loss = 15.9679
2024-10-30 14:55:49: [2024-10-30 14:55:49] iter = 09120, loss = 2.4008
2024-10-30 14:55:49: [2024-10-30 14:55:49] iter = 09130, loss = 1.0704
2024-10-30 14:55:49: [2024-10-30 14:55:49] iter = 09140, loss = 2.7197
2024-10-30 14:55:50: [2024-10-30 14:55:50] iter = 09150, loss = 4.3213
2024-10-30 14:55:50: [2024-10-30 14:55:50] iter = 09160, loss = 3.4887
2024-10-30 14:55:51: [2024-10-30 14:55:51] iter = 09170, loss = 3.0313
2024-10-30 14:55:51: [2024-10-30 14:55:51] iter = 09180, loss = 4.7745
2024-10-30 14:55:52: [2024-10-30 14:55:52] iter = 09190, loss = 7.8203
2024-10-30 14:55:52: [2024-10-30 14:55:52] iter = 09200, loss = 1.9439
2024-10-30 14:55:53: [2024-10-30 14:55:53] iter = 09210, loss = 2.8268
2024-10-30 14:55:53: [2024-10-30 14:55:53] iter = 09220, loss = 2.0909
2024-10-30 14:55:54: [2024-10-30 14:55:54] iter = 09230, loss = 1.8580
2024-10-30 14:55:54: [2024-10-30 14:55:54] iter = 09240, loss = 1.9175
2024-10-30 14:55:55: [2024-10-30 14:55:55] iter = 09250, loss = 1.5699
2024-10-30 14:55:55: [2024-10-30 14:55:55] iter = 09260, loss = 2.1537
2024-10-30 14:55:56: [2024-10-30 14:55:56] iter = 09270, loss = 1.7277
2024-10-30 14:55:57: [2024-10-30 14:55:57] iter = 09280, loss = 3.4684
2024-10-30 14:55:57: [2024-10-30 14:55:57] iter = 09290, loss = 1.2701
2024-10-30 14:55:58: [2024-10-30 14:55:58] iter = 09300, loss = 6.1692
2024-10-30 14:55:58: [2024-10-30 14:55:58] iter = 09310, loss = 8.5702
2024-10-30 14:55:59: [2024-10-30 14:55:59] iter = 09320, loss = 1.8786
2024-10-30 14:55:59: [2024-10-30 14:55:59] iter = 09330, loss = 2.4662
2024-10-30 14:56:00: [2024-10-30 14:56:00] iter = 09340, loss = 3.6092
2024-10-30 14:56:01: [2024-10-30 14:56:01] iter = 09350, loss = 2.3621
2024-10-30 14:56:01: [2024-10-30 14:56:01] iter = 09360, loss = 2.6833
2024-10-30 14:56:02: [2024-10-30 14:56:02] iter = 09370, loss = 1.7325
2024-10-30 14:56:02: [2024-10-30 14:56:02] iter = 09380, loss = 1.3366
2024-10-30 14:56:03: [2024-10-30 14:56:03] iter = 09390, loss = 3.7129
2024-10-30 14:56:03: [2024-10-30 14:56:03] iter = 09400, loss = 2.1281
2024-10-30 14:56:04: [2024-10-30 14:56:04] iter = 09410, loss = 1.2828
2024-10-30 14:56:05: [2024-10-30 14:56:05] iter = 09420, loss = 2.7773
2024-10-30 14:56:05: [2024-10-30 14:56:05] iter = 09430, loss = 7.8739
2024-10-30 14:56:06: [2024-10-30 14:56:06] iter = 09440, loss = 1.3537
2024-10-30 14:56:06: [2024-10-30 14:56:06] iter = 09450, loss = 9.8211
2024-10-30 14:56:07: [2024-10-30 14:56:07] iter = 09460, loss = 2.9041
2024-10-30 14:56:07: [2024-10-30 14:56:07] iter = 09470, loss = 4.2338
2024-10-30 14:56:08: [2024-10-30 14:56:08] iter = 09480, loss = 2.9379
2024-10-30 14:56:08: [2024-10-30 14:56:08] iter = 09490, loss = 1.5844
2024-10-30 14:56:09: [2024-10-30 14:56:09] iter = 09500, loss = 1.4030
2024-10-30 14:56:09: [2024-10-30 14:56:09] iter = 09510, loss = 3.7052
2024-10-30 14:56:10: [2024-10-30 14:56:10] iter = 09520, loss = 12.6629
2024-10-30 14:56:10: [2024-10-30 14:56:10] iter = 09530, loss = 2.4700
2024-10-30 14:56:11: [2024-10-30 14:56:11] iter = 09540, loss = 4.6301
2024-10-30 14:56:12: [2024-10-30 14:56:12] iter = 09550, loss = 1.6735
2024-10-30 14:56:12: [2024-10-30 14:56:12] iter = 09560, loss = 4.8059
2024-10-30 14:56:13: [2024-10-30 14:56:13] iter = 09570, loss = 1.2831
2024-10-30 14:56:14: [2024-10-30 14:56:14] iter = 09580, loss = 3.5923
2024-10-30 14:56:14: [2024-10-30 14:56:14] iter = 09590, loss = 1.1317
2024-10-30 14:56:15: [2024-10-30 14:56:15] iter = 09600, loss = 3.5003
2024-10-30 14:56:16: [2024-10-30 14:56:16] iter = 09610, loss = 19.5561
2024-10-30 14:56:16: [2024-10-30 14:56:16] iter = 09620, loss = 17.1161
2024-10-30 14:56:17: [2024-10-30 14:56:17] iter = 09630, loss = 1.9406
2024-10-30 14:56:17: [2024-10-30 14:56:17] iter = 09640, loss = 1.2269
2024-10-30 14:56:18: [2024-10-30 14:56:18] iter = 09650, loss = 7.0585
2024-10-30 14:56:19: [2024-10-30 14:56:19] iter = 09660, loss = 1.2939
2024-10-30 14:56:20: [2024-10-30 14:56:20] iter = 09670, loss = 1.7836
2024-10-30 14:56:20: [2024-10-30 14:56:20] iter = 09680, loss = 5.3498
2024-10-30 14:56:21: [2024-10-30 14:56:21] iter = 09690, loss = 2.3134
2024-10-30 14:56:22: [2024-10-30 14:56:22] iter = 09700, loss = 12.4657
2024-10-30 14:56:22: [2024-10-30 14:56:22] iter = 09710, loss = 3.3014
2024-10-30 14:56:23: [2024-10-30 14:56:23] iter = 09720, loss = 11.7161
2024-10-30 14:56:24: [2024-10-30 14:56:24] iter = 09730, loss = 5.9943
2024-10-30 14:56:24: [2024-10-30 14:56:24] iter = 09740, loss = 4.3106
2024-10-30 14:56:25: [2024-10-30 14:56:25] iter = 09750, loss = 2.9022
2024-10-30 14:56:26: [2024-10-30 14:56:26] iter = 09760, loss = 1.6061
2024-10-30 14:56:26: [2024-10-30 14:56:26] iter = 09770, loss = 3.5867
2024-10-30 14:56:27: [2024-10-30 14:56:27] iter = 09780, loss = 5.4783
2024-10-30 14:56:28: [2024-10-30 14:56:28] iter = 09790, loss = 2.2516
2024-10-30 14:56:28: [2024-10-30 14:56:28] iter = 09800, loss = 1.4031
2024-10-30 14:56:29: [2024-10-30 14:56:29] iter = 09810, loss = 2.4796
2024-10-30 14:56:29: [2024-10-30 14:56:29] iter = 09820, loss = 9.3625
2024-10-30 14:56:29: [2024-10-30 14:56:29] iter = 09830, loss = 1.5237
2024-10-30 14:56:30: [2024-10-30 14:56:30] iter = 09840, loss = 4.5212
2024-10-30 14:56:31: [2024-10-30 14:56:31] iter = 09850, loss = 7.1834
2024-10-30 14:56:31: [2024-10-30 14:56:31] iter = 09860, loss = 1.8819
2024-10-30 14:56:32: [2024-10-30 14:56:32] iter = 09870, loss = 1.7263
2024-10-30 14:56:33: [2024-10-30 14:56:33] iter = 09880, loss = 17.9095
2024-10-30 14:56:33: [2024-10-30 14:56:33] iter = 09890, loss = 2.8299
2024-10-30 14:56:34: [2024-10-30 14:56:34] iter = 09900, loss = 3.9081
2024-10-30 14:56:34: [2024-10-30 14:56:34] iter = 09910, loss = 3.7992
2024-10-30 14:56:35: [2024-10-30 14:56:35] iter = 09920, loss = 2.0955
2024-10-30 14:56:35: [2024-10-30 14:56:35] iter = 09930, loss = 2.8054
2024-10-30 14:56:36: [2024-10-30 14:56:36] iter = 09940, loss = 3.8225
2024-10-30 14:56:36: [2024-10-30 14:56:36] iter = 09950, loss = 1.5434
2024-10-30 14:56:37: [2024-10-30 14:56:37] iter = 09960, loss = 7.0109
2024-10-30 14:56:37: [2024-10-30 14:56:37] iter = 09970, loss = 2.9802
2024-10-30 14:56:38: [2024-10-30 14:56:38] iter = 09980, loss = 3.1240
2024-10-30 14:56:38: [2024-10-30 14:56:38] iter = 09990, loss = 3.9930
2024-10-30 14:56:38: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 14:56:38: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:56:38: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 98953}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:57:53: Evaluate 5 random ConvNet, ACCmean = 0.7590 ACCstd = 0.0077
-------------------------
2024-10-30 14:57:53: Evaluate 5 random ConvNet, SENmean = 0.6757 SENstd = 0.0050
-------------------------
2024-10-30 14:57:53: Evaluate 5 random ConvNet, SPEmean = 0.6757 SPEstd = 0.0050
-------------------------
2024-10-30 14:57:53: Evaluate 5 random ConvNet, F!mean = 0.6818 F!std = 0.0057
-------------------------
2024-10-30 14:57:53: Evaluate 5 random ConvNet, mean = 0.7590 std = 0.0077
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:57:53: [2024-10-30 14:57:53] iter = 10000, loss = 3.7588
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:57:54: [2024-10-30 14:57:54] iter = 10010, loss = 2.5325
2024-10-30 14:57:56: [2024-10-30 14:57:56] iter = 10020, loss = 1.6226
2024-10-30 14:57:57: [2024-10-30 14:57:57] iter = 10030, loss = 1.4523
2024-10-30 14:57:58: [2024-10-30 14:57:58] iter = 10040, loss = 1.6783
2024-10-30 14:57:59: [2024-10-30 14:57:59] iter = 10050, loss = 2.6778
2024-10-30 14:58:00: [2024-10-30 14:58:00] iter = 10060, loss = 1.7793
2024-10-30 14:58:01: [2024-10-30 14:58:01] iter = 10070, loss = 3.5946
2024-10-30 14:58:02: [2024-10-30 14:58:02] iter = 10080, loss = 17.4377
2024-10-30 14:58:03: [2024-10-30 14:58:03] iter = 10090, loss = 1.8230
2024-10-30 14:58:03: [2024-10-30 14:58:03] iter = 10100, loss = 3.0912
2024-10-30 14:58:04: [2024-10-30 14:58:04] iter = 10110, loss = 4.4688
2024-10-30 14:58:04: [2024-10-30 14:58:04] iter = 10120, loss = 17.1017
2024-10-30 14:58:05: [2024-10-30 14:58:05] iter = 10130, loss = 1.1160
2024-10-30 14:58:05: [2024-10-30 14:58:05] iter = 10140, loss = 1.6263
2024-10-30 14:58:06: [2024-10-30 14:58:06] iter = 10150, loss = 2.2046
2024-10-30 14:58:07: [2024-10-30 14:58:07] iter = 10160, loss = 27.2965
2024-10-30 14:58:07: [2024-10-30 14:58:07] iter = 10170, loss = 4.0830
2024-10-30 14:58:08: [2024-10-30 14:58:08] iter = 10180, loss = 1.6208
2024-10-30 14:58:09: [2024-10-30 14:58:09] iter = 10190, loss = 3.3806
2024-10-30 14:58:09: [2024-10-30 14:58:09] iter = 10200, loss = 2.2322
2024-10-30 14:58:10: [2024-10-30 14:58:10] iter = 10210, loss = 1.6846
2024-10-30 14:58:11: [2024-10-30 14:58:11] iter = 10220, loss = 3.3357
2024-10-30 14:58:12: [2024-10-30 14:58:12] iter = 10230, loss = 1.7017
2024-10-30 14:58:13: [2024-10-30 14:58:13] iter = 10240, loss = 7.5881
2024-10-30 14:58:14: [2024-10-30 14:58:14] iter = 10250, loss = 1.5045
2024-10-30 14:58:15: [2024-10-30 14:58:15] iter = 10260, loss = 3.2599
2024-10-30 14:58:16: [2024-10-30 14:58:16] iter = 10270, loss = 1.4210
2024-10-30 14:58:16: [2024-10-30 14:58:16] iter = 10280, loss = 1.9772
2024-10-30 14:58:18: [2024-10-30 14:58:18] iter = 10290, loss = 1.7731
2024-10-30 14:58:18: [2024-10-30 14:58:18] iter = 10300, loss = 2.9430
2024-10-30 14:58:20: [2024-10-30 14:58:20] iter = 10310, loss = 1.4434
2024-10-30 14:58:20: [2024-10-30 14:58:20] iter = 10320, loss = 2.2886
2024-10-30 14:58:21: [2024-10-30 14:58:21] iter = 10330, loss = 3.0579
2024-10-30 14:58:22: [2024-10-30 14:58:22] iter = 10340, loss = 9.9855
2024-10-30 14:58:23: [2024-10-30 14:58:23] iter = 10350, loss = 15.9243
2024-10-30 14:58:24: [2024-10-30 14:58:24] iter = 10360, loss = 5.2152
2024-10-30 14:58:25: [2024-10-30 14:58:25] iter = 10370, loss = 1.9672
2024-10-30 14:58:26: [2024-10-30 14:58:26] iter = 10380, loss = 5.5446
2024-10-30 14:58:27: [2024-10-30 14:58:27] iter = 10390, loss = 1.3532
2024-10-30 14:58:28: [2024-10-30 14:58:28] iter = 10400, loss = 1.2017
2024-10-30 14:58:29: [2024-10-30 14:58:29] iter = 10410, loss = 3.2409
2024-10-30 14:58:31: [2024-10-30 14:58:31] iter = 10420, loss = 1.6316
2024-10-30 14:58:32: [2024-10-30 14:58:32] iter = 10430, loss = 3.3181
2024-10-30 14:58:33: [2024-10-30 14:58:33] iter = 10440, loss = 11.4836
2024-10-30 14:58:34: [2024-10-30 14:58:34] iter = 10450, loss = 6.6455
2024-10-30 14:58:35: [2024-10-30 14:58:35] iter = 10460, loss = 4.0979
2024-10-30 14:58:36: [2024-10-30 14:58:36] iter = 10470, loss = 14.7679
2024-10-30 14:58:37: [2024-10-30 14:58:37] iter = 10480, loss = 4.0110
2024-10-30 14:58:38: [2024-10-30 14:58:38] iter = 10490, loss = 4.8396
2024-10-30 14:58:39: [2024-10-30 14:58:39] iter = 10500, loss = 17.2267
2024-10-30 14:58:40: [2024-10-30 14:58:40] iter = 10510, loss = 8.4696
2024-10-30 14:58:41: [2024-10-30 14:58:41] iter = 10520, loss = 1.4427
2024-10-30 14:58:42: [2024-10-30 14:58:42] iter = 10530, loss = 2.7115
2024-10-30 14:58:43: [2024-10-30 14:58:43] iter = 10540, loss = 5.5857
2024-10-30 14:58:44: [2024-10-30 14:58:44] iter = 10550, loss = 2.1418
2024-10-30 14:58:45: [2024-10-30 14:58:45] iter = 10560, loss = 2.3877
2024-10-30 14:58:46: [2024-10-30 14:58:46] iter = 10570, loss = 3.0420
2024-10-30 14:58:47: [2024-10-30 14:58:47] iter = 10580, loss = 2.9070
2024-10-30 14:58:48: [2024-10-30 14:58:48] iter = 10590, loss = 9.0646
2024-10-30 14:58:48: [2024-10-30 14:58:48] iter = 10600, loss = 22.2478
2024-10-30 14:58:50: [2024-10-30 14:58:50] iter = 10610, loss = 1.3776
2024-10-30 14:58:51: [2024-10-30 14:58:51] iter = 10620, loss = 12.8274
2024-10-30 14:58:52: [2024-10-30 14:58:52] iter = 10630, loss = 1.5900
2024-10-30 14:58:52: [2024-10-30 14:58:52] iter = 10640, loss = 1.4944
2024-10-30 14:58:53: [2024-10-30 14:58:53] iter = 10650, loss = 1.1990
2024-10-30 14:58:54: [2024-10-30 14:58:54] iter = 10660, loss = 1.9409
2024-10-30 14:58:55: [2024-10-30 14:58:55] iter = 10670, loss = 1.5961
2024-10-30 14:58:56: [2024-10-30 14:58:56] iter = 10680, loss = 3.7341
2024-10-30 14:58:57: [2024-10-30 14:58:57] iter = 10690, loss = 13.3810
2024-10-30 14:58:58: [2024-10-30 14:58:58] iter = 10700, loss = 2.7786
2024-10-30 14:58:59: [2024-10-30 14:58:59] iter = 10710, loss = 1.2416
2024-10-30 14:59:00: [2024-10-30 14:59:00] iter = 10720, loss = 1.5608
2024-10-30 14:59:01: [2024-10-30 14:59:01] iter = 10730, loss = 4.2973
2024-10-30 14:59:02: [2024-10-30 14:59:02] iter = 10740, loss = 4.0200
2024-10-30 14:59:03: [2024-10-30 14:59:03] iter = 10750, loss = 1.3386
2024-10-30 14:59:04: [2024-10-30 14:59:04] iter = 10760, loss = 1.0990
2024-10-30 14:59:04: [2024-10-30 14:59:04] iter = 10770, loss = 1.2821
2024-10-30 14:59:06: [2024-10-30 14:59:06] iter = 10780, loss = 2.8826
2024-10-30 14:59:06: [2024-10-30 14:59:06] iter = 10790, loss = 1.7883
2024-10-30 14:59:07: [2024-10-30 14:59:07] iter = 10800, loss = 3.3993
2024-10-30 14:59:08: [2024-10-30 14:59:08] iter = 10810, loss = 1.6003
2024-10-30 14:59:09: [2024-10-30 14:59:09] iter = 10820, loss = 5.4504
2024-10-30 14:59:10: [2024-10-30 14:59:10] iter = 10830, loss = 7.9255
2024-10-30 14:59:10: [2024-10-30 14:59:10] iter = 10840, loss = 1.3479
2024-10-30 14:59:11: [2024-10-30 14:59:11] iter = 10850, loss = 2.3987
2024-10-30 14:59:12: [2024-10-30 14:59:12] iter = 10860, loss = 7.6532
2024-10-30 14:59:13: [2024-10-30 14:59:13] iter = 10870, loss = 9.7812
2024-10-30 14:59:14: [2024-10-30 14:59:14] iter = 10880, loss = 2.2529
2024-10-30 14:59:15: [2024-10-30 14:59:15] iter = 10890, loss = 1.6463
2024-10-30 14:59:16: [2024-10-30 14:59:16] iter = 10900, loss = 15.7919
2024-10-30 14:59:16: [2024-10-30 14:59:16] iter = 10910, loss = 1.9665
2024-10-30 14:59:17: [2024-10-30 14:59:17] iter = 10920, loss = 21.4601
2024-10-30 14:59:18: [2024-10-30 14:59:18] iter = 10930, loss = 7.2784
2024-10-30 14:59:20: [2024-10-30 14:59:20] iter = 10940, loss = 1.5258
2024-10-30 14:59:20: [2024-10-30 14:59:20] iter = 10950, loss = 1.6128
2024-10-30 14:59:21: [2024-10-30 14:59:21] iter = 10960, loss = 1.0838
2024-10-30 14:59:22: [2024-10-30 14:59:22] iter = 10970, loss = 2.2749
2024-10-30 14:59:23: [2024-10-30 14:59:23] iter = 10980, loss = 4.2417
2024-10-30 14:59:24: [2024-10-30 14:59:24] iter = 10990, loss = 4.4215
2024-10-30 14:59:25: [2024-10-30 14:59:25] iter = 11000, loss = 5.2237
2024-10-30 14:59:26: [2024-10-30 14:59:26] iter = 11010, loss = 6.0334
2024-10-30 14:59:27: [2024-10-30 14:59:27] iter = 11020, loss = 4.8869
2024-10-30 14:59:28: [2024-10-30 14:59:28] iter = 11030, loss = 2.3088
2024-10-30 14:59:29: [2024-10-30 14:59:29] iter = 11040, loss = 12.8371
2024-10-30 14:59:30: [2024-10-30 14:59:30] iter = 11050, loss = 2.7596
2024-10-30 14:59:31: [2024-10-30 14:59:31] iter = 11060, loss = 9.5927
2024-10-30 14:59:32: [2024-10-30 14:59:32] iter = 11070, loss = 5.1878
2024-10-30 14:59:33: [2024-10-30 14:59:33] iter = 11080, loss = 6.5792
2024-10-30 14:59:34: [2024-10-30 14:59:34] iter = 11090, loss = 1.9606
2024-10-30 14:59:34: [2024-10-30 14:59:34] iter = 11100, loss = 11.6458
2024-10-30 14:59:35: [2024-10-30 14:59:35] iter = 11110, loss = 1.5649
2024-10-30 14:59:36: [2024-10-30 14:59:36] iter = 11120, loss = 1.7467
2024-10-30 14:59:37: [2024-10-30 14:59:37] iter = 11130, loss = 12.5962
2024-10-30 14:59:38: [2024-10-30 14:59:38] iter = 11140, loss = 2.1678
2024-10-30 14:59:38: [2024-10-30 14:59:38] iter = 11150, loss = 2.0255
2024-10-30 14:59:39: [2024-10-30 14:59:39] iter = 11160, loss = 2.9361
2024-10-30 14:59:39: [2024-10-30 14:59:39] iter = 11170, loss = 19.8632
2024-10-30 14:59:40: [2024-10-30 14:59:40] iter = 11180, loss = 3.9916
2024-10-30 14:59:41: [2024-10-30 14:59:41] iter = 11190, loss = 9.4996
2024-10-30 14:59:41: [2024-10-30 14:59:41] iter = 11200, loss = 2.2840
2024-10-30 14:59:42: [2024-10-30 14:59:42] iter = 11210, loss = 2.6528
2024-10-30 14:59:43: [2024-10-30 14:59:43] iter = 11220, loss = 2.0722
2024-10-30 14:59:43: [2024-10-30 14:59:43] iter = 11230, loss = 4.3526
2024-10-30 14:59:44: [2024-10-30 14:59:44] iter = 11240, loss = 2.8647
2024-10-30 14:59:45: [2024-10-30 14:59:45] iter = 11250, loss = 5.9425
2024-10-30 14:59:46: [2024-10-30 14:59:46] iter = 11260, loss = 4.8301
2024-10-30 14:59:47: [2024-10-30 14:59:47] iter = 11270, loss = 2.5035
2024-10-30 14:59:47: [2024-10-30 14:59:47] iter = 11280, loss = 3.8910
2024-10-30 14:59:48: [2024-10-30 14:59:48] iter = 11290, loss = 3.2730
2024-10-30 14:59:49: [2024-10-30 14:59:49] iter = 11300, loss = 2.2052
2024-10-30 14:59:50: [2024-10-30 14:59:50] iter = 11310, loss = 1.3937
2024-10-30 14:59:50: [2024-10-30 14:59:50] iter = 11320, loss = 3.1612
2024-10-30 14:59:51: [2024-10-30 14:59:51] iter = 11330, loss = 5.7068
2024-10-30 14:59:51: [2024-10-30 14:59:51] iter = 11340, loss = 1.7210
2024-10-30 14:59:52: [2024-10-30 14:59:52] iter = 11350, loss = 1.6490
2024-10-30 14:59:53: [2024-10-30 14:59:53] iter = 11360, loss = 7.2135
2024-10-30 14:59:54: [2024-10-30 14:59:54] iter = 11370, loss = 3.9242
2024-10-30 14:59:55: [2024-10-30 14:59:55] iter = 11380, loss = 5.0132
2024-10-30 14:59:56: [2024-10-30 14:59:56] iter = 11390, loss = 1.6030
2024-10-30 14:59:57: [2024-10-30 14:59:57] iter = 11400, loss = 2.3110
2024-10-30 14:59:57: [2024-10-30 14:59:57] iter = 11410, loss = 13.2747
2024-10-30 14:59:58: [2024-10-30 14:59:58] iter = 11420, loss = 10.0242
2024-10-30 14:59:59: [2024-10-30 14:59:59] iter = 11430, loss = 8.0819
2024-10-30 15:00:00: [2024-10-30 15:00:00] iter = 11440, loss = 1.6854
2024-10-30 15:00:01: [2024-10-30 15:00:01] iter = 11450, loss = 3.4126
2024-10-30 15:00:02: [2024-10-30 15:00:02] iter = 11460, loss = 0.9601
2024-10-30 15:00:03: [2024-10-30 15:00:03] iter = 11470, loss = 31.7457
2024-10-30 15:00:03: [2024-10-30 15:00:03] iter = 11480, loss = 1.2984
2024-10-30 15:00:04: [2024-10-30 15:00:04] iter = 11490, loss = 10.2006
2024-10-30 15:00:05: [2024-10-30 15:00:05] iter = 11500, loss = 1.6836
2024-10-30 15:00:06: [2024-10-30 15:00:06] iter = 11510, loss = 2.9393
2024-10-30 15:00:07: [2024-10-30 15:00:07] iter = 11520, loss = 6.5413
2024-10-30 15:00:08: [2024-10-30 15:00:08] iter = 11530, loss = 12.4350
2024-10-30 15:00:09: [2024-10-30 15:00:09] iter = 11540, loss = 24.7539
2024-10-30 15:00:10: [2024-10-30 15:00:10] iter = 11550, loss = 2.6012
2024-10-30 15:00:11: [2024-10-30 15:00:11] iter = 11560, loss = 4.4493
2024-10-30 15:00:12: [2024-10-30 15:00:12] iter = 11570, loss = 1.2514
2024-10-30 15:00:12: [2024-10-30 15:00:12] iter = 11580, loss = 1.4078
2024-10-30 15:00:12: [2024-10-30 15:00:12] iter = 11590, loss = 3.3165
2024-10-30 15:00:14: [2024-10-30 15:00:14] iter = 11600, loss = 1.8333
2024-10-30 15:00:15: [2024-10-30 15:00:15] iter = 11610, loss = 11.2102
2024-10-30 15:00:16: [2024-10-30 15:00:16] iter = 11620, loss = 1.5474
2024-10-30 15:00:17: [2024-10-30 15:00:17] iter = 11630, loss = 1.1148
2024-10-30 15:00:18: [2024-10-30 15:00:18] iter = 11640, loss = 2.3460
2024-10-30 15:00:19: [2024-10-30 15:00:19] iter = 11650, loss = 1.3771
2024-10-30 15:00:19: [2024-10-30 15:00:19] iter = 11660, loss = 3.3250
2024-10-30 15:00:20: [2024-10-30 15:00:20] iter = 11670, loss = 1.2684
2024-10-30 15:00:21: [2024-10-30 15:00:21] iter = 11680, loss = 2.1549
2024-10-30 15:00:22: [2024-10-30 15:00:22] iter = 11690, loss = 1.9493
2024-10-30 15:00:23: [2024-10-30 15:00:23] iter = 11700, loss = 19.5519
2024-10-30 15:00:24: [2024-10-30 15:00:24] iter = 11710, loss = 2.1238
2024-10-30 15:00:25: [2024-10-30 15:00:25] iter = 11720, loss = 1.5671
2024-10-30 15:00:26: [2024-10-30 15:00:26] iter = 11730, loss = 1.8403
2024-10-30 15:00:27: [2024-10-30 15:00:27] iter = 11740, loss = 1.2737
2024-10-30 15:00:27: [2024-10-30 15:00:27] iter = 11750, loss = 9.4678
2024-10-30 15:00:28: [2024-10-30 15:00:28] iter = 11760, loss = 1.7688
2024-10-30 15:00:29: [2024-10-30 15:00:29] iter = 11770, loss = 11.0100
2024-10-30 15:00:30: [2024-10-30 15:00:30] iter = 11780, loss = 2.4848
2024-10-30 15:00:30: [2024-10-30 15:00:30] iter = 11790, loss = 3.6857
2024-10-30 15:00:31: [2024-10-30 15:00:31] iter = 11800, loss = 1.3344
2024-10-30 15:00:32: [2024-10-30 15:00:32] iter = 11810, loss = 15.1608
2024-10-30 15:00:32: [2024-10-30 15:00:32] iter = 11820, loss = 1.1281
2024-10-30 15:00:33: [2024-10-30 15:00:33] iter = 11830, loss = 8.1461
2024-10-30 15:00:34: [2024-10-30 15:00:34] iter = 11840, loss = 1.2004
2024-10-30 15:00:35: [2024-10-30 15:00:35] iter = 11850, loss = 1.7215
2024-10-30 15:00:36: [2024-10-30 15:00:36] iter = 11860, loss = 2.2060
2024-10-30 15:00:37: [2024-10-30 15:00:37] iter = 11870, loss = 9.7227
2024-10-30 15:00:38: [2024-10-30 15:00:38] iter = 11880, loss = 16.0448
2024-10-30 15:00:38: [2024-10-30 15:00:38] iter = 11890, loss = 5.2615
2024-10-30 15:00:39: [2024-10-30 15:00:39] iter = 11900, loss = 1.2615
2024-10-30 15:00:40: [2024-10-30 15:00:40] iter = 11910, loss = 1.1266
2024-10-30 15:00:41: [2024-10-30 15:00:41] iter = 11920, loss = 2.2748
2024-10-30 15:00:41: [2024-10-30 15:00:41] iter = 11930, loss = 4.7826
2024-10-30 15:00:42: [2024-10-30 15:00:42] iter = 11940, loss = 2.2146
2024-10-30 15:00:43: [2024-10-30 15:00:43] iter = 11950, loss = 2.1020
2024-10-30 15:00:44: [2024-10-30 15:00:44] iter = 11960, loss = 1.5174
2024-10-30 15:00:45: [2024-10-30 15:00:45] iter = 11970, loss = 1.1727
2024-10-30 15:00:46: [2024-10-30 15:00:46] iter = 11980, loss = 8.1107
2024-10-30 15:00:47: [2024-10-30 15:00:47] iter = 11990, loss = 1.3076
2024-10-30 15:00:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 15:00:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:00:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 47922}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:02:10: Evaluate 5 random ConvNet, ACCmean = 0.6936 ACCstd = 0.0200
-------------------------
2024-10-30 15:02:10: Evaluate 5 random ConvNet, SENmean = 0.7197 SENstd = 0.0172
-------------------------
2024-10-30 15:02:10: Evaluate 5 random ConvNet, SPEmean = 0.7197 SPEstd = 0.0172
-------------------------
2024-10-30 15:02:10: Evaluate 5 random ConvNet, F!mean = 0.6684 F!std = 0.0187
-------------------------
2024-10-30 15:02:10: Evaluate 5 random ConvNet, mean = 0.6936 std = 0.0200
-------------------------
2024-10-30 15:02:10: [2024-10-30 15:02:10] iter = 12000, loss = 2.2402
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:02:12: [2024-10-30 15:02:12] iter = 12010, loss = 2.4583
2024-10-30 15:02:12: [2024-10-30 15:02:12] iter = 12020, loss = 5.7383
2024-10-30 15:02:13: [2024-10-30 15:02:13] iter = 12030, loss = 2.2710
2024-10-30 15:02:14: [2024-10-30 15:02:14] iter = 12040, loss = 21.4793
2024-10-30 15:02:15: [2024-10-30 15:02:15] iter = 12050, loss = 4.9149
2024-10-30 15:02:16: [2024-10-30 15:02:16] iter = 12060, loss = 1.9506
2024-10-30 15:02:16: [2024-10-30 15:02:16] iter = 12070, loss = 1.3014
2024-10-30 15:02:18: [2024-10-30 15:02:18] iter = 12080, loss = 34.2956
2024-10-30 15:02:18: [2024-10-30 15:02:18] iter = 12090, loss = 3.0951
2024-10-30 15:02:19: [2024-10-30 15:02:19] iter = 12100, loss = 1.9722
2024-10-30 15:02:20: [2024-10-30 15:02:20] iter = 12110, loss = 2.5247
2024-10-30 15:02:21: [2024-10-30 15:02:21] iter = 12120, loss = 1.8092
2024-10-30 15:02:21: [2024-10-30 15:02:21] iter = 12130, loss = 15.2057
2024-10-30 15:02:22: [2024-10-30 15:02:22] iter = 12140, loss = 5.3923
2024-10-30 15:02:23: [2024-10-30 15:02:23] iter = 12150, loss = 1.9380
2024-10-30 15:02:24: [2024-10-30 15:02:24] iter = 12160, loss = 1.7859
2024-10-30 15:02:25: [2024-10-30 15:02:25] iter = 12170, loss = 4.7285
2024-10-30 15:02:26: [2024-10-30 15:02:26] iter = 12180, loss = 2.8009
2024-10-30 15:02:27: [2024-10-30 15:02:27] iter = 12190, loss = 1.2243
2024-10-30 15:02:28: [2024-10-30 15:02:28] iter = 12200, loss = 7.4724
2024-10-30 15:02:28: [2024-10-30 15:02:28] iter = 12210, loss = 3.3656
2024-10-30 15:02:29: [2024-10-30 15:02:29] iter = 12220, loss = 1.0923
2024-10-30 15:02:30: [2024-10-30 15:02:30] iter = 12230, loss = 1.9917
2024-10-30 15:02:31: [2024-10-30 15:02:31] iter = 12240, loss = 1.5851
2024-10-30 15:02:31: [2024-10-30 15:02:31] iter = 12250, loss = 1.3926
2024-10-30 15:02:32: [2024-10-30 15:02:32] iter = 12260, loss = 1.3695
2024-10-30 15:02:33: [2024-10-30 15:02:33] iter = 12270, loss = 3.0393
2024-10-30 15:02:33: [2024-10-30 15:02:33] iter = 12280, loss = 3.2168
2024-10-30 15:02:35: [2024-10-30 15:02:35] iter = 12290, loss = 2.2288
2024-10-30 15:02:35: [2024-10-30 15:02:35] iter = 12300, loss = 3.9003
2024-10-30 15:02:36: [2024-10-30 15:02:36] iter = 12310, loss = 3.3844
2024-10-30 15:02:37: [2024-10-30 15:02:37] iter = 12320, loss = 14.3325
2024-10-30 15:02:38: [2024-10-30 15:02:38] iter = 12330, loss = 1.7386
2024-10-30 15:02:39: [2024-10-30 15:02:39] iter = 12340, loss = 1.9239
2024-10-30 15:02:39: [2024-10-30 15:02:39] iter = 12350, loss = 1.0806
2024-10-30 15:02:40: [2024-10-30 15:02:40] iter = 12360, loss = 2.4715
2024-10-30 15:02:41: [2024-10-30 15:02:41] iter = 12370, loss = 6.6654
2024-10-30 15:02:42: [2024-10-30 15:02:42] iter = 12380, loss = 5.7007
2024-10-30 15:02:43: [2024-10-30 15:02:43] iter = 12390, loss = 4.1543
2024-10-30 15:02:44: [2024-10-30 15:02:44] iter = 12400, loss = 2.1668
2024-10-30 15:02:45: [2024-10-30 15:02:45] iter = 12410, loss = 3.2623
2024-10-30 15:02:46: [2024-10-30 15:02:46] iter = 12420, loss = 2.5850
2024-10-30 15:02:47: [2024-10-30 15:02:47] iter = 12430, loss = 6.4189
2024-10-30 15:02:48: [2024-10-30 15:02:48] iter = 12440, loss = 1.5927
2024-10-30 15:02:49: [2024-10-30 15:02:49] iter = 12450, loss = 2.2236
2024-10-30 15:02:50: [2024-10-30 15:02:50] iter = 12460, loss = 3.2282
2024-10-30 15:02:51: [2024-10-30 15:02:51] iter = 12470, loss = 1.5922
2024-10-30 15:02:51: [2024-10-30 15:02:51] iter = 12480, loss = 4.3853
2024-10-30 15:02:52: [2024-10-30 15:02:52] iter = 12490, loss = 1.5154
2024-10-30 15:02:53: [2024-10-30 15:02:53] iter = 12500, loss = 1.2968
2024-10-30 15:02:54: [2024-10-30 15:02:54] iter = 12510, loss = 3.9469
2024-10-30 15:02:55: [2024-10-30 15:02:55] iter = 12520, loss = 3.6166
2024-10-30 15:02:56: [2024-10-30 15:02:56] iter = 12530, loss = 4.7615
2024-10-30 15:02:57: [2024-10-30 15:02:57] iter = 12540, loss = 8.4546
2024-10-30 15:02:58: [2024-10-30 15:02:58] iter = 12550, loss = 2.1106
2024-10-30 15:02:59: [2024-10-30 15:02:59] iter = 12560, loss = 1.3124
2024-10-30 15:03:00: [2024-10-30 15:03:00] iter = 12570, loss = 8.7934
2024-10-30 15:03:01: [2024-10-30 15:03:01] iter = 12580, loss = 1.8543
2024-10-30 15:03:02: [2024-10-30 15:03:02] iter = 12590, loss = 3.9892
2024-10-30 15:03:02: [2024-10-30 15:03:02] iter = 12600, loss = 2.4276
2024-10-30 15:03:03: [2024-10-30 15:03:03] iter = 12610, loss = 5.3645
2024-10-30 15:03:03: [2024-10-30 15:03:03] iter = 12620, loss = 2.3917
2024-10-30 15:03:04: [2024-10-30 15:03:04] iter = 12630, loss = 6.6468
2024-10-30 15:03:04: [2024-10-30 15:03:04] iter = 12640, loss = 1.6443
2024-10-30 15:03:05: [2024-10-30 15:03:05] iter = 12650, loss = 1.4248
2024-10-30 15:03:05: [2024-10-30 15:03:05] iter = 12660, loss = 12.0893
2024-10-30 15:03:06: [2024-10-30 15:03:06] iter = 12670, loss = 7.0467
2024-10-30 15:03:07: [2024-10-30 15:03:07] iter = 12680, loss = 1.4588
2024-10-30 15:03:08: [2024-10-30 15:03:08] iter = 12690, loss = 1.3259
2024-10-30 15:03:08: [2024-10-30 15:03:08] iter = 12700, loss = 1.7066
2024-10-30 15:03:09: [2024-10-30 15:03:09] iter = 12710, loss = 1.9058
2024-10-30 15:03:10: [2024-10-30 15:03:10] iter = 12720, loss = 14.3484
2024-10-30 15:03:11: [2024-10-30 15:03:11] iter = 12730, loss = 3.9800
2024-10-30 15:03:12: [2024-10-30 15:03:12] iter = 12740, loss = 8.4492
2024-10-30 15:03:13: [2024-10-30 15:03:13] iter = 12750, loss = 3.7566
2024-10-30 15:03:14: [2024-10-30 15:03:14] iter = 12760, loss = 5.8719
2024-10-30 15:03:15: [2024-10-30 15:03:15] iter = 12770, loss = 1.2136
2024-10-30 15:03:16: [2024-10-30 15:03:16] iter = 12780, loss = 10.5534
2024-10-30 15:03:17: [2024-10-30 15:03:17] iter = 12790, loss = 1.7821
2024-10-30 15:03:17: [2024-10-30 15:03:17] iter = 12800, loss = 5.6471
2024-10-30 15:03:18: [2024-10-30 15:03:18] iter = 12810, loss = 2.0821
2024-10-30 15:03:19: [2024-10-30 15:03:19] iter = 12820, loss = 8.2620
2024-10-30 15:03:20: [2024-10-30 15:03:20] iter = 12830, loss = 29.2275
2024-10-30 15:03:21: [2024-10-30 15:03:21] iter = 12840, loss = 34.3115
2024-10-30 15:03:22: [2024-10-30 15:03:22] iter = 12850, loss = 6.9355
2024-10-30 15:03:23: [2024-10-30 15:03:23] iter = 12860, loss = 2.7701
2024-10-30 15:03:23: [2024-10-30 15:03:23] iter = 12870, loss = 1.4855
2024-10-30 15:03:25: [2024-10-30 15:03:25] iter = 12880, loss = 6.1279
2024-10-30 15:03:26: [2024-10-30 15:03:26] iter = 12890, loss = 2.4668
2024-10-30 15:03:26: [2024-10-30 15:03:26] iter = 12900, loss = 4.5147
2024-10-30 15:03:27: [2024-10-30 15:03:27] iter = 12910, loss = 1.6948
2024-10-30 15:03:29: [2024-10-30 15:03:29] iter = 12920, loss = 1.5065
2024-10-30 15:03:29: [2024-10-30 15:03:29] iter = 12930, loss = 3.8280
2024-10-30 15:03:30: [2024-10-30 15:03:30] iter = 12940, loss = 16.0156
2024-10-30 15:03:31: [2024-10-30 15:03:31] iter = 12950, loss = 2.0315
2024-10-30 15:03:32: [2024-10-30 15:03:32] iter = 12960, loss = 6.3001
2024-10-30 15:03:33: [2024-10-30 15:03:33] iter = 12970, loss = 19.5439
2024-10-30 15:03:34: [2024-10-30 15:03:34] iter = 12980, loss = 1.2739
2024-10-30 15:03:35: [2024-10-30 15:03:35] iter = 12990, loss = 1.1667
2024-10-30 15:03:36: [2024-10-30 15:03:36] iter = 13000, loss = 1.4295
2024-10-30 15:03:37: [2024-10-30 15:03:37] iter = 13010, loss = 2.2703
2024-10-30 15:03:39: [2024-10-30 15:03:39] iter = 13020, loss = 3.7995
2024-10-30 15:03:40: [2024-10-30 15:03:40] iter = 13030, loss = 1.5711
2024-10-30 15:03:42: [2024-10-30 15:03:42] iter = 13040, loss = 5.4005
2024-10-30 15:03:43: [2024-10-30 15:03:43] iter = 13050, loss = 1.8127
2024-10-30 15:03:44: [2024-10-30 15:03:44] iter = 13060, loss = 4.0283
2024-10-30 15:03:45: [2024-10-30 15:03:45] iter = 13070, loss = 4.2224
2024-10-30 15:03:46: [2024-10-30 15:03:46] iter = 13080, loss = 2.4847
2024-10-30 15:03:46: [2024-10-30 15:03:46] iter = 13090, loss = 16.8278
2024-10-30 15:03:47: [2024-10-30 15:03:47] iter = 13100, loss = 6.9580
2024-10-30 15:03:48: [2024-10-30 15:03:48] iter = 13110, loss = 1.3585
2024-10-30 15:03:49: [2024-10-30 15:03:49] iter = 13120, loss = 10.1365
2024-10-30 15:03:50: [2024-10-30 15:03:50] iter = 13130, loss = 22.7943
2024-10-30 15:03:51: [2024-10-30 15:03:51] iter = 13140, loss = 5.0278
2024-10-30 15:03:52: [2024-10-30 15:03:52] iter = 13150, loss = 5.7751
2024-10-30 15:03:53: [2024-10-30 15:03:53] iter = 13160, loss = 30.8702
2024-10-30 15:03:54: [2024-10-30 15:03:54] iter = 13170, loss = 2.5501
2024-10-30 15:03:55: [2024-10-30 15:03:55] iter = 13180, loss = 1.4699
2024-10-30 15:03:56: [2024-10-30 15:03:56] iter = 13190, loss = 2.5823
2024-10-30 15:03:57: [2024-10-30 15:03:57] iter = 13200, loss = 20.7461
2024-10-30 15:03:58: [2024-10-30 15:03:58] iter = 13210, loss = 2.1825
2024-10-30 15:03:59: [2024-10-30 15:03:59] iter = 13220, loss = 4.9627
2024-10-30 15:04:00: [2024-10-30 15:04:00] iter = 13230, loss = 2.9974
2024-10-30 15:04:01: [2024-10-30 15:04:01] iter = 13240, loss = 23.2082
2024-10-30 15:04:02: [2024-10-30 15:04:02] iter = 13250, loss = 4.1779
2024-10-30 15:04:02: [2024-10-30 15:04:02] iter = 13260, loss = 14.4273
2024-10-30 15:04:03: [2024-10-30 15:04:03] iter = 13270, loss = 2.3161
2024-10-30 15:04:03: [2024-10-30 15:04:03] iter = 13280, loss = 1.3574
2024-10-30 15:04:04: [2024-10-30 15:04:04] iter = 13290, loss = 4.8090
2024-10-30 15:04:05: [2024-10-30 15:04:05] iter = 13300, loss = 1.2226
2024-10-30 15:04:06: [2024-10-30 15:04:06] iter = 13310, loss = 1.7308
2024-10-30 15:04:07: [2024-10-30 15:04:07] iter = 13320, loss = 1.1173
2024-10-30 15:04:08: [2024-10-30 15:04:08] iter = 13330, loss = 6.6273
2024-10-30 15:04:09: [2024-10-30 15:04:09] iter = 13340, loss = 3.4217
2024-10-30 15:04:10: [2024-10-30 15:04:10] iter = 13350, loss = 6.6900
2024-10-30 15:04:11: [2024-10-30 15:04:11] iter = 13360, loss = 8.4586
2024-10-30 15:04:12: [2024-10-30 15:04:12] iter = 13370, loss = 7.7259
2024-10-30 15:04:13: [2024-10-30 15:04:13] iter = 13380, loss = 2.5433
2024-10-30 15:04:14: [2024-10-30 15:04:14] iter = 13390, loss = 2.1479
2024-10-30 15:04:15: [2024-10-30 15:04:15] iter = 13400, loss = 8.9078
2024-10-30 15:04:16: [2024-10-30 15:04:16] iter = 13410, loss = 1.2874
2024-10-30 15:04:17: [2024-10-30 15:04:17] iter = 13420, loss = 2.4474
2024-10-30 15:04:18: [2024-10-30 15:04:18] iter = 13430, loss = 4.0754
2024-10-30 15:04:19: [2024-10-30 15:04:19] iter = 13440, loss = 14.3308
2024-10-30 15:04:20: [2024-10-30 15:04:20] iter = 13450, loss = 5.1934
2024-10-30 15:04:21: [2024-10-30 15:04:21] iter = 13460, loss = 4.6640
2024-10-30 15:04:22: [2024-10-30 15:04:22] iter = 13470, loss = 2.4304
2024-10-30 15:04:23: [2024-10-30 15:04:23] iter = 13480, loss = 12.8878
2024-10-30 15:04:24: [2024-10-30 15:04:24] iter = 13490, loss = 1.3832
2024-10-30 15:04:26: [2024-10-30 15:04:26] iter = 13500, loss = 1.6913
2024-10-30 15:04:26: [2024-10-30 15:04:26] iter = 13510, loss = 44.4402
2024-10-30 15:04:27: [2024-10-30 15:04:27] iter = 13520, loss = 4.3220
2024-10-30 15:04:28: [2024-10-30 15:04:28] iter = 13530, loss = 1.8601
2024-10-30 15:04:29: [2024-10-30 15:04:29] iter = 13540, loss = 2.3408
2024-10-30 15:04:29: [2024-10-30 15:04:29] iter = 13550, loss = 22.9865
2024-10-30 15:04:30: [2024-10-30 15:04:30] iter = 13560, loss = 1.9720
2024-10-30 15:04:31: [2024-10-30 15:04:31] iter = 13570, loss = 14.1161
2024-10-30 15:04:32: [2024-10-30 15:04:32] iter = 13580, loss = 1.9275
2024-10-30 15:04:33: [2024-10-30 15:04:33] iter = 13590, loss = 1.3309
2024-10-30 15:04:34: [2024-10-30 15:04:34] iter = 13600, loss = 1.3566
2024-10-30 15:04:35: [2024-10-30 15:04:35] iter = 13610, loss = 1.3882
2024-10-30 15:04:36: [2024-10-30 15:04:36] iter = 13620, loss = 2.8823
2024-10-30 15:04:37: [2024-10-30 15:04:37] iter = 13630, loss = 1.8401
2024-10-30 15:04:37: [2024-10-30 15:04:37] iter = 13640, loss = 6.3578
2024-10-30 15:04:38: [2024-10-30 15:04:38] iter = 13650, loss = 1.5690
2024-10-30 15:04:39: [2024-10-30 15:04:39] iter = 13660, loss = 2.3933
2024-10-30 15:04:39: [2024-10-30 15:04:39] iter = 13670, loss = 21.8972
2024-10-30 15:04:40: [2024-10-30 15:04:40] iter = 13680, loss = 11.1805
2024-10-30 15:04:41: [2024-10-30 15:04:41] iter = 13690, loss = 2.1468
2024-10-30 15:04:42: [2024-10-30 15:04:42] iter = 13700, loss = 2.3704
2024-10-30 15:04:43: [2024-10-30 15:04:43] iter = 13710, loss = 3.1981
2024-10-30 15:04:43: [2024-10-30 15:04:43] iter = 13720, loss = 7.8123
2024-10-30 15:04:44: [2024-10-30 15:04:44] iter = 13730, loss = 3.9005
2024-10-30 15:04:45: [2024-10-30 15:04:45] iter = 13740, loss = 2.3615
2024-10-30 15:04:46: [2024-10-30 15:04:46] iter = 13750, loss = 1.9025
2024-10-30 15:04:46: [2024-10-30 15:04:46] iter = 13760, loss = 1.6544
2024-10-30 15:04:47: [2024-10-30 15:04:47] iter = 13770, loss = 5.0396
2024-10-30 15:04:48: [2024-10-30 15:04:48] iter = 13780, loss = 1.1571
2024-10-30 15:04:49: [2024-10-30 15:04:49] iter = 13790, loss = 2.4203
2024-10-30 15:04:50: [2024-10-30 15:04:50] iter = 13800, loss = 28.2358
2024-10-30 15:04:51: [2024-10-30 15:04:51] iter = 13810, loss = 3.0823
2024-10-30 15:04:52: [2024-10-30 15:04:52] iter = 13820, loss = 1.4275
2024-10-30 15:04:53: [2024-10-30 15:04:53] iter = 13830, loss = 1.5446
2024-10-30 15:04:53: [2024-10-30 15:04:53] iter = 13840, loss = 2.4691
2024-10-30 15:04:55: [2024-10-30 15:04:55] iter = 13850, loss = 1.5920
2024-10-30 15:04:56: [2024-10-30 15:04:56] iter = 13860, loss = 2.4416
2024-10-30 15:04:56: [2024-10-30 15:04:56] iter = 13870, loss = 3.1830
2024-10-30 15:04:57: [2024-10-30 15:04:57] iter = 13880, loss = 0.9505
2024-10-30 15:04:58: [2024-10-30 15:04:58] iter = 13890, loss = 2.1627
2024-10-30 15:04:59: [2024-10-30 15:04:59] iter = 13900, loss = 1.5644
2024-10-30 15:05:00: [2024-10-30 15:05:00] iter = 13910, loss = 1.4059
2024-10-30 15:05:00: [2024-10-30 15:05:00] iter = 13920, loss = 1.6315
2024-10-30 15:05:01: [2024-10-30 15:05:01] iter = 13930, loss = 17.4748
2024-10-30 15:05:02: [2024-10-30 15:05:02] iter = 13940, loss = 1.9567
2024-10-30 15:05:03: [2024-10-30 15:05:03] iter = 13950, loss = 6.1204
2024-10-30 15:05:04: [2024-10-30 15:05:04] iter = 13960, loss = 1.4157
2024-10-30 15:05:05: [2024-10-30 15:05:05] iter = 13970, loss = 1.1191
2024-10-30 15:05:06: [2024-10-30 15:05:06] iter = 13980, loss = 1.3266
2024-10-30 15:05:07: [2024-10-30 15:05:07] iter = 13990, loss = 8.9363
2024-10-30 15:05:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 15:05:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:05:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 8026}

[2024-10-30 14:41:30] Evaluate_01: epoch = 1000 train time = 8 s train loss = 0.001834 train acc = 1.0000, test acc = 0.6667, test_sen =0.7118, test_spe =0.7118, test_f1 =0.6479
[2024-10-30 14:41:39] Evaluate_02: epoch = 1000 train time = 8 s train loss = 0.004297 train acc = 1.0000, test acc = 0.5897, test_sen =0.6667, test_spe =0.6667, test_f1 =0.5814
[2024-10-30 14:41:49] Evaluate_03: epoch = 1000 train time = 10 s train loss = 0.000220 train acc = 1.0000, test acc = 0.6474, test_sen =0.6911, test_spe =0.6911, test_f1 =0.6287
[2024-10-30 14:41:59] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.001252 train acc = 1.0000, test acc = 0.6667, test_sen =0.7043, test_spe =0.7043, test_f1 =0.6456
[2024-10-30 14:43:42] Evaluate_00: epoch = 1000 train time = 7 s train loss = 0.033226 train acc = 1.0000, test acc = 0.7885, test_sen =0.6673, test_spe =0.6673, test_f1 =0.6864
[2024-10-30 14:43:50] Evaluate_01: epoch = 1000 train time = 7 s train loss = 0.005863 train acc = 1.0000, test acc = 0.7885, test_sen =0.7124, test_spe =0.7124, test_f1 =0.7203
[2024-10-30 14:43:58] Evaluate_02: epoch = 1000 train time = 8 s train loss = 0.000785 train acc = 1.0000, test acc = 0.7692, test_sen =0.6692, test_spe =0.6692, test_f1 =0.6811
[2024-10-30 14:44:07] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.000041 train acc = 1.0000, test acc = 0.7821, test_sen =0.6779, test_spe =0.6779, test_f1 =0.6931
[2024-10-30 14:44:17] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.000896 train acc = 1.0000, test acc = 0.8013, test_sen =0.7137, test_spe =0.7137, test_f1 =0.7279
[2024-10-30 14:44:25] Evaluate_00: epoch = 1000 train time = 8 s train loss = 0.002610 train acc = 1.0000, test acc = 0.6603, test_sen =0.6322, test_spe =0.6322, test_f1 =0.6120
[2024-10-30 14:44:35] Evaluate_01: epoch = 1000 train time = 10 s train loss = 0.002144 train acc = 1.0000, test acc = 0.6218, test_sen =0.5984, test_spe =0.5984, test_f1 =0.5765
[2024-10-30 14:44:43] Evaluate_02: epoch = 1000 train time = 7 s train loss = 0.008352 train acc = 1.0000, test acc = 0.6218, test_sen =0.6209, test_spe =0.6209, test_f1 =0.5875
[2024-10-30 14:44:50] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.018876 train acc = 1.0000, test acc = 0.6410, test_sen =0.6040, test_spe =0.6040, test_f1 =0.5879
[2024-10-30 14:44:56] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.000024 train acc = 1.0000, test acc = 0.6859, test_sen =0.6798, test_spe =0.6798, test_f1 =0.6483
[2024-10-30 14:46:31] Evaluate_00: epoch = 1000 train time = 7 s train loss = 0.000465 train acc = 1.0000, test acc = 0.5000, test_sen =0.6053, test_spe =0.6053, test_f1 =0.4987
[2024-10-30 14:46:37] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.001178 train acc = 1.0000, test acc = 0.5513, test_sen =0.6554, test_spe =0.6554, test_f1 =0.5486
[2024-10-30 14:46:47] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.004238 train acc = 1.0000, test acc = 0.5192, test_sen =0.6259, test_spe =0.6259, test_f1 =0.5176
[2024-10-30 14:46:55] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.000172 train acc = 1.0000, test acc = 0.5256, test_sen =0.6228, test_spe =0.6228, test_f1 =0.5228
[2024-10-30 14:47:03] Evaluate_04: epoch = 1000 train time = 8 s train loss = 0.000065 train acc = 1.0000, test acc = 0.5000, test_sen =0.6203, test_spe =0.6203, test_f1 =0.4997
[2024-10-30 14:48:39] Evaluate_00: epoch = 1000 train time = 9 s train loss = 0.000334 train acc = 1.0000, test acc = 0.7436, test_sen =0.5464, test_spe =0.5464, test_f1 =0.5237
[2024-10-30 14:48:48] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.000106 train acc = 1.0000, test acc = 0.7308, test_sen =0.5150, test_spe =0.5150, test_f1 =0.4645
[2024-10-30 14:48:58] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.000117 train acc = 1.0000, test acc = 0.7564, test_sen =0.5627, test_spe =0.5627, test_f1 =0.5475
[2024-10-30 14:49:06] Evaluate_03: epoch = 1000 train time = 8 s train loss = 0.001511 train acc = 1.0000, test acc = 0.7500, test_sen =0.5508, test_spe =0.5508, test_f1 =0.5279
[2024-10-30 14:49:15] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.000060 train acc = 1.0000, test acc = 0.7436, test_sen =0.5464, test_spe =0.5464, test_f1 =0.5237
[2024-10-30 14:51:08] Evaluate_00: epoch = 1000 train time = 9 s train loss = 0.021466 train acc = 1.0000, test acc = 0.7500, test_sen =0.7011, test_spe =0.7011, test_f1 =0.6935
[2024-10-30 14:51:18] Evaluate_01: epoch = 1000 train time = 10 s train loss = 0.051196 train acc = 0.9500, test acc = 0.7564, test_sen =0.6830, test_spe =0.6830, test_f1 =0.6857
[2024-10-30 14:51:29] Evaluate_02: epoch = 1000 train time = 10 s train loss = 0.000642 train acc = 1.0000, test acc = 0.7949, test_sen =0.7318, test_spe =0.7318, test_f1 =0.7353
[2024-10-30 14:51:40] Evaluate_03: epoch = 1000 train time = 11 s train loss = 0.000159 train acc = 1.0000, test acc = 0.7692, test_sen =0.7068, test_spe =0.7068, test_f1 =0.7068
[2024-10-30 14:51:52] Evaluate_04: epoch = 1000 train time = 11 s train loss = 0.001849 train acc = 1.0000, test acc = 0.7756, test_sen =0.7112, test_spe =0.7112, test_f1 =0.7127
[2024-10-30 14:54:02] Evaluate_00: epoch = 1000 train time = 11 s train loss = 0.006307 train acc = 1.0000, test acc = 0.6603, test_sen =0.7224, test_spe =0.7224, test_f1 =0.6463
[2024-10-30 14:54:13] Evaluate_01: epoch = 1000 train time = 11 s train loss = 0.000137 train acc = 1.0000, test acc = 0.6731, test_sen =0.7162, test_spe =0.7162, test_f1 =0.6536
[2024-10-30 14:54:28] Evaluate_02: epoch = 1000 train time = 14 s train loss = 0.000802 train acc = 1.0000, test acc = 0.6859, test_sen =0.7475, test_spe =0.7475, test_f1 =0.6712
[2024-10-30 14:54:41] Evaluate_03: epoch = 1000 train time = 12 s train loss = 0.006588 train acc = 1.0000, test acc = 0.7179, test_sen =0.7544, test_spe =0.7544, test_f1 =0.6959
[2024-10-30 14:54:53] Evaluate_04: epoch = 1000 train time = 11 s train loss = 0.000109 train acc = 1.0000, test acc = 0.6603, test_sen =0.6999, test_spe =0.6999, test_f1 =0.6400
[2024-10-30 14:56:50] Evaluate_00: epoch = 1000 train time = 11 s train loss = 0.001377 train acc = 1.0000, test acc = 0.7500, test_sen =0.6711, test_spe =0.6711, test_f1 =0.6748
[2024-10-30 14:57:03] Evaluate_01: epoch = 1000 train time = 12 s train loss = 0.000555 train acc = 1.0000, test acc = 0.7628, test_sen =0.6723, test_spe =0.6723, test_f1 =0.6810
[2024-10-30 14:57:17] Evaluate_02: epoch = 1000 train time = 13 s train loss = 0.000372 train acc = 1.0000, test acc = 0.7500, test_sen =0.6786, test_spe =0.6786, test_f1 =0.6799
[2024-10-30 14:57:35] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000206 train acc = 1.0000, test acc = 0.7628, test_sen =0.6723, test_spe =0.6723, test_f1 =0.6810
[2024-10-30 14:57:53] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000699 train acc = 1.0000, test acc = 0.7692, test_sen =0.6842, test_spe =0.6842, test_f1 =0.6923
[2024-10-30 15:01:04] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000071 train acc = 1.0000, test acc = 0.6795, test_sen =0.7130, test_spe =0.7130, test_f1 =0.6569
[2024-10-30 15:01:20] Evaluate_01: epoch = 1000 train time = 15 s train loss = 0.007455 train acc = 1.0000, test acc = 0.6731, test_sen =0.7011, test_spe =0.7011, test_f1 =0.6488
[2024-10-30 15:01:37] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.003793 train acc = 1.0000, test acc = 0.7179, test_sen =0.7469, test_spe =0.7469, test_f1 =0.6936
[2024-10-30 15:01:55] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000034 train acc = 1.0000, test acc = 0.7179, test_sen =0.7318, test_spe =0.7318, test_f1 =0.6885
[2024-10-30 15:02:10] Evaluate_04: epoch = 1000 train time = 15 s train loss = 0.000377 train acc = 1.0000, test acc = 0.6795, test_sen =0.7055, test_spe =0.7055, test_f1 =0.6544
[2024-10-30 15:05:28] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.000053 train acc = 1.0000, test acc = 0.3910, test_sen =0.5758, test_spe =0.5758, test_f1 =0.3798
[2024-10-30 15:05:46] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.000206 train acc = 1.0000, test acc = 0.3910, test_sen =0.5683, test_spe =0.5683, test_f1 =0.3819/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:06:41: Evaluate 5 random ConvNet, ACCmean = 0.3872 ACCstd = 0.0112
-------------------------
2024-10-30 15:06:41: Evaluate 5 random ConvNet, SENmean = 0.5627 SENstd = 0.0139
-------------------------
2024-10-30 15:06:41: Evaluate 5 random ConvNet, SPEmean = 0.5627 SPEstd = 0.0139
-------------------------
2024-10-30 15:06:41: Evaluate 5 random ConvNet, F!mean = 0.3781 F!std = 0.0118
-------------------------
2024-10-30 15:06:41: Evaluate 5 random ConvNet, mean = 0.3872 std = 0.0112
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:06:41: [2024-10-30 15:06:41] iter = 14000, loss = 2.8625
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:06:42: [2024-10-30 15:06:42] iter = 14010, loss = 19.7721
2024-10-30 15:06:43: [2024-10-30 15:06:43] iter = 14020, loss = 3.6144
2024-10-30 15:06:44: [2024-10-30 15:06:44] iter = 14030, loss = 7.6727
2024-10-30 15:06:44: [2024-10-30 15:06:44] iter = 14040, loss = 13.5800
2024-10-30 15:06:45: [2024-10-30 15:06:45] iter = 14050, loss = 2.3649
2024-10-30 15:06:46: [2024-10-30 15:06:46] iter = 14060, loss = 1.7862
2024-10-30 15:06:47: [2024-10-30 15:06:47] iter = 14070, loss = 1.9256
2024-10-30 15:06:48: [2024-10-30 15:06:48] iter = 14080, loss = 2.1886
2024-10-30 15:06:49: [2024-10-30 15:06:49] iter = 14090, loss = 1.5063
2024-10-30 15:06:50: [2024-10-30 15:06:50] iter = 14100, loss = 1.4998
2024-10-30 15:06:50: [2024-10-30 15:06:50] iter = 14110, loss = 3.4401
2024-10-30 15:06:51: [2024-10-30 15:06:51] iter = 14120, loss = 1.9941
2024-10-30 15:06:52: [2024-10-30 15:06:52] iter = 14130, loss = 1.4503
2024-10-30 15:06:53: [2024-10-30 15:06:53] iter = 14140, loss = 6.5807
2024-10-30 15:06:53: [2024-10-30 15:06:53] iter = 14150, loss = 5.2949
2024-10-30 15:06:54: [2024-10-30 15:06:54] iter = 14160, loss = 14.3650
2024-10-30 15:06:56: [2024-10-30 15:06:55] iter = 14170, loss = 1.7539
2024-10-30 15:06:56: [2024-10-30 15:06:56] iter = 14180, loss = 5.9460
2024-10-30 15:06:57: [2024-10-30 15:06:57] iter = 14190, loss = 4.6269
2024-10-30 15:06:58: [2024-10-30 15:06:58] iter = 14200, loss = 7.4253
2024-10-30 15:06:59: [2024-10-30 15:06:59] iter = 14210, loss = 3.1075
2024-10-30 15:07:00: [2024-10-30 15:07:00] iter = 14220, loss = 1.5553
2024-10-30 15:07:02: [2024-10-30 15:07:02] iter = 14230, loss = 38.4688
2024-10-30 15:07:03: [2024-10-30 15:07:03] iter = 14240, loss = 5.3513
2024-10-30 15:07:04: [2024-10-30 15:07:04] iter = 14250, loss = 7.4796
2024-10-30 15:07:04: [2024-10-30 15:07:04] iter = 14260, loss = 5.0328
2024-10-30 15:07:05: [2024-10-30 15:07:05] iter = 14270, loss = 1.6753
2024-10-30 15:07:07: [2024-10-30 15:07:06] iter = 14280, loss = 9.3839
2024-10-30 15:07:08: [2024-10-30 15:07:08] iter = 14290, loss = 1.9518
2024-10-30 15:07:09: [2024-10-30 15:07:09] iter = 14300, loss = 6.1809
2024-10-30 15:07:10: [2024-10-30 15:07:10] iter = 14310, loss = 5.0835
2024-10-30 15:07:11: [2024-10-30 15:07:11] iter = 14320, loss = 3.0390
2024-10-30 15:07:12: [2024-10-30 15:07:12] iter = 14330, loss = 2.1643
2024-10-30 15:07:13: [2024-10-30 15:07:13] iter = 14340, loss = 3.0852
2024-10-30 15:07:15: [2024-10-30 15:07:15] iter = 14350, loss = 24.7210
2024-10-30 15:07:16: [2024-10-30 15:07:16] iter = 14360, loss = 9.9846
2024-10-30 15:07:17: [2024-10-30 15:07:17] iter = 14370, loss = 1.7014
2024-10-30 15:07:18: [2024-10-30 15:07:18] iter = 14380, loss = 2.1451
2024-10-30 15:07:19: [2024-10-30 15:07:19] iter = 14390, loss = 31.2679
2024-10-30 15:07:20: [2024-10-30 15:07:20] iter = 14400, loss = 1.9751
2024-10-30 15:07:21: [2024-10-30 15:07:21] iter = 14410, loss = 1.4507
2024-10-30 15:07:21: [2024-10-30 15:07:21] iter = 14420, loss = 1.6260
2024-10-30 15:07:23: [2024-10-30 15:07:23] iter = 14430, loss = 1.5749
2024-10-30 15:07:24: [2024-10-30 15:07:24] iter = 14440, loss = 5.5707
2024-10-30 15:07:25: [2024-10-30 15:07:25] iter = 14450, loss = 5.3015
2024-10-30 15:07:26: [2024-10-30 15:07:26] iter = 14460, loss = 5.7827
2024-10-30 15:07:27: [2024-10-30 15:07:27] iter = 14470, loss = 7.8559
2024-10-30 15:07:28: [2024-10-30 15:07:28] iter = 14480, loss = 3.0470
2024-10-30 15:07:29: [2024-10-30 15:07:29] iter = 14490, loss = 1.5013
2024-10-30 15:07:29: [2024-10-30 15:07:29] iter = 14500, loss = 18.2374
2024-10-30 15:07:30: [2024-10-30 15:07:30] iter = 14510, loss = 2.0288
2024-10-30 15:07:31: [2024-10-30 15:07:31] iter = 14520, loss = 2.9156
2024-10-30 15:07:32: [2024-10-30 15:07:32] iter = 14530, loss = 3.2906
2024-10-30 15:07:33: [2024-10-30 15:07:33] iter = 14540, loss = 3.8640
2024-10-30 15:07:34: [2024-10-30 15:07:34] iter = 14550, loss = 16.3394
2024-10-30 15:07:36: [2024-10-30 15:07:36] iter = 14560, loss = 1.2211
2024-10-30 15:07:37: [2024-10-30 15:07:37] iter = 14570, loss = 5.1297
2024-10-30 15:07:38: [2024-10-30 15:07:38] iter = 14580, loss = 1.4140
2024-10-30 15:07:39: [2024-10-30 15:07:39] iter = 14590, loss = 5.1783
2024-10-30 15:07:41: [2024-10-30 15:07:41] iter = 14600, loss = 1.6664
2024-10-30 15:07:42: [2024-10-30 15:07:42] iter = 14610, loss = 3.9408
2024-10-30 15:07:43: [2024-10-30 15:07:43] iter = 14620, loss = 1.2443
2024-10-30 15:07:44: [2024-10-30 15:07:44] iter = 14630, loss = 5.2702
2024-10-30 15:07:44: [2024-10-30 15:07:44] iter = 14640, loss = 2.3516
2024-10-30 15:07:45: [2024-10-30 15:07:45] iter = 14650, loss = 2.2017
2024-10-30 15:07:46: [2024-10-30 15:07:46] iter = 14660, loss = 5.6780
2024-10-30 15:07:47: [2024-10-30 15:07:47] iter = 14670, loss = 13.6234
2024-10-30 15:07:48: [2024-10-30 15:07:48] iter = 14680, loss = 7.3054
2024-10-30 15:07:49: [2024-10-30 15:07:49] iter = 14690, loss = 2.0943
2024-10-30 15:07:50: [2024-10-30 15:07:50] iter = 14700, loss = 2.7405
2024-10-30 15:07:50: [2024-10-30 15:07:50] iter = 14710, loss = 2.2484
2024-10-30 15:07:51: [2024-10-30 15:07:51] iter = 14720, loss = 2.0814
2024-10-30 15:07:52: [2024-10-30 15:07:52] iter = 14730, loss = 1.4865
2024-10-30 15:07:53: [2024-10-30 15:07:53] iter = 14740, loss = 2.0597
2024-10-30 15:07:54: [2024-10-30 15:07:54] iter = 14750, loss = 2.4557
2024-10-30 15:07:54: [2024-10-30 15:07:54] iter = 14760, loss = 7.8504
2024-10-30 15:07:55: [2024-10-30 15:07:55] iter = 14770, loss = 2.7189
2024-10-30 15:07:56: [2024-10-30 15:07:56] iter = 14780, loss = 40.4191
2024-10-30 15:07:57: [2024-10-30 15:07:57] iter = 14790, loss = 7.3384
2024-10-30 15:07:58: [2024-10-30 15:07:58] iter = 14800, loss = 2.2062
2024-10-30 15:07:59: [2024-10-30 15:07:59] iter = 14810, loss = 2.1362
2024-10-30 15:07:59: [2024-10-30 15:07:59] iter = 14820, loss = 3.6034
2024-10-30 15:08:00: [2024-10-30 15:08:00] iter = 14830, loss = 3.2509
2024-10-30 15:08:01: [2024-10-30 15:08:01] iter = 14840, loss = 12.7200
2024-10-30 15:08:02: [2024-10-30 15:08:02] iter = 14850, loss = 8.8014
2024-10-30 15:08:03: [2024-10-30 15:08:03] iter = 14860, loss = 5.9289
2024-10-30 15:08:04: [2024-10-30 15:08:04] iter = 14870, loss = 2.5726
2024-10-30 15:08:05: [2024-10-30 15:08:05] iter = 14880, loss = 1.2955
2024-10-30 15:08:06: [2024-10-30 15:08:06] iter = 14890, loss = 12.3556
2024-10-30 15:08:06: [2024-10-30 15:08:06] iter = 14900, loss = 4.3035
2024-10-30 15:08:07: [2024-10-30 15:08:07] iter = 14910, loss = 1.5312
2024-10-30 15:08:08: [2024-10-30 15:08:08] iter = 14920, loss = 1.1882
2024-10-30 15:08:09: [2024-10-30 15:08:09] iter = 14930, loss = 1.5986
2024-10-30 15:08:10: [2024-10-30 15:08:10] iter = 14940, loss = 2.2332
2024-10-30 15:08:11: [2024-10-30 15:08:11] iter = 14950, loss = 1.9328
2024-10-30 15:08:12: [2024-10-30 15:08:12] iter = 14960, loss = 9.9994
2024-10-30 15:08:13: [2024-10-30 15:08:13] iter = 14970, loss = 3.1342
2024-10-30 15:08:14: [2024-10-30 15:08:14] iter = 14980, loss = 4.2736
2024-10-30 15:08:15: [2024-10-30 15:08:15] iter = 14990, loss = 1.9505
2024-10-30 15:08:16: [2024-10-30 15:08:16] iter = 15000, loss = 1.9428
2024-10-30 15:08:17: [2024-10-30 15:08:17] iter = 15010, loss = 4.6319
2024-10-30 15:08:18: [2024-10-30 15:08:18] iter = 15020, loss = 7.6223
2024-10-30 15:08:19: [2024-10-30 15:08:19] iter = 15030, loss = 2.2727
2024-10-30 15:08:20: [2024-10-30 15:08:20] iter = 15040, loss = 13.1923
2024-10-30 15:08:21: [2024-10-30 15:08:21] iter = 15050, loss = 2.3073
2024-10-30 15:08:21: [2024-10-30 15:08:21] iter = 15060, loss = 9.2965
2024-10-30 15:08:22: [2024-10-30 15:08:22] iter = 15070, loss = 2.3993
2024-10-30 15:08:23: [2024-10-30 15:08:23] iter = 15080, loss = 1.6208
2024-10-30 15:08:24: [2024-10-30 15:08:24] iter = 15090, loss = 1.5629
2024-10-30 15:08:25: [2024-10-30 15:08:25] iter = 15100, loss = 1.3891
2024-10-30 15:08:26: [2024-10-30 15:08:26] iter = 15110, loss = 4.0520
2024-10-30 15:08:27: [2024-10-30 15:08:27] iter = 15120, loss = 1.4648
2024-10-30 15:08:28: [2024-10-30 15:08:28] iter = 15130, loss = 1.2480
2024-10-30 15:08:29: [2024-10-30 15:08:29] iter = 15140, loss = 1.4232
2024-10-30 15:08:30: [2024-10-30 15:08:30] iter = 15150, loss = 5.3333
2024-10-30 15:08:31: [2024-10-30 15:08:31] iter = 15160, loss = 4.4451
2024-10-30 15:08:32: [2024-10-30 15:08:32] iter = 15170, loss = 2.0207
2024-10-30 15:08:33: [2024-10-30 15:08:33] iter = 15180, loss = 1.2404
2024-10-30 15:08:33: [2024-10-30 15:08:33] iter = 15190, loss = 1.4106
2024-10-30 15:08:34: [2024-10-30 15:08:34] iter = 15200, loss = 4.8981
2024-10-30 15:08:35: [2024-10-30 15:08:35] iter = 15210, loss = 5.7251
2024-10-30 15:08:36: [2024-10-30 15:08:36] iter = 15220, loss = 1.4757
2024-10-30 15:08:37: [2024-10-30 15:08:37] iter = 15230, loss = 2.2324
2024-10-30 15:08:38: [2024-10-30 15:08:38] iter = 15240, loss = 2.0637
2024-10-30 15:08:39: [2024-10-30 15:08:39] iter = 15250, loss = 3.7836
2024-10-30 15:08:40: [2024-10-30 15:08:40] iter = 15260, loss = 1.5349
2024-10-30 15:08:41: [2024-10-30 15:08:41] iter = 15270, loss = 3.9424
2024-10-30 15:08:42: [2024-10-30 15:08:42] iter = 15280, loss = 13.0843
2024-10-30 15:08:42: [2024-10-30 15:08:42] iter = 15290, loss = 1.5021
2024-10-30 15:08:43: [2024-10-30 15:08:43] iter = 15300, loss = 9.4788
2024-10-30 15:08:44: [2024-10-30 15:08:44] iter = 15310, loss = 1.4856
2024-10-30 15:08:46: [2024-10-30 15:08:46] iter = 15320, loss = 18.2134
2024-10-30 15:08:47: [2024-10-30 15:08:47] iter = 15330, loss = 3.7389
2024-10-30 15:08:47: [2024-10-30 15:08:47] iter = 15340, loss = 3.7279
2024-10-30 15:08:48: [2024-10-30 15:08:48] iter = 15350, loss = 1.9120
2024-10-30 15:08:49: [2024-10-30 15:08:49] iter = 15360, loss = 4.2904
2024-10-30 15:08:51: [2024-10-30 15:08:51] iter = 15370, loss = 2.1452
2024-10-30 15:08:52: [2024-10-30 15:08:52] iter = 15380, loss = 3.1890
2024-10-30 15:08:53: [2024-10-30 15:08:53] iter = 15390, loss = 2.6957
2024-10-30 15:08:55: [2024-10-30 15:08:55] iter = 15400, loss = 1.3461
2024-10-30 15:08:56: [2024-10-30 15:08:56] iter = 15410, loss = 2.0471
2024-10-30 15:08:57: [2024-10-30 15:08:57] iter = 15420, loss = 3.4939
2024-10-30 15:08:58: [2024-10-30 15:08:58] iter = 15430, loss = 1.7618
2024-10-30 15:08:59: [2024-10-30 15:08:59] iter = 15440, loss = 2.3411
2024-10-30 15:09:00: [2024-10-30 15:09:00] iter = 15450, loss = 3.9893
2024-10-30 15:09:01: [2024-10-30 15:09:01] iter = 15460, loss = 2.0746
2024-10-30 15:09:02: [2024-10-30 15:09:02] iter = 15470, loss = 1.2941
2024-10-30 15:09:03: [2024-10-30 15:09:03] iter = 15480, loss = 2.2128
2024-10-30 15:09:04: [2024-10-30 15:09:04] iter = 15490, loss = 1.7182
2024-10-30 15:09:05: [2024-10-30 15:09:05] iter = 15500, loss = 2.3200
2024-10-30 15:09:06: [2024-10-30 15:09:06] iter = 15510, loss = 28.3050
2024-10-30 15:09:07: [2024-10-30 15:09:07] iter = 15520, loss = 1.7200
2024-10-30 15:09:08: [2024-10-30 15:09:08] iter = 15530, loss = 2.0816
2024-10-30 15:09:08: [2024-10-30 15:09:08] iter = 15540, loss = 1.2287
2024-10-30 15:09:10: [2024-10-30 15:09:10] iter = 15550, loss = 2.2862
2024-10-30 15:09:10: [2024-10-30 15:09:10] iter = 15560, loss = 15.5718
2024-10-30 15:09:11: [2024-10-30 15:09:11] iter = 15570, loss = 2.1049
2024-10-30 15:09:12: [2024-10-30 15:09:12] iter = 15580, loss = 3.1669
2024-10-30 15:09:14: [2024-10-30 15:09:14] iter = 15590, loss = 2.2849
2024-10-30 15:09:14: [2024-10-30 15:09:14] iter = 15600, loss = 7.3487
2024-10-30 15:09:15: [2024-10-30 15:09:15] iter = 15610, loss = 16.6816
2024-10-30 15:09:15: [2024-10-30 15:09:15] iter = 15620, loss = 1.4379
2024-10-30 15:09:17: [2024-10-30 15:09:17] iter = 15630, loss = 1.2594
2024-10-30 15:09:18: [2024-10-30 15:09:18] iter = 15640, loss = 3.5987
2024-10-30 15:09:19: [2024-10-30 15:09:19] iter = 15650, loss = 3.4694
2024-10-30 15:09:20: [2024-10-30 15:09:20] iter = 15660, loss = 2.4657
2024-10-30 15:09:21: [2024-10-30 15:09:21] iter = 15670, loss = 10.9873
2024-10-30 15:09:22: [2024-10-30 15:09:22] iter = 15680, loss = 2.3072
2024-10-30 15:09:23: [2024-10-30 15:09:23] iter = 15690, loss = 3.5065
2024-10-30 15:09:23: [2024-10-30 15:09:23] iter = 15700, loss = 6.1853
2024-10-30 15:09:24: [2024-10-30 15:09:24] iter = 15710, loss = 1.7941
2024-10-30 15:09:25: [2024-10-30 15:09:25] iter = 15720, loss = 1.8482
2024-10-30 15:09:26: [2024-10-30 15:09:26] iter = 15730, loss = 1.8191
2024-10-30 15:09:27: [2024-10-30 15:09:27] iter = 15740, loss = 5.9843
2024-10-30 15:09:27: [2024-10-30 15:09:27] iter = 15750, loss = 4.2564
2024-10-30 15:09:28: [2024-10-30 15:09:28] iter = 15760, loss = 3.7342
2024-10-30 15:09:29: [2024-10-30 15:09:29] iter = 15770, loss = 4.4389
2024-10-30 15:09:29: [2024-10-30 15:09:29] iter = 15780, loss = 4.8733
2024-10-30 15:09:30: [2024-10-30 15:09:30] iter = 15790, loss = 2.0826
2024-10-30 15:09:31: [2024-10-30 15:09:31] iter = 15800, loss = 1.5591
2024-10-30 15:09:32: [2024-10-30 15:09:32] iter = 15810, loss = 2.5361
2024-10-30 15:09:33: [2024-10-30 15:09:33] iter = 15820, loss = 2.0426
2024-10-30 15:09:33: [2024-10-30 15:09:33] iter = 15830, loss = 7.3228
2024-10-30 15:09:34: [2024-10-30 15:09:34] iter = 15840, loss = 5.2394
2024-10-30 15:09:35: [2024-10-30 15:09:35] iter = 15850, loss = 7.2846
2024-10-30 15:09:35: [2024-10-30 15:09:35] iter = 15860, loss = 1.4218
2024-10-30 15:09:36: [2024-10-30 15:09:36] iter = 15870, loss = 1.2528
2024-10-30 15:09:37: [2024-10-30 15:09:37] iter = 15880, loss = 1.1734
2024-10-30 15:09:38: [2024-10-30 15:09:38] iter = 15890, loss = 1.4881
2024-10-30 15:09:38: [2024-10-30 15:09:38] iter = 15900, loss = 1.0541
2024-10-30 15:09:39: [2024-10-30 15:09:39] iter = 15910, loss = 2.1509
2024-10-30 15:09:40: [2024-10-30 15:09:40] iter = 15920, loss = 1.6305
2024-10-30 15:09:41: [2024-10-30 15:09:41] iter = 15930, loss = 7.1672
2024-10-30 15:09:42: [2024-10-30 15:09:42] iter = 15940, loss = 2.8425
2024-10-30 15:09:43: [2024-10-30 15:09:43] iter = 15950, loss = 28.4226
2024-10-30 15:09:44: [2024-10-30 15:09:44] iter = 15960, loss = 2.3228
2024-10-30 15:09:45: [2024-10-30 15:09:45] iter = 15970, loss = 2.0515
2024-10-30 15:09:45: [2024-10-30 15:09:45] iter = 15980, loss = 5.2601
2024-10-30 15:09:46: [2024-10-30 15:09:46] iter = 15990, loss = 1.6785
2024-10-30 15:09:47: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 15:09:47: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:09:47: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87344}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:11:17: Evaluate 5 random ConvNet, ACCmean = 0.7038 ACCstd = 0.0169
-------------------------
2024-10-30 15:11:17: Evaluate 5 random ConvNet, SENmean = 0.7086 SENstd = 0.0163
-------------------------
2024-10-30 15:11:17: Evaluate 5 random ConvNet, SPEmean = 0.7086 SPEstd = 0.0163
-------------------------
2024-10-30 15:11:17: Evaluate 5 random ConvNet, F!mean = 0.6708 F!std = 0.0164
-------------------------
2024-10-30 15:11:17: Evaluate 5 random ConvNet, mean = 0.7038 std = 0.0169
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:11:17: [2024-10-30 15:11:17] iter = 16000, loss = 1.0402
2024-10-30 15:11:18: [2024-10-30 15:11:18] iter = 16010, loss = 4.1216
2024-10-30 15:11:19: [2024-10-30 15:11:19] iter = 16020, loss = 17.3854
2024-10-30 15:11:19: [2024-10-30 15:11:19] iter = 16030, loss = 1.6623
2024-10-30 15:11:20: [2024-10-30 15:11:20] iter = 16040, loss = 2.4389
2024-10-30 15:11:21: [2024-10-30 15:11:21] iter = 16050, loss = 1.9010
2024-10-30 15:11:22: [2024-10-30 15:11:22] iter = 16060, loss = 3.5865
2024-10-30 15:11:23: [2024-10-30 15:11:23] iter = 16070, loss = 10.9572
2024-10-30 15:11:24: [2024-10-30 15:11:24] iter = 16080, loss = 8.4725
2024-10-30 15:11:26: [2024-10-30 15:11:26] iter = 16090, loss = 7.2894
2024-10-30 15:11:27: [2024-10-30 15:11:27] iter = 16100, loss = 1.8359
2024-10-30 15:11:28: [2024-10-30 15:11:28] iter = 16110, loss = 1.5538
2024-10-30 15:11:29: [2024-10-30 15:11:29] iter = 16120, loss = 5.1300
2024-10-30 15:11:30: [2024-10-30 15:11:30] iter = 16130, loss = 2.7344
2024-10-30 15:11:31: [2024-10-30 15:11:31] iter = 16140, loss = 1.5935
2024-10-30 15:11:32: [2024-10-30 15:11:32] iter = 16150, loss = 1.5767
2024-10-30 15:11:34: [2024-10-30 15:11:34] iter = 16160, loss = 2.8115
2024-10-30 15:11:35: [2024-10-30 15:11:35] iter = 16170, loss = 2.1894
2024-10-30 15:11:36: [2024-10-30 15:11:36] iter = 16180, loss = 4.0379
2024-10-30 15:11:37: [2024-10-30 15:11:37] iter = 16190, loss = 2.2271
2024-10-30 15:11:38: [2024-10-30 15:11:38] iter = 16200, loss = 23.4487
2024-10-30 15:11:39: [2024-10-30 15:11:39] iter = 16210, loss = 2.0500
2024-10-30 15:11:40: [2024-10-30 15:11:40] iter = 16220, loss = 1.2756
2024-10-30 15:11:41: [2024-10-30 15:11:41] iter = 16230, loss = 2.3597
2024-10-30 15:11:42: [2024-10-30 15:11:42] iter = 16240, loss = 10.9246
2024-10-30 15:11:43: [2024-10-30 15:11:43] iter = 16250, loss = 3.0297
2024-10-30 15:11:44: [2024-10-30 15:11:44] iter = 16260, loss = 6.2184
2024-10-30 15:11:45: [2024-10-30 15:11:45] iter = 16270, loss = 4.2644
2024-10-30 15:11:46: [2024-10-30 15:11:46] iter = 16280, loss = 2.2575
2024-10-30 15:11:47: [2024-10-30 15:11:47] iter = 16290, loss = 1.4669
2024-10-30 15:11:48: [2024-10-30 15:11:48] iter = 16300, loss = 3.8787
2024-10-30 15:11:49: [2024-10-30 15:11:49] iter = 16310, loss = 1.7040
2024-10-30 15:11:49: [2024-10-30 15:11:49] iter = 16320, loss = 1.4495
2024-10-30 15:11:50: [2024-10-30 15:11:50] iter = 16330, loss = 4.2349
2024-10-30 15:11:51: [2024-10-30 15:11:51] iter = 16340, loss = 4.2896
2024-10-30 15:11:52: [2024-10-30 15:11:52] iter = 16350, loss = 2.0216
2024-10-30 15:11:53: [2024-10-30 15:11:53] iter = 16360, loss = 3.9376
2024-10-30 15:11:54: [2024-10-30 15:11:54] iter = 16370, loss = 4.2314
2024-10-30 15:11:55: [2024-10-30 15:11:55] iter = 16380, loss = 2.3501
2024-10-30 15:11:56: [2024-10-30 15:11:56] iter = 16390, loss = 2.3047
2024-10-30 15:11:57: [2024-10-30 15:11:57] iter = 16400, loss = 2.9644
2024-10-30 15:11:58: [2024-10-30 15:11:58] iter = 16410, loss = 1.3432
2024-10-30 15:11:58: [2024-10-30 15:11:58] iter = 16420, loss = 7.1311
2024-10-30 15:11:59: [2024-10-30 15:11:59] iter = 16430, loss = 5.4873
2024-10-30 15:12:00: [2024-10-30 15:12:00] iter = 16440, loss = 2.4334
2024-10-30 15:12:00: [2024-10-30 15:12:00] iter = 16450, loss = 4.8978
2024-10-30 15:12:01: [2024-10-30 15:12:01] iter = 16460, loss = 29.2496
2024-10-30 15:12:01: [2024-10-30 15:12:01] iter = 16470, loss = 4.1682
2024-10-30 15:12:02: [2024-10-30 15:12:02] iter = 16480, loss = 1.6430
2024-10-30 15:12:03: [2024-10-30 15:12:03] iter = 16490, loss = 1.9868
2024-10-30 15:12:04: [2024-10-30 15:12:04] iter = 16500, loss = 2.9482
2024-10-30 15:12:04: [2024-10-30 15:12:04] iter = 16510, loss = 3.3314
2024-10-30 15:12:05: [2024-10-30 15:12:05] iter = 16520, loss = 5.2448
2024-10-30 15:12:06: [2024-10-30 15:12:06] iter = 16530, loss = 2.2654
2024-10-30 15:12:07: [2024-10-30 15:12:07] iter = 16540, loss = 1.3227
2024-10-30 15:12:07: [2024-10-30 15:12:07] iter = 16550, loss = 2.4921
2024-10-30 15:12:08: [2024-10-30 15:12:08] iter = 16560, loss = 4.1882
2024-10-30 15:12:09: [2024-10-30 15:12:09] iter = 16570, loss = 1.3649
2024-10-30 15:12:10: [2024-10-30 15:12:10] iter = 16580, loss = 1.9758
2024-10-30 15:12:11: [2024-10-30 15:12:11] iter = 16590, loss = 2.0840
2024-10-30 15:12:12: [2024-10-30 15:12:12] iter = 16600, loss = 3.5729
2024-10-30 15:12:13: [2024-10-30 15:12:13] iter = 16610, loss = 1.7375
2024-10-30 15:12:14: [2024-10-30 15:12:14] iter = 16620, loss = 3.5399
2024-10-30 15:12:15: [2024-10-30 15:12:15] iter = 16630, loss = 17.4159
2024-10-30 15:12:16: [2024-10-30 15:12:16] iter = 16640, loss = 3.5839
2024-10-30 15:12:17: [2024-10-30 15:12:17] iter = 16650, loss = 11.8558
2024-10-30 15:12:18: [2024-10-30 15:12:18] iter = 16660, loss = 1.4272
2024-10-30 15:12:19: [2024-10-30 15:12:19] iter = 16670, loss = 3.8333
2024-10-30 15:12:20: [2024-10-30 15:12:20] iter = 16680, loss = 1.1753
2024-10-30 15:12:22: [2024-10-30 15:12:22] iter = 16690, loss = 1.3573
2024-10-30 15:12:23: [2024-10-30 15:12:23] iter = 16700, loss = 5.4727
2024-10-30 15:12:23: [2024-10-30 15:12:23] iter = 16710, loss = 1.3608
2024-10-30 15:12:24: [2024-10-30 15:12:24] iter = 16720, loss = 8.4238
2024-10-30 15:12:25: [2024-10-30 15:12:25] iter = 16730, loss = 3.0413
2024-10-30 15:12:27: [2024-10-30 15:12:27] iter = 16740, loss = 4.2305
2024-10-30 15:12:28: [2024-10-30 15:12:28] iter = 16750, loss = 4.3643
2024-10-30 15:12:28: [2024-10-30 15:12:28] iter = 16760, loss = 1.3966
2024-10-30 15:12:29: [2024-10-30 15:12:29] iter = 16770, loss = 2.9797
2024-10-30 15:12:30: [2024-10-30 15:12:30] iter = 16780, loss = 1.5413
2024-10-30 15:12:31: [2024-10-30 15:12:31] iter = 16790, loss = 27.3026
2024-10-30 15:12:32: [2024-10-30 15:12:32] iter = 16800, loss = 1.5647
2024-10-30 15:12:32: [2024-10-30 15:12:32] iter = 16810, loss = 2.7556
2024-10-30 15:12:33: [2024-10-30 15:12:33] iter = 16820, loss = 1.5936
2024-10-30 15:12:34: [2024-10-30 15:12:34] iter = 16830, loss = 21.3053
2024-10-30 15:12:35: [2024-10-30 15:12:35] iter = 16840, loss = 25.7893
2024-10-30 15:12:36: [2024-10-30 15:12:36] iter = 16850, loss = 24.1257
2024-10-30 15:12:37: [2024-10-30 15:12:37] iter = 16860, loss = 4.7408
2024-10-30 15:12:38: [2024-10-30 15:12:38] iter = 16870, loss = 1.4476
2024-10-30 15:12:39: [2024-10-30 15:12:39] iter = 16880, loss = 1.8331
2024-10-30 15:12:40: [2024-10-30 15:12:40] iter = 16890, loss = 1.9831
2024-10-30 15:12:41: [2024-10-30 15:12:41] iter = 16900, loss = 1.5437
2024-10-30 15:12:41: [2024-10-30 15:12:41] iter = 16910, loss = 1.4763
2024-10-30 15:12:42: [2024-10-30 15:12:42] iter = 16920, loss = 15.4928
2024-10-30 15:12:43: [2024-10-30 15:12:43] iter = 16930, loss = 2.7510
2024-10-30 15:12:44: [2024-10-30 15:12:44] iter = 16940, loss = 2.7676
2024-10-30 15:12:45: [2024-10-30 15:12:45] iter = 16950, loss = 2.2716
2024-10-30 15:12:46: [2024-10-30 15:12:46] iter = 16960, loss = 3.1723
2024-10-30 15:12:47: [2024-10-30 15:12:47] iter = 16970, loss = 3.3683
2024-10-30 15:12:47: [2024-10-30 15:12:47] iter = 16980, loss = 2.8920
2024-10-30 15:12:48: [2024-10-30 15:12:48] iter = 16990, loss = 5.9119
2024-10-30 15:12:48: [2024-10-30 15:12:48] iter = 17000, loss = 13.0328
2024-10-30 15:12:49: [2024-10-30 15:12:49] iter = 17010, loss = 1.4160
2024-10-30 15:12:50: [2024-10-30 15:12:50] iter = 17020, loss = 2.7038
2024-10-30 15:12:52: [2024-10-30 15:12:52] iter = 17030, loss = 31.8196
2024-10-30 15:12:53: [2024-10-30 15:12:53] iter = 17040, loss = 4.5017
2024-10-30 15:12:54: [2024-10-30 15:12:54] iter = 17050, loss = 1.4405
2024-10-30 15:12:54: [2024-10-30 15:12:54] iter = 17060, loss = 3.7844
2024-10-30 15:12:55: [2024-10-30 15:12:55] iter = 17070, loss = 1.8440
2024-10-30 15:12:56: [2024-10-30 15:12:56] iter = 17080, loss = 1.1466
2024-10-30 15:12:57: [2024-10-30 15:12:57] iter = 17090, loss = 1.2175
2024-10-30 15:12:58: [2024-10-30 15:12:58] iter = 17100, loss = 4.6186
2024-10-30 15:12:59: [2024-10-30 15:12:59] iter = 17110, loss = 2.7553
2024-10-30 15:12:59: [2024-10-30 15:12:59] iter = 17120, loss = 2.9349
2024-10-30 15:13:00: [2024-10-30 15:13:00] iter = 17130, loss = 5.5168
2024-10-30 15:13:01: [2024-10-30 15:13:01] iter = 17140, loss = 3.1861
2024-10-30 15:13:02: [2024-10-30 15:13:02] iter = 17150, loss = 15.6711
2024-10-30 15:13:03: [2024-10-30 15:13:03] iter = 17160, loss = 5.7070
2024-10-30 15:13:04: [2024-10-30 15:13:04] iter = 17170, loss = 3.4956
2024-10-30 15:13:05: [2024-10-30 15:13:05] iter = 17180, loss = 2.2901
2024-10-30 15:13:06: [2024-10-30 15:13:06] iter = 17190, loss = 59.9480
2024-10-30 15:13:07: [2024-10-30 15:13:07] iter = 17200, loss = 15.7311
2024-10-30 15:13:08: [2024-10-30 15:13:08] iter = 17210, loss = 1.2406
2024-10-30 15:13:09: [2024-10-30 15:13:09] iter = 17220, loss = 0.9305
2024-10-30 15:13:09: [2024-10-30 15:13:09] iter = 17230, loss = 1.7425
2024-10-30 15:13:10: [2024-10-30 15:13:10] iter = 17240, loss = 1.2546
2024-10-30 15:13:11: [2024-10-30 15:13:11] iter = 17250, loss = 1.1717
2024-10-30 15:13:12: [2024-10-30 15:13:12] iter = 17260, loss = 11.6371
2024-10-30 15:13:13: [2024-10-30 15:13:13] iter = 17270, loss = 4.6166
2024-10-30 15:13:14: [2024-10-30 15:13:14] iter = 17280, loss = 2.0601
2024-10-30 15:13:15: [2024-10-30 15:13:15] iter = 17290, loss = 3.7563
2024-10-30 15:13:15: [2024-10-30 15:13:15] iter = 17300, loss = 3.3526
2024-10-30 15:13:16: [2024-10-30 15:13:16] iter = 17310, loss = 3.5011
2024-10-30 15:13:17: [2024-10-30 15:13:17] iter = 17320, loss = 1.4244
2024-10-30 15:13:18: [2024-10-30 15:13:18] iter = 17330, loss = 4.2870
2024-10-30 15:13:18: [2024-10-30 15:13:18] iter = 17340, loss = 3.7587
2024-10-30 15:13:20: [2024-10-30 15:13:19] iter = 17350, loss = 2.4170
2024-10-30 15:13:21: [2024-10-30 15:13:21] iter = 17360, loss = 3.4736
2024-10-30 15:13:22: [2024-10-30 15:13:22] iter = 17370, loss = 1.0332
2024-10-30 15:13:23: [2024-10-30 15:13:23] iter = 17380, loss = 1.9532
2024-10-30 15:13:24: [2024-10-30 15:13:24] iter = 17390, loss = 1.3166
2024-10-30 15:13:25: [2024-10-30 15:13:25] iter = 17400, loss = 1.7585
2024-10-30 15:13:27: [2024-10-30 15:13:27] iter = 17410, loss = 1.4122
2024-10-30 15:13:28: [2024-10-30 15:13:28] iter = 17420, loss = 4.2091
2024-10-30 15:13:29: [2024-10-30 15:13:29] iter = 17430, loss = 1.9137
2024-10-30 15:13:30: [2024-10-30 15:13:30] iter = 17440, loss = 0.9185
2024-10-30 15:13:31: [2024-10-30 15:13:31] iter = 17450, loss = 1.0481
2024-10-30 15:13:31: [2024-10-30 15:13:31] iter = 17460, loss = 5.1385
2024-10-30 15:13:33: [2024-10-30 15:13:33] iter = 17470, loss = 10.7603
2024-10-30 15:13:34: [2024-10-30 15:13:34] iter = 17480, loss = 1.6281
2024-10-30 15:13:35: [2024-10-30 15:13:35] iter = 17490, loss = 8.4169
2024-10-30 15:13:36: [2024-10-30 15:13:36] iter = 17500, loss = 1.7478
2024-10-30 15:13:37: [2024-10-30 15:13:37] iter = 17510, loss = 1.7378
2024-10-30 15:13:38: [2024-10-30 15:13:38] iter = 17520, loss = 1.6638
2024-10-30 15:13:39: [2024-10-30 15:13:39] iter = 17530, loss = 7.4885
2024-10-30 15:13:40: [2024-10-30 15:13:40] iter = 17540, loss = 2.2217
2024-10-30 15:13:41: [2024-10-30 15:13:41] iter = 17550, loss = 14.2082
2024-10-30 15:13:42: [2024-10-30 15:13:42] iter = 17560, loss = 6.5166
2024-10-30 15:13:43: [2024-10-30 15:13:43] iter = 17570, loss = 22.9484
2024-10-30 15:13:43: [2024-10-30 15:13:43] iter = 17580, loss = 9.0128
2024-10-30 15:13:44: [2024-10-30 15:13:44] iter = 17590, loss = 1.6556
2024-10-30 15:13:45: [2024-10-30 15:13:45] iter = 17600, loss = 2.1469
2024-10-30 15:13:46: [2024-10-30 15:13:46] iter = 17610, loss = 1.1506
2024-10-30 15:13:46: [2024-10-30 15:13:46] iter = 17620, loss = 1.2176
2024-10-30 15:13:47: [2024-10-30 15:13:47] iter = 17630, loss = 13.9423
2024-10-30 15:13:47: [2024-10-30 15:13:47] iter = 17640, loss = 4.9200
2024-10-30 15:13:48: [2024-10-30 15:13:48] iter = 17650, loss = 8.8145
2024-10-30 15:13:49: [2024-10-30 15:13:49] iter = 17660, loss = 2.0937
2024-10-30 15:13:50: [2024-10-30 15:13:50] iter = 17670, loss = 5.6876
2024-10-30 15:13:50: [2024-10-30 15:13:50] iter = 17680, loss = 3.4540
2024-10-30 15:13:51: [2024-10-30 15:13:51] iter = 17690, loss = 1.8663
2024-10-30 15:13:52: [2024-10-30 15:13:52] iter = 17700, loss = 1.1665
2024-10-30 15:13:52: [2024-10-30 15:13:52] iter = 17710, loss = 1.2079
2024-10-30 15:13:53: [2024-10-30 15:13:53] iter = 17720, loss = 1.5068
2024-10-30 15:13:54: [2024-10-30 15:13:54] iter = 17730, loss = 1.6887
2024-10-30 15:13:55: [2024-10-30 15:13:55] iter = 17740, loss = 3.0335
2024-10-30 15:13:56: [2024-10-30 15:13:56] iter = 17750, loss = 8.0328
2024-10-30 15:13:57: [2024-10-30 15:13:57] iter = 17760, loss = 1.9881
2024-10-30 15:13:59: [2024-10-30 15:13:59] iter = 17770, loss = 2.8281
2024-10-30 15:13:59: [2024-10-30 15:13:59] iter = 17780, loss = 1.6916
2024-10-30 15:14:01: [2024-10-30 15:14:01] iter = 17790, loss = 1.1155
2024-10-30 15:14:02: [2024-10-30 15:14:02] iter = 17800, loss = 1.6650
2024-10-30 15:14:03: [2024-10-30 15:14:03] iter = 17810, loss = 5.6242
2024-10-30 15:14:04: [2024-10-30 15:14:04] iter = 17820, loss = 2.3853
2024-10-30 15:14:05: [2024-10-30 15:14:05] iter = 17830, loss = 1.3915
2024-10-30 15:14:06: [2024-10-30 15:14:06] iter = 17840, loss = 1.9785
2024-10-30 15:14:07: [2024-10-30 15:14:07] iter = 17850, loss = 4.6610
2024-10-30 15:14:09: [2024-10-30 15:14:09] iter = 17860, loss = 1.3644
2024-10-30 15:14:10: [2024-10-30 15:14:10] iter = 17870, loss = 4.5477
2024-10-30 15:14:11: [2024-10-30 15:14:11] iter = 17880, loss = 10.0540
2024-10-30 15:14:12: [2024-10-30 15:14:12] iter = 17890, loss = 1.7377
2024-10-30 15:14:12: [2024-10-30 15:14:12] iter = 17900, loss = 11.8921
2024-10-30 15:14:14: [2024-10-30 15:14:14] iter = 17910, loss = 1.5835
2024-10-30 15:14:15: [2024-10-30 15:14:15] iter = 17920, loss = 3.5214
2024-10-30 15:14:16: [2024-10-30 15:14:16] iter = 17930, loss = 17.9425
2024-10-30 15:14:17: [2024-10-30 15:14:17] iter = 17940, loss = 5.0061
2024-10-30 15:14:18: [2024-10-30 15:14:18] iter = 17950, loss = 1.7589
2024-10-30 15:14:19: [2024-10-30 15:14:19] iter = 17960, loss = 1.3621
2024-10-30 15:14:20: [2024-10-30 15:14:20] iter = 17970, loss = 1.3980
2024-10-30 15:14:22: [2024-10-30 15:14:22] iter = 17980, loss = 5.0608
2024-10-30 15:14:23: [2024-10-30 15:14:23] iter = 17990, loss = 2.5387
2024-10-30 15:14:24: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 15:14:24: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:14:24: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 64123}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:15:58: Evaluate 5 random ConvNet, ACCmean = 0.6615 ACCstd = 0.0085
-------------------------
2024-10-30 15:15:58: Evaluate 5 random ConvNet, SENmean = 0.7128 SENstd = 0.0165
-------------------------
2024-10-30 15:15:58: Evaluate 5 random ConvNet, SPEmean = 0.7128 SPEstd = 0.0165
-------------------------
2024-10-30 15:15:58: Evaluate 5 random ConvNet, F!mean = 0.6446 F!std = 0.0104
-------------------------
2024-10-30 15:15:58: Evaluate 5 random ConvNet, mean = 0.6615 std = 0.0085
-------------------------
2024-10-30 15:15:58: [2024-10-30 15:15:58] iter = 18000, loss = 2.1391
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:15:59: [2024-10-30 15:15:59] iter = 18010, loss = 2.3903
2024-10-30 15:16:00: [2024-10-30 15:16:00] iter = 18020, loss = 2.2180
2024-10-30 15:16:01: [2024-10-30 15:16:01] iter = 18030, loss = 9.4084
2024-10-30 15:16:02: [2024-10-30 15:16:02] iter = 18040, loss = 11.0945
2024-10-30 15:16:02: [2024-10-30 15:16:02] iter = 18050, loss = 2.2915
2024-10-30 15:16:03: [2024-10-30 15:16:03] iter = 18060, loss = 2.9256
2024-10-30 15:16:04: [2024-10-30 15:16:04] iter = 18070, loss = 1.7688
2024-10-30 15:16:05: [2024-10-30 15:16:05] iter = 18080, loss = 12.2574
2024-10-30 15:16:06: [2024-10-30 15:16:06] iter = 18090, loss = 2.3144
2024-10-30 15:16:07: [2024-10-30 15:16:07] iter = 18100, loss = 1.3978
2024-10-30 15:16:08: [2024-10-30 15:16:08] iter = 18110, loss = 1.8581
2024-10-30 15:16:09: [2024-10-30 15:16:09] iter = 18120, loss = 1.6530
2024-10-30 15:16:10: [2024-10-30 15:16:10] iter = 18130, loss = 2.1170
2024-10-30 15:16:11: [2024-10-30 15:16:11] iter = 18140, loss = 19.8321
2024-10-30 15:16:12: [2024-10-30 15:16:12] iter = 18150, loss = 2.3857
2024-10-30 15:16:13: [2024-10-30 15:16:13] iter = 18160, loss = 4.2717
2024-10-30 15:16:14: [2024-10-30 15:16:14] iter = 18170, loss = 1.3489
2024-10-30 15:16:15: [2024-10-30 15:16:15] iter = 18180, loss = 2.9480
2024-10-30 15:16:15: [2024-10-30 15:16:15] iter = 18190, loss = 6.9791
2024-10-30 15:16:16: [2024-10-30 15:16:16] iter = 18200, loss = 7.1088
2024-10-30 15:16:17: [2024-10-30 15:16:17] iter = 18210, loss = 3.1823
2024-10-30 15:16:19: [2024-10-30 15:16:19] iter = 18220, loss = 1.5896
2024-10-30 15:16:20: [2024-10-30 15:16:20] iter = 18230, loss = 1.3239
2024-10-30 15:16:21: [2024-10-30 15:16:21] iter = 18240, loss = 3.8939
2024-10-30 15:16:22: [2024-10-30 15:16:22] iter = 18250, loss = 1.7486
2024-10-30 15:16:22: [2024-10-30 15:16:22] iter = 18260, loss = 22.9353
2024-10-30 15:16:24: [2024-10-30 15:16:24] iter = 18270, loss = 3.5784
2024-10-30 15:16:24: [2024-10-30 15:16:24] iter = 18280, loss = 2.9952
2024-10-30 15:16:25: [2024-10-30 15:16:25] iter = 18290, loss = 6.8438
2024-10-30 15:16:26: [2024-10-30 15:16:26] iter = 18300, loss = 2.1829
2024-10-30 15:16:28: [2024-10-30 15:16:28] iter = 18310, loss = 21.0640
2024-10-30 15:16:29: [2024-10-30 15:16:29] iter = 18320, loss = 3.0490
2024-10-30 15:16:29: [2024-10-30 15:16:29] iter = 18330, loss = 3.6800
2024-10-30 15:16:30: [2024-10-30 15:16:30] iter = 18340, loss = 3.7767
2024-10-30 15:16:31: [2024-10-30 15:16:31] iter = 18350, loss = 3.7434
2024-10-30 15:16:32: [2024-10-30 15:16:32] iter = 18360, loss = 2.6577
2024-10-30 15:16:33: [2024-10-30 15:16:33] iter = 18370, loss = 1.7305
2024-10-30 15:16:34: [2024-10-30 15:16:34] iter = 18380, loss = 6.7567
2024-10-30 15:16:35: [2024-10-30 15:16:35] iter = 18390, loss = 2.2043
2024-10-30 15:16:36: [2024-10-30 15:16:36] iter = 18400, loss = 1.1725
2024-10-30 15:16:37: [2024-10-30 15:16:37] iter = 18410, loss = 1.5186
2024-10-30 15:16:38: [2024-10-30 15:16:38] iter = 18420, loss = 3.2635
2024-10-30 15:16:38: [2024-10-30 15:16:38] iter = 18430, loss = 23.2368
2024-10-30 15:16:39: [2024-10-30 15:16:39] iter = 18440, loss = 5.0229
2024-10-30 15:16:40: [2024-10-30 15:16:40] iter = 18450, loss = 4.9933
2024-10-30 15:16:41: [2024-10-30 15:16:41] iter = 18460, loss = 1.5777
2024-10-30 15:16:42: [2024-10-30 15:16:42] iter = 18470, loss = 3.1807
2024-10-30 15:16:43: [2024-10-30 15:16:43] iter = 18480, loss = 2.6229
2024-10-30 15:16:44: [2024-10-30 15:16:44] iter = 18490, loss = 3.4742
2024-10-30 15:16:45: [2024-10-30 15:16:45] iter = 18500, loss = 7.7685
2024-10-30 15:16:46: [2024-10-30 15:16:46] iter = 18510, loss = 6.1145
2024-10-30 15:16:47: [2024-10-30 15:16:47] iter = 18520, loss = 1.9006
2024-10-30 15:16:48: [2024-10-30 15:16:48] iter = 18530, loss = 20.9712
2024-10-30 15:16:48: [2024-10-30 15:16:48] iter = 18540, loss = 3.5554
2024-10-30 15:16:50: [2024-10-30 15:16:50] iter = 18550, loss = 1.2773
2024-10-30 15:16:51: [2024-10-30 15:16:51] iter = 18560, loss = 0.9670
2024-10-30 15:16:52: [2024-10-30 15:16:52] iter = 18570, loss = 1.6027
2024-10-30 15:16:53: [2024-10-30 15:16:53] iter = 18580, loss = 2.6897
2024-10-30 15:16:54: [2024-10-30 15:16:54] iter = 18590, loss = 2.0679
2024-10-30 15:16:55: [2024-10-30 15:16:55] iter = 18600, loss = 7.9100
2024-10-30 15:16:56: [2024-10-30 15:16:56] iter = 18610, loss = 14.6404
2024-10-30 15:16:57: [2024-10-30 15:16:56] iter = 18620, loss = 4.6891
2024-10-30 15:16:57: [2024-10-30 15:16:57] iter = 18630, loss = 4.0032
2024-10-30 15:16:58: [2024-10-30 15:16:58] iter = 18640, loss = 2.2824
2024-10-30 15:16:59: [2024-10-30 15:16:59] iter = 18650, loss = 16.0092
2024-10-30 15:17:01: [2024-10-30 15:17:01] iter = 18660, loss = 44.1421
2024-10-30 15:17:02: [2024-10-30 15:17:02] iter = 18670, loss = 8.6028
2024-10-30 15:17:03: [2024-10-30 15:17:03] iter = 18680, loss = 2.6144
2024-10-30 15:17:04: [2024-10-30 15:17:04] iter = 18690, loss = 6.0700
2024-10-30 15:17:04: [2024-10-30 15:17:04] iter = 18700, loss = 4.8062
2024-10-30 15:17:05: [2024-10-30 15:17:05] iter = 18710, loss = 5.7626
2024-10-30 15:17:06: [2024-10-30 15:17:06] iter = 18720, loss = 5.0015
2024-10-30 15:17:08: [2024-10-30 15:17:08] iter = 18730, loss = 8.3938
2024-10-30 15:17:09: [2024-10-30 15:17:09] iter = 18740, loss = 4.3861
2024-10-30 15:17:09: [2024-10-30 15:17:09] iter = 18750, loss = 10.8140
2024-10-30 15:17:11: [2024-10-30 15:17:11] iter = 18760, loss = 2.7848
2024-10-30 15:17:12: [2024-10-30 15:17:12] iter = 18770, loss = 1.5717
2024-10-30 15:17:13: [2024-10-30 15:17:13] iter = 18780, loss = 3.7456
2024-10-30 15:17:14: [2024-10-30 15:17:14] iter = 18790, loss = 1.3980
2024-10-30 15:17:15: [2024-10-30 15:17:15] iter = 18800, loss = 1.2488
2024-10-30 15:17:16: [2024-10-30 15:17:16] iter = 18810, loss = 1.6995
2024-10-30 15:17:17: [2024-10-30 15:17:17] iter = 18820, loss = 4.8182
2024-10-30 15:17:18: [2024-10-30 15:17:18] iter = 18830, loss = 1.8295
2024-10-30 15:17:19: [2024-10-30 15:17:19] iter = 18840, loss = 1.6780
2024-10-30 15:17:20: [2024-10-30 15:17:20] iter = 18850, loss = 1.9367
2024-10-30 15:17:21: [2024-10-30 15:17:21] iter = 18860, loss = 2.3151
2024-10-30 15:17:21: [2024-10-30 15:17:21] iter = 18870, loss = 1.5041
2024-10-30 15:17:22: [2024-10-30 15:17:22] iter = 18880, loss = 2.0352
2024-10-30 15:17:23: [2024-10-30 15:17:23] iter = 18890, loss = 12.0780
2024-10-30 15:17:24: [2024-10-30 15:17:24] iter = 18900, loss = 1.8687
2024-10-30 15:17:25: [2024-10-30 15:17:25] iter = 18910, loss = 1.5345
2024-10-30 15:17:27: [2024-10-30 15:17:26] iter = 18920, loss = 2.0723
2024-10-30 15:17:28: [2024-10-30 15:17:28] iter = 18930, loss = 2.3954
2024-10-30 15:17:29: [2024-10-30 15:17:29] iter = 18940, loss = 1.2723
2024-10-30 15:17:30: [2024-10-30 15:17:30] iter = 18950, loss = 3.5812
2024-10-30 15:17:32: [2024-10-30 15:17:32] iter = 18960, loss = 1.9967
2024-10-30 15:17:33: [2024-10-30 15:17:33] iter = 18970, loss = 1.4455
2024-10-30 15:17:34: [2024-10-30 15:17:34] iter = 18980, loss = 2.4131
2024-10-30 15:17:35: [2024-10-30 15:17:35] iter = 18990, loss = 13.6805
2024-10-30 15:17:36: [2024-10-30 15:17:36] iter = 19000, loss = 7.2052
2024-10-30 15:17:37: [2024-10-30 15:17:37] iter = 19010, loss = 3.8056
2024-10-30 15:17:38: [2024-10-30 15:17:38] iter = 19020, loss = 2.0361
2024-10-30 15:17:39: [2024-10-30 15:17:39] iter = 19030, loss = 2.3402
2024-10-30 15:17:40: [2024-10-30 15:17:40] iter = 19040, loss = 1.2550
2024-10-30 15:17:41: [2024-10-30 15:17:41] iter = 19050, loss = 1.2234
2024-10-30 15:17:41: [2024-10-30 15:17:41] iter = 19060, loss = 1.3822
2024-10-30 15:17:43: [2024-10-30 15:17:43] iter = 19070, loss = 1.0882
2024-10-30 15:17:43: [2024-10-30 15:17:43] iter = 19080, loss = 25.6967
2024-10-30 15:17:45: [2024-10-30 15:17:45] iter = 19090, loss = 1.5903
2024-10-30 15:17:46: [2024-10-30 15:17:46] iter = 19100, loss = 13.0125
2024-10-30 15:17:47: [2024-10-30 15:17:47] iter = 19110, loss = 2.0329
2024-10-30 15:17:48: [2024-10-30 15:17:48] iter = 19120, loss = 9.0790
2024-10-30 15:17:48: [2024-10-30 15:17:48] iter = 19130, loss = 1.5410
2024-10-30 15:17:49: [2024-10-30 15:17:49] iter = 19140, loss = 26.5801
2024-10-30 15:17:50: [2024-10-30 15:17:50] iter = 19150, loss = 3.0100
2024-10-30 15:17:51: [2024-10-30 15:17:51] iter = 19160, loss = 1.5619
2024-10-30 15:17:52: [2024-10-30 15:17:52] iter = 19170, loss = 11.7871
2024-10-30 15:17:52: [2024-10-30 15:17:52] iter = 19180, loss = 17.4188
2024-10-30 15:17:53: [2024-10-30 15:17:53] iter = 19190, loss = 2.2036
2024-10-30 15:17:54: [2024-10-30 15:17:54] iter = 19200, loss = 1.8209
2024-10-30 15:17:55: [2024-10-30 15:17:55] iter = 19210, loss = 27.1627
2024-10-30 15:17:56: [2024-10-30 15:17:56] iter = 19220, loss = 4.8754
2024-10-30 15:17:57: [2024-10-30 15:17:57] iter = 19230, loss = 4.4591
2024-10-30 15:17:58: [2024-10-30 15:17:58] iter = 19240, loss = 2.3606
2024-10-30 15:17:59: [2024-10-30 15:17:59] iter = 19250, loss = 1.2398
2024-10-30 15:18:00: [2024-10-30 15:18:00] iter = 19260, loss = 3.9981
2024-10-30 15:18:01: [2024-10-30 15:18:01] iter = 19270, loss = 11.4110
2024-10-30 15:18:02: [2024-10-30 15:18:02] iter = 19280, loss = 4.7968
2024-10-30 15:18:03: [2024-10-30 15:18:03] iter = 19290, loss = 1.9887
2024-10-30 15:18:04: [2024-10-30 15:18:04] iter = 19300, loss = 1.9699
2024-10-30 15:18:05: [2024-10-30 15:18:05] iter = 19310, loss = 1.3783
2024-10-30 15:18:06: [2024-10-30 15:18:06] iter = 19320, loss = 1.0258
2024-10-30 15:18:07: [2024-10-30 15:18:07] iter = 19330, loss = 1.7092
2024-10-30 15:18:08: [2024-10-30 15:18:08] iter = 19340, loss = 2.3448
2024-10-30 15:18:09: [2024-10-30 15:18:09] iter = 19350, loss = 1.8610
2024-10-30 15:18:10: [2024-10-30 15:18:10] iter = 19360, loss = 1.5666
2024-10-30 15:18:11: [2024-10-30 15:18:11] iter = 19370, loss = 2.1858
2024-10-30 15:18:12: [2024-10-30 15:18:12] iter = 19380, loss = 1.1576
2024-10-30 15:18:13: [2024-10-30 15:18:13] iter = 19390, loss = 3.0642
2024-10-30 15:18:13: [2024-10-30 15:18:13] iter = 19400, loss = 4.5464
2024-10-30 15:18:14: [2024-10-30 15:18:14] iter = 19410, loss = 3.0523
2024-10-30 15:18:15: [2024-10-30 15:18:15] iter = 19420, loss = 3.2823
2024-10-30 15:18:15: [2024-10-30 15:18:15] iter = 19430, loss = 6.8222
2024-10-30 15:18:16: [2024-10-30 15:18:16] iter = 19440, loss = 1.7106
2024-10-30 15:18:18: [2024-10-30 15:18:18] iter = 19450, loss = 7.6148
2024-10-30 15:18:19: [2024-10-30 15:18:19] iter = 19460, loss = 2.2487
2024-10-30 15:18:20: [2024-10-30 15:18:20] iter = 19470, loss = 1.6382
2024-10-30 15:18:21: [2024-10-30 15:18:21] iter = 19480, loss = 3.1517
2024-10-30 15:18:22: [2024-10-30 15:18:22] iter = 19490, loss = 1.5053
2024-10-30 15:18:23: [2024-10-30 15:18:23] iter = 19500, loss = 5.2429
2024-10-30 15:18:24: [2024-10-30 15:18:24] iter = 19510, loss = 4.8119
2024-10-30 15:18:25: [2024-10-30 15:18:25] iter = 19520, loss = 2.5389
2024-10-30 15:18:26: [2024-10-30 15:18:26] iter = 19530, loss = 3.3346
2024-10-30 15:18:27: [2024-10-30 15:18:27] iter = 19540, loss = 1.4905
2024-10-30 15:18:28: [2024-10-30 15:18:28] iter = 19550, loss = 9.8613
2024-10-30 15:18:29: [2024-10-30 15:18:29] iter = 19560, loss = 11.5050
2024-10-30 15:18:30: [2024-10-30 15:18:30] iter = 19570, loss = 11.3148
2024-10-30 15:18:31: [2024-10-30 15:18:31] iter = 19580, loss = 9.1103
2024-10-30 15:18:32: [2024-10-30 15:18:32] iter = 19590, loss = 19.1020
2024-10-30 15:18:33: [2024-10-30 15:18:33] iter = 19600, loss = 4.9921
2024-10-30 15:18:34: [2024-10-30 15:18:34] iter = 19610, loss = 2.2214
2024-10-30 15:18:36: [2024-10-30 15:18:36] iter = 19620, loss = 5.7373
2024-10-30 15:18:37: [2024-10-30 15:18:37] iter = 19630, loss = 4.0667
2024-10-30 15:18:38: [2024-10-30 15:18:38] iter = 19640, loss = 1.7261
2024-10-30 15:18:38: [2024-10-30 15:18:38] iter = 19650, loss = 1.4563
2024-10-30 15:18:39: [2024-10-30 15:18:39] iter = 19660, loss = 11.3544
2024-10-30 15:18:40: [2024-10-30 15:18:40] iter = 19670, loss = 2.0171
2024-10-30 15:18:41: [2024-10-30 15:18:41] iter = 19680, loss = 3.4756
2024-10-30 15:18:42: [2024-10-30 15:18:42] iter = 19690, loss = 3.8756
2024-10-30 15:18:44: [2024-10-30 15:18:44] iter = 19700, loss = 3.4424
2024-10-30 15:18:45: [2024-10-30 15:18:45] iter = 19710, loss = 7.4527
2024-10-30 15:18:46: [2024-10-30 15:18:46] iter = 19720, loss = 3.0714
2024-10-30 15:18:47: [2024-10-30 15:18:47] iter = 19730, loss = 1.4807
2024-10-30 15:18:48: [2024-10-30 15:18:48] iter = 19740, loss = 3.2275
2024-10-30 15:18:49: [2024-10-30 15:18:49] iter = 19750, loss = 1.9017
2024-10-30 15:18:49: [2024-10-30 15:18:49] iter = 19760, loss = 7.2608
2024-10-30 15:18:50: [2024-10-30 15:18:50] iter = 19770, loss = 1.8250
2024-10-30 15:18:51: [2024-10-30 15:18:51] iter = 19780, loss = 15.1418
2024-10-30 15:18:52: [2024-10-30 15:18:52] iter = 19790, loss = 1.2562
2024-10-30 15:18:53: [2024-10-30 15:18:53] iter = 19800, loss = 7.3121
2024-10-30 15:18:54: [2024-10-30 15:18:54] iter = 19810, loss = 12.8998
2024-10-30 15:18:55: [2024-10-30 15:18:55] iter = 19820, loss = 5.2667
2024-10-30 15:18:56: [2024-10-30 15:18:56] iter = 19830, loss = 2.1519
2024-10-30 15:18:58: [2024-10-30 15:18:58] iter = 19840, loss = 2.3888
2024-10-30 15:18:59: [2024-10-30 15:18:59] iter = 19850, loss = 1.1780
2024-10-30 15:19:00: [2024-10-30 15:19:00] iter = 19860, loss = 1.5411
2024-10-30 15:19:01: [2024-10-30 15:19:01] iter = 19870, loss = 6.7476
2024-10-30 15:19:02: [2024-10-30 15:19:02] iter = 19880, loss = 5.5767
2024-10-30 15:19:03: [2024-10-30 15:19:03] iter = 19890, loss = 2.1334
2024-10-30 15:19:04: [2024-10-30 15:19:04] iter = 19900, loss = 1.2421
2024-10-30 15:19:04: [2024-10-30 15:19:04] iter = 19910, loss = 2.6400
2024-10-30 15:19:05: [2024-10-30 15:19:05] iter = 19920, loss = 1.5198
2024-10-30 15:19:06: [2024-10-30 15:19:06] iter = 19930, loss = 2.3817
2024-10-30 15:19:07: [2024-10-30 15:19:07] iter = 19940, loss = 8.0235
2024-10-30 15:19:09: [2024-10-30 15:19:09] iter = 19950, loss = 1.4284
2024-10-30 15:19:10: [2024-10-30 15:19:10] iter = 19960, loss = 2.3838
2024-10-30 15:19:11: [2024-10-30 15:19:11] iter = 19970, loss = 8.3303
2024-10-30 15:19:12: [2024-10-30 15:19:12] iter = 19980, loss = 1.0071
2024-10-30 15:19:13: [2024-10-30 15:19:13] iter = 19990, loss = 2.8677
2024-10-30 15:19:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 15:19:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:19:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 54814}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:20:46: Evaluate 5 random ConvNet, ACCmean = 0.7167 ACCstd = 0.0154
-------------------------
2024-10-30 15:20:46: Evaluate 5 random ConvNet, SENmean = 0.7385 SENstd = 0.0114
-------------------------
2024-10-30 15:20:46: Evaluate 5 random ConvNet, SPEmean = 0.7385 SPEstd = 0.0114
-------------------------
2024-10-30 15:20:46: Evaluate 5 random ConvNet, F!mean = 0.6897 F!std = 0.0114
-------------------------
2024-10-30 15:20:46: Evaluate 5 random ConvNet, mean = 0.7167 std = 0.0154
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:20:46: [2024-10-30 15:20:46] iter = 20000, loss = 1.9782
2024-10-30 15:20:46: 
================== Exp 2 ==================
 
2024-10-30 15:20:46: Hyper-parameters: 
{'dataset': 'BreastMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ff878e0ab20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_BreastMNIST (INFO)>}
2024-10-30 15:20:46: Evaluation model pool: ['ConvNet']
2024-10-30 15:20:46: class c = 0: 147 real images
2024-10-30 15:20:46: class c = 1: 399 real images
2024-10-30 15:20:46: real images channel 0, mean = 0.3276, std = 0.2057
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 15:20:46: initialize synthetic data from random real images
2024-10-30 15:20:46: [2024-10-30 15:20:46] training begins
2024-10-30 15:20:46: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 15:20:46: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:20:46: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 46598}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:22:18: Evaluate 5 random ConvNet, ACCmean = 0.6372 ACCstd = 0.0316
-------------------------
2024-10-30 15:22:18: Evaluate 5 random ConvNet, SENmean = 0.6330 SENstd = 0.0191
-------------------------
2024-10-30 15:22:18: Evaluate 5 random ConvNet, SPEmean = 0.6330 SPEstd = 0.0191
-------------------------
2024-10-30 15:22:18: Evaluate 5 random ConvNet, F!mean = 0.6008 F!std = 0.0249
-------------------------
2024-10-30 15:22:18: Evaluate 5 random ConvNet, mean = 0.6372 std = 0.0316
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:22:18: [2024-10-30 15:22:18] iter = 00000, loss = 10.0584
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:22:19: [2024-10-30 15:22:19] iter = 00010, loss = 4.9227
2024-10-30 15:22:20: [2024-10-30 15:22:20] iter = 00020, loss = 5.7368
2024-10-30 15:22:21: [2024-10-30 15:22:21] iter = 00030, loss = 2.1179
2024-10-30 15:22:21: [2024-10-30 15:22:21] iter = 00040, loss = 13.0283
2024-10-30 15:22:22: [2024-10-30 15:22:22] iter = 00050, loss = 3.8402
2024-10-30 15:22:23: [2024-10-30 15:22:23] iter = 00060, loss = 3.9498
2024-10-30 15:22:24: [2024-10-30 15:22:24] iter = 00070, loss = 2.0923
2024-10-30 15:22:25: [2024-10-30 15:22:25] iter = 00080, loss = 7.0680
2024-10-30 15:22:26: [2024-10-30 15:22:26] iter = 00090, loss = 1.9617
2024-10-30 15:22:27: [2024-10-30 15:22:27] iter = 00100, loss = 4.1325
2024-10-30 15:22:28: [2024-10-30 15:22:28] iter = 00110, loss = 20.0558
2024-10-30 15:22:29: [2024-10-30 15:22:29] iter = 00120, loss = 6.6117
2024-10-30 15:22:30: [2024-10-30 15:22:30] iter = 00130, loss = 5.0621
2024-10-30 15:22:31: [2024-10-30 15:22:31] iter = 00140, loss = 7.7610
2024-10-30 15:22:32: [2024-10-30 15:22:32] iter = 00150, loss = 2.7034
2024-10-30 15:22:33: [2024-10-30 15:22:33] iter = 00160, loss = 1.6704
2024-10-30 15:22:34: [2024-10-30 15:22:34] iter = 00170, loss = 3.2336
2024-10-30 15:22:35: [2024-10-30 15:22:35] iter = 00180, loss = 1.5754
2024-10-30 15:22:36: [2024-10-30 15:22:36] iter = 00190, loss = 4.1823
2024-10-30 15:22:37: [2024-10-30 15:22:37] iter = 00200, loss = 2.2350
2024-10-30 15:22:38: [2024-10-30 15:22:38] iter = 00210, loss = 4.0769
2024-10-30 15:22:39: [2024-10-30 15:22:39] iter = 00220, loss = 14.7581
2024-10-30 15:22:40: [2024-10-30 15:22:40] iter = 00230, loss = 2.0847
2024-10-30 15:22:41: [2024-10-30 15:22:41] iter = 00240, loss = 2.5003
2024-10-30 15:22:41: [2024-10-30 15:22:41] iter = 00250, loss = 6.4487
2024-10-30 15:22:42: [2024-10-30 15:22:42] iter = 00260, loss = 1.5383
2024-10-30 15:22:43: [2024-10-30 15:22:43] iter = 00270, loss = 3.4276
2024-10-30 15:22:44: [2024-10-30 15:22:44] iter = 00280, loss = 2.4829
2024-10-30 15:22:45: [2024-10-30 15:22:45] iter = 00290, loss = 1.6404
2024-10-30 15:22:46: [2024-10-30 15:22:46] iter = 00300, loss = 1.9294
2024-10-30 15:22:46: [2024-10-30 15:22:46] iter = 00310, loss = 1.4674
2024-10-30 15:22:47: [2024-10-30 15:22:47] iter = 00320, loss = 1.6876
2024-10-30 15:22:48: [2024-10-30 15:22:48] iter = 00330, loss = 6.3574
2024-10-30 15:22:49: [2024-10-30 15:22:49] iter = 00340, loss = 4.2416
2024-10-30 15:22:50: [2024-10-30 15:22:50] iter = 00350, loss = 2.9372
2024-10-30 15:22:51: [2024-10-30 15:22:51] iter = 00360, loss = 1.4050
2024-10-30 15:22:52: [2024-10-30 15:22:52] iter = 00370, loss = 5.2971
2024-10-30 15:22:53: [2024-10-30 15:22:53] iter = 00380, loss = 1.5413
2024-10-30 15:22:54: [2024-10-30 15:22:54] iter = 00390, loss = 3.4610
2024-10-30 15:22:55: [2024-10-30 15:22:55] iter = 00400, loss = 1.5254
2024-10-30 15:22:56: [2024-10-30 15:22:56] iter = 00410, loss = 2.5809
2024-10-30 15:22:57: [2024-10-30 15:22:57] iter = 00420, loss = 14.3754
2024-10-30 15:22:58: [2024-10-30 15:22:58] iter = 00430, loss = 1.5365
2024-10-30 15:22:59: [2024-10-30 15:22:59] iter = 00440, loss = 5.3654
2024-10-30 15:23:00: [2024-10-30 15:23:00] iter = 00450, loss = 13.6273
2024-10-30 15:23:01: [2024-10-30 15:23:01] iter = 00460, loss = 6.6257
2024-10-30 15:23:02: [2024-10-30 15:23:02] iter = 00470, loss = 8.2809
2024-10-30 15:23:03: [2024-10-30 15:23:03] iter = 00480, loss = 5.1827
2024-10-30 15:23:04: [2024-10-30 15:23:04] iter = 00490, loss = 2.3544
2024-10-30 15:23:04: [2024-10-30 15:23:04] iter = 00500, loss = 1.4013
2024-10-30 15:23:06: [2024-10-30 15:23:06] iter = 00510, loss = 1.3218
2024-10-30 15:23:06: [2024-10-30 15:23:06] iter = 00520, loss = 3.1451
2024-10-30 15:23:07: [2024-10-30 15:23:07] iter = 00530, loss = 3.1066
2024-10-30 15:23:08: [2024-10-30 15:23:08] iter = 00540, loss = 13.9063
2024-10-30 15:23:09: [2024-10-30 15:23:09] iter = 00550, loss = 4.1428
2024-10-30 15:23:10: [2024-10-30 15:23:10] iter = 00560, loss = 5.3595
2024-10-30 15:23:11: [2024-10-30 15:23:11] iter = 00570, loss = 2.8905
2024-10-30 15:23:12: [2024-10-30 15:23:12] iter = 00580, loss = 3.3262
2024-10-30 15:23:12: [2024-10-30 15:23:12] iter = 00590, loss = 1.7441
2024-10-30 15:23:14: [2024-10-30 15:23:14] iter = 00600, loss = 6.9209
2024-10-30 15:23:15: [2024-10-30 15:23:15] iter = 00610, loss = 3.6957
2024-10-30 15:23:16: [2024-10-30 15:23:16] iter = 00620, loss = 2.8375
2024-10-30 15:23:17: [2024-10-30 15:23:17] iter = 00630, loss = 2.7053
2024-10-30 15:23:17: [2024-10-30 15:23:17] iter = 00640, loss = 6.0808
2024-10-30 15:23:19: [2024-10-30 15:23:19] iter = 00650, loss = 1.1597
2024-10-30 15:23:19: [2024-10-30 15:23:19] iter = 00660, loss = 1.7463
2024-10-30 15:23:20: [2024-10-30 15:23:20] iter = 00670, loss = 1.2978
2024-10-30 15:23:21: [2024-10-30 15:23:21] iter = 00680, loss = 1.3931
2024-10-30 15:23:22: [2024-10-30 15:23:22] iter = 00690, loss = 7.2032
2024-10-30 15:23:23: [2024-10-30 15:23:23] iter = 00700, loss = 2.2054
2024-10-30 15:23:24: [2024-10-30 15:23:24] iter = 00710, loss = 4.4958
2024-10-30 15:23:25: [2024-10-30 15:23:25] iter = 00720, loss = 2.3688
2024-10-30 15:23:26: [2024-10-30 15:23:26] iter = 00730, loss = 2.3870
2024-10-30 15:23:26: [2024-10-30 15:23:26] iter = 00740, loss = 1.3677
2024-10-30 15:23:27: [2024-10-30 15:23:27] iter = 00750, loss = 6.0461
2024-10-30 15:23:28: [2024-10-30 15:23:28] iter = 00760, loss = 1.3272
2024-10-30 15:23:30: [2024-10-30 15:23:30] iter = 00770, loss = 0.9963
2024-10-30 15:23:31: [2024-10-30 15:23:31] iter = 00780, loss = 3.3104
2024-10-30 15:23:32: [2024-10-30 15:23:32] iter = 00790, loss = 1.2740
2024-10-30 15:23:33: [2024-10-30 15:23:33] iter = 00800, loss = 1.7871
2024-10-30 15:23:34: [2024-10-30 15:23:34] iter = 00810, loss = 9.4852
2024-10-30 15:23:35: [2024-10-30 15:23:35] iter = 00820, loss = 9.1163
2024-10-30 15:23:36: [2024-10-30 15:23:36] iter = 00830, loss = 3.8761
2024-10-30 15:23:37: [2024-10-30 15:23:37] iter = 00840, loss = 1.7870
2024-10-30 15:23:38: [2024-10-30 15:23:38] iter = 00850, loss = 2.8513
2024-10-30 15:23:38: [2024-10-30 15:23:38] iter = 00860, loss = 5.9693
2024-10-30 15:23:39: [2024-10-30 15:23:39] iter = 00870, loss = 24.3101
2024-10-30 15:23:40: [2024-10-30 15:23:40] iter = 00880, loss = 15.2793
2024-10-30 15:23:41: [2024-10-30 15:23:41] iter = 00890, loss = 3.1728
2024-10-30 15:23:42: [2024-10-30 15:23:42] iter = 00900, loss = 2.2232
2024-10-30 15:23:43: [2024-10-30 15:23:43] iter = 00910, loss = 8.9946
2024-10-30 15:23:44: [2024-10-30 15:23:44] iter = 00920, loss = 19.6823
2024-10-30 15:23:44: [2024-10-30 15:23:44] iter = 00930, loss = 2.3574
2024-10-30 15:23:45: [2024-10-30 15:23:45] iter = 00940, loss = 5.8868
2024-10-30 15:23:46: [2024-10-30 15:23:46] iter = 00950, loss = 1.5765
2024-10-30 15:23:47: [2024-10-30 15:23:47] iter = 00960, loss = 34.2032
2024-10-30 15:23:48: [2024-10-30 15:23:48] iter = 00970, loss = 3.3163
2024-10-30 15:23:49: [2024-10-30 15:23:49] iter = 00980, loss = 3.3329
2024-10-30 15:23:50: [2024-10-30 15:23:50] iter = 00990, loss = 5.0255
2024-10-30 15:23:50: [2024-10-30 15:23:50] iter = 01000, loss = 2.8306
2024-10-30 15:23:51: [2024-10-30 15:23:51] iter = 01010, loss = 3.0061
2024-10-30 15:23:52: [2024-10-30 15:23:52] iter = 01020, loss = 3.1485
2024-10-30 15:23:53: [2024-10-30 15:23:53] iter = 01030, loss = 1.9730
2024-10-30 15:23:54: [2024-10-30 15:23:54] iter = 01040, loss = 3.2478
2024-10-30 15:23:54: [2024-10-30 15:23:54] iter = 01050, loss = 1.7524
2024-10-30 15:23:55: [2024-10-30 15:23:55] iter = 01060, loss = 2.4166
2024-10-30 15:23:56: [2024-10-30 15:23:56] iter = 01070, loss = 1.6933
2024-10-30 15:23:58: [2024-10-30 15:23:58] iter = 01080, loss = 1.4501
2024-10-30 15:23:59: [2024-10-30 15:23:59] iter = 01090, loss = 1.1243
2024-10-30 15:24:00: [2024-10-30 15:24:00] iter = 01100, loss = 2.8597
2024-10-30 15:24:01: [2024-10-30 15:24:01] iter = 01110, loss = 1.2726
2024-10-30 15:24:02: [2024-10-30 15:24:02] iter = 01120, loss = 2.9006
2024-10-30 15:24:03: [2024-10-30 15:24:03] iter = 01130, loss = 1.3484
2024-10-30 15:24:04: [2024-10-30 15:24:04] iter = 01140, loss = 5.7739
2024-10-30 15:24:06: [2024-10-30 15:24:06] iter = 01150, loss = 1.8455
2024-10-30 15:24:07: [2024-10-30 15:24:07] iter = 01160, loss = 1.7749
2024-10-30 15:24:08: [2024-10-30 15:24:08] iter = 01170, loss = 4.1611
2024-10-30 15:24:09: [2024-10-30 15:24:09] iter = 01180, loss = 2.7833
2024-10-30 15:24:10: [2024-10-30 15:24:10] iter = 01190, loss = 1.3529
2024-10-30 15:24:11: [2024-10-30 15:24:11] iter = 01200, loss = 1.3110
2024-10-30 15:24:12: [2024-10-30 15:24:12] iter = 01210, loss = 5.8928
2024-10-30 15:24:13: [2024-10-30 15:24:13] iter = 01220, loss = 10.8068
2024-10-30 15:24:14: [2024-10-30 15:24:14] iter = 01230, loss = 1.8345
2024-10-30 15:24:15: [2024-10-30 15:24:15] iter = 01240, loss = 5.8110
2024-10-30 15:24:16: [2024-10-30 15:24:16] iter = 01250, loss = 2.2379
2024-10-30 15:24:17: [2024-10-30 15:24:17] iter = 01260, loss = 4.1911
2024-10-30 15:24:18: [2024-10-30 15:24:18] iter = 01270, loss = 28.6421
2024-10-30 15:24:19: [2024-10-30 15:24:19] iter = 01280, loss = 3.8620
2024-10-30 15:24:20: [2024-10-30 15:24:20] iter = 01290, loss = 1.3191
2024-10-30 15:24:21: [2024-10-30 15:24:21] iter = 01300, loss = 2.4843
2024-10-30 15:24:22: [2024-10-30 15:24:22] iter = 01310, loss = 1.4316
2024-10-30 15:24:23: [2024-10-30 15:24:23] iter = 01320, loss = 17.6306
2024-10-30 15:24:23: [2024-10-30 15:24:23] iter = 01330, loss = 1.5969
2024-10-30 15:24:24: [2024-10-30 15:24:24] iter = 01340, loss = 2.8465
2024-10-30 15:24:25: [2024-10-30 15:24:25] iter = 01350, loss = 4.0451
2024-10-30 15:24:26: [2024-10-30 15:24:26] iter = 01360, loss = 1.6522
2024-10-30 15:24:27: [2024-10-30 15:24:27] iter = 01370, loss = 1.7733
2024-10-30 15:24:28: [2024-10-30 15:24:28] iter = 01380, loss = 2.5387
2024-10-30 15:24:29: [2024-10-30 15:24:29] iter = 01390, loss = 2.9848
2024-10-30 15:24:30: [2024-10-30 15:24:30] iter = 01400, loss = 2.7560
2024-10-30 15:24:31: [2024-10-30 15:24:31] iter = 01410, loss = 3.4375
2024-10-30 15:24:32: [2024-10-30 15:24:32] iter = 01420, loss = 1.5747
2024-10-30 15:24:33: [2024-10-30 15:24:33] iter = 01430, loss = 2.1571
2024-10-30 15:24:34: [2024-10-30 15:24:34] iter = 01440, loss = 2.4657
2024-10-30 15:24:35: [2024-10-30 15:24:35] iter = 01450, loss = 1.1226
2024-10-30 15:24:36: [2024-10-30 15:24:36] iter = 01460, loss = 1.4362
2024-10-30 15:24:37: [2024-10-30 15:24:37] iter = 01470, loss = 1.6772
2024-10-30 15:24:38: [2024-10-30 15:24:38] iter = 01480, loss = 1.1122
2024-10-30 15:24:38: [2024-10-30 15:24:38] iter = 01490, loss = 18.5866
2024-10-30 15:24:39: [2024-10-30 15:24:39] iter = 01500, loss = 17.2435
2024-10-30 15:24:40: [2024-10-30 15:24:40] iter = 01510, loss = 1.7940
2024-10-30 15:24:42: [2024-10-30 15:24:42] iter = 01520, loss = 2.1385
2024-10-30 15:24:43: [2024-10-30 15:24:43] iter = 01530, loss = 3.1467
2024-10-30 15:24:44: [2024-10-30 15:24:44] iter = 01540, loss = 2.3086
2024-10-30 15:24:45: [2024-10-30 15:24:45] iter = 01550, loss = 2.0569
2024-10-30 15:24:46: [2024-10-30 15:24:46] iter = 01560, loss = 1.4638
2024-10-30 15:24:48: [2024-10-30 15:24:48] iter = 01570, loss = 1.8121
2024-10-30 15:24:49: [2024-10-30 15:24:49] iter = 01580, loss = 5.3712
2024-10-30 15:24:50: [2024-10-30 15:24:50] iter = 01590, loss = 1.2038
2024-10-30 15:24:51: [2024-10-30 15:24:51] iter = 01600, loss = 2.8196
2024-10-30 15:24:52: [2024-10-30 15:24:52] iter = 01610, loss = 1.2274
2024-10-30 15:24:53: [2024-10-30 15:24:53] iter = 01620, loss = 7.5852
2024-10-30 15:24:54: [2024-10-30 15:24:54] iter = 01630, loss = 4.1074
2024-10-30 15:24:55: [2024-10-30 15:24:55] iter = 01640, loss = 9.5195
2024-10-30 15:24:56: [2024-10-30 15:24:56] iter = 01650, loss = 7.1410
2024-10-30 15:24:57: [2024-10-30 15:24:57] iter = 01660, loss = 4.7926
2024-10-30 15:24:58: [2024-10-30 15:24:58] iter = 01670, loss = 3.1854
2024-10-30 15:24:59: [2024-10-30 15:24:59] iter = 01680, loss = 1.3262
2024-10-30 15:24:59: [2024-10-30 15:24:59] iter = 01690, loss = 2.8020
2024-10-30 15:25:00: [2024-10-30 15:25:00] iter = 01700, loss = 2.1875
2024-10-30 15:25:00: [2024-10-30 15:25:00] iter = 01710, loss = 5.2075
2024-10-30 15:25:01: [2024-10-30 15:25:01] iter = 01720, loss = 4.4591
2024-10-30 15:25:02: [2024-10-30 15:25:02] iter = 01730, loss = 16.3884
2024-10-30 15:25:03: [2024-10-30 15:25:03] iter = 01740, loss = 4.8127
2024-10-30 15:25:04: [2024-10-30 15:25:04] iter = 01750, loss = 2.4959
2024-10-30 15:25:05: [2024-10-30 15:25:05] iter = 01760, loss = 2.9033
2024-10-30 15:25:06: [2024-10-30 15:25:06] iter = 01770, loss = 1.6285
2024-10-30 15:25:07: [2024-10-30 15:25:07] iter = 01780, loss = 2.5953
2024-10-30 15:25:08: [2024-10-30 15:25:08] iter = 01790, loss = 4.3542
2024-10-30 15:25:09: [2024-10-30 15:25:09] iter = 01800, loss = 3.4457
2024-10-30 15:25:10: [2024-10-30 15:25:10] iter = 01810, loss = 1.8022
2024-10-30 15:25:11: [2024-10-30 15:25:11] iter = 01820, loss = 2.1976
2024-10-30 15:25:12: [2024-10-30 15:25:12] iter = 01830, loss = 2.3193
2024-10-30 15:25:13: [2024-10-30 15:25:13] iter = 01840, loss = 2.0007
2024-10-30 15:25:14: [2024-10-30 15:25:14] iter = 01850, loss = 1.2789
2024-10-30 15:25:15: [2024-10-30 15:25:15] iter = 01860, loss = 2.2963
2024-10-30 15:25:16: [2024-10-30 15:25:16] iter = 01870, loss = 1.9228
2024-10-30 15:25:17: [2024-10-30 15:25:17] iter = 01880, loss = 1.4412
2024-10-30 15:25:18: [2024-10-30 15:25:18] iter = 01890, loss = 2.3393
2024-10-30 15:25:19: [2024-10-30 15:25:19] iter = 01900, loss = 2.3498
2024-10-30 15:25:20: [2024-10-30 15:25:20] iter = 01910, loss = 1.5234
2024-10-30 15:25:21: [2024-10-30 15:25:21] iter = 01920, loss = 5.2368
2024-10-30 15:25:22: [2024-10-30 15:25:22] iter = 01930, loss = 1.2499
2024-10-30 15:25:23: [2024-10-30 15:25:23] iter = 01940, loss = 5.0043
2024-10-30 15:25:24: [2024-10-30 15:25:24] iter = 01950, loss = 5.3379
2024-10-30 15:25:25: [2024-10-30 15:25:25] iter = 01960, loss = 1.8635
2024-10-30 15:25:25: [2024-10-30 15:25:25] iter = 01970, loss = 1.9794
2024-10-30 15:25:26: [2024-10-30 15:25:26] iter = 01980, loss = 5.6928
2024-10-30 15:25:27: [2024-10-30 15:25:27] iter = 01990, loss = 1.5106
2024-10-30 15:25:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 15:25:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:25:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 27330}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:26:51: Evaluate 5 random ConvNet, ACCmean = 0.7538 ACCstd = 0.0265
-------------------------
2024-10-30 15:26:51: Evaluate 5 random ConvNet, SENmean = 0.7383 SENstd = 0.0186
-------------------------
2024-10-30 15:26:51: Evaluate 5 random ConvNet, SPEmean = 0.7383 SPEstd = 0.0186
-------------------------
2024-10-30 15:26:51: Evaluate 5 random ConvNet, F!mean = 0.7139 F!std = 0.0236
-------------------------
2024-10-30 15:26:51: Evaluate 5 random ConvNet, mean = 0.7538 std = 0.0265
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:26:51: [2024-10-30 15:26:51] iter = 02000, loss = 1.4306
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:26:52: [2024-10-30 15:26:52] iter = 02010, loss = 3.5839
2024-10-30 15:26:54: [2024-10-30 15:26:54] iter = 02020, loss = 29.2337
2024-10-30 15:26:54: [2024-10-30 15:26:54] iter = 02030, loss = 2.8920
2024-10-30 15:26:55: [2024-10-30 15:26:55] iter = 02040, loss = 1.4001
2024-10-30 15:26:56: [2024-10-30 15:26:56] iter = 02050, loss = 1.3021
2024-10-30 15:26:56: [2024-10-30 15:26:56] iter = 02060, loss = 2.4889
2024-10-30 15:26:57: [2024-10-30 15:26:57] iter = 02070, loss = 2.5610
2024-10-30 15:26:58: [2024-10-30 15:26:58] iter = 02080, loss = 4.0444
2024-10-30 15:26:59: [2024-10-30 15:26:59] iter = 02090, loss = 5.0658
2024-10-30 15:27:00: [2024-10-30 15:27:00] iter = 02100, loss = 2.0532
2024-10-30 15:27:01: [2024-10-30 15:27:01] iter = 02110, loss = 2.5332
2024-10-30 15:27:02: [2024-10-30 15:27:02] iter = 02120, loss = 2.4536
2024-10-30 15:27:03: [2024-10-30 15:27:03] iter = 02130, loss = 18.1623
2024-10-30 15:27:03: [2024-10-30 15:27:03] iter = 02140, loss = 5.0167
2024-10-30 15:27:04: [2024-10-30 15:27:04] iter = 02150, loss = 3.3750
2024-10-30 15:27:05: [2024-10-30 15:27:05] iter = 02160, loss = 6.8916
2024-10-30 15:27:06: [2024-10-30 15:27:06] iter = 02170, loss = 1.3239
2024-10-30 15:27:07: [2024-10-30 15:27:07] iter = 02180, loss = 1.0398
2024-10-30 15:27:08: [2024-10-30 15:27:08] iter = 02190, loss = 2.1043
2024-10-30 15:27:09: [2024-10-30 15:27:09] iter = 02200, loss = 1.3636
2024-10-30 15:27:10: [2024-10-30 15:27:10] iter = 02210, loss = 1.5041
2024-10-30 15:27:11: [2024-10-30 15:27:11] iter = 02220, loss = 1.7023
2024-10-30 15:27:12: [2024-10-30 15:27:12] iter = 02230, loss = 1.2890
2024-10-30 15:27:13: [2024-10-30 15:27:13] iter = 02240, loss = 27.6961
2024-10-30 15:27:14: [2024-10-30 15:27:14] iter = 02250, loss = 1.8376
2024-10-30 15:27:15: [2024-10-30 15:27:15] iter = 02260, loss = 2.0429
2024-10-30 15:27:16: [2024-10-30 15:27:16] iter = 02270, loss = 1.8076
2024-10-30 15:27:17: [2024-10-30 15:27:17] iter = 02280, loss = 1.6068
2024-10-30 15:27:17: [2024-10-30 15:27:17] iter = 02290, loss = 3.3659
2024-10-30 15:27:18: [2024-10-30 15:27:18] iter = 02300, loss = 1.2349
2024-10-30 15:27:20: [2024-10-30 15:27:20] iter = 02310, loss = 17.9511
2024-10-30 15:27:21: [2024-10-30 15:27:21] iter = 02320, loss = 2.2507
2024-10-30 15:27:21: [2024-10-30 15:27:21] iter = 02330, loss = 7.1141
2024-10-30 15:27:23: [2024-10-30 15:27:23] iter = 02340, loss = 1.9817
2024-10-30 15:27:24: [2024-10-30 15:27:24] iter = 02350, loss = 4.4264
2024-10-30 15:27:24: [2024-10-30 15:27:24] iter = 02360, loss = 10.2143
2024-10-30 15:27:25: [2024-10-30 15:27:25] iter = 02370, loss = 1.4750
2024-10-30 15:27:26: [2024-10-30 15:27:26] iter = 02380, loss = 5.3183
2024-10-30 15:27:27: [2024-10-30 15:27:27] iter = 02390, loss = 7.4554
2024-10-30 15:27:28: [2024-10-30 15:27:28] iter = 02400, loss = 1.4333
2024-10-30 15:27:30: [2024-10-30 15:27:30] iter = 02410, loss = 1.1715
2024-10-30 15:27:31: [2024-10-30 15:27:31] iter = 02420, loss = 8.2994
2024-10-30 15:27:31: [2024-10-30 15:27:31] iter = 02430, loss = 1.3561
2024-10-30 15:27:32: [2024-10-30 15:27:32] iter = 02440, loss = 1.2623
2024-10-30 15:27:33: [2024-10-30 15:27:33] iter = 02450, loss = 3.4152
2024-10-30 15:27:34: [2024-10-30 15:27:34] iter = 02460, loss = 11.4316
2024-10-30 15:27:35: [2024-10-30 15:27:35] iter = 02470, loss = 2.2236
2024-10-30 15:27:36: [2024-10-30 15:27:36] iter = 02480, loss = 4.7428
2024-10-30 15:27:37: [2024-10-30 15:27:37] iter = 02490, loss = 10.0811
2024-10-30 15:27:38: [2024-10-30 15:27:38] iter = 02500, loss = 1.5666
2024-10-30 15:27:39: [2024-10-30 15:27:39] iter = 02510, loss = 1.8254
2024-10-30 15:27:40: [2024-10-30 15:27:40] iter = 02520, loss = 1.8012
2024-10-30 15:27:41: [2024-10-30 15:27:41] iter = 02530, loss = 1.5152
2024-10-30 15:27:42: [2024-10-30 15:27:42] iter = 02540, loss = 4.5171
2024-10-30 15:27:43: [2024-10-30 15:27:43] iter = 02550, loss = 1.1498
2024-10-30 15:27:44: [2024-10-30 15:27:44] iter = 02560, loss = 5.6443
2024-10-30 15:27:45: [2024-10-30 15:27:45] iter = 02570, loss = 17.8724
2024-10-30 15:27:46: [2024-10-30 15:27:46] iter = 02580, loss = 11.7987
2024-10-30 15:27:47: [2024-10-30 15:27:47] iter = 02590, loss = 2.4033
2024-10-30 15:27:47: [2024-10-30 15:27:47] iter = 02600, loss = 4.3993
2024-10-30 15:27:48: [2024-10-30 15:27:48] iter = 02610, loss = 2.9928
2024-10-30 15:27:49: [2024-10-30 15:27:49] iter = 02620, loss = 6.6550
2024-10-30 15:27:50: [2024-10-30 15:27:50] iter = 02630, loss = 2.0591
2024-10-30 15:27:51: [2024-10-30 15:27:51] iter = 02640, loss = 5.0996
2024-10-30 15:27:52: [2024-10-30 15:27:52] iter = 02650, loss = 7.2372
2024-10-30 15:27:53: [2024-10-30 15:27:53] iter = 02660, loss = 1.5232
2024-10-30 15:27:53: [2024-10-30 15:27:53] iter = 02670, loss = 10.6843
2024-10-30 15:27:54: [2024-10-30 15:27:54] iter = 02680, loss = 3.6331
2024-10-30 15:27:55: [2024-10-30 15:27:55] iter = 02690, loss = 1.6207
2024-10-30 15:27:56: [2024-10-30 15:27:56] iter = 02700, loss = 4.6633
2024-10-30 15:27:57: [2024-10-30 15:27:57] iter = 02710, loss = 1.4988
2024-10-30 15:27:58: [2024-10-30 15:27:58] iter = 02720, loss = 4.5653
2024-10-30 15:27:59: [2024-10-30 15:27:59] iter = 02730, loss = 1.7893
2024-10-30 15:28:00: [2024-10-30 15:28:00] iter = 02740, loss = 2.9884
2024-10-30 15:28:01: [2024-10-30 15:28:01] iter = 02750, loss = 11.7272
2024-10-30 15:28:02: [2024-10-30 15:28:02] iter = 02760, loss = 2.3145
2024-10-30 15:28:02: [2024-10-30 15:28:02] iter = 02770, loss = 2.7072
2024-10-30 15:28:03: [2024-10-30 15:28:03] iter = 02780, loss = 2.5730
2024-10-30 15:28:04: [2024-10-30 15:28:04] iter = 02790, loss = 2.1880
2024-10-30 15:28:05: [2024-10-30 15:28:05] iter = 02800, loss = 3.3642
2024-10-30 15:28:06: [2024-10-30 15:28:06] iter = 02810, loss = 2.7159
2024-10-30 15:28:06: [2024-10-30 15:28:06] iter = 02820, loss = 9.4018
2024-10-30 15:28:07: [2024-10-30 15:28:07] iter = 02830, loss = 2.7414
2024-10-30 15:28:08: [2024-10-30 15:28:08] iter = 02840, loss = 4.9620
2024-10-30 15:28:09: [2024-10-30 15:28:09] iter = 02850, loss = 2.9857
2024-10-30 15:28:10: [2024-10-30 15:28:10] iter = 02860, loss = 2.2652
2024-10-30 15:28:11: [2024-10-30 15:28:11] iter = 02870, loss = 2.3879
2024-10-30 15:28:12: [2024-10-30 15:28:12] iter = 02880, loss = 5.2679
2024-10-30 15:28:13: [2024-10-30 15:28:13] iter = 02890, loss = 1.6601
2024-10-30 15:28:14: [2024-10-30 15:28:14] iter = 02900, loss = 1.3309
2024-10-30 15:28:14: [2024-10-30 15:28:14] iter = 02910, loss = 2.2525
2024-10-30 15:28:15: [2024-10-30 15:28:15] iter = 02920, loss = 2.5010
2024-10-30 15:28:16: [2024-10-30 15:28:16] iter = 02930, loss = 1.4818
2024-10-30 15:28:17: [2024-10-30 15:28:17] iter = 02940, loss = 1.8535
2024-10-30 15:28:18: [2024-10-30 15:28:18] iter = 02950, loss = 0.9325
2024-10-30 15:28:18: [2024-10-30 15:28:18] iter = 02960, loss = 4.1498
2024-10-30 15:28:19: [2024-10-30 15:28:19] iter = 02970, loss = 5.3344
2024-10-30 15:28:20: [2024-10-30 15:28:20] iter = 02980, loss = 6.8522
2024-10-30 15:28:21: [2024-10-30 15:28:21] iter = 02990, loss = 12.8699
2024-10-30 15:28:22: [2024-10-30 15:28:22] iter = 03000, loss = 1.9860
2024-10-30 15:28:24: [2024-10-30 15:28:24] iter = 03010, loss = 4.6862
2024-10-30 15:28:24: [2024-10-30 15:28:24] iter = 03020, loss = 3.6659
2024-10-30 15:28:26: [2024-10-30 15:28:26] iter = 03030, loss = 2.6185
2024-10-30 15:28:27: [2024-10-30 15:28:27] iter = 03040, loss = 1.3039
2024-10-30 15:28:28: [2024-10-30 15:28:28] iter = 03050, loss = 1.6598
2024-10-30 15:28:29: [2024-10-30 15:28:29] iter = 03060, loss = 11.5742
2024-10-30 15:28:30: [2024-10-30 15:28:30] iter = 03070, loss = 1.5956
2024-10-30 15:28:31: [2024-10-30 15:28:31] iter = 03080, loss = 4.2429
2024-10-30 15:28:31: [2024-10-30 15:28:31] iter = 03090, loss = 2.1774
2024-10-30 15:28:32: [2024-10-30 15:28:32] iter = 03100, loss = 1.3090
2024-10-30 15:28:33: [2024-10-30 15:28:33] iter = 03110, loss = 9.4097
2024-10-30 15:28:34: [2024-10-30 15:28:34] iter = 03120, loss = 7.0748
2024-10-30 15:28:35: [2024-10-30 15:28:35] iter = 03130, loss = 11.1387
2024-10-30 15:28:36: [2024-10-30 15:28:36] iter = 03140, loss = 3.4320
2024-10-30 15:28:37: [2024-10-30 15:28:37] iter = 03150, loss = 2.0749
2024-10-30 15:28:38: [2024-10-30 15:28:38] iter = 03160, loss = 10.3758
2024-10-30 15:28:39: [2024-10-30 15:28:39] iter = 03170, loss = 3.5134
2024-10-30 15:28:40: [2024-10-30 15:28:40] iter = 03180, loss = 1.4497
2024-10-30 15:28:41: [2024-10-30 15:28:41] iter = 03190, loss = 2.3767
2024-10-30 15:28:43: [2024-10-30 15:28:43] iter = 03200, loss = 3.8671
2024-10-30 15:28:43: [2024-10-30 15:28:43] iter = 03210, loss = 14.7234
2024-10-30 15:28:44: [2024-10-30 15:28:44] iter = 03220, loss = 1.9567
2024-10-30 15:28:45: [2024-10-30 15:28:45] iter = 03230, loss = 11.7214
2024-10-30 15:28:46: [2024-10-30 15:28:46] iter = 03240, loss = 1.2441
2024-10-30 15:28:47: [2024-10-30 15:28:47] iter = 03250, loss = 19.7444
2024-10-30 15:28:48: [2024-10-30 15:28:48] iter = 03260, loss = 3.0282
2024-10-30 15:28:49: [2024-10-30 15:28:49] iter = 03270, loss = 44.1996
2024-10-30 15:28:50: [2024-10-30 15:28:50] iter = 03280, loss = 18.7636
2024-10-30 15:28:51: [2024-10-30 15:28:51] iter = 03290, loss = 1.5581
2024-10-30 15:28:52: [2024-10-30 15:28:52] iter = 03300, loss = 2.6119
2024-10-30 15:28:53: [2024-10-30 15:28:53] iter = 03310, loss = 4.1743
2024-10-30 15:28:54: [2024-10-30 15:28:54] iter = 03320, loss = 2.7524
2024-10-30 15:28:54: [2024-10-30 15:28:54] iter = 03330, loss = 21.4889
2024-10-30 15:28:56: [2024-10-30 15:28:56] iter = 03340, loss = 6.8575
2024-10-30 15:28:56: [2024-10-30 15:28:56] iter = 03350, loss = 1.4293
2024-10-30 15:28:57: [2024-10-30 15:28:57] iter = 03360, loss = 3.7862
2024-10-30 15:28:58: [2024-10-30 15:28:58] iter = 03370, loss = 2.6318
2024-10-30 15:28:59: [2024-10-30 15:28:59] iter = 03380, loss = 1.8014
2024-10-30 15:29:00: [2024-10-30 15:29:00] iter = 03390, loss = 2.4026
2024-10-30 15:29:01: [2024-10-30 15:29:01] iter = 03400, loss = 3.4914
2024-10-30 15:29:01: [2024-10-30 15:29:01] iter = 03410, loss = 18.6326
2024-10-30 15:29:03: [2024-10-30 15:29:03] iter = 03420, loss = 1.7828
2024-10-30 15:29:03: [2024-10-30 15:29:03] iter = 03430, loss = 1.2913
2024-10-30 15:29:04: [2024-10-30 15:29:04] iter = 03440, loss = 4.6336
2024-10-30 15:29:05: [2024-10-30 15:29:05] iter = 03450, loss = 2.6985
2024-10-30 15:29:05: [2024-10-30 15:29:05] iter = 03460, loss = 1.6932
2024-10-30 15:29:06: [2024-10-30 15:29:06] iter = 03470, loss = 1.6106
2024-10-30 15:29:07: [2024-10-30 15:29:07] iter = 03480, loss = 8.6388
2024-10-30 15:29:07: [2024-10-30 15:29:07] iter = 03490, loss = 1.3338
2024-10-30 15:29:08: [2024-10-30 15:29:08] iter = 03500, loss = 1.5233
2024-10-30 15:29:09: [2024-10-30 15:29:09] iter = 03510, loss = 1.8131
2024-10-30 15:29:10: [2024-10-30 15:29:10] iter = 03520, loss = 1.8250
2024-10-30 15:29:11: [2024-10-30 15:29:11] iter = 03530, loss = 4.7158
2024-10-30 15:29:11: [2024-10-30 15:29:11] iter = 03540, loss = 2.7542
2024-10-30 15:29:12: [2024-10-30 15:29:12] iter = 03550, loss = 6.7150
2024-10-30 15:29:14: [2024-10-30 15:29:13] iter = 03560, loss = 1.6949
2024-10-30 15:29:14: [2024-10-30 15:29:14] iter = 03570, loss = 3.6109
2024-10-30 15:29:15: [2024-10-30 15:29:15] iter = 03580, loss = 1.8289
2024-10-30 15:29:16: [2024-10-30 15:29:16] iter = 03590, loss = 3.9464
2024-10-30 15:29:17: [2024-10-30 15:29:17] iter = 03600, loss = 2.5680
2024-10-30 15:29:18: [2024-10-30 15:29:18] iter = 03610, loss = 2.2096
2024-10-30 15:29:20: [2024-10-30 15:29:20] iter = 03620, loss = 9.4450
2024-10-30 15:29:20: [2024-10-30 15:29:20] iter = 03630, loss = 1.6950
2024-10-30 15:29:22: [2024-10-30 15:29:21] iter = 03640, loss = 4.8063
2024-10-30 15:29:22: [2024-10-30 15:29:22] iter = 03650, loss = 2.9222
2024-10-30 15:29:23: [2024-10-30 15:29:23] iter = 03660, loss = 1.7830
2024-10-30 15:29:24: [2024-10-30 15:29:24] iter = 03670, loss = 1.3395
2024-10-30 15:29:24: [2024-10-30 15:29:24] iter = 03680, loss = 10.7657
2024-10-30 15:29:26: [2024-10-30 15:29:26] iter = 03690, loss = 2.9150
2024-10-30 15:29:27: [2024-10-30 15:29:27] iter = 03700, loss = 9.7024
2024-10-30 15:29:27: [2024-10-30 15:29:27] iter = 03710, loss = 2.5823
2024-10-30 15:29:29: [2024-10-30 15:29:29] iter = 03720, loss = 5.3436
2024-10-30 15:29:30: [2024-10-30 15:29:30] iter = 03730, loss = 4.7673
2024-10-30 15:29:31: [2024-10-30 15:29:31] iter = 03740, loss = 1.1457
2024-10-30 15:29:31: [2024-10-30 15:29:31] iter = 03750, loss = 4.5912
2024-10-30 15:29:32: [2024-10-30 15:29:32] iter = 03760, loss = 4.5604
2024-10-30 15:29:33: [2024-10-30 15:29:33] iter = 03770, loss = 2.6979
2024-10-30 15:29:34: [2024-10-30 15:29:34] iter = 03780, loss = 2.8034
2024-10-30 15:29:35: [2024-10-30 15:29:35] iter = 03790, loss = 2.8128
2024-10-30 15:29:36: [2024-10-30 15:29:36] iter = 03800, loss = 5.3280
2024-10-30 15:29:37: [2024-10-30 15:29:37] iter = 03810, loss = 1.5698
2024-10-30 15:29:37: [2024-10-30 15:29:37] iter = 03820, loss = 1.3663
2024-10-30 15:29:38: [2024-10-30 15:29:38] iter = 03830, loss = 2.7961
2024-10-30 15:29:39: [2024-10-30 15:29:39] iter = 03840, loss = 1.3456
2024-10-30 15:29:40: [2024-10-30 15:29:40] iter = 03850, loss = 10.4279
2024-10-30 15:29:41: [2024-10-30 15:29:41] iter = 03860, loss = 2.8845
2024-10-30 15:29:42: [2024-10-30 15:29:42] iter = 03870, loss = 3.0375
2024-10-30 15:29:43: [2024-10-30 15:29:43] iter = 03880, loss = 1.7925
2024-10-30 15:29:44: [2024-10-30 15:29:44] iter = 03890, loss = 2.3929
2024-10-30 15:29:44: [2024-10-30 15:29:44] iter = 03900, loss = 1.8122
2024-10-30 15:29:45: [2024-10-30 15:29:45] iter = 03910, loss = 1.5775
2024-10-30 15:29:46: [2024-10-30 15:29:46] iter = 03920, loss = 3.0253
2024-10-30 15:29:47: [2024-10-30 15:29:47] iter = 03930, loss = 3.1100
2024-10-30 15:29:48: [2024-10-30 15:29:48] iter = 03940, loss = 5.3523
2024-10-30 15:29:48: [2024-10-30 15:29:48] iter = 03950, loss = 8.2919
2024-10-30 15:29:49: [2024-10-30 15:29:49] iter = 03960, loss = 5.6471
2024-10-30 15:29:51: [2024-10-30 15:29:51] iter = 03970, loss = 6.4708
2024-10-30 15:29:51: [2024-10-30 15:29:51] iter = 03980, loss = 2.3730
2024-10-30 15:29:52: [2024-10-30 15:29:52] iter = 03990, loss = 2.2818
2024-10-30 15:29:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 15:29:53: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:29:53: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 93286}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:31:30: Evaluate 5 random ConvNet, ACCmean = 0.7141 ACCstd = 0.0065
-------------------------
2024-10-30 15:31:30: Evaluate 5 random ConvNet, SENmean = 0.4976 SENstd = 0.0049
-------------------------
2024-10-30 15:31:30: Evaluate 5 random ConvNet, SPEmean = 0.4976 SPEstd = 0.0049
-------------------------
2024-10-30 15:31:30: Evaluate 5 random ConvNet, F!mean = 0.4412 F!std = 0.0075
-------------------------
2024-10-30 15:31:30: Evaluate 5 random ConvNet, mean = 0.7141 std = 0.0065
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:31:30: [2024-10-30 15:31:30] iter = 04000, loss = 17.2957
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:31:31: [2024-10-30 15:31:31] iter = 04010, loss = 4.9948
2024-10-30 15:31:32: [2024-10-30 15:31:32] iter = 04020, loss = 1.6485
2024-10-30 15:31:33: [2024-10-30 15:31:33] iter = 04030, loss = 5.4452
2024-10-30 15:31:35: [2024-10-30 15:31:35] iter = 04040, loss = 1.3035
2024-10-30 15:31:35: [2024-10-30 15:31:35] iter = 04050, loss = 13.4207
2024-10-30 15:31:36: [2024-10-30 15:31:36] iter = 04060, loss = 3.5686
2024-10-30 15:31:37: [2024-10-30 15:31:37] iter = 04070, loss = 2.5952
2024-10-30 15:31:38: [2024-10-30 15:31:38] iter = 04080, loss = 4.3993
2024-10-30 15:31:39: [2024-10-30 15:31:39] iter = 04090, loss = 2.0015
2024-10-30 15:31:40: [2024-10-30 15:31:40] iter = 04100, loss = 3.1465
2024-10-30 15:31:41: [2024-10-30 15:31:41] iter = 04110, loss = 8.0009
2024-10-30 15:31:41: [2024-10-30 15:31:41] iter = 04120, loss = 3.0674
2024-10-30 15:31:42: [2024-10-30 15:31:42] iter = 04130, loss = 1.8435
2024-10-30 15:31:43: [2024-10-30 15:31:43] iter = 04140, loss = 3.0936
2024-10-30 15:31:44: [2024-10-30 15:31:44] iter = 04150, loss = 12.0050
2024-10-30 15:31:44: [2024-10-30 15:31:44] iter = 04160, loss = 2.7679
2024-10-30 15:31:45: [2024-10-30 15:31:45] iter = 04170, loss = 5.4861
2024-10-30 15:31:46: [2024-10-30 15:31:46] iter = 04180, loss = 1.6460
2024-10-30 15:31:47: [2024-10-30 15:31:47] iter = 04190, loss = 2.9075
2024-10-30 15:31:47: [2024-10-30 15:31:47] iter = 04200, loss = 1.7297
2024-10-30 15:31:48: [2024-10-30 15:31:48] iter = 04210, loss = 3.7515
2024-10-30 15:31:49: [2024-10-30 15:31:49] iter = 04220, loss = 1.4963
2024-10-30 15:31:50: [2024-10-30 15:31:50] iter = 04230, loss = 5.0777
2024-10-30 15:31:51: [2024-10-30 15:31:51] iter = 04240, loss = 2.7670
2024-10-30 15:31:52: [2024-10-30 15:31:52] iter = 04250, loss = 1.6365
2024-10-30 15:31:53: [2024-10-30 15:31:53] iter = 04260, loss = 1.3681
2024-10-30 15:31:54: [2024-10-30 15:31:54] iter = 04270, loss = 1.8544
2024-10-30 15:31:55: [2024-10-30 15:31:55] iter = 04280, loss = 2.5973
2024-10-30 15:31:56: [2024-10-30 15:31:56] iter = 04290, loss = 26.1685
2024-10-30 15:31:57: [2024-10-30 15:31:57] iter = 04300, loss = 1.6580
2024-10-30 15:31:58: [2024-10-30 15:31:58] iter = 04310, loss = 2.7531
2024-10-30 15:31:59: [2024-10-30 15:31:59] iter = 04320, loss = 1.7832
2024-10-30 15:32:00: [2024-10-30 15:32:00] iter = 04330, loss = 1.6247
2024-10-30 15:32:01: [2024-10-30 15:32:01] iter = 04340, loss = 2.5928
2024-10-30 15:32:02: [2024-10-30 15:32:02] iter = 04350, loss = 7.4146
2024-10-30 15:32:03: [2024-10-30 15:32:03] iter = 04360, loss = 1.6848
2024-10-30 15:32:04: [2024-10-30 15:32:04] iter = 04370, loss = 8.6481
2024-10-30 15:32:05: [2024-10-30 15:32:05] iter = 04380, loss = 11.0244
2024-10-30 15:32:06: [2024-10-30 15:32:06] iter = 04390, loss = 1.2565
2024-10-30 15:32:07: [2024-10-30 15:32:07] iter = 04400, loss = 2.7628
2024-10-30 15:32:08: [2024-10-30 15:32:08] iter = 04410, loss = 1.5818
2024-10-30 15:32:08: [2024-10-30 15:32:08] iter = 04420, loss = 1.1308
2024-10-30 15:32:09: [2024-10-30 15:32:09] iter = 04430, loss = 13.9026
2024-10-30 15:32:10: [2024-10-30 15:32:10] iter = 04440, loss = 1.2965
2024-10-30 15:32:11: [2024-10-30 15:32:11] iter = 04450, loss = 2.1044
2024-10-30 15:32:12: [2024-10-30 15:32:12] iter = 04460, loss = 1.3799
2024-10-30 15:32:13: [2024-10-30 15:32:13] iter = 04470, loss = 0.9382
2024-10-30 15:32:14: [2024-10-30 15:32:14] iter = 04480, loss = 1.0886
2024-10-30 15:32:15: [2024-10-30 15:32:15] iter = 04490, loss = 2.0521
2024-10-30 15:32:15: [2024-10-30 15:32:15] iter = 04500, loss = 1.8117
2024-10-30 15:32:16: [2024-10-30 15:32:16] iter = 04510, loss = 1.3855
2024-10-30 15:32:17: [2024-10-30 15:32:17] iter = 04520, loss = 1.4655
2024-10-30 15:32:18: [2024-10-30 15:32:18] iter = 04530, loss = 8.5182
2024-10-30 15:32:19: [2024-10-30 15:32:19] iter = 04540, loss = 5.8153
2024-10-30 15:32:20: [2024-10-30 15:32:20] iter = 04550, loss = 27.0501
2024-10-30 15:32:21: [2024-10-30 15:32:21] iter = 04560, loss = 3.5402
2024-10-30 15:32:22: [2024-10-30 15:32:22] iter = 04570, loss = 1.6692
2024-10-30 15:32:22: [2024-10-30 15:32:22] iter = 04580, loss = 1.7934
2024-10-30 15:32:23: [2024-10-30 15:32:23] iter = 04590, loss = 15.8745
2024-10-30 15:32:24: [2024-10-30 15:32:24] iter = 04600, loss = 31.0975
2024-10-30 15:32:25: [2024-10-30 15:32:25] iter = 04610, loss = 7.9884
2024-10-30 15:32:25: [2024-10-30 15:32:25] iter = 04620, loss = 2.1754
2024-10-30 15:32:25: [2024-10-30 15:32:25] iter = 04630, loss = 1.5996
2024-10-30 15:32:26: [2024-10-30 15:32:26] iter = 04640, loss = 1.7819
2024-10-30 15:32:27: [2024-10-30 15:32:27] iter = 04650, loss = 3.4135
2024-10-30 15:32:27: [2024-10-30 15:32:27] iter = 04660, loss = 3.6547
2024-10-30 15:32:28: [2024-10-30 15:32:28] iter = 04670, loss = 2.1786
2024-10-30 15:32:28: [2024-10-30 15:32:28] iter = 04680, loss = 1.4620
2024-10-30 15:32:29: [2024-10-30 15:32:29] iter = 04690, loss = 3.5072
2024-10-30 15:32:30: [2024-10-30 15:32:30] iter = 04700, loss = 1.8863
2024-10-30 15:32:31: [2024-10-30 15:32:31] iter = 04710, loss = 3.1839
2024-10-30 15:32:32: [2024-10-30 15:32:32] iter = 04720, loss = 1.9344
2024-10-30 15:32:32: [2024-10-30 15:32:32] iter = 04730, loss = 2.4979
2024-10-30 15:32:33: [2024-10-30 15:32:33] iter = 04740, loss = 2.0419
2024-10-30 15:32:34: [2024-10-30 15:32:34] iter = 04750, loss = 11.5178
2024-10-30 15:32:35: [2024-10-30 15:32:35] iter = 04760, loss = 1.9758
2024-10-30 15:32:36: [2024-10-30 15:32:36] iter = 04770, loss = 1.0178
2024-10-30 15:32:37: [2024-10-30 15:32:37] iter = 04780, loss = 6.8492
2024-10-30 15:32:38: [2024-10-30 15:32:38] iter = 04790, loss = 2.4063
2024-10-30 15:32:39: [2024-10-30 15:32:39] iter = 04800, loss = 5.3072
2024-10-30 15:32:40: [2024-10-30 15:32:40] iter = 04810, loss = 1.1659
2024-10-30 15:32:41: [2024-10-30 15:32:41] iter = 04820, loss = 2.1814
2024-10-30 15:32:42: [2024-10-30 15:32:42] iter = 04830, loss = 1.6826
2024-10-30 15:32:43: [2024-10-30 15:32:43] iter = 04840, loss = 1.2199
2024-10-30 15:32:44: [2024-10-30 15:32:44] iter = 04850, loss = 1.2548
2024-10-30 15:32:46: [2024-10-30 15:32:46] iter = 04860, loss = 1.6713
2024-10-30 15:32:47: [2024-10-30 15:32:47] iter = 04870, loss = 1.2533
2024-10-30 15:32:48: [2024-10-30 15:32:47] iter = 04880, loss = 1.7601
2024-10-30 15:32:48: [2024-10-30 15:32:48] iter = 04890, loss = 4.4354
2024-10-30 15:32:49: [2024-10-30 15:32:49] iter = 04900, loss = 2.0331
2024-10-30 15:32:50: [2024-10-30 15:32:50] iter = 04910, loss = 2.1403
2024-10-30 15:32:52: [2024-10-30 15:32:52] iter = 04920, loss = 10.0894
2024-10-30 15:32:52: [2024-10-30 15:32:52] iter = 04930, loss = 3.2530
2024-10-30 15:32:54: [2024-10-30 15:32:54] iter = 04940, loss = 7.9263
2024-10-30 15:32:55: [2024-10-30 15:32:55] iter = 04950, loss = 1.5595
2024-10-30 15:32:56: [2024-10-30 15:32:56] iter = 04960, loss = 11.8813
2024-10-30 15:32:56: [2024-10-30 15:32:56] iter = 04970, loss = 1.2870
2024-10-30 15:32:57: [2024-10-30 15:32:57] iter = 04980, loss = 5.5464
2024-10-30 15:32:58: [2024-10-30 15:32:58] iter = 04990, loss = 7.1353
2024-10-30 15:32:59: [2024-10-30 15:32:59] iter = 05000, loss = 7.7859
2024-10-30 15:33:00: [2024-10-30 15:33:00] iter = 05010, loss = 3.8680
2024-10-30 15:33:02: [2024-10-30 15:33:02] iter = 05020, loss = 1.7232
2024-10-30 15:33:03: [2024-10-30 15:33:03] iter = 05030, loss = 2.3371
2024-10-30 15:33:04: [2024-10-30 15:33:04] iter = 05040, loss = 1.4674
2024-10-30 15:33:05: [2024-10-30 15:33:05] iter = 05050, loss = 3.4591
2024-10-30 15:33:06: [2024-10-30 15:33:06] iter = 05060, loss = 2.1337
2024-10-30 15:33:07: [2024-10-30 15:33:07] iter = 05070, loss = 4.0205
2024-10-30 15:33:08: [2024-10-30 15:33:08] iter = 05080, loss = 1.9056
2024-10-30 15:33:09: [2024-10-30 15:33:09] iter = 05090, loss = 3.9615
2024-10-30 15:33:11: [2024-10-30 15:33:11] iter = 05100, loss = 14.4462
2024-10-30 15:33:12: [2024-10-30 15:33:12] iter = 05110, loss = 4.0745
2024-10-30 15:33:13: [2024-10-30 15:33:13] iter = 05120, loss = 14.2002
2024-10-30 15:33:14: [2024-10-30 15:33:14] iter = 05130, loss = 1.7588
2024-10-30 15:33:15: [2024-10-30 15:33:15] iter = 05140, loss = 1.1340
2024-10-30 15:33:16: [2024-10-30 15:33:16] iter = 05150, loss = 8.5623
2024-10-30 15:33:16: [2024-10-30 15:33:16] iter = 05160, loss = 1.4803
2024-10-30 15:33:17: [2024-10-30 15:33:17] iter = 05170, loss = 6.8119
2024-10-30 15:33:18: [2024-10-30 15:33:18] iter = 05180, loss = 18.2852
2024-10-30 15:33:18: [2024-10-30 15:33:18] iter = 05190, loss = 5.1831
2024-10-30 15:33:19: [2024-10-30 15:33:19] iter = 05200, loss = 1.7446
2024-10-30 15:33:20: [2024-10-30 15:33:20] iter = 05210, loss = 2.0612
2024-10-30 15:33:21: [2024-10-30 15:33:21] iter = 05220, loss = 1.6442
2024-10-30 15:33:22: [2024-10-30 15:33:22] iter = 05230, loss = 1.3245
2024-10-30 15:33:23: [2024-10-30 15:33:23] iter = 05240, loss = 5.6263
2024-10-30 15:33:24: [2024-10-30 15:33:24] iter = 05250, loss = 3.8025
2024-10-30 15:33:24: [2024-10-30 15:33:24] iter = 05260, loss = 2.3483
2024-10-30 15:33:25: [2024-10-30 15:33:25] iter = 05270, loss = 1.2246
2024-10-30 15:33:26: [2024-10-30 15:33:26] iter = 05280, loss = 1.8354
2024-10-30 15:33:27: [2024-10-30 15:33:27] iter = 05290, loss = 1.4955
2024-10-30 15:33:28: [2024-10-30 15:33:28] iter = 05300, loss = 4.1452
2024-10-30 15:33:29: [2024-10-30 15:33:29] iter = 05310, loss = 1.8122
2024-10-30 15:33:30: [2024-10-30 15:33:30] iter = 05320, loss = 22.7238
2024-10-30 15:33:30: [2024-10-30 15:33:30] iter = 05330, loss = 9.4109
2024-10-30 15:33:31: [2024-10-30 15:33:31] iter = 05340, loss = 1.6588
2024-10-30 15:33:33: [2024-10-30 15:33:33] iter = 05350, loss = 1.3813
2024-10-30 15:33:33: [2024-10-30 15:33:33] iter = 05360, loss = 2.6344
2024-10-30 15:33:34: [2024-10-30 15:33:34] iter = 05370, loss = 2.6630
2024-10-30 15:33:35: [2024-10-30 15:33:35] iter = 05380, loss = 1.5184
2024-10-30 15:33:36: [2024-10-30 15:33:36] iter = 05390, loss = 1.5813
2024-10-30 15:33:37: [2024-10-30 15:33:37] iter = 05400, loss = 12.1401
2024-10-30 15:33:38: [2024-10-30 15:33:38] iter = 05410, loss = 12.9716
2024-10-30 15:33:39: [2024-10-30 15:33:39] iter = 05420, loss = 4.5553
2024-10-30 15:33:40: [2024-10-30 15:33:40] iter = 05430, loss = 1.6645
2024-10-30 15:33:41: [2024-10-30 15:33:41] iter = 05440, loss = 8.6783
2024-10-30 15:33:42: [2024-10-30 15:33:42] iter = 05450, loss = 1.9359
2024-10-30 15:33:43: [2024-10-30 15:33:43] iter = 05460, loss = 11.8163
2024-10-30 15:33:44: [2024-10-30 15:33:44] iter = 05470, loss = 2.8516
2024-10-30 15:33:45: [2024-10-30 15:33:45] iter = 05480, loss = 8.8858
2024-10-30 15:33:46: [2024-10-30 15:33:46] iter = 05490, loss = 2.1208
2024-10-30 15:33:47: [2024-10-30 15:33:47] iter = 05500, loss = 1.8461
2024-10-30 15:33:48: [2024-10-30 15:33:48] iter = 05510, loss = 2.2075
2024-10-30 15:33:49: [2024-10-30 15:33:49] iter = 05520, loss = 19.1935
2024-10-30 15:33:50: [2024-10-30 15:33:50] iter = 05530, loss = 3.8280
2024-10-30 15:33:51: [2024-10-30 15:33:51] iter = 05540, loss = 1.0578
2024-10-30 15:33:52: [2024-10-30 15:33:52] iter = 05550, loss = 5.2698
2024-10-30 15:33:54: [2024-10-30 15:33:54] iter = 05560, loss = 8.1351
2024-10-30 15:33:55: [2024-10-30 15:33:55] iter = 05570, loss = 1.8561
2024-10-30 15:33:56: [2024-10-30 15:33:56] iter = 05580, loss = 3.1964
2024-10-30 15:33:56: [2024-10-30 15:33:56] iter = 05590, loss = 3.2763
2024-10-30 15:33:57: [2024-10-30 15:33:57] iter = 05600, loss = 5.6365
2024-10-30 15:33:57: [2024-10-30 15:33:57] iter = 05610, loss = 2.2809
2024-10-30 15:33:58: [2024-10-30 15:33:58] iter = 05620, loss = 2.0351
2024-10-30 15:33:59: [2024-10-30 15:33:59] iter = 05630, loss = 2.3110
2024-10-30 15:33:59: [2024-10-30 15:33:59] iter = 05640, loss = 5.7486
2024-10-30 15:34:00: [2024-10-30 15:34:00] iter = 05650, loss = 3.8067
2024-10-30 15:34:01: [2024-10-30 15:34:01] iter = 05660, loss = 2.0173
2024-10-30 15:34:02: [2024-10-30 15:34:02] iter = 05670, loss = 1.2014
2024-10-30 15:34:03: [2024-10-30 15:34:03] iter = 05680, loss = 6.9578
2024-10-30 15:34:05: [2024-10-30 15:34:05] iter = 05690, loss = 1.2093
2024-10-30 15:34:05: [2024-10-30 15:34:05] iter = 05700, loss = 4.5756
2024-10-30 15:34:06: [2024-10-30 15:34:06] iter = 05710, loss = 7.2610
2024-10-30 15:34:07: [2024-10-30 15:34:07] iter = 05720, loss = 2.5949
2024-10-30 15:34:09: [2024-10-30 15:34:09] iter = 05730, loss = 1.1488
2024-10-30 15:34:10: [2024-10-30 15:34:10] iter = 05740, loss = 11.9225
2024-10-30 15:34:10: [2024-10-30 15:34:10] iter = 05750, loss = 11.1873
2024-10-30 15:34:11: [2024-10-30 15:34:11] iter = 05760, loss = 31.6409
2024-10-30 15:34:12: [2024-10-30 15:34:12] iter = 05770, loss = 2.3558
2024-10-30 15:34:13: [2024-10-30 15:34:13] iter = 05780, loss = 2.0715
2024-10-30 15:34:14: [2024-10-30 15:34:14] iter = 05790, loss = 2.6182
2024-10-30 15:34:15: [2024-10-30 15:34:15] iter = 05800, loss = 3.4571
2024-10-30 15:34:16: [2024-10-30 15:34:16] iter = 05810, loss = 3.2431
2024-10-30 15:34:17: [2024-10-30 15:34:17] iter = 05820, loss = 1.4343
2024-10-30 15:34:18: [2024-10-30 15:34:18] iter = 05830, loss = 33.1925
2024-10-30 15:34:19: [2024-10-30 15:34:19] iter = 05840, loss = 13.0025
2024-10-30 15:34:20: [2024-10-30 15:34:20] iter = 05850, loss = 9.4781
2024-10-30 15:34:21: [2024-10-30 15:34:21] iter = 05860, loss = 1.9624
2024-10-30 15:34:22: [2024-10-30 15:34:22] iter = 05870, loss = 4.3604
2024-10-30 15:34:23: [2024-10-30 15:34:23] iter = 05880, loss = 1.8840
2024-10-30 15:34:25: [2024-10-30 15:34:25] iter = 05890, loss = 1.6320
2024-10-30 15:34:25: [2024-10-30 15:34:25] iter = 05900, loss = 16.3047
2024-10-30 15:34:26: [2024-10-30 15:34:26] iter = 05910, loss = 4.1815
2024-10-30 15:34:28: [2024-10-30 15:34:28] iter = 05920, loss = 2.2455
2024-10-30 15:34:29: [2024-10-30 15:34:29] iter = 05930, loss = 1.3286
2024-10-30 15:34:29: [2024-10-30 15:34:29] iter = 05940, loss = 1.7912
2024-10-30 15:34:31: [2024-10-30 15:34:31] iter = 05950, loss = 1.4706
2024-10-30 15:34:31: [2024-10-30 15:34:31] iter = 05960, loss = 1.0739
2024-10-30 15:34:32: [2024-10-30 15:34:32] iter = 05970, loss = 4.2806
2024-10-30 15:34:33: [2024-10-30 15:34:33] iter = 05980, loss = 3.6030
2024-10-30 15:34:34: [2024-10-30 15:34:34] iter = 05990, loss = 2.0892
2024-10-30 15:34:35: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 15:34:35: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:34:35: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 75720}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:36:13: Evaluate 5 random ConvNet, ACCmean = 0.7308 ACCstd = 0.0190
-------------------------
2024-10-30 15:36:13: Evaluate 5 random ConvNet, SENmean = 0.6820 SENstd = 0.0266
-------------------------
2024-10-30 15:36:13: Evaluate 5 random ConvNet, SPEmean = 0.6820 SPEstd = 0.0266
-------------------------
2024-10-30 15:36:13: Evaluate 5 random ConvNet, F!mean = 0.6727 F!std = 0.0238
-------------------------
2024-10-30 15:36:13: Evaluate 5 random ConvNet, mean = 0.7308 std = 0.0190
-------------------------
2024-10-30 15:36:13: [2024-10-30 15:36:13] iter = 06000, loss = 1.6143
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:36:14: [2024-10-30 15:36:14] iter = 06010, loss = 2.5442
2024-10-30 15:36:15: [2024-10-30 15:36:15] iter = 06020, loss = 6.5253
2024-10-30 15:36:15: [2024-10-30 15:36:15] iter = 06030, loss = 1.6424
2024-10-30 15:36:16: [2024-10-30 15:36:16] iter = 06040, loss = 2.9489
2024-10-30 15:36:16: [2024-10-30 15:36:16] iter = 06050, loss = 2.0395
2024-10-30 15:36:17: [2024-10-30 15:36:17] iter = 06060, loss = 1.8053
2024-10-30 15:36:17: [2024-10-30 15:36:17] iter = 06070, loss = 4.5188
2024-10-30 15:36:18: [2024-10-30 15:36:18] iter = 06080, loss = 1.9516
2024-10-30 15:36:19: [2024-10-30 15:36:19] iter = 06090, loss = 3.3783
2024-10-30 15:36:20: [2024-10-30 15:36:20] iter = 06100, loss = 2.0016
2024-10-30 15:36:21: [2024-10-30 15:36:21] iter = 06110, loss = 12.0002
2024-10-30 15:36:22: [2024-10-30 15:36:22] iter = 06120, loss = 1.3264
2024-10-30 15:36:23: [2024-10-30 15:36:23] iter = 06130, loss = 1.1737
2024-10-30 15:36:24: [2024-10-30 15:36:24] iter = 06140, loss = 1.7931
2024-10-30 15:36:24: [2024-10-30 15:36:24] iter = 06150, loss = 3.1709
2024-10-30 15:36:25: [2024-10-30 15:36:25] iter = 06160, loss = 7.2142
2024-10-30 15:36:26: [2024-10-30 15:36:26] iter = 06170, loss = 7.0330
2024-10-30 15:36:27: [2024-10-30 15:36:27] iter = 06180, loss = 49.6323
2024-10-30 15:36:28: [2024-10-30 15:36:28] iter = 06190, loss = 2.0857
2024-10-30 15:36:29: [2024-10-30 15:36:29] iter = 06200, loss = 3.1401
2024-10-30 15:36:30: [2024-10-30 15:36:30] iter = 06210, loss = 1.5270
2024-10-30 15:36:31: [2024-10-30 15:36:31] iter = 06220, loss = 1.0688
2024-10-30 15:36:33: [2024-10-30 15:36:33] iter = 06230, loss = 2.1807
2024-10-30 15:36:34: [2024-10-30 15:36:34] iter = 06240, loss = 1.4702
2024-10-30 15:36:35: [2024-10-30 15:36:35] iter = 06250, loss = 2.5168
2024-10-30 15:36:36: [2024-10-30 15:36:36] iter = 06260, loss = 8.9451
2024-10-30 15:36:37: [2024-10-30 15:36:37] iter = 06270, loss = 5.1631
2024-10-30 15:36:38: [2024-10-30 15:36:38] iter = 06280, loss = 35.7340
2024-10-30 15:36:39: [2024-10-30 15:36:39] iter = 06290, loss = 13.3283
2024-10-30 15:36:40: [2024-10-30 15:36:40] iter = 06300, loss = 1.6032
2024-10-30 15:36:41: [2024-10-30 15:36:41] iter = 06310, loss = 11.4301
2024-10-30 15:36:42: [2024-10-30 15:36:42] iter = 06320, loss = 2.3260
2024-10-30 15:36:42: [2024-10-30 15:36:42] iter = 06330, loss = 1.5141
2024-10-30 15:36:43: [2024-10-30 15:36:43] iter = 06340, loss = 1.8138
2024-10-30 15:36:44: [2024-10-30 15:36:44] iter = 06350, loss = 1.4287
2024-10-30 15:36:45: [2024-10-30 15:36:45] iter = 06360, loss = 1.9541
2024-10-30 15:36:46: [2024-10-30 15:36:46] iter = 06370, loss = 1.2593
2024-10-30 15:36:47: [2024-10-30 15:36:47] iter = 06380, loss = 10.6588
2024-10-30 15:36:48: [2024-10-30 15:36:48] iter = 06390, loss = 2.7417
2024-10-30 15:36:49: [2024-10-30 15:36:49] iter = 06400, loss = 2.9688
2024-10-30 15:36:50: [2024-10-30 15:36:50] iter = 06410, loss = 14.3581
2024-10-30 15:36:51: [2024-10-30 15:36:51] iter = 06420, loss = 1.6079
2024-10-30 15:36:52: [2024-10-30 15:36:52] iter = 06430, loss = 3.5603
2024-10-30 15:36:53: [2024-10-30 15:36:53] iter = 06440, loss = 1.5975
2024-10-30 15:36:54: [2024-10-30 15:36:54] iter = 06450, loss = 8.5072
2024-10-30 15:36:55: [2024-10-30 15:36:55] iter = 06460, loss = 3.3938
2024-10-30 15:36:56: [2024-10-30 15:36:56] iter = 06470, loss = 2.8838
2024-10-30 15:36:57: [2024-10-30 15:36:57] iter = 06480, loss = 1.3557
2024-10-30 15:36:58: [2024-10-30 15:36:58] iter = 06490, loss = 1.3277
2024-10-30 15:36:58: [2024-10-30 15:36:58] iter = 06500, loss = 29.1929
2024-10-30 15:36:59: [2024-10-30 15:36:59] iter = 06510, loss = 6.0238
2024-10-30 15:37:00: [2024-10-30 15:37:00] iter = 06520, loss = 1.6468
2024-10-30 15:37:00: [2024-10-30 15:37:00] iter = 06530, loss = 1.1592
2024-10-30 15:37:01: [2024-10-30 15:37:01] iter = 06540, loss = 1.6627
2024-10-30 15:37:02: [2024-10-30 15:37:02] iter = 06550, loss = 2.0683
2024-10-30 15:37:03: [2024-10-30 15:37:03] iter = 06560, loss = 3.2937
2024-10-30 15:37:04: [2024-10-30 15:37:04] iter = 06570, loss = 5.1922
2024-10-30 15:37:05: [2024-10-30 15:37:05] iter = 06580, loss = 6.3199
2024-10-30 15:37:05: [2024-10-30 15:37:05] iter = 06590, loss = 5.0691
2024-10-30 15:37:06: [2024-10-30 15:37:06] iter = 06600, loss = 1.9588
2024-10-30 15:37:06: [2024-10-30 15:37:06] iter = 06610, loss = 1.7905
2024-10-30 15:37:08: [2024-10-30 15:37:08] iter = 06620, loss = 1.2651
2024-10-30 15:37:09: [2024-10-30 15:37:09] iter = 06630, loss = 1.6276
2024-10-30 15:37:09: [2024-10-30 15:37:09] iter = 06640, loss = 13.3070
2024-10-30 15:37:10: [2024-10-30 15:37:10] iter = 06650, loss = 36.0492
2024-10-30 15:37:11: [2024-10-30 15:37:11] iter = 06660, loss = 2.2387
2024-10-30 15:37:12: [2024-10-30 15:37:12] iter = 06670, loss = 4.3264
2024-10-30 15:37:13: [2024-10-30 15:37:13] iter = 06680, loss = 2.4148
2024-10-30 15:37:14: [2024-10-30 15:37:14] iter = 06690, loss = 2.9825
2024-10-30 15:37:15: [2024-10-30 15:37:15] iter = 06700, loss = 2.4866
2024-10-30 15:37:16: [2024-10-30 15:37:16] iter = 06710, loss = 1.4343
2024-10-30 15:37:17: [2024-10-30 15:37:17] iter = 06720, loss = 12.4315
2024-10-30 15:37:18: [2024-10-30 15:37:18] iter = 06730, loss = 2.8841
2024-10-30 15:37:19: [2024-10-30 15:37:19] iter = 06740, loss = 4.2501
2024-10-30 15:37:19: [2024-10-30 15:37:19] iter = 06750, loss = 1.1427
2024-10-30 15:37:21: [2024-10-30 15:37:21] iter = 06760, loss = 1.0239
2024-10-30 15:37:22: [2024-10-30 15:37:22] iter = 06770, loss = 4.8214
2024-10-30 15:37:22: [2024-10-30 15:37:22] iter = 06780, loss = 1.7250
2024-10-30 15:37:24: [2024-10-30 15:37:24] iter = 06790, loss = 1.6568
2024-10-30 15:37:24: [2024-10-30 15:37:24] iter = 06800, loss = 1.3878
2024-10-30 15:37:26: [2024-10-30 15:37:26] iter = 06810, loss = 1.2120
2024-10-30 15:37:27: [2024-10-30 15:37:27] iter = 06820, loss = 4.0889
2024-10-30 15:37:28: [2024-10-30 15:37:28] iter = 06830, loss = 2.4852
2024-10-30 15:37:29: [2024-10-30 15:37:29] iter = 06840, loss = 1.9555
2024-10-30 15:37:30: [2024-10-30 15:37:30] iter = 06850, loss = 14.3642
2024-10-30 15:37:31: [2024-10-30 15:37:31] iter = 06860, loss = 2.0012
2024-10-30 15:37:32: [2024-10-30 15:37:32] iter = 06870, loss = 7.0062
2024-10-30 15:37:33: [2024-10-30 15:37:33] iter = 06880, loss = 2.7667
2024-10-30 15:37:34: [2024-10-30 15:37:34] iter = 06890, loss = 1.9894
2024-10-30 15:37:35: [2024-10-30 15:37:35] iter = 06900, loss = 2.4670
2024-10-30 15:37:35: [2024-10-30 15:37:35] iter = 06910, loss = 1.8328
2024-10-30 15:37:36: [2024-10-30 15:37:36] iter = 06920, loss = 5.7936
2024-10-30 15:37:37: [2024-10-30 15:37:37] iter = 06930, loss = 3.2556
2024-10-30 15:37:38: [2024-10-30 15:37:38] iter = 06940, loss = 1.8810
2024-10-30 15:37:39: [2024-10-30 15:37:39] iter = 06950, loss = 1.2666
2024-10-30 15:37:40: [2024-10-30 15:37:40] iter = 06960, loss = 4.8673
2024-10-30 15:37:41: [2024-10-30 15:37:41] iter = 06970, loss = 1.3356
2024-10-30 15:37:42: [2024-10-30 15:37:42] iter = 06980, loss = 1.5730
2024-10-30 15:37:43: [2024-10-30 15:37:43] iter = 06990, loss = 3.4907
2024-10-30 15:37:44: [2024-10-30 15:37:44] iter = 07000, loss = 2.2268
2024-10-30 15:37:45: [2024-10-30 15:37:45] iter = 07010, loss = 1.5892
2024-10-30 15:37:46: [2024-10-30 15:37:46] iter = 07020, loss = 9.0879
2024-10-30 15:37:47: [2024-10-30 15:37:47] iter = 07030, loss = 14.5520
2024-10-30 15:37:48: [2024-10-30 15:37:48] iter = 07040, loss = 3.4622
2024-10-30 15:37:48: [2024-10-30 15:37:48] iter = 07050, loss = 6.0830
2024-10-30 15:37:49: [2024-10-30 15:37:49] iter = 07060, loss = 7.8201
2024-10-30 15:37:50: [2024-10-30 15:37:50] iter = 07070, loss = 1.7508
2024-10-30 15:37:51: [2024-10-30 15:37:51] iter = 07080, loss = 7.7583
2024-10-30 15:37:52: [2024-10-30 15:37:52] iter = 07090, loss = 2.2680
2024-10-30 15:37:53: [2024-10-30 15:37:53] iter = 07100, loss = 2.3731
2024-10-30 15:37:53: [2024-10-30 15:37:53] iter = 07110, loss = 4.4819
2024-10-30 15:37:54: [2024-10-30 15:37:54] iter = 07120, loss = 5.0838
2024-10-30 15:37:56: [2024-10-30 15:37:56] iter = 07130, loss = 9.5905
2024-10-30 15:37:56: [2024-10-30 15:37:56] iter = 07140, loss = 8.3863
2024-10-30 15:37:57: [2024-10-30 15:37:57] iter = 07150, loss = 2.5614
2024-10-30 15:37:58: [2024-10-30 15:37:58] iter = 07160, loss = 2.7237
2024-10-30 15:37:59: [2024-10-30 15:37:59] iter = 07170, loss = 2.0641
2024-10-30 15:38:00: [2024-10-30 15:38:00] iter = 07180, loss = 2.6548
2024-10-30 15:38:01: [2024-10-30 15:38:01] iter = 07190, loss = 1.5894
2024-10-30 15:38:02: [2024-10-30 15:38:02] iter = 07200, loss = 24.3709
2024-10-30 15:38:04: [2024-10-30 15:38:04] iter = 07210, loss = 1.7836
2024-10-30 15:38:05: [2024-10-30 15:38:05] iter = 07220, loss = 1.8954
2024-10-30 15:38:06: [2024-10-30 15:38:06] iter = 07230, loss = 3.1283
2024-10-30 15:38:07: [2024-10-30 15:38:07] iter = 07240, loss = 5.1697
2024-10-30 15:38:07: [2024-10-30 15:38:07] iter = 07250, loss = 4.2981
2024-10-30 15:38:08: [2024-10-30 15:38:08] iter = 07260, loss = 2.2573
2024-10-30 15:38:09: [2024-10-30 15:38:09] iter = 07270, loss = 7.3873
2024-10-30 15:38:09: [2024-10-30 15:38:09] iter = 07280, loss = 2.9098
2024-10-30 15:38:10: [2024-10-30 15:38:10] iter = 07290, loss = 1.9314
2024-10-30 15:38:11: [2024-10-30 15:38:11] iter = 07300, loss = 1.5469
2024-10-30 15:38:12: [2024-10-30 15:38:12] iter = 07310, loss = 2.1115
2024-10-30 15:38:13: [2024-10-30 15:38:13] iter = 07320, loss = 1.6666
2024-10-30 15:38:14: [2024-10-30 15:38:14] iter = 07330, loss = 2.8199
2024-10-30 15:38:16: [2024-10-30 15:38:16] iter = 07340, loss = 1.7661
2024-10-30 15:38:17: [2024-10-30 15:38:17] iter = 07350, loss = 1.7307
2024-10-30 15:38:18: [2024-10-30 15:38:18] iter = 07360, loss = 11.8517
2024-10-30 15:38:19: [2024-10-30 15:38:19] iter = 07370, loss = 1.9457
2024-10-30 15:38:20: [2024-10-30 15:38:20] iter = 07380, loss = 2.7709
2024-10-30 15:38:20: [2024-10-30 15:38:20] iter = 07390, loss = 4.9721
2024-10-30 15:38:21: [2024-10-30 15:38:21] iter = 07400, loss = 20.4543
2024-10-30 15:38:21: [2024-10-30 15:38:21] iter = 07410, loss = 2.4935
2024-10-30 15:38:22: [2024-10-30 15:38:22] iter = 07420, loss = 11.0836
2024-10-30 15:38:23: [2024-10-30 15:38:23] iter = 07430, loss = 2.4163
2024-10-30 15:38:23: [2024-10-30 15:38:23] iter = 07440, loss = 1.7253
2024-10-30 15:38:24: [2024-10-30 15:38:24] iter = 07450, loss = 1.5148
2024-10-30 15:38:25: [2024-10-30 15:38:25] iter = 07460, loss = 2.0360
2024-10-30 15:38:26: [2024-10-30 15:38:26] iter = 07470, loss = 2.8885
2024-10-30 15:38:27: [2024-10-30 15:38:27] iter = 07480, loss = 3.8965
2024-10-30 15:38:28: [2024-10-30 15:38:28] iter = 07490, loss = 1.9837
2024-10-30 15:38:29: [2024-10-30 15:38:29] iter = 07500, loss = 11.1310
2024-10-30 15:38:30: [2024-10-30 15:38:30] iter = 07510, loss = 2.7654
2024-10-30 15:38:31: [2024-10-30 15:38:31] iter = 07520, loss = 1.8155
2024-10-30 15:38:32: [2024-10-30 15:38:32] iter = 07530, loss = 1.7896
2024-10-30 15:38:33: [2024-10-30 15:38:33] iter = 07540, loss = 1.3303
2024-10-30 15:38:34: [2024-10-30 15:38:34] iter = 07550, loss = 14.8144
2024-10-30 15:38:34: [2024-10-30 15:38:34] iter = 07560, loss = 8.7024
2024-10-30 15:38:35: [2024-10-30 15:38:35] iter = 07570, loss = 3.0692
2024-10-30 15:38:36: [2024-10-30 15:38:36] iter = 07580, loss = 1.6205
2024-10-30 15:38:36: [2024-10-30 15:38:36] iter = 07590, loss = 3.4135
2024-10-30 15:38:37: [2024-10-30 15:38:37] iter = 07600, loss = 1.7600
2024-10-30 15:38:38: [2024-10-30 15:38:38] iter = 07610, loss = 20.6059
2024-10-30 15:38:39: [2024-10-30 15:38:39] iter = 07620, loss = 1.6632
2024-10-30 15:38:41: [2024-10-30 15:38:41] iter = 07630, loss = 3.4967
2024-10-30 15:38:42: [2024-10-30 15:38:42] iter = 07640, loss = 2.3251
2024-10-30 15:38:43: [2024-10-30 15:38:43] iter = 07650, loss = 1.1395
2024-10-30 15:38:44: [2024-10-30 15:38:44] iter = 07660, loss = 20.7728
2024-10-30 15:38:45: [2024-10-30 15:38:45] iter = 07670, loss = 3.5808
2024-10-30 15:38:46: [2024-10-30 15:38:46] iter = 07680, loss = 1.7901
2024-10-30 15:38:47: [2024-10-30 15:38:47] iter = 07690, loss = 1.5218
2024-10-30 15:38:48: [2024-10-30 15:38:48] iter = 07700, loss = 1.3224
2024-10-30 15:38:48: [2024-10-30 15:38:48] iter = 07710, loss = 1.1641
2024-10-30 15:38:50: [2024-10-30 15:38:50] iter = 07720, loss = 1.4047
2024-10-30 15:38:50: [2024-10-30 15:38:50] iter = 07730, loss = 2.4624
2024-10-30 15:38:51: [2024-10-30 15:38:51] iter = 07740, loss = 2.4462
2024-10-30 15:38:53: [2024-10-30 15:38:53] iter = 07750, loss = 1.3907
2024-10-30 15:38:54: [2024-10-30 15:38:54] iter = 07760, loss = 2.1329
2024-10-30 15:38:55: [2024-10-30 15:38:55] iter = 07770, loss = 5.0386
2024-10-30 15:38:56: [2024-10-30 15:38:56] iter = 07780, loss = 5.4479
2024-10-30 15:38:57: [2024-10-30 15:38:57] iter = 07790, loss = 6.4295
2024-10-30 15:38:58: [2024-10-30 15:38:58] iter = 07800, loss = 7.4988
2024-10-30 15:38:59: [2024-10-30 15:38:59] iter = 07810, loss = 2.9406
2024-10-30 15:39:00: [2024-10-30 15:39:00] iter = 07820, loss = 15.1592
2024-10-30 15:39:01: [2024-10-30 15:39:01] iter = 07830, loss = 5.1114
2024-10-30 15:39:02: [2024-10-30 15:39:02] iter = 07840, loss = 1.2233
2024-10-30 15:39:03: [2024-10-30 15:39:03] iter = 07850, loss = 1.9281
2024-10-30 15:39:04: [2024-10-30 15:39:04] iter = 07860, loss = 2.8468
2024-10-30 15:39:05: [2024-10-30 15:39:05] iter = 07870, loss = 1.3255
2024-10-30 15:39:06: [2024-10-30 15:39:06] iter = 07880, loss = 5.0038
2024-10-30 15:39:06: [2024-10-30 15:39:06] iter = 07890, loss = 1.6934
2024-10-30 15:39:07: [2024-10-30 15:39:07] iter = 07900, loss = 1.5092
2024-10-30 15:39:08: [2024-10-30 15:39:08] iter = 07910, loss = 3.6059
2024-10-30 15:39:09: [2024-10-30 15:39:09] iter = 07920, loss = 1.7271
2024-10-30 15:39:10: [2024-10-30 15:39:10] iter = 07930, loss = 1.2316
2024-10-30 15:39:10: [2024-10-30 15:39:10] iter = 07940, loss = 1.4604
2024-10-30 15:39:11: [2024-10-30 15:39:11] iter = 07950, loss = 8.6930
2024-10-30 15:39:11: [2024-10-30 15:39:11] iter = 07960, loss = 1.8049
2024-10-30 15:39:12: [2024-10-30 15:39:12] iter = 07970, loss = 9.4616
2024-10-30 15:39:13: [2024-10-30 15:39:13] iter = 07980, loss = 1.4720
2024-10-30 15:39:13: [2024-10-30 15:39:13] iter = 07990, loss = 4.1886
2024-10-30 15:39:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 15:39:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:39:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 54108}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:40:47: Evaluate 5 random ConvNet, ACCmean = 0.7333 ACCstd = 0.0283
-------------------------
2024-10-30 15:40:47: Evaluate 5 random ConvNet, SENmean = 0.6867 SENstd = 0.0178
-------------------------
2024-10-30 15:40:47: Evaluate 5 random ConvNet, SPEmean = 0.6867 SPEstd = 0.0178
-------------------------
2024-10-30 15:40:47: Evaluate 5 random ConvNet, F!mean = 0.6772 F!std = 0.0236
-------------------------
2024-10-30 15:40:47: Evaluate 5 random ConvNet, mean = 0.7333 std = 0.0283
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:40:47: [2024-10-30 15:40:47] iter = 08000, loss = 1.9251
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:40:48: [2024-10-30 15:40:48] iter = 08010, loss = 4.7056
2024-10-30 15:40:49: [2024-10-30 15:40:49] iter = 08020, loss = 2.2599
2024-10-30 15:40:49: [2024-10-30 15:40:49] iter = 08030, loss = 13.8991
2024-10-30 15:40:50: [2024-10-30 15:40:50] iter = 08040, loss = 2.4006
2024-10-30 15:40:51: [2024-10-30 15:40:51] iter = 08050, loss = 3.9806
2024-10-30 15:40:52: [2024-10-30 15:40:52] iter = 08060, loss = 10.9918
2024-10-30 15:40:53: [2024-10-30 15:40:53] iter = 08070, loss = 6.1443
2024-10-30 15:40:54: [2024-10-30 15:40:54] iter = 08080, loss = 3.5703
2024-10-30 15:40:54: [2024-10-30 15:40:54] iter = 08090, loss = 2.5422
2024-10-30 15:40:55: [2024-10-30 15:40:55] iter = 08100, loss = 1.7523
2024-10-30 15:40:57: [2024-10-30 15:40:57] iter = 08110, loss = 1.8713
2024-10-30 15:40:57: [2024-10-30 15:40:57] iter = 08120, loss = 1.2423
2024-10-30 15:40:58: [2024-10-30 15:40:58] iter = 08130, loss = 8.5289
2024-10-30 15:40:59: [2024-10-30 15:40:59] iter = 08140, loss = 2.6174
2024-10-30 15:41:00: [2024-10-30 15:41:00] iter = 08150, loss = 1.3417
2024-10-30 15:41:01: [2024-10-30 15:41:01] iter = 08160, loss = 2.7227
2024-10-30 15:41:02: [2024-10-30 15:41:02] iter = 08170, loss = 1.9687
2024-10-30 15:41:02: [2024-10-30 15:41:02] iter = 08180, loss = 50.1352
2024-10-30 15:41:03: [2024-10-30 15:41:03] iter = 08190, loss = 5.1309
2024-10-30 15:41:05: [2024-10-30 15:41:05] iter = 08200, loss = 1.1235
2024-10-30 15:41:06: [2024-10-30 15:41:06] iter = 08210, loss = 2.7174
2024-10-30 15:41:07: [2024-10-30 15:41:07] iter = 08220, loss = 1.7041
2024-10-30 15:41:07: [2024-10-30 15:41:07] iter = 08230, loss = 2.8865
2024-10-30 15:41:08: [2024-10-30 15:41:08] iter = 08240, loss = 9.7606
2024-10-30 15:41:09: [2024-10-30 15:41:09] iter = 08250, loss = 3.3289
2024-10-30 15:41:10: [2024-10-30 15:41:10] iter = 08260, loss = 8.3164
2024-10-30 15:41:11: [2024-10-30 15:41:11] iter = 08270, loss = 14.9761
2024-10-30 15:41:12: [2024-10-30 15:41:12] iter = 08280, loss = 1.9800
2024-10-30 15:41:13: [2024-10-30 15:41:13] iter = 08290, loss = 4.7388
2024-10-30 15:41:13: [2024-10-30 15:41:13] iter = 08300, loss = 17.2789
2024-10-30 15:41:14: [2024-10-30 15:41:14] iter = 08310, loss = 3.3914
2024-10-30 15:41:15: [2024-10-30 15:41:15] iter = 08320, loss = 2.1018
2024-10-30 15:41:16: [2024-10-30 15:41:16] iter = 08330, loss = 5.4945
2024-10-30 15:41:16: [2024-10-30 15:41:16] iter = 08340, loss = 5.8303
2024-10-30 15:41:17: [2024-10-30 15:41:17] iter = 08350, loss = 38.6100
2024-10-30 15:41:17: [2024-10-30 15:41:17] iter = 08360, loss = 1.7797
2024-10-30 15:41:18: [2024-10-30 15:41:18] iter = 08370, loss = 2.7654
2024-10-30 15:41:19: [2024-10-30 15:41:19] iter = 08380, loss = 2.3212
2024-10-30 15:41:20: [2024-10-30 15:41:20] iter = 08390, loss = 4.6449
2024-10-30 15:41:21: [2024-10-30 15:41:21] iter = 08400, loss = 14.7962
2024-10-30 15:41:22: [2024-10-30 15:41:22] iter = 08410, loss = 16.3310
2024-10-30 15:41:23: [2024-10-30 15:41:23] iter = 08420, loss = 3.4149
2024-10-30 15:41:23: [2024-10-30 15:41:23] iter = 08430, loss = 10.8922
2024-10-30 15:41:24: [2024-10-30 15:41:24] iter = 08440, loss = 6.0546
2024-10-30 15:41:25: [2024-10-30 15:41:25] iter = 08450, loss = 1.6037
2024-10-30 15:41:26: [2024-10-30 15:41:26] iter = 08460, loss = 2.1081
2024-10-30 15:41:27: [2024-10-30 15:41:27] iter = 08470, loss = 20.0359
2024-10-30 15:41:28: [2024-10-30 15:41:28] iter = 08480, loss = 3.7466
2024-10-30 15:41:29: [2024-10-30 15:41:29] iter = 08490, loss = 8.0623
2024-10-30 15:41:30: [2024-10-30 15:41:30] iter = 08500, loss = 2.2374
2024-10-30 15:41:31: [2024-10-30 15:41:31] iter = 08510, loss = 23.6719
2024-10-30 15:41:32: [2024-10-30 15:41:32] iter = 08520, loss = 1.9653
2024-10-30 15:41:33: [2024-10-30 15:41:33] iter = 08530, loss = 5.4298
2024-10-30 15:41:34: [2024-10-30 15:41:34] iter = 08540, loss = 2.1977
2024-10-30 15:41:35: [2024-10-30 15:41:35] iter = 08550, loss = 2.2474
2024-10-30 15:41:35: [2024-10-30 15:41:35] iter = 08560, loss = 1.4403
2024-10-30 15:41:35: [2024-10-30 15:41:35] iter = 08570, loss = 1.5603
2024-10-30 15:41:36: [2024-10-30 15:41:36] iter = 08580, loss = 2.1922
2024-10-30 15:41:37: [2024-10-30 15:41:37] iter = 08590, loss = 1.3400
2024-10-30 15:41:39: [2024-10-30 15:41:39] iter = 08600, loss = 22.9544
2024-10-30 15:41:40: [2024-10-30 15:41:40] iter = 08610, loss = 2.3851
2024-10-30 15:41:41: [2024-10-30 15:41:41] iter = 08620, loss = 2.8435
2024-10-30 15:41:41: [2024-10-30 15:41:41] iter = 08630, loss = 8.2905
2024-10-30 15:41:42: [2024-10-30 15:41:42] iter = 08640, loss = 4.3990
2024-10-30 15:41:42: [2024-10-30 15:41:42] iter = 08650, loss = 30.8724
2024-10-30 15:41:42: [2024-10-30 15:41:42] iter = 08660, loss = 5.0962
2024-10-30 15:41:43: [2024-10-30 15:41:43] iter = 08670, loss = 4.7568
2024-10-30 15:41:44: [2024-10-30 15:41:44] iter = 08680, loss = 2.6721
2024-10-30 15:41:45: [2024-10-30 15:41:45] iter = 08690, loss = 15.3538
2024-10-30 15:41:47: [2024-10-30 15:41:47] iter = 08700, loss = 4.6158
2024-10-30 15:41:47: [2024-10-30 15:41:47] iter = 08710, loss = 1.4531
2024-10-30 15:41:48: [2024-10-30 15:41:48] iter = 08720, loss = 2.8804
2024-10-30 15:41:50: [2024-10-30 15:41:50] iter = 08730, loss = 3.0227
2024-10-30 15:41:51: [2024-10-30 15:41:51] iter = 08740, loss = 3.0736
2024-10-30 15:41:52: [2024-10-30 15:41:52] iter = 08750, loss = 1.6123
2024-10-30 15:41:53: [2024-10-30 15:41:53] iter = 08760, loss = 1.5751
2024-10-30 15:41:54: [2024-10-30 15:41:54] iter = 08770, loss = 3.5334
2024-10-30 15:41:55: [2024-10-30 15:41:55] iter = 08780, loss = 2.0037
2024-10-30 15:41:56: [2024-10-30 15:41:56] iter = 08790, loss = 4.3748
2024-10-30 15:41:57: [2024-10-30 15:41:57] iter = 08800, loss = 1.8339
2024-10-30 15:41:58: [2024-10-30 15:41:58] iter = 08810, loss = 2.6099
2024-10-30 15:41:59: [2024-10-30 15:41:59] iter = 08820, loss = 4.9829
2024-10-30 15:42:00: [2024-10-30 15:42:00] iter = 08830, loss = 1.8324
2024-10-30 15:42:00: [2024-10-30 15:42:00] iter = 08840, loss = 1.5464
2024-10-30 15:42:01: [2024-10-30 15:42:01] iter = 08850, loss = 2.5056
2024-10-30 15:42:02: [2024-10-30 15:42:02] iter = 08860, loss = 3.9546
2024-10-30 15:42:03: [2024-10-30 15:42:03] iter = 08870, loss = 4.6542
2024-10-30 15:42:03: [2024-10-30 15:42:03] iter = 08880, loss = 1.9179
2024-10-30 15:42:04: [2024-10-30 15:42:04] iter = 08890, loss = 1.4331
2024-10-30 15:42:05: [2024-10-30 15:42:05] iter = 08900, loss = 5.2320
2024-10-30 15:42:06: [2024-10-30 15:42:06] iter = 08910, loss = 2.0756
2024-10-30 15:42:07: [2024-10-30 15:42:07] iter = 08920, loss = 1.3097
2024-10-30 15:42:08: [2024-10-30 15:42:08] iter = 08930, loss = 1.1965
2024-10-30 15:42:08: [2024-10-30 15:42:08] iter = 08940, loss = 7.7297
2024-10-30 15:42:10: [2024-10-30 15:42:10] iter = 08950, loss = 1.9441
2024-10-30 15:42:11: [2024-10-30 15:42:11] iter = 08960, loss = 7.8389
2024-10-30 15:42:11: [2024-10-30 15:42:11] iter = 08970, loss = 4.8697
2024-10-30 15:42:12: [2024-10-30 15:42:12] iter = 08980, loss = 1.9311
2024-10-30 15:42:14: [2024-10-30 15:42:14] iter = 08990, loss = 5.0338
2024-10-30 15:42:14: [2024-10-30 15:42:14] iter = 09000, loss = 3.8631
2024-10-30 15:42:15: [2024-10-30 15:42:15] iter = 09010, loss = 1.4383
2024-10-30 15:42:16: [2024-10-30 15:42:16] iter = 09020, loss = 3.6113
2024-10-30 15:42:16: [2024-10-30 15:42:16] iter = 09030, loss = 7.1248
2024-10-30 15:42:17: [2024-10-30 15:42:17] iter = 09040, loss = 4.5186
2024-10-30 15:42:18: [2024-10-30 15:42:18] iter = 09050, loss = 14.6456
2024-10-30 15:42:19: [2024-10-30 15:42:19] iter = 09060, loss = 7.1258
2024-10-30 15:42:20: [2024-10-30 15:42:20] iter = 09070, loss = 4.9514
2024-10-30 15:42:21: [2024-10-30 15:42:21] iter = 09080, loss = 9.5874
2024-10-30 15:42:22: [2024-10-30 15:42:22] iter = 09090, loss = 2.0024
2024-10-30 15:42:23: [2024-10-30 15:42:23] iter = 09100, loss = 3.4685
2024-10-30 15:42:24: [2024-10-30 15:42:24] iter = 09110, loss = 4.0451
2024-10-30 15:42:25: [2024-10-30 15:42:25] iter = 09120, loss = 2.2038
2024-10-30 15:42:25: [2024-10-30 15:42:25] iter = 09130, loss = 9.4705
2024-10-30 15:42:26: [2024-10-30 15:42:26] iter = 09140, loss = 3.5554
2024-10-30 15:42:27: [2024-10-30 15:42:27] iter = 09150, loss = 10.1980
2024-10-30 15:42:28: [2024-10-30 15:42:28] iter = 09160, loss = 16.4390
2024-10-30 15:42:29: [2024-10-30 15:42:29] iter = 09170, loss = 4.1807
2024-10-30 15:42:29: [2024-10-30 15:42:29] iter = 09180, loss = 6.6532
2024-10-30 15:42:30: [2024-10-30 15:42:30] iter = 09190, loss = 2.2543
2024-10-30 15:42:31: [2024-10-30 15:42:31] iter = 09200, loss = 1.5365
2024-10-30 15:42:32: [2024-10-30 15:42:32] iter = 09210, loss = 16.4373
2024-10-30 15:42:33: [2024-10-30 15:42:33] iter = 09220, loss = 12.6759
2024-10-30 15:42:34: [2024-10-30 15:42:34] iter = 09230, loss = 1.8441
2024-10-30 15:42:35: [2024-10-30 15:42:35] iter = 09240, loss = 2.8444
2024-10-30 15:42:36: [2024-10-30 15:42:36] iter = 09250, loss = 6.5118
2024-10-30 15:42:37: [2024-10-30 15:42:37] iter = 09260, loss = 3.3198
2024-10-30 15:42:38: [2024-10-30 15:42:38] iter = 09270, loss = 2.8111
2024-10-30 15:42:39: [2024-10-30 15:42:39] iter = 09280, loss = 14.3420
2024-10-30 15:42:40: [2024-10-30 15:42:40] iter = 09290, loss = 4.1126
2024-10-30 15:42:42: [2024-10-30 15:42:42] iter = 09300, loss = 1.6400
2024-10-30 15:42:43: [2024-10-30 15:42:43] iter = 09310, loss = 10.0681
2024-10-30 15:42:44: [2024-10-30 15:42:44] iter = 09320, loss = 9.3117
2024-10-30 15:42:45: [2024-10-30 15:42:45] iter = 09330, loss = 3.1835
2024-10-30 15:42:46: [2024-10-30 15:42:46] iter = 09340, loss = 1.4626
2024-10-30 15:42:47: [2024-10-30 15:42:47] iter = 09350, loss = 5.1019
2024-10-30 15:42:48: [2024-10-30 15:42:48] iter = 09360, loss = 1.6459
2024-10-30 15:42:49: [2024-10-30 15:42:49] iter = 09370, loss = 1.7004
2024-10-30 15:42:51: [2024-10-30 15:42:51] iter = 09380, loss = 1.6005
2024-10-30 15:42:52: [2024-10-30 15:42:52] iter = 09390, loss = 2.3081
2024-10-30 15:42:53: [2024-10-30 15:42:53] iter = 09400, loss = 2.3867
2024-10-30 15:42:54: [2024-10-30 15:42:54] iter = 09410, loss = 2.2506
2024-10-30 15:42:55: [2024-10-30 15:42:55] iter = 09420, loss = 15.7441
2024-10-30 15:42:56: [2024-10-30 15:42:55] iter = 09430, loss = 16.0472
2024-10-30 15:42:57: [2024-10-30 15:42:57] iter = 09440, loss = 2.2311
2024-10-30 15:42:58: [2024-10-30 15:42:58] iter = 09450, loss = 4.9704
2024-10-30 15:42:59: [2024-10-30 15:42:59] iter = 09460, loss = 1.9682
2024-10-30 15:43:00: [2024-10-30 15:43:00] iter = 09470, loss = 3.1829
2024-10-30 15:43:01: [2024-10-30 15:43:01] iter = 09480, loss = 1.8962
2024-10-30 15:43:02: [2024-10-30 15:43:02] iter = 09490, loss = 1.4324
2024-10-30 15:43:03: [2024-10-30 15:43:03] iter = 09500, loss = 2.2432
2024-10-30 15:43:04: [2024-10-30 15:43:04] iter = 09510, loss = 1.9880
2024-10-30 15:43:05: [2024-10-30 15:43:05] iter = 09520, loss = 2.5911
2024-10-30 15:43:06: [2024-10-30 15:43:06] iter = 09530, loss = 1.8221
2024-10-30 15:43:07: [2024-10-30 15:43:07] iter = 09540, loss = 43.3831
2024-10-30 15:43:08: [2024-10-30 15:43:08] iter = 09550, loss = 3.3818
2024-10-30 15:43:09: [2024-10-30 15:43:09] iter = 09560, loss = 2.7090
2024-10-30 15:43:10: [2024-10-30 15:43:10] iter = 09570, loss = 1.3149
2024-10-30 15:43:10: [2024-10-30 15:43:10] iter = 09580, loss = 3.0056
2024-10-30 15:43:11: [2024-10-30 15:43:11] iter = 09590, loss = 2.1592
2024-10-30 15:43:12: [2024-10-30 15:43:12] iter = 09600, loss = 1.6152
2024-10-30 15:43:13: [2024-10-30 15:43:13] iter = 09610, loss = 2.5304
2024-10-30 15:43:15: [2024-10-30 15:43:15] iter = 09620, loss = 3.3862
2024-10-30 15:43:16: [2024-10-30 15:43:16] iter = 09630, loss = 4.4192
2024-10-30 15:43:17: [2024-10-30 15:43:17] iter = 09640, loss = 14.7854
2024-10-30 15:43:18: [2024-10-30 15:43:18] iter = 09650, loss = 4.8251
2024-10-30 15:43:19: [2024-10-30 15:43:19] iter = 09660, loss = 6.2719
2024-10-30 15:43:20: [2024-10-30 15:43:20] iter = 09670, loss = 2.8262
2024-10-30 15:43:20: [2024-10-30 15:43:20] iter = 09680, loss = 6.4305
2024-10-30 15:43:21: [2024-10-30 15:43:21] iter = 09690, loss = 2.6910
2024-10-30 15:43:22: [2024-10-30 15:43:22] iter = 09700, loss = 7.9161
2024-10-30 15:43:23: [2024-10-30 15:43:23] iter = 09710, loss = 8.4691
2024-10-30 15:43:24: [2024-10-30 15:43:24] iter = 09720, loss = 5.3026
2024-10-30 15:43:25: [2024-10-30 15:43:25] iter = 09730, loss = 28.1467
2024-10-30 15:43:26: [2024-10-30 15:43:26] iter = 09740, loss = 6.5894
2024-10-30 15:43:27: [2024-10-30 15:43:27] iter = 09750, loss = 5.5057
2024-10-30 15:43:27: [2024-10-30 15:43:27] iter = 09760, loss = 2.0378
2024-10-30 15:43:28: [2024-10-30 15:43:28] iter = 09770, loss = 5.9236
2024-10-30 15:43:29: [2024-10-30 15:43:29] iter = 09780, loss = 3.7173
2024-10-30 15:43:30: [2024-10-30 15:43:30] iter = 09790, loss = 4.4168
2024-10-30 15:43:31: [2024-10-30 15:43:31] iter = 09800, loss = 2.8274
2024-10-30 15:43:32: [2024-10-30 15:43:32] iter = 09810, loss = 2.2317
2024-10-30 15:43:33: [2024-10-30 15:43:33] iter = 09820, loss = 1.6034
2024-10-30 15:43:34: [2024-10-30 15:43:34] iter = 09830, loss = 3.6577
2024-10-30 15:43:35: [2024-10-30 15:43:35] iter = 09840, loss = 3.9641
2024-10-30 15:43:36: [2024-10-30 15:43:36] iter = 09850, loss = 1.8188
2024-10-30 15:43:37: [2024-10-30 15:43:37] iter = 09860, loss = 6.7950
2024-10-30 15:43:38: [2024-10-30 15:43:38] iter = 09870, loss = 1.9335
2024-10-30 15:43:39: [2024-10-30 15:43:39] iter = 09880, loss = 6.0800
2024-10-30 15:43:39: [2024-10-30 15:43:39] iter = 09890, loss = 2.2307
2024-10-30 15:43:40: [2024-10-30 15:43:40] iter = 09900, loss = 21.1732
2024-10-30 15:43:42: [2024-10-30 15:43:42] iter = 09910, loss = 1.5956
2024-10-30 15:43:43: [2024-10-30 15:43:43] iter = 09920, loss = 5.9075
2024-10-30 15:43:44: [2024-10-30 15:43:44] iter = 09930, loss = 6.7806
2024-10-30 15:43:44: [2024-10-30 15:43:44] iter = 09940, loss = 2.2275
2024-10-30 15:43:45: [2024-10-30 15:43:45] iter = 09950, loss = 2.8935
2024-10-30 15:43:46: [2024-10-30 15:43:46] iter = 09960, loss = 3.6579
2024-10-30 15:43:47: [2024-10-30 15:43:47] iter = 09970, loss = 1.8002
2024-10-30 15:43:48: [2024-10-30 15:43:48] iter = 09980, loss = 2.4954
2024-10-30 15:43:49: [2024-10-30 15:43:49] iter = 09990, loss = 7.2037
2024-10-30 15:43:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 15:43:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:43:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30676}

[2024-10-30 15:06:05] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.000128 train acc = 1.0000, test acc = 0.3718, test_sen =0.5476, test_spe =0.5476, test_f1 =0.3613
[2024-10-30 15:06:23] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000276 train acc = 1.0000, test acc = 0.4038, test_sen =0.5771, test_spe =0.5771, test_f1 =0.3967
[2024-10-30 15:06:41] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000025 train acc = 1.0000, test acc = 0.3782, test_sen =0.5445, test_spe =0.5445, test_f1 =0.3707
[2024-10-30 15:10:05] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.001019 train acc = 1.0000, test acc = 0.6923, test_sen =0.6992, test_spe =0.6992, test_f1 =0.6601
[2024-10-30 15:10:21] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.000637 train acc = 1.0000, test acc = 0.7372, test_sen =0.7375, test_spe =0.7375, test_f1 =0.7029
[2024-10-30 15:10:38] Evaluate_02: epoch = 1000 train time = 16 s train loss = 0.001788 train acc = 1.0000, test acc = 0.6987, test_sen =0.7112, test_spe =0.7112, test_f1 =0.6686
[2024-10-30 15:10:57] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.011463 train acc = 1.0000, test acc = 0.6987, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6594
[2024-10-30 15:11:17] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.000154 train acc = 1.0000, test acc = 0.6923, test_sen =0.7068, test_spe =0.7068, test_f1 =0.6630
[2024-10-30 15:14:44] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.009497 train acc = 1.0000, test acc = 0.6603, test_sen =0.7224, test_spe =0.7224, test_f1 =0.6463
[2024-10-30 15:15:03] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.000497 train acc = 1.0000, test acc = 0.6603, test_sen =0.7074, test_spe =0.7074, test_f1 =0.6422
[2024-10-30 15:15:19] Evaluate_02: epoch = 1000 train time = 16 s train loss = 0.000417 train acc = 1.0000, test acc = 0.6474, test_sen =0.6836, test_spe =0.6836, test_f1 =0.6264
[2024-10-30 15:15:39] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.000210 train acc = 1.0000, test acc = 0.6667, test_sen =0.7193, test_spe =0.7193, test_f1 =0.6500
[2024-10-30 15:15:58] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.000401 train acc = 1.0000, test acc = 0.6731, test_sen =0.7312, test_spe =0.7312, test_f1 =0.6578
[2024-10-30 15:19:38] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.000260 train acc = 1.0000, test acc = 0.7308, test_sen =0.7256, test_spe =0.7256, test_f1 =0.6941
[2024-10-30 15:19:56] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.004099 train acc = 1.0000, test acc = 0.7244, test_sen =0.7588, test_spe =0.7588, test_f1 =0.7017
[2024-10-30 15:20:14] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.015961 train acc = 1.0000, test acc = 0.7308, test_sen =0.7406, test_spe =0.7406, test_f1 =0.6999
[2024-10-30 15:20:29] Evaluate_03: epoch = 1000 train time = 15 s train loss = 0.000274 train acc = 1.0000, test acc = 0.7051, test_sen =0.7306, test_spe =0.7306, test_f1 =0.6796
[2024-10-30 15:20:46] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.000537 train acc = 1.0000, test acc = 0.6923, test_sen =0.7368, test_spe =0.7368, test_f1 =0.6729
[2024-10-30 15:21:03] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000051 train acc = 1.0000, test acc = 0.6859, test_sen =0.6573, test_spe =0.6573, test_f1 =0.6375
[2024-10-30 15:21:23] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.000054 train acc = 1.0000, test acc = 0.6603, test_sen =0.6548, test_spe =0.6548, test_f1 =0.6231
[2024-10-30 15:21:42] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.000030 train acc = 1.0000, test acc = 0.6090, test_sen =0.6122, test_spe =0.6122, test_f1 =0.5768
[2024-10-30 15:22:01] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.068820 train acc = 0.9500, test acc = 0.6282, test_sen =0.6178, test_spe =0.6178, test_f1 =0.5893
[2024-10-30 15:22:18] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000025 train acc = 1.0000, test acc = 0.6026, test_sen =0.6228, test_spe =0.6228, test_f1 =0.5775
[2024-10-30 15:25:39] Evaluate_00: epoch = 1000 train time = 12 s train loss = 0.001369 train acc = 1.0000, test acc = 0.7115, test_sen =0.7049, test_spe =0.7049, test_f1 =0.6739
[2024-10-30 15:25:58] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.002656 train acc = 1.0000, test acc = 0.7949, test_sen =0.7544, test_spe =0.7544, test_f1 =0.7468
[2024-10-30 15:26:16] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.002723 train acc = 1.0000, test acc = 0.7564, test_sen =0.7506, test_spe =0.7506, test_f1 =0.7204
[2024-10-30 15:26:35] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.001824 train acc = 1.0000, test acc = 0.7500, test_sen =0.7312, test_spe =0.7312, test_f1 =0.7083
[2024-10-30 15:26:51] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.000247 train acc = 1.0000, test acc = 0.7564, test_sen =0.7506, test_spe =0.7506, test_f1 =0.7204
[2024-10-30 15:30:13] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.000037 train acc = 1.0000, test acc = 0.7244, test_sen =0.5031, test_spe =0.5031, test_f1 =0.4417
[2024-10-30 15:30:33] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.000789 train acc = 1.0000, test acc = 0.7115, test_sen =0.4944, test_spe =0.4944, test_f1 =0.4364
[2024-10-30 15:30:51] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000026 train acc = 1.0000, test acc = 0.7115, test_sen =0.5019, test_spe =0.5019, test_f1 =0.4553
[2024-10-30 15:31:11] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.003131 train acc = 1.0000, test acc = 0.7051, test_sen =0.4900, test_spe =0.4900, test_f1 =0.4337
[2024-10-30 15:31:30] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.000455 train acc = 1.0000, test acc = 0.7179, test_sen =0.4987, test_spe =0.4987, test_f1 =0.4390
[2024-10-30 15:34:57] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.000456 train acc = 1.0000, test acc = 0.7628, test_sen =0.7325, test_spe =0.7325, test_f1 =0.7166
[2024-10-30 15:35:15] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.018874 train acc = 1.0000, test acc = 0.7051, test_sen =0.6629, test_spe =0.6629, test_f1 =0.6498
[2024-10-30 15:35:35] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.002071 train acc = 1.0000, test acc = 0.7244, test_sen =0.6685, test_spe =0.6685, test_f1 =0.6620
[2024-10-30 15:35:54] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.000091 train acc = 1.0000, test acc = 0.7244, test_sen =0.6610, test_spe =0.6610, test_f1 =0.6573
[2024-10-30 15:36:13] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.032006 train acc = 1.0000, test acc = 0.7372, test_sen =0.6848, test_spe =0.6848, test_f1 =0.6777
[2024-10-30 15:39:30] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000363 train acc = 1.0000, test acc = 0.7564, test_sen =0.6905, test_spe =0.6905, test_f1 =0.6905
[2024-10-30 15:39:48] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.000106 train acc = 1.0000, test acc = 0.6859, test_sen =0.6573, test_spe =0.6573, test_f1 =0.6375
[2024-10-30 15:40:07] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.001361 train acc = 1.0000, test acc = 0.7436, test_sen =0.6967, test_spe =0.6967, test_f1 =0.6877
[2024-10-30 15:40:26] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.000264 train acc = 1.0000, test acc = 0.7179, test_sen =0.6792, test_spe =0.6792, test_f1 =0.6650
[2024-10-30 15:40:47] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.000092 train acc = 1.0000, test acc = 0.7628, test_sen =0.7099, test_spe =0.7099, test_f1 =0.7051
[2024-10-30 15:44:09] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.010142 train acc = 1.0000, test acc = 0.6410, test_sen =0.6792, test_spe =0.6792, test_f1 =0.6208
[2024-10-30 15:44:28] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.000307 train acc = 1.0000, test acc = 0.6667, test_sen =0.6892, test_spe =0.6892, test_f1 =0.6406
[2024-10-30 15:44:47] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000066 train acc = 1.0000, test acc = 0.6795, test_sen =0.7055, test_spe =0.7055, test_f1 =0.6544/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:31: Evaluate 5 random ConvNet, ACCmean = 0.6667 ACCstd = 0.0134
-------------------------
2024-10-30 15:45:31: Evaluate 5 random ConvNet, SENmean = 0.6967 SENstd = 0.0110
-------------------------
2024-10-30 15:45:31: Evaluate 5 random ConvNet, SPEmean = 0.6967 SPEstd = 0.0110
-------------------------
2024-10-30 15:45:31: Evaluate 5 random ConvNet, F!mean = 0.6432 F!std = 0.0121
-------------------------
2024-10-30 15:45:31: Evaluate 5 random ConvNet, mean = 0.6667 std = 0.0134
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:31: [2024-10-30 15:45:31] iter = 10000, loss = 3.3917
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:45:32: [2024-10-30 15:45:32] iter = 10010, loss = 2.5203
2024-10-30 15:45:33: [2024-10-30 15:45:33] iter = 10020, loss = 1.4745
2024-10-30 15:45:34: [2024-10-30 15:45:34] iter = 10030, loss = 3.5938
2024-10-30 15:45:35: [2024-10-30 15:45:35] iter = 10040, loss = 5.7600
2024-10-30 15:45:36: [2024-10-30 15:45:36] iter = 10050, loss = 10.8679
2024-10-30 15:45:37: [2024-10-30 15:45:37] iter = 10060, loss = 4.3122
2024-10-30 15:45:37: [2024-10-30 15:45:37] iter = 10070, loss = 1.8792
2024-10-30 15:45:38: [2024-10-30 15:45:38] iter = 10080, loss = 1.4349
2024-10-30 15:45:40: [2024-10-30 15:45:40] iter = 10090, loss = 1.1106
2024-10-30 15:45:40: [2024-10-30 15:45:40] iter = 10100, loss = 1.4952
2024-10-30 15:45:41: [2024-10-30 15:45:41] iter = 10110, loss = 1.4692
2024-10-30 15:45:42: [2024-10-30 15:45:42] iter = 10120, loss = 1.1653
2024-10-30 15:45:43: [2024-10-30 15:45:43] iter = 10130, loss = 15.8198
2024-10-30 15:45:43: [2024-10-30 15:45:43] iter = 10140, loss = 7.5620
2024-10-30 15:45:44: [2024-10-30 15:45:44] iter = 10150, loss = 4.2100
2024-10-30 15:45:45: [2024-10-30 15:45:45] iter = 10160, loss = 4.1382
2024-10-30 15:45:46: [2024-10-30 15:45:46] iter = 10170, loss = 5.9823
2024-10-30 15:45:47: [2024-10-30 15:45:47] iter = 10180, loss = 5.1568
2024-10-30 15:45:48: [2024-10-30 15:45:48] iter = 10190, loss = 1.8208
2024-10-30 15:45:49: [2024-10-30 15:45:49] iter = 10200, loss = 3.1998
2024-10-30 15:45:50: [2024-10-30 15:45:50] iter = 10210, loss = 2.4808
2024-10-30 15:45:51: [2024-10-30 15:45:51] iter = 10220, loss = 1.0825
2024-10-30 15:45:53: [2024-10-30 15:45:53] iter = 10230, loss = 1.9452
2024-10-30 15:45:54: [2024-10-30 15:45:54] iter = 10240, loss = 12.1183
2024-10-30 15:45:55: [2024-10-30 15:45:55] iter = 10250, loss = 2.8331
2024-10-30 15:45:56: [2024-10-30 15:45:56] iter = 10260, loss = 14.6818
2024-10-30 15:45:57: [2024-10-30 15:45:57] iter = 10270, loss = 2.6387
2024-10-30 15:45:58: [2024-10-30 15:45:58] iter = 10280, loss = 33.4622
2024-10-30 15:45:59: [2024-10-30 15:45:59] iter = 10290, loss = 2.4082
2024-10-30 15:46:00: [2024-10-30 15:46:00] iter = 10300, loss = 1.3757
2024-10-30 15:46:01: [2024-10-30 15:46:01] iter = 10310, loss = 3.4707
2024-10-30 15:46:02: [2024-10-30 15:46:02] iter = 10320, loss = 6.8599
2024-10-30 15:46:03: [2024-10-30 15:46:03] iter = 10330, loss = 1.2555
2024-10-30 15:46:03: [2024-10-30 15:46:03] iter = 10340, loss = 1.1991
2024-10-30 15:46:04: [2024-10-30 15:46:04] iter = 10350, loss = 3.1428
2024-10-30 15:46:05: [2024-10-30 15:46:05] iter = 10360, loss = 3.8157
2024-10-30 15:46:06: [2024-10-30 15:46:06] iter = 10370, loss = 1.7399
2024-10-30 15:46:06: [2024-10-30 15:46:06] iter = 10380, loss = 4.3568
2024-10-30 15:46:07: [2024-10-30 15:46:07] iter = 10390, loss = 4.4175
2024-10-30 15:46:08: [2024-10-30 15:46:08] iter = 10400, loss = 2.6126
2024-10-30 15:46:09: [2024-10-30 15:46:09] iter = 10410, loss = 16.4181
2024-10-30 15:46:10: [2024-10-30 15:46:10] iter = 10420, loss = 3.3231
2024-10-30 15:46:11: [2024-10-30 15:46:11] iter = 10430, loss = 1.9022
2024-10-30 15:46:12: [2024-10-30 15:46:12] iter = 10440, loss = 1.6095
2024-10-30 15:46:13: [2024-10-30 15:46:13] iter = 10450, loss = 1.0045
2024-10-30 15:46:15: [2024-10-30 15:46:15] iter = 10460, loss = 1.8748
2024-10-30 15:46:16: [2024-10-30 15:46:16] iter = 10470, loss = 9.2141
2024-10-30 15:46:16: [2024-10-30 15:46:16] iter = 10480, loss = 4.0090
2024-10-30 15:46:17: [2024-10-30 15:46:17] iter = 10490, loss = 7.8317
2024-10-30 15:46:18: [2024-10-30 15:46:18] iter = 10500, loss = 2.8156
2024-10-30 15:46:19: [2024-10-30 15:46:19] iter = 10510, loss = 1.4725
2024-10-30 15:46:20: [2024-10-30 15:46:20] iter = 10520, loss = 5.7351
2024-10-30 15:46:21: [2024-10-30 15:46:21] iter = 10530, loss = 2.7194
2024-10-30 15:46:22: [2024-10-30 15:46:22] iter = 10540, loss = 8.3314
2024-10-30 15:46:23: [2024-10-30 15:46:23] iter = 10550, loss = 3.5792
2024-10-30 15:46:24: [2024-10-30 15:46:24] iter = 10560, loss = 3.0393
2024-10-30 15:46:25: [2024-10-30 15:46:25] iter = 10570, loss = 2.0141
2024-10-30 15:46:26: [2024-10-30 15:46:26] iter = 10580, loss = 2.4682
2024-10-30 15:46:27: [2024-10-30 15:46:27] iter = 10590, loss = 16.7276
2024-10-30 15:46:28: [2024-10-30 15:46:28] iter = 10600, loss = 3.4519
2024-10-30 15:46:29: [2024-10-30 15:46:29] iter = 10610, loss = 3.4786
2024-10-30 15:46:29: [2024-10-30 15:46:29] iter = 10620, loss = 3.5737
2024-10-30 15:46:30: [2024-10-30 15:46:30] iter = 10630, loss = 2.8095
2024-10-30 15:46:32: [2024-10-30 15:46:32] iter = 10640, loss = 2.4790
2024-10-30 15:46:33: [2024-10-30 15:46:33] iter = 10650, loss = 2.3222
2024-10-30 15:46:34: [2024-10-30 15:46:34] iter = 10660, loss = 6.1836
2024-10-30 15:46:34: [2024-10-30 15:46:34] iter = 10670, loss = 1.2946
2024-10-30 15:46:36: [2024-10-30 15:46:36] iter = 10680, loss = 2.4165
2024-10-30 15:46:36: [2024-10-30 15:46:36] iter = 10690, loss = 2.3962
2024-10-30 15:46:37: [2024-10-30 15:46:37] iter = 10700, loss = 14.9246
2024-10-30 15:46:38: [2024-10-30 15:46:38] iter = 10710, loss = 10.9013
2024-10-30 15:46:39: [2024-10-30 15:46:39] iter = 10720, loss = 8.6319
2024-10-30 15:46:40: [2024-10-30 15:46:40] iter = 10730, loss = 14.8535
2024-10-30 15:46:41: [2024-10-30 15:46:41] iter = 10740, loss = 5.6189
2024-10-30 15:46:42: [2024-10-30 15:46:42] iter = 10750, loss = 1.9767
2024-10-30 15:46:43: [2024-10-30 15:46:43] iter = 10760, loss = 2.8393
2024-10-30 15:46:44: [2024-10-30 15:46:44] iter = 10770, loss = 2.0510
2024-10-30 15:46:45: [2024-10-30 15:46:45] iter = 10780, loss = 1.4702
2024-10-30 15:46:47: [2024-10-30 15:46:47] iter = 10790, loss = 9.0637
2024-10-30 15:46:47: [2024-10-30 15:46:47] iter = 10800, loss = 1.7869
2024-10-30 15:46:48: [2024-10-30 15:46:48] iter = 10810, loss = 6.3107
2024-10-30 15:46:49: [2024-10-30 15:46:49] iter = 10820, loss = 4.7932
2024-10-30 15:46:51: [2024-10-30 15:46:51] iter = 10830, loss = 3.1565
2024-10-30 15:46:52: [2024-10-30 15:46:52] iter = 10840, loss = 1.1719
2024-10-30 15:46:53: [2024-10-30 15:46:53] iter = 10850, loss = 2.3595
2024-10-30 15:46:54: [2024-10-30 15:46:54] iter = 10860, loss = 1.1851
2024-10-30 15:46:56: [2024-10-30 15:46:56] iter = 10870, loss = 9.3846
2024-10-30 15:46:56: [2024-10-30 15:46:56] iter = 10880, loss = 7.8825
2024-10-30 15:46:57: [2024-10-30 15:46:57] iter = 10890, loss = 2.6081
2024-10-30 15:46:58: [2024-10-30 15:46:58] iter = 10900, loss = 6.9606
2024-10-30 15:46:59: [2024-10-30 15:46:59] iter = 10910, loss = 3.7107
2024-10-30 15:46:59: [2024-10-30 15:46:59] iter = 10920, loss = 2.3843
2024-10-30 15:47:00: [2024-10-30 15:47:00] iter = 10930, loss = 0.9911
2024-10-30 15:47:01: [2024-10-30 15:47:01] iter = 10940, loss = 18.0122
2024-10-30 15:47:02: [2024-10-30 15:47:02] iter = 10950, loss = 10.5223
2024-10-30 15:47:03: [2024-10-30 15:47:03] iter = 10960, loss = 3.3724
2024-10-30 15:47:04: [2024-10-30 15:47:04] iter = 10970, loss = 6.0753
2024-10-30 15:47:04: [2024-10-30 15:47:04] iter = 10980, loss = 18.7477
2024-10-30 15:47:05: [2024-10-30 15:47:05] iter = 10990, loss = 4.4418
2024-10-30 15:47:06: [2024-10-30 15:47:06] iter = 11000, loss = 1.4013
2024-10-30 15:47:07: [2024-10-30 15:47:07] iter = 11010, loss = 4.1215
2024-10-30 15:47:08: [2024-10-30 15:47:08] iter = 11020, loss = 1.6880
2024-10-30 15:47:08: [2024-10-30 15:47:08] iter = 11030, loss = 4.0713
2024-10-30 15:47:09: [2024-10-30 15:47:09] iter = 11040, loss = 26.8071
2024-10-30 15:47:10: [2024-10-30 15:47:10] iter = 11050, loss = 4.7434
2024-10-30 15:47:11: [2024-10-30 15:47:11] iter = 11060, loss = 3.8290
2024-10-30 15:47:12: [2024-10-30 15:47:12] iter = 11070, loss = 2.3651
2024-10-30 15:47:13: [2024-10-30 15:47:13] iter = 11080, loss = 1.8762
2024-10-30 15:47:14: [2024-10-30 15:47:14] iter = 11090, loss = 2.7475
2024-10-30 15:47:15: [2024-10-30 15:47:15] iter = 11100, loss = 1.5873
2024-10-30 15:47:16: [2024-10-30 15:47:16] iter = 11110, loss = 8.7947
2024-10-30 15:47:17: [2024-10-30 15:47:17] iter = 11120, loss = 2.9703
2024-10-30 15:47:18: [2024-10-30 15:47:18] iter = 11130, loss = 2.5104
2024-10-30 15:47:19: [2024-10-30 15:47:19] iter = 11140, loss = 1.3533
2024-10-30 15:47:20: [2024-10-30 15:47:20] iter = 11150, loss = 2.5578
2024-10-30 15:47:21: [2024-10-30 15:47:21] iter = 11160, loss = 3.4515
2024-10-30 15:47:21: [2024-10-30 15:47:21] iter = 11170, loss = 29.7631
2024-10-30 15:47:22: [2024-10-30 15:47:22] iter = 11180, loss = 1.8010
2024-10-30 15:47:23: [2024-10-30 15:47:23] iter = 11190, loss = 1.2772
2024-10-30 15:47:24: [2024-10-30 15:47:24] iter = 11200, loss = 2.4314
2024-10-30 15:47:25: [2024-10-30 15:47:25] iter = 11210, loss = 2.0558
2024-10-30 15:47:26: [2024-10-30 15:47:26] iter = 11220, loss = 4.9280
2024-10-30 15:47:27: [2024-10-30 15:47:27] iter = 11230, loss = 4.0567
2024-10-30 15:47:27: [2024-10-30 15:47:27] iter = 11240, loss = 3.8106
2024-10-30 15:47:27: [2024-10-30 15:47:27] iter = 11250, loss = 1.1183
2024-10-30 15:47:28: [2024-10-30 15:47:28] iter = 11260, loss = 2.6335
2024-10-30 15:47:29: [2024-10-30 15:47:29] iter = 11270, loss = 5.4450
2024-10-30 15:47:29: [2024-10-30 15:47:29] iter = 11280, loss = 3.2723
2024-10-30 15:47:30: [2024-10-30 15:47:30] iter = 11290, loss = 1.5849
2024-10-30 15:47:31: [2024-10-30 15:47:31] iter = 11300, loss = 3.8700
2024-10-30 15:47:32: [2024-10-30 15:47:32] iter = 11310, loss = 4.6257
2024-10-30 15:47:32: [2024-10-30 15:47:32] iter = 11320, loss = 4.2304
2024-10-30 15:47:33: [2024-10-30 15:47:33] iter = 11330, loss = 1.8139
2024-10-30 15:47:34: [2024-10-30 15:47:34] iter = 11340, loss = 1.3940
2024-10-30 15:47:35: [2024-10-30 15:47:35] iter = 11350, loss = 2.3978
2024-10-30 15:47:36: [2024-10-30 15:47:36] iter = 11360, loss = 1.4617
2024-10-30 15:47:37: [2024-10-30 15:47:37] iter = 11370, loss = 24.0208
2024-10-30 15:47:38: [2024-10-30 15:47:38] iter = 11380, loss = 2.7663
2024-10-30 15:47:39: [2024-10-30 15:47:39] iter = 11390, loss = 2.8871
2024-10-30 15:47:40: [2024-10-30 15:47:40] iter = 11400, loss = 1.2110
2024-10-30 15:47:41: [2024-10-30 15:47:41] iter = 11410, loss = 2.6587
2024-10-30 15:47:41: [2024-10-30 15:47:41] iter = 11420, loss = 11.4732
2024-10-30 15:47:42: [2024-10-30 15:47:42] iter = 11430, loss = 5.0875
2024-10-30 15:47:43: [2024-10-30 15:47:43] iter = 11440, loss = 17.4361
2024-10-30 15:47:43: [2024-10-30 15:47:43] iter = 11450, loss = 1.7969
2024-10-30 15:47:44: [2024-10-30 15:47:44] iter = 11460, loss = 1.6480
2024-10-30 15:47:46: [2024-10-30 15:47:46] iter = 11470, loss = 1.1420
2024-10-30 15:47:47: [2024-10-30 15:47:47] iter = 11480, loss = 1.1862
2024-10-30 15:47:48: [2024-10-30 15:47:48] iter = 11490, loss = 2.6793
2024-10-30 15:47:49: [2024-10-30 15:47:49] iter = 11500, loss = 8.4516
2024-10-30 15:47:50: [2024-10-30 15:47:50] iter = 11510, loss = 1.2994
2024-10-30 15:47:51: [2024-10-30 15:47:51] iter = 11520, loss = 2.3301
2024-10-30 15:47:52: [2024-10-30 15:47:52] iter = 11530, loss = 2.8094
2024-10-30 15:47:53: [2024-10-30 15:47:53] iter = 11540, loss = 3.3365
2024-10-30 15:47:54: [2024-10-30 15:47:54] iter = 11550, loss = 1.3973
2024-10-30 15:47:55: [2024-10-30 15:47:55] iter = 11560, loss = 1.8386
2024-10-30 15:47:56: [2024-10-30 15:47:56] iter = 11570, loss = 2.2586
2024-10-30 15:47:57: [2024-10-30 15:47:57] iter = 11580, loss = 2.5137
2024-10-30 15:47:58: [2024-10-30 15:47:58] iter = 11590, loss = 2.5546
2024-10-30 15:47:59: [2024-10-30 15:47:59] iter = 11600, loss = 2.1958
2024-10-30 15:48:00: [2024-10-30 15:48:00] iter = 11610, loss = 2.8931
2024-10-30 15:48:01: [2024-10-30 15:48:01] iter = 11620, loss = 3.5304
2024-10-30 15:48:03: [2024-10-30 15:48:03] iter = 11630, loss = 1.6382
2024-10-30 15:48:03: [2024-10-30 15:48:03] iter = 11640, loss = 3.3123
2024-10-30 15:48:04: [2024-10-30 15:48:04] iter = 11650, loss = 1.3712
2024-10-30 15:48:05: [2024-10-30 15:48:05] iter = 11660, loss = 1.0485
2024-10-30 15:48:05: [2024-10-30 15:48:05] iter = 11670, loss = 9.8520
2024-10-30 15:48:05: [2024-10-30 15:48:05] iter = 11680, loss = 4.8843
2024-10-30 15:48:05: [2024-10-30 15:48:05] iter = 11690, loss = 4.0385
2024-10-30 15:48:06: [2024-10-30 15:48:06] iter = 11700, loss = 2.5952
2024-10-30 15:48:07: [2024-10-30 15:48:07] iter = 11710, loss = 2.5568
2024-10-30 15:48:08: [2024-10-30 15:48:08] iter = 11720, loss = 6.4483
2024-10-30 15:48:09: [2024-10-30 15:48:09] iter = 11730, loss = 1.0312
2024-10-30 15:48:10: [2024-10-30 15:48:10] iter = 11740, loss = 2.3774
2024-10-30 15:48:11: [2024-10-30 15:48:11] iter = 11750, loss = 3.1375
2024-10-30 15:48:12: [2024-10-30 15:48:12] iter = 11760, loss = 2.8628
2024-10-30 15:48:13: [2024-10-30 15:48:13] iter = 11770, loss = 22.5181
2024-10-30 15:48:14: [2024-10-30 15:48:14] iter = 11780, loss = 7.5527
2024-10-30 15:48:15: [2024-10-30 15:48:15] iter = 11790, loss = 2.0045
2024-10-30 15:48:15: [2024-10-30 15:48:15] iter = 11800, loss = 4.0257
2024-10-30 15:48:16: [2024-10-30 15:48:16] iter = 11810, loss = 3.8574
2024-10-30 15:48:17: [2024-10-30 15:48:17] iter = 11820, loss = 2.8280
2024-10-30 15:48:17: [2024-10-30 15:48:17] iter = 11830, loss = 1.3362
2024-10-30 15:48:18: [2024-10-30 15:48:18] iter = 11840, loss = 3.2372
2024-10-30 15:48:18: [2024-10-30 15:48:18] iter = 11850, loss = 27.3218
2024-10-30 15:48:19: [2024-10-30 15:48:19] iter = 11860, loss = 2.8664
2024-10-30 15:48:20: [2024-10-30 15:48:20] iter = 11870, loss = 1.7416
2024-10-30 15:48:20: [2024-10-30 15:48:20] iter = 11880, loss = 3.0447
2024-10-30 15:48:21: [2024-10-30 15:48:21] iter = 11890, loss = 2.7616
2024-10-30 15:48:22: [2024-10-30 15:48:22] iter = 11900, loss = 2.1684
2024-10-30 15:48:23: [2024-10-30 15:48:23] iter = 11910, loss = 1.2502
2024-10-30 15:48:25: [2024-10-30 15:48:25] iter = 11920, loss = 3.3761
2024-10-30 15:48:26: [2024-10-30 15:48:26] iter = 11930, loss = 4.0796
2024-10-30 15:48:26: [2024-10-30 15:48:26] iter = 11940, loss = 5.9975
2024-10-30 15:48:27: [2024-10-30 15:48:27] iter = 11950, loss = 2.9057
2024-10-30 15:48:28: [2024-10-30 15:48:28] iter = 11960, loss = 2.7028
2024-10-30 15:48:29: [2024-10-30 15:48:29] iter = 11970, loss = 11.2367
2024-10-30 15:48:30: [2024-10-30 15:48:30] iter = 11980, loss = 10.0573
2024-10-30 15:48:30: [2024-10-30 15:48:30] iter = 11990, loss = 1.5227
2024-10-30 15:48:31: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 15:48:31: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:48:31: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 11214}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:50:13: Evaluate 5 random ConvNet, ACCmean = 0.6897 ACCstd = 0.0377
-------------------------
2024-10-30 15:50:13: Evaluate 5 random ConvNet, SENmean = 0.7125 SENstd = 0.0206
-------------------------
2024-10-30 15:50:13: Evaluate 5 random ConvNet, SPEmean = 0.7125 SPEstd = 0.0206
-------------------------
2024-10-30 15:50:13: Evaluate 5 random ConvNet, F!mean = 0.6634 F!std = 0.0310
-------------------------
2024-10-30 15:50:13: Evaluate 5 random ConvNet, mean = 0.6897 std = 0.0377
-------------------------
2024-10-30 15:50:13: [2024-10-30 15:50:13] iter = 12000, loss = 4.2255
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:50:14: [2024-10-30 15:50:14] iter = 12010, loss = 5.4038
2024-10-30 15:50:15: [2024-10-30 15:50:15] iter = 12020, loss = 20.2237
2024-10-30 15:50:16: [2024-10-30 15:50:16] iter = 12030, loss = 1.6781
2024-10-30 15:50:17: [2024-10-30 15:50:17] iter = 12040, loss = 4.9958
2024-10-30 15:50:18: [2024-10-30 15:50:18] iter = 12050, loss = 1.6487
2024-10-30 15:50:18: [2024-10-30 15:50:18] iter = 12060, loss = 25.3722
2024-10-30 15:50:19: [2024-10-30 15:50:19] iter = 12070, loss = 1.7354
2024-10-30 15:50:20: [2024-10-30 15:50:20] iter = 12080, loss = 2.9176
2024-10-30 15:50:21: [2024-10-30 15:50:21] iter = 12090, loss = 1.2293
2024-10-30 15:50:21: [2024-10-30 15:50:21] iter = 12100, loss = 1.4072
2024-10-30 15:50:22: [2024-10-30 15:50:22] iter = 12110, loss = 15.2512
2024-10-30 15:50:22: [2024-10-30 15:50:22] iter = 12120, loss = 3.5889
2024-10-30 15:50:22: [2024-10-30 15:50:22] iter = 12130, loss = 6.4151
2024-10-30 15:50:23: [2024-10-30 15:50:23] iter = 12140, loss = 1.8224
2024-10-30 15:50:24: [2024-10-30 15:50:24] iter = 12150, loss = 8.5429
2024-10-30 15:50:24: [2024-10-30 15:50:24] iter = 12160, loss = 18.3379
2024-10-30 15:50:25: [2024-10-30 15:50:25] iter = 12170, loss = 3.3640
2024-10-30 15:50:26: [2024-10-30 15:50:26] iter = 12180, loss = 6.7279
2024-10-30 15:50:27: [2024-10-30 15:50:27] iter = 12190, loss = 1.5799
2024-10-30 15:50:28: [2024-10-30 15:50:28] iter = 12200, loss = 4.5075
2024-10-30 15:50:29: [2024-10-30 15:50:29] iter = 12210, loss = 2.6190
2024-10-30 15:50:30: [2024-10-30 15:50:30] iter = 12220, loss = 1.0767
2024-10-30 15:50:31: [2024-10-30 15:50:31] iter = 12230, loss = 11.8528
2024-10-30 15:50:32: [2024-10-30 15:50:32] iter = 12240, loss = 28.1223
2024-10-30 15:50:33: [2024-10-30 15:50:33] iter = 12250, loss = 3.8202
2024-10-30 15:50:34: [2024-10-30 15:50:34] iter = 12260, loss = 6.5235
2024-10-30 15:50:34: [2024-10-30 15:50:34] iter = 12270, loss = 18.9983
2024-10-30 15:50:36: [2024-10-30 15:50:36] iter = 12280, loss = 3.6506
2024-10-30 15:50:37: [2024-10-30 15:50:37] iter = 12290, loss = 3.9880
2024-10-30 15:50:38: [2024-10-30 15:50:38] iter = 12300, loss = 1.9001
2024-10-30 15:50:38: [2024-10-30 15:50:38] iter = 12310, loss = 2.7305
2024-10-30 15:50:39: [2024-10-30 15:50:39] iter = 12320, loss = 9.6411
2024-10-30 15:50:40: [2024-10-30 15:50:40] iter = 12330, loss = 2.2083
2024-10-30 15:50:41: [2024-10-30 15:50:41] iter = 12340, loss = 4.2087
2024-10-30 15:50:42: [2024-10-30 15:50:42] iter = 12350, loss = 1.8619
2024-10-30 15:50:42: [2024-10-30 15:50:42] iter = 12360, loss = 2.5826
2024-10-30 15:50:42: [2024-10-30 15:50:42] iter = 12370, loss = 4.4811
2024-10-30 15:50:43: [2024-10-30 15:50:43] iter = 12380, loss = 6.8847
2024-10-30 15:50:43: [2024-10-30 15:50:43] iter = 12390, loss = 1.7554
2024-10-30 15:50:43: [2024-10-30 15:50:43] iter = 12400, loss = 3.0004
2024-10-30 15:50:44: [2024-10-30 15:50:44] iter = 12410, loss = 1.2437
2024-10-30 15:50:45: [2024-10-30 15:50:45] iter = 12420, loss = 6.9789
2024-10-30 15:50:46: [2024-10-30 15:50:46] iter = 12430, loss = 1.1455
2024-10-30 15:50:46: [2024-10-30 15:50:46] iter = 12440, loss = 1.3004
2024-10-30 15:50:47: [2024-10-30 15:50:47] iter = 12450, loss = 1.3569
2024-10-30 15:50:48: [2024-10-30 15:50:48] iter = 12460, loss = 0.9925
2024-10-30 15:50:49: [2024-10-30 15:50:49] iter = 12470, loss = 2.3037
2024-10-30 15:50:50: [2024-10-30 15:50:50] iter = 12480, loss = 3.3215
2024-10-30 15:50:51: [2024-10-30 15:50:51] iter = 12490, loss = 1.9671
2024-10-30 15:50:52: [2024-10-30 15:50:52] iter = 12500, loss = 6.4108
2024-10-30 15:50:53: [2024-10-30 15:50:53] iter = 12510, loss = 3.4258
2024-10-30 15:50:54: [2024-10-30 15:50:54] iter = 12520, loss = 8.0609
2024-10-30 15:50:55: [2024-10-30 15:50:55] iter = 12530, loss = 1.8889
2024-10-30 15:50:56: [2024-10-30 15:50:56] iter = 12540, loss = 3.5153
2024-10-30 15:50:57: [2024-10-30 15:50:57] iter = 12550, loss = 2.9549
2024-10-30 15:50:59: [2024-10-30 15:50:59] iter = 12560, loss = 1.7162
2024-10-30 15:51:00: [2024-10-30 15:51:00] iter = 12570, loss = 1.0148
2024-10-30 15:51:01: [2024-10-30 15:51:00] iter = 12580, loss = 7.4031
2024-10-30 15:51:01: [2024-10-30 15:51:01] iter = 12590, loss = 2.4730
2024-10-30 15:51:02: [2024-10-30 15:51:02] iter = 12600, loss = 1.2255
2024-10-30 15:51:03: [2024-10-30 15:51:03] iter = 12610, loss = 1.8558
2024-10-30 15:51:03: [2024-10-30 15:51:03] iter = 12620, loss = 3.7066
2024-10-30 15:51:03: [2024-10-30 15:51:03] iter = 12630, loss = 11.2647
2024-10-30 15:51:04: [2024-10-30 15:51:04] iter = 12640, loss = 2.2861
2024-10-30 15:51:05: [2024-10-30 15:51:05] iter = 12650, loss = 1.6736
2024-10-30 15:51:06: [2024-10-30 15:51:06] iter = 12660, loss = 2.4516
2024-10-30 15:51:07: [2024-10-30 15:51:07] iter = 12670, loss = 29.6445
2024-10-30 15:51:08: [2024-10-30 15:51:08] iter = 12680, loss = 2.2757
2024-10-30 15:51:09: [2024-10-30 15:51:09] iter = 12690, loss = 1.2573
2024-10-30 15:51:10: [2024-10-30 15:51:10] iter = 12700, loss = 8.2710
2024-10-30 15:51:11: [2024-10-30 15:51:11] iter = 12710, loss = 8.4373
2024-10-30 15:51:12: [2024-10-30 15:51:12] iter = 12720, loss = 4.1144
2024-10-30 15:51:13: [2024-10-30 15:51:13] iter = 12730, loss = 4.3527
2024-10-30 15:51:14: [2024-10-30 15:51:14] iter = 12740, loss = 3.4221
2024-10-30 15:51:15: [2024-10-30 15:51:15] iter = 12750, loss = 2.4671
2024-10-30 15:51:16: [2024-10-30 15:51:16] iter = 12760, loss = 3.7678
2024-10-30 15:51:17: [2024-10-30 15:51:17] iter = 12770, loss = 1.7647
2024-10-30 15:51:18: [2024-10-30 15:51:18] iter = 12780, loss = 7.9387
2024-10-30 15:51:18: [2024-10-30 15:51:18] iter = 12790, loss = 5.7759
2024-10-30 15:51:19: [2024-10-30 15:51:19] iter = 12800, loss = 2.5708
2024-10-30 15:51:20: [2024-10-30 15:51:20] iter = 12810, loss = 2.2360
2024-10-30 15:51:20: [2024-10-30 15:51:20] iter = 12820, loss = 3.2984
2024-10-30 15:51:21: [2024-10-30 15:51:21] iter = 12830, loss = 1.6742
2024-10-30 15:51:22: [2024-10-30 15:51:22] iter = 12840, loss = 3.3200
2024-10-30 15:51:22: [2024-10-30 15:51:22] iter = 12850, loss = 15.3749
2024-10-30 15:51:24: [2024-10-30 15:51:24] iter = 12860, loss = 2.3393
2024-10-30 15:51:25: [2024-10-30 15:51:25] iter = 12870, loss = 2.4555
2024-10-30 15:51:26: [2024-10-30 15:51:26] iter = 12880, loss = 4.2016
2024-10-30 15:51:27: [2024-10-30 15:51:27] iter = 12890, loss = 2.2571
2024-10-30 15:51:27: [2024-10-30 15:51:27] iter = 12900, loss = 2.1725
2024-10-30 15:51:28: [2024-10-30 15:51:28] iter = 12910, loss = 4.2024
2024-10-30 15:51:29: [2024-10-30 15:51:29] iter = 12920, loss = 30.5392
2024-10-30 15:51:30: [2024-10-30 15:51:30] iter = 12930, loss = 5.9152
2024-10-30 15:51:31: [2024-10-30 15:51:31] iter = 12940, loss = 1.7803
2024-10-30 15:51:31: [2024-10-30 15:51:31] iter = 12950, loss = 7.7743
2024-10-30 15:51:32: [2024-10-30 15:51:32] iter = 12960, loss = 3.3475
2024-10-30 15:51:34: [2024-10-30 15:51:33] iter = 12970, loss = 3.7196
2024-10-30 15:51:35: [2024-10-30 15:51:35] iter = 12980, loss = 2.0086
2024-10-30 15:51:35: [2024-10-30 15:51:35] iter = 12990, loss = 4.8619
2024-10-30 15:51:36: [2024-10-30 15:51:36] iter = 13000, loss = 4.5383
2024-10-30 15:51:37: [2024-10-30 15:51:37] iter = 13010, loss = 16.6869
2024-10-30 15:51:38: [2024-10-30 15:51:38] iter = 13020, loss = 9.2368
2024-10-30 15:51:39: [2024-10-30 15:51:39] iter = 13030, loss = 5.2045
2024-10-30 15:51:40: [2024-10-30 15:51:40] iter = 13040, loss = 1.3796
2024-10-30 15:51:40: [2024-10-30 15:51:40] iter = 13050, loss = 1.7963
2024-10-30 15:51:41: [2024-10-30 15:51:41] iter = 13060, loss = 2.8713
2024-10-30 15:51:42: [2024-10-30 15:51:42] iter = 13070, loss = 1.6265
2024-10-30 15:51:43: [2024-10-30 15:51:43] iter = 13080, loss = 23.6350
2024-10-30 15:51:44: [2024-10-30 15:51:44] iter = 13090, loss = 1.8618
2024-10-30 15:51:44: [2024-10-30 15:51:44] iter = 13100, loss = 4.7313
2024-10-30 15:51:45: [2024-10-30 15:51:45] iter = 13110, loss = 3.9355
2024-10-30 15:51:46: [2024-10-30 15:51:46] iter = 13120, loss = 2.3491
2024-10-30 15:51:47: [2024-10-30 15:51:47] iter = 13130, loss = 2.6172
2024-10-30 15:51:48: [2024-10-30 15:51:48] iter = 13140, loss = 8.8703
2024-10-30 15:51:49: [2024-10-30 15:51:49] iter = 13150, loss = 1.6010
2024-10-30 15:51:50: [2024-10-30 15:51:50] iter = 13160, loss = 6.8791
2024-10-30 15:51:51: [2024-10-30 15:51:51] iter = 13170, loss = 2.1143
2024-10-30 15:51:52: [2024-10-30 15:51:52] iter = 13180, loss = 5.9415
2024-10-30 15:51:53: [2024-10-30 15:51:53] iter = 13190, loss = 2.3797
2024-10-30 15:51:54: [2024-10-30 15:51:54] iter = 13200, loss = 5.9315
2024-10-30 15:51:55: [2024-10-30 15:51:55] iter = 13210, loss = 1.8903
2024-10-30 15:51:56: [2024-10-30 15:51:56] iter = 13220, loss = 1.2399
2024-10-30 15:51:57: [2024-10-30 15:51:57] iter = 13230, loss = 2.3284
2024-10-30 15:51:58: [2024-10-30 15:51:58] iter = 13240, loss = 5.1950
2024-10-30 15:51:59: [2024-10-30 15:51:59] iter = 13250, loss = 1.6746
2024-10-30 15:52:00: [2024-10-30 15:52:00] iter = 13260, loss = 2.3285
2024-10-30 15:52:01: [2024-10-30 15:52:01] iter = 13270, loss = 2.0238
2024-10-30 15:52:02: [2024-10-30 15:52:02] iter = 13280, loss = 7.6267
2024-10-30 15:52:03: [2024-10-30 15:52:03] iter = 13290, loss = 1.7861
2024-10-30 15:52:04: [2024-10-30 15:52:04] iter = 13300, loss = 1.3676
2024-10-30 15:52:04: [2024-10-30 15:52:04] iter = 13310, loss = 1.9603
2024-10-30 15:52:05: [2024-10-30 15:52:05] iter = 13320, loss = 9.6472
2024-10-30 15:52:07: [2024-10-30 15:52:07] iter = 13330, loss = 1.4152
2024-10-30 15:52:08: [2024-10-30 15:52:08] iter = 13340, loss = 2.2162
2024-10-30 15:52:08: [2024-10-30 15:52:08] iter = 13350, loss = 6.4273
2024-10-30 15:52:09: [2024-10-30 15:52:09] iter = 13360, loss = 4.2421
2024-10-30 15:52:10: [2024-10-30 15:52:10] iter = 13370, loss = 1.6049
2024-10-30 15:52:11: [2024-10-30 15:52:11] iter = 13380, loss = 1.8603
2024-10-30 15:52:11: [2024-10-30 15:52:11] iter = 13390, loss = 2.9017
2024-10-30 15:52:12: [2024-10-30 15:52:12] iter = 13400, loss = 1.8881
2024-10-30 15:52:13: [2024-10-30 15:52:13] iter = 13410, loss = 1.3149
2024-10-30 15:52:14: [2024-10-30 15:52:14] iter = 13420, loss = 5.0043
2024-10-30 15:52:14: [2024-10-30 15:52:14] iter = 13430, loss = 1.5516
2024-10-30 15:52:15: [2024-10-30 15:52:15] iter = 13440, loss = 1.5529
2024-10-30 15:52:15: [2024-10-30 15:52:15] iter = 13450, loss = 5.7149
2024-10-30 15:52:16: [2024-10-30 15:52:16] iter = 13460, loss = 2.1561
2024-10-30 15:52:17: [2024-10-30 15:52:17] iter = 13470, loss = 3.7438
2024-10-30 15:52:18: [2024-10-30 15:52:18] iter = 13480, loss = 2.7424
2024-10-30 15:52:19: [2024-10-30 15:52:19] iter = 13490, loss = 6.1887
2024-10-30 15:52:20: [2024-10-30 15:52:20] iter = 13500, loss = 2.4106
2024-10-30 15:52:21: [2024-10-30 15:52:21] iter = 13510, loss = 2.2259
2024-10-30 15:52:22: [2024-10-30 15:52:22] iter = 13520, loss = 6.2847
2024-10-30 15:52:23: [2024-10-30 15:52:23] iter = 13530, loss = 3.0468
2024-10-30 15:52:23: [2024-10-30 15:52:23] iter = 13540, loss = 15.4273
2024-10-30 15:52:24: [2024-10-30 15:52:24] iter = 13550, loss = 3.1345
2024-10-30 15:52:25: [2024-10-30 15:52:25] iter = 13560, loss = 2.6747
2024-10-30 15:52:26: [2024-10-30 15:52:26] iter = 13570, loss = 2.1355
2024-10-30 15:52:27: [2024-10-30 15:52:27] iter = 13580, loss = 3.1589
2024-10-30 15:52:28: [2024-10-30 15:52:28] iter = 13590, loss = 1.6213
2024-10-30 15:52:30: [2024-10-30 15:52:30] iter = 13600, loss = 4.1533
2024-10-30 15:52:31: [2024-10-30 15:52:31] iter = 13610, loss = 2.6261
2024-10-30 15:52:32: [2024-10-30 15:52:32] iter = 13620, loss = 1.0527
2024-10-30 15:52:33: [2024-10-30 15:52:33] iter = 13630, loss = 3.6865
2024-10-30 15:52:34: [2024-10-30 15:52:34] iter = 13640, loss = 1.6263
2024-10-30 15:52:34: [2024-10-30 15:52:34] iter = 13650, loss = 1.2093
2024-10-30 15:52:35: [2024-10-30 15:52:35] iter = 13660, loss = 3.5473
2024-10-30 15:52:36: [2024-10-30 15:52:36] iter = 13670, loss = 1.6934
2024-10-30 15:52:37: [2024-10-30 15:52:37] iter = 13680, loss = 4.8652
2024-10-30 15:52:38: [2024-10-30 15:52:38] iter = 13690, loss = 2.4286
2024-10-30 15:52:39: [2024-10-30 15:52:39] iter = 13700, loss = 2.2265
2024-10-30 15:52:40: [2024-10-30 15:52:40] iter = 13710, loss = 10.0993
2024-10-30 15:52:41: [2024-10-30 15:52:41] iter = 13720, loss = 1.4864
2024-10-30 15:52:42: [2024-10-30 15:52:42] iter = 13730, loss = 2.2766
2024-10-30 15:52:43: [2024-10-30 15:52:43] iter = 13740, loss = 1.7334
2024-10-30 15:52:43: [2024-10-30 15:52:43] iter = 13750, loss = 2.4719
2024-10-30 15:52:44: [2024-10-30 15:52:44] iter = 13760, loss = 2.6826
2024-10-30 15:52:45: [2024-10-30 15:52:45] iter = 13770, loss = 3.3855
2024-10-30 15:52:46: [2024-10-30 15:52:46] iter = 13780, loss = 1.3404
2024-10-30 15:52:47: [2024-10-30 15:52:47] iter = 13790, loss = 8.4608
2024-10-30 15:52:48: [2024-10-30 15:52:48] iter = 13800, loss = 1.7151
2024-10-30 15:52:49: [2024-10-30 15:52:49] iter = 13810, loss = 8.2582
2024-10-30 15:52:50: [2024-10-30 15:52:50] iter = 13820, loss = 12.7423
2024-10-30 15:52:51: [2024-10-30 15:52:51] iter = 13830, loss = 11.3344
2024-10-30 15:52:52: [2024-10-30 15:52:52] iter = 13840, loss = 3.3819
2024-10-30 15:52:53: [2024-10-30 15:52:53] iter = 13850, loss = 2.2362
2024-10-30 15:52:54: [2024-10-30 15:52:54] iter = 13860, loss = 1.1813
2024-10-30 15:52:55: [2024-10-30 15:52:55] iter = 13870, loss = 1.6909
2024-10-30 15:52:56: [2024-10-30 15:52:56] iter = 13880, loss = 1.3786
2024-10-30 15:52:57: [2024-10-30 15:52:57] iter = 13890, loss = 2.2666
2024-10-30 15:52:58: [2024-10-30 15:52:58] iter = 13900, loss = 7.8449
2024-10-30 15:53:00: [2024-10-30 15:53:00] iter = 13910, loss = 1.8339
2024-10-30 15:53:00: [2024-10-30 15:53:00] iter = 13920, loss = 1.4176
2024-10-30 15:53:01: [2024-10-30 15:53:01] iter = 13930, loss = 10.4537
2024-10-30 15:53:02: [2024-10-30 15:53:02] iter = 13940, loss = 13.6795
2024-10-30 15:53:03: [2024-10-30 15:53:03] iter = 13950, loss = 2.6691
2024-10-30 15:53:03: [2024-10-30 15:53:03] iter = 13960, loss = 1.3666
2024-10-30 15:53:04: [2024-10-30 15:53:04] iter = 13970, loss = 1.8737
2024-10-30 15:53:05: [2024-10-30 15:53:05] iter = 13980, loss = 1.3185
2024-10-30 15:53:06: [2024-10-30 15:53:06] iter = 13990, loss = 3.0484
2024-10-30 15:53:07: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 15:53:07: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:53:07: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87310}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:54:44: Evaluate 5 random ConvNet, ACCmean = 0.7795 ACCstd = 0.0144
-------------------------
2024-10-30 15:54:44: Evaluate 5 random ConvNet, SENmean = 0.7424 SENstd = 0.0117
-------------------------
2024-10-30 15:54:44: Evaluate 5 random ConvNet, SPEmean = 0.7424 SPEstd = 0.0117
-------------------------
2024-10-30 15:54:44: Evaluate 5 random ConvNet, F!mean = 0.7315 F!std = 0.0139
-------------------------
2024-10-30 15:54:44: Evaluate 5 random ConvNet, mean = 0.7795 std = 0.0144
-------------------------
2024-10-30 15:54:44: [2024-10-30 15:54:44] iter = 14000, loss = 1.2372
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:54:45: [2024-10-30 15:54:45] iter = 14010, loss = 1.8974
2024-10-30 15:54:46: [2024-10-30 15:54:46] iter = 14020, loss = 3.4926
2024-10-30 15:54:47: [2024-10-30 15:54:47] iter = 14030, loss = 1.4134
2024-10-30 15:54:48: [2024-10-30 15:54:48] iter = 14040, loss = 2.5280
2024-10-30 15:54:49: [2024-10-30 15:54:49] iter = 14050, loss = 1.4565
2024-10-30 15:54:50: [2024-10-30 15:54:50] iter = 14060, loss = 5.2874
2024-10-30 15:54:51: [2024-10-30 15:54:51] iter = 14070, loss = 6.4851
2024-10-30 15:54:52: [2024-10-30 15:54:52] iter = 14080, loss = 3.4858
2024-10-30 15:54:52: [2024-10-30 15:54:52] iter = 14090, loss = 3.5742
2024-10-30 15:54:53: [2024-10-30 15:54:53] iter = 14100, loss = 4.3549
2024-10-30 15:54:54: [2024-10-30 15:54:54] iter = 14110, loss = 3.3090
2024-10-30 15:54:55: [2024-10-30 15:54:55] iter = 14120, loss = 3.2035
2024-10-30 15:54:56: [2024-10-30 15:54:56] iter = 14130, loss = 3.2148
2024-10-30 15:54:57: [2024-10-30 15:54:57] iter = 14140, loss = 1.3796
2024-10-30 15:54:57: [2024-10-30 15:54:57] iter = 14150, loss = 2.4184
2024-10-30 15:54:58: [2024-10-30 15:54:58] iter = 14160, loss = 2.5567
2024-10-30 15:54:59: [2024-10-30 15:54:59] iter = 14170, loss = 2.4260
2024-10-30 15:55:00: [2024-10-30 15:55:00] iter = 14180, loss = 1.8712
2024-10-30 15:55:01: [2024-10-30 15:55:01] iter = 14190, loss = 2.9515
2024-10-30 15:55:02: [2024-10-30 15:55:02] iter = 14200, loss = 4.8962
2024-10-30 15:55:02: [2024-10-30 15:55:02] iter = 14210, loss = 1.8790
2024-10-30 15:55:03: [2024-10-30 15:55:03] iter = 14220, loss = 1.2853
2024-10-30 15:55:04: [2024-10-30 15:55:04] iter = 14230, loss = 1.1068
2024-10-30 15:55:05: [2024-10-30 15:55:05] iter = 14240, loss = 1.1458
2024-10-30 15:55:06: [2024-10-30 15:55:06] iter = 14250, loss = 1.3308
2024-10-30 15:55:06: [2024-10-30 15:55:06] iter = 14260, loss = 1.3290
2024-10-30 15:55:07: [2024-10-30 15:55:07] iter = 14270, loss = 7.5194
2024-10-30 15:55:08: [2024-10-30 15:55:08] iter = 14280, loss = 3.4713
2024-10-30 15:55:09: [2024-10-30 15:55:09] iter = 14290, loss = 4.9735
2024-10-30 15:55:10: [2024-10-30 15:55:10] iter = 14300, loss = 7.4377
2024-10-30 15:55:11: [2024-10-30 15:55:11] iter = 14310, loss = 2.9661
2024-10-30 15:55:12: [2024-10-30 15:55:12] iter = 14320, loss = 3.4391
2024-10-30 15:55:14: [2024-10-30 15:55:14] iter = 14330, loss = 4.2862
2024-10-30 15:55:14: [2024-10-30 15:55:14] iter = 14340, loss = 4.3712
2024-10-30 15:55:15: [2024-10-30 15:55:15] iter = 14350, loss = 2.1371
2024-10-30 15:55:17: [2024-10-30 15:55:17] iter = 14360, loss = 8.0854
2024-10-30 15:55:18: [2024-10-30 15:55:18] iter = 14370, loss = 3.0488
2024-10-30 15:55:19: [2024-10-30 15:55:19] iter = 14380, loss = 1.8078
2024-10-30 15:55:20: [2024-10-30 15:55:20] iter = 14390, loss = 3.6374
2024-10-30 15:55:20: [2024-10-30 15:55:20] iter = 14400, loss = 1.6125
2024-10-30 15:55:22: [2024-10-30 15:55:22] iter = 14410, loss = 1.4548
2024-10-30 15:55:23: [2024-10-30 15:55:23] iter = 14420, loss = 5.8269
2024-10-30 15:55:24: [2024-10-30 15:55:24] iter = 14430, loss = 5.0462
2024-10-30 15:55:25: [2024-10-30 15:55:25] iter = 14440, loss = 1.8214
2024-10-30 15:55:26: [2024-10-30 15:55:26] iter = 14450, loss = 8.4019
2024-10-30 15:55:26: [2024-10-30 15:55:26] iter = 14460, loss = 2.0533
2024-10-30 15:55:27: [2024-10-30 15:55:27] iter = 14470, loss = 1.9391
2024-10-30 15:55:28: [2024-10-30 15:55:28] iter = 14480, loss = 1.3414
2024-10-30 15:55:29: [2024-10-30 15:55:29] iter = 14490, loss = 3.7021
2024-10-30 15:55:29: [2024-10-30 15:55:29] iter = 14500, loss = 1.7395
2024-10-30 15:55:31: [2024-10-30 15:55:31] iter = 14510, loss = 5.6780
2024-10-30 15:55:32: [2024-10-30 15:55:32] iter = 14520, loss = 5.8273
2024-10-30 15:55:32: [2024-10-30 15:55:32] iter = 14530, loss = 25.5535
2024-10-30 15:55:33: [2024-10-30 15:55:33] iter = 14540, loss = 2.0110
2024-10-30 15:55:34: [2024-10-30 15:55:34] iter = 14550, loss = 5.3960
2024-10-30 15:55:36: [2024-10-30 15:55:36] iter = 14560, loss = 3.1170
2024-10-30 15:55:37: [2024-10-30 15:55:37] iter = 14570, loss = 2.0836
2024-10-30 15:55:38: [2024-10-30 15:55:38] iter = 14580, loss = 1.8280
2024-10-30 15:55:38: [2024-10-30 15:55:38] iter = 14590, loss = 1.8893
2024-10-30 15:55:39: [2024-10-30 15:55:39] iter = 14600, loss = 3.2582
2024-10-30 15:55:40: [2024-10-30 15:55:40] iter = 14610, loss = 5.1689
2024-10-30 15:55:41: [2024-10-30 15:55:41] iter = 14620, loss = 1.3637
2024-10-30 15:55:41: [2024-10-30 15:55:41] iter = 14630, loss = 8.5832
2024-10-30 15:55:42: [2024-10-30 15:55:42] iter = 14640, loss = 1.6962
2024-10-30 15:55:43: [2024-10-30 15:55:43] iter = 14650, loss = 1.2370
2024-10-30 15:55:44: [2024-10-30 15:55:44] iter = 14660, loss = 4.9868
2024-10-30 15:55:45: [2024-10-30 15:55:45] iter = 14670, loss = 1.4633
2024-10-30 15:55:46: [2024-10-30 15:55:46] iter = 14680, loss = 8.0340
2024-10-30 15:55:47: [2024-10-30 15:55:47] iter = 14690, loss = 1.3155
2024-10-30 15:55:48: [2024-10-30 15:55:48] iter = 14700, loss = 1.3092
2024-10-30 15:55:49: [2024-10-30 15:55:49] iter = 14710, loss = 28.4079
2024-10-30 15:55:50: [2024-10-30 15:55:50] iter = 14720, loss = 4.8787
2024-10-30 15:55:52: [2024-10-30 15:55:52] iter = 14730, loss = 6.8424
2024-10-30 15:55:53: [2024-10-30 15:55:53] iter = 14740, loss = 1.9023
2024-10-30 15:55:54: [2024-10-30 15:55:54] iter = 14750, loss = 1.9298
2024-10-30 15:55:55: [2024-10-30 15:55:55] iter = 14760, loss = 2.0775
2024-10-30 15:55:56: [2024-10-30 15:55:56] iter = 14770, loss = 1.7851
2024-10-30 15:55:56: [2024-10-30 15:55:56] iter = 14780, loss = 4.3254
2024-10-30 15:55:58: [2024-10-30 15:55:58] iter = 14790, loss = 1.7963
2024-10-30 15:55:59: [2024-10-30 15:55:59] iter = 14800, loss = 1.7911
2024-10-30 15:55:59: [2024-10-30 15:55:59] iter = 14810, loss = 2.3741
2024-10-30 15:56:00: [2024-10-30 15:56:00] iter = 14820, loss = 13.7287
2024-10-30 15:56:01: [2024-10-30 15:56:01] iter = 14830, loss = 4.8977
2024-10-30 15:56:02: [2024-10-30 15:56:02] iter = 14840, loss = 1.9895
2024-10-30 15:56:02: [2024-10-30 15:56:02] iter = 14850, loss = 2.5188
2024-10-30 15:56:03: [2024-10-30 15:56:03] iter = 14860, loss = 0.9318
2024-10-30 15:56:04: [2024-10-30 15:56:04] iter = 14870, loss = 13.4476
2024-10-30 15:56:05: [2024-10-30 15:56:05] iter = 14880, loss = 1.4604
2024-10-30 15:56:06: [2024-10-30 15:56:06] iter = 14890, loss = 1.7707
2024-10-30 15:56:07: [2024-10-30 15:56:07] iter = 14900, loss = 1.5792
2024-10-30 15:56:08: [2024-10-30 15:56:08] iter = 14910, loss = 8.6902
2024-10-30 15:56:09: [2024-10-30 15:56:09] iter = 14920, loss = 7.1776
2024-10-30 15:56:10: [2024-10-30 15:56:10] iter = 14930, loss = 2.4178
2024-10-30 15:56:11: [2024-10-30 15:56:11] iter = 14940, loss = 2.4269
2024-10-30 15:56:12: [2024-10-30 15:56:12] iter = 14950, loss = 1.7467
2024-10-30 15:56:14: [2024-10-30 15:56:14] iter = 14960, loss = 4.8189
2024-10-30 15:56:15: [2024-10-30 15:56:15] iter = 14970, loss = 2.1612
2024-10-30 15:56:16: [2024-10-30 15:56:16] iter = 14980, loss = 8.8593
2024-10-30 15:56:17: [2024-10-30 15:56:17] iter = 14990, loss = 2.9318
2024-10-30 15:56:18: [2024-10-30 15:56:18] iter = 15000, loss = 4.5186
2024-10-30 15:56:18: [2024-10-30 15:56:18] iter = 15010, loss = 4.0172
2024-10-30 15:56:19: [2024-10-30 15:56:19] iter = 15020, loss = 2.7447
2024-10-30 15:56:20: [2024-10-30 15:56:20] iter = 15030, loss = 17.5060
2024-10-30 15:56:21: [2024-10-30 15:56:21] iter = 15040, loss = 1.3665
2024-10-30 15:56:22: [2024-10-30 15:56:22] iter = 15050, loss = 1.3123
2024-10-30 15:56:23: [2024-10-30 15:56:23] iter = 15060, loss = 2.0619
2024-10-30 15:56:24: [2024-10-30 15:56:24] iter = 15070, loss = 19.9897
2024-10-30 15:56:25: [2024-10-30 15:56:25] iter = 15080, loss = 2.1446
2024-10-30 15:56:26: [2024-10-30 15:56:26] iter = 15090, loss = 2.0253
2024-10-30 15:56:27: [2024-10-30 15:56:27] iter = 15100, loss = 6.4481
2024-10-30 15:56:29: [2024-10-30 15:56:29] iter = 15110, loss = 1.7915
2024-10-30 15:56:29: [2024-10-30 15:56:29] iter = 15120, loss = 5.5973
2024-10-30 15:56:31: [2024-10-30 15:56:31] iter = 15130, loss = 8.1231
2024-10-30 15:56:32: [2024-10-30 15:56:32] iter = 15140, loss = 5.1580
2024-10-30 15:56:33: [2024-10-30 15:56:33] iter = 15150, loss = 41.5136
2024-10-30 15:56:34: [2024-10-30 15:56:34] iter = 15160, loss = 1.4399
2024-10-30 15:56:36: [2024-10-30 15:56:36] iter = 15170, loss = 1.9730
2024-10-30 15:56:37: [2024-10-30 15:56:37] iter = 15180, loss = 6.3867
2024-10-30 15:56:38: [2024-10-30 15:56:38] iter = 15190, loss = 5.0143
2024-10-30 15:56:39: [2024-10-30 15:56:39] iter = 15200, loss = 8.6675
2024-10-30 15:56:40: [2024-10-30 15:56:40] iter = 15210, loss = 1.7684
2024-10-30 15:56:41: [2024-10-30 15:56:41] iter = 15220, loss = 1.9901
2024-10-30 15:56:42: [2024-10-30 15:56:42] iter = 15230, loss = 3.0104
2024-10-30 15:56:43: [2024-10-30 15:56:43] iter = 15240, loss = 2.0972
2024-10-30 15:56:44: [2024-10-30 15:56:44] iter = 15250, loss = 3.0798
2024-10-30 15:56:45: [2024-10-30 15:56:45] iter = 15260, loss = 5.0171
2024-10-30 15:56:45: [2024-10-30 15:56:45] iter = 15270, loss = 1.8512
2024-10-30 15:56:45: [2024-10-30 15:56:45] iter = 15280, loss = 1.5584
2024-10-30 15:56:46: [2024-10-30 15:56:46] iter = 15290, loss = 2.2551
2024-10-30 15:56:47: [2024-10-30 15:56:47] iter = 15300, loss = 6.1921
2024-10-30 15:56:47: [2024-10-30 15:56:47] iter = 15310, loss = 2.1753
2024-10-30 15:56:48: [2024-10-30 15:56:48] iter = 15320, loss = 2.1949
2024-10-30 15:56:49: [2024-10-30 15:56:49] iter = 15330, loss = 2.9863
2024-10-30 15:56:50: [2024-10-30 15:56:50] iter = 15340, loss = 2.0143
2024-10-30 15:56:51: [2024-10-30 15:56:51] iter = 15350, loss = 4.3263
2024-10-30 15:56:52: [2024-10-30 15:56:52] iter = 15360, loss = 5.2359
2024-10-30 15:56:53: [2024-10-30 15:56:53] iter = 15370, loss = 5.2063
2024-10-30 15:56:54: [2024-10-30 15:56:54] iter = 15380, loss = 1.2162
2024-10-30 15:56:55: [2024-10-30 15:56:55] iter = 15390, loss = 1.2858
2024-10-30 15:56:56: [2024-10-30 15:56:56] iter = 15400, loss = 17.4785
2024-10-30 15:56:57: [2024-10-30 15:56:57] iter = 15410, loss = 3.0899
2024-10-30 15:56:58: [2024-10-30 15:56:58] iter = 15420, loss = 7.4840
2024-10-30 15:56:58: [2024-10-30 15:56:58] iter = 15430, loss = 6.5051
2024-10-30 15:56:59: [2024-10-30 15:56:59] iter = 15440, loss = 2.5834
2024-10-30 15:57:00: [2024-10-30 15:57:00] iter = 15450, loss = 3.2027
2024-10-30 15:57:01: [2024-10-30 15:57:01] iter = 15460, loss = 6.8279
2024-10-30 15:57:01: [2024-10-30 15:57:01] iter = 15470, loss = 6.4970
2024-10-30 15:57:02: [2024-10-30 15:57:02] iter = 15480, loss = 1.8072
2024-10-30 15:57:03: [2024-10-30 15:57:03] iter = 15490, loss = 1.2599
2024-10-30 15:57:04: [2024-10-30 15:57:04] iter = 15500, loss = 9.0312
2024-10-30 15:57:04: [2024-10-30 15:57:04] iter = 15510, loss = 5.8982
2024-10-30 15:57:05: [2024-10-30 15:57:05] iter = 15520, loss = 3.1750
2024-10-30 15:57:06: [2024-10-30 15:57:06] iter = 15530, loss = 2.0979
2024-10-30 15:57:07: [2024-10-30 15:57:07] iter = 15540, loss = 6.8919
2024-10-30 15:57:08: [2024-10-30 15:57:08] iter = 15550, loss = 2.7539
2024-10-30 15:57:09: [2024-10-30 15:57:09] iter = 15560, loss = 2.9486
2024-10-30 15:57:10: [2024-10-30 15:57:10] iter = 15570, loss = 10.0107
2024-10-30 15:57:11: [2024-10-30 15:57:11] iter = 15580, loss = 2.2984
2024-10-30 15:57:12: [2024-10-30 15:57:12] iter = 15590, loss = 5.3945
2024-10-30 15:57:13: [2024-10-30 15:57:13] iter = 15600, loss = 2.1546
2024-10-30 15:57:14: [2024-10-30 15:57:14] iter = 15610, loss = 5.3011
2024-10-30 15:57:15: [2024-10-30 15:57:15] iter = 15620, loss = 5.8463
2024-10-30 15:57:16: [2024-10-30 15:57:16] iter = 15630, loss = 2.0237
2024-10-30 15:57:17: [2024-10-30 15:57:17] iter = 15640, loss = 3.7734
2024-10-30 15:57:18: [2024-10-30 15:57:18] iter = 15650, loss = 14.9334
2024-10-30 15:57:19: [2024-10-30 15:57:19] iter = 15660, loss = 34.2116
2024-10-30 15:57:20: [2024-10-30 15:57:20] iter = 15670, loss = 2.9902
2024-10-30 15:57:21: [2024-10-30 15:57:21] iter = 15680, loss = 1.8676
2024-10-30 15:57:21: [2024-10-30 15:57:21] iter = 15690, loss = 1.4924
2024-10-30 15:57:22: [2024-10-30 15:57:22] iter = 15700, loss = 2.8123
2024-10-30 15:57:23: [2024-10-30 15:57:23] iter = 15710, loss = 1.1665
2024-10-30 15:57:24: [2024-10-30 15:57:24] iter = 15720, loss = 1.6570
2024-10-30 15:57:25: [2024-10-30 15:57:25] iter = 15730, loss = 3.1108
2024-10-30 15:57:25: [2024-10-30 15:57:25] iter = 15740, loss = 1.8944
2024-10-30 15:57:26: [2024-10-30 15:57:26] iter = 15750, loss = 2.1446
2024-10-30 15:57:27: [2024-10-30 15:57:27] iter = 15760, loss = 2.4517
2024-10-30 15:57:27: [2024-10-30 15:57:27] iter = 15770, loss = 4.4652
2024-10-30 15:57:28: [2024-10-30 15:57:28] iter = 15780, loss = 29.7515
2024-10-30 15:57:29: [2024-10-30 15:57:29] iter = 15790, loss = 2.0199
2024-10-30 15:57:30: [2024-10-30 15:57:30] iter = 15800, loss = 2.2641
2024-10-30 15:57:31: [2024-10-30 15:57:31] iter = 15810, loss = 9.3002
2024-10-30 15:57:32: [2024-10-30 15:57:32] iter = 15820, loss = 7.4388
2024-10-30 15:57:33: [2024-10-30 15:57:33] iter = 15830, loss = 1.4184
2024-10-30 15:57:34: [2024-10-30 15:57:34] iter = 15840, loss = 0.9123
2024-10-30 15:57:35: [2024-10-30 15:57:35] iter = 15850, loss = 1.9457
2024-10-30 15:57:36: [2024-10-30 15:57:36] iter = 15860, loss = 7.3355
2024-10-30 15:57:38: [2024-10-30 15:57:38] iter = 15870, loss = 20.3708
2024-10-30 15:57:39: [2024-10-30 15:57:39] iter = 15880, loss = 54.8646
2024-10-30 15:57:40: [2024-10-30 15:57:40] iter = 15890, loss = 2.5675
2024-10-30 15:57:40: [2024-10-30 15:57:40] iter = 15900, loss = 2.1090
2024-10-30 15:57:41: [2024-10-30 15:57:41] iter = 15910, loss = 7.0296
2024-10-30 15:57:42: [2024-10-30 15:57:42] iter = 15920, loss = 1.8142
2024-10-30 15:57:43: [2024-10-30 15:57:43] iter = 15930, loss = 1.4880
2024-10-30 15:57:44: [2024-10-30 15:57:44] iter = 15940, loss = 5.2446
2024-10-30 15:57:45: [2024-10-30 15:57:45] iter = 15950, loss = 6.4778
2024-10-30 15:57:46: [2024-10-30 15:57:46] iter = 15960, loss = 11.0044
2024-10-30 15:57:47: [2024-10-30 15:57:47] iter = 15970, loss = 1.1706
2024-10-30 15:57:48: [2024-10-30 15:57:48] iter = 15980, loss = 1.6079
2024-10-30 15:57:49: [2024-10-30 15:57:49] iter = 15990, loss = 50.6225
2024-10-30 15:57:49: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 15:57:49: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:57:49: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 69969}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:59:21: Evaluate 5 random ConvNet, ACCmean = 0.6782 ACCstd = 0.0204
-------------------------
2024-10-30 15:59:21: Evaluate 5 random ConvNet, SENmean = 0.7016 SENstd = 0.0121
-------------------------
2024-10-30 15:59:21: Evaluate 5 random ConvNet, SPEmean = 0.7016 SPEstd = 0.0121
-------------------------
2024-10-30 15:59:21: Evaluate 5 random ConvNet, F!mean = 0.6523 F!std = 0.0170
-------------------------
2024-10-30 15:59:21: Evaluate 5 random ConvNet, mean = 0.6782 std = 0.0204
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:59:21: [2024-10-30 15:59:21] iter = 16000, loss = 2.2633
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:59:22: [2024-10-30 15:59:22] iter = 16010, loss = 1.3503
2024-10-30 15:59:23: [2024-10-30 15:59:23] iter = 16020, loss = 12.3421
2024-10-30 15:59:24: [2024-10-30 15:59:24] iter = 16030, loss = 7.7846
2024-10-30 15:59:25: [2024-10-30 15:59:25] iter = 16040, loss = 23.6598
2024-10-30 15:59:26: [2024-10-30 15:59:26] iter = 16050, loss = 2.5719
2024-10-30 15:59:27: [2024-10-30 15:59:26] iter = 16060, loss = 1.5989
2024-10-30 15:59:27: [2024-10-30 15:59:27] iter = 16070, loss = 1.3607
2024-10-30 15:59:28: [2024-10-30 15:59:28] iter = 16080, loss = 2.7432
2024-10-30 15:59:29: [2024-10-30 15:59:29] iter = 16090, loss = 1.8849
2024-10-30 15:59:30: [2024-10-30 15:59:30] iter = 16100, loss = 2.8133
2024-10-30 15:59:31: [2024-10-30 15:59:31] iter = 16110, loss = 4.9474
2024-10-30 15:59:32: [2024-10-30 15:59:32] iter = 16120, loss = 4.6727
2024-10-30 15:59:33: [2024-10-30 15:59:33] iter = 16130, loss = 1.9575
2024-10-30 15:59:34: [2024-10-30 15:59:34] iter = 16140, loss = 2.2910
2024-10-30 15:59:35: [2024-10-30 15:59:35] iter = 16150, loss = 3.8780
2024-10-30 15:59:36: [2024-10-30 15:59:36] iter = 16160, loss = 3.3607
2024-10-30 15:59:37: [2024-10-30 15:59:37] iter = 16170, loss = 5.2070
2024-10-30 15:59:38: [2024-10-30 15:59:38] iter = 16180, loss = 18.4522
2024-10-30 15:59:39: [2024-10-30 15:59:39] iter = 16190, loss = 1.5601
2024-10-30 15:59:40: [2024-10-30 15:59:40] iter = 16200, loss = 2.0803
2024-10-30 15:59:41: [2024-10-30 15:59:41] iter = 16210, loss = 4.3884
2024-10-30 15:59:42: [2024-10-30 15:59:42] iter = 16220, loss = 1.7666
2024-10-30 15:59:42: [2024-10-30 15:59:42] iter = 16230, loss = 1.8812
2024-10-30 15:59:43: [2024-10-30 15:59:43] iter = 16240, loss = 1.3496
2024-10-30 15:59:44: [2024-10-30 15:59:44] iter = 16250, loss = 1.4655
2024-10-30 15:59:45: [2024-10-30 15:59:45] iter = 16260, loss = 1.0329
2024-10-30 15:59:46: [2024-10-30 15:59:46] iter = 16270, loss = 2.2240
2024-10-30 15:59:47: [2024-10-30 15:59:47] iter = 16280, loss = 3.2713
2024-10-30 15:59:48: [2024-10-30 15:59:48] iter = 16290, loss = 3.2131
2024-10-30 15:59:49: [2024-10-30 15:59:49] iter = 16300, loss = 1.7506
2024-10-30 15:59:50: [2024-10-30 15:59:50] iter = 16310, loss = 3.0465
2024-10-30 15:59:52: [2024-10-30 15:59:52] iter = 16320, loss = 4.4871
2024-10-30 15:59:52: [2024-10-30 15:59:52] iter = 16330, loss = 6.3683
2024-10-30 15:59:53: [2024-10-30 15:59:53] iter = 16340, loss = 2.3560
2024-10-30 15:59:54: [2024-10-30 15:59:54] iter = 16350, loss = 4.9758
2024-10-30 15:59:55: [2024-10-30 15:59:55] iter = 16360, loss = 1.8757
2024-10-30 15:59:56: [2024-10-30 15:59:56] iter = 16370, loss = 1.6017
2024-10-30 15:59:57: [2024-10-30 15:59:57] iter = 16380, loss = 3.9996
2024-10-30 15:59:57: [2024-10-30 15:59:57] iter = 16390, loss = 1.3480
2024-10-30 15:59:58: [2024-10-30 15:59:58] iter = 16400, loss = 7.8119
2024-10-30 15:59:59: [2024-10-30 15:59:59] iter = 16410, loss = 9.8647
2024-10-30 16:00:00: [2024-10-30 16:00:00] iter = 16420, loss = 13.7950
2024-10-30 16:00:01: [2024-10-30 16:00:01] iter = 16430, loss = 4.5532
2024-10-30 16:00:02: [2024-10-30 16:00:02] iter = 16440, loss = 3.0181
2024-10-30 16:00:03: [2024-10-30 16:00:03] iter = 16450, loss = 12.8414
2024-10-30 16:00:04: [2024-10-30 16:00:04] iter = 16460, loss = 3.1809
2024-10-30 16:00:04: [2024-10-30 16:00:04] iter = 16470, loss = 6.1945
2024-10-30 16:00:05: [2024-10-30 16:00:05] iter = 16480, loss = 10.8701
2024-10-30 16:00:06: [2024-10-30 16:00:06] iter = 16490, loss = 1.5973
2024-10-30 16:00:07: [2024-10-30 16:00:07] iter = 16500, loss = 3.2312
2024-10-30 16:00:08: [2024-10-30 16:00:08] iter = 16510, loss = 4.3798
2024-10-30 16:00:09: [2024-10-30 16:00:09] iter = 16520, loss = 1.3688
2024-10-30 16:00:10: [2024-10-30 16:00:10] iter = 16530, loss = 3.5292
2024-10-30 16:00:11: [2024-10-30 16:00:11] iter = 16540, loss = 4.9623
2024-10-30 16:00:12: [2024-10-30 16:00:12] iter = 16550, loss = 2.7127
2024-10-30 16:00:13: [2024-10-30 16:00:13] iter = 16560, loss = 1.7303
2024-10-30 16:00:13: [2024-10-30 16:00:13] iter = 16570, loss = 2.1265
2024-10-30 16:00:14: [2024-10-30 16:00:14] iter = 16580, loss = 1.3250
2024-10-30 16:00:15: [2024-10-30 16:00:15] iter = 16590, loss = 1.3756
2024-10-30 16:00:17: [2024-10-30 16:00:17] iter = 16600, loss = 13.2564
2024-10-30 16:00:17: [2024-10-30 16:00:17] iter = 16610, loss = 10.1831
2024-10-30 16:00:18: [2024-10-30 16:00:18] iter = 16620, loss = 2.3722
2024-10-30 16:00:19: [2024-10-30 16:00:19] iter = 16630, loss = 3.8563
2024-10-30 16:00:20: [2024-10-30 16:00:20] iter = 16640, loss = 2.8598
2024-10-30 16:00:21: [2024-10-30 16:00:21] iter = 16650, loss = 2.6565
2024-10-30 16:00:22: [2024-10-30 16:00:22] iter = 16660, loss = 1.7201
2024-10-30 16:00:22: [2024-10-30 16:00:22] iter = 16670, loss = 4.4036
2024-10-30 16:00:23: [2024-10-30 16:00:23] iter = 16680, loss = 3.8170
2024-10-30 16:00:24: [2024-10-30 16:00:24] iter = 16690, loss = 5.9117
2024-10-30 16:00:25: [2024-10-30 16:00:25] iter = 16700, loss = 6.9374
2024-10-30 16:00:25: [2024-10-30 16:00:25] iter = 16710, loss = 5.1865
2024-10-30 16:00:26: [2024-10-30 16:00:26] iter = 16720, loss = 1.4717
2024-10-30 16:00:28: [2024-10-30 16:00:28] iter = 16730, loss = 2.9032
2024-10-30 16:00:28: [2024-10-30 16:00:28] iter = 16740, loss = 1.7949
2024-10-30 16:00:29: [2024-10-30 16:00:29] iter = 16750, loss = 6.9715
2024-10-30 16:00:30: [2024-10-30 16:00:30] iter = 16760, loss = 11.9997
2024-10-30 16:00:31: [2024-10-30 16:00:31] iter = 16770, loss = 1.2136
2024-10-30 16:00:32: [2024-10-30 16:00:32] iter = 16780, loss = 3.1010
2024-10-30 16:00:33: [2024-10-30 16:00:33] iter = 16790, loss = 7.4212
2024-10-30 16:00:34: [2024-10-30 16:00:34] iter = 16800, loss = 3.1722
2024-10-30 16:00:35: [2024-10-30 16:00:35] iter = 16810, loss = 1.5184
2024-10-30 16:00:36: [2024-10-30 16:00:36] iter = 16820, loss = 2.2254
2024-10-30 16:00:37: [2024-10-30 16:00:37] iter = 16830, loss = 2.7991
2024-10-30 16:00:37: [2024-10-30 16:00:37] iter = 16840, loss = 5.6700
2024-10-30 16:00:38: [2024-10-30 16:00:38] iter = 16850, loss = 1.3266
2024-10-30 16:00:39: [2024-10-30 16:00:39] iter = 16860, loss = 1.6925
2024-10-30 16:00:40: [2024-10-30 16:00:40] iter = 16870, loss = 1.1552
2024-10-30 16:00:41: [2024-10-30 16:00:41] iter = 16880, loss = 9.3341
2024-10-30 16:00:42: [2024-10-30 16:00:42] iter = 16890, loss = 1.3217
2024-10-30 16:00:43: [2024-10-30 16:00:43] iter = 16900, loss = 2.8060
2024-10-30 16:00:44: [2024-10-30 16:00:44] iter = 16910, loss = 18.5251
2024-10-30 16:00:45: [2024-10-30 16:00:45] iter = 16920, loss = 3.5792
2024-10-30 16:00:46: [2024-10-30 16:00:46] iter = 16930, loss = 4.7530
2024-10-30 16:00:47: [2024-10-30 16:00:47] iter = 16940, loss = 4.2576
2024-10-30 16:00:47: [2024-10-30 16:00:47] iter = 16950, loss = 18.0674
2024-10-30 16:00:48: [2024-10-30 16:00:48] iter = 16960, loss = 1.8356
2024-10-30 16:00:49: [2024-10-30 16:00:49] iter = 16970, loss = 2.6112
2024-10-30 16:00:50: [2024-10-30 16:00:50] iter = 16980, loss = 8.1690
2024-10-30 16:00:52: [2024-10-30 16:00:52] iter = 16990, loss = 17.8085
2024-10-30 16:00:53: [2024-10-30 16:00:53] iter = 17000, loss = 4.2754
2024-10-30 16:00:54: [2024-10-30 16:00:54] iter = 17010, loss = 2.2035
2024-10-30 16:00:55: [2024-10-30 16:00:55] iter = 17020, loss = 14.5466
2024-10-30 16:00:56: [2024-10-30 16:00:56] iter = 17030, loss = 1.5682
2024-10-30 16:00:56: [2024-10-30 16:00:56] iter = 17040, loss = 10.8564
2024-10-30 16:00:57: [2024-10-30 16:00:57] iter = 17050, loss = 1.5823
2024-10-30 16:00:58: [2024-10-30 16:00:58] iter = 17060, loss = 3.2692
2024-10-30 16:00:59: [2024-10-30 16:00:59] iter = 17070, loss = 2.4139
2024-10-30 16:01:00: [2024-10-30 16:01:00] iter = 17080, loss = 1.1113
2024-10-30 16:01:01: [2024-10-30 16:01:01] iter = 17090, loss = 2.9567
2024-10-30 16:01:02: [2024-10-30 16:01:02] iter = 17100, loss = 1.2836
2024-10-30 16:01:03: [2024-10-30 16:01:03] iter = 17110, loss = 5.8885
2024-10-30 16:01:03: [2024-10-30 16:01:03] iter = 17120, loss = 4.3609
2024-10-30 16:01:04: [2024-10-30 16:01:04] iter = 17130, loss = 2.3162
2024-10-30 16:01:05: [2024-10-30 16:01:05] iter = 17140, loss = 7.9394
2024-10-30 16:01:06: [2024-10-30 16:01:06] iter = 17150, loss = 1.1560
2024-10-30 16:01:07: [2024-10-30 16:01:07] iter = 17160, loss = 2.1890
2024-10-30 16:01:08: [2024-10-30 16:01:08] iter = 17170, loss = 1.5809
2024-10-30 16:01:09: [2024-10-30 16:01:09] iter = 17180, loss = 4.9263
2024-10-30 16:01:10: [2024-10-30 16:01:10] iter = 17190, loss = 3.4671
2024-10-30 16:01:11: [2024-10-30 16:01:11] iter = 17200, loss = 3.0557
2024-10-30 16:01:12: [2024-10-30 16:01:12] iter = 17210, loss = 6.2621
2024-10-30 16:01:13: [2024-10-30 16:01:13] iter = 17220, loss = 2.1359
2024-10-30 16:01:14: [2024-10-30 16:01:14] iter = 17230, loss = 1.6478
2024-10-30 16:01:15: [2024-10-30 16:01:15] iter = 17240, loss = 7.4685
2024-10-30 16:01:16: [2024-10-30 16:01:16] iter = 17250, loss = 13.3845
2024-10-30 16:01:17: [2024-10-30 16:01:17] iter = 17260, loss = 2.3654
2024-10-30 16:01:18: [2024-10-30 16:01:18] iter = 17270, loss = 1.5018
2024-10-30 16:01:18: [2024-10-30 16:01:18] iter = 17280, loss = 1.2746
2024-10-30 16:01:19: [2024-10-30 16:01:19] iter = 17290, loss = 7.6761
2024-10-30 16:01:20: [2024-10-30 16:01:20] iter = 17300, loss = 2.0528
2024-10-30 16:01:21: [2024-10-30 16:01:21] iter = 17310, loss = 1.5620
2024-10-30 16:01:22: [2024-10-30 16:01:22] iter = 17320, loss = 1.1698
2024-10-30 16:01:24: [2024-10-30 16:01:24] iter = 17330, loss = 1.1580
2024-10-30 16:01:24: [2024-10-30 16:01:24] iter = 17340, loss = 0.8634
2024-10-30 16:01:25: [2024-10-30 16:01:25] iter = 17350, loss = 1.7428
2024-10-30 16:01:26: [2024-10-30 16:01:26] iter = 17360, loss = 3.4543
2024-10-30 16:01:27: [2024-10-30 16:01:27] iter = 17370, loss = 13.9830
2024-10-30 16:01:28: [2024-10-30 16:01:28] iter = 17380, loss = 4.3537
2024-10-30 16:01:28: [2024-10-30 16:01:28] iter = 17390, loss = 1.8713
2024-10-30 16:01:29: [2024-10-30 16:01:29] iter = 17400, loss = 2.4888
2024-10-30 16:01:30: [2024-10-30 16:01:30] iter = 17410, loss = 2.8502
2024-10-30 16:01:31: [2024-10-30 16:01:31] iter = 17420, loss = 2.1932
2024-10-30 16:01:32: [2024-10-30 16:01:32] iter = 17430, loss = 13.2095
2024-10-30 16:01:33: [2024-10-30 16:01:33] iter = 17440, loss = 11.0449
2024-10-30 16:01:34: [2024-10-30 16:01:34] iter = 17450, loss = 14.9530
2024-10-30 16:01:35: [2024-10-30 16:01:35] iter = 17460, loss = 3.9006
2024-10-30 16:01:36: [2024-10-30 16:01:36] iter = 17470, loss = 2.0172
2024-10-30 16:01:37: [2024-10-30 16:01:37] iter = 17480, loss = 1.1945
2024-10-30 16:01:38: [2024-10-30 16:01:38] iter = 17490, loss = 1.4522
2024-10-30 16:01:39: [2024-10-30 16:01:39] iter = 17500, loss = 2.4318
2024-10-30 16:01:41: [2024-10-30 16:01:40] iter = 17510, loss = 5.5254
2024-10-30 16:01:41: [2024-10-30 16:01:41] iter = 17520, loss = 1.4530
2024-10-30 16:01:43: [2024-10-30 16:01:43] iter = 17530, loss = 9.2653
2024-10-30 16:01:44: [2024-10-30 16:01:44] iter = 17540, loss = 2.8921
2024-10-30 16:01:45: [2024-10-30 16:01:45] iter = 17550, loss = 3.8513
2024-10-30 16:01:46: [2024-10-30 16:01:46] iter = 17560, loss = 1.8025
2024-10-30 16:01:47: [2024-10-30 16:01:47] iter = 17570, loss = 1.7254
2024-10-30 16:01:48: [2024-10-30 16:01:48] iter = 17580, loss = 7.4021
2024-10-30 16:01:49: [2024-10-30 16:01:49] iter = 17590, loss = 4.4182
2024-10-30 16:01:50: [2024-10-30 16:01:50] iter = 17600, loss = 4.3766
2024-10-30 16:01:51: [2024-10-30 16:01:51] iter = 17610, loss = 4.3947
2024-10-30 16:01:52: [2024-10-30 16:01:52] iter = 17620, loss = 3.6091
2024-10-30 16:01:53: [2024-10-30 16:01:53] iter = 17630, loss = 3.3992
2024-10-30 16:01:54: [2024-10-30 16:01:54] iter = 17640, loss = 8.1510
2024-10-30 16:01:55: [2024-10-30 16:01:55] iter = 17650, loss = 2.2985
2024-10-30 16:01:56: [2024-10-30 16:01:56] iter = 17660, loss = 1.6737
2024-10-30 16:01:57: [2024-10-30 16:01:57] iter = 17670, loss = 4.5044
2024-10-30 16:01:58: [2024-10-30 16:01:58] iter = 17680, loss = 1.1431
2024-10-30 16:01:59: [2024-10-30 16:01:59] iter = 17690, loss = 3.0470
2024-10-30 16:02:00: [2024-10-30 16:02:00] iter = 17700, loss = 1.4096
2024-10-30 16:02:01: [2024-10-30 16:02:01] iter = 17710, loss = 1.7559
2024-10-30 16:02:02: [2024-10-30 16:02:02] iter = 17720, loss = 1.3788
2024-10-30 16:02:03: [2024-10-30 16:02:03] iter = 17730, loss = 3.5196
2024-10-30 16:02:04: [2024-10-30 16:02:04] iter = 17740, loss = 2.1806
2024-10-30 16:02:06: [2024-10-30 16:02:06] iter = 17750, loss = 2.0653
2024-10-30 16:02:07: [2024-10-30 16:02:07] iter = 17760, loss = 1.9659
2024-10-30 16:02:07: [2024-10-30 16:02:07] iter = 17770, loss = 2.8408
2024-10-30 16:02:08: [2024-10-30 16:02:08] iter = 17780, loss = 2.6981
2024-10-30 16:02:09: [2024-10-30 16:02:09] iter = 17790, loss = 1.2684
2024-10-30 16:02:10: [2024-10-30 16:02:10] iter = 17800, loss = 1.1474
2024-10-30 16:02:11: [2024-10-30 16:02:11] iter = 17810, loss = 1.7252
2024-10-30 16:02:12: [2024-10-30 16:02:12] iter = 17820, loss = 1.7298
2024-10-30 16:02:12: [2024-10-30 16:02:12] iter = 17830, loss = 38.9549
2024-10-30 16:02:13: [2024-10-30 16:02:13] iter = 17840, loss = 2.3043
2024-10-30 16:02:15: [2024-10-30 16:02:15] iter = 17850, loss = 1.4625
2024-10-30 16:02:16: [2024-10-30 16:02:16] iter = 17860, loss = 0.8424
2024-10-30 16:02:17: [2024-10-30 16:02:17] iter = 17870, loss = 1.5721
2024-10-30 16:02:18: [2024-10-30 16:02:18] iter = 17880, loss = 6.2027
2024-10-30 16:02:19: [2024-10-30 16:02:19] iter = 17890, loss = 25.8058
2024-10-30 16:02:20: [2024-10-30 16:02:20] iter = 17900, loss = 4.2023
2024-10-30 16:02:21: [2024-10-30 16:02:21] iter = 17910, loss = 13.3418
2024-10-30 16:02:22: [2024-10-30 16:02:22] iter = 17920, loss = 7.5046
2024-10-30 16:02:22: [2024-10-30 16:02:22] iter = 17930, loss = 2.4576
2024-10-30 16:02:23: [2024-10-30 16:02:23] iter = 17940, loss = 1.6598
2024-10-30 16:02:24: [2024-10-30 16:02:24] iter = 17950, loss = 2.4312
2024-10-30 16:02:25: [2024-10-30 16:02:25] iter = 17960, loss = 2.7328
2024-10-30 16:02:26: [2024-10-30 16:02:26] iter = 17970, loss = 1.3234
2024-10-30 16:02:27: [2024-10-30 16:02:27] iter = 17980, loss = 2.0627
2024-10-30 16:02:28: [2024-10-30 16:02:28] iter = 17990, loss = 2.3602
2024-10-30 16:02:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 16:02:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:02:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49486}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:03:57: Evaluate 5 random ConvNet, ACCmean = 0.7705 ACCstd = 0.0188
-------------------------
2024-10-30 16:03:57: Evaluate 5 random ConvNet, SENmean = 0.6971 SENstd = 0.0117
-------------------------
2024-10-30 16:03:57: Evaluate 5 random ConvNet, SPEmean = 0.6971 SPEstd = 0.0117
-------------------------
2024-10-30 16:03:57: Evaluate 5 random ConvNet, F!mean = 0.7016 F!std = 0.0161
-------------------------
2024-10-30 16:03:57: Evaluate 5 random ConvNet, mean = 0.7705 std = 0.0188
-------------------------
2024-10-30 16:03:57: [2024-10-30 16:03:57] iter = 18000, loss = 4.8034
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:03:58: [2024-10-30 16:03:58] iter = 18010, loss = 2.6707
2024-10-30 16:03:59: [2024-10-30 16:03:59] iter = 18020, loss = 2.1871
2024-10-30 16:04:00: [2024-10-30 16:04:00] iter = 18030, loss = 2.3320
2024-10-30 16:04:01: [2024-10-30 16:04:01] iter = 18040, loss = 23.7543
2024-10-30 16:04:02: [2024-10-30 16:04:02] iter = 18050, loss = 1.7626
2024-10-30 16:04:02: [2024-10-30 16:04:02] iter = 18060, loss = 1.8502
2024-10-30 16:04:03: [2024-10-30 16:04:03] iter = 18070, loss = 5.1074
2024-10-30 16:04:04: [2024-10-30 16:04:04] iter = 18080, loss = 2.5403
2024-10-30 16:04:04: [2024-10-30 16:04:04] iter = 18090, loss = 2.6677
2024-10-30 16:04:05: [2024-10-30 16:04:05] iter = 18100, loss = 4.9477
2024-10-30 16:04:06: [2024-10-30 16:04:06] iter = 18110, loss = 5.6482
2024-10-30 16:04:07: [2024-10-30 16:04:07] iter = 18120, loss = 3.9248
2024-10-30 16:04:08: [2024-10-30 16:04:08] iter = 18130, loss = 64.9124
2024-10-30 16:04:09: [2024-10-30 16:04:09] iter = 18140, loss = 3.4999
2024-10-30 16:04:11: [2024-10-30 16:04:11] iter = 18150, loss = 2.0521
2024-10-30 16:04:12: [2024-10-30 16:04:12] iter = 18160, loss = 4.1830
2024-10-30 16:04:13: [2024-10-30 16:04:13] iter = 18170, loss = 3.5287
2024-10-30 16:04:14: [2024-10-30 16:04:14] iter = 18180, loss = 2.5566
2024-10-30 16:04:15: [2024-10-30 16:04:15] iter = 18190, loss = 1.5375
2024-10-30 16:04:16: [2024-10-30 16:04:16] iter = 18200, loss = 1.2947
2024-10-30 16:04:17: [2024-10-30 16:04:17] iter = 18210, loss = 2.0433
2024-10-30 16:04:18: [2024-10-30 16:04:18] iter = 18220, loss = 2.3489
2024-10-30 16:04:19: [2024-10-30 16:04:19] iter = 18230, loss = 3.3802
2024-10-30 16:04:19: [2024-10-30 16:04:19] iter = 18240, loss = 5.7284
2024-10-30 16:04:20: [2024-10-30 16:04:20] iter = 18250, loss = 1.7134
2024-10-30 16:04:21: [2024-10-30 16:04:21] iter = 18260, loss = 2.1533
2024-10-30 16:04:22: [2024-10-30 16:04:22] iter = 18270, loss = 1.7698
2024-10-30 16:04:23: [2024-10-30 16:04:23] iter = 18280, loss = 4.4842
2024-10-30 16:04:24: [2024-10-30 16:04:24] iter = 18290, loss = 1.3804
2024-10-30 16:04:25: [2024-10-30 16:04:25] iter = 18300, loss = 3.1209
2024-10-30 16:04:25: [2024-10-30 16:04:25] iter = 18310, loss = 1.5940
2024-10-30 16:04:26: [2024-10-30 16:04:26] iter = 18320, loss = 2.5347
2024-10-30 16:04:27: [2024-10-30 16:04:27] iter = 18330, loss = 1.3324
2024-10-30 16:04:29: [2024-10-30 16:04:29] iter = 18340, loss = 2.0712
2024-10-30 16:04:29: [2024-10-30 16:04:29] iter = 18350, loss = 1.1256
2024-10-30 16:04:30: [2024-10-30 16:04:30] iter = 18360, loss = 5.4560
2024-10-30 16:04:31: [2024-10-30 16:04:31] iter = 18370, loss = 3.5928
2024-10-30 16:04:32: [2024-10-30 16:04:32] iter = 18380, loss = 3.7869
2024-10-30 16:04:33: [2024-10-30 16:04:33] iter = 18390, loss = 2.3012
2024-10-30 16:04:34: [2024-10-30 16:04:34] iter = 18400, loss = 12.1380
2024-10-30 16:04:35: [2024-10-30 16:04:35] iter = 18410, loss = 2.1711
2024-10-30 16:04:36: [2024-10-30 16:04:36] iter = 18420, loss = 5.0393
2024-10-30 16:04:37: [2024-10-30 16:04:37] iter = 18430, loss = 4.2610
2024-10-30 16:04:38: [2024-10-30 16:04:38] iter = 18440, loss = 5.9984
2024-10-30 16:04:39: [2024-10-30 16:04:39] iter = 18450, loss = 1.3760
2024-10-30 16:04:40: [2024-10-30 16:04:40] iter = 18460, loss = 10.1384
2024-10-30 16:04:41: [2024-10-30 16:04:41] iter = 18470, loss = 2.1410
2024-10-30 16:04:42: [2024-10-30 16:04:42] iter = 18480, loss = 1.2945
2024-10-30 16:04:43: [2024-10-30 16:04:43] iter = 18490, loss = 1.4374
2024-10-30 16:04:43: [2024-10-30 16:04:43] iter = 18500, loss = 4.5580
2024-10-30 16:04:44: [2024-10-30 16:04:44] iter = 18510, loss = 3.3926
2024-10-30 16:04:45: [2024-10-30 16:04:45] iter = 18520, loss = 3.9330
2024-10-30 16:04:46: [2024-10-30 16:04:46] iter = 18530, loss = 2.4529
2024-10-30 16:04:47: [2024-10-30 16:04:47] iter = 18540, loss = 1.2606
2024-10-30 16:04:47: [2024-10-30 16:04:47] iter = 18550, loss = 6.2290
2024-10-30 16:04:48: [2024-10-30 16:04:48] iter = 18560, loss = 9.5672
2024-10-30 16:04:49: [2024-10-30 16:04:49] iter = 18570, loss = 4.7151
2024-10-30 16:04:50: [2024-10-30 16:04:50] iter = 18580, loss = 1.6527
2024-10-30 16:04:51: [2024-10-30 16:04:51] iter = 18590, loss = 7.8994
2024-10-30 16:04:52: [2024-10-30 16:04:52] iter = 18600, loss = 1.9414
2024-10-30 16:04:53: [2024-10-30 16:04:53] iter = 18610, loss = 23.7393
2024-10-30 16:04:54: [2024-10-30 16:04:54] iter = 18620, loss = 2.6914
2024-10-30 16:04:55: [2024-10-30 16:04:55] iter = 18630, loss = 3.2877
2024-10-30 16:04:55: [2024-10-30 16:04:55] iter = 18640, loss = 1.2968
2024-10-30 16:04:56: [2024-10-30 16:04:56] iter = 18650, loss = 3.1629
2024-10-30 16:04:57: [2024-10-30 16:04:57] iter = 18660, loss = 13.3560
2024-10-30 16:04:58: [2024-10-30 16:04:58] iter = 18670, loss = 1.7683
2024-10-30 16:04:59: [2024-10-30 16:04:59] iter = 18680, loss = 0.9964
2024-10-30 16:05:00: [2024-10-30 16:05:00] iter = 18690, loss = 2.2578
2024-10-30 16:05:01: [2024-10-30 16:05:01] iter = 18700, loss = 1.4398
2024-10-30 16:05:02: [2024-10-30 16:05:02] iter = 18710, loss = 3.1404
2024-10-30 16:05:03: [2024-10-30 16:05:03] iter = 18720, loss = 2.1110
2024-10-30 16:05:04: [2024-10-30 16:05:04] iter = 18730, loss = 18.0815
2024-10-30 16:05:04: [2024-10-30 16:05:04] iter = 18740, loss = 2.3513
2024-10-30 16:05:05: [2024-10-30 16:05:05] iter = 18750, loss = 3.9772
2024-10-30 16:05:06: [2024-10-30 16:05:06] iter = 18760, loss = 7.7126
2024-10-30 16:05:07: [2024-10-30 16:05:07] iter = 18770, loss = 1.2788
2024-10-30 16:05:07: [2024-10-30 16:05:07] iter = 18780, loss = 2.1379
2024-10-30 16:05:08: [2024-10-30 16:05:08] iter = 18790, loss = 9.8737
2024-10-30 16:05:10: [2024-10-30 16:05:10] iter = 18800, loss = 1.9067
2024-10-30 16:05:11: [2024-10-30 16:05:11] iter = 18810, loss = 3.7844
2024-10-30 16:05:11: [2024-10-30 16:05:11] iter = 18820, loss = 15.6658
2024-10-30 16:05:12: [2024-10-30 16:05:12] iter = 18830, loss = 2.7973
2024-10-30 16:05:12: [2024-10-30 16:05:12] iter = 18840, loss = 2.4808
2024-10-30 16:05:13: [2024-10-30 16:05:13] iter = 18850, loss = 2.7787
2024-10-30 16:05:14: [2024-10-30 16:05:14] iter = 18860, loss = 2.3653
2024-10-30 16:05:14: [2024-10-30 16:05:14] iter = 18870, loss = 1.5002
2024-10-30 16:05:15: [2024-10-30 16:05:15] iter = 18880, loss = 1.3840
2024-10-30 16:05:17: [2024-10-30 16:05:17] iter = 18890, loss = 2.8052
2024-10-30 16:05:18: [2024-10-30 16:05:18] iter = 18900, loss = 2.5111
2024-10-30 16:05:18: [2024-10-30 16:05:18] iter = 18910, loss = 2.3414
2024-10-30 16:05:19: [2024-10-30 16:05:19] iter = 18920, loss = 1.7184
2024-10-30 16:05:20: [2024-10-30 16:05:20] iter = 18930, loss = 6.7849
2024-10-30 16:05:21: [2024-10-30 16:05:21] iter = 18940, loss = 2.8869
2024-10-30 16:05:22: [2024-10-30 16:05:22] iter = 18950, loss = 1.4800
2024-10-30 16:05:23: [2024-10-30 16:05:23] iter = 18960, loss = 1.3011
2024-10-30 16:05:24: [2024-10-30 16:05:24] iter = 18970, loss = 1.7680
2024-10-30 16:05:25: [2024-10-30 16:05:25] iter = 18980, loss = 2.3757
2024-10-30 16:05:26: [2024-10-30 16:05:26] iter = 18990, loss = 1.8230
2024-10-30 16:05:27: [2024-10-30 16:05:27] iter = 19000, loss = 4.9293
2024-10-30 16:05:28: [2024-10-30 16:05:28] iter = 19010, loss = 1.2443
2024-10-30 16:05:29: [2024-10-30 16:05:29] iter = 19020, loss = 4.5691
2024-10-30 16:05:30: [2024-10-30 16:05:30] iter = 19030, loss = 2.6809
2024-10-30 16:05:30: [2024-10-30 16:05:30] iter = 19040, loss = 2.8950
2024-10-30 16:05:32: [2024-10-30 16:05:32] iter = 19050, loss = 2.4878
2024-10-30 16:05:33: [2024-10-30 16:05:33] iter = 19060, loss = 0.9697
2024-10-30 16:05:33: [2024-10-30 16:05:33] iter = 19070, loss = 1.8800
2024-10-30 16:05:34: [2024-10-30 16:05:34] iter = 19080, loss = 4.8055
2024-10-30 16:05:35: [2024-10-30 16:05:35] iter = 19090, loss = 1.0899
2024-10-30 16:05:36: [2024-10-30 16:05:36] iter = 19100, loss = 2.1786
2024-10-30 16:05:37: [2024-10-30 16:05:37] iter = 19110, loss = 18.2082
2024-10-30 16:05:38: [2024-10-30 16:05:38] iter = 19120, loss = 2.0829
2024-10-30 16:05:38: [2024-10-30 16:05:38] iter = 19130, loss = 1.3614
2024-10-30 16:05:39: [2024-10-30 16:05:39] iter = 19140, loss = 3.2190
2024-10-30 16:05:40: [2024-10-30 16:05:40] iter = 19150, loss = 39.9872
2024-10-30 16:05:41: [2024-10-30 16:05:41] iter = 19160, loss = 4.5724
2024-10-30 16:05:42: [2024-10-30 16:05:42] iter = 19170, loss = 3.1146
2024-10-30 16:05:43: [2024-10-30 16:05:43] iter = 19180, loss = 2.2404
2024-10-30 16:05:44: [2024-10-30 16:05:44] iter = 19190, loss = 1.0872
2024-10-30 16:05:45: [2024-10-30 16:05:45] iter = 19200, loss = 3.5670
2024-10-30 16:05:46: [2024-10-30 16:05:46] iter = 19210, loss = 1.8983
2024-10-30 16:05:47: [2024-10-30 16:05:47] iter = 19220, loss = 6.7526
2024-10-30 16:05:48: [2024-10-30 16:05:48] iter = 19230, loss = 4.2517
2024-10-30 16:05:49: [2024-10-30 16:05:49] iter = 19240, loss = 1.9954
2024-10-30 16:05:50: [2024-10-30 16:05:50] iter = 19250, loss = 1.3840
2024-10-30 16:05:51: [2024-10-30 16:05:51] iter = 19260, loss = 1.0583
2024-10-30 16:05:52: [2024-10-30 16:05:52] iter = 19270, loss = 10.0967
2024-10-30 16:05:53: [2024-10-30 16:05:53] iter = 19280, loss = 2.7305
2024-10-30 16:05:54: [2024-10-30 16:05:54] iter = 19290, loss = 5.8475
2024-10-30 16:05:54: [2024-10-30 16:05:54] iter = 19300, loss = 3.0026
2024-10-30 16:05:55: [2024-10-30 16:05:55] iter = 19310, loss = 5.4855
2024-10-30 16:05:56: [2024-10-30 16:05:56] iter = 19320, loss = 5.7067
2024-10-30 16:05:56: [2024-10-30 16:05:56] iter = 19330, loss = 1.3331
2024-10-30 16:05:57: [2024-10-30 16:05:57] iter = 19340, loss = 1.8531
2024-10-30 16:05:59: [2024-10-30 16:05:59] iter = 19350, loss = 2.8389
2024-10-30 16:05:59: [2024-10-30 16:05:59] iter = 19360, loss = 3.5583
2024-10-30 16:06:00: [2024-10-30 16:06:00] iter = 19370, loss = 13.6280
2024-10-30 16:06:01: [2024-10-30 16:06:01] iter = 19380, loss = 1.5306
2024-10-30 16:06:02: [2024-10-30 16:06:02] iter = 19390, loss = 25.5168
2024-10-30 16:06:03: [2024-10-30 16:06:03] iter = 19400, loss = 2.2414
2024-10-30 16:06:04: [2024-10-30 16:06:04] iter = 19410, loss = 2.3820
2024-10-30 16:06:05: [2024-10-30 16:06:05] iter = 19420, loss = 4.4580
2024-10-30 16:06:06: [2024-10-30 16:06:06] iter = 19430, loss = 1.8113
2024-10-30 16:06:07: [2024-10-30 16:06:07] iter = 19440, loss = 1.1281
2024-10-30 16:06:08: [2024-10-30 16:06:08] iter = 19450, loss = 3.8787
2024-10-30 16:06:09: [2024-10-30 16:06:09] iter = 19460, loss = 6.6473
2024-10-30 16:06:10: [2024-10-30 16:06:10] iter = 19470, loss = 2.1482
2024-10-30 16:06:11: [2024-10-30 16:06:11] iter = 19480, loss = 4.7401
2024-10-30 16:06:11: [2024-10-30 16:06:11] iter = 19490, loss = 2.1418
2024-10-30 16:06:12: [2024-10-30 16:06:12] iter = 19500, loss = 2.8500
2024-10-30 16:06:13: [2024-10-30 16:06:13] iter = 19510, loss = 3.9054
2024-10-30 16:06:14: [2024-10-30 16:06:14] iter = 19520, loss = 1.6310
2024-10-30 16:06:15: [2024-10-30 16:06:15] iter = 19530, loss = 1.1508
2024-10-30 16:06:16: [2024-10-30 16:06:16] iter = 19540, loss = 1.3957
2024-10-30 16:06:17: [2024-10-30 16:06:17] iter = 19550, loss = 1.1835
2024-10-30 16:06:18: [2024-10-30 16:06:18] iter = 19560, loss = 1.8661
2024-10-30 16:06:19: [2024-10-30 16:06:19] iter = 19570, loss = 1.8432
2024-10-30 16:06:20: [2024-10-30 16:06:20] iter = 19580, loss = 2.2288
2024-10-30 16:06:21: [2024-10-30 16:06:21] iter = 19590, loss = 1.4926
2024-10-30 16:06:21: [2024-10-30 16:06:21] iter = 19600, loss = 1.6621
2024-10-30 16:06:22: [2024-10-30 16:06:22] iter = 19610, loss = 1.8148
2024-10-30 16:06:23: [2024-10-30 16:06:23] iter = 19620, loss = 3.9590
2024-10-30 16:06:24: [2024-10-30 16:06:24] iter = 19630, loss = 1.5576
2024-10-30 16:06:26: [2024-10-30 16:06:25] iter = 19640, loss = 5.1707
2024-10-30 16:06:27: [2024-10-30 16:06:27] iter = 19650, loss = 1.4580
2024-10-30 16:06:28: [2024-10-30 16:06:28] iter = 19660, loss = 2.3509
2024-10-30 16:06:29: [2024-10-30 16:06:29] iter = 19670, loss = 4.2284
2024-10-30 16:06:30: [2024-10-30 16:06:30] iter = 19680, loss = 2.2834
2024-10-30 16:06:31: [2024-10-30 16:06:31] iter = 19690, loss = 1.3067
2024-10-30 16:06:32: [2024-10-30 16:06:32] iter = 19700, loss = 3.7557
2024-10-30 16:06:33: [2024-10-30 16:06:33] iter = 19710, loss = 2.9773
2024-10-30 16:06:35: [2024-10-30 16:06:35] iter = 19720, loss = 2.7011
2024-10-30 16:06:36: [2024-10-30 16:06:36] iter = 19730, loss = 2.6850
2024-10-30 16:06:36: [2024-10-30 16:06:36] iter = 19740, loss = 2.5500
2024-10-30 16:06:37: [2024-10-30 16:06:37] iter = 19750, loss = 5.7056
2024-10-30 16:06:38: [2024-10-30 16:06:38] iter = 19760, loss = 9.6850
2024-10-30 16:06:39: [2024-10-30 16:06:39] iter = 19770, loss = 1.6870
2024-10-30 16:06:40: [2024-10-30 16:06:40] iter = 19780, loss = 2.3775
2024-10-30 16:06:41: [2024-10-30 16:06:41] iter = 19790, loss = 1.4837
2024-10-30 16:06:43: [2024-10-30 16:06:43] iter = 19800, loss = 2.5491
2024-10-30 16:06:44: [2024-10-30 16:06:44] iter = 19810, loss = 1.5310
2024-10-30 16:06:44: [2024-10-30 16:06:44] iter = 19820, loss = 2.7831
2024-10-30 16:06:45: [2024-10-30 16:06:45] iter = 19830, loss = 7.3612
2024-10-30 16:06:46: [2024-10-30 16:06:46] iter = 19840, loss = 1.6816
2024-10-30 16:06:47: [2024-10-30 16:06:47] iter = 19850, loss = 5.0950
2024-10-30 16:06:48: [2024-10-30 16:06:48] iter = 19860, loss = 1.2630
2024-10-30 16:06:49: [2024-10-30 16:06:49] iter = 19870, loss = 3.3065
2024-10-30 16:06:50: [2024-10-30 16:06:50] iter = 19880, loss = 2.7073
2024-10-30 16:06:51: [2024-10-30 16:06:51] iter = 19890, loss = 1.4495
2024-10-30 16:06:52: [2024-10-30 16:06:52] iter = 19900, loss = 6.7610
2024-10-30 16:06:52: [2024-10-30 16:06:52] iter = 19910, loss = 4.6459
2024-10-30 16:06:53: [2024-10-30 16:06:53] iter = 19920, loss = 6.5073
2024-10-30 16:06:54: [2024-10-30 16:06:54] iter = 19930, loss = 2.2627
2024-10-30 16:06:55: [2024-10-30 16:06:55] iter = 19940, loss = 9.4999
2024-10-30 16:06:56: [2024-10-30 16:06:56] iter = 19950, loss = 13.5661
2024-10-30 16:06:57: [2024-10-30 16:06:57] iter = 19960, loss = 2.2185
2024-10-30 16:06:58: [2024-10-30 16:06:58] iter = 19970, loss = 7.8426
2024-10-30 16:06:59: [2024-10-30 16:06:59] iter = 19980, loss = 2.2086
2024-10-30 16:07:00: [2024-10-30 16:07:00] iter = 19990, loss = 1.7766
2024-10-30 16:07:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 16:07:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:07:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 21612}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:08:35: Evaluate 5 random ConvNet, ACCmean = 0.6885 ACCstd = 0.0249
-------------------------
2024-10-30 16:08:35: Evaluate 5 random ConvNet, SENmean = 0.7177 SENstd = 0.0207
-------------------------
2024-10-30 16:08:35: Evaluate 5 random ConvNet, SPEmean = 0.7177 SPEstd = 0.0207
-------------------------
2024-10-30 16:08:35: Evaluate 5 random ConvNet, F!mean = 0.6642 F!std = 0.0214
-------------------------
2024-10-30 16:08:35: Evaluate 5 random ConvNet, mean = 0.6885 std = 0.0249
-------------------------
2024-10-30 16:08:35: [2024-10-30 16:08:35] iter = 20000, loss = 2.0994
2024-10-30 16:08:35: 
================== Exp 3 ==================
 
2024-10-30 16:08:35: Hyper-parameters: 
{'dataset': 'BreastMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ff878e0ab20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_BreastMNIST (INFO)>}
2024-10-30 16:08:35: Evaluation model pool: ['ConvNet']
2024-10-30 16:08:35: class c = 0: 147 real images
2024-10-30 16:08:35: class c = 1: 399 real images
2024-10-30 16:08:35: real images channel 0, mean = 0.3276, std = 0.2057
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 16:08:35: initialize synthetic data from random real images
2024-10-30 16:08:35: [2024-10-30 16:08:35] training begins
2024-10-30 16:08:35: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 16:08:35: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:08:35: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 15726}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:10:16: Evaluate 5 random ConvNet, ACCmean = 0.6231 ACCstd = 0.0110
-------------------------
2024-10-30 16:10:16: Evaluate 5 random ConvNet, SENmean = 0.6414 SENstd = 0.0110
-------------------------
2024-10-30 16:10:16: Evaluate 5 random ConvNet, SPEmean = 0.6414 SPEstd = 0.0110
-------------------------
2024-10-30 16:10:16: Evaluate 5 random ConvNet, F!mean = 0.5965 F!std = 0.0099
-------------------------
2024-10-30 16:10:16: Evaluate 5 random ConvNet, mean = 0.6231 std = 0.0110
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:10:16: [2024-10-30 16:10:16] iter = 00000, loss = 19.2102
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:10:17: [2024-10-30 16:10:17] iter = 00010, loss = 9.9038
2024-10-30 16:10:18: [2024-10-30 16:10:18] iter = 00020, loss = 2.4807
2024-10-30 16:10:18: [2024-10-30 16:10:18] iter = 00030, loss = 11.2304
2024-10-30 16:10:19: [2024-10-30 16:10:19] iter = 00040, loss = 2.1922
2024-10-30 16:10:20: [2024-10-30 16:10:20] iter = 00050, loss = 2.6149
2024-10-30 16:10:21: [2024-10-30 16:10:21] iter = 00060, loss = 4.4865
2024-10-30 16:10:22: [2024-10-30 16:10:22] iter = 00070, loss = 1.4701
2024-10-30 16:10:23: [2024-10-30 16:10:23] iter = 00080, loss = 6.0989
2024-10-30 16:10:24: [2024-10-30 16:10:24] iter = 00090, loss = 1.5452
2024-10-30 16:10:24: [2024-10-30 16:10:24] iter = 00100, loss = 1.2442
2024-10-30 16:10:25: [2024-10-30 16:10:25] iter = 00110, loss = 2.6014
2024-10-30 16:10:26: [2024-10-30 16:10:26] iter = 00120, loss = 1.4161
2024-10-30 16:10:28: [2024-10-30 16:10:28] iter = 00130, loss = 2.8008
2024-10-30 16:10:29: [2024-10-30 16:10:29] iter = 00140, loss = 3.9561
2024-10-30 16:10:30: [2024-10-30 16:10:30] iter = 00150, loss = 4.1017
2024-10-30 16:10:30: [2024-10-30 16:10:30] iter = 00160, loss = 1.9073
2024-10-30 16:10:31: [2024-10-30 16:10:31] iter = 00170, loss = 6.3258
2024-10-30 16:10:32: [2024-10-30 16:10:32] iter = 00180, loss = 1.8041
2024-10-30 16:10:33: [2024-10-30 16:10:33] iter = 00190, loss = 3.0064
2024-10-30 16:10:34: [2024-10-30 16:10:34] iter = 00200, loss = 1.6863
2024-10-30 16:10:35: [2024-10-30 16:10:35] iter = 00210, loss = 4.0844
2024-10-30 16:10:36: [2024-10-30 16:10:36] iter = 00220, loss = 1.8177
2024-10-30 16:10:37: [2024-10-30 16:10:37] iter = 00230, loss = 1.4000
2024-10-30 16:10:38: [2024-10-30 16:10:38] iter = 00240, loss = 11.1629
2024-10-30 16:10:39: [2024-10-30 16:10:39] iter = 00250, loss = 1.3855
2024-10-30 16:10:40: [2024-10-30 16:10:40] iter = 00260, loss = 2.1614
2024-10-30 16:10:41: [2024-10-30 16:10:41] iter = 00270, loss = 14.2140
2024-10-30 16:10:41: [2024-10-30 16:10:41] iter = 00280, loss = 4.4083
2024-10-30 16:10:42: [2024-10-30 16:10:42] iter = 00290, loss = 2.5329
2024-10-30 16:10:43: [2024-10-30 16:10:43] iter = 00300, loss = 6.5715
2024-10-30 16:10:44: [2024-10-30 16:10:44] iter = 00310, loss = 3.4982
2024-10-30 16:10:45: [2024-10-30 16:10:45] iter = 00320, loss = 3.6293
2024-10-30 16:10:46: [2024-10-30 16:10:46] iter = 00330, loss = 5.5836
2024-10-30 16:10:47: [2024-10-30 16:10:47] iter = 00340, loss = 2.5825
2024-10-30 16:10:48: [2024-10-30 16:10:48] iter = 00350, loss = 8.2654
2024-10-30 16:10:48: [2024-10-30 16:10:48] iter = 00360, loss = 1.4462
2024-10-30 16:10:49: [2024-10-30 16:10:49] iter = 00370, loss = 1.8150
2024-10-30 16:10:50: [2024-10-30 16:10:50] iter = 00380, loss = 1.4565
2024-10-30 16:10:51: [2024-10-30 16:10:51] iter = 00390, loss = 1.5864
2024-10-30 16:10:51: [2024-10-30 16:10:51] iter = 00400, loss = 1.4146
2024-10-30 16:10:52: [2024-10-30 16:10:52] iter = 00410, loss = 4.3276
2024-10-30 16:10:52: [2024-10-30 16:10:52] iter = 00420, loss = 1.7490
2024-10-30 16:10:53: [2024-10-30 16:10:53] iter = 00430, loss = 5.7355
2024-10-30 16:10:54: [2024-10-30 16:10:54] iter = 00440, loss = 6.8091
2024-10-30 16:10:55: [2024-10-30 16:10:55] iter = 00450, loss = 1.5491
2024-10-30 16:10:56: [2024-10-30 16:10:56] iter = 00460, loss = 7.3190
2024-10-30 16:10:57: [2024-10-30 16:10:57] iter = 00470, loss = 2.5880
2024-10-30 16:10:58: [2024-10-30 16:10:58] iter = 00480, loss = 5.3605
2024-10-30 16:10:59: [2024-10-30 16:10:59] iter = 00490, loss = 14.7950
2024-10-30 16:11:00: [2024-10-30 16:11:00] iter = 00500, loss = 1.4955
2024-10-30 16:11:00: [2024-10-30 16:11:00] iter = 00510, loss = 2.0010
2024-10-30 16:11:01: [2024-10-30 16:11:01] iter = 00520, loss = 1.2619
2024-10-30 16:11:01: [2024-10-30 16:11:01] iter = 00530, loss = 1.4639
2024-10-30 16:11:02: [2024-10-30 16:11:02] iter = 00540, loss = 1.3643
2024-10-30 16:11:03: [2024-10-30 16:11:03] iter = 00550, loss = 1.2583
2024-10-30 16:11:03: [2024-10-30 16:11:03] iter = 00560, loss = 3.4746
2024-10-30 16:11:04: [2024-10-30 16:11:04] iter = 00570, loss = 4.2395
2024-10-30 16:11:05: [2024-10-30 16:11:05] iter = 00580, loss = 13.4832
2024-10-30 16:11:06: [2024-10-30 16:11:06] iter = 00590, loss = 2.9529
2024-10-30 16:11:07: [2024-10-30 16:11:07] iter = 00600, loss = 1.3850
2024-10-30 16:11:08: [2024-10-30 16:11:08] iter = 00610, loss = 1.4688
2024-10-30 16:11:09: [2024-10-30 16:11:09] iter = 00620, loss = 3.9684
2024-10-30 16:11:09: [2024-10-30 16:11:09] iter = 00630, loss = 1.9268
2024-10-30 16:11:11: [2024-10-30 16:11:11] iter = 00640, loss = 1.3520
2024-10-30 16:11:11: [2024-10-30 16:11:11] iter = 00650, loss = 9.1192
2024-10-30 16:11:12: [2024-10-30 16:11:12] iter = 00660, loss = 12.6339
2024-10-30 16:11:13: [2024-10-30 16:11:13] iter = 00670, loss = 1.7178
2024-10-30 16:11:14: [2024-10-30 16:11:14] iter = 00680, loss = 1.7505
2024-10-30 16:11:15: [2024-10-30 16:11:15] iter = 00690, loss = 1.4753
2024-10-30 16:11:16: [2024-10-30 16:11:16] iter = 00700, loss = 1.0749
2024-10-30 16:11:17: [2024-10-30 16:11:17] iter = 00710, loss = 1.4116
2024-10-30 16:11:18: [2024-10-30 16:11:18] iter = 00720, loss = 35.7345
2024-10-30 16:11:18: [2024-10-30 16:11:18] iter = 00730, loss = 1.6433
2024-10-30 16:11:19: [2024-10-30 16:11:19] iter = 00740, loss = 1.9645
2024-10-30 16:11:20: [2024-10-30 16:11:20] iter = 00750, loss = 1.1170
2024-10-30 16:11:21: [2024-10-30 16:11:21] iter = 00760, loss = 27.2983
2024-10-30 16:11:22: [2024-10-30 16:11:22] iter = 00770, loss = 2.4276
2024-10-30 16:11:23: [2024-10-30 16:11:23] iter = 00780, loss = 7.1696
2024-10-30 16:11:24: [2024-10-30 16:11:24] iter = 00790, loss = 2.3804
2024-10-30 16:11:25: [2024-10-30 16:11:25] iter = 00800, loss = 1.9850
2024-10-30 16:11:26: [2024-10-30 16:11:26] iter = 00810, loss = 1.3327
2024-10-30 16:11:27: [2024-10-30 16:11:27] iter = 00820, loss = 7.9550
2024-10-30 16:11:28: [2024-10-30 16:11:28] iter = 00830, loss = 5.8622
2024-10-30 16:11:29: [2024-10-30 16:11:29] iter = 00840, loss = 3.5900
2024-10-30 16:11:30: [2024-10-30 16:11:30] iter = 00850, loss = 1.3726
2024-10-30 16:11:30: [2024-10-30 16:11:30] iter = 00860, loss = 3.5229
2024-10-30 16:11:31: [2024-10-30 16:11:31] iter = 00870, loss = 3.4511
2024-10-30 16:11:32: [2024-10-30 16:11:32] iter = 00880, loss = 6.9876
2024-10-30 16:11:34: [2024-10-30 16:11:34] iter = 00890, loss = 3.5447
2024-10-30 16:11:35: [2024-10-30 16:11:35] iter = 00900, loss = 4.0704
2024-10-30 16:11:36: [2024-10-30 16:11:36] iter = 00910, loss = 1.9644
2024-10-30 16:11:37: [2024-10-30 16:11:37] iter = 00920, loss = 3.2881
2024-10-30 16:11:38: [2024-10-30 16:11:38] iter = 00930, loss = 4.4595
2024-10-30 16:11:38: [2024-10-30 16:11:38] iter = 00940, loss = 2.0558
2024-10-30 16:11:39: [2024-10-30 16:11:39] iter = 00950, loss = 2.3543
2024-10-30 16:11:40: [2024-10-30 16:11:40] iter = 00960, loss = 2.3758
2024-10-30 16:11:41: [2024-10-30 16:11:41] iter = 00970, loss = 26.6279
2024-10-30 16:11:43: [2024-10-30 16:11:43] iter = 00980, loss = 2.3890
2024-10-30 16:11:44: [2024-10-30 16:11:44] iter = 00990, loss = 1.2940
2024-10-30 16:11:45: [2024-10-30 16:11:45] iter = 01000, loss = 14.1646
2024-10-30 16:11:46: [2024-10-30 16:11:46] iter = 01010, loss = 3.5526
2024-10-30 16:11:47: [2024-10-30 16:11:47] iter = 01020, loss = 8.1707
2024-10-30 16:11:48: [2024-10-30 16:11:48] iter = 01030, loss = 1.9393
2024-10-30 16:11:49: [2024-10-30 16:11:49] iter = 01040, loss = 1.3201
2024-10-30 16:11:50: [2024-10-30 16:11:50] iter = 01050, loss = 4.4151
2024-10-30 16:11:51: [2024-10-30 16:11:51] iter = 01060, loss = 2.4234
2024-10-30 16:11:51: [2024-10-30 16:11:51] iter = 01070, loss = 1.4751
2024-10-30 16:11:53: [2024-10-30 16:11:52] iter = 01080, loss = 2.2174
2024-10-30 16:11:53: [2024-10-30 16:11:53] iter = 01090, loss = 5.9577
2024-10-30 16:11:54: [2024-10-30 16:11:54] iter = 01100, loss = 5.8390
2024-10-30 16:11:55: [2024-10-30 16:11:55] iter = 01110, loss = 5.3243
2024-10-30 16:11:56: [2024-10-30 16:11:56] iter = 01120, loss = 2.3973
2024-10-30 16:11:57: [2024-10-30 16:11:57] iter = 01130, loss = 1.4450
2024-10-30 16:11:58: [2024-10-30 16:11:58] iter = 01140, loss = 2.2643
2024-10-30 16:11:59: [2024-10-30 16:11:59] iter = 01150, loss = 1.5162
2024-10-30 16:12:00: [2024-10-30 16:12:00] iter = 01160, loss = 5.8078
2024-10-30 16:12:01: [2024-10-30 16:12:01] iter = 01170, loss = 1.9543
2024-10-30 16:12:03: [2024-10-30 16:12:03] iter = 01180, loss = 5.3837
2024-10-30 16:12:04: [2024-10-30 16:12:04] iter = 01190, loss = 3.1612
2024-10-30 16:12:05: [2024-10-30 16:12:05] iter = 01200, loss = 1.6227
2024-10-30 16:12:06: [2024-10-30 16:12:06] iter = 01210, loss = 2.6202
2024-10-30 16:12:07: [2024-10-30 16:12:07] iter = 01220, loss = 2.3471
2024-10-30 16:12:08: [2024-10-30 16:12:08] iter = 01230, loss = 1.1984
2024-10-30 16:12:08: [2024-10-30 16:12:08] iter = 01240, loss = 1.1738
2024-10-30 16:12:09: [2024-10-30 16:12:09] iter = 01250, loss = 4.1008
2024-10-30 16:12:10: [2024-10-30 16:12:10] iter = 01260, loss = 1.7312
2024-10-30 16:12:11: [2024-10-30 16:12:11] iter = 01270, loss = 2.3046
2024-10-30 16:12:12: [2024-10-30 16:12:12] iter = 01280, loss = 1.6056
2024-10-30 16:12:13: [2024-10-30 16:12:13] iter = 01290, loss = 3.8600
2024-10-30 16:12:14: [2024-10-30 16:12:14] iter = 01300, loss = 2.0634
2024-10-30 16:12:15: [2024-10-30 16:12:15] iter = 01310, loss = 1.3898
2024-10-30 16:12:16: [2024-10-30 16:12:16] iter = 01320, loss = 7.3435
2024-10-30 16:12:17: [2024-10-30 16:12:17] iter = 01330, loss = 2.5811
2024-10-30 16:12:18: [2024-10-30 16:12:18] iter = 01340, loss = 2.1641
2024-10-30 16:12:19: [2024-10-30 16:12:19] iter = 01350, loss = 3.8194
2024-10-30 16:12:20: [2024-10-30 16:12:20] iter = 01360, loss = 1.2860
2024-10-30 16:12:20: [2024-10-30 16:12:20] iter = 01370, loss = 7.4354
2024-10-30 16:12:21: [2024-10-30 16:12:21] iter = 01380, loss = 2.9785
2024-10-30 16:12:22: [2024-10-30 16:12:22] iter = 01390, loss = 1.6591
2024-10-30 16:12:23: [2024-10-30 16:12:23] iter = 01400, loss = 1.5280
2024-10-30 16:12:24: [2024-10-30 16:12:24] iter = 01410, loss = 1.2710
2024-10-30 16:12:25: [2024-10-30 16:12:25] iter = 01420, loss = 39.7188
2024-10-30 16:12:27: [2024-10-30 16:12:27] iter = 01430, loss = 8.9095
2024-10-30 16:12:27: [2024-10-30 16:12:27] iter = 01440, loss = 14.9546
2024-10-30 16:12:28: [2024-10-30 16:12:28] iter = 01450, loss = 11.8651
2024-10-30 16:12:29: [2024-10-30 16:12:29] iter = 01460, loss = 1.8477
2024-10-30 16:12:30: [2024-10-30 16:12:30] iter = 01470, loss = 3.8895
2024-10-30 16:12:31: [2024-10-30 16:12:31] iter = 01480, loss = 3.3535
2024-10-30 16:12:32: [2024-10-30 16:12:32] iter = 01490, loss = 3.1388
2024-10-30 16:12:34: [2024-10-30 16:12:34] iter = 01500, loss = 1.1911
2024-10-30 16:12:35: [2024-10-30 16:12:35] iter = 01510, loss = 1.3283
2024-10-30 16:12:36: [2024-10-30 16:12:36] iter = 01520, loss = 1.1644
2024-10-30 16:12:36: [2024-10-30 16:12:36] iter = 01530, loss = 8.5507
2024-10-30 16:12:37: [2024-10-30 16:12:37] iter = 01540, loss = 3.0013
2024-10-30 16:12:38: [2024-10-30 16:12:38] iter = 01550, loss = 7.1799
2024-10-30 16:12:39: [2024-10-30 16:12:39] iter = 01560, loss = 1.2939
2024-10-30 16:12:40: [2024-10-30 16:12:40] iter = 01570, loss = 1.3293
2024-10-30 16:12:41: [2024-10-30 16:12:41] iter = 01580, loss = 2.0888
2024-10-30 16:12:42: [2024-10-30 16:12:42] iter = 01590, loss = 1.3706
2024-10-30 16:12:43: [2024-10-30 16:12:43] iter = 01600, loss = 6.8483
2024-10-30 16:12:44: [2024-10-30 16:12:44] iter = 01610, loss = 1.9359
2024-10-30 16:12:45: [2024-10-30 16:12:45] iter = 01620, loss = 2.6717
2024-10-30 16:12:46: [2024-10-30 16:12:46] iter = 01630, loss = 1.6936
2024-10-30 16:12:47: [2024-10-30 16:12:47] iter = 01640, loss = 2.2825
2024-10-30 16:12:48: [2024-10-30 16:12:48] iter = 01650, loss = 33.5199
2024-10-30 16:12:49: [2024-10-30 16:12:49] iter = 01660, loss = 11.2684
2024-10-30 16:12:50: [2024-10-30 16:12:50] iter = 01670, loss = 1.6145
2024-10-30 16:12:50: [2024-10-30 16:12:50] iter = 01680, loss = 16.9984
2024-10-30 16:12:51: [2024-10-30 16:12:51] iter = 01690, loss = 6.4385
2024-10-30 16:12:52: [2024-10-30 16:12:52] iter = 01700, loss = 5.6098
2024-10-30 16:12:52: [2024-10-30 16:12:52] iter = 01710, loss = 9.4643
2024-10-30 16:12:53: [2024-10-30 16:12:53] iter = 01720, loss = 6.9059
2024-10-30 16:12:54: [2024-10-30 16:12:54] iter = 01730, loss = 1.7455
2024-10-30 16:12:55: [2024-10-30 16:12:55] iter = 01740, loss = 1.2341
2024-10-30 16:12:56: [2024-10-30 16:12:56] iter = 01750, loss = 2.7542
2024-10-30 16:12:56: [2024-10-30 16:12:56] iter = 01760, loss = 4.3604
2024-10-30 16:12:57: [2024-10-30 16:12:57] iter = 01770, loss = 1.9324
2024-10-30 16:12:58: [2024-10-30 16:12:58] iter = 01780, loss = 1.6210
2024-10-30 16:12:58: [2024-10-30 16:12:58] iter = 01790, loss = 3.9741
2024-10-30 16:12:59: [2024-10-30 16:12:59] iter = 01800, loss = 4.7198
2024-10-30 16:13:00: [2024-10-30 16:13:00] iter = 01810, loss = 15.3503
2024-10-30 16:13:01: [2024-10-30 16:13:01] iter = 01820, loss = 6.5071
2024-10-30 16:13:02: [2024-10-30 16:13:02] iter = 01830, loss = 2.2314
2024-10-30 16:13:03: [2024-10-30 16:13:03] iter = 01840, loss = 5.1595
2024-10-30 16:13:03: [2024-10-30 16:13:03] iter = 01850, loss = 4.0175
2024-10-30 16:13:04: [2024-10-30 16:13:04] iter = 01860, loss = 2.7435
2024-10-30 16:13:05: [2024-10-30 16:13:05] iter = 01870, loss = 2.2813
2024-10-30 16:13:05: [2024-10-30 16:13:05] iter = 01880, loss = 4.2338
2024-10-30 16:13:06: [2024-10-30 16:13:06] iter = 01890, loss = 3.3832
2024-10-30 16:13:07: [2024-10-30 16:13:07] iter = 01900, loss = 3.7917
2024-10-30 16:13:09: [2024-10-30 16:13:09] iter = 01910, loss = 3.8622
2024-10-30 16:13:09: [2024-10-30 16:13:09] iter = 01920, loss = 1.3061
2024-10-30 16:13:10: [2024-10-30 16:13:10] iter = 01930, loss = 3.6187
2024-10-30 16:13:11: [2024-10-30 16:13:11] iter = 01940, loss = 2.1446
2024-10-30 16:13:11: [2024-10-30 16:13:11] iter = 01950, loss = 2.2731
2024-10-30 16:13:12: [2024-10-30 16:13:12] iter = 01960, loss = 4.0461
2024-10-30 16:13:13: [2024-10-30 16:13:13] iter = 01970, loss = 1.4548
2024-10-30 16:13:14: [2024-10-30 16:13:14] iter = 01980, loss = 1.1496
2024-10-30 16:13:16: [2024-10-30 16:13:16] iter = 01990, loss = 3.2819
2024-10-30 16:13:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 16:13:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:13:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97033}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:14:49: Evaluate 5 random ConvNet, ACCmean = 0.7731 ACCstd = 0.0051
-------------------------
2024-10-30 16:14:49: Evaluate 5 random ConvNet, SENmean = 0.7470 SENstd = 0.0047
-------------------------
2024-10-30 16:14:49: Evaluate 5 random ConvNet, SPEmean = 0.7470 SPEstd = 0.0047
-------------------------
2024-10-30 16:14:49: Evaluate 5 random ConvNet, F!mean = 0.7295 F!std = 0.0044
-------------------------
2024-10-30 16:14:49: Evaluate 5 random ConvNet, mean = 0.7731 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:14:49: [2024-10-30 16:14:49] iter = 02000, loss = 1.4437
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:14:50: [2024-10-30 16:14:50] iter = 02010, loss = 10.7919
2024-10-30 16:14:51: [2024-10-30 16:14:51] iter = 02020, loss = 4.8348
2024-10-30 16:14:52: [2024-10-30 16:14:52] iter = 02030, loss = 1.6132
2024-10-30 16:14:53: [2024-10-30 16:14:53] iter = 02040, loss = 5.5895
2024-10-30 16:14:54: [2024-10-30 16:14:54] iter = 02050, loss = 2.0359
2024-10-30 16:14:55: [2024-10-30 16:14:55] iter = 02060, loss = 1.7643
2024-10-30 16:14:55: [2024-10-30 16:14:55] iter = 02070, loss = 0.9592
2024-10-30 16:14:56: [2024-10-30 16:14:56] iter = 02080, loss = 7.5850
2024-10-30 16:14:57: [2024-10-30 16:14:57] iter = 02090, loss = 5.8447
2024-10-30 16:14:58: [2024-10-30 16:14:58] iter = 02100, loss = 9.4096
2024-10-30 16:14:58: [2024-10-30 16:14:58] iter = 02110, loss = 3.5769
2024-10-30 16:14:59: [2024-10-30 16:14:59] iter = 02120, loss = 1.7802
2024-10-30 16:15:00: [2024-10-30 16:15:00] iter = 02130, loss = 2.7827
2024-10-30 16:15:01: [2024-10-30 16:15:01] iter = 02140, loss = 3.0023
2024-10-30 16:15:02: [2024-10-30 16:15:02] iter = 02150, loss = 6.2326
2024-10-30 16:15:03: [2024-10-30 16:15:03] iter = 02160, loss = 1.4686
2024-10-30 16:15:04: [2024-10-30 16:15:04] iter = 02170, loss = 11.5975
2024-10-30 16:15:04: [2024-10-30 16:15:04] iter = 02180, loss = 2.5412
2024-10-30 16:15:05: [2024-10-30 16:15:05] iter = 02190, loss = 8.5644
2024-10-30 16:15:06: [2024-10-30 16:15:06] iter = 02200, loss = 2.9400
2024-10-30 16:15:07: [2024-10-30 16:15:07] iter = 02210, loss = 1.5094
2024-10-30 16:15:08: [2024-10-30 16:15:08] iter = 02220, loss = 2.2380
2024-10-30 16:15:09: [2024-10-30 16:15:09] iter = 02230, loss = 1.7114
2024-10-30 16:15:10: [2024-10-30 16:15:10] iter = 02240, loss = 1.9635
2024-10-30 16:15:11: [2024-10-30 16:15:11] iter = 02250, loss = 4.0680
2024-10-30 16:15:12: [2024-10-30 16:15:12] iter = 02260, loss = 1.7600
2024-10-30 16:15:13: [2024-10-30 16:15:13] iter = 02270, loss = 1.7462
2024-10-30 16:15:14: [2024-10-30 16:15:14] iter = 02280, loss = 4.5162
2024-10-30 16:15:15: [2024-10-30 16:15:15] iter = 02290, loss = 1.5123
2024-10-30 16:15:16: [2024-10-30 16:15:16] iter = 02300, loss = 12.8400
2024-10-30 16:15:17: [2024-10-30 16:15:17] iter = 02310, loss = 5.6037
2024-10-30 16:15:19: [2024-10-30 16:15:19] iter = 02320, loss = 3.0305
2024-10-30 16:15:20: [2024-10-30 16:15:20] iter = 02330, loss = 2.9956
2024-10-30 16:15:21: [2024-10-30 16:15:21] iter = 02340, loss = 1.9038
2024-10-30 16:15:21: [2024-10-30 16:15:21] iter = 02350, loss = 2.0405
2024-10-30 16:15:23: [2024-10-30 16:15:23] iter = 02360, loss = 5.2021
2024-10-30 16:15:24: [2024-10-30 16:15:24] iter = 02370, loss = 4.5284
2024-10-30 16:15:25: [2024-10-30 16:15:25] iter = 02380, loss = 2.1101
2024-10-30 16:15:26: [2024-10-30 16:15:26] iter = 02390, loss = 5.6237
2024-10-30 16:15:27: [2024-10-30 16:15:27] iter = 02400, loss = 7.9090
2024-10-30 16:15:28: [2024-10-30 16:15:28] iter = 02410, loss = 11.6615
2024-10-30 16:15:29: [2024-10-30 16:15:29] iter = 02420, loss = 3.0046
2024-10-30 16:15:30: [2024-10-30 16:15:30] iter = 02430, loss = 1.4871
2024-10-30 16:15:31: [2024-10-30 16:15:31] iter = 02440, loss = 14.5664
2024-10-30 16:15:32: [2024-10-30 16:15:32] iter = 02450, loss = 1.9322
2024-10-30 16:15:33: [2024-10-30 16:15:33] iter = 02460, loss = 4.1326
2024-10-30 16:15:34: [2024-10-30 16:15:34] iter = 02470, loss = 2.4307
2024-10-30 16:15:35: [2024-10-30 16:15:35] iter = 02480, loss = 10.2372
2024-10-30 16:15:36: [2024-10-30 16:15:36] iter = 02490, loss = 4.1458
2024-10-30 16:15:37: [2024-10-30 16:15:37] iter = 02500, loss = 2.6651
2024-10-30 16:15:38: [2024-10-30 16:15:38] iter = 02510, loss = 35.5031
2024-10-30 16:15:38: [2024-10-30 16:15:38] iter = 02520, loss = 1.8844
2024-10-30 16:15:39: [2024-10-30 16:15:39] iter = 02530, loss = 3.0821
2024-10-30 16:15:40: [2024-10-30 16:15:40] iter = 02540, loss = 9.4400
2024-10-30 16:15:41: [2024-10-30 16:15:41] iter = 02550, loss = 1.3617
2024-10-30 16:15:41: [2024-10-30 16:15:41] iter = 02560, loss = 5.8675
2024-10-30 16:15:42: [2024-10-30 16:15:42] iter = 02570, loss = 3.9972
2024-10-30 16:15:43: [2024-10-30 16:15:43] iter = 02580, loss = 13.5913
2024-10-30 16:15:44: [2024-10-30 16:15:44] iter = 02590, loss = 3.3244
2024-10-30 16:15:45: [2024-10-30 16:15:45] iter = 02600, loss = 2.0210
2024-10-30 16:15:46: [2024-10-30 16:15:46] iter = 02610, loss = 4.0977
2024-10-30 16:15:47: [2024-10-30 16:15:47] iter = 02620, loss = 8.7172
2024-10-30 16:15:48: [2024-10-30 16:15:48] iter = 02630, loss = 33.6793
2024-10-30 16:15:49: [2024-10-30 16:15:49] iter = 02640, loss = 13.2898
2024-10-30 16:15:50: [2024-10-30 16:15:50] iter = 02650, loss = 1.6609
2024-10-30 16:15:51: [2024-10-30 16:15:51] iter = 02660, loss = 1.4137
2024-10-30 16:15:52: [2024-10-30 16:15:52] iter = 02670, loss = 14.4254
2024-10-30 16:15:53: [2024-10-30 16:15:53] iter = 02680, loss = 29.6991
2024-10-30 16:15:54: [2024-10-30 16:15:54] iter = 02690, loss = 5.3147
2024-10-30 16:15:56: [2024-10-30 16:15:56] iter = 02700, loss = 5.4909
2024-10-30 16:15:57: [2024-10-30 16:15:57] iter = 02710, loss = 1.6546
2024-10-30 16:15:58: [2024-10-30 16:15:58] iter = 02720, loss = 3.6497
2024-10-30 16:15:58: [2024-10-30 16:15:58] iter = 02730, loss = 1.6030
2024-10-30 16:15:59: [2024-10-30 16:15:59] iter = 02740, loss = 6.6040
2024-10-30 16:16:00: [2024-10-30 16:16:00] iter = 02750, loss = 2.3283
2024-10-30 16:16:01: [2024-10-30 16:16:01] iter = 02760, loss = 2.3790
2024-10-30 16:16:02: [2024-10-30 16:16:02] iter = 02770, loss = 3.4336
2024-10-30 16:16:03: [2024-10-30 16:16:03] iter = 02780, loss = 2.0744
2024-10-30 16:16:04: [2024-10-30 16:16:04] iter = 02790, loss = 5.6463
2024-10-30 16:16:05: [2024-10-30 16:16:05] iter = 02800, loss = 13.3710
2024-10-30 16:16:06: [2024-10-30 16:16:06] iter = 02810, loss = 2.1270
2024-10-30 16:16:07: [2024-10-30 16:16:07] iter = 02820, loss = 5.8050
2024-10-30 16:16:08: [2024-10-30 16:16:08] iter = 02830, loss = 4.6513
2024-10-30 16:16:08: [2024-10-30 16:16:08] iter = 02840, loss = 7.0950
2024-10-30 16:16:09: [2024-10-30 16:16:09] iter = 02850, loss = 12.6244
2024-10-30 16:16:11: [2024-10-30 16:16:11] iter = 02860, loss = 1.9440
2024-10-30 16:16:12: [2024-10-30 16:16:12] iter = 02870, loss = 3.0214
2024-10-30 16:16:12: [2024-10-30 16:16:12] iter = 02880, loss = 3.3961
2024-10-30 16:16:13: [2024-10-30 16:16:13] iter = 02890, loss = 3.1724
2024-10-30 16:16:14: [2024-10-30 16:16:14] iter = 02900, loss = 2.5123
2024-10-30 16:16:15: [2024-10-30 16:16:15] iter = 02910, loss = 5.4694
2024-10-30 16:16:16: [2024-10-30 16:16:16] iter = 02920, loss = 2.5204
2024-10-30 16:16:17: [2024-10-30 16:16:17] iter = 02930, loss = 4.5449
2024-10-30 16:16:18: [2024-10-30 16:16:18] iter = 02940, loss = 5.8277
2024-10-30 16:16:19: [2024-10-30 16:16:19] iter = 02950, loss = 45.8405
2024-10-30 16:16:20: [2024-10-30 16:16:20] iter = 02960, loss = 5.5682
2024-10-30 16:16:20: [2024-10-30 16:16:20] iter = 02970, loss = 2.5147
2024-10-30 16:16:21: [2024-10-30 16:16:21] iter = 02980, loss = 1.5448
2024-10-30 16:16:22: [2024-10-30 16:16:22] iter = 02990, loss = 14.4348
2024-10-30 16:16:23: [2024-10-30 16:16:23] iter = 03000, loss = 1.9462
2024-10-30 16:16:24: [2024-10-30 16:16:24] iter = 03010, loss = 1.5086
2024-10-30 16:16:25: [2024-10-30 16:16:25] iter = 03020, loss = 5.8324
2024-10-30 16:16:26: [2024-10-30 16:16:26] iter = 03030, loss = 2.2104
2024-10-30 16:16:27: [2024-10-30 16:16:27] iter = 03040, loss = 1.9441
2024-10-30 16:16:28: [2024-10-30 16:16:28] iter = 03050, loss = 1.5477
2024-10-30 16:16:28: [2024-10-30 16:16:28] iter = 03060, loss = 1.4926
2024-10-30 16:16:29: [2024-10-30 16:16:29] iter = 03070, loss = 3.6730
2024-10-30 16:16:30: [2024-10-30 16:16:30] iter = 03080, loss = 1.3722
2024-10-30 16:16:31: [2024-10-30 16:16:31] iter = 03090, loss = 3.5318
2024-10-30 16:16:33: [2024-10-30 16:16:33] iter = 03100, loss = 6.2923
2024-10-30 16:16:33: [2024-10-30 16:16:33] iter = 03110, loss = 8.1540
2024-10-30 16:16:34: [2024-10-30 16:16:34] iter = 03120, loss = 3.7007
2024-10-30 16:16:35: [2024-10-30 16:16:35] iter = 03130, loss = 2.1448
2024-10-30 16:16:37: [2024-10-30 16:16:37] iter = 03140, loss = 3.9393
2024-10-30 16:16:38: [2024-10-30 16:16:38] iter = 03150, loss = 1.3516
2024-10-30 16:16:38: [2024-10-30 16:16:38] iter = 03160, loss = 6.2730
2024-10-30 16:16:39: [2024-10-30 16:16:39] iter = 03170, loss = 2.1208
2024-10-30 16:16:41: [2024-10-30 16:16:41] iter = 03180, loss = 2.3430
2024-10-30 16:16:41: [2024-10-30 16:16:41] iter = 03190, loss = 4.6396
2024-10-30 16:16:42: [2024-10-30 16:16:42] iter = 03200, loss = 8.2177
2024-10-30 16:16:43: [2024-10-30 16:16:43] iter = 03210, loss = 2.8453
2024-10-30 16:16:44: [2024-10-30 16:16:44] iter = 03220, loss = 10.4900
2024-10-30 16:16:45: [2024-10-30 16:16:45] iter = 03230, loss = 4.0509
2024-10-30 16:16:46: [2024-10-30 16:16:46] iter = 03240, loss = 2.5889
2024-10-30 16:16:47: [2024-10-30 16:16:47] iter = 03250, loss = 44.3363
2024-10-30 16:16:48: [2024-10-30 16:16:48] iter = 03260, loss = 2.7458
2024-10-30 16:16:50: [2024-10-30 16:16:50] iter = 03270, loss = 2.0771
2024-10-30 16:16:51: [2024-10-30 16:16:51] iter = 03280, loss = 2.5073
2024-10-30 16:16:51: [2024-10-30 16:16:51] iter = 03290, loss = 1.4174
2024-10-30 16:16:52: [2024-10-30 16:16:52] iter = 03300, loss = 1.3984
2024-10-30 16:16:53: [2024-10-30 16:16:53] iter = 03310, loss = 2.8246
2024-10-30 16:16:54: [2024-10-30 16:16:54] iter = 03320, loss = 6.4855
2024-10-30 16:16:55: [2024-10-30 16:16:55] iter = 03330, loss = 1.9351
2024-10-30 16:16:56: [2024-10-30 16:16:56] iter = 03340, loss = 1.7098
2024-10-30 16:16:57: [2024-10-30 16:16:57] iter = 03350, loss = 1.5687
2024-10-30 16:16:59: [2024-10-30 16:16:59] iter = 03360, loss = 3.6886
2024-10-30 16:16:59: [2024-10-30 16:16:59] iter = 03370, loss = 2.1438
2024-10-30 16:17:00: [2024-10-30 16:17:00] iter = 03380, loss = 7.5235
2024-10-30 16:17:01: [2024-10-30 16:17:01] iter = 03390, loss = 2.1256
2024-10-30 16:17:02: [2024-10-30 16:17:02] iter = 03400, loss = 1.7019
2024-10-30 16:17:03: [2024-10-30 16:17:03] iter = 03410, loss = 12.6521
2024-10-30 16:17:04: [2024-10-30 16:17:04] iter = 03420, loss = 5.9380
2024-10-30 16:17:05: [2024-10-30 16:17:05] iter = 03430, loss = 9.6381
2024-10-30 16:17:06: [2024-10-30 16:17:06] iter = 03440, loss = 3.1211
2024-10-30 16:17:07: [2024-10-30 16:17:07] iter = 03450, loss = 1.6941
2024-10-30 16:17:08: [2024-10-30 16:17:08] iter = 03460, loss = 2.4552
2024-10-30 16:17:09: [2024-10-30 16:17:09] iter = 03470, loss = 1.7642
2024-10-30 16:17:10: [2024-10-30 16:17:10] iter = 03480, loss = 1.9863
2024-10-30 16:17:10: [2024-10-30 16:17:10] iter = 03490, loss = 5.6913
2024-10-30 16:17:11: [2024-10-30 16:17:11] iter = 03500, loss = 1.7365
2024-10-30 16:17:12: [2024-10-30 16:17:12] iter = 03510, loss = 14.4940
2024-10-30 16:17:13: [2024-10-30 16:17:13] iter = 03520, loss = 9.0292
2024-10-30 16:17:14: [2024-10-30 16:17:14] iter = 03530, loss = 3.9322
2024-10-30 16:17:15: [2024-10-30 16:17:15] iter = 03540, loss = 4.3972
2024-10-30 16:17:16: [2024-10-30 16:17:16] iter = 03550, loss = 3.6685
2024-10-30 16:17:17: [2024-10-30 16:17:17] iter = 03560, loss = 11.2150
2024-10-30 16:17:18: [2024-10-30 16:17:18] iter = 03570, loss = 2.1419
2024-10-30 16:17:19: [2024-10-30 16:17:19] iter = 03580, loss = 6.4285
2024-10-30 16:17:20: [2024-10-30 16:17:20] iter = 03590, loss = 1.3516
2024-10-30 16:17:21: [2024-10-30 16:17:21] iter = 03600, loss = 4.9530
2024-10-30 16:17:22: [2024-10-30 16:17:22] iter = 03610, loss = 3.5188
2024-10-30 16:17:23: [2024-10-30 16:17:23] iter = 03620, loss = 1.9181
2024-10-30 16:17:24: [2024-10-30 16:17:24] iter = 03630, loss = 1.6998
2024-10-30 16:17:24: [2024-10-30 16:17:24] iter = 03640, loss = 1.1684
2024-10-30 16:17:26: [2024-10-30 16:17:26] iter = 03650, loss = 2.5077
2024-10-30 16:17:27: [2024-10-30 16:17:27] iter = 03660, loss = 1.2516
2024-10-30 16:17:28: [2024-10-30 16:17:28] iter = 03670, loss = 3.2740
2024-10-30 16:17:29: [2024-10-30 16:17:29] iter = 03680, loss = 1.6131
2024-10-30 16:17:30: [2024-10-30 16:17:30] iter = 03690, loss = 3.1703
2024-10-30 16:17:31: [2024-10-30 16:17:31] iter = 03700, loss = 13.1029
2024-10-30 16:17:32: [2024-10-30 16:17:32] iter = 03710, loss = 6.1883
2024-10-30 16:17:33: [2024-10-30 16:17:33] iter = 03720, loss = 2.0686
2024-10-30 16:17:34: [2024-10-30 16:17:34] iter = 03730, loss = 1.9311
2024-10-30 16:17:35: [2024-10-30 16:17:35] iter = 03740, loss = 4.3622
2024-10-30 16:17:36: [2024-10-30 16:17:36] iter = 03750, loss = 4.6031
2024-10-30 16:17:38: [2024-10-30 16:17:38] iter = 03760, loss = 3.0239
2024-10-30 16:17:39: [2024-10-30 16:17:39] iter = 03770, loss = 8.3329
2024-10-30 16:17:40: [2024-10-30 16:17:40] iter = 03780, loss = 4.7447
2024-10-30 16:17:41: [2024-10-30 16:17:41] iter = 03790, loss = 12.0104
2024-10-30 16:17:42: [2024-10-30 16:17:42] iter = 03800, loss = 1.8863
2024-10-30 16:17:42: [2024-10-30 16:17:42] iter = 03810, loss = 8.4139
2024-10-30 16:17:44: [2024-10-30 16:17:44] iter = 03820, loss = 2.7107
2024-10-30 16:17:44: [2024-10-30 16:17:44] iter = 03830, loss = 1.5909
2024-10-30 16:17:45: [2024-10-30 16:17:45] iter = 03840, loss = 5.8294
2024-10-30 16:17:46: [2024-10-30 16:17:46] iter = 03850, loss = 7.5265
2024-10-30 16:17:47: [2024-10-30 16:17:47] iter = 03860, loss = 1.8329
2024-10-30 16:17:48: [2024-10-30 16:17:48] iter = 03870, loss = 1.4870
2024-10-30 16:17:49: [2024-10-30 16:17:49] iter = 03880, loss = 1.5144
2024-10-30 16:17:50: [2024-10-30 16:17:50] iter = 03890, loss = 0.9904
2024-10-30 16:17:51: [2024-10-30 16:17:51] iter = 03900, loss = 2.2417
2024-10-30 16:17:52: [2024-10-30 16:17:52] iter = 03910, loss = 1.8854
2024-10-30 16:17:53: [2024-10-30 16:17:53] iter = 03920, loss = 1.1765
2024-10-30 16:17:54: [2024-10-30 16:17:54] iter = 03930, loss = 4.6317
2024-10-30 16:17:55: [2024-10-30 16:17:55] iter = 03940, loss = 2.8588
2024-10-30 16:17:56: [2024-10-30 16:17:56] iter = 03950, loss = 1.5571
2024-10-30 16:17:57: [2024-10-30 16:17:57] iter = 03960, loss = 3.7774
2024-10-30 16:17:57: [2024-10-30 16:17:57] iter = 03970, loss = 11.5755
2024-10-30 16:17:59: [2024-10-30 16:17:59] iter = 03980, loss = 1.6279
2024-10-30 16:17:59: [2024-10-30 16:17:59] iter = 03990, loss = 4.8071
2024-10-30 16:18:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 16:18:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:18:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 80166}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:19:33: Evaluate 5 random ConvNet, ACCmean = 0.7269 ACCstd = 0.0132
-------------------------
2024-10-30 16:19:33: Evaluate 5 random ConvNet, SENmean = 0.5635 SENstd = 0.0193
-------------------------
2024-10-30 16:19:33: Evaluate 5 random ConvNet, SPEmean = 0.5635 SPEstd = 0.0193
-------------------------
2024-10-30 16:19:33: Evaluate 5 random ConvNet, F!mean = 0.5608 F!std = 0.0261
-------------------------
2024-10-30 16:19:33: Evaluate 5 random ConvNet, mean = 0.7269 std = 0.0132
-------------------------
2024-10-30 16:19:33: [2024-10-30 16:19:33] iter = 04000, loss = 4.1771
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:19:34: [2024-10-30 16:19:34] iter = 04010, loss = 5.4170
2024-10-30 16:19:35: [2024-10-30 16:19:35] iter = 04020, loss = 2.3993
2024-10-30 16:19:36: [2024-10-30 16:19:36] iter = 04030, loss = 2.0136
2024-10-30 16:19:37: [2024-10-30 16:19:37] iter = 04040, loss = 3.9170
2024-10-30 16:19:38: [2024-10-30 16:19:38] iter = 04050, loss = 1.4328
2024-10-30 16:19:39: [2024-10-30 16:19:39] iter = 04060, loss = 4.5337
2024-10-30 16:19:40: [2024-10-30 16:19:40] iter = 04070, loss = 20.0570
2024-10-30 16:19:41: [2024-10-30 16:19:41] iter = 04080, loss = 3.3611
2024-10-30 16:19:41: [2024-10-30 16:19:41] iter = 04090, loss = 10.5706
2024-10-30 16:19:43: [2024-10-30 16:19:43] iter = 04100, loss = 1.4222
2024-10-30 16:19:44: [2024-10-30 16:19:44] iter = 04110, loss = 1.5761
2024-10-30 16:19:45: [2024-10-30 16:19:45] iter = 04120, loss = 6.3224
2024-10-30 16:19:46: [2024-10-30 16:19:46] iter = 04130, loss = 2.8853
2024-10-30 16:19:47: [2024-10-30 16:19:47] iter = 04140, loss = 1.1553
2024-10-30 16:19:48: [2024-10-30 16:19:48] iter = 04150, loss = 1.2237
2024-10-30 16:19:49: [2024-10-30 16:19:49] iter = 04160, loss = 3.6225
2024-10-30 16:19:50: [2024-10-30 16:19:50] iter = 04170, loss = 2.7293
2024-10-30 16:19:51: [2024-10-30 16:19:51] iter = 04180, loss = 1.2641
2024-10-30 16:19:51: [2024-10-30 16:19:51] iter = 04190, loss = 2.1618
2024-10-30 16:19:52: [2024-10-30 16:19:52] iter = 04200, loss = 3.4645
2024-10-30 16:19:53: [2024-10-30 16:19:53] iter = 04210, loss = 4.5355
2024-10-30 16:19:53: [2024-10-30 16:19:53] iter = 04220, loss = 27.5333
2024-10-30 16:19:54: [2024-10-30 16:19:54] iter = 04230, loss = 2.1488
2024-10-30 16:19:55: [2024-10-30 16:19:55] iter = 04240, loss = 1.2704
2024-10-30 16:19:56: [2024-10-30 16:19:56] iter = 04250, loss = 2.4808
2024-10-30 16:19:57: [2024-10-30 16:19:57] iter = 04260, loss = 2.8609
2024-10-30 16:19:58: [2024-10-30 16:19:58] iter = 04270, loss = 1.8078
2024-10-30 16:19:58: [2024-10-30 16:19:58] iter = 04280, loss = 2.2861
2024-10-30 16:19:59: [2024-10-30 16:19:59] iter = 04290, loss = 2.9998
2024-10-30 16:20:00: [2024-10-30 16:20:00] iter = 04300, loss = 4.6081
2024-10-30 16:20:01: [2024-10-30 16:20:01] iter = 04310, loss = 4.6031
2024-10-30 16:20:02: [2024-10-30 16:20:02] iter = 04320, loss = 2.1924
2024-10-30 16:20:03: [2024-10-30 16:20:03] iter = 04330, loss = 1.3126
2024-10-30 16:20:04: [2024-10-30 16:20:04] iter = 04340, loss = 1.0617
2024-10-30 16:20:05: [2024-10-30 16:20:05] iter = 04350, loss = 12.5524
2024-10-30 16:20:06: [2024-10-30 16:20:06] iter = 04360, loss = 4.0015
2024-10-30 16:20:07: [2024-10-30 16:20:07] iter = 04370, loss = 1.2941
2024-10-30 16:20:08: [2024-10-30 16:20:08] iter = 04380, loss = 3.8077
2024-10-30 16:20:09: [2024-10-30 16:20:09] iter = 04390, loss = 1.3134
2024-10-30 16:20:09: [2024-10-30 16:20:09] iter = 04400, loss = 10.8819
2024-10-30 16:20:10: [2024-10-30 16:20:10] iter = 04410, loss = 2.2308
2024-10-30 16:20:11: [2024-10-30 16:20:11] iter = 04420, loss = 7.7664
2024-10-30 16:20:11: [2024-10-30 16:20:11] iter = 04430, loss = 9.4376
2024-10-30 16:20:12: [2024-10-30 16:20:12] iter = 04440, loss = 1.8849
2024-10-30 16:20:13: [2024-10-30 16:20:13] iter = 04450, loss = 22.1952
2024-10-30 16:20:14: [2024-10-30 16:20:14] iter = 04460, loss = 2.1860
2024-10-30 16:20:15: [2024-10-30 16:20:15] iter = 04470, loss = 2.3657
2024-10-30 16:20:15: [2024-10-30 16:20:15] iter = 04480, loss = 1.5941
2024-10-30 16:20:16: [2024-10-30 16:20:16] iter = 04490, loss = 1.8529
2024-10-30 16:20:17: [2024-10-30 16:20:17] iter = 04500, loss = 20.1343
2024-10-30 16:20:18: [2024-10-30 16:20:18] iter = 04510, loss = 2.8135
2024-10-30 16:20:19: [2024-10-30 16:20:19] iter = 04520, loss = 2.4856
2024-10-30 16:20:20: [2024-10-30 16:20:20] iter = 04530, loss = 2.9364
2024-10-30 16:20:21: [2024-10-30 16:20:21] iter = 04540, loss = 2.3103
2024-10-30 16:20:22: [2024-10-30 16:20:22] iter = 04550, loss = 1.3925
2024-10-30 16:20:23: [2024-10-30 16:20:23] iter = 04560, loss = 3.3543
2024-10-30 16:20:24: [2024-10-30 16:20:24] iter = 04570, loss = 1.1663
2024-10-30 16:20:24: [2024-10-30 16:20:24] iter = 04580, loss = 2.1549
2024-10-30 16:20:25: [2024-10-30 16:20:25] iter = 04590, loss = 1.6484
2024-10-30 16:20:25: [2024-10-30 16:20:25] iter = 04600, loss = 15.1983
2024-10-30 16:20:26: [2024-10-30 16:20:26] iter = 04610, loss = 2.3087
2024-10-30 16:20:27: [2024-10-30 16:20:27] iter = 04620, loss = 5.2791
2024-10-30 16:20:28: [2024-10-30 16:20:28] iter = 04630, loss = 7.2173
2024-10-30 16:20:29: [2024-10-30 16:20:29] iter = 04640, loss = 1.6826
2024-10-30 16:20:30: [2024-10-30 16:20:30] iter = 04650, loss = 2.0087
2024-10-30 16:20:31: [2024-10-30 16:20:31] iter = 04660, loss = 12.3172
2024-10-30 16:20:33: [2024-10-30 16:20:33] iter = 04670, loss = 1.9798
2024-10-30 16:20:34: [2024-10-30 16:20:34] iter = 04680, loss = 3.4995
2024-10-30 16:20:34: [2024-10-30 16:20:34] iter = 04690, loss = 3.1341
2024-10-30 16:20:35: [2024-10-30 16:20:35] iter = 04700, loss = 2.0468
2024-10-30 16:20:35: [2024-10-30 16:20:35] iter = 04710, loss = 1.3360
2024-10-30 16:20:36: [2024-10-30 16:20:36] iter = 04720, loss = 1.1127
2024-10-30 16:20:37: [2024-10-30 16:20:37] iter = 04730, loss = 3.6092
2024-10-30 16:20:38: [2024-10-30 16:20:38] iter = 04740, loss = 1.5670
2024-10-30 16:20:39: [2024-10-30 16:20:39] iter = 04750, loss = 1.1410
2024-10-30 16:20:40: [2024-10-30 16:20:40] iter = 04760, loss = 2.6711
2024-10-30 16:20:41: [2024-10-30 16:20:41] iter = 04770, loss = 1.6423
2024-10-30 16:20:41: [2024-10-30 16:20:41] iter = 04780, loss = 2.6757
2024-10-30 16:20:42: [2024-10-30 16:20:42] iter = 04790, loss = 2.0547
2024-10-30 16:20:44: [2024-10-30 16:20:44] iter = 04800, loss = 1.3333
2024-10-30 16:20:45: [2024-10-30 16:20:45] iter = 04810, loss = 1.1466
2024-10-30 16:20:46: [2024-10-30 16:20:46] iter = 04820, loss = 2.0174
2024-10-30 16:20:47: [2024-10-30 16:20:47] iter = 04830, loss = 2.7621
2024-10-30 16:20:48: [2024-10-30 16:20:48] iter = 04840, loss = 1.2478
2024-10-30 16:20:49: [2024-10-30 16:20:49] iter = 04850, loss = 4.6145
2024-10-30 16:20:50: [2024-10-30 16:20:50] iter = 04860, loss = 2.4564
2024-10-30 16:20:51: [2024-10-30 16:20:51] iter = 04870, loss = 1.4378
2024-10-30 16:20:52: [2024-10-30 16:20:52] iter = 04880, loss = 1.3142
2024-10-30 16:20:52: [2024-10-30 16:20:52] iter = 04890, loss = 16.2064
2024-10-30 16:20:53: [2024-10-30 16:20:53] iter = 04900, loss = 13.0284
2024-10-30 16:20:54: [2024-10-30 16:20:54] iter = 04910, loss = 2.3149
2024-10-30 16:20:55: [2024-10-30 16:20:55] iter = 04920, loss = 2.5537
2024-10-30 16:20:56: [2024-10-30 16:20:56] iter = 04930, loss = 1.9888
2024-10-30 16:20:57: [2024-10-30 16:20:57] iter = 04940, loss = 1.9213
2024-10-30 16:20:58: [2024-10-30 16:20:58] iter = 04950, loss = 13.1738
2024-10-30 16:20:59: [2024-10-30 16:20:59] iter = 04960, loss = 2.1084
2024-10-30 16:21:00: [2024-10-30 16:21:00] iter = 04970, loss = 27.1354
2024-10-30 16:21:01: [2024-10-30 16:21:01] iter = 04980, loss = 4.4244
2024-10-30 16:21:02: [2024-10-30 16:21:02] iter = 04990, loss = 4.2750
2024-10-30 16:21:02: [2024-10-30 16:21:02] iter = 05000, loss = 31.8372
2024-10-30 16:21:03: [2024-10-30 16:21:03] iter = 05010, loss = 2.5443
2024-10-30 16:21:04: [2024-10-30 16:21:04] iter = 05020, loss = 2.5067
2024-10-30 16:21:05: [2024-10-30 16:21:05] iter = 05030, loss = 3.6325
2024-10-30 16:21:06: [2024-10-30 16:21:06] iter = 05040, loss = 1.6806
2024-10-30 16:21:07: [2024-10-30 16:21:07] iter = 05050, loss = 1.1219
2024-10-30 16:21:08: [2024-10-30 16:21:08] iter = 05060, loss = 3.1786
2024-10-30 16:21:09: [2024-10-30 16:21:09] iter = 05070, loss = 3.7802
2024-10-30 16:21:11: [2024-10-30 16:21:11] iter = 05080, loss = 5.3532
2024-10-30 16:21:12: [2024-10-30 16:21:11] iter = 05090, loss = 2.6214
2024-10-30 16:21:12: [2024-10-30 16:21:12] iter = 05100, loss = 23.8702
2024-10-30 16:21:13: [2024-10-30 16:21:13] iter = 05110, loss = 2.6674
2024-10-30 16:21:14: [2024-10-30 16:21:14] iter = 05120, loss = 4.3785
2024-10-30 16:21:15: [2024-10-30 16:21:15] iter = 05130, loss = 1.2474
2024-10-30 16:21:16: [2024-10-30 16:21:16] iter = 05140, loss = 2.1196
2024-10-30 16:21:17: [2024-10-30 16:21:17] iter = 05150, loss = 6.5766
2024-10-30 16:21:18: [2024-10-30 16:21:18] iter = 05160, loss = 1.4154
2024-10-30 16:21:19: [2024-10-30 16:21:19] iter = 05170, loss = 5.8324
2024-10-30 16:21:20: [2024-10-30 16:21:20] iter = 05180, loss = 8.1319
2024-10-30 16:21:21: [2024-10-30 16:21:21] iter = 05190, loss = 1.8233
2024-10-30 16:21:21: [2024-10-30 16:21:21] iter = 05200, loss = 25.2617
2024-10-30 16:21:22: [2024-10-30 16:21:22] iter = 05210, loss = 6.4542
2024-10-30 16:21:22: [2024-10-30 16:21:22] iter = 05220, loss = 15.1724
2024-10-30 16:21:23: [2024-10-30 16:21:23] iter = 05230, loss = 3.4887
2024-10-30 16:21:24: [2024-10-30 16:21:24] iter = 05240, loss = 4.3210
2024-10-30 16:21:25: [2024-10-30 16:21:25] iter = 05250, loss = 15.7701
2024-10-30 16:21:26: [2024-10-30 16:21:26] iter = 05260, loss = 25.5112
2024-10-30 16:21:26: [2024-10-30 16:21:26] iter = 05270, loss = 2.2686
2024-10-30 16:21:27: [2024-10-30 16:21:27] iter = 05280, loss = 2.3022
2024-10-30 16:21:29: [2024-10-30 16:21:29] iter = 05290, loss = 19.5075
2024-10-30 16:21:29: [2024-10-30 16:21:29] iter = 05300, loss = 3.0247
2024-10-30 16:21:30: [2024-10-30 16:21:30] iter = 05310, loss = 2.0113
2024-10-30 16:21:31: [2024-10-30 16:21:31] iter = 05320, loss = 1.8105
2024-10-30 16:21:32: [2024-10-30 16:21:32] iter = 05330, loss = 1.7793
2024-10-30 16:21:33: [2024-10-30 16:21:33] iter = 05340, loss = 3.2877
2024-10-30 16:21:34: [2024-10-30 16:21:34] iter = 05350, loss = 2.9763
2024-10-30 16:21:35: [2024-10-30 16:21:35] iter = 05360, loss = 20.1618
2024-10-30 16:21:36: [2024-10-30 16:21:36] iter = 05370, loss = 3.5865
2024-10-30 16:21:37: [2024-10-30 16:21:37] iter = 05380, loss = 3.3230
2024-10-30 16:21:38: [2024-10-30 16:21:38] iter = 05390, loss = 1.3683
2024-10-30 16:21:39: [2024-10-30 16:21:39] iter = 05400, loss = 1.5332
2024-10-30 16:21:40: [2024-10-30 16:21:40] iter = 05410, loss = 2.4658
2024-10-30 16:21:41: [2024-10-30 16:21:41] iter = 05420, loss = 11.0867
2024-10-30 16:21:42: [2024-10-30 16:21:42] iter = 05430, loss = 1.3621
2024-10-30 16:21:43: [2024-10-30 16:21:43] iter = 05440, loss = 6.4938
2024-10-30 16:21:43: [2024-10-30 16:21:43] iter = 05450, loss = 2.2509
2024-10-30 16:21:45: [2024-10-30 16:21:45] iter = 05460, loss = 1.7510
2024-10-30 16:21:46: [2024-10-30 16:21:46] iter = 05470, loss = 1.3388
2024-10-30 16:21:47: [2024-10-30 16:21:47] iter = 05480, loss = 1.2555
2024-10-30 16:21:47: [2024-10-30 16:21:47] iter = 05490, loss = 2.6495
2024-10-30 16:21:48: [2024-10-30 16:21:48] iter = 05500, loss = 22.2956
2024-10-30 16:21:49: [2024-10-30 16:21:49] iter = 05510, loss = 8.0478
2024-10-30 16:21:50: [2024-10-30 16:21:50] iter = 05520, loss = 3.3767
2024-10-30 16:21:51: [2024-10-30 16:21:51] iter = 05530, loss = 1.7454
2024-10-30 16:21:52: [2024-10-30 16:21:52] iter = 05540, loss = 2.0906
2024-10-30 16:21:53: [2024-10-30 16:21:53] iter = 05550, loss = 1.3087
2024-10-30 16:21:54: [2024-10-30 16:21:54] iter = 05560, loss = 3.4194
2024-10-30 16:21:54: [2024-10-30 16:21:54] iter = 05570, loss = 2.9394
2024-10-30 16:21:55: [2024-10-30 16:21:55] iter = 05580, loss = 1.6133
2024-10-30 16:21:56: [2024-10-30 16:21:56] iter = 05590, loss = 2.1960
2024-10-30 16:21:57: [2024-10-30 16:21:57] iter = 05600, loss = 5.0400
2024-10-30 16:21:58: [2024-10-30 16:21:58] iter = 05610, loss = 1.2748
2024-10-30 16:21:59: [2024-10-30 16:21:59] iter = 05620, loss = 5.8344
2024-10-30 16:22:00: [2024-10-30 16:22:00] iter = 05630, loss = 1.2679
2024-10-30 16:22:01: [2024-10-30 16:22:01] iter = 05640, loss = 2.4020
2024-10-30 16:22:02: [2024-10-30 16:22:02] iter = 05650, loss = 2.7428
2024-10-30 16:22:03: [2024-10-30 16:22:03] iter = 05660, loss = 0.9255
2024-10-30 16:22:04: [2024-10-30 16:22:04] iter = 05670, loss = 6.6368
2024-10-30 16:22:05: [2024-10-30 16:22:05] iter = 05680, loss = 1.5249
2024-10-30 16:22:05: [2024-10-30 16:22:05] iter = 05690, loss = 1.9841
2024-10-30 16:22:06: [2024-10-30 16:22:06] iter = 05700, loss = 1.7773
2024-10-30 16:22:07: [2024-10-30 16:22:07] iter = 05710, loss = 1.7600
2024-10-30 16:22:08: [2024-10-30 16:22:08] iter = 05720, loss = 8.4784
2024-10-30 16:22:09: [2024-10-30 16:22:09] iter = 05730, loss = 6.6857
2024-10-30 16:22:10: [2024-10-30 16:22:10] iter = 05740, loss = 10.2115
2024-10-30 16:22:11: [2024-10-30 16:22:11] iter = 05750, loss = 1.3265
2024-10-30 16:22:12: [2024-10-30 16:22:12] iter = 05760, loss = 2.4714
2024-10-30 16:22:13: [2024-10-30 16:22:13] iter = 05770, loss = 1.7326
2024-10-30 16:22:14: [2024-10-30 16:22:14] iter = 05780, loss = 27.7291
2024-10-30 16:22:15: [2024-10-30 16:22:15] iter = 05790, loss = 1.4128
2024-10-30 16:22:16: [2024-10-30 16:22:16] iter = 05800, loss = 4.6063
2024-10-30 16:22:16: [2024-10-30 16:22:16] iter = 05810, loss = 2.1275
2024-10-30 16:22:17: [2024-10-30 16:22:17] iter = 05820, loss = 3.4406
2024-10-30 16:22:18: [2024-10-30 16:22:18] iter = 05830, loss = 1.7553
2024-10-30 16:22:19: [2024-10-30 16:22:19] iter = 05840, loss = 4.9694
2024-10-30 16:22:20: [2024-10-30 16:22:20] iter = 05850, loss = 8.9633
2024-10-30 16:22:21: [2024-10-30 16:22:21] iter = 05860, loss = 2.9360
2024-10-30 16:22:21: [2024-10-30 16:22:21] iter = 05870, loss = 8.5960
2024-10-30 16:22:22: [2024-10-30 16:22:22] iter = 05880, loss = 2.2351
2024-10-30 16:22:23: [2024-10-30 16:22:23] iter = 05890, loss = 1.3829
2024-10-30 16:22:24: [2024-10-30 16:22:24] iter = 05900, loss = 1.8999
2024-10-30 16:22:25: [2024-10-30 16:22:25] iter = 05910, loss = 7.3345
2024-10-30 16:22:26: [2024-10-30 16:22:26] iter = 05920, loss = 1.6886
2024-10-30 16:22:27: [2024-10-30 16:22:27] iter = 05930, loss = 3.1602
2024-10-30 16:22:28: [2024-10-30 16:22:28] iter = 05940, loss = 5.4041
2024-10-30 16:22:29: [2024-10-30 16:22:29] iter = 05950, loss = 1.9984
2024-10-30 16:22:30: [2024-10-30 16:22:30] iter = 05960, loss = 2.9690
2024-10-30 16:22:31: [2024-10-30 16:22:31] iter = 05970, loss = 1.3637
2024-10-30 16:22:32: [2024-10-30 16:22:32] iter = 05980, loss = 1.7223
2024-10-30 16:22:33: [2024-10-30 16:22:33] iter = 05990, loss = 3.2068
2024-10-30 16:22:34: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 16:22:34: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:22:34: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 54392}

[2024-10-30 15:45:08] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.000109 train acc = 1.0000, test acc = 0.6731, test_sen =0.7086, test_spe =0.7086, test_f1 =0.6513
[2024-10-30 15:45:31] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.003332 train acc = 1.0000, test acc = 0.6731, test_sen =0.7011, test_spe =0.7011, test_f1 =0.6488
[2024-10-30 15:48:52] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.000172 train acc = 1.0000, test acc = 0.6474, test_sen =0.6836, test_spe =0.6836, test_f1 =0.6264
[2024-10-30 15:49:13] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.000585 train acc = 1.0000, test acc = 0.7179, test_sen =0.7393, test_spe =0.7393, test_f1 =0.6911
[2024-10-30 15:49:33] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.001194 train acc = 1.0000, test acc = 0.7115, test_sen =0.7199, test_spe =0.7199, test_f1 =0.6800
[2024-10-30 15:49:53] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.002294 train acc = 1.0000, test acc = 0.6410, test_sen =0.6942, test_spe =0.6942, test_f1 =0.6253
[2024-10-30 15:50:13] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.002262 train acc = 1.0000, test acc = 0.7308, test_sen =0.7256, test_spe =0.7256, test_f1 =0.6941
[2024-10-30 15:53:26] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.000364 train acc = 1.0000, test acc = 0.7564, test_sen =0.7206, test_spe =0.7206, test_f1 =0.7071
[2024-10-30 15:53:44] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.005686 train acc = 1.0000, test acc = 0.7692, test_sen =0.7444, test_spe =0.7444, test_f1 =0.7259
[2024-10-30 15:54:04] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.035459 train acc = 1.0000, test acc = 0.7885, test_sen =0.7425, test_spe =0.7425, test_f1 =0.7370
[2024-10-30 15:54:25] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.003973 train acc = 1.0000, test acc = 0.7949, test_sen =0.7544, test_spe =0.7544, test_f1 =0.7468
[2024-10-30 15:54:44] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.061914 train acc = 0.9500, test acc = 0.7885, test_sen =0.7500, test_spe =0.7500, test_f1 =0.7406
[2024-10-30 15:58:09] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.000146 train acc = 1.0000, test acc = 0.7179, test_sen =0.7243, test_spe =0.7243, test_f1 =0.6857
[2024-10-30 15:58:25] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.000855 train acc = 1.0000, test acc = 0.6603, test_sen =0.6999, test_spe =0.6999, test_f1 =0.6400
[2024-10-30 15:58:43] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.000334 train acc = 1.0000, test acc = 0.6731, test_sen =0.6936, test_spe =0.6936, test_f1 =0.6462
[2024-10-30 15:59:02] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.000948 train acc = 1.0000, test acc = 0.6667, test_sen =0.6892, test_spe =0.6892, test_f1 =0.6406
[2024-10-30 15:59:21] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.001972 train acc = 1.0000, test acc = 0.6731, test_sen =0.7011, test_spe =0.7011, test_f1 =0.6488
[2024-10-30 16:02:46] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.000529 train acc = 1.0000, test acc = 0.7628, test_sen =0.6798, test_spe =0.6798, test_f1 =0.6864
[2024-10-30 16:03:04] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.003230 train acc = 1.0000, test acc = 0.7756, test_sen =0.7036, test_spe =0.7036, test_f1 =0.7082
[2024-10-30 16:03:20] Evaluate_02: epoch = 1000 train time = 15 s train loss = 0.001139 train acc = 1.0000, test acc = 0.7692, test_sen =0.6992, test_spe =0.6992, test_f1 =0.7022
[2024-10-30 16:03:38] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000667 train acc = 1.0000, test acc = 0.7436, test_sen =0.6892, test_spe =0.6892, test_f1 =0.6834
[2024-10-30 16:03:57] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.000095 train acc = 1.0000, test acc = 0.8013, test_sen =0.7137, test_spe =0.7137, test_f1 =0.7279
[2024-10-30 16:07:18] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000616 train acc = 1.0000, test acc = 0.6859, test_sen =0.7174, test_spe =0.7174, test_f1 =0.6626
[2024-10-30 16:07:36] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.000542 train acc = 1.0000, test acc = 0.6859, test_sen =0.7174, test_spe =0.7174, test_f1 =0.6626
[2024-10-30 16:07:56] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.000618 train acc = 1.0000, test acc = 0.6474, test_sen =0.6836, test_spe =0.6836, test_f1 =0.6264
[2024-10-30 16:08:17] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.000381 train acc = 1.0000, test acc = 0.7244, test_sen =0.7212, test_spe =0.7212, test_f1 =0.6884
[2024-10-30 16:08:35] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.001438 train acc = 1.0000, test acc = 0.6987, test_sen =0.7487, test_spe =0.7487, test_f1 =0.6808
[2024-10-30 16:08:56] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.005741 train acc = 1.0000, test acc = 0.6154, test_sen =0.6466, test_spe =0.6466, test_f1 =0.5938
[2024-10-30 16:09:16] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.001683 train acc = 1.0000, test acc = 0.6282, test_sen =0.6479, test_spe =0.6479, test_f1 =0.6020
[2024-10-30 16:09:35] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.008466 train acc = 1.0000, test acc = 0.6090, test_sen =0.6197, test_spe =0.6197, test_f1 =0.5800
[2024-10-30 16:09:56] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.032468 train acc = 1.0000, test acc = 0.6410, test_sen =0.6491, test_spe =0.6491, test_f1 =0.6100
[2024-10-30 16:10:16] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.010566 train acc = 1.0000, test acc = 0.6218, test_sen =0.6435, test_spe =0.6435, test_f1 =0.5966
[2024-10-30 16:13:37] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.004124 train acc = 1.0000, test acc = 0.7692, test_sen =0.7444, test_spe =0.7444, test_f1 =0.7259
[2024-10-30 16:13:59] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.000263 train acc = 1.0000, test acc = 0.7692, test_sen =0.7519, test_spe =0.7519, test_f1 =0.7292
[2024-10-30 16:14:15] Evaluate_02: epoch = 1000 train time = 16 s train loss = 0.012628 train acc = 1.0000, test acc = 0.7756, test_sen =0.7412, test_spe =0.7412, test_f1 =0.7285
[2024-10-30 16:14:33] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000145 train acc = 1.0000, test acc = 0.7692, test_sen =0.7444, test_spe =0.7444, test_f1 =0.7259
[2024-10-30 16:14:49] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.030179 train acc = 1.0000, test acc = 0.7821, test_sen =0.7531, test_spe =0.7531, test_f1 =0.7379
[2024-10-30 16:18:18] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.001333 train acc = 1.0000, test acc = 0.7115, test_sen =0.5620, test_spe =0.5620, test_f1 =0.5628
[2024-10-30 16:18:38] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.000605 train acc = 1.0000, test acc = 0.7436, test_sen =0.5915, test_spe =0.5915, test_f1 =0.5974
[2024-10-30 16:18:57] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000047 train acc = 1.0000, test acc = 0.7372, test_sen =0.5721, test_spe =0.5721, test_f1 =0.5715
[2024-10-30 16:19:14] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000242 train acc = 1.0000, test acc = 0.7115, test_sen =0.5320, test_spe =0.5320, test_f1 =0.5170
[2024-10-30 16:19:33] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.000055 train acc = 1.0000, test acc = 0.7308, test_sen =0.5602, test_spe =0.5602, test_f1 =0.5553
[2024-10-30 16:22:52] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000115 train acc = 1.0000, test acc = 0.7756, test_sen =0.6510, test_spe =0.6510, test_f1 =0.6674
[2024-10-30 16:23:09] Evaluate_01: epoch = 1000 train time = 15 s train loss = 0.006917 train acc = 1.0000, test acc = 0.8013, test_sen =0.6535, test_spe =0.6535, test_f1 =0.6760
[2024-10-30 16:23:24] Evaluate_02: epoch = 1000 train time = 15 s train loss = 0.000108 train acc = 1.0000, test acc = 0.7821, test_sen =0.6253, test_spe =0.6253, test_f1 =0.6400
[2024-10-30 16:23:43] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000508 train acc = 1.0000, test acc = 0.8077, test_sen =0.6805, test_spe =0.6805, test_f1 =0.7051/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:24:02: Evaluate 5 random ConvNet, ACCmean = 0.7910 ACCstd = 0.0119
-------------------------
2024-10-30 16:24:02: Evaluate 5 random ConvNet, SENmean = 0.6480 SENstd = 0.0197
-------------------------
2024-10-30 16:24:02: Evaluate 5 random ConvNet, SPEmean = 0.6480 SPEstd = 0.0197
-------------------------
2024-10-30 16:24:02: Evaluate 5 random ConvNet, F!mean = 0.6669 F!std = 0.0233
-------------------------
2024-10-30 16:24:02: Evaluate 5 random ConvNet, mean = 0.7910 std = 0.0119
-------------------------
2024-10-30 16:24:02: [2024-10-30 16:24:02] iter = 06000, loss = 1.9427
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:24:03: [2024-10-30 16:24:03] iter = 06010, loss = 2.4049
2024-10-30 16:24:04: [2024-10-30 16:24:04] iter = 06020, loss = 12.9969
2024-10-30 16:24:05: [2024-10-30 16:24:05] iter = 06030, loss = 2.1736
2024-10-30 16:24:06: [2024-10-30 16:24:06] iter = 06040, loss = 1.3805
2024-10-30 16:24:07: [2024-10-30 16:24:07] iter = 06050, loss = 1.9028
2024-10-30 16:24:08: [2024-10-30 16:24:08] iter = 06060, loss = 8.9210
2024-10-30 16:24:09: [2024-10-30 16:24:09] iter = 06070, loss = 3.9085
2024-10-30 16:24:09: [2024-10-30 16:24:09] iter = 06080, loss = 9.7929
2024-10-30 16:24:10: [2024-10-30 16:24:10] iter = 06090, loss = 2.4393
2024-10-30 16:24:11: [2024-10-30 16:24:11] iter = 06100, loss = 1.4154
2024-10-30 16:24:12: [2024-10-30 16:24:12] iter = 06110, loss = 7.3170
2024-10-30 16:24:13: [2024-10-30 16:24:13] iter = 06120, loss = 2.2209
2024-10-30 16:24:14: [2024-10-30 16:24:14] iter = 06130, loss = 3.1705
2024-10-30 16:24:15: [2024-10-30 16:24:15] iter = 06140, loss = 1.2854
2024-10-30 16:24:16: [2024-10-30 16:24:16] iter = 06150, loss = 26.0763
2024-10-30 16:24:17: [2024-10-30 16:24:17] iter = 06160, loss = 3.8568
2024-10-30 16:24:18: [2024-10-30 16:24:18] iter = 06170, loss = 7.0677
2024-10-30 16:24:18: [2024-10-30 16:24:18] iter = 06180, loss = 1.7339
2024-10-30 16:24:20: [2024-10-30 16:24:20] iter = 06190, loss = 12.8035
2024-10-30 16:24:21: [2024-10-30 16:24:21] iter = 06200, loss = 1.8545
2024-10-30 16:24:21: [2024-10-30 16:24:21] iter = 06210, loss = 15.5022
2024-10-30 16:24:22: [2024-10-30 16:24:22] iter = 06220, loss = 4.6802
2024-10-30 16:24:23: [2024-10-30 16:24:23] iter = 06230, loss = 3.5907
2024-10-30 16:24:24: [2024-10-30 16:24:24] iter = 06240, loss = 9.1352
2024-10-30 16:24:25: [2024-10-30 16:24:25] iter = 06250, loss = 4.2653
2024-10-30 16:24:26: [2024-10-30 16:24:26] iter = 06260, loss = 6.7841
2024-10-30 16:24:27: [2024-10-30 16:24:27] iter = 06270, loss = 2.4642
2024-10-30 16:24:28: [2024-10-30 16:24:28] iter = 06280, loss = 12.0206
2024-10-30 16:24:29: [2024-10-30 16:24:29] iter = 06290, loss = 1.9519
2024-10-30 16:24:30: [2024-10-30 16:24:30] iter = 06300, loss = 3.5860
2024-10-30 16:24:31: [2024-10-30 16:24:31] iter = 06310, loss = 4.0195
2024-10-30 16:24:32: [2024-10-30 16:24:32] iter = 06320, loss = 5.2455
2024-10-30 16:24:33: [2024-10-30 16:24:33] iter = 06330, loss = 2.0027
2024-10-30 16:24:34: [2024-10-30 16:24:34] iter = 06340, loss = 1.3718
2024-10-30 16:24:35: [2024-10-30 16:24:35] iter = 06350, loss = 3.8869
2024-10-30 16:24:35: [2024-10-30 16:24:35] iter = 06360, loss = 3.7839
2024-10-30 16:24:36: [2024-10-30 16:24:36] iter = 06370, loss = 3.1016
2024-10-30 16:24:37: [2024-10-30 16:24:37] iter = 06380, loss = 1.6099
2024-10-30 16:24:39: [2024-10-30 16:24:39] iter = 06390, loss = 4.5373
2024-10-30 16:24:39: [2024-10-30 16:24:39] iter = 06400, loss = 14.7615
2024-10-30 16:24:40: [2024-10-30 16:24:40] iter = 06410, loss = 3.3525
2024-10-30 16:24:41: [2024-10-30 16:24:41] iter = 06420, loss = 3.8645
2024-10-30 16:24:42: [2024-10-30 16:24:42] iter = 06430, loss = 5.9593
2024-10-30 16:24:42: [2024-10-30 16:24:42] iter = 06440, loss = 4.2414
2024-10-30 16:24:43: [2024-10-30 16:24:43] iter = 06450, loss = 17.9069
2024-10-30 16:24:43: [2024-10-30 16:24:43] iter = 06460, loss = 5.5238
2024-10-30 16:24:44: [2024-10-30 16:24:44] iter = 06470, loss = 1.8152
2024-10-30 16:24:45: [2024-10-30 16:24:45] iter = 06480, loss = 5.4807
2024-10-30 16:24:46: [2024-10-30 16:24:46] iter = 06490, loss = 1.7612
2024-10-30 16:24:46: [2024-10-30 16:24:46] iter = 06500, loss = 6.1064
2024-10-30 16:24:47: [2024-10-30 16:24:47] iter = 06510, loss = 1.9167
2024-10-30 16:24:48: [2024-10-30 16:24:48] iter = 06520, loss = 3.1161
2024-10-30 16:24:49: [2024-10-30 16:24:49] iter = 06530, loss = 13.7538
2024-10-30 16:24:49: [2024-10-30 16:24:49] iter = 06540, loss = 4.1790
2024-10-30 16:24:50: [2024-10-30 16:24:50] iter = 06550, loss = 10.3638
2024-10-30 16:24:51: [2024-10-30 16:24:51] iter = 06560, loss = 2.0046
2024-10-30 16:24:52: [2024-10-30 16:24:52] iter = 06570, loss = 1.2667
2024-10-30 16:24:52: [2024-10-30 16:24:52] iter = 06580, loss = 1.3060
2024-10-30 16:24:53: [2024-10-30 16:24:53] iter = 06590, loss = 1.0381
2024-10-30 16:24:54: [2024-10-30 16:24:54] iter = 06600, loss = 1.5347
2024-10-30 16:24:55: [2024-10-30 16:24:55] iter = 06610, loss = 2.2258
2024-10-30 16:24:56: [2024-10-30 16:24:56] iter = 06620, loss = 6.6720
2024-10-30 16:24:57: [2024-10-30 16:24:57] iter = 06630, loss = 22.7858
2024-10-30 16:24:58: [2024-10-30 16:24:58] iter = 06640, loss = 3.9548
2024-10-30 16:24:59: [2024-10-30 16:24:59] iter = 06650, loss = 3.0423
2024-10-30 16:25:00: [2024-10-30 16:25:00] iter = 06660, loss = 2.2227
2024-10-30 16:25:01: [2024-10-30 16:25:01] iter = 06670, loss = 3.9383
2024-10-30 16:25:02: [2024-10-30 16:25:02] iter = 06680, loss = 1.4489
2024-10-30 16:25:03: [2024-10-30 16:25:03] iter = 06690, loss = 4.5712
2024-10-30 16:25:03: [2024-10-30 16:25:03] iter = 06700, loss = 1.9818
2024-10-30 16:25:04: [2024-10-30 16:25:04] iter = 06710, loss = 5.8023
2024-10-30 16:25:05: [2024-10-30 16:25:05] iter = 06720, loss = 1.4141
2024-10-30 16:25:06: [2024-10-30 16:25:06] iter = 06730, loss = 1.5279
2024-10-30 16:25:07: [2024-10-30 16:25:07] iter = 06740, loss = 1.4683
2024-10-30 16:25:08: [2024-10-30 16:25:08] iter = 06750, loss = 2.9026
2024-10-30 16:25:09: [2024-10-30 16:25:09] iter = 06760, loss = 1.5588
2024-10-30 16:25:10: [2024-10-30 16:25:10] iter = 06770, loss = 1.5602
2024-10-30 16:25:11: [2024-10-30 16:25:11] iter = 06780, loss = 12.9513
2024-10-30 16:25:11: [2024-10-30 16:25:11] iter = 06790, loss = 2.2070
2024-10-30 16:25:12: [2024-10-30 16:25:12] iter = 06800, loss = 1.2688
2024-10-30 16:25:13: [2024-10-30 16:25:13] iter = 06810, loss = 1.7469
2024-10-30 16:25:13: [2024-10-30 16:25:13] iter = 06820, loss = 3.9857
2024-10-30 16:25:14: [2024-10-30 16:25:14] iter = 06830, loss = 10.2586
2024-10-30 16:25:15: [2024-10-30 16:25:15] iter = 06840, loss = 1.7349
2024-10-30 16:25:16: [2024-10-30 16:25:16] iter = 06850, loss = 4.2349
2024-10-30 16:25:17: [2024-10-30 16:25:17] iter = 06860, loss = 2.3680
2024-10-30 16:25:17: [2024-10-30 16:25:17] iter = 06870, loss = 9.2631
2024-10-30 16:25:18: [2024-10-30 16:25:18] iter = 06880, loss = 2.4645
2024-10-30 16:25:19: [2024-10-30 16:25:19] iter = 06890, loss = 5.8758
2024-10-30 16:25:20: [2024-10-30 16:25:20] iter = 06900, loss = 4.3698
2024-10-30 16:25:21: [2024-10-30 16:25:21] iter = 06910, loss = 7.2757
2024-10-30 16:25:22: [2024-10-30 16:25:22] iter = 06920, loss = 2.2740
2024-10-30 16:25:23: [2024-10-30 16:25:23] iter = 06930, loss = 6.9521
2024-10-30 16:25:23: [2024-10-30 16:25:23] iter = 06940, loss = 12.6697
2024-10-30 16:25:23: [2024-10-30 16:25:23] iter = 06950, loss = 2.9470
2024-10-30 16:25:24: [2024-10-30 16:25:24] iter = 06960, loss = 5.8698
2024-10-30 16:25:25: [2024-10-30 16:25:25] iter = 06970, loss = 6.0841
2024-10-30 16:25:25: [2024-10-30 16:25:25] iter = 06980, loss = 2.7097
2024-10-30 16:25:26: [2024-10-30 16:25:26] iter = 06990, loss = 4.1887
2024-10-30 16:25:27: [2024-10-30 16:25:27] iter = 07000, loss = 3.7201
2024-10-30 16:25:28: [2024-10-30 16:25:28] iter = 07010, loss = 1.7007
2024-10-30 16:25:28: [2024-10-30 16:25:28] iter = 07020, loss = 2.5942
2024-10-30 16:25:29: [2024-10-30 16:25:29] iter = 07030, loss = 9.5198
2024-10-30 16:25:30: [2024-10-30 16:25:30] iter = 07040, loss = 3.4855
2024-10-30 16:25:31: [2024-10-30 16:25:31] iter = 07050, loss = 2.3575
2024-10-30 16:25:32: [2024-10-30 16:25:32] iter = 07060, loss = 1.3168
2024-10-30 16:25:33: [2024-10-30 16:25:33] iter = 07070, loss = 1.7792
2024-10-30 16:25:34: [2024-10-30 16:25:34] iter = 07080, loss = 6.3489
2024-10-30 16:25:35: [2024-10-30 16:25:35] iter = 07090, loss = 3.9618
2024-10-30 16:25:36: [2024-10-30 16:25:36] iter = 07100, loss = 9.3780
2024-10-30 16:25:37: [2024-10-30 16:25:37] iter = 07110, loss = 5.9258
2024-10-30 16:25:38: [2024-10-30 16:25:38] iter = 07120, loss = 1.6693
2024-10-30 16:25:38: [2024-10-30 16:25:38] iter = 07130, loss = 2.3561
2024-10-30 16:25:40: [2024-10-30 16:25:40] iter = 07140, loss = 2.2959
2024-10-30 16:25:41: [2024-10-30 16:25:41] iter = 07150, loss = 1.3036
2024-10-30 16:25:42: [2024-10-30 16:25:42] iter = 07160, loss = 2.2613
2024-10-30 16:25:43: [2024-10-30 16:25:43] iter = 07170, loss = 1.9168
2024-10-30 16:25:43: [2024-10-30 16:25:43] iter = 07180, loss = 2.6735
2024-10-30 16:25:44: [2024-10-30 16:25:44] iter = 07190, loss = 1.6924
2024-10-30 16:25:45: [2024-10-30 16:25:45] iter = 07200, loss = 2.1789
2024-10-30 16:25:46: [2024-10-30 16:25:46] iter = 07210, loss = 2.9024
2024-10-30 16:25:46: [2024-10-30 16:25:46] iter = 07220, loss = 2.7263
2024-10-30 16:25:47: [2024-10-30 16:25:47] iter = 07230, loss = 2.4538
2024-10-30 16:25:48: [2024-10-30 16:25:48] iter = 07240, loss = 2.0241
2024-10-30 16:25:49: [2024-10-30 16:25:49] iter = 07250, loss = 1.4906
2024-10-30 16:25:50: [2024-10-30 16:25:50] iter = 07260, loss = 1.5031
2024-10-30 16:25:51: [2024-10-30 16:25:51] iter = 07270, loss = 13.9478
2024-10-30 16:25:52: [2024-10-30 16:25:52] iter = 07280, loss = 1.8715
2024-10-30 16:25:53: [2024-10-30 16:25:53] iter = 07290, loss = 2.9035
2024-10-30 16:25:54: [2024-10-30 16:25:54] iter = 07300, loss = 6.0804
2024-10-30 16:25:55: [2024-10-30 16:25:55] iter = 07310, loss = 2.2281
2024-10-30 16:25:56: [2024-10-30 16:25:56] iter = 07320, loss = 1.7147
2024-10-30 16:25:57: [2024-10-30 16:25:57] iter = 07330, loss = 17.6045
2024-10-30 16:25:58: [2024-10-30 16:25:58] iter = 07340, loss = 2.4484
2024-10-30 16:25:58: [2024-10-30 16:25:58] iter = 07350, loss = 2.3564
2024-10-30 16:25:59: [2024-10-30 16:25:59] iter = 07360, loss = 3.7441
2024-10-30 16:26:00: [2024-10-30 16:26:00] iter = 07370, loss = 1.7945
2024-10-30 16:26:00: [2024-10-30 16:26:00] iter = 07380, loss = 15.8008
2024-10-30 16:26:02: [2024-10-30 16:26:02] iter = 07390, loss = 5.4651
2024-10-30 16:26:03: [2024-10-30 16:26:03] iter = 07400, loss = 1.5951
2024-10-30 16:26:03: [2024-10-30 16:26:03] iter = 07410, loss = 1.5732
2024-10-30 16:26:04: [2024-10-30 16:26:04] iter = 07420, loss = 4.3914
2024-10-30 16:26:04: [2024-10-30 16:26:04] iter = 07430, loss = 2.8876
2024-10-30 16:26:05: [2024-10-30 16:26:05] iter = 07440, loss = 6.7430
2024-10-30 16:26:06: [2024-10-30 16:26:06] iter = 07450, loss = 2.6310
2024-10-30 16:26:06: [2024-10-30 16:26:06] iter = 07460, loss = 5.1585
2024-10-30 16:26:07: [2024-10-30 16:26:07] iter = 07470, loss = 6.6946
2024-10-30 16:26:08: [2024-10-30 16:26:08] iter = 07480, loss = 2.8600
2024-10-30 16:26:08: [2024-10-30 16:26:08] iter = 07490, loss = 12.9476
2024-10-30 16:26:09: [2024-10-30 16:26:09] iter = 07500, loss = 1.6063
2024-10-30 16:26:10: [2024-10-30 16:26:10] iter = 07510, loss = 1.2968
2024-10-30 16:26:11: [2024-10-30 16:26:11] iter = 07520, loss = 2.5820
2024-10-30 16:26:11: [2024-10-30 16:26:11] iter = 07530, loss = 1.7564
2024-10-30 16:26:12: [2024-10-30 16:26:12] iter = 07540, loss = 4.1057
2024-10-30 16:26:13: [2024-10-30 16:26:13] iter = 07550, loss = 3.4023
2024-10-30 16:26:14: [2024-10-30 16:26:14] iter = 07560, loss = 1.5635
2024-10-30 16:26:14: [2024-10-30 16:26:14] iter = 07570, loss = 2.5557
2024-10-30 16:26:15: [2024-10-30 16:26:15] iter = 07580, loss = 4.6125
2024-10-30 16:26:16: [2024-10-30 16:26:16] iter = 07590, loss = 1.6173
2024-10-30 16:26:16: [2024-10-30 16:26:16] iter = 07600, loss = 5.5218
2024-10-30 16:26:17: [2024-10-30 16:26:17] iter = 07610, loss = 13.3748
2024-10-30 16:26:18: [2024-10-30 16:26:18] iter = 07620, loss = 2.5605
2024-10-30 16:26:18: [2024-10-30 16:26:18] iter = 07630, loss = 5.5743
2024-10-30 16:26:19: [2024-10-30 16:26:19] iter = 07640, loss = 7.2343
2024-10-30 16:26:20: [2024-10-30 16:26:20] iter = 07650, loss = 4.7470
2024-10-30 16:26:21: [2024-10-30 16:26:21] iter = 07660, loss = 3.7204
2024-10-30 16:26:22: [2024-10-30 16:26:22] iter = 07670, loss = 4.0507
2024-10-30 16:26:22: [2024-10-30 16:26:22] iter = 07680, loss = 1.9152
2024-10-30 16:26:23: [2024-10-30 16:26:23] iter = 07690, loss = 6.2279
2024-10-30 16:26:24: [2024-10-30 16:26:24] iter = 07700, loss = 3.2452
2024-10-30 16:26:25: [2024-10-30 16:26:25] iter = 07710, loss = 2.6414
2024-10-30 16:26:26: [2024-10-30 16:26:26] iter = 07720, loss = 2.8660
2024-10-30 16:26:27: [2024-10-30 16:26:27] iter = 07730, loss = 8.7089
2024-10-30 16:26:28: [2024-10-30 16:26:28] iter = 07740, loss = 2.5821
2024-10-30 16:26:29: [2024-10-30 16:26:29] iter = 07750, loss = 1.9311
2024-10-30 16:26:30: [2024-10-30 16:26:30] iter = 07760, loss = 1.8845
2024-10-30 16:26:30: [2024-10-30 16:26:30] iter = 07770, loss = 1.5139
2024-10-30 16:26:31: [2024-10-30 16:26:31] iter = 07780, loss = 5.4034
2024-10-30 16:26:32: [2024-10-30 16:26:32] iter = 07790, loss = 3.0496
2024-10-30 16:26:33: [2024-10-30 16:26:33] iter = 07800, loss = 4.4478
2024-10-30 16:26:34: [2024-10-30 16:26:34] iter = 07810, loss = 3.6198
2024-10-30 16:26:35: [2024-10-30 16:26:35] iter = 07820, loss = 3.3616
2024-10-30 16:26:36: [2024-10-30 16:26:36] iter = 07830, loss = 9.1526
2024-10-30 16:26:36: [2024-10-30 16:26:36] iter = 07840, loss = 1.7998
2024-10-30 16:26:37: [2024-10-30 16:26:37] iter = 07850, loss = 6.5858
2024-10-30 16:26:38: [2024-10-30 16:26:38] iter = 07860, loss = 1.9863
2024-10-30 16:26:38: [2024-10-30 16:26:38] iter = 07870, loss = 2.0347
2024-10-30 16:26:39: [2024-10-30 16:26:39] iter = 07880, loss = 2.2423
2024-10-30 16:26:40: [2024-10-30 16:26:40] iter = 07890, loss = 1.5549
2024-10-30 16:26:40: [2024-10-30 16:26:40] iter = 07900, loss = 8.2248
2024-10-30 16:26:41: [2024-10-30 16:26:41] iter = 07910, loss = 1.7107
2024-10-30 16:26:42: [2024-10-30 16:26:42] iter = 07920, loss = 2.6750
2024-10-30 16:26:43: [2024-10-30 16:26:43] iter = 07930, loss = 6.3133
2024-10-30 16:26:43: [2024-10-30 16:26:43] iter = 07940, loss = 2.1684
2024-10-30 16:26:44: [2024-10-30 16:26:44] iter = 07950, loss = 6.2456
2024-10-30 16:26:45: [2024-10-30 16:26:45] iter = 07960, loss = 6.8794
2024-10-30 16:26:45: [2024-10-30 16:26:45] iter = 07970, loss = 1.4918
2024-10-30 16:26:46: [2024-10-30 16:26:46] iter = 07980, loss = 5.7850
2024-10-30 16:26:47: [2024-10-30 16:26:47] iter = 07990, loss = 1.2917
2024-10-30 16:26:48: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 16:26:48: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:26:48: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 8320}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:28:17: Evaluate 5 random ConvNet, ACCmean = 0.4962 ACCstd = 0.0326
-------------------------
2024-10-30 16:28:17: Evaluate 5 random ConvNet, SENmean = 0.6177 SENstd = 0.0188
-------------------------
2024-10-30 16:28:17: Evaluate 5 random ConvNet, SPEmean = 0.6177 SPEstd = 0.0188
-------------------------
2024-10-30 16:28:17: Evaluate 5 random ConvNet, F!mean = 0.4951 F!std = 0.0320
-------------------------
2024-10-30 16:28:17: Evaluate 5 random ConvNet, mean = 0.4962 std = 0.0326
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:28:17: [2024-10-30 16:28:17] iter = 08000, loss = 5.0473
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:28:18: [2024-10-30 16:28:18] iter = 08010, loss = 1.2032
2024-10-30 16:28:18: [2024-10-30 16:28:18] iter = 08020, loss = 1.3859
2024-10-30 16:28:19: [2024-10-30 16:28:19] iter = 08030, loss = 1.0955
2024-10-30 16:28:19: [2024-10-30 16:28:19] iter = 08040, loss = 2.8357
2024-10-30 16:28:20: [2024-10-30 16:28:20] iter = 08050, loss = 1.3156
2024-10-30 16:28:21: [2024-10-30 16:28:21] iter = 08060, loss = 5.7455
2024-10-30 16:28:21: [2024-10-30 16:28:21] iter = 08070, loss = 3.4830
2024-10-30 16:28:22: [2024-10-30 16:28:22] iter = 08080, loss = 1.2840
2024-10-30 16:28:23: [2024-10-30 16:28:23] iter = 08090, loss = 2.2196
2024-10-30 16:28:24: [2024-10-30 16:28:24] iter = 08100, loss = 12.8554
2024-10-30 16:28:25: [2024-10-30 16:28:25] iter = 08110, loss = 1.8696
2024-10-30 16:28:26: [2024-10-30 16:28:26] iter = 08120, loss = 2.8742
2024-10-30 16:28:27: [2024-10-30 16:28:27] iter = 08130, loss = 4.2370
2024-10-30 16:28:28: [2024-10-30 16:28:28] iter = 08140, loss = 5.4543
2024-10-30 16:28:29: [2024-10-30 16:28:29] iter = 08150, loss = 2.7112
2024-10-30 16:28:30: [2024-10-30 16:28:30] iter = 08160, loss = 7.8907
2024-10-30 16:28:31: [2024-10-30 16:28:31] iter = 08170, loss = 3.9274
2024-10-30 16:28:32: [2024-10-30 16:28:32] iter = 08180, loss = 3.7941
2024-10-30 16:28:33: [2024-10-30 16:28:33] iter = 08190, loss = 26.8855
2024-10-30 16:28:33: [2024-10-30 16:28:33] iter = 08200, loss = 2.2796
2024-10-30 16:28:35: [2024-10-30 16:28:35] iter = 08210, loss = 1.9839
2024-10-30 16:28:35: [2024-10-30 16:28:35] iter = 08220, loss = 2.5596
2024-10-30 16:28:36: [2024-10-30 16:28:36] iter = 08230, loss = 10.8480
2024-10-30 16:28:36: [2024-10-30 16:28:36] iter = 08240, loss = 1.3520
2024-10-30 16:28:37: [2024-10-30 16:28:37] iter = 08250, loss = 3.4865
2024-10-30 16:28:38: [2024-10-30 16:28:38] iter = 08260, loss = 2.9464
2024-10-30 16:28:38: [2024-10-30 16:28:38] iter = 08270, loss = 11.1348
2024-10-30 16:28:39: [2024-10-30 16:28:39] iter = 08280, loss = 4.8919
2024-10-30 16:28:40: [2024-10-30 16:28:40] iter = 08290, loss = 4.3063
2024-10-30 16:28:41: [2024-10-30 16:28:41] iter = 08300, loss = 1.6702
2024-10-30 16:28:42: [2024-10-30 16:28:42] iter = 08310, loss = 1.7908
2024-10-30 16:28:43: [2024-10-30 16:28:43] iter = 08320, loss = 21.4667
2024-10-30 16:28:44: [2024-10-30 16:28:44] iter = 08330, loss = 3.0989
2024-10-30 16:28:44: [2024-10-30 16:28:44] iter = 08340, loss = 1.3020
2024-10-30 16:28:45: [2024-10-30 16:28:45] iter = 08350, loss = 5.2753
2024-10-30 16:28:46: [2024-10-30 16:28:46] iter = 08360, loss = 18.3401
2024-10-30 16:28:47: [2024-10-30 16:28:47] iter = 08370, loss = 2.9938
2024-10-30 16:28:48: [2024-10-30 16:28:48] iter = 08380, loss = 1.2976
2024-10-30 16:28:49: [2024-10-30 16:28:49] iter = 08390, loss = 4.0620
2024-10-30 16:28:49: [2024-10-30 16:28:49] iter = 08400, loss = 13.1996
2024-10-30 16:28:50: [2024-10-30 16:28:50] iter = 08410, loss = 2.2146
2024-10-30 16:28:51: [2024-10-30 16:28:51] iter = 08420, loss = 1.2657
2024-10-30 16:28:52: [2024-10-30 16:28:52] iter = 08430, loss = 1.7289
2024-10-30 16:28:53: [2024-10-30 16:28:53] iter = 08440, loss = 48.2819
2024-10-30 16:28:54: [2024-10-30 16:28:54] iter = 08450, loss = 5.1866
2024-10-30 16:28:55: [2024-10-30 16:28:55] iter = 08460, loss = 2.1068
2024-10-30 16:28:56: [2024-10-30 16:28:56] iter = 08470, loss = 2.1740
2024-10-30 16:28:57: [2024-10-30 16:28:57] iter = 08480, loss = 2.0848
2024-10-30 16:28:58: [2024-10-30 16:28:58] iter = 08490, loss = 1.1897
2024-10-30 16:28:59: [2024-10-30 16:28:59] iter = 08500, loss = 3.2821
2024-10-30 16:29:00: [2024-10-30 16:29:00] iter = 08510, loss = 4.6629
2024-10-30 16:29:00: [2024-10-30 16:29:00] iter = 08520, loss = 3.4423
2024-10-30 16:29:01: [2024-10-30 16:29:01] iter = 08530, loss = 2.0407
2024-10-30 16:29:02: [2024-10-30 16:29:02] iter = 08540, loss = 3.9435
2024-10-30 16:29:03: [2024-10-30 16:29:03] iter = 08550, loss = 8.1124
2024-10-30 16:29:04: [2024-10-30 16:29:04] iter = 08560, loss = 14.9056
2024-10-30 16:29:05: [2024-10-30 16:29:05] iter = 08570, loss = 6.6463
2024-10-30 16:29:06: [2024-10-30 16:29:06] iter = 08580, loss = 1.0834
2024-10-30 16:29:07: [2024-10-30 16:29:07] iter = 08590, loss = 1.6681
2024-10-30 16:29:08: [2024-10-30 16:29:08] iter = 08600, loss = 6.1670
2024-10-30 16:29:08: [2024-10-30 16:29:08] iter = 08610, loss = 2.1393
2024-10-30 16:29:09: [2024-10-30 16:29:09] iter = 08620, loss = 4.2263
2024-10-30 16:29:09: [2024-10-30 16:29:09] iter = 08630, loss = 5.7893
2024-10-30 16:29:10: [2024-10-30 16:29:10] iter = 08640, loss = 6.1005
2024-10-30 16:29:11: [2024-10-30 16:29:11] iter = 08650, loss = 1.7812
2024-10-30 16:29:11: [2024-10-30 16:29:11] iter = 08660, loss = 3.1136
2024-10-30 16:29:12: [2024-10-30 16:29:12] iter = 08670, loss = 3.6009
2024-10-30 16:29:13: [2024-10-30 16:29:13] iter = 08680, loss = 3.4979
2024-10-30 16:29:14: [2024-10-30 16:29:14] iter = 08690, loss = 1.0969
2024-10-30 16:29:15: [2024-10-30 16:29:15] iter = 08700, loss = 2.0181
2024-10-30 16:29:16: [2024-10-30 16:29:16] iter = 08710, loss = 6.3040
2024-10-30 16:29:16: [2024-10-30 16:29:16] iter = 08720, loss = 13.5168
2024-10-30 16:29:17: [2024-10-30 16:29:17] iter = 08730, loss = 3.2849
2024-10-30 16:29:18: [2024-10-30 16:29:18] iter = 08740, loss = 2.7330
2024-10-30 16:29:19: [2024-10-30 16:29:19] iter = 08750, loss = 15.2527
2024-10-30 16:29:20: [2024-10-30 16:29:20] iter = 08760, loss = 1.7624
2024-10-30 16:29:21: [2024-10-30 16:29:21] iter = 08770, loss = 1.9757
2024-10-30 16:29:22: [2024-10-30 16:29:22] iter = 08780, loss = 1.4174
2024-10-30 16:29:23: [2024-10-30 16:29:23] iter = 08790, loss = 1.2750
2024-10-30 16:29:23: [2024-10-30 16:29:23] iter = 08800, loss = 2.3090
2024-10-30 16:29:24: [2024-10-30 16:29:24] iter = 08810, loss = 4.2964
2024-10-30 16:29:25: [2024-10-30 16:29:25] iter = 08820, loss = 1.3199
2024-10-30 16:29:25: [2024-10-30 16:29:25] iter = 08830, loss = 2.2740
2024-10-30 16:29:26: [2024-10-30 16:29:26] iter = 08840, loss = 13.7384
2024-10-30 16:29:26: [2024-10-30 16:29:26] iter = 08850, loss = 32.8514
2024-10-30 16:29:27: [2024-10-30 16:29:27] iter = 08860, loss = 4.4910
2024-10-30 16:29:27: [2024-10-30 16:29:27] iter = 08870, loss = 2.1087
2024-10-30 16:29:28: [2024-10-30 16:29:28] iter = 08880, loss = 9.3228
2024-10-30 16:29:28: [2024-10-30 16:29:28] iter = 08890, loss = 8.5085
2024-10-30 16:29:29: [2024-10-30 16:29:29] iter = 08900, loss = 3.7891
2024-10-30 16:29:30: [2024-10-30 16:29:30] iter = 08910, loss = 3.4392
2024-10-30 16:29:30: [2024-10-30 16:29:30] iter = 08920, loss = 3.4393
2024-10-30 16:29:31: [2024-10-30 16:29:31] iter = 08930, loss = 3.1810
2024-10-30 16:29:32: [2024-10-30 16:29:32] iter = 08940, loss = 2.6929
2024-10-30 16:29:33: [2024-10-30 16:29:33] iter = 08950, loss = 9.9071
2024-10-30 16:29:33: [2024-10-30 16:29:33] iter = 08960, loss = 1.6001
2024-10-30 16:29:34: [2024-10-30 16:29:34] iter = 08970, loss = 1.3575
2024-10-30 16:29:34: [2024-10-30 16:29:34] iter = 08980, loss = 2.2328
2024-10-30 16:29:35: [2024-10-30 16:29:35] iter = 08990, loss = 2.8990
2024-10-30 16:29:36: [2024-10-30 16:29:36] iter = 09000, loss = 23.1822
2024-10-30 16:29:36: [2024-10-30 16:29:36] iter = 09010, loss = 3.2393
2024-10-30 16:29:37: [2024-10-30 16:29:37] iter = 09020, loss = 3.5420
2024-10-30 16:29:37: [2024-10-30 16:29:37] iter = 09030, loss = 3.4152
2024-10-30 16:29:38: [2024-10-30 16:29:38] iter = 09040, loss = 1.2810
2024-10-30 16:29:39: [2024-10-30 16:29:39] iter = 09050, loss = 1.3740
2024-10-30 16:29:40: [2024-10-30 16:29:40] iter = 09060, loss = 10.1563
2024-10-30 16:29:41: [2024-10-30 16:29:41] iter = 09070, loss = 18.8780
2024-10-30 16:29:41: [2024-10-30 16:29:41] iter = 09080, loss = 2.8643
2024-10-30 16:29:42: [2024-10-30 16:29:42] iter = 09090, loss = 5.1960
2024-10-30 16:29:42: [2024-10-30 16:29:42] iter = 09100, loss = 3.7460
2024-10-30 16:29:43: [2024-10-30 16:29:43] iter = 09110, loss = 7.3523
2024-10-30 16:29:44: [2024-10-30 16:29:44] iter = 09120, loss = 2.2096
2024-10-30 16:29:45: [2024-10-30 16:29:45] iter = 09130, loss = 8.3635
2024-10-30 16:29:46: [2024-10-30 16:29:46] iter = 09140, loss = 2.1051
2024-10-30 16:29:46: [2024-10-30 16:29:46] iter = 09150, loss = 3.0266
2024-10-30 16:29:47: [2024-10-30 16:29:47] iter = 09160, loss = 1.2485
2024-10-30 16:29:48: [2024-10-30 16:29:48] iter = 09170, loss = 1.4365
2024-10-30 16:29:49: [2024-10-30 16:29:49] iter = 09180, loss = 1.3783
2024-10-30 16:29:49: [2024-10-30 16:29:49] iter = 09190, loss = 2.0472
2024-10-30 16:29:50: [2024-10-30 16:29:50] iter = 09200, loss = 8.8041
2024-10-30 16:29:52: [2024-10-30 16:29:52] iter = 09210, loss = 2.8253
2024-10-30 16:29:53: [2024-10-30 16:29:53] iter = 09220, loss = 1.8803
2024-10-30 16:29:53: [2024-10-30 16:29:53] iter = 09230, loss = 3.8122
2024-10-30 16:29:54: [2024-10-30 16:29:54] iter = 09240, loss = 1.8221
2024-10-30 16:29:55: [2024-10-30 16:29:55] iter = 09250, loss = 4.5331
2024-10-30 16:29:56: [2024-10-30 16:29:56] iter = 09260, loss = 2.1811
2024-10-30 16:29:57: [2024-10-30 16:29:57] iter = 09270, loss = 1.1177
2024-10-30 16:29:58: [2024-10-30 16:29:58] iter = 09280, loss = 3.0655
2024-10-30 16:29:59: [2024-10-30 16:29:59] iter = 09290, loss = 1.6631
2024-10-30 16:30:01: [2024-10-30 16:30:01] iter = 09300, loss = 1.1344
2024-10-30 16:30:02: [2024-10-30 16:30:02] iter = 09310, loss = 1.5278
2024-10-30 16:30:02: [2024-10-30 16:30:02] iter = 09320, loss = 14.1246
2024-10-30 16:30:03: [2024-10-30 16:30:03] iter = 09330, loss = 8.1177
2024-10-30 16:30:04: [2024-10-30 16:30:04] iter = 09340, loss = 2.5002
2024-10-30 16:30:05: [2024-10-30 16:30:05] iter = 09350, loss = 2.9146
2024-10-30 16:30:06: [2024-10-30 16:30:06] iter = 09360, loss = 7.2925
2024-10-30 16:30:07: [2024-10-30 16:30:07] iter = 09370, loss = 4.1610
2024-10-30 16:30:08: [2024-10-30 16:30:08] iter = 09380, loss = 1.2037
2024-10-30 16:30:09: [2024-10-30 16:30:09] iter = 09390, loss = 1.3958
2024-10-30 16:30:09: [2024-10-30 16:30:09] iter = 09400, loss = 4.7507
2024-10-30 16:30:10: [2024-10-30 16:30:10] iter = 09410, loss = 2.9767
2024-10-30 16:30:11: [2024-10-30 16:30:11] iter = 09420, loss = 1.9939
2024-10-30 16:30:12: [2024-10-30 16:30:12] iter = 09430, loss = 2.5863
2024-10-30 16:30:13: [2024-10-30 16:30:13] iter = 09440, loss = 2.3202
2024-10-30 16:30:13: [2024-10-30 16:30:13] iter = 09450, loss = 4.8707
2024-10-30 16:30:14: [2024-10-30 16:30:14] iter = 09460, loss = 9.8347
2024-10-30 16:30:15: [2024-10-30 16:30:15] iter = 09470, loss = 5.1590
2024-10-30 16:30:15: [2024-10-30 16:30:15] iter = 09480, loss = 11.4361
2024-10-30 16:30:16: [2024-10-30 16:30:16] iter = 09490, loss = 3.7580
2024-10-30 16:30:17: [2024-10-30 16:30:17] iter = 09500, loss = 6.8648
2024-10-30 16:30:19: [2024-10-30 16:30:19] iter = 09510, loss = 33.2340
2024-10-30 16:30:19: [2024-10-30 16:30:19] iter = 09520, loss = 6.9060
2024-10-30 16:30:20: [2024-10-30 16:30:20] iter = 09530, loss = 2.2230
2024-10-30 16:30:21: [2024-10-30 16:30:21] iter = 09540, loss = 7.2380
2024-10-30 16:30:22: [2024-10-30 16:30:22] iter = 09550, loss = 1.8890
2024-10-30 16:30:23: [2024-10-30 16:30:23] iter = 09560, loss = 4.5614
2024-10-30 16:30:24: [2024-10-30 16:30:24] iter = 09570, loss = 2.7124
2024-10-30 16:30:25: [2024-10-30 16:30:25] iter = 09580, loss = 4.3067
2024-10-30 16:30:26: [2024-10-30 16:30:26] iter = 09590, loss = 4.3535
2024-10-30 16:30:27: [2024-10-30 16:30:27] iter = 09600, loss = 3.2663
2024-10-30 16:30:28: [2024-10-30 16:30:28] iter = 09610, loss = 10.2616
2024-10-30 16:30:29: [2024-10-30 16:30:29] iter = 09620, loss = 30.5756
2024-10-30 16:30:30: [2024-10-30 16:30:30] iter = 09630, loss = 47.5369
2024-10-30 16:30:31: [2024-10-30 16:30:31] iter = 09640, loss = 12.4296
2024-10-30 16:30:32: [2024-10-30 16:30:32] iter = 09650, loss = 1.6698
2024-10-30 16:30:33: [2024-10-30 16:30:33] iter = 09660, loss = 2.0090
2024-10-30 16:30:34: [2024-10-30 16:30:34] iter = 09670, loss = 3.9194
2024-10-30 16:30:34: [2024-10-30 16:30:34] iter = 09680, loss = 12.0511
2024-10-30 16:30:35: [2024-10-30 16:30:35] iter = 09690, loss = 2.9621
2024-10-30 16:30:36: [2024-10-30 16:30:36] iter = 09700, loss = 4.2989
2024-10-30 16:30:37: [2024-10-30 16:30:37] iter = 09710, loss = 8.6209
2024-10-30 16:30:38: [2024-10-30 16:30:38] iter = 09720, loss = 4.3915
2024-10-30 16:30:39: [2024-10-30 16:30:39] iter = 09730, loss = 4.1921
2024-10-30 16:30:40: [2024-10-30 16:30:40] iter = 09740, loss = 3.5089
2024-10-30 16:30:41: [2024-10-30 16:30:41] iter = 09750, loss = 5.8950
2024-10-30 16:30:42: [2024-10-30 16:30:42] iter = 09760, loss = 5.3852
2024-10-30 16:30:43: [2024-10-30 16:30:43] iter = 09770, loss = 2.5090
2024-10-30 16:30:44: [2024-10-30 16:30:44] iter = 09780, loss = 6.7482
2024-10-30 16:30:44: [2024-10-30 16:30:44] iter = 09790, loss = 1.8989
2024-10-30 16:30:45: [2024-10-30 16:30:45] iter = 09800, loss = 1.7555
2024-10-30 16:30:46: [2024-10-30 16:30:46] iter = 09810, loss = 10.8189
2024-10-30 16:30:47: [2024-10-30 16:30:47] iter = 09820, loss = 2.8352
2024-10-30 16:30:47: [2024-10-30 16:30:47] iter = 09830, loss = 1.3947
2024-10-30 16:30:48: [2024-10-30 16:30:48] iter = 09840, loss = 2.6240
2024-10-30 16:30:49: [2024-10-30 16:30:49] iter = 09850, loss = 1.6314
2024-10-30 16:30:50: [2024-10-30 16:30:50] iter = 09860, loss = 1.5728
2024-10-30 16:30:51: [2024-10-30 16:30:51] iter = 09870, loss = 3.4153
2024-10-30 16:30:52: [2024-10-30 16:30:52] iter = 09880, loss = 2.9125
2024-10-30 16:30:53: [2024-10-30 16:30:53] iter = 09890, loss = 9.0735
2024-10-30 16:30:54: [2024-10-30 16:30:54] iter = 09900, loss = 3.1945
2024-10-30 16:30:55: [2024-10-30 16:30:55] iter = 09910, loss = 10.8814
2024-10-30 16:30:56: [2024-10-30 16:30:56] iter = 09920, loss = 1.8820
2024-10-30 16:30:56: [2024-10-30 16:30:56] iter = 09930, loss = 1.4278
2024-10-30 16:30:57: [2024-10-30 16:30:57] iter = 09940, loss = 1.5358
2024-10-30 16:30:58: [2024-10-30 16:30:58] iter = 09950, loss = 6.8501
2024-10-30 16:30:59: [2024-10-30 16:30:59] iter = 09960, loss = 7.1950
2024-10-30 16:31:00: [2024-10-30 16:31:00] iter = 09970, loss = 21.1716
2024-10-30 16:31:01: [2024-10-30 16:31:01] iter = 09980, loss = 2.7769
2024-10-30 16:31:02: [2024-10-30 16:31:02] iter = 09990, loss = 3.3713
2024-10-30 16:31:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 16:31:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:31:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63018}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:32:33: Evaluate 5 random ConvNet, ACCmean = 0.5846 ACCstd = 0.0164
-------------------------
2024-10-30 16:32:33: Evaluate 5 random ConvNet, SENmean = 0.6737 SENstd = 0.0088
-------------------------
2024-10-30 16:32:33: Evaluate 5 random ConvNet, SPEmean = 0.6737 SPEstd = 0.0088
-------------------------
2024-10-30 16:32:33: Evaluate 5 random ConvNet, F!mean = 0.5786 F!std = 0.0144
-------------------------
2024-10-30 16:32:33: Evaluate 5 random ConvNet, mean = 0.5846 std = 0.0164
-------------------------
2024-10-30 16:32:33: [2024-10-30 16:32:33] iter = 10000, loss = 3.5366
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:32:34: [2024-10-30 16:32:34] iter = 10010, loss = 3.7204
2024-10-30 16:32:34: [2024-10-30 16:32:34] iter = 10020, loss = 10.8419
2024-10-30 16:32:35: [2024-10-30 16:32:35] iter = 10030, loss = 2.4598
2024-10-30 16:32:36: [2024-10-30 16:32:36] iter = 10040, loss = 3.8042
2024-10-30 16:32:37: [2024-10-30 16:32:37] iter = 10050, loss = 2.1908
2024-10-30 16:32:38: [2024-10-30 16:32:38] iter = 10060, loss = 1.0184
2024-10-30 16:32:38: [2024-10-30 16:32:38] iter = 10070, loss = 2.8847
2024-10-30 16:32:39: [2024-10-30 16:32:39] iter = 10080, loss = 15.5952
2024-10-30 16:32:40: [2024-10-30 16:32:40] iter = 10090, loss = 19.7718
2024-10-30 16:32:41: [2024-10-30 16:32:41] iter = 10100, loss = 3.9639
2024-10-30 16:32:42: [2024-10-30 16:32:42] iter = 10110, loss = 10.4665
2024-10-30 16:32:43: [2024-10-30 16:32:43] iter = 10120, loss = 1.9540
2024-10-30 16:32:44: [2024-10-30 16:32:44] iter = 10130, loss = 6.2512
2024-10-30 16:32:45: [2024-10-30 16:32:45] iter = 10140, loss = 1.3247
2024-10-30 16:32:46: [2024-10-30 16:32:46] iter = 10150, loss = 3.4251
2024-10-30 16:32:47: [2024-10-30 16:32:47] iter = 10160, loss = 1.2802
2024-10-30 16:32:47: [2024-10-30 16:32:47] iter = 10170, loss = 1.4323
2024-10-30 16:32:48: [2024-10-30 16:32:48] iter = 10180, loss = 1.3537
2024-10-30 16:32:49: [2024-10-30 16:32:49] iter = 10190, loss = 1.5516
2024-10-30 16:32:50: [2024-10-30 16:32:50] iter = 10200, loss = 4.5565
2024-10-30 16:32:51: [2024-10-30 16:32:51] iter = 10210, loss = 4.1139
2024-10-30 16:32:52: [2024-10-30 16:32:52] iter = 10220, loss = 4.2257
2024-10-30 16:32:53: [2024-10-30 16:32:53] iter = 10230, loss = 1.6452
2024-10-30 16:32:54: [2024-10-30 16:32:54] iter = 10240, loss = 0.8910
2024-10-30 16:32:54: [2024-10-30 16:32:54] iter = 10250, loss = 3.8501
2024-10-30 16:32:55: [2024-10-30 16:32:55] iter = 10260, loss = 1.4261
2024-10-30 16:32:56: [2024-10-30 16:32:56] iter = 10270, loss = 5.1012
2024-10-30 16:32:57: [2024-10-30 16:32:57] iter = 10280, loss = 3.3158
2024-10-30 16:32:58: [2024-10-30 16:32:58] iter = 10290, loss = 4.7991
2024-10-30 16:32:59: [2024-10-30 16:32:59] iter = 10300, loss = 1.5825
2024-10-30 16:32:59: [2024-10-30 16:32:59] iter = 10310, loss = 8.3439
2024-10-30 16:33:01: [2024-10-30 16:33:01] iter = 10320, loss = 21.3840
2024-10-30 16:33:01: [2024-10-30 16:33:01] iter = 10330, loss = 2.6137
2024-10-30 16:33:02: [2024-10-30 16:33:02] iter = 10340, loss = 7.7858
2024-10-30 16:33:03: [2024-10-30 16:33:03] iter = 10350, loss = 16.0938
2024-10-30 16:33:04: [2024-10-30 16:33:04] iter = 10360, loss = 2.0900
2024-10-30 16:33:05: [2024-10-30 16:33:05] iter = 10370, loss = 1.9656
2024-10-30 16:33:07: [2024-10-30 16:33:07] iter = 10380, loss = 2.3482
2024-10-30 16:33:08: [2024-10-30 16:33:08] iter = 10390, loss = 3.6960
2024-10-30 16:33:08: [2024-10-30 16:33:08] iter = 10400, loss = 16.4119
2024-10-30 16:33:09: [2024-10-30 16:33:09] iter = 10410, loss = 3.2696
2024-10-30 16:33:10: [2024-10-30 16:33:10] iter = 10420, loss = 1.2966
2024-10-30 16:33:11: [2024-10-30 16:33:11] iter = 10430, loss = 1.8498
2024-10-30 16:33:12: [2024-10-30 16:33:12] iter = 10440, loss = 1.7570
2024-10-30 16:33:13: [2024-10-30 16:33:13] iter = 10450, loss = 1.4259
2024-10-30 16:33:13: [2024-10-30 16:33:13] iter = 10460, loss = 2.7717
2024-10-30 16:33:14: [2024-10-30 16:33:14] iter = 10470, loss = 4.3482
2024-10-30 16:33:15: [2024-10-30 16:33:15] iter = 10480, loss = 14.8239
2024-10-30 16:33:16: [2024-10-30 16:33:16] iter = 10490, loss = 8.9780
2024-10-30 16:33:16: [2024-10-30 16:33:16] iter = 10500, loss = 7.6227
2024-10-30 16:33:17: [2024-10-30 16:33:17] iter = 10510, loss = 1.9365
2024-10-30 16:33:18: [2024-10-30 16:33:18] iter = 10520, loss = 26.8741
2024-10-30 16:33:18: [2024-10-30 16:33:18] iter = 10530, loss = 2.0268
2024-10-30 16:33:19: [2024-10-30 16:33:19] iter = 10540, loss = 9.1000
2024-10-30 16:33:20: [2024-10-30 16:33:20] iter = 10550, loss = 14.2883
2024-10-30 16:33:21: [2024-10-30 16:33:21] iter = 10560, loss = 1.5336
2024-10-30 16:33:22: [2024-10-30 16:33:22] iter = 10570, loss = 2.7491
2024-10-30 16:33:23: [2024-10-30 16:33:23] iter = 10580, loss = 5.0554
2024-10-30 16:33:24: [2024-10-30 16:33:24] iter = 10590, loss = 2.6745
2024-10-30 16:33:24: [2024-10-30 16:33:24] iter = 10600, loss = 2.0083
2024-10-30 16:33:25: [2024-10-30 16:33:25] iter = 10610, loss = 3.0700
2024-10-30 16:33:26: [2024-10-30 16:33:26] iter = 10620, loss = 19.9523
2024-10-30 16:33:27: [2024-10-30 16:33:27] iter = 10630, loss = 10.6560
2024-10-30 16:33:28: [2024-10-30 16:33:28] iter = 10640, loss = 2.0954
2024-10-30 16:33:29: [2024-10-30 16:33:29] iter = 10650, loss = 3.3103
2024-10-30 16:33:30: [2024-10-30 16:33:30] iter = 10660, loss = 1.7121
2024-10-30 16:33:31: [2024-10-30 16:33:31] iter = 10670, loss = 2.3213
2024-10-30 16:33:32: [2024-10-30 16:33:32] iter = 10680, loss = 1.6792
2024-10-30 16:33:33: [2024-10-30 16:33:33] iter = 10690, loss = 2.2045
2024-10-30 16:33:34: [2024-10-30 16:33:34] iter = 10700, loss = 2.7228
2024-10-30 16:33:35: [2024-10-30 16:33:35] iter = 10710, loss = 5.8603
2024-10-30 16:33:35: [2024-10-30 16:33:35] iter = 10720, loss = 3.7767
2024-10-30 16:33:36: [2024-10-30 16:33:36] iter = 10730, loss = 2.4220
2024-10-30 16:33:37: [2024-10-30 16:33:37] iter = 10740, loss = 2.5070
2024-10-30 16:33:38: [2024-10-30 16:33:38] iter = 10750, loss = 2.2442
2024-10-30 16:33:39: [2024-10-30 16:33:39] iter = 10760, loss = 2.1523
2024-10-30 16:33:40: [2024-10-30 16:33:40] iter = 10770, loss = 1.5153
2024-10-30 16:33:41: [2024-10-30 16:33:41] iter = 10780, loss = 4.4478
2024-10-30 16:33:42: [2024-10-30 16:33:42] iter = 10790, loss = 2.1649
2024-10-30 16:33:42: [2024-10-30 16:33:42] iter = 10800, loss = 1.2853
2024-10-30 16:33:43: [2024-10-30 16:33:43] iter = 10810, loss = 3.9854
2024-10-30 16:33:44: [2024-10-30 16:33:44] iter = 10820, loss = 6.6161
2024-10-30 16:33:45: [2024-10-30 16:33:45] iter = 10830, loss = 8.1402
2024-10-30 16:33:46: [2024-10-30 16:33:46] iter = 10840, loss = 2.9728
2024-10-30 16:33:47: [2024-10-30 16:33:47] iter = 10850, loss = 2.6510
2024-10-30 16:33:48: [2024-10-30 16:33:48] iter = 10860, loss = 4.8748
2024-10-30 16:33:49: [2024-10-30 16:33:49] iter = 10870, loss = 13.8705
2024-10-30 16:33:50: [2024-10-30 16:33:50] iter = 10880, loss = 2.7768
2024-10-30 16:33:50: [2024-10-30 16:33:50] iter = 10890, loss = 3.0713
2024-10-30 16:33:51: [2024-10-30 16:33:51] iter = 10900, loss = 7.4126
2024-10-30 16:33:52: [2024-10-30 16:33:52] iter = 10910, loss = 1.1873
2024-10-30 16:33:53: [2024-10-30 16:33:53] iter = 10920, loss = 2.2390
2024-10-30 16:33:54: [2024-10-30 16:33:54] iter = 10930, loss = 4.1934
2024-10-30 16:33:55: [2024-10-30 16:33:55] iter = 10940, loss = 2.2744
2024-10-30 16:33:56: [2024-10-30 16:33:56] iter = 10950, loss = 1.6603
2024-10-30 16:33:57: [2024-10-30 16:33:57] iter = 10960, loss = 5.3773
2024-10-30 16:33:58: [2024-10-30 16:33:58] iter = 10970, loss = 3.0030
2024-10-30 16:33:59: [2024-10-30 16:33:59] iter = 10980, loss = 2.1879
2024-10-30 16:34:00: [2024-10-30 16:34:00] iter = 10990, loss = 1.4637
2024-10-30 16:34:01: [2024-10-30 16:34:01] iter = 11000, loss = 6.0093
2024-10-30 16:34:01: [2024-10-30 16:34:01] iter = 11010, loss = 10.9667
2024-10-30 16:34:02: [2024-10-30 16:34:02] iter = 11020, loss = 2.1643
2024-10-30 16:34:03: [2024-10-30 16:34:03] iter = 11030, loss = 12.4122
2024-10-30 16:34:04: [2024-10-30 16:34:04] iter = 11040, loss = 1.5532
2024-10-30 16:34:05: [2024-10-30 16:34:05] iter = 11050, loss = 2.3416
2024-10-30 16:34:05: [2024-10-30 16:34:05] iter = 11060, loss = 47.3690
2024-10-30 16:34:06: [2024-10-30 16:34:06] iter = 11070, loss = 3.6645
2024-10-30 16:34:07: [2024-10-30 16:34:07] iter = 11080, loss = 2.5024
2024-10-30 16:34:08: [2024-10-30 16:34:08] iter = 11090, loss = 2.8247
2024-10-30 16:34:09: [2024-10-30 16:34:09] iter = 11100, loss = 17.0205
2024-10-30 16:34:10: [2024-10-30 16:34:10] iter = 11110, loss = 2.0038
2024-10-30 16:34:11: [2024-10-30 16:34:11] iter = 11120, loss = 1.5220
2024-10-30 16:34:11: [2024-10-30 16:34:11] iter = 11130, loss = 2.9574
2024-10-30 16:34:12: [2024-10-30 16:34:12] iter = 11140, loss = 17.3796
2024-10-30 16:34:13: [2024-10-30 16:34:13] iter = 11150, loss = 2.2223
2024-10-30 16:34:14: [2024-10-30 16:34:14] iter = 11160, loss = 2.1014
2024-10-30 16:34:15: [2024-10-30 16:34:15] iter = 11170, loss = 2.2246
2024-10-30 16:34:16: [2024-10-30 16:34:16] iter = 11180, loss = 11.2247
2024-10-30 16:34:17: [2024-10-30 16:34:17] iter = 11190, loss = 2.2989
2024-10-30 16:34:18: [2024-10-30 16:34:18] iter = 11200, loss = 4.6306
2024-10-30 16:34:19: [2024-10-30 16:34:19] iter = 11210, loss = 2.5757
2024-10-30 16:34:20: [2024-10-30 16:34:20] iter = 11220, loss = 4.4079
2024-10-30 16:34:21: [2024-10-30 16:34:21] iter = 11230, loss = 1.5186
2024-10-30 16:34:21: [2024-10-30 16:34:21] iter = 11240, loss = 2.4243
2024-10-30 16:34:22: [2024-10-30 16:34:22] iter = 11250, loss = 3.8073
2024-10-30 16:34:23: [2024-10-30 16:34:23] iter = 11260, loss = 2.2005
2024-10-30 16:34:24: [2024-10-30 16:34:24] iter = 11270, loss = 2.8458
2024-10-30 16:34:25: [2024-10-30 16:34:25] iter = 11280, loss = 1.2955
2024-10-30 16:34:26: [2024-10-30 16:34:26] iter = 11290, loss = 1.5824
2024-10-30 16:34:26: [2024-10-30 16:34:26] iter = 11300, loss = 1.2035
2024-10-30 16:34:27: [2024-10-30 16:34:27] iter = 11310, loss = 1.9771
2024-10-30 16:34:28: [2024-10-30 16:34:28] iter = 11320, loss = 3.7821
2024-10-30 16:34:30: [2024-10-30 16:34:30] iter = 11330, loss = 1.5570
2024-10-30 16:34:30: [2024-10-30 16:34:30] iter = 11340, loss = 35.9173
2024-10-30 16:34:31: [2024-10-30 16:34:31] iter = 11350, loss = 2.0684
2024-10-30 16:34:32: [2024-10-30 16:34:32] iter = 11360, loss = 5.9197
2024-10-30 16:34:33: [2024-10-30 16:34:33] iter = 11370, loss = 1.8556
2024-10-30 16:34:34: [2024-10-30 16:34:34] iter = 11380, loss = 4.5694
2024-10-30 16:34:35: [2024-10-30 16:34:35] iter = 11390, loss = 1.4939
2024-10-30 16:34:36: [2024-10-30 16:34:36] iter = 11400, loss = 1.6380
2024-10-30 16:34:37: [2024-10-30 16:34:37] iter = 11410, loss = 1.6825
2024-10-30 16:34:38: [2024-10-30 16:34:38] iter = 11420, loss = 3.3511
2024-10-30 16:34:38: [2024-10-30 16:34:38] iter = 11430, loss = 5.6805
2024-10-30 16:34:39: [2024-10-30 16:34:39] iter = 11440, loss = 8.0393
2024-10-30 16:34:40: [2024-10-30 16:34:40] iter = 11450, loss = 17.9749
2024-10-30 16:34:41: [2024-10-30 16:34:41] iter = 11460, loss = 1.4541
2024-10-30 16:34:41: [2024-10-30 16:34:41] iter = 11470, loss = 5.8264
2024-10-30 16:34:43: [2024-10-30 16:34:43] iter = 11480, loss = 3.9251
2024-10-30 16:34:44: [2024-10-30 16:34:44] iter = 11490, loss = 8.3340
2024-10-30 16:34:44: [2024-10-30 16:34:44] iter = 11500, loss = 1.8317
2024-10-30 16:34:45: [2024-10-30 16:34:45] iter = 11510, loss = 7.1798
2024-10-30 16:34:46: [2024-10-30 16:34:46] iter = 11520, loss = 6.2849
2024-10-30 16:34:47: [2024-10-30 16:34:47] iter = 11530, loss = 10.2730
2024-10-30 16:34:48: [2024-10-30 16:34:48] iter = 11540, loss = 3.5984
2024-10-30 16:34:49: [2024-10-30 16:34:49] iter = 11550, loss = 1.4971
2024-10-30 16:34:50: [2024-10-30 16:34:50] iter = 11560, loss = 3.7130
2024-10-30 16:34:50: [2024-10-30 16:34:50] iter = 11570, loss = 1.8058
2024-10-30 16:34:51: [2024-10-30 16:34:51] iter = 11580, loss = 1.7285
2024-10-30 16:34:51: [2024-10-30 16:34:51] iter = 11590, loss = 1.3834
2024-10-30 16:34:52: [2024-10-30 16:34:52] iter = 11600, loss = 8.8437
2024-10-30 16:34:53: [2024-10-30 16:34:53] iter = 11610, loss = 1.8463
2024-10-30 16:34:53: [2024-10-30 16:34:53] iter = 11620, loss = 1.3948
2024-10-30 16:34:54: [2024-10-30 16:34:54] iter = 11630, loss = 2.5540
2024-10-30 16:34:55: [2024-10-30 16:34:55] iter = 11640, loss = 1.4531
2024-10-30 16:34:56: [2024-10-30 16:34:56] iter = 11650, loss = 3.3007
2024-10-30 16:34:57: [2024-10-30 16:34:57] iter = 11660, loss = 2.3196
2024-10-30 16:34:58: [2024-10-30 16:34:58] iter = 11670, loss = 2.3199
2024-10-30 16:34:58: [2024-10-30 16:34:58] iter = 11680, loss = 3.6783
2024-10-30 16:34:59: [2024-10-30 16:34:59] iter = 11690, loss = 1.6949
2024-10-30 16:35:00: [2024-10-30 16:35:00] iter = 11700, loss = 12.9266
2024-10-30 16:35:01: [2024-10-30 16:35:01] iter = 11710, loss = 2.1532
2024-10-30 16:35:02: [2024-10-30 16:35:02] iter = 11720, loss = 1.6782
2024-10-30 16:35:03: [2024-10-30 16:35:03] iter = 11730, loss = 6.8103
2024-10-30 16:35:04: [2024-10-30 16:35:04] iter = 11740, loss = 0.9864
2024-10-30 16:35:04: [2024-10-30 16:35:04] iter = 11750, loss = 2.6236
2024-10-30 16:35:05: [2024-10-30 16:35:05] iter = 11760, loss = 10.7027
2024-10-30 16:35:06: [2024-10-30 16:35:06] iter = 11770, loss = 1.8068
2024-10-30 16:35:07: [2024-10-30 16:35:07] iter = 11780, loss = 8.5308
2024-10-30 16:35:08: [2024-10-30 16:35:08] iter = 11790, loss = 13.0394
2024-10-30 16:35:09: [2024-10-30 16:35:09] iter = 11800, loss = 2.4290
2024-10-30 16:35:10: [2024-10-30 16:35:10] iter = 11810, loss = 2.0611
2024-10-30 16:35:11: [2024-10-30 16:35:11] iter = 11820, loss = 1.5807
2024-10-30 16:35:12: [2024-10-30 16:35:12] iter = 11830, loss = 2.5887
2024-10-30 16:35:13: [2024-10-30 16:35:13] iter = 11840, loss = 8.9865
2024-10-30 16:35:13: [2024-10-30 16:35:13] iter = 11850, loss = 19.8728
2024-10-30 16:35:14: [2024-10-30 16:35:14] iter = 11860, loss = 4.2980
2024-10-30 16:35:15: [2024-10-30 16:35:15] iter = 11870, loss = 3.1816
2024-10-30 16:35:16: [2024-10-30 16:35:16] iter = 11880, loss = 2.1135
2024-10-30 16:35:16: [2024-10-30 16:35:16] iter = 11890, loss = 2.4187
2024-10-30 16:35:17: [2024-10-30 16:35:17] iter = 11900, loss = 1.3083
2024-10-30 16:35:18: [2024-10-30 16:35:18] iter = 11910, loss = 15.0827
2024-10-30 16:35:19: [2024-10-30 16:35:19] iter = 11920, loss = 1.8194
2024-10-30 16:35:20: [2024-10-30 16:35:20] iter = 11930, loss = 1.6491
2024-10-30 16:35:21: [2024-10-30 16:35:21] iter = 11940, loss = 1.0401
2024-10-30 16:35:22: [2024-10-30 16:35:22] iter = 11950, loss = 1.1384
2024-10-30 16:35:23: [2024-10-30 16:35:23] iter = 11960, loss = 1.9083
2024-10-30 16:35:23: [2024-10-30 16:35:23] iter = 11970, loss = 3.7007
2024-10-30 16:35:24: [2024-10-30 16:35:24] iter = 11980, loss = 4.2370
2024-10-30 16:35:25: [2024-10-30 16:35:25] iter = 11990, loss = 1.4694
2024-10-30 16:35:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 16:35:26: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:35:26: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 26282}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:36:58: Evaluate 5 random ConvNet, ACCmean = 0.7372 ACCstd = 0.0243
-------------------------
2024-10-30 16:36:58: Evaluate 5 random ConvNet, SENmean = 0.7299 SENstd = 0.0218
-------------------------
2024-10-30 16:36:58: Evaluate 5 random ConvNet, SPEmean = 0.7299 SPEstd = 0.0218
-------------------------
2024-10-30 16:36:58: Evaluate 5 random ConvNet, F!mean = 0.7000 F!std = 0.0237
-------------------------
2024-10-30 16:36:58: Evaluate 5 random ConvNet, mean = 0.7372 std = 0.0243
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:36:58: [2024-10-30 16:36:58] iter = 12000, loss = 1.3569
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:36:59: [2024-10-30 16:36:59] iter = 12010, loss = 1.5575
2024-10-30 16:37:01: [2024-10-30 16:37:01] iter = 12020, loss = 5.6536
2024-10-30 16:37:02: [2024-10-30 16:37:02] iter = 12030, loss = 5.2288
2024-10-30 16:37:02: [2024-10-30 16:37:02] iter = 12040, loss = 2.2213
2024-10-30 16:37:03: [2024-10-30 16:37:03] iter = 12050, loss = 1.6210
2024-10-30 16:37:04: [2024-10-30 16:37:04] iter = 12060, loss = 1.8703
2024-10-30 16:37:05: [2024-10-30 16:37:05] iter = 12070, loss = 1.4932
2024-10-30 16:37:06: [2024-10-30 16:37:06] iter = 12080, loss = 4.5655
2024-10-30 16:37:07: [2024-10-30 16:37:07] iter = 12090, loss = 10.1975
2024-10-30 16:37:08: [2024-10-30 16:37:08] iter = 12100, loss = 2.6732
2024-10-30 16:37:09: [2024-10-30 16:37:09] iter = 12110, loss = 5.3829
2024-10-30 16:37:11: [2024-10-30 16:37:11] iter = 12120, loss = 3.6821
2024-10-30 16:37:12: [2024-10-30 16:37:12] iter = 12130, loss = 2.1810
2024-10-30 16:37:12: [2024-10-30 16:37:12] iter = 12140, loss = 1.8385
2024-10-30 16:37:13: [2024-10-30 16:37:13] iter = 12150, loss = 2.5535
2024-10-30 16:37:13: [2024-10-30 16:37:13] iter = 12160, loss = 3.3170
2024-10-30 16:37:14: [2024-10-30 16:37:14] iter = 12170, loss = 3.2836
2024-10-30 16:37:15: [2024-10-30 16:37:15] iter = 12180, loss = 2.9184
2024-10-30 16:37:15: [2024-10-30 16:37:15] iter = 12190, loss = 14.1655
2024-10-30 16:37:17: [2024-10-30 16:37:17] iter = 12200, loss = 2.9239
2024-10-30 16:37:18: [2024-10-30 16:37:18] iter = 12210, loss = 15.0046
2024-10-30 16:37:19: [2024-10-30 16:37:19] iter = 12220, loss = 7.0270
2024-10-30 16:37:20: [2024-10-30 16:37:20] iter = 12230, loss = 1.3280
2024-10-30 16:37:21: [2024-10-30 16:37:21] iter = 12240, loss = 5.5277
2024-10-30 16:37:22: [2024-10-30 16:37:22] iter = 12250, loss = 4.3273
2024-10-30 16:37:23: [2024-10-30 16:37:23] iter = 12260, loss = 1.7888
2024-10-30 16:37:24: [2024-10-30 16:37:24] iter = 12270, loss = 5.9956
2024-10-30 16:37:25: [2024-10-30 16:37:25] iter = 12280, loss = 15.2690
2024-10-30 16:37:26: [2024-10-30 16:37:26] iter = 12290, loss = 19.8755
2024-10-30 16:37:27: [2024-10-30 16:37:27] iter = 12300, loss = 3.3100
2024-10-30 16:37:28: [2024-10-30 16:37:28] iter = 12310, loss = 2.1432
2024-10-30 16:37:29: [2024-10-30 16:37:29] iter = 12320, loss = 6.5650
2024-10-30 16:37:30: [2024-10-30 16:37:30] iter = 12330, loss = 2.0157
2024-10-30 16:37:31: [2024-10-30 16:37:31] iter = 12340, loss = 1.2900
2024-10-30 16:37:32: [2024-10-30 16:37:32] iter = 12350, loss = 1.0618
2024-10-30 16:37:33: [2024-10-30 16:37:33] iter = 12360, loss = 2.7002
2024-10-30 16:37:34: [2024-10-30 16:37:34] iter = 12370, loss = 7.9971
2024-10-30 16:37:34: [2024-10-30 16:37:34] iter = 12380, loss = 1.6909
2024-10-30 16:37:35: [2024-10-30 16:37:35] iter = 12390, loss = 1.1243
2024-10-30 16:37:36: [2024-10-30 16:37:36] iter = 12400, loss = 1.6205
2024-10-30 16:37:37: [2024-10-30 16:37:37] iter = 12410, loss = 1.9875
2024-10-30 16:37:38: [2024-10-30 16:37:38] iter = 12420, loss = 2.7976
2024-10-30 16:37:39: [2024-10-30 16:37:39] iter = 12430, loss = 5.8353
2024-10-30 16:37:40: [2024-10-30 16:37:40] iter = 12440, loss = 22.9976
2024-10-30 16:37:41: [2024-10-30 16:37:41] iter = 12450, loss = 7.1701
2024-10-30 16:37:42: [2024-10-30 16:37:42] iter = 12460, loss = 4.7302
2024-10-30 16:37:43: [2024-10-30 16:37:43] iter = 12470, loss = 2.4179
2024-10-30 16:37:44: [2024-10-30 16:37:44] iter = 12480, loss = 2.3345
2024-10-30 16:37:44: [2024-10-30 16:37:44] iter = 12490, loss = 1.5451
2024-10-30 16:37:45: [2024-10-30 16:37:45] iter = 12500, loss = 6.4087
2024-10-30 16:37:46: [2024-10-30 16:37:46] iter = 12510, loss = 3.2559
2024-10-30 16:37:47: [2024-10-30 16:37:47] iter = 12520, loss = 1.8374
2024-10-30 16:37:48: [2024-10-30 16:37:48] iter = 12530, loss = 2.2943
2024-10-30 16:37:49: [2024-10-30 16:37:49] iter = 12540, loss = 3.5392
2024-10-30 16:37:50: [2024-10-30 16:37:50] iter = 12550, loss = 1.8707
2024-10-30 16:37:51: [2024-10-30 16:37:51] iter = 12560, loss = 1.5518
2024-10-30 16:37:52: [2024-10-30 16:37:52] iter = 12570, loss = 2.1365
2024-10-30 16:37:52: [2024-10-30 16:37:52] iter = 12580, loss = 1.8987
2024-10-30 16:37:53: [2024-10-30 16:37:53] iter = 12590, loss = 1.0594
2024-10-30 16:37:54: [2024-10-30 16:37:54] iter = 12600, loss = 1.9694
2024-10-30 16:37:55: [2024-10-30 16:37:55] iter = 12610, loss = 1.7065
2024-10-30 16:37:56: [2024-10-30 16:37:56] iter = 12620, loss = 2.3999
2024-10-30 16:37:57: [2024-10-30 16:37:57] iter = 12630, loss = 7.2293
2024-10-30 16:37:58: [2024-10-30 16:37:58] iter = 12640, loss = 2.8247
2024-10-30 16:37:59: [2024-10-30 16:37:59] iter = 12650, loss = 3.0559
2024-10-30 16:38:00: [2024-10-30 16:38:00] iter = 12660, loss = 4.1997
2024-10-30 16:38:01: [2024-10-30 16:38:01] iter = 12670, loss = 3.0175
2024-10-30 16:38:02: [2024-10-30 16:38:02] iter = 12680, loss = 1.8831
2024-10-30 16:38:03: [2024-10-30 16:38:03] iter = 12690, loss = 1.3502
2024-10-30 16:38:04: [2024-10-30 16:38:04] iter = 12700, loss = 15.8824
2024-10-30 16:38:05: [2024-10-30 16:38:05] iter = 12710, loss = 2.3049
2024-10-30 16:38:06: [2024-10-30 16:38:06] iter = 12720, loss = 9.9127
2024-10-30 16:38:07: [2024-10-30 16:38:07] iter = 12730, loss = 1.5999
2024-10-30 16:38:07: [2024-10-30 16:38:07] iter = 12740, loss = 1.7406
2024-10-30 16:38:09: [2024-10-30 16:38:09] iter = 12750, loss = 1.3526
2024-10-30 16:38:10: [2024-10-30 16:38:10] iter = 12760, loss = 2.1329
2024-10-30 16:38:11: [2024-10-30 16:38:11] iter = 12770, loss = 1.7816
2024-10-30 16:38:11: [2024-10-30 16:38:11] iter = 12780, loss = 21.3319
2024-10-30 16:38:12: [2024-10-30 16:38:12] iter = 12790, loss = 7.5864
2024-10-30 16:38:13: [2024-10-30 16:38:13] iter = 12800, loss = 2.0991
2024-10-30 16:38:14: [2024-10-30 16:38:14] iter = 12810, loss = 5.7798
2024-10-30 16:38:15: [2024-10-30 16:38:15] iter = 12820, loss = 3.9810
2024-10-30 16:38:16: [2024-10-30 16:38:16] iter = 12830, loss = 1.9896
2024-10-30 16:38:17: [2024-10-30 16:38:17] iter = 12840, loss = 1.9467
2024-10-30 16:38:18: [2024-10-30 16:38:18] iter = 12850, loss = 39.7096
2024-10-30 16:38:19: [2024-10-30 16:38:19] iter = 12860, loss = 3.8171
2024-10-30 16:38:20: [2024-10-30 16:38:20] iter = 12870, loss = 1.8726
2024-10-30 16:38:21: [2024-10-30 16:38:21] iter = 12880, loss = 3.6387
2024-10-30 16:38:21: [2024-10-30 16:38:21] iter = 12890, loss = 1.6681
2024-10-30 16:38:22: [2024-10-30 16:38:22] iter = 12900, loss = 2.1249
2024-10-30 16:38:22: [2024-10-30 16:38:22] iter = 12910, loss = 7.0236
2024-10-30 16:38:23: [2024-10-30 16:38:23] iter = 12920, loss = 1.9425
2024-10-30 16:38:24: [2024-10-30 16:38:24] iter = 12930, loss = 2.9074
2024-10-30 16:38:25: [2024-10-30 16:38:25] iter = 12940, loss = 3.8776
2024-10-30 16:38:27: [2024-10-30 16:38:27] iter = 12950, loss = 5.0323
2024-10-30 16:38:27: [2024-10-30 16:38:27] iter = 12960, loss = 40.9557
2024-10-30 16:38:28: [2024-10-30 16:38:28] iter = 12970, loss = 4.2537
2024-10-30 16:38:29: [2024-10-30 16:38:29] iter = 12980, loss = 3.8830
2024-10-30 16:38:30: [2024-10-30 16:38:30] iter = 12990, loss = 2.0070
2024-10-30 16:38:31: [2024-10-30 16:38:31] iter = 13000, loss = 1.3705
2024-10-30 16:38:32: [2024-10-30 16:38:32] iter = 13010, loss = 1.2733
2024-10-30 16:38:33: [2024-10-30 16:38:33] iter = 13020, loss = 7.3404
2024-10-30 16:38:34: [2024-10-30 16:38:34] iter = 13030, loss = 2.0631
2024-10-30 16:38:35: [2024-10-30 16:38:35] iter = 13040, loss = 2.5202
2024-10-30 16:38:36: [2024-10-30 16:38:36] iter = 13050, loss = 18.0607
2024-10-30 16:38:37: [2024-10-30 16:38:37] iter = 13060, loss = 2.0998
2024-10-30 16:38:38: [2024-10-30 16:38:38] iter = 13070, loss = 2.7167
2024-10-30 16:38:39: [2024-10-30 16:38:39] iter = 13080, loss = 3.5778
2024-10-30 16:38:40: [2024-10-30 16:38:40] iter = 13090, loss = 2.8945
2024-10-30 16:38:41: [2024-10-30 16:38:41] iter = 13100, loss = 3.2291
2024-10-30 16:38:42: [2024-10-30 16:38:42] iter = 13110, loss = 3.1834
2024-10-30 16:38:42: [2024-10-30 16:38:42] iter = 13120, loss = 26.7735
2024-10-30 16:38:43: [2024-10-30 16:38:43] iter = 13130, loss = 8.0436
2024-10-30 16:38:44: [2024-10-30 16:38:44] iter = 13140, loss = 3.9946
2024-10-30 16:38:45: [2024-10-30 16:38:45] iter = 13150, loss = 3.2401
2024-10-30 16:38:46: [2024-10-30 16:38:46] iter = 13160, loss = 2.8929
2024-10-30 16:38:47: [2024-10-30 16:38:47] iter = 13170, loss = 1.9354
2024-10-30 16:38:48: [2024-10-30 16:38:48] iter = 13180, loss = 1.2791
2024-10-30 16:38:49: [2024-10-30 16:38:49] iter = 13190, loss = 4.4335
2024-10-30 16:38:50: [2024-10-30 16:38:50] iter = 13200, loss = 4.5109
2024-10-30 16:38:51: [2024-10-30 16:38:51] iter = 13210, loss = 4.5352
2024-10-30 16:38:52: [2024-10-30 16:38:52] iter = 13220, loss = 1.6337
2024-10-30 16:38:53: [2024-10-30 16:38:53] iter = 13230, loss = 2.0588
2024-10-30 16:38:54: [2024-10-30 16:38:54] iter = 13240, loss = 22.0915
2024-10-30 16:38:55: [2024-10-30 16:38:55] iter = 13250, loss = 3.7502
2024-10-30 16:38:56: [2024-10-30 16:38:56] iter = 13260, loss = 1.7666
2024-10-30 16:38:57: [2024-10-30 16:38:57] iter = 13270, loss = 1.9776
2024-10-30 16:38:58: [2024-10-30 16:38:58] iter = 13280, loss = 1.4352
2024-10-30 16:38:59: [2024-10-30 16:38:59] iter = 13290, loss = 1.7792
2024-10-30 16:39:00: [2024-10-30 16:39:00] iter = 13300, loss = 2.0351
2024-10-30 16:39:01: [2024-10-30 16:39:01] iter = 13310, loss = 2.7142
2024-10-30 16:39:01: [2024-10-30 16:39:01] iter = 13320, loss = 2.3839
2024-10-30 16:39:02: [2024-10-30 16:39:02] iter = 13330, loss = 1.8327
2024-10-30 16:39:03: [2024-10-30 16:39:03] iter = 13340, loss = 3.6631
2024-10-30 16:39:03: [2024-10-30 16:39:03] iter = 13350, loss = 2.6334
2024-10-30 16:39:04: [2024-10-30 16:39:04] iter = 13360, loss = 1.8396
2024-10-30 16:39:05: [2024-10-30 16:39:05] iter = 13370, loss = 3.6084
2024-10-30 16:39:06: [2024-10-30 16:39:06] iter = 13380, loss = 4.8945
2024-10-30 16:39:07: [2024-10-30 16:39:07] iter = 13390, loss = 4.2678
2024-10-30 16:39:08: [2024-10-30 16:39:08] iter = 13400, loss = 1.8872
2024-10-30 16:39:09: [2024-10-30 16:39:09] iter = 13410, loss = 1.5382
2024-10-30 16:39:10: [2024-10-30 16:39:10] iter = 13420, loss = 18.0775
2024-10-30 16:39:11: [2024-10-30 16:39:11] iter = 13430, loss = 7.2250
2024-10-30 16:39:12: [2024-10-30 16:39:12] iter = 13440, loss = 3.3146
2024-10-30 16:39:13: [2024-10-30 16:39:13] iter = 13450, loss = 7.3027
2024-10-30 16:39:14: [2024-10-30 16:39:14] iter = 13460, loss = 19.5198
2024-10-30 16:39:14: [2024-10-30 16:39:14] iter = 13470, loss = 10.9109
2024-10-30 16:39:16: [2024-10-30 16:39:16] iter = 13480, loss = 1.5381
2024-10-30 16:39:17: [2024-10-30 16:39:17] iter = 13490, loss = 1.8091
2024-10-30 16:39:18: [2024-10-30 16:39:18] iter = 13500, loss = 2.8329
2024-10-30 16:39:18: [2024-10-30 16:39:18] iter = 13510, loss = 2.2786
2024-10-30 16:39:19: [2024-10-30 16:39:19] iter = 13520, loss = 14.4750
2024-10-30 16:39:20: [2024-10-30 16:39:20] iter = 13530, loss = 12.9392
2024-10-30 16:39:21: [2024-10-30 16:39:21] iter = 13540, loss = 6.8913
2024-10-30 16:39:21: [2024-10-30 16:39:21] iter = 13550, loss = 5.3104
2024-10-30 16:39:22: [2024-10-30 16:39:22] iter = 13560, loss = 1.5433
2024-10-30 16:39:23: [2024-10-30 16:39:23] iter = 13570, loss = 4.6108
2024-10-30 16:39:24: [2024-10-30 16:39:24] iter = 13580, loss = 2.1712
2024-10-30 16:39:25: [2024-10-30 16:39:25] iter = 13590, loss = 8.4352
2024-10-30 16:39:25: [2024-10-30 16:39:25] iter = 13600, loss = 1.8285
2024-10-30 16:39:26: [2024-10-30 16:39:26] iter = 13610, loss = 1.0925
2024-10-30 16:39:27: [2024-10-30 16:39:27] iter = 13620, loss = 1.2230
2024-10-30 16:39:28: [2024-10-30 16:39:28] iter = 13630, loss = 1.3271
2024-10-30 16:39:29: [2024-10-30 16:39:29] iter = 13640, loss = 12.2679
2024-10-30 16:39:30: [2024-10-30 16:39:30] iter = 13650, loss = 1.7455
2024-10-30 16:39:31: [2024-10-30 16:39:31] iter = 13660, loss = 1.4015
2024-10-30 16:39:31: [2024-10-30 16:39:31] iter = 13670, loss = 1.4885
2024-10-30 16:39:32: [2024-10-30 16:39:32] iter = 13680, loss = 13.7524
2024-10-30 16:39:33: [2024-10-30 16:39:33] iter = 13690, loss = 2.1662
2024-10-30 16:39:34: [2024-10-30 16:39:34] iter = 13700, loss = 6.5699
2024-10-30 16:39:34: [2024-10-30 16:39:34] iter = 13710, loss = 3.3754
2024-10-30 16:39:35: [2024-10-30 16:39:35] iter = 13720, loss = 2.2854
2024-10-30 16:39:36: [2024-10-30 16:39:36] iter = 13730, loss = 12.2583
2024-10-30 16:39:37: [2024-10-30 16:39:37] iter = 13740, loss = 7.7342
2024-10-30 16:39:38: [2024-10-30 16:39:38] iter = 13750, loss = 12.7935
2024-10-30 16:39:39: [2024-10-30 16:39:39] iter = 13760, loss = 2.6861
2024-10-30 16:39:40: [2024-10-30 16:39:40] iter = 13770, loss = 3.0921
2024-10-30 16:39:41: [2024-10-30 16:39:41] iter = 13780, loss = 7.7844
2024-10-30 16:39:42: [2024-10-30 16:39:42] iter = 13790, loss = 2.0456
2024-10-30 16:39:42: [2024-10-30 16:39:42] iter = 13800, loss = 15.3938
2024-10-30 16:39:43: [2024-10-30 16:39:43] iter = 13810, loss = 1.6169
2024-10-30 16:39:44: [2024-10-30 16:39:44] iter = 13820, loss = 1.5804
2024-10-30 16:39:45: [2024-10-30 16:39:45] iter = 13830, loss = 1.5569
2024-10-30 16:39:46: [2024-10-30 16:39:46] iter = 13840, loss = 12.0450
2024-10-30 16:39:46: [2024-10-30 16:39:46] iter = 13850, loss = 12.2444
2024-10-30 16:39:47: [2024-10-30 16:39:47] iter = 13860, loss = 3.6723
2024-10-30 16:39:47: [2024-10-30 16:39:47] iter = 13870, loss = 2.5029
2024-10-30 16:39:48: [2024-10-30 16:39:48] iter = 13880, loss = 1.3410
2024-10-30 16:39:49: [2024-10-30 16:39:49] iter = 13890, loss = 1.4531
2024-10-30 16:39:50: [2024-10-30 16:39:50] iter = 13900, loss = 2.0780
2024-10-30 16:39:51: [2024-10-30 16:39:51] iter = 13910, loss = 2.0211
2024-10-30 16:39:52: [2024-10-30 16:39:52] iter = 13920, loss = 2.2572
2024-10-30 16:39:52: [2024-10-30 16:39:52] iter = 13930, loss = 6.8584
2024-10-30 16:39:53: [2024-10-30 16:39:53] iter = 13940, loss = 1.5636
2024-10-30 16:39:54: [2024-10-30 16:39:54] iter = 13950, loss = 6.2613
2024-10-30 16:39:54: [2024-10-30 16:39:54] iter = 13960, loss = 1.9168
2024-10-30 16:39:55: [2024-10-30 16:39:55] iter = 13970, loss = 7.0953
2024-10-30 16:39:56: [2024-10-30 16:39:56] iter = 13980, loss = 8.5546
2024-10-30 16:39:57: [2024-10-30 16:39:57] iter = 13990, loss = 2.6238
2024-10-30 16:39:58: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 16:39:58: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:39:58: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 98417}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:41:25: Evaluate 5 random ConvNet, ACCmean = 0.7731 ACCstd = 0.0201
-------------------------
2024-10-30 16:41:25: Evaluate 5 random ConvNet, SENmean = 0.6989 SENstd = 0.0152
-------------------------
2024-10-30 16:41:25: Evaluate 5 random ConvNet, SPEmean = 0.6989 SPEstd = 0.0152
-------------------------
2024-10-30 16:41:25: Evaluate 5 random ConvNet, F!mean = 0.7035 F!std = 0.0167
-------------------------
2024-10-30 16:41:25: Evaluate 5 random ConvNet, mean = 0.7731 std = 0.0201
-------------------------
2024-10-30 16:41:25: [2024-10-30 16:41:25] iter = 14000, loss = 2.6040
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:41:26: [2024-10-30 16:41:26] iter = 14010, loss = 3.8622
2024-10-30 16:41:26: [2024-10-30 16:41:26] iter = 14020, loss = 3.8696
2024-10-30 16:41:27: [2024-10-30 16:41:27] iter = 14030, loss = 16.3999
2024-10-30 16:41:28: [2024-10-30 16:41:28] iter = 14040, loss = 2.0495
2024-10-30 16:41:29: [2024-10-30 16:41:29] iter = 14050, loss = 27.4760
2024-10-30 16:41:29: [2024-10-30 16:41:29] iter = 14060, loss = 1.4397
2024-10-30 16:41:30: [2024-10-30 16:41:30] iter = 14070, loss = 13.7165
2024-10-30 16:41:31: [2024-10-30 16:41:31] iter = 14080, loss = 2.5403
2024-10-30 16:41:31: [2024-10-30 16:41:31] iter = 14090, loss = 6.5328
2024-10-30 16:41:32: [2024-10-30 16:41:32] iter = 14100, loss = 12.5154
2024-10-30 16:41:33: [2024-10-30 16:41:33] iter = 14110, loss = 1.9208
2024-10-30 16:41:34: [2024-10-30 16:41:34] iter = 14120, loss = 1.6184
2024-10-30 16:41:35: [2024-10-30 16:41:35] iter = 14130, loss = 1.4296
2024-10-30 16:41:36: [2024-10-30 16:41:36] iter = 14140, loss = 2.1107
2024-10-30 16:41:37: [2024-10-30 16:41:37] iter = 14150, loss = 1.1616
2024-10-30 16:41:38: [2024-10-30 16:41:38] iter = 14160, loss = 5.0076
2024-10-30 16:41:39: [2024-10-30 16:41:39] iter = 14170, loss = 4.3830
2024-10-30 16:41:40: [2024-10-30 16:41:40] iter = 14180, loss = 3.0526
2024-10-30 16:41:41: [2024-10-30 16:41:41] iter = 14190, loss = 1.8581
2024-10-30 16:41:42: [2024-10-30 16:41:42] iter = 14200, loss = 3.1939
2024-10-30 16:41:42: [2024-10-30 16:41:42] iter = 14210, loss = 4.7082
2024-10-30 16:41:43: [2024-10-30 16:41:43] iter = 14220, loss = 1.4125
2024-10-30 16:41:44: [2024-10-30 16:41:44] iter = 14230, loss = 2.3871
2024-10-30 16:41:45: [2024-10-30 16:41:45] iter = 14240, loss = 1.1975
2024-10-30 16:41:45: [2024-10-30 16:41:45] iter = 14250, loss = 2.1754
2024-10-30 16:41:46: [2024-10-30 16:41:46] iter = 14260, loss = 2.1947
2024-10-30 16:41:47: [2024-10-30 16:41:47] iter = 14270, loss = 26.3614
2024-10-30 16:41:48: [2024-10-30 16:41:48] iter = 14280, loss = 5.6330
2024-10-30 16:41:49: [2024-10-30 16:41:49] iter = 14290, loss = 1.6968
2024-10-30 16:41:50: [2024-10-30 16:41:50] iter = 14300, loss = 3.7681
2024-10-30 16:41:50: [2024-10-30 16:41:50] iter = 14310, loss = 8.4894
2024-10-30 16:41:51: [2024-10-30 16:41:51] iter = 14320, loss = 2.7372
2024-10-30 16:41:52: [2024-10-30 16:41:52] iter = 14330, loss = 1.1110
2024-10-30 16:41:53: [2024-10-30 16:41:53] iter = 14340, loss = 8.6054
2024-10-30 16:41:54: [2024-10-30 16:41:54] iter = 14350, loss = 1.7133
2024-10-30 16:41:54: [2024-10-30 16:41:54] iter = 14360, loss = 3.1572
2024-10-30 16:41:55: [2024-10-30 16:41:55] iter = 14370, loss = 1.3642
2024-10-30 16:41:56: [2024-10-30 16:41:56] iter = 14380, loss = 4.6256
2024-10-30 16:41:57: [2024-10-30 16:41:57] iter = 14390, loss = 2.3729
2024-10-30 16:41:58: [2024-10-30 16:41:58] iter = 14400, loss = 9.6759
2024-10-30 16:41:59: [2024-10-30 16:41:59] iter = 14410, loss = 2.8958
2024-10-30 16:41:59: [2024-10-30 16:41:59] iter = 14420, loss = 1.2915
2024-10-30 16:42:00: [2024-10-30 16:42:00] iter = 14430, loss = 3.8301
2024-10-30 16:42:01: [2024-10-30 16:42:01] iter = 14440, loss = 3.0853
2024-10-30 16:42:02: [2024-10-30 16:42:02] iter = 14450, loss = 21.9057
2024-10-30 16:42:03: [2024-10-30 16:42:03] iter = 14460, loss = 31.1359
2024-10-30 16:42:05: [2024-10-30 16:42:05] iter = 14470, loss = 2.8320
2024-10-30 16:42:05: [2024-10-30 16:42:05] iter = 14480, loss = 1.9829
2024-10-30 16:42:06: [2024-10-30 16:42:06] iter = 14490, loss = 2.7884
2024-10-30 16:42:07: [2024-10-30 16:42:07] iter = 14500, loss = 3.6664
2024-10-30 16:42:08: [2024-10-30 16:42:08] iter = 14510, loss = 12.4068
2024-10-30 16:42:09: [2024-10-30 16:42:09] iter = 14520, loss = 2.5774
2024-10-30 16:42:10: [2024-10-30 16:42:10] iter = 14530, loss = 1.7007
2024-10-30 16:42:11: [2024-10-30 16:42:11] iter = 14540, loss = 1.3872
2024-10-30 16:42:11: [2024-10-30 16:42:11] iter = 14550, loss = 1.1013
2024-10-30 16:42:12: [2024-10-30 16:42:12] iter = 14560, loss = 5.4311
2024-10-30 16:42:13: [2024-10-30 16:42:13] iter = 14570, loss = 1.3702
2024-10-30 16:42:14: [2024-10-30 16:42:14] iter = 14580, loss = 4.8074
2024-10-30 16:42:14: [2024-10-30 16:42:14] iter = 14590, loss = 1.2556
2024-10-30 16:42:15: [2024-10-30 16:42:15] iter = 14600, loss = 1.3166
2024-10-30 16:42:16: [2024-10-30 16:42:16] iter = 14610, loss = 1.8065
2024-10-30 16:42:17: [2024-10-30 16:42:17] iter = 14620, loss = 10.1600
2024-10-30 16:42:18: [2024-10-30 16:42:18] iter = 14630, loss = 9.8546
2024-10-30 16:42:19: [2024-10-30 16:42:19] iter = 14640, loss = 8.2414
2024-10-30 16:42:20: [2024-10-30 16:42:20] iter = 14650, loss = 4.9168
2024-10-30 16:42:21: [2024-10-30 16:42:21] iter = 14660, loss = 2.5074
2024-10-30 16:42:22: [2024-10-30 16:42:22] iter = 14670, loss = 3.4847
2024-10-30 16:42:23: [2024-10-30 16:42:23] iter = 14680, loss = 1.6032
2024-10-30 16:42:24: [2024-10-30 16:42:24] iter = 14690, loss = 1.3546
2024-10-30 16:42:25: [2024-10-30 16:42:25] iter = 14700, loss = 20.5828
2024-10-30 16:42:26: [2024-10-30 16:42:26] iter = 14710, loss = 12.3459
2024-10-30 16:42:27: [2024-10-30 16:42:27] iter = 14720, loss = 8.3779
2024-10-30 16:42:28: [2024-10-30 16:42:28] iter = 14730, loss = 9.0709
2024-10-30 16:42:29: [2024-10-30 16:42:29] iter = 14740, loss = 1.8473
2024-10-30 16:42:30: [2024-10-30 16:42:30] iter = 14750, loss = 6.2412
2024-10-30 16:42:31: [2024-10-30 16:42:31] iter = 14760, loss = 2.6670
2024-10-30 16:42:31: [2024-10-30 16:42:31] iter = 14770, loss = 3.3566
2024-10-30 16:42:32: [2024-10-30 16:42:32] iter = 14780, loss = 3.4443
2024-10-30 16:42:33: [2024-10-30 16:42:33] iter = 14790, loss = 8.3329
2024-10-30 16:42:34: [2024-10-30 16:42:34] iter = 14800, loss = 4.1139
2024-10-30 16:42:34: [2024-10-30 16:42:34] iter = 14810, loss = 2.2294
2024-10-30 16:42:35: [2024-10-30 16:42:35] iter = 14820, loss = 16.3416
2024-10-30 16:42:36: [2024-10-30 16:42:36] iter = 14830, loss = 2.3767
2024-10-30 16:42:37: [2024-10-30 16:42:37] iter = 14840, loss = 4.1596
2024-10-30 16:42:38: [2024-10-30 16:42:38] iter = 14850, loss = 2.6970
2024-10-30 16:42:39: [2024-10-30 16:42:39] iter = 14860, loss = 3.1762
2024-10-30 16:42:40: [2024-10-30 16:42:40] iter = 14870, loss = 21.6227
2024-10-30 16:42:41: [2024-10-30 16:42:41] iter = 14880, loss = 5.1891
2024-10-30 16:42:42: [2024-10-30 16:42:42] iter = 14890, loss = 1.6540
2024-10-30 16:42:43: [2024-10-30 16:42:43] iter = 14900, loss = 1.9035
2024-10-30 16:42:43: [2024-10-30 16:42:43] iter = 14910, loss = 1.6145
2024-10-30 16:42:44: [2024-10-30 16:42:44] iter = 14920, loss = 9.1977
2024-10-30 16:42:45: [2024-10-30 16:42:45] iter = 14930, loss = 2.0719
2024-10-30 16:42:46: [2024-10-30 16:42:46] iter = 14940, loss = 1.5966
2024-10-30 16:42:47: [2024-10-30 16:42:47] iter = 14950, loss = 1.0412
2024-10-30 16:42:48: [2024-10-30 16:42:48] iter = 14960, loss = 1.4553
2024-10-30 16:42:49: [2024-10-30 16:42:49] iter = 14970, loss = 1.5282
2024-10-30 16:42:49: [2024-10-30 16:42:49] iter = 14980, loss = 1.9114
2024-10-30 16:42:50: [2024-10-30 16:42:50] iter = 14990, loss = 17.7861
2024-10-30 16:42:50: [2024-10-30 16:42:50] iter = 15000, loss = 19.7162
2024-10-30 16:42:51: [2024-10-30 16:42:51] iter = 15010, loss = 4.7494
2024-10-30 16:42:52: [2024-10-30 16:42:52] iter = 15020, loss = 1.6144
2024-10-30 16:42:52: [2024-10-30 16:42:52] iter = 15030, loss = 1.2282
2024-10-30 16:42:53: [2024-10-30 16:42:53] iter = 15040, loss = 1.3959
2024-10-30 16:42:54: [2024-10-30 16:42:54] iter = 15050, loss = 1.2269
2024-10-30 16:42:54: [2024-10-30 16:42:54] iter = 15060, loss = 7.5987
2024-10-30 16:42:55: [2024-10-30 16:42:55] iter = 15070, loss = 2.1808
2024-10-30 16:42:55: [2024-10-30 16:42:55] iter = 15080, loss = 8.0965
2024-10-30 16:42:56: [2024-10-30 16:42:56] iter = 15090, loss = 3.9259
2024-10-30 16:42:57: [2024-10-30 16:42:57] iter = 15100, loss = 4.9838
2024-10-30 16:42:58: [2024-10-30 16:42:58] iter = 15110, loss = 1.8530
2024-10-30 16:42:59: [2024-10-30 16:42:59] iter = 15120, loss = 2.2446
2024-10-30 16:42:59: [2024-10-30 16:42:59] iter = 15130, loss = 3.7084
2024-10-30 16:43:00: [2024-10-30 16:43:00] iter = 15140, loss = 18.8802
2024-10-30 16:43:01: [2024-10-30 16:43:01] iter = 15150, loss = 4.1809
2024-10-30 16:43:03: [2024-10-30 16:43:03] iter = 15160, loss = 1.1138
2024-10-30 16:43:03: [2024-10-30 16:43:03] iter = 15170, loss = 6.7655
2024-10-30 16:43:04: [2024-10-30 16:43:04] iter = 15180, loss = 2.2557
2024-10-30 16:43:05: [2024-10-30 16:43:05] iter = 15190, loss = 5.4874
2024-10-30 16:43:07: [2024-10-30 16:43:07] iter = 15200, loss = 3.9726
2024-10-30 16:43:07: [2024-10-30 16:43:07] iter = 15210, loss = 1.6370
2024-10-30 16:43:08: [2024-10-30 16:43:08] iter = 15220, loss = 1.6430
2024-10-30 16:43:09: [2024-10-30 16:43:09] iter = 15230, loss = 3.1900
2024-10-30 16:43:10: [2024-10-30 16:43:10] iter = 15240, loss = 21.8634
2024-10-30 16:43:11: [2024-10-30 16:43:11] iter = 15250, loss = 18.5476
2024-10-30 16:43:12: [2024-10-30 16:43:12] iter = 15260, loss = 2.9913
2024-10-30 16:43:13: [2024-10-30 16:43:13] iter = 15270, loss = 1.9278
2024-10-30 16:43:13: [2024-10-30 16:43:13] iter = 15280, loss = 1.6597
2024-10-30 16:43:14: [2024-10-30 16:43:14] iter = 15290, loss = 3.0298
2024-10-30 16:43:15: [2024-10-30 16:43:15] iter = 15300, loss = 1.5277
2024-10-30 16:43:16: [2024-10-30 16:43:16] iter = 15310, loss = 1.2405
2024-10-30 16:43:16: [2024-10-30 16:43:16] iter = 15320, loss = 1.6990
2024-10-30 16:43:17: [2024-10-30 16:43:17] iter = 15330, loss = 4.4444
2024-10-30 16:43:18: [2024-10-30 16:43:18] iter = 15340, loss = 2.1152
2024-10-30 16:43:19: [2024-10-30 16:43:19] iter = 15350, loss = 5.5266
2024-10-30 16:43:19: [2024-10-30 16:43:19] iter = 15360, loss = 1.3727
2024-10-30 16:43:20: [2024-10-30 16:43:20] iter = 15370, loss = 3.2494
2024-10-30 16:43:21: [2024-10-30 16:43:21] iter = 15380, loss = 11.1283
2024-10-30 16:43:22: [2024-10-30 16:43:22] iter = 15390, loss = 4.4067
2024-10-30 16:43:23: [2024-10-30 16:43:23] iter = 15400, loss = 1.5170
2024-10-30 16:43:23: [2024-10-30 16:43:23] iter = 15410, loss = 7.4545
2024-10-30 16:43:24: [2024-10-30 16:43:24] iter = 15420, loss = 2.2865
2024-10-30 16:43:25: [2024-10-30 16:43:25] iter = 15430, loss = 1.1936
2024-10-30 16:43:27: [2024-10-30 16:43:27] iter = 15440, loss = 6.2111
2024-10-30 16:43:28: [2024-10-30 16:43:28] iter = 15450, loss = 5.5962
2024-10-30 16:43:29: [2024-10-30 16:43:29] iter = 15460, loss = 2.1044
2024-10-30 16:43:30: [2024-10-30 16:43:30] iter = 15470, loss = 2.7972
2024-10-30 16:43:31: [2024-10-30 16:43:31] iter = 15480, loss = 2.0361
2024-10-30 16:43:32: [2024-10-30 16:43:32] iter = 15490, loss = 3.9023
2024-10-30 16:43:33: [2024-10-30 16:43:33] iter = 15500, loss = 4.4518
2024-10-30 16:43:33: [2024-10-30 16:43:33] iter = 15510, loss = 6.8864
2024-10-30 16:43:34: [2024-10-30 16:43:34] iter = 15520, loss = 2.1598
2024-10-30 16:43:35: [2024-10-30 16:43:35] iter = 15530, loss = 27.8061
2024-10-30 16:43:36: [2024-10-30 16:43:36] iter = 15540, loss = 10.3095
2024-10-30 16:43:37: [2024-10-30 16:43:37] iter = 15550, loss = 3.4487
2024-10-30 16:43:37: [2024-10-30 16:43:37] iter = 15560, loss = 1.4981
2024-10-30 16:43:38: [2024-10-30 16:43:38] iter = 15570, loss = 1.6295
2024-10-30 16:43:39: [2024-10-30 16:43:39] iter = 15580, loss = 2.0517
2024-10-30 16:43:40: [2024-10-30 16:43:40] iter = 15590, loss = 1.2464
2024-10-30 16:43:41: [2024-10-30 16:43:41] iter = 15600, loss = 1.3896
2024-10-30 16:43:41: [2024-10-30 16:43:41] iter = 15610, loss = 3.0499
2024-10-30 16:43:42: [2024-10-30 16:43:42] iter = 15620, loss = 4.6540
2024-10-30 16:43:43: [2024-10-30 16:43:43] iter = 15630, loss = 3.0578
2024-10-30 16:43:44: [2024-10-30 16:43:44] iter = 15640, loss = 3.8736
2024-10-30 16:43:45: [2024-10-30 16:43:45] iter = 15650, loss = 4.8179
2024-10-30 16:43:45: [2024-10-30 16:43:45] iter = 15660, loss = 7.6197
2024-10-30 16:43:46: [2024-10-30 16:43:46] iter = 15670, loss = 5.7212
2024-10-30 16:43:47: [2024-10-30 16:43:47] iter = 15680, loss = 3.4109
2024-10-30 16:43:48: [2024-10-30 16:43:48] iter = 15690, loss = 1.1222
2024-10-30 16:43:49: [2024-10-30 16:43:49] iter = 15700, loss = 3.6134
2024-10-30 16:43:50: [2024-10-30 16:43:50] iter = 15710, loss = 5.9846
2024-10-30 16:43:52: [2024-10-30 16:43:52] iter = 15720, loss = 1.4084
2024-10-30 16:43:53: [2024-10-30 16:43:53] iter = 15730, loss = 6.9543
2024-10-30 16:43:54: [2024-10-30 16:43:54] iter = 15740, loss = 3.4493
2024-10-30 16:43:55: [2024-10-30 16:43:55] iter = 15750, loss = 9.0590
2024-10-30 16:43:56: [2024-10-30 16:43:56] iter = 15760, loss = 9.8834
2024-10-30 16:43:56: [2024-10-30 16:43:56] iter = 15770, loss = 1.5280
2024-10-30 16:43:58: [2024-10-30 16:43:58] iter = 15780, loss = 3.5663
2024-10-30 16:43:59: [2024-10-30 16:43:59] iter = 15790, loss = 2.3453
2024-10-30 16:44:00: [2024-10-30 16:44:00] iter = 15800, loss = 2.0724
2024-10-30 16:44:01: [2024-10-30 16:44:01] iter = 15810, loss = 6.6353
2024-10-30 16:44:01: [2024-10-30 16:44:01] iter = 15820, loss = 9.5599
2024-10-30 16:44:02: [2024-10-30 16:44:02] iter = 15830, loss = 1.9743
2024-10-30 16:44:03: [2024-10-30 16:44:03] iter = 15840, loss = 5.4257
2024-10-30 16:44:04: [2024-10-30 16:44:04] iter = 15850, loss = 6.3744
2024-10-30 16:44:05: [2024-10-30 16:44:05] iter = 15860, loss = 2.0234
2024-10-30 16:44:06: [2024-10-30 16:44:06] iter = 15870, loss = 1.3521
2024-10-30 16:44:06: [2024-10-30 16:44:06] iter = 15880, loss = 12.9746
2024-10-30 16:44:07: [2024-10-30 16:44:07] iter = 15890, loss = 2.1696
2024-10-30 16:44:08: [2024-10-30 16:44:08] iter = 15900, loss = 1.4013
2024-10-30 16:44:09: [2024-10-30 16:44:09] iter = 15910, loss = 7.0806
2024-10-30 16:44:09: [2024-10-30 16:44:09] iter = 15920, loss = 1.8314
2024-10-30 16:44:10: [2024-10-30 16:44:10] iter = 15930, loss = 2.2421
2024-10-30 16:44:10: [2024-10-30 16:44:10] iter = 15940, loss = 2.1204
2024-10-30 16:44:11: [2024-10-30 16:44:11] iter = 15950, loss = 13.2237
2024-10-30 16:44:12: [2024-10-30 16:44:12] iter = 15960, loss = 3.1582
2024-10-30 16:44:13: [2024-10-30 16:44:13] iter = 15970, loss = 1.8413
2024-10-30 16:44:14: [2024-10-30 16:44:14] iter = 15980, loss = 3.2064
2024-10-30 16:44:16: [2024-10-30 16:44:16] iter = 15990, loss = 1.7026
2024-10-30 16:44:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 16:44:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:44:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57275}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:46: Evaluate 5 random ConvNet, ACCmean = 0.7474 ACCstd = 0.0104
-------------------------
2024-10-30 16:45:46: Evaluate 5 random ConvNet, SENmean = 0.7535 SENstd = 0.0051
-------------------------
2024-10-30 16:45:46: Evaluate 5 random ConvNet, SPEmean = 0.7535 SPEstd = 0.0051
-------------------------
2024-10-30 16:45:46: Evaluate 5 random ConvNet, F!mean = 0.7156 F!std = 0.0087
-------------------------
2024-10-30 16:45:46: Evaluate 5 random ConvNet, mean = 0.7474 std = 0.0104
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:46: [2024-10-30 16:45:46] iter = 16000, loss = 1.4919
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:47: [2024-10-30 16:45:47] iter = 16010, loss = 2.9078
2024-10-30 16:45:48: [2024-10-30 16:45:48] iter = 16020, loss = 1.5377
2024-10-30 16:45:49: [2024-10-30 16:45:49] iter = 16030, loss = 1.6101
2024-10-30 16:45:49: [2024-10-30 16:45:49] iter = 16040, loss = 11.8471
2024-10-30 16:45:50: [2024-10-30 16:45:50] iter = 16050, loss = 3.0440
2024-10-30 16:45:51: [2024-10-30 16:45:51] iter = 16060, loss = 2.0375
2024-10-30 16:45:51: [2024-10-30 16:45:51] iter = 16070, loss = 31.5402
2024-10-30 16:45:52: [2024-10-30 16:45:52] iter = 16080, loss = 12.1470
2024-10-30 16:45:53: [2024-10-30 16:45:53] iter = 16090, loss = 1.4746
2024-10-30 16:45:54: [2024-10-30 16:45:54] iter = 16100, loss = 4.1339
2024-10-30 16:45:55: [2024-10-30 16:45:55] iter = 16110, loss = 3.7483
2024-10-30 16:45:56: [2024-10-30 16:45:56] iter = 16120, loss = 1.3385
2024-10-30 16:45:57: [2024-10-30 16:45:57] iter = 16130, loss = 5.0668
2024-10-30 16:45:57: [2024-10-30 16:45:57] iter = 16140, loss = 2.9092
2024-10-30 16:45:58: [2024-10-30 16:45:58] iter = 16150, loss = 3.3179
2024-10-30 16:45:59: [2024-10-30 16:45:59] iter = 16160, loss = 2.5442
2024-10-30 16:46:00: [2024-10-30 16:46:00] iter = 16170, loss = 23.4784
2024-10-30 16:46:00: [2024-10-30 16:46:00] iter = 16180, loss = 3.2098
2024-10-30 16:46:01: [2024-10-30 16:46:01] iter = 16190, loss = 1.5286
2024-10-30 16:46:02: [2024-10-30 16:46:02] iter = 16200, loss = 5.2493
2024-10-30 16:46:03: [2024-10-30 16:46:03] iter = 16210, loss = 1.5591
2024-10-30 16:46:04: [2024-10-30 16:46:04] iter = 16220, loss = 2.3213
2024-10-30 16:46:05: [2024-10-30 16:46:05] iter = 16230, loss = 4.1247
2024-10-30 16:46:06: [2024-10-30 16:46:06] iter = 16240, loss = 2.3318
2024-10-30 16:46:07: [2024-10-30 16:46:07] iter = 16250, loss = 3.3807
2024-10-30 16:46:08: [2024-10-30 16:46:08] iter = 16260, loss = 11.2587
2024-10-30 16:46:09: [2024-10-30 16:46:09] iter = 16270, loss = 25.5816
2024-10-30 16:46:10: [2024-10-30 16:46:10] iter = 16280, loss = 1.6550
2024-10-30 16:46:10: [2024-10-30 16:46:10] iter = 16290, loss = 4.8339
2024-10-30 16:46:11: [2024-10-30 16:46:11] iter = 16300, loss = 3.8697
2024-10-30 16:46:12: [2024-10-30 16:46:12] iter = 16310, loss = 2.4545
2024-10-30 16:46:12: [2024-10-30 16:46:12] iter = 16320, loss = 1.2496
2024-10-30 16:46:13: [2024-10-30 16:46:13] iter = 16330, loss = 4.7003
2024-10-30 16:46:14: [2024-10-30 16:46:14] iter = 16340, loss = 1.0336
2024-10-30 16:46:15: [2024-10-30 16:46:15] iter = 16350, loss = 1.6613
2024-10-30 16:46:16: [2024-10-30 16:46:16] iter = 16360, loss = 1.1968
2024-10-30 16:46:17: [2024-10-30 16:46:17] iter = 16370, loss = 2.7591
2024-10-30 16:46:18: [2024-10-30 16:46:18] iter = 16380, loss = 3.7314
2024-10-30 16:46:19: [2024-10-30 16:46:19] iter = 16390, loss = 1.3143
2024-10-30 16:46:20: [2024-10-30 16:46:20] iter = 16400, loss = 2.3606
2024-10-30 16:46:21: [2024-10-30 16:46:21] iter = 16410, loss = 1.5944
2024-10-30 16:46:21: [2024-10-30 16:46:21] iter = 16420, loss = 1.4990
2024-10-30 16:46:22: [2024-10-30 16:46:22] iter = 16430, loss = 1.0144
2024-10-30 16:46:23: [2024-10-30 16:46:23] iter = 16440, loss = 4.2743
2024-10-30 16:46:23: [2024-10-30 16:46:23] iter = 16450, loss = 30.3833
2024-10-30 16:46:24: [2024-10-30 16:46:24] iter = 16460, loss = 3.0138
2024-10-30 16:46:24: [2024-10-30 16:46:24] iter = 16470, loss = 10.5348
2024-10-30 16:46:26: [2024-10-30 16:46:26] iter = 16480, loss = 7.9948
2024-10-30 16:46:27: [2024-10-30 16:46:27] iter = 16490, loss = 2.4283
2024-10-30 16:46:27: [2024-10-30 16:46:27] iter = 16500, loss = 5.3155
2024-10-30 16:46:28: [2024-10-30 16:46:28] iter = 16510, loss = 2.5400
2024-10-30 16:46:29: [2024-10-30 16:46:29] iter = 16520, loss = 1.5540
2024-10-30 16:46:30: [2024-10-30 16:46:30] iter = 16530, loss = 1.4298
2024-10-30 16:46:31: [2024-10-30 16:46:31] iter = 16540, loss = 3.9465
2024-10-30 16:46:32: [2024-10-30 16:46:32] iter = 16550, loss = 2.1889
2024-10-30 16:46:33: [2024-10-30 16:46:33] iter = 16560, loss = 1.5129
2024-10-30 16:46:33: [2024-10-30 16:46:33] iter = 16570, loss = 1.8102
2024-10-30 16:46:34: [2024-10-30 16:46:34] iter = 16580, loss = 4.8878
2024-10-30 16:46:34: [2024-10-30 16:46:34] iter = 16590, loss = 1.3579
2024-10-30 16:46:35: [2024-10-30 16:46:35] iter = 16600, loss = 1.5562
2024-10-30 16:46:36: [2024-10-30 16:46:36] iter = 16610, loss = 1.4521
2024-10-30 16:46:37: [2024-10-30 16:46:37] iter = 16620, loss = 1.1376
2024-10-30 16:46:38: [2024-10-30 16:46:38] iter = 16630, loss = 1.4636
2024-10-30 16:46:39: [2024-10-30 16:46:39] iter = 16640, loss = 1.7299
2024-10-30 16:46:40: [2024-10-30 16:46:40] iter = 16650, loss = 7.2125
2024-10-30 16:46:41: [2024-10-30 16:46:41] iter = 16660, loss = 1.4740
2024-10-30 16:46:42: [2024-10-30 16:46:42] iter = 16670, loss = 1.6506
2024-10-30 16:46:42: [2024-10-30 16:46:42] iter = 16680, loss = 3.6921
2024-10-30 16:46:43: [2024-10-30 16:46:43] iter = 16690, loss = 40.4613
2024-10-30 16:46:44: [2024-10-30 16:46:44] iter = 16700, loss = 4.0525
2024-10-30 16:46:45: [2024-10-30 16:46:45] iter = 16710, loss = 25.1431
2024-10-30 16:46:46: [2024-10-30 16:46:46] iter = 16720, loss = 33.2195
2024-10-30 16:46:47: [2024-10-30 16:46:47] iter = 16730, loss = 1.6217
2024-10-30 16:46:47: [2024-10-30 16:46:47] iter = 16740, loss = 2.8053
2024-10-30 16:46:47: [2024-10-30 16:46:47] iter = 16750, loss = 1.9235
2024-10-30 16:46:48: [2024-10-30 16:46:48] iter = 16760, loss = 1.7643
2024-10-30 16:46:49: [2024-10-30 16:46:49] iter = 16770, loss = 4.6410
2024-10-30 16:46:50: [2024-10-30 16:46:50] iter = 16780, loss = 1.7248
2024-10-30 16:46:51: [2024-10-30 16:46:51] iter = 16790, loss = 1.5683
2024-10-30 16:46:52: [2024-10-30 16:46:52] iter = 16800, loss = 2.0815
2024-10-30 16:46:53: [2024-10-30 16:46:53] iter = 16810, loss = 2.0032
2024-10-30 16:46:54: [2024-10-30 16:46:54] iter = 16820, loss = 9.0752
2024-10-30 16:46:55: [2024-10-30 16:46:55] iter = 16830, loss = 26.6786
2024-10-30 16:46:56: [2024-10-30 16:46:56] iter = 16840, loss = 5.3172
2024-10-30 16:46:57: [2024-10-30 16:46:57] iter = 16850, loss = 3.5986
2024-10-30 16:46:57: [2024-10-30 16:46:57] iter = 16860, loss = 4.8815
2024-10-30 16:46:58: [2024-10-30 16:46:58] iter = 16870, loss = 18.2480
2024-10-30 16:46:58: [2024-10-30 16:46:58] iter = 16880, loss = 2.2969
2024-10-30 16:46:59: [2024-10-30 16:46:59] iter = 16890, loss = 4.0028
2024-10-30 16:47:00: [2024-10-30 16:47:00] iter = 16900, loss = 7.1100
2024-10-30 16:47:01: [2024-10-30 16:47:01] iter = 16910, loss = 2.9079
2024-10-30 16:47:02: [2024-10-30 16:47:02] iter = 16920, loss = 1.2627
2024-10-30 16:47:02: [2024-10-30 16:47:02] iter = 16930, loss = 4.5249
2024-10-30 16:47:03: [2024-10-30 16:47:03] iter = 16940, loss = 3.0483
2024-10-30 16:47:04: [2024-10-30 16:47:04] iter = 16950, loss = 1.6985
2024-10-30 16:47:05: [2024-10-30 16:47:05] iter = 16960, loss = 3.9898
2024-10-30 16:47:05: [2024-10-30 16:47:05] iter = 16970, loss = 5.0614
2024-10-30 16:47:06: [2024-10-30 16:47:06] iter = 16980, loss = 2.9786
2024-10-30 16:47:07: [2024-10-30 16:47:07] iter = 16990, loss = 8.5405
2024-10-30 16:47:08: [2024-10-30 16:47:08] iter = 17000, loss = 1.4297
2024-10-30 16:47:09: [2024-10-30 16:47:09] iter = 17010, loss = 5.5150
2024-10-30 16:47:10: [2024-10-30 16:47:10] iter = 17020, loss = 3.8467
2024-10-30 16:47:11: [2024-10-30 16:47:11] iter = 17030, loss = 1.5130
2024-10-30 16:47:12: [2024-10-30 16:47:12] iter = 17040, loss = 1.2674
2024-10-30 16:47:13: [2024-10-30 16:47:13] iter = 17050, loss = 2.1039
2024-10-30 16:47:14: [2024-10-30 16:47:14] iter = 17060, loss = 1.7781
2024-10-30 16:47:15: [2024-10-30 16:47:15] iter = 17070, loss = 2.2154
2024-10-30 16:47:16: [2024-10-30 16:47:16] iter = 17080, loss = 6.3146
2024-10-30 16:47:16: [2024-10-30 16:47:16] iter = 17090, loss = 5.2821
2024-10-30 16:47:17: [2024-10-30 16:47:17] iter = 17100, loss = 1.6099
2024-10-30 16:47:17: [2024-10-30 16:47:17] iter = 17110, loss = 1.4376
2024-10-30 16:47:18: [2024-10-30 16:47:18] iter = 17120, loss = 4.6714
2024-10-30 16:47:19: [2024-10-30 16:47:19] iter = 17130, loss = 2.3135
2024-10-30 16:47:20: [2024-10-30 16:47:20] iter = 17140, loss = 1.9004
2024-10-30 16:47:22: [2024-10-30 16:47:22] iter = 17150, loss = 1.3981
2024-10-30 16:47:22: [2024-10-30 16:47:22] iter = 17160, loss = 4.5639
2024-10-30 16:47:23: [2024-10-30 16:47:23] iter = 17170, loss = 6.3835
2024-10-30 16:47:25: [2024-10-30 16:47:25] iter = 17180, loss = 1.7914
2024-10-30 16:47:25: [2024-10-30 16:47:25] iter = 17190, loss = 1.0528
2024-10-30 16:47:26: [2024-10-30 16:47:26] iter = 17200, loss = 1.1291
2024-10-30 16:47:27: [2024-10-30 16:47:27] iter = 17210, loss = 1.3027
2024-10-30 16:47:27: [2024-10-30 16:47:27] iter = 17220, loss = 2.5853
2024-10-30 16:47:28: [2024-10-30 16:47:28] iter = 17230, loss = 12.7487
2024-10-30 16:47:28: [2024-10-30 16:47:28] iter = 17240, loss = 4.5957
2024-10-30 16:47:29: [2024-10-30 16:47:29] iter = 17250, loss = 2.7753
2024-10-30 16:47:30: [2024-10-30 16:47:30] iter = 17260, loss = 3.4451
2024-10-30 16:47:31: [2024-10-30 16:47:31] iter = 17270, loss = 2.8966
2024-10-30 16:47:33: [2024-10-30 16:47:33] iter = 17280, loss = 1.9845
2024-10-30 16:47:33: [2024-10-30 16:47:33] iter = 17290, loss = 1.6938
2024-10-30 16:47:34: [2024-10-30 16:47:34] iter = 17300, loss = 2.1299
2024-10-30 16:47:35: [2024-10-30 16:47:35] iter = 17310, loss = 1.9571
2024-10-30 16:47:36: [2024-10-30 16:47:36] iter = 17320, loss = 7.5353
2024-10-30 16:47:36: [2024-10-30 16:47:36] iter = 17330, loss = 38.8458
2024-10-30 16:47:37: [2024-10-30 16:47:37] iter = 17340, loss = 4.1415
2024-10-30 16:47:38: [2024-10-30 16:47:38] iter = 17350, loss = 5.7033
2024-10-30 16:47:39: [2024-10-30 16:47:39] iter = 17360, loss = 2.3321
2024-10-30 16:47:40: [2024-10-30 16:47:40] iter = 17370, loss = 1.9194
2024-10-30 16:47:41: [2024-10-30 16:47:41] iter = 17380, loss = 4.9851
2024-10-30 16:47:41: [2024-10-30 16:47:41] iter = 17390, loss = 1.8597
2024-10-30 16:47:42: [2024-10-30 16:47:42] iter = 17400, loss = 8.8031
2024-10-30 16:47:43: [2024-10-30 16:47:43] iter = 17410, loss = 3.3685
2024-10-30 16:47:44: [2024-10-30 16:47:44] iter = 17420, loss = 1.2924
2024-10-30 16:47:44: [2024-10-30 16:47:44] iter = 17430, loss = 2.3962
2024-10-30 16:47:45: [2024-10-30 16:47:45] iter = 17440, loss = 2.8734
2024-10-30 16:47:46: [2024-10-30 16:47:46] iter = 17450, loss = 16.9068
2024-10-30 16:47:47: [2024-10-30 16:47:47] iter = 17460, loss = 1.5168
2024-10-30 16:47:48: [2024-10-30 16:47:48] iter = 17470, loss = 1.5390
2024-10-30 16:47:49: [2024-10-30 16:47:49] iter = 17480, loss = 2.0559
2024-10-30 16:47:50: [2024-10-30 16:47:50] iter = 17490, loss = 3.1815
2024-10-30 16:47:51: [2024-10-30 16:47:51] iter = 17500, loss = 4.1241
2024-10-30 16:47:52: [2024-10-30 16:47:52] iter = 17510, loss = 1.5461
2024-10-30 16:47:52: [2024-10-30 16:47:52] iter = 17520, loss = 1.1133
2024-10-30 16:47:53: [2024-10-30 16:47:53] iter = 17530, loss = 2.9841
2024-10-30 16:47:54: [2024-10-30 16:47:54] iter = 17540, loss = 1.4145
2024-10-30 16:47:54: [2024-10-30 16:47:54] iter = 17550, loss = 20.1765
2024-10-30 16:47:55: [2024-10-30 16:47:55] iter = 17560, loss = 5.5754
2024-10-30 16:47:56: [2024-10-30 16:47:56] iter = 17570, loss = 1.2739
2024-10-30 16:47:57: [2024-10-30 16:47:57] iter = 17580, loss = 5.9535
2024-10-30 16:47:58: [2024-10-30 16:47:58] iter = 17590, loss = 11.4470
2024-10-30 16:47:58: [2024-10-30 16:47:58] iter = 17600, loss = 1.3144
2024-10-30 16:47:59: [2024-10-30 16:47:59] iter = 17610, loss = 4.3183
2024-10-30 16:48:00: [2024-10-30 16:48:00] iter = 17620, loss = 9.5449
2024-10-30 16:48:01: [2024-10-30 16:48:01] iter = 17630, loss = 1.6363
2024-10-30 16:48:02: [2024-10-30 16:48:02] iter = 17640, loss = 5.6689
2024-10-30 16:48:02: [2024-10-30 16:48:02] iter = 17650, loss = 2.0357
2024-10-30 16:48:03: [2024-10-30 16:48:03] iter = 17660, loss = 1.5166
2024-10-30 16:48:04: [2024-10-30 16:48:04] iter = 17670, loss = 8.2345
2024-10-30 16:48:05: [2024-10-30 16:48:05] iter = 17680, loss = 17.2366
2024-10-30 16:48:06: [2024-10-30 16:48:06] iter = 17690, loss = 1.4148
2024-10-30 16:48:07: [2024-10-30 16:48:07] iter = 17700, loss = 3.1209
2024-10-30 16:48:07: [2024-10-30 16:48:07] iter = 17710, loss = 8.9450
2024-10-30 16:48:08: [2024-10-30 16:48:08] iter = 17720, loss = 4.2515
2024-10-30 16:48:08: [2024-10-30 16:48:08] iter = 17730, loss = 1.7786
2024-10-30 16:48:09: [2024-10-30 16:48:09] iter = 17740, loss = 2.3487
2024-10-30 16:48:10: [2024-10-30 16:48:10] iter = 17750, loss = 2.7841
2024-10-30 16:48:10: [2024-10-30 16:48:10] iter = 17760, loss = 1.9676
2024-10-30 16:48:11: [2024-10-30 16:48:11] iter = 17770, loss = 3.0178
2024-10-30 16:48:11: [2024-10-30 16:48:11] iter = 17780, loss = 6.9249
2024-10-30 16:48:12: [2024-10-30 16:48:12] iter = 17790, loss = 1.0665
2024-10-30 16:48:13: [2024-10-30 16:48:13] iter = 17800, loss = 11.8866
2024-10-30 16:48:13: [2024-10-30 16:48:13] iter = 17810, loss = 9.2418
2024-10-30 16:48:14: [2024-10-30 16:48:14] iter = 17820, loss = 11.2582
2024-10-30 16:48:14: [2024-10-30 16:48:14] iter = 17830, loss = 2.8020
2024-10-30 16:48:15: [2024-10-30 16:48:15] iter = 17840, loss = 1.7010
2024-10-30 16:48:16: [2024-10-30 16:48:16] iter = 17850, loss = 12.0832
2024-10-30 16:48:17: [2024-10-30 16:48:17] iter = 17860, loss = 4.7216
2024-10-30 16:48:18: [2024-10-30 16:48:18] iter = 17870, loss = 2.7190
2024-10-30 16:48:19: [2024-10-30 16:48:19] iter = 17880, loss = 4.4036
2024-10-30 16:48:20: [2024-10-30 16:48:20] iter = 17890, loss = 4.4799
2024-10-30 16:48:21: [2024-10-30 16:48:21] iter = 17900, loss = 2.7017
2024-10-30 16:48:22: [2024-10-30 16:48:22] iter = 17910, loss = 2.5227
2024-10-30 16:48:23: [2024-10-30 16:48:23] iter = 17920, loss = 6.5195
2024-10-30 16:48:24: [2024-10-30 16:48:24] iter = 17930, loss = 1.4100
2024-10-30 16:48:24: [2024-10-30 16:48:24] iter = 17940, loss = 3.1961
2024-10-30 16:48:25: [2024-10-30 16:48:25] iter = 17950, loss = 3.2963
2024-10-30 16:48:26: [2024-10-30 16:48:26] iter = 17960, loss = 1.3936
2024-10-30 16:48:27: [2024-10-30 16:48:27] iter = 17970, loss = 1.3872
2024-10-30 16:48:28: [2024-10-30 16:48:28] iter = 17980, loss = 1.3633
2024-10-30 16:48:28: [2024-10-30 16:48:28] iter = 17990, loss = 4.8562
2024-10-30 16:48:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 16:48:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:48:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 9802}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:49:57: Evaluate 5 random ConvNet, ACCmean = 0.5192 ACCstd = 0.0107
-------------------------
2024-10-30 16:49:57: Evaluate 5 random ConvNet, SENmean = 0.6274 SENstd = 0.0077
-------------------------
2024-10-30 16:49:57: Evaluate 5 random ConvNet, SPEmean = 0.6274 SPEstd = 0.0077
-------------------------
2024-10-30 16:49:57: Evaluate 5 random ConvNet, F!mean = 0.5176 F!std = 0.0100
-------------------------
2024-10-30 16:49:57: Evaluate 5 random ConvNet, mean = 0.5192 std = 0.0107
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:49:57: [2024-10-30 16:49:57] iter = 18000, loss = 8.0088
2024-10-30 16:49:58: [2024-10-30 16:49:58] iter = 18010, loss = 1.9820
2024-10-30 16:49:59: [2024-10-30 16:49:59] iter = 18020, loss = 4.0232
2024-10-30 16:50:00: [2024-10-30 16:50:00] iter = 18030, loss = 3.6142
2024-10-30 16:50:00: [2024-10-30 16:50:00] iter = 18040, loss = 10.9272
2024-10-30 16:50:01: [2024-10-30 16:50:01] iter = 18050, loss = 2.4634
2024-10-30 16:50:02: [2024-10-30 16:50:02] iter = 18060, loss = 2.0403
2024-10-30 16:50:03: [2024-10-30 16:50:03] iter = 18070, loss = 2.5287
2024-10-30 16:50:04: [2024-10-30 16:50:04] iter = 18080, loss = 4.1328
2024-10-30 16:50:05: [2024-10-30 16:50:05] iter = 18090, loss = 2.3469
2024-10-30 16:50:06: [2024-10-30 16:50:06] iter = 18100, loss = 4.8964
2024-10-30 16:50:07: [2024-10-30 16:50:07] iter = 18110, loss = 6.8219
2024-10-30 16:50:07: [2024-10-30 16:50:07] iter = 18120, loss = 1.6629
2024-10-30 16:50:08: [2024-10-30 16:50:08] iter = 18130, loss = 2.7717
2024-10-30 16:50:09: [2024-10-30 16:50:09] iter = 18140, loss = 6.1205
2024-10-30 16:50:10: [2024-10-30 16:50:10] iter = 18150, loss = 1.6684
2024-10-30 16:50:11: [2024-10-30 16:50:11] iter = 18160, loss = 2.9957
2024-10-30 16:50:11: [2024-10-30 16:50:11] iter = 18170, loss = 2.2093
2024-10-30 16:50:12: [2024-10-30 16:50:12] iter = 18180, loss = 16.4450
2024-10-30 16:50:13: [2024-10-30 16:50:13] iter = 18190, loss = 3.5505
2024-10-30 16:50:14: [2024-10-30 16:50:14] iter = 18200, loss = 8.8084
2024-10-30 16:50:15: [2024-10-30 16:50:15] iter = 18210, loss = 1.4689
2024-10-30 16:50:16: [2024-10-30 16:50:16] iter = 18220, loss = 3.0907
2024-10-30 16:50:16: [2024-10-30 16:50:16] iter = 18230, loss = 1.9444
2024-10-30 16:50:17: [2024-10-30 16:50:17] iter = 18240, loss = 1.5239
2024-10-30 16:50:18: [2024-10-30 16:50:18] iter = 18250, loss = 7.8896
2024-10-30 16:50:19: [2024-10-30 16:50:19] iter = 18260, loss = 5.1261
2024-10-30 16:50:19: [2024-10-30 16:50:19] iter = 18270, loss = 1.6719
2024-10-30 16:50:20: [2024-10-30 16:50:20] iter = 18280, loss = 2.5584
2024-10-30 16:50:21: [2024-10-30 16:50:21] iter = 18290, loss = 7.4166
2024-10-30 16:50:22: [2024-10-30 16:50:22] iter = 18300, loss = 16.5832
2024-10-30 16:50:23: [2024-10-30 16:50:23] iter = 18310, loss = 3.6065
2024-10-30 16:50:24: [2024-10-30 16:50:24] iter = 18320, loss = 1.9663
2024-10-30 16:50:24: [2024-10-30 16:50:24] iter = 18330, loss = 2.7749
2024-10-30 16:50:25: [2024-10-30 16:50:25] iter = 18340, loss = 5.8510
2024-10-30 16:50:26: [2024-10-30 16:50:26] iter = 18350, loss = 1.7522
2024-10-30 16:50:27: [2024-10-30 16:50:27] iter = 18360, loss = 1.0639
2024-10-30 16:50:27: [2024-10-30 16:50:27] iter = 18370, loss = 4.1285
2024-10-30 16:50:28: [2024-10-30 16:50:28] iter = 18380, loss = 5.4891
2024-10-30 16:50:29: [2024-10-30 16:50:29] iter = 18390, loss = 6.0275
2024-10-30 16:50:30: [2024-10-30 16:50:30] iter = 18400, loss = 1.9677
2024-10-30 16:50:31: [2024-10-30 16:50:31] iter = 18410, loss = 2.2821
2024-10-30 16:50:32: [2024-10-30 16:50:32] iter = 18420, loss = 2.1550
2024-10-30 16:50:33: [2024-10-30 16:50:33] iter = 18430, loss = 5.6008
2024-10-30 16:50:34: [2024-10-30 16:50:34] iter = 18440, loss = 1.2924
2024-10-30 16:50:34: [2024-10-30 16:50:34] iter = 18450, loss = 2.1568
2024-10-30 16:50:35: [2024-10-30 16:50:35] iter = 18460, loss = 3.4984
2024-10-30 16:50:36: [2024-10-30 16:50:36] iter = 18470, loss = 20.8318
2024-10-30 16:50:37: [2024-10-30 16:50:37] iter = 18480, loss = 2.4029
2024-10-30 16:50:37: [2024-10-30 16:50:37] iter = 18490, loss = 3.7906
2024-10-30 16:50:38: [2024-10-30 16:50:38] iter = 18500, loss = 5.3169
2024-10-30 16:50:39: [2024-10-30 16:50:39] iter = 18510, loss = 2.3331
2024-10-30 16:50:40: [2024-10-30 16:50:40] iter = 18520, loss = 17.6721
2024-10-30 16:50:41: [2024-10-30 16:50:41] iter = 18530, loss = 3.4177
2024-10-30 16:50:42: [2024-10-30 16:50:42] iter = 18540, loss = 2.1834
2024-10-30 16:50:42: [2024-10-30 16:50:42] iter = 18550, loss = 8.8349
2024-10-30 16:50:43: [2024-10-30 16:50:43] iter = 18560, loss = 1.5656
2024-10-30 16:50:44: [2024-10-30 16:50:44] iter = 18570, loss = 3.3382
2024-10-30 16:50:45: [2024-10-30 16:50:45] iter = 18580, loss = 11.0229
2024-10-30 16:50:45: [2024-10-30 16:50:45] iter = 18590, loss = 1.8288
2024-10-30 16:50:46: [2024-10-30 16:50:46] iter = 18600, loss = 1.3416
2024-10-30 16:50:47: [2024-10-30 16:50:47] iter = 18610, loss = 19.4696
2024-10-30 16:50:47: [2024-10-30 16:50:47] iter = 18620, loss = 3.8147
2024-10-30 16:50:48: [2024-10-30 16:50:48] iter = 18630, loss = 3.9125
2024-10-30 16:50:49: [2024-10-30 16:50:49] iter = 18640, loss = 4.2061
2024-10-30 16:50:50: [2024-10-30 16:50:50] iter = 18650, loss = 1.3311
2024-10-30 16:50:51: [2024-10-30 16:50:51] iter = 18660, loss = 11.2678
2024-10-30 16:50:52: [2024-10-30 16:50:52] iter = 18670, loss = 3.8798
2024-10-30 16:50:53: [2024-10-30 16:50:53] iter = 18680, loss = 1.2801
2024-10-30 16:50:54: [2024-10-30 16:50:54] iter = 18690, loss = 1.5609
2024-10-30 16:50:55: [2024-10-30 16:50:55] iter = 18700, loss = 1.7503
2024-10-30 16:50:56: [2024-10-30 16:50:56] iter = 18710, loss = 3.2034
2024-10-30 16:50:57: [2024-10-30 16:50:57] iter = 18720, loss = 11.9863
2024-10-30 16:50:58: [2024-10-30 16:50:58] iter = 18730, loss = 3.4319
2024-10-30 16:50:58: [2024-10-30 16:50:58] iter = 18740, loss = 1.6047
2024-10-30 16:51:00: [2024-10-30 16:51:00] iter = 18750, loss = 1.2699
2024-10-30 16:51:01: [2024-10-30 16:51:01] iter = 18760, loss = 1.9006
2024-10-30 16:51:01: [2024-10-30 16:51:01] iter = 18770, loss = 2.4674
2024-10-30 16:51:02: [2024-10-30 16:51:02] iter = 18780, loss = 2.3498
2024-10-30 16:51:03: [2024-10-30 16:51:03] iter = 18790, loss = 16.1653
2024-10-30 16:51:04: [2024-10-30 16:51:04] iter = 18800, loss = 3.2407
2024-10-30 16:51:04: [2024-10-30 16:51:04] iter = 18810, loss = 24.9119
2024-10-30 16:51:05: [2024-10-30 16:51:05] iter = 18820, loss = 6.2845
2024-10-30 16:51:06: [2024-10-30 16:51:06] iter = 18830, loss = 2.0252
2024-10-30 16:51:07: [2024-10-30 16:51:07] iter = 18840, loss = 1.4221
2024-10-30 16:51:09: [2024-10-30 16:51:09] iter = 18850, loss = 4.7548
2024-10-30 16:51:09: [2024-10-30 16:51:09] iter = 18860, loss = 1.8100
2024-10-30 16:51:10: [2024-10-30 16:51:10] iter = 18870, loss = 1.8783
2024-10-30 16:51:11: [2024-10-30 16:51:11] iter = 18880, loss = 3.4293
2024-10-30 16:51:12: [2024-10-30 16:51:12] iter = 18890, loss = 2.7606
2024-10-30 16:51:13: [2024-10-30 16:51:13] iter = 18900, loss = 1.5402
2024-10-30 16:51:14: [2024-10-30 16:51:14] iter = 18910, loss = 1.1194
2024-10-30 16:51:15: [2024-10-30 16:51:15] iter = 18920, loss = 1.2948
2024-10-30 16:51:15: [2024-10-30 16:51:15] iter = 18930, loss = 1.1619
2024-10-30 16:51:17: [2024-10-30 16:51:17] iter = 18940, loss = 0.9620
2024-10-30 16:51:17: [2024-10-30 16:51:17] iter = 18950, loss = 1.2930
2024-10-30 16:51:18: [2024-10-30 16:51:18] iter = 18960, loss = 2.2040
2024-10-30 16:51:19: [2024-10-30 16:51:19] iter = 18970, loss = 2.9278
2024-10-30 16:51:20: [2024-10-30 16:51:20] iter = 18980, loss = 3.7895
2024-10-30 16:51:21: [2024-10-30 16:51:21] iter = 18990, loss = 6.3572
2024-10-30 16:51:22: [2024-10-30 16:51:22] iter = 19000, loss = 2.3350
2024-10-30 16:51:23: [2024-10-30 16:51:23] iter = 19010, loss = 4.5741
2024-10-30 16:51:24: [2024-10-30 16:51:24] iter = 19020, loss = 2.9729
2024-10-30 16:51:25: [2024-10-30 16:51:25] iter = 19030, loss = 11.3953
2024-10-30 16:51:26: [2024-10-30 16:51:26] iter = 19040, loss = 3.1902
2024-10-30 16:51:27: [2024-10-30 16:51:27] iter = 19050, loss = 1.5656
2024-10-30 16:51:28: [2024-10-30 16:51:28] iter = 19060, loss = 2.0712
2024-10-30 16:51:28: [2024-10-30 16:51:28] iter = 19070, loss = 2.4686
2024-10-30 16:51:28: [2024-10-30 16:51:28] iter = 19080, loss = 1.5374
2024-10-30 16:51:29: [2024-10-30 16:51:29] iter = 19090, loss = 4.3590
2024-10-30 16:51:30: [2024-10-30 16:51:30] iter = 19100, loss = 5.2417
2024-10-30 16:51:31: [2024-10-30 16:51:31] iter = 19110, loss = 1.3833
2024-10-30 16:51:32: [2024-10-30 16:51:32] iter = 19120, loss = 2.7718
2024-10-30 16:51:32: [2024-10-30 16:51:32] iter = 19130, loss = 5.8163
2024-10-30 16:51:33: [2024-10-30 16:51:33] iter = 19140, loss = 2.0035
2024-10-30 16:51:34: [2024-10-30 16:51:34] iter = 19150, loss = 2.0845
2024-10-30 16:51:35: [2024-10-30 16:51:35] iter = 19160, loss = 2.0379
2024-10-30 16:51:36: [2024-10-30 16:51:36] iter = 19170, loss = 25.2814
2024-10-30 16:51:37: [2024-10-30 16:51:37] iter = 19180, loss = 1.6233
2024-10-30 16:51:37: [2024-10-30 16:51:37] iter = 19190, loss = 2.8335
2024-10-30 16:51:38: [2024-10-30 16:51:38] iter = 19200, loss = 3.2668
2024-10-30 16:51:39: [2024-10-30 16:51:39] iter = 19210, loss = 2.3111
2024-10-30 16:51:39: [2024-10-30 16:51:39] iter = 19220, loss = 1.5847
2024-10-30 16:51:40: [2024-10-30 16:51:40] iter = 19230, loss = 4.4110
2024-10-30 16:51:41: [2024-10-30 16:51:41] iter = 19240, loss = 37.7016
2024-10-30 16:51:42: [2024-10-30 16:51:42] iter = 19250, loss = 7.1518
2024-10-30 16:51:43: [2024-10-30 16:51:43] iter = 19260, loss = 2.1140
2024-10-30 16:51:44: [2024-10-30 16:51:44] iter = 19270, loss = 4.2350
2024-10-30 16:51:45: [2024-10-30 16:51:45] iter = 19280, loss = 18.7095
2024-10-30 16:51:45: [2024-10-30 16:51:45] iter = 19290, loss = 16.9256
2024-10-30 16:51:46: [2024-10-30 16:51:46] iter = 19300, loss = 2.1448
2024-10-30 16:51:46: [2024-10-30 16:51:46] iter = 19310, loss = 2.1724
2024-10-30 16:51:47: [2024-10-30 16:51:47] iter = 19320, loss = 1.2292
2024-10-30 16:51:48: [2024-10-30 16:51:48] iter = 19330, loss = 12.6061
2024-10-30 16:51:49: [2024-10-30 16:51:49] iter = 19340, loss = 1.4841
2024-10-30 16:51:50: [2024-10-30 16:51:50] iter = 19350, loss = 2.2222
2024-10-30 16:51:50: [2024-10-30 16:51:50] iter = 19360, loss = 1.6230
2024-10-30 16:51:52: [2024-10-30 16:51:52] iter = 19370, loss = 2.5936
2024-10-30 16:51:53: [2024-10-30 16:51:53] iter = 19380, loss = 18.2277
2024-10-30 16:51:54: [2024-10-30 16:51:54] iter = 19390, loss = 1.9979
2024-10-30 16:51:55: [2024-10-30 16:51:55] iter = 19400, loss = 2.0848
2024-10-30 16:51:55: [2024-10-30 16:51:55] iter = 19410, loss = 2.0904
2024-10-30 16:51:56: [2024-10-30 16:51:56] iter = 19420, loss = 1.7955
2024-10-30 16:51:57: [2024-10-30 16:51:57] iter = 19430, loss = 2.2422
2024-10-30 16:51:58: [2024-10-30 16:51:58] iter = 19440, loss = 2.9839
2024-10-30 16:51:59: [2024-10-30 16:51:59] iter = 19450, loss = 1.5844
2024-10-30 16:52:00: [2024-10-30 16:52:00] iter = 19460, loss = 1.0520
2024-10-30 16:52:01: [2024-10-30 16:52:01] iter = 19470, loss = 3.3434
2024-10-30 16:52:01: [2024-10-30 16:52:01] iter = 19480, loss = 5.3261
2024-10-30 16:52:03: [2024-10-30 16:52:03] iter = 19490, loss = 0.9556
2024-10-30 16:52:04: [2024-10-30 16:52:04] iter = 19500, loss = 2.3411
2024-10-30 16:52:04: [2024-10-30 16:52:04] iter = 19510, loss = 1.2704
2024-10-30 16:52:05: [2024-10-30 16:52:05] iter = 19520, loss = 7.4708
2024-10-30 16:52:06: [2024-10-30 16:52:06] iter = 19530, loss = 4.4376
2024-10-30 16:52:07: [2024-10-30 16:52:07] iter = 19540, loss = 2.9337
2024-10-30 16:52:08: [2024-10-30 16:52:08] iter = 19550, loss = 4.4422
2024-10-30 16:52:08: [2024-10-30 16:52:08] iter = 19560, loss = 4.3390
2024-10-30 16:52:09: [2024-10-30 16:52:09] iter = 19570, loss = 8.5841
2024-10-30 16:52:10: [2024-10-30 16:52:10] iter = 19580, loss = 16.8605
2024-10-30 16:52:11: [2024-10-30 16:52:11] iter = 19590, loss = 7.8348
2024-10-30 16:52:12: [2024-10-30 16:52:12] iter = 19600, loss = 2.3470
2024-10-30 16:52:13: [2024-10-30 16:52:13] iter = 19610, loss = 1.8891
2024-10-30 16:52:15: [2024-10-30 16:52:15] iter = 19620, loss = 1.6114
2024-10-30 16:52:16: [2024-10-30 16:52:16] iter = 19630, loss = 1.3197
2024-10-30 16:52:17: [2024-10-30 16:52:16] iter = 19640, loss = 2.5327
2024-10-30 16:52:18: [2024-10-30 16:52:18] iter = 19650, loss = 2.9478
2024-10-30 16:52:18: [2024-10-30 16:52:18] iter = 19660, loss = 3.0339
2024-10-30 16:52:19: [2024-10-30 16:52:19] iter = 19670, loss = 1.9120
2024-10-30 16:52:20: [2024-10-30 16:52:20] iter = 19680, loss = 1.1519
2024-10-30 16:52:21: [2024-10-30 16:52:21] iter = 19690, loss = 1.6174
2024-10-30 16:52:22: [2024-10-30 16:52:22] iter = 19700, loss = 2.3469
2024-10-30 16:52:23: [2024-10-30 16:52:23] iter = 19710, loss = 1.3556
2024-10-30 16:52:24: [2024-10-30 16:52:24] iter = 19720, loss = 4.9153
2024-10-30 16:52:25: [2024-10-30 16:52:25] iter = 19730, loss = 7.5189
2024-10-30 16:52:26: [2024-10-30 16:52:26] iter = 19740, loss = 11.0808
2024-10-30 16:52:27: [2024-10-30 16:52:27] iter = 19750, loss = 1.3808
2024-10-30 16:52:28: [2024-10-30 16:52:28] iter = 19760, loss = 1.8175
2024-10-30 16:52:29: [2024-10-30 16:52:29] iter = 19770, loss = 1.5614
2024-10-30 16:52:29: [2024-10-30 16:52:29] iter = 19780, loss = 1.0053
2024-10-30 16:52:30: [2024-10-30 16:52:30] iter = 19790, loss = 1.0435
2024-10-30 16:52:31: [2024-10-30 16:52:31] iter = 19800, loss = 1.2999
2024-10-30 16:52:32: [2024-10-30 16:52:32] iter = 19810, loss = 1.9731
2024-10-30 16:52:33: [2024-10-30 16:52:33] iter = 19820, loss = 5.2386
2024-10-30 16:52:34: [2024-10-30 16:52:34] iter = 19830, loss = 2.5866
2024-10-30 16:52:35: [2024-10-30 16:52:35] iter = 19840, loss = 1.4033
2024-10-30 16:52:36: [2024-10-30 16:52:36] iter = 19850, loss = 1.5888
2024-10-30 16:52:37: [2024-10-30 16:52:37] iter = 19860, loss = 8.0839
2024-10-30 16:52:38: [2024-10-30 16:52:38] iter = 19870, loss = 1.7657
2024-10-30 16:52:39: [2024-10-30 16:52:39] iter = 19880, loss = 5.7925
2024-10-30 16:52:39: [2024-10-30 16:52:39] iter = 19890, loss = 2.0758
2024-10-30 16:52:40: [2024-10-30 16:52:40] iter = 19900, loss = 1.5171
2024-10-30 16:52:40: [2024-10-30 16:52:40] iter = 19910, loss = 1.8543
2024-10-30 16:52:41: [2024-10-30 16:52:41] iter = 19920, loss = 5.8872
2024-10-30 16:52:42: [2024-10-30 16:52:42] iter = 19930, loss = 3.2887
2024-10-30 16:52:43: [2024-10-30 16:52:43] iter = 19940, loss = 1.4894
2024-10-30 16:52:44: [2024-10-30 16:52:44] iter = 19950, loss = 2.4737
2024-10-30 16:52:44: [2024-10-30 16:52:44] iter = 19960, loss = 1.7882
2024-10-30 16:52:45: [2024-10-30 16:52:45] iter = 19970, loss = 2.1616
2024-10-30 16:52:46: [2024-10-30 16:52:46] iter = 19980, loss = 3.2610
2024-10-30 16:52:47: [2024-10-30 16:52:47] iter = 19990, loss = 2.7229
2024-10-30 16:52:48: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 16:52:48: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:52:48: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 68379}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:54:13: Evaluate 5 random ConvNet, ACCmean = 0.6974 ACCstd = 0.0196
-------------------------
2024-10-30 16:54:13: Evaluate 5 random ConvNet, SENmean = 0.6125 SENstd = 0.0243
-------------------------
2024-10-30 16:54:13: Evaluate 5 random ConvNet, SPEmean = 0.6125 SPEstd = 0.0243
-------------------------
2024-10-30 16:54:13: Evaluate 5 random ConvNet, F!mean = 0.6129 F!std = 0.0240
-------------------------
2024-10-30 16:54:13: Evaluate 5 random ConvNet, mean = 0.6974 std = 0.0196
-------------------------
2024-10-30 16:54:13: [2024-10-30 16:54:13] iter = 20000, loss = 4.7979
2024-10-30 16:54:13: 
================== Exp 4 ==================
 
2024-10-30 16:54:13: Hyper-parameters: 
{'dataset': 'BreastMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ff878e0ab20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_BreastMNIST (INFO)>}
2024-10-30 16:54:13: Evaluation model pool: ['ConvNet']
2024-10-30 16:54:13: class c = 0: 147 real images
2024-10-30 16:54:13: class c = 1: 399 real images
2024-10-30 16:54:13: real images channel 0, mean = 0.3276, std = 0.2057
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 16:54:13: initialize synthetic data from random real images
2024-10-30 16:54:13: [2024-10-30 16:54:13] training begins
2024-10-30 16:54:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 16:54:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:54:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53110}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:55:39: Evaluate 5 random ConvNet, ACCmean = 0.6718 ACCstd = 0.0063
-------------------------
2024-10-30 16:55:39: Evaluate 5 random ConvNet, SENmean = 0.6566 SENstd = 0.0157
-------------------------
2024-10-30 16:55:39: Evaluate 5 random ConvNet, SPEmean = 0.6566 SPEstd = 0.0157
-------------------------
2024-10-30 16:55:39: Evaluate 5 random ConvNet, F!mean = 0.6297 F!std = 0.0094
-------------------------
2024-10-30 16:55:39: Evaluate 5 random ConvNet, mean = 0.6718 std = 0.0063
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:55:39: [2024-10-30 16:55:39] iter = 00000, loss = 27.7961
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:55:40: [2024-10-30 16:55:40] iter = 00010, loss = 14.1369
2024-10-30 16:55:40: [2024-10-30 16:55:40] iter = 00020, loss = 7.6490
2024-10-30 16:55:41: [2024-10-30 16:55:41] iter = 00030, loss = 2.0727
2024-10-30 16:55:42: [2024-10-30 16:55:42] iter = 00040, loss = 1.6922
2024-10-30 16:55:43: [2024-10-30 16:55:43] iter = 00050, loss = 2.7097
2024-10-30 16:55:44: [2024-10-30 16:55:44] iter = 00060, loss = 3.4314
2024-10-30 16:55:45: [2024-10-30 16:55:45] iter = 00070, loss = 1.7751
2024-10-30 16:55:46: [2024-10-30 16:55:46] iter = 00080, loss = 2.2274
2024-10-30 16:55:47: [2024-10-30 16:55:47] iter = 00090, loss = 8.5209
2024-10-30 16:55:48: [2024-10-30 16:55:48] iter = 00100, loss = 3.8995
2024-10-30 16:55:49: [2024-10-30 16:55:49] iter = 00110, loss = 12.3913
2024-10-30 16:55:50: [2024-10-30 16:55:50] iter = 00120, loss = 6.1336
2024-10-30 16:55:50: [2024-10-30 16:55:50] iter = 00130, loss = 3.1099
2024-10-30 16:55:51: [2024-10-30 16:55:51] iter = 00140, loss = 11.9002
2024-10-30 16:55:52: [2024-10-30 16:55:52] iter = 00150, loss = 3.5980
2024-10-30 16:55:52: [2024-10-30 16:55:52] iter = 00160, loss = 2.1762
2024-10-30 16:55:53: [2024-10-30 16:55:53] iter = 00170, loss = 1.7784
2024-10-30 16:55:54: [2024-10-30 16:55:54] iter = 00180, loss = 4.3481
2024-10-30 16:55:56: [2024-10-30 16:55:56] iter = 00190, loss = 6.3108
2024-10-30 16:55:57: [2024-10-30 16:55:57] iter = 00200, loss = 1.7479
2024-10-30 16:55:57: [2024-10-30 16:55:57] iter = 00210, loss = 4.2120
2024-10-30 16:55:58: [2024-10-30 16:55:58] iter = 00220, loss = 1.5434
2024-10-30 16:55:59: [2024-10-30 16:55:59] iter = 00230, loss = 2.5775
2024-10-30 16:56:00: [2024-10-30 16:56:00] iter = 00240, loss = 1.9711
2024-10-30 16:56:01: [2024-10-30 16:56:01] iter = 00250, loss = 2.9422
2024-10-30 16:56:02: [2024-10-30 16:56:02] iter = 00260, loss = 16.4304
2024-10-30 16:56:03: [2024-10-30 16:56:03] iter = 00270, loss = 4.6043
2024-10-30 16:56:04: [2024-10-30 16:56:04] iter = 00280, loss = 10.3176
2024-10-30 16:56:04: [2024-10-30 16:56:04] iter = 00290, loss = 31.5005
2024-10-30 16:56:05: [2024-10-30 16:56:05] iter = 00300, loss = 17.8644
2024-10-30 16:56:06: [2024-10-30 16:56:06] iter = 00310, loss = 13.6479
2024-10-30 16:56:07: [2024-10-30 16:56:07] iter = 00320, loss = 4.5321
2024-10-30 16:56:08: [2024-10-30 16:56:08] iter = 00330, loss = 3.3065
2024-10-30 16:56:09: [2024-10-30 16:56:09] iter = 00340, loss = 6.7775
2024-10-30 16:56:10: [2024-10-30 16:56:10] iter = 00350, loss = 1.8717
2024-10-30 16:56:11: [2024-10-30 16:56:11] iter = 00360, loss = 2.3729
2024-10-30 16:56:12: [2024-10-30 16:56:12] iter = 00370, loss = 5.3342
2024-10-30 16:56:13: [2024-10-30 16:56:13] iter = 00380, loss = 1.4800
2024-10-30 16:56:14: [2024-10-30 16:56:14] iter = 00390, loss = 16.5063
2024-10-30 16:56:15: [2024-10-30 16:56:15] iter = 00400, loss = 2.1765
2024-10-30 16:56:16: [2024-10-30 16:56:16] iter = 00410, loss = 1.7835
2024-10-30 16:56:16: [2024-10-30 16:56:16] iter = 00420, loss = 2.3667
2024-10-30 16:56:17: [2024-10-30 16:56:17] iter = 00430, loss = 2.4571
2024-10-30 16:56:18: [2024-10-30 16:56:18] iter = 00440, loss = 1.3882
2024-10-30 16:56:19: [2024-10-30 16:56:19] iter = 00450, loss = 6.6124
2024-10-30 16:56:19: [2024-10-30 16:56:19] iter = 00460, loss = 1.7101
2024-10-30 16:56:20: [2024-10-30 16:56:20] iter = 00470, loss = 3.0898
2024-10-30 16:56:21: [2024-10-30 16:56:21] iter = 00480, loss = 5.7335
2024-10-30 16:56:22: [2024-10-30 16:56:22] iter = 00490, loss = 4.9729
2024-10-30 16:56:22: [2024-10-30 16:56:22] iter = 00500, loss = 3.8996
2024-10-30 16:56:23: [2024-10-30 16:56:23] iter = 00510, loss = 1.5877
2024-10-30 16:56:24: [2024-10-30 16:56:24] iter = 00520, loss = 1.4491
2024-10-30 16:56:25: [2024-10-30 16:56:25] iter = 00530, loss = 2.7689
2024-10-30 16:56:26: [2024-10-30 16:56:26] iter = 00540, loss = 1.0778
2024-10-30 16:56:27: [2024-10-30 16:56:27] iter = 00550, loss = 1.8130
2024-10-30 16:56:28: [2024-10-30 16:56:28] iter = 00560, loss = 4.1778
2024-10-30 16:56:29: [2024-10-30 16:56:29] iter = 00570, loss = 1.8606
2024-10-30 16:56:30: [2024-10-30 16:56:30] iter = 00580, loss = 1.5041
2024-10-30 16:56:31: [2024-10-30 16:56:31] iter = 00590, loss = 5.1358
2024-10-30 16:56:32: [2024-10-30 16:56:32] iter = 00600, loss = 2.9800
2024-10-30 16:56:32: [2024-10-30 16:56:32] iter = 00610, loss = 1.5608
2024-10-30 16:56:33: [2024-10-30 16:56:33] iter = 00620, loss = 2.8446
2024-10-30 16:56:34: [2024-10-30 16:56:34] iter = 00630, loss = 3.1820
2024-10-30 16:56:35: [2024-10-30 16:56:35] iter = 00640, loss = 1.7640
2024-10-30 16:56:36: [2024-10-30 16:56:36] iter = 00650, loss = 5.7408
2024-10-30 16:56:37: [2024-10-30 16:56:37] iter = 00660, loss = 2.2269
2024-10-30 16:56:38: [2024-10-30 16:56:38] iter = 00670, loss = 5.6666
2024-10-30 16:56:39: [2024-10-30 16:56:39] iter = 00680, loss = 20.4074
2024-10-30 16:56:40: [2024-10-30 16:56:40] iter = 00690, loss = 5.2354
2024-10-30 16:56:41: [2024-10-30 16:56:41] iter = 00700, loss = 2.4518
2024-10-30 16:56:41: [2024-10-30 16:56:41] iter = 00710, loss = 6.4175
2024-10-30 16:56:42: [2024-10-30 16:56:42] iter = 00720, loss = 2.1349
2024-10-30 16:56:43: [2024-10-30 16:56:43] iter = 00730, loss = 1.8983
2024-10-30 16:56:43: [2024-10-30 16:56:43] iter = 00740, loss = 1.4664
2024-10-30 16:56:44: [2024-10-30 16:56:44] iter = 00750, loss = 3.8895
2024-10-30 16:56:44: [2024-10-30 16:56:44] iter = 00760, loss = 1.4430
2024-10-30 16:56:45: [2024-10-30 16:56:45] iter = 00770, loss = 1.7704
2024-10-30 16:56:46: [2024-10-30 16:56:46] iter = 00780, loss = 1.6675
2024-10-30 16:56:47: [2024-10-30 16:56:47] iter = 00790, loss = 1.3983
2024-10-30 16:56:47: [2024-10-30 16:56:47] iter = 00800, loss = 10.2424
2024-10-30 16:56:49: [2024-10-30 16:56:49] iter = 00810, loss = 2.3337
2024-10-30 16:56:49: [2024-10-30 16:56:49] iter = 00820, loss = 4.3012
2024-10-30 16:56:50: [2024-10-30 16:56:50] iter = 00830, loss = 5.0179
2024-10-30 16:56:51: [2024-10-30 16:56:51] iter = 00840, loss = 4.0866
2024-10-30 16:56:51: [2024-10-30 16:56:51] iter = 00850, loss = 1.4504
2024-10-30 16:56:52: [2024-10-30 16:56:52] iter = 00860, loss = 3.9497
2024-10-30 16:56:53: [2024-10-30 16:56:53] iter = 00870, loss = 4.7730
2024-10-30 16:56:54: [2024-10-30 16:56:54] iter = 00880, loss = 2.3377
2024-10-30 16:56:55: [2024-10-30 16:56:55] iter = 00890, loss = 17.5252
2024-10-30 16:56:56: [2024-10-30 16:56:56] iter = 00900, loss = 2.7709
2024-10-30 16:56:57: [2024-10-30 16:56:57] iter = 00910, loss = 14.3503
2024-10-30 16:56:58: [2024-10-30 16:56:58] iter = 00920, loss = 8.8708
2024-10-30 16:56:58: [2024-10-30 16:56:58] iter = 00930, loss = 1.7787
2024-10-30 16:56:59: [2024-10-30 16:56:59] iter = 00940, loss = 2.2633
2024-10-30 16:57:00: [2024-10-30 16:57:00] iter = 00950, loss = 2.2980
2024-10-30 16:57:01: [2024-10-30 16:57:01] iter = 00960, loss = 8.7148
2024-10-30 16:57:02: [2024-10-30 16:57:02] iter = 00970, loss = 1.5419
2024-10-30 16:57:03: [2024-10-30 16:57:03] iter = 00980, loss = 1.0899
2024-10-30 16:57:04: [2024-10-30 16:57:04] iter = 00990, loss = 48.1422
2024-10-30 16:57:05: [2024-10-30 16:57:05] iter = 01000, loss = 4.8679
2024-10-30 16:57:06: [2024-10-30 16:57:06] iter = 01010, loss = 1.4223
2024-10-30 16:57:07: [2024-10-30 16:57:07] iter = 01020, loss = 1.6095
2024-10-30 16:57:07: [2024-10-30 16:57:07] iter = 01030, loss = 9.9718
2024-10-30 16:57:08: [2024-10-30 16:57:08] iter = 01040, loss = 2.5969
2024-10-30 16:57:09: [2024-10-30 16:57:09] iter = 01050, loss = 1.1121
2024-10-30 16:57:09: [2024-10-30 16:57:09] iter = 01060, loss = 1.2692
2024-10-30 16:57:10: [2024-10-30 16:57:10] iter = 01070, loss = 4.4767
2024-10-30 16:57:11: [2024-10-30 16:57:11] iter = 01080, loss = 18.4231
2024-10-30 16:57:12: [2024-10-30 16:57:12] iter = 01090, loss = 4.0618
2024-10-30 16:57:13: [2024-10-30 16:57:13] iter = 01100, loss = 1.8806
2024-10-30 16:57:13: [2024-10-30 16:57:13] iter = 01110, loss = 1.8195
2024-10-30 16:57:14: [2024-10-30 16:57:14] iter = 01120, loss = 1.1129
2024-10-30 16:57:16: [2024-10-30 16:57:16] iter = 01130, loss = 2.5834
2024-10-30 16:57:16: [2024-10-30 16:57:16] iter = 01140, loss = 2.0232
2024-10-30 16:57:18: [2024-10-30 16:57:18] iter = 01150, loss = 1.8655
2024-10-30 16:57:19: [2024-10-30 16:57:19] iter = 01160, loss = 2.1646
2024-10-30 16:57:19: [2024-10-30 16:57:19] iter = 01170, loss = 7.7875
2024-10-30 16:57:20: [2024-10-30 16:57:20] iter = 01180, loss = 3.4192
2024-10-30 16:57:22: [2024-10-30 16:57:22] iter = 01190, loss = 4.7663
2024-10-30 16:57:22: [2024-10-30 16:57:22] iter = 01200, loss = 31.7908
2024-10-30 16:57:24: [2024-10-30 16:57:24] iter = 01210, loss = 2.8045
2024-10-30 16:57:24: [2024-10-30 16:57:24] iter = 01220, loss = 4.3594
2024-10-30 16:57:25: [2024-10-30 16:57:25] iter = 01230, loss = 1.5135
2024-10-30 16:57:26: [2024-10-30 16:57:26] iter = 01240, loss = 4.6912
2024-10-30 16:57:27: [2024-10-30 16:57:27] iter = 01250, loss = 1.5302
2024-10-30 16:57:28: [2024-10-30 16:57:28] iter = 01260, loss = 1.3802
2024-10-30 16:57:29: [2024-10-30 16:57:29] iter = 01270, loss = 1.3288
2024-10-30 16:57:30: [2024-10-30 16:57:30] iter = 01280, loss = 4.7089
2024-10-30 16:57:31: [2024-10-30 16:57:31] iter = 01290, loss = 2.5188
2024-10-30 16:57:32: [2024-10-30 16:57:32] iter = 01300, loss = 1.7228
2024-10-30 16:57:33: [2024-10-30 16:57:33] iter = 01310, loss = 9.1649
2024-10-30 16:57:34: [2024-10-30 16:57:34] iter = 01320, loss = 3.6311
2024-10-30 16:57:35: [2024-10-30 16:57:35] iter = 01330, loss = 15.5604
2024-10-30 16:57:36: [2024-10-30 16:57:36] iter = 01340, loss = 5.4173
2024-10-30 16:57:37: [2024-10-30 16:57:37] iter = 01350, loss = 3.7475
2024-10-30 16:57:38: [2024-10-30 16:57:38] iter = 01360, loss = 1.7102
2024-10-30 16:57:39: [2024-10-30 16:57:39] iter = 01370, loss = 3.7250
2024-10-30 16:57:39: [2024-10-30 16:57:39] iter = 01380, loss = 8.9106
2024-10-30 16:57:40: [2024-10-30 16:57:40] iter = 01390, loss = 2.7849
2024-10-30 16:57:41: [2024-10-30 16:57:41] iter = 01400, loss = 3.4839
2024-10-30 16:57:42: [2024-10-30 16:57:42] iter = 01410, loss = 3.0842
2024-10-30 16:57:43: [2024-10-30 16:57:43] iter = 01420, loss = 6.1564
2024-10-30 16:57:44: [2024-10-30 16:57:44] iter = 01430, loss = 5.3760
2024-10-30 16:57:45: [2024-10-30 16:57:45] iter = 01440, loss = 15.0959
2024-10-30 16:57:45: [2024-10-30 16:57:45] iter = 01450, loss = 2.8686
2024-10-30 16:57:46: [2024-10-30 16:57:46] iter = 01460, loss = 3.2881
2024-10-30 16:57:47: [2024-10-30 16:57:47] iter = 01470, loss = 4.5069
2024-10-30 16:57:47: [2024-10-30 16:57:47] iter = 01480, loss = 1.5771
2024-10-30 16:57:48: [2024-10-30 16:57:48] iter = 01490, loss = 2.4661
2024-10-30 16:57:48: [2024-10-30 16:57:48] iter = 01500, loss = 2.5374
2024-10-30 16:57:49: [2024-10-30 16:57:49] iter = 01510, loss = 2.8342
2024-10-30 16:57:50: [2024-10-30 16:57:50] iter = 01520, loss = 2.5990
2024-10-30 16:57:51: [2024-10-30 16:57:51] iter = 01530, loss = 2.2957
2024-10-30 16:57:52: [2024-10-30 16:57:52] iter = 01540, loss = 1.7426
2024-10-30 16:57:53: [2024-10-30 16:57:53] iter = 01550, loss = 3.1203
2024-10-30 16:57:54: [2024-10-30 16:57:54] iter = 01560, loss = 31.2946
2024-10-30 16:57:54: [2024-10-30 16:57:54] iter = 01570, loss = 1.9901
2024-10-30 16:57:55: [2024-10-30 16:57:55] iter = 01580, loss = 2.3623
2024-10-30 16:57:56: [2024-10-30 16:57:56] iter = 01590, loss = 3.8235
2024-10-30 16:57:57: [2024-10-30 16:57:57] iter = 01600, loss = 1.3240
2024-10-30 16:57:57: [2024-10-30 16:57:57] iter = 01610, loss = 45.6520
2024-10-30 16:57:58: [2024-10-30 16:57:58] iter = 01620, loss = 8.4099
2024-10-30 16:57:59: [2024-10-30 16:57:59] iter = 01630, loss = 1.4503
2024-10-30 16:58:00: [2024-10-30 16:58:00] iter = 01640, loss = 6.8572
2024-10-30 16:58:00: [2024-10-30 16:58:00] iter = 01650, loss = 7.3881
2024-10-30 16:58:01: [2024-10-30 16:58:01] iter = 01660, loss = 1.6462
2024-10-30 16:58:01: [2024-10-30 16:58:01] iter = 01670, loss = 1.0173
2024-10-30 16:58:02: [2024-10-30 16:58:02] iter = 01680, loss = 2.8989
2024-10-30 16:58:02: [2024-10-30 16:58:02] iter = 01690, loss = 6.8766
2024-10-30 16:58:03: [2024-10-30 16:58:03] iter = 01700, loss = 3.8677
2024-10-30 16:58:04: [2024-10-30 16:58:04] iter = 01710, loss = 3.1934
2024-10-30 16:58:05: [2024-10-30 16:58:05] iter = 01720, loss = 4.0976
2024-10-30 16:58:06: [2024-10-30 16:58:06] iter = 01730, loss = 5.4714
2024-10-30 16:58:07: [2024-10-30 16:58:07] iter = 01740, loss = 2.6524
2024-10-30 16:58:07: [2024-10-30 16:58:07] iter = 01750, loss = 2.5482
2024-10-30 16:58:08: [2024-10-30 16:58:08] iter = 01760, loss = 10.0130
2024-10-30 16:58:09: [2024-10-30 16:58:09] iter = 01770, loss = 15.2330
2024-10-30 16:58:10: [2024-10-30 16:58:10] iter = 01780, loss = 1.8443
2024-10-30 16:58:11: [2024-10-30 16:58:11] iter = 01790, loss = 3.0153
2024-10-30 16:58:12: [2024-10-30 16:58:12] iter = 01800, loss = 2.1445
2024-10-30 16:58:14: [2024-10-30 16:58:14] iter = 01810, loss = 3.3292
2024-10-30 16:58:14: [2024-10-30 16:58:14] iter = 01820, loss = 3.2332
2024-10-30 16:58:15: [2024-10-30 16:58:15] iter = 01830, loss = 7.1805
2024-10-30 16:58:16: [2024-10-30 16:58:16] iter = 01840, loss = 1.7882
2024-10-30 16:58:17: [2024-10-30 16:58:17] iter = 01850, loss = 1.3082
2024-10-30 16:58:18: [2024-10-30 16:58:18] iter = 01860, loss = 8.6714
2024-10-30 16:58:19: [2024-10-30 16:58:19] iter = 01870, loss = 2.6994
2024-10-30 16:58:19: [2024-10-30 16:58:19] iter = 01880, loss = 4.5020
2024-10-30 16:58:20: [2024-10-30 16:58:20] iter = 01890, loss = 1.2410
2024-10-30 16:58:22: [2024-10-30 16:58:22] iter = 01900, loss = 26.0769
2024-10-30 16:58:23: [2024-10-30 16:58:23] iter = 01910, loss = 10.3250
2024-10-30 16:58:24: [2024-10-30 16:58:24] iter = 01920, loss = 1.2502
2024-10-30 16:58:25: [2024-10-30 16:58:25] iter = 01930, loss = 5.0243
2024-10-30 16:58:26: [2024-10-30 16:58:26] iter = 01940, loss = 11.1202
2024-10-30 16:58:27: [2024-10-30 16:58:27] iter = 01950, loss = 1.9851
2024-10-30 16:58:27: [2024-10-30 16:58:27] iter = 01960, loss = 1.8392
2024-10-30 16:58:28: [2024-10-30 16:58:28] iter = 01970, loss = 11.3373
2024-10-30 16:58:29: [2024-10-30 16:58:29] iter = 01980, loss = 5.4443
2024-10-30 16:58:29: [2024-10-30 16:58:29] iter = 01990, loss = 1.8098
2024-10-30 16:58:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 16:58:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:58:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10651}

[2024-10-30 16:24:02] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.018822 train acc = 1.0000, test acc = 0.7885, test_sen =0.6297, test_spe =0.6297, test_f1 =0.6458
[2024-10-30 16:27:06] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000349 train acc = 1.0000, test acc = 0.5256, test_sen =0.6378, test_spe =0.6378, test_f1 =0.5244
[2024-10-30 16:27:23] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.000228 train acc = 1.0000, test acc = 0.4679, test_sen =0.6134, test_spe =0.6134, test_f1 =0.4674
[2024-10-30 16:27:41] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000856 train acc = 1.0000, test acc = 0.5321, test_sen =0.6347, test_spe =0.6347, test_f1 =0.5297
[2024-10-30 16:27:59] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000061 train acc = 1.0000, test acc = 0.4487, test_sen =0.5852, test_spe =0.5852, test_f1 =0.4484
[2024-10-30 16:28:17] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.018436 train acc = 1.0000, test acc = 0.5064, test_sen =0.6172, test_spe =0.6172, test_f1 =0.5054
[2024-10-30 16:31:21] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000485 train acc = 1.0000, test acc = 0.5962, test_sen =0.6786, test_spe =0.6786, test_f1 =0.5887
[2024-10-30 16:31:38] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.002195 train acc = 1.0000, test acc = 0.5641, test_sen =0.6717, test_spe =0.6717, test_f1 =0.5615
[2024-10-30 16:31:56] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.003728 train acc = 1.0000, test acc = 0.5705, test_sen =0.6610, test_spe =0.6610, test_f1 =0.5654
[2024-10-30 16:32:15] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000112 train acc = 1.0000, test acc = 0.5833, test_sen =0.6698, test_spe =0.6698, test_f1 =0.5771
[2024-10-30 16:32:33] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.001674 train acc = 1.0000, test acc = 0.6090, test_sen =0.6873, test_spe =0.6873, test_f1 =0.6003
[2024-10-30 16:35:44] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.011690 train acc = 1.0000, test acc = 0.7308, test_sen =0.7331, test_spe =0.7331, test_f1 =0.6971
[2024-10-30 16:36:04] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.045299 train acc = 1.0000, test acc = 0.7308, test_sen =0.7331, test_spe =0.7331, test_f1 =0.6971
[2024-10-30 16:36:22] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.002040 train acc = 1.0000, test acc = 0.7692, test_sen =0.7519, test_spe =0.7519, test_f1 =0.7292
[2024-10-30 16:36:40] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.013963 train acc = 1.0000, test acc = 0.6987, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6594
[2024-10-30 16:36:58] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000235 train acc = 1.0000, test acc = 0.7564, test_sen =0.7431, test_spe =0.7431, test_f1 =0.7173
[2024-10-30 16:40:16] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.000931 train acc = 1.0000, test acc = 0.7949, test_sen =0.7093, test_spe =0.7093, test_f1 =0.7217
[2024-10-30 16:40:34] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.001156 train acc = 1.0000, test acc = 0.7885, test_sen =0.7199, test_spe =0.7199, test_f1 =0.7249
[2024-10-30 16:40:52] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.004425 train acc = 1.0000, test acc = 0.7372, test_sen =0.6999, test_spe =0.6999, test_f1 =0.6860
[2024-10-30 16:41:10] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.013953 train acc = 1.0000, test acc = 0.7692, test_sen =0.6767, test_spe =0.6767, test_f1 =0.6869
[2024-10-30 16:41:25] Evaluate_04: epoch = 1000 train time = 14 s train loss = 0.000737 train acc = 1.0000, test acc = 0.7756, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6983
[2024-10-30 16:44:31] Evaluate_00: epoch = 1000 train time = 14 s train loss = 0.003598 train acc = 1.0000, test acc = 0.7500, test_sen =0.7538, test_spe =0.7538, test_f1 =0.7174
[2024-10-30 16:44:49] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.001519 train acc = 1.0000, test acc = 0.7436, test_sen =0.7494, test_spe =0.7494, test_f1 =0.7115
[2024-10-30 16:45:08] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.020656 train acc = 1.0000, test acc = 0.7308, test_sen =0.7481, test_spe =0.7481, test_f1 =0.7026
[2024-10-30 16:45:27] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000415 train acc = 1.0000, test acc = 0.7628, test_sen =0.7625, test_spe =0.7625, test_f1 =0.7292
[2024-10-30 16:45:46] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.007786 train acc = 1.0000, test acc = 0.7500, test_sen =0.7538, test_spe =0.7538, test_f1 =0.7174
[2024-10-30 16:48:49] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.008007 train acc = 1.0000, test acc = 0.5385, test_sen =0.6391, test_spe =0.6391, test_f1 =0.5357
[2024-10-30 16:49:05] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.000096 train acc = 1.0000, test acc = 0.5064, test_sen =0.6247, test_spe =0.6247, test_f1 =0.5059
[2024-10-30 16:49:20] Evaluate_02: epoch = 1000 train time = 15 s train loss = 0.000217 train acc = 1.0000, test acc = 0.5192, test_sen =0.6335, test_spe =0.6335, test_f1 =0.5183
[2024-10-30 16:49:39] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.000068 train acc = 1.0000, test acc = 0.5192, test_sen =0.6184, test_spe =0.6184, test_f1 =0.5168
[2024-10-30 16:49:57] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.000132 train acc = 1.0000, test acc = 0.5128, test_sen =0.6216, test_spe =0.6216, test_f1 =0.5115
[2024-10-30 16:53:05] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000102 train acc = 1.0000, test acc = 0.7051, test_sen =0.6404, test_spe =0.6404, test_f1 =0.6360
[2024-10-30 16:53:20] Evaluate_01: epoch = 1000 train time = 14 s train loss = 0.032566 train acc = 1.0000, test acc = 0.7308, test_sen =0.6353, test_spe =0.6353, test_f1 =0.6410
[2024-10-30 16:53:38] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.020990 train acc = 1.0000, test acc = 0.6859, test_sen =0.6122, test_spe =0.6122, test_f1 =0.6095
[2024-10-30 16:53:55] Evaluate_03: epoch = 1000 train time = 16 s train loss = 0.000301 train acc = 1.0000, test acc = 0.6731, test_sen =0.5733, test_spe =0.5733, test_f1 =0.5748
[2024-10-30 16:54:13] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000709 train acc = 1.0000, test acc = 0.6923, test_sen =0.6015, test_spe =0.6015, test_f1 =0.6030
[2024-10-30 16:54:27] Evaluate_00: epoch = 1000 train time = 14 s train loss = 0.000490 train acc = 1.0000, test acc = 0.6795, test_sen =0.6679, test_spe =0.6679, test_f1 =0.6394
[2024-10-30 16:54:46] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.032677 train acc = 1.0000, test acc = 0.6603, test_sen =0.6472, test_spe =0.6472, test_f1 =0.6196
[2024-10-30 16:55:04] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.017516 train acc = 1.0000, test acc = 0.6731, test_sen =0.6335, test_spe =0.6335, test_f1 =0.6185
[2024-10-30 16:55:21] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.000029 train acc = 1.0000, test acc = 0.6731, test_sen =0.6560, test_spe =0.6560, test_f1 =0.6304
[2024-10-30 16:55:39] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.007193 train acc = 1.0000, test acc = 0.6731, test_sen =0.6786, test_spe =0.6786, test_f1 =0.6404
[2024-10-30 16:58:46] Evaluate_00: epoch = 1000 train time = 15 s train loss = 0.000091 train acc = 1.0000, test acc = 0.7372, test_sen =0.5796, test_spe =0.5796, test_f1 =0.5823
[2024-10-30 16:59:04] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.001686 train acc = 1.0000, test acc = 0.7436, test_sen =0.5689, test_spe =0.5689, test_f1 =0.5647
[2024-10-30 16:59:24] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.000095 train acc = 1.0000, test acc = 0.7436, test_sen =0.5764, test_spe =0.5764, test_f1 =0.5764
[2024-10-30 16:59:41] Evaluate_03: epoch = 1000 train time = 16 s train loss = 0.000051 train acc = 1.0000, test acc = 0.7372, test_sen =0.5871, test_spe =0.5871, test_f1 =0.5923
[2024-10-30 16:59:58] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.024227 train acc = 1.0000, test acc = 0.7628, test_sen =0.6122, test_spe =0.6122, test_f1 =0.6230/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:59:58: Evaluate 5 random ConvNet, ACCmean = 0.7449 ACCstd = 0.0094
-------------------------
2024-10-30 16:59:58: Evaluate 5 random ConvNet, SENmean = 0.5848 SENstd = 0.0149
-------------------------
2024-10-30 16:59:58: Evaluate 5 random ConvNet, SPEmean = 0.5848 SPEstd = 0.0149
-------------------------
2024-10-30 16:59:58: Evaluate 5 random ConvNet, F!mean = 0.5877 F!std = 0.0198
-------------------------
2024-10-30 16:59:58: Evaluate 5 random ConvNet, mean = 0.7449 std = 0.0094
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:59:59: [2024-10-30 16:59:59] iter = 02000, loss = 4.4765
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:59:59: [2024-10-30 16:59:59] iter = 02010, loss = 0.8955
2024-10-30 17:00:00: [2024-10-30 17:00:00] iter = 02020, loss = 1.0838
2024-10-30 17:00:02: [2024-10-30 17:00:02] iter = 02030, loss = 1.6929
2024-10-30 17:00:03: [2024-10-30 17:00:03] iter = 02040, loss = 1.6392
2024-10-30 17:00:04: [2024-10-30 17:00:04] iter = 02050, loss = 5.7220
2024-10-30 17:00:04: [2024-10-30 17:00:04] iter = 02060, loss = 3.5023
2024-10-30 17:00:05: [2024-10-30 17:00:05] iter = 02070, loss = 2.5755
2024-10-30 17:00:06: [2024-10-30 17:00:06] iter = 02080, loss = 54.5523
2024-10-30 17:00:07: [2024-10-30 17:00:07] iter = 02090, loss = 2.8179
2024-10-30 17:00:08: [2024-10-30 17:00:08] iter = 02100, loss = 4.4487
2024-10-30 17:00:09: [2024-10-30 17:00:09] iter = 02110, loss = 1.3520
2024-10-30 17:00:09: [2024-10-30 17:00:09] iter = 02120, loss = 4.0998
2024-10-30 17:00:10: [2024-10-30 17:00:10] iter = 02130, loss = 13.1077
2024-10-30 17:00:11: [2024-10-30 17:00:11] iter = 02140, loss = 2.6191
2024-10-30 17:00:12: [2024-10-30 17:00:12] iter = 02150, loss = 1.2750
2024-10-30 17:00:13: [2024-10-30 17:00:13] iter = 02160, loss = 2.3172
2024-10-30 17:00:14: [2024-10-30 17:00:14] iter = 02170, loss = 2.1457
2024-10-30 17:00:15: [2024-10-30 17:00:15] iter = 02180, loss = 4.9674
2024-10-30 17:00:16: [2024-10-30 17:00:16] iter = 02190, loss = 8.2093
2024-10-30 17:00:16: [2024-10-30 17:00:16] iter = 02200, loss = 30.6973
2024-10-30 17:00:17: [2024-10-30 17:00:17] iter = 02210, loss = 4.7401
2024-10-30 17:00:18: [2024-10-30 17:00:18] iter = 02220, loss = 2.4173
2024-10-30 17:00:19: [2024-10-30 17:00:19] iter = 02230, loss = 22.7934
2024-10-30 17:00:20: [2024-10-30 17:00:20] iter = 02240, loss = 1.9934
2024-10-30 17:00:21: [2024-10-30 17:00:21] iter = 02250, loss = 1.7518
2024-10-30 17:00:22: [2024-10-30 17:00:22] iter = 02260, loss = 1.9785
2024-10-30 17:00:23: [2024-10-30 17:00:23] iter = 02270, loss = 1.8310
2024-10-30 17:00:24: [2024-10-30 17:00:24] iter = 02280, loss = 2.6845
2024-10-30 17:00:25: [2024-10-30 17:00:25] iter = 02290, loss = 4.7782
2024-10-30 17:00:26: [2024-10-30 17:00:26] iter = 02300, loss = 1.5623
2024-10-30 17:00:26: [2024-10-30 17:00:26] iter = 02310, loss = 4.5340
2024-10-30 17:00:27: [2024-10-30 17:00:27] iter = 02320, loss = 5.2519
2024-10-30 17:00:28: [2024-10-30 17:00:28] iter = 02330, loss = 1.3258
2024-10-30 17:00:29: [2024-10-30 17:00:29] iter = 02340, loss = 1.1348
2024-10-30 17:00:30: [2024-10-30 17:00:30] iter = 02350, loss = 3.0300
2024-10-30 17:00:31: [2024-10-30 17:00:31] iter = 02360, loss = 2.2046
2024-10-30 17:00:32: [2024-10-30 17:00:32] iter = 02370, loss = 1.7473
2024-10-30 17:00:32: [2024-10-30 17:00:32] iter = 02380, loss = 17.8515
2024-10-30 17:00:33: [2024-10-30 17:00:33] iter = 02390, loss = 1.6141
2024-10-30 17:00:34: [2024-10-30 17:00:34] iter = 02400, loss = 2.3994
2024-10-30 17:00:34: [2024-10-30 17:00:34] iter = 02410, loss = 1.2748
2024-10-30 17:00:35: [2024-10-30 17:00:35] iter = 02420, loss = 4.0842
2024-10-30 17:00:36: [2024-10-30 17:00:36] iter = 02430, loss = 1.6052
2024-10-30 17:00:37: [2024-10-30 17:00:37] iter = 02440, loss = 4.9236
2024-10-30 17:00:38: [2024-10-30 17:00:38] iter = 02450, loss = 2.3294
2024-10-30 17:00:39: [2024-10-30 17:00:39] iter = 02460, loss = 1.3750
2024-10-30 17:00:40: [2024-10-30 17:00:40] iter = 02470, loss = 2.1324
2024-10-30 17:00:40: [2024-10-30 17:00:40] iter = 02480, loss = 12.5591
2024-10-30 17:00:41: [2024-10-30 17:00:41] iter = 02490, loss = 3.5040
2024-10-30 17:00:42: [2024-10-30 17:00:42] iter = 02500, loss = 4.7110
2024-10-30 17:00:43: [2024-10-30 17:00:43] iter = 02510, loss = 2.6716
2024-10-30 17:00:44: [2024-10-30 17:00:44] iter = 02520, loss = 13.7116
2024-10-30 17:00:45: [2024-10-30 17:00:45] iter = 02530, loss = 5.2454
2024-10-30 17:00:45: [2024-10-30 17:00:45] iter = 02540, loss = 2.8616
2024-10-30 17:00:46: [2024-10-30 17:00:46] iter = 02550, loss = 2.5811
2024-10-30 17:00:48: [2024-10-30 17:00:48] iter = 02560, loss = 4.9083
2024-10-30 17:00:49: [2024-10-30 17:00:49] iter = 02570, loss = 1.6004
2024-10-30 17:00:50: [2024-10-30 17:00:50] iter = 02580, loss = 5.1835
2024-10-30 17:00:51: [2024-10-30 17:00:51] iter = 02590, loss = 1.7725
2024-10-30 17:00:52: [2024-10-30 17:00:52] iter = 02600, loss = 2.5570
2024-10-30 17:00:53: [2024-10-30 17:00:53] iter = 02610, loss = 2.6466
2024-10-30 17:00:53: [2024-10-30 17:00:53] iter = 02620, loss = 1.7726
2024-10-30 17:00:54: [2024-10-30 17:00:54] iter = 02630, loss = 1.7527
2024-10-30 17:00:55: [2024-10-30 17:00:55] iter = 02640, loss = 1.8431
2024-10-30 17:00:56: [2024-10-30 17:00:56] iter = 02650, loss = 3.0602
2024-10-30 17:00:58: [2024-10-30 17:00:58] iter = 02660, loss = 4.6375
2024-10-30 17:00:59: [2024-10-30 17:00:59] iter = 02670, loss = 10.1484
2024-10-30 17:01:00: [2024-10-30 17:01:00] iter = 02680, loss = 1.6562
2024-10-30 17:01:01: [2024-10-30 17:01:01] iter = 02690, loss = 1.5824
2024-10-30 17:01:01: [2024-10-30 17:01:01] iter = 02700, loss = 4.7406
2024-10-30 17:01:02: [2024-10-30 17:01:02] iter = 02710, loss = 2.5640
2024-10-30 17:01:03: [2024-10-30 17:01:03] iter = 02720, loss = 18.7720
2024-10-30 17:01:03: [2024-10-30 17:01:03] iter = 02730, loss = 5.0056
2024-10-30 17:01:04: [2024-10-30 17:01:04] iter = 02740, loss = 1.6614
2024-10-30 17:01:05: [2024-10-30 17:01:05] iter = 02750, loss = 1.9991
2024-10-30 17:01:06: [2024-10-30 17:01:06] iter = 02760, loss = 4.0385
2024-10-30 17:01:07: [2024-10-30 17:01:07] iter = 02770, loss = 1.3312
2024-10-30 17:01:08: [2024-10-30 17:01:08] iter = 02780, loss = 2.1470
2024-10-30 17:01:10: [2024-10-30 17:01:10] iter = 02790, loss = 1.1651
2024-10-30 17:01:10: [2024-10-30 17:01:10] iter = 02800, loss = 3.4020
2024-10-30 17:01:11: [2024-10-30 17:01:11] iter = 02810, loss = 3.5243
2024-10-30 17:01:12: [2024-10-30 17:01:12] iter = 02820, loss = 4.7035
2024-10-30 17:01:13: [2024-10-30 17:01:13] iter = 02830, loss = 2.6199
2024-10-30 17:01:13: [2024-10-30 17:01:13] iter = 02840, loss = 3.0315
2024-10-30 17:01:14: [2024-10-30 17:01:14] iter = 02850, loss = 2.6838
2024-10-30 17:01:15: [2024-10-30 17:01:15] iter = 02860, loss = 1.2414
2024-10-30 17:01:16: [2024-10-30 17:01:16] iter = 02870, loss = 10.6719
2024-10-30 17:01:16: [2024-10-30 17:01:16] iter = 02880, loss = 4.4849
2024-10-30 17:01:17: [2024-10-30 17:01:17] iter = 02890, loss = 3.3030
2024-10-30 17:01:18: [2024-10-30 17:01:18] iter = 02900, loss = 1.9675
2024-10-30 17:01:19: [2024-10-30 17:01:19] iter = 02910, loss = 2.2461
2024-10-30 17:01:20: [2024-10-30 17:01:20] iter = 02920, loss = 1.5022
2024-10-30 17:01:21: [2024-10-30 17:01:21] iter = 02930, loss = 6.7927
2024-10-30 17:01:21: [2024-10-30 17:01:21] iter = 02940, loss = 9.6700
2024-10-30 17:01:22: [2024-10-30 17:01:22] iter = 02950, loss = 3.9284
2024-10-30 17:01:23: [2024-10-30 17:01:23] iter = 02960, loss = 3.5386
2024-10-30 17:01:24: [2024-10-30 17:01:24] iter = 02970, loss = 2.1478
2024-10-30 17:01:25: [2024-10-30 17:01:25] iter = 02980, loss = 2.3122
2024-10-30 17:01:26: [2024-10-30 17:01:26] iter = 02990, loss = 28.7741
2024-10-30 17:01:26: [2024-10-30 17:01:26] iter = 03000, loss = 11.2402
2024-10-30 17:01:27: [2024-10-30 17:01:27] iter = 03010, loss = 7.1959
2024-10-30 17:01:28: [2024-10-30 17:01:28] iter = 03020, loss = 2.9577
2024-10-30 17:01:29: [2024-10-30 17:01:29] iter = 03030, loss = 2.1078
2024-10-30 17:01:30: [2024-10-30 17:01:30] iter = 03040, loss = 2.6841
2024-10-30 17:01:31: [2024-10-30 17:01:31] iter = 03050, loss = 6.9832
2024-10-30 17:01:32: [2024-10-30 17:01:32] iter = 03060, loss = 16.8787
2024-10-30 17:01:33: [2024-10-30 17:01:33] iter = 03070, loss = 36.2070
2024-10-30 17:01:34: [2024-10-30 17:01:34] iter = 03080, loss = 4.1227
2024-10-30 17:01:35: [2024-10-30 17:01:35] iter = 03090, loss = 2.3791
2024-10-30 17:01:36: [2024-10-30 17:01:36] iter = 03100, loss = 3.5676
2024-10-30 17:01:37: [2024-10-30 17:01:37] iter = 03110, loss = 8.0654
2024-10-30 17:01:38: [2024-10-30 17:01:38] iter = 03120, loss = 1.8653
2024-10-30 17:01:39: [2024-10-30 17:01:39] iter = 03130, loss = 2.9280
2024-10-30 17:01:40: [2024-10-30 17:01:40] iter = 03140, loss = 3.8042
2024-10-30 17:01:40: [2024-10-30 17:01:40] iter = 03150, loss = 1.3911
2024-10-30 17:01:41: [2024-10-30 17:01:41] iter = 03160, loss = 5.3783
2024-10-30 17:01:42: [2024-10-30 17:01:42] iter = 03170, loss = 9.4916
2024-10-30 17:01:43: [2024-10-30 17:01:43] iter = 03180, loss = 4.6053
2024-10-30 17:01:44: [2024-10-30 17:01:44] iter = 03190, loss = 1.9772
2024-10-30 17:01:45: [2024-10-30 17:01:45] iter = 03200, loss = 1.2217
2024-10-30 17:01:46: [2024-10-30 17:01:46] iter = 03210, loss = 1.7183
2024-10-30 17:01:46: [2024-10-30 17:01:46] iter = 03220, loss = 2.1783
2024-10-30 17:01:47: [2024-10-30 17:01:47] iter = 03230, loss = 4.0664
2024-10-30 17:01:48: [2024-10-30 17:01:48] iter = 03240, loss = 3.1805
2024-10-30 17:01:49: [2024-10-30 17:01:49] iter = 03250, loss = 4.7269
2024-10-30 17:01:50: [2024-10-30 17:01:50] iter = 03260, loss = 2.1204
2024-10-30 17:01:50: [2024-10-30 17:01:50] iter = 03270, loss = 1.8211
2024-10-30 17:01:51: [2024-10-30 17:01:51] iter = 03280, loss = 2.9078
2024-10-30 17:01:51: [2024-10-30 17:01:51] iter = 03290, loss = 1.6362
2024-10-30 17:01:52: [2024-10-30 17:01:52] iter = 03300, loss = 1.4872
2024-10-30 17:01:52: [2024-10-30 17:01:52] iter = 03310, loss = 1.8826
2024-10-30 17:01:53: [2024-10-30 17:01:53] iter = 03320, loss = 11.0634
2024-10-30 17:01:54: [2024-10-30 17:01:54] iter = 03330, loss = 1.2046
2024-10-30 17:01:54: [2024-10-30 17:01:54] iter = 03340, loss = 9.4908
2024-10-30 17:01:55: [2024-10-30 17:01:55] iter = 03350, loss = 8.8988
2024-10-30 17:01:57: [2024-10-30 17:01:57] iter = 03360, loss = 1.5266
2024-10-30 17:01:58: [2024-10-30 17:01:58] iter = 03370, loss = 1.0726
2024-10-30 17:01:58: [2024-10-30 17:01:58] iter = 03380, loss = 1.4839
2024-10-30 17:02:00: [2024-10-30 17:02:00] iter = 03390, loss = 1.1512
2024-10-30 17:02:01: [2024-10-30 17:02:01] iter = 03400, loss = 1.5139
2024-10-30 17:02:01: [2024-10-30 17:02:01] iter = 03410, loss = 4.3922
2024-10-30 17:02:03: [2024-10-30 17:02:03] iter = 03420, loss = 1.9344
2024-10-30 17:02:04: [2024-10-30 17:02:04] iter = 03430, loss = 2.0228
2024-10-30 17:02:04: [2024-10-30 17:02:04] iter = 03440, loss = 2.8260
2024-10-30 17:02:06: [2024-10-30 17:02:06] iter = 03450, loss = 1.6362
2024-10-30 17:02:06: [2024-10-30 17:02:06] iter = 03460, loss = 2.4267
2024-10-30 17:02:07: [2024-10-30 17:02:07] iter = 03470, loss = 0.9345
2024-10-30 17:02:07: [2024-10-30 17:02:07] iter = 03480, loss = 8.2675
2024-10-30 17:02:07: [2024-10-30 17:02:07] iter = 03490, loss = 1.6551
2024-10-30 17:02:08: [2024-10-30 17:02:08] iter = 03500, loss = 4.0998
2024-10-30 17:02:09: [2024-10-30 17:02:09] iter = 03510, loss = 2.3991
2024-10-30 17:02:10: [2024-10-30 17:02:10] iter = 03520, loss = 1.9373
2024-10-30 17:02:11: [2024-10-30 17:02:11] iter = 03530, loss = 1.5851
2024-10-30 17:02:11: [2024-10-30 17:02:11] iter = 03540, loss = 5.4491
2024-10-30 17:02:13: [2024-10-30 17:02:13] iter = 03550, loss = 1.5635
2024-10-30 17:02:14: [2024-10-30 17:02:14] iter = 03560, loss = 5.3963
2024-10-30 17:02:15: [2024-10-30 17:02:15] iter = 03570, loss = 12.8469
2024-10-30 17:02:15: [2024-10-30 17:02:15] iter = 03580, loss = 1.5721
2024-10-30 17:02:17: [2024-10-30 17:02:17] iter = 03590, loss = 4.9630
2024-10-30 17:02:18: [2024-10-30 17:02:18] iter = 03600, loss = 2.8098
2024-10-30 17:02:18: [2024-10-30 17:02:18] iter = 03610, loss = 0.9052
2024-10-30 17:02:19: [2024-10-30 17:02:19] iter = 03620, loss = 10.4210
2024-10-30 17:02:20: [2024-10-30 17:02:20] iter = 03630, loss = 26.1852
2024-10-30 17:02:20: [2024-10-30 17:02:20] iter = 03640, loss = 4.5310
2024-10-30 17:02:21: [2024-10-30 17:02:21] iter = 03650, loss = 14.4010
2024-10-30 17:02:22: [2024-10-30 17:02:22] iter = 03660, loss = 1.6362
2024-10-30 17:02:22: [2024-10-30 17:02:22] iter = 03670, loss = 1.6421
2024-10-30 17:02:24: [2024-10-30 17:02:24] iter = 03680, loss = 16.9424
2024-10-30 17:02:25: [2024-10-30 17:02:25] iter = 03690, loss = 3.2273
2024-10-30 17:02:26: [2024-10-30 17:02:26] iter = 03700, loss = 1.2082
2024-10-30 17:02:27: [2024-10-30 17:02:27] iter = 03710, loss = 7.8965
2024-10-30 17:02:28: [2024-10-30 17:02:28] iter = 03720, loss = 46.7267
2024-10-30 17:02:29: [2024-10-30 17:02:28] iter = 03730, loss = 4.5780
2024-10-30 17:02:29: [2024-10-30 17:02:29] iter = 03740, loss = 6.3192
2024-10-30 17:02:30: [2024-10-30 17:02:30] iter = 03750, loss = 1.5527
2024-10-30 17:02:31: [2024-10-30 17:02:31] iter = 03760, loss = 2.0978
2024-10-30 17:02:32: [2024-10-30 17:02:32] iter = 03770, loss = 13.3566
2024-10-30 17:02:33: [2024-10-30 17:02:33] iter = 03780, loss = 5.3607
2024-10-30 17:02:34: [2024-10-30 17:02:34] iter = 03790, loss = 2.2157
2024-10-30 17:02:35: [2024-10-30 17:02:35] iter = 03800, loss = 3.5526
2024-10-30 17:02:36: [2024-10-30 17:02:36] iter = 03810, loss = 5.4794
2024-10-30 17:02:37: [2024-10-30 17:02:37] iter = 03820, loss = 3.9166
2024-10-30 17:02:38: [2024-10-30 17:02:38] iter = 03830, loss = 5.6415
2024-10-30 17:02:39: [2024-10-30 17:02:39] iter = 03840, loss = 1.1079
2024-10-30 17:02:40: [2024-10-30 17:02:40] iter = 03850, loss = 2.4009
2024-10-30 17:02:41: [2024-10-30 17:02:41] iter = 03860, loss = 4.4703
2024-10-30 17:02:42: [2024-10-30 17:02:42] iter = 03870, loss = 1.2342
2024-10-30 17:02:43: [2024-10-30 17:02:43] iter = 03880, loss = 2.5270
2024-10-30 17:02:44: [2024-10-30 17:02:44] iter = 03890, loss = 1.8570
2024-10-30 17:02:45: [2024-10-30 17:02:45] iter = 03900, loss = 15.3470
2024-10-30 17:02:46: [2024-10-30 17:02:46] iter = 03910, loss = 1.6323
2024-10-30 17:02:47: [2024-10-30 17:02:47] iter = 03920, loss = 4.2509
2024-10-30 17:02:48: [2024-10-30 17:02:48] iter = 03930, loss = 17.2762
2024-10-30 17:02:49: [2024-10-30 17:02:49] iter = 03940, loss = 2.0209
2024-10-30 17:02:50: [2024-10-30 17:02:50] iter = 03950, loss = 1.9335
2024-10-30 17:02:51: [2024-10-30 17:02:51] iter = 03960, loss = 14.4169
2024-10-30 17:02:52: [2024-10-30 17:02:52] iter = 03970, loss = 1.7972
2024-10-30 17:02:52: [2024-10-30 17:02:52] iter = 03980, loss = 1.9678
2024-10-30 17:02:53: [2024-10-30 17:02:53] iter = 03990, loss = 4.5857
2024-10-30 17:02:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 17:02:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:02:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 74570}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:04:27: Evaluate 5 random ConvNet, ACCmean = 0.7372 ACCstd = 0.0140
-------------------------
2024-10-30 17:04:27: Evaluate 5 random ConvNet, SENmean = 0.7420 SENstd = 0.0229
-------------------------
2024-10-30 17:04:27: Evaluate 5 random ConvNet, SPEmean = 0.7420 SPEstd = 0.0229
-------------------------
2024-10-30 17:04:27: Evaluate 5 random ConvNet, F!mean = 0.7044 F!std = 0.0176
-------------------------
2024-10-30 17:04:27: Evaluate 5 random ConvNet, mean = 0.7372 std = 0.0140
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:04:27: [2024-10-30 17:04:27] iter = 04000, loss = 2.0662
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:04:28: [2024-10-30 17:04:28] iter = 04010, loss = 2.2490
2024-10-30 17:04:28: [2024-10-30 17:04:28] iter = 04020, loss = 4.7193
2024-10-30 17:04:29: [2024-10-30 17:04:29] iter = 04030, loss = 24.0183
2024-10-30 17:04:30: [2024-10-30 17:04:30] iter = 04040, loss = 6.6503
2024-10-30 17:04:31: [2024-10-30 17:04:31] iter = 04050, loss = 3.6726
2024-10-30 17:04:32: [2024-10-30 17:04:32] iter = 04060, loss = 2.2167
2024-10-30 17:04:33: [2024-10-30 17:04:33] iter = 04070, loss = 2.8018
2024-10-30 17:04:34: [2024-10-30 17:04:34] iter = 04080, loss = 4.0816
2024-10-30 17:04:34: [2024-10-30 17:04:34] iter = 04090, loss = 6.7377
2024-10-30 17:04:35: [2024-10-30 17:04:35] iter = 04100, loss = 2.3009
2024-10-30 17:04:36: [2024-10-30 17:04:36] iter = 04110, loss = 3.5417
2024-10-30 17:04:37: [2024-10-30 17:04:37] iter = 04120, loss = 5.9086
2024-10-30 17:04:38: [2024-10-30 17:04:38] iter = 04130, loss = 5.0530
2024-10-30 17:04:39: [2024-10-30 17:04:39] iter = 04140, loss = 1.6780
2024-10-30 17:04:40: [2024-10-30 17:04:40] iter = 04150, loss = 21.9560
2024-10-30 17:04:41: [2024-10-30 17:04:41] iter = 04160, loss = 7.2895
2024-10-30 17:04:42: [2024-10-30 17:04:42] iter = 04170, loss = 3.6372
2024-10-30 17:04:43: [2024-10-30 17:04:43] iter = 04180, loss = 2.0099
2024-10-30 17:04:44: [2024-10-30 17:04:44] iter = 04190, loss = 6.9501
2024-10-30 17:04:45: [2024-10-30 17:04:45] iter = 04200, loss = 33.1826
2024-10-30 17:04:46: [2024-10-30 17:04:46] iter = 04210, loss = 3.5664
2024-10-30 17:04:47: [2024-10-30 17:04:47] iter = 04220, loss = 1.2807
2024-10-30 17:04:47: [2024-10-30 17:04:47] iter = 04230, loss = 15.6788
2024-10-30 17:04:48: [2024-10-30 17:04:48] iter = 04240, loss = 1.6079
2024-10-30 17:04:49: [2024-10-30 17:04:49] iter = 04250, loss = 1.8500
2024-10-30 17:04:50: [2024-10-30 17:04:50] iter = 04260, loss = 4.0908
2024-10-30 17:04:51: [2024-10-30 17:04:51] iter = 04270, loss = 1.1613
2024-10-30 17:04:51: [2024-10-30 17:04:51] iter = 04280, loss = 1.6354
2024-10-30 17:04:53: [2024-10-30 17:04:53] iter = 04290, loss = 1.8822
2024-10-30 17:04:53: [2024-10-30 17:04:53] iter = 04300, loss = 5.6783
2024-10-30 17:04:54: [2024-10-30 17:04:54] iter = 04310, loss = 13.3497
2024-10-30 17:04:55: [2024-10-30 17:04:55] iter = 04320, loss = 3.6015
2024-10-30 17:04:56: [2024-10-30 17:04:56] iter = 04330, loss = 8.8179
2024-10-30 17:04:56: [2024-10-30 17:04:56] iter = 04340, loss = 2.9342
2024-10-30 17:04:57: [2024-10-30 17:04:57] iter = 04350, loss = 1.9501
2024-10-30 17:04:58: [2024-10-30 17:04:58] iter = 04360, loss = 3.3626
2024-10-30 17:04:59: [2024-10-30 17:04:59] iter = 04370, loss = 2.5865
2024-10-30 17:05:00: [2024-10-30 17:05:00] iter = 04380, loss = 1.1505
2024-10-30 17:05:01: [2024-10-30 17:05:01] iter = 04390, loss = 17.2265
2024-10-30 17:05:02: [2024-10-30 17:05:02] iter = 04400, loss = 12.1614
2024-10-30 17:05:03: [2024-10-30 17:05:03] iter = 04410, loss = 3.9997
2024-10-30 17:05:04: [2024-10-30 17:05:04] iter = 04420, loss = 4.0456
2024-10-30 17:05:05: [2024-10-30 17:05:05] iter = 04430, loss = 1.8531
2024-10-30 17:05:06: [2024-10-30 17:05:06] iter = 04440, loss = 1.0014
2024-10-30 17:05:07: [2024-10-30 17:05:07] iter = 04450, loss = 5.9291
2024-10-30 17:05:08: [2024-10-30 17:05:08] iter = 04460, loss = 7.1540
2024-10-30 17:05:08: [2024-10-30 17:05:08] iter = 04470, loss = 1.7760
2024-10-30 17:05:09: [2024-10-30 17:05:09] iter = 04480, loss = 8.1519
2024-10-30 17:05:10: [2024-10-30 17:05:10] iter = 04490, loss = 2.8031
2024-10-30 17:05:11: [2024-10-30 17:05:11] iter = 04500, loss = 2.1502
2024-10-30 17:05:11: [2024-10-30 17:05:11] iter = 04510, loss = 7.1733
2024-10-30 17:05:12: [2024-10-30 17:05:12] iter = 04520, loss = 4.3862
2024-10-30 17:05:13: [2024-10-30 17:05:13] iter = 04530, loss = 1.5010
2024-10-30 17:05:14: [2024-10-30 17:05:14] iter = 04540, loss = 1.6822
2024-10-30 17:05:14: [2024-10-30 17:05:14] iter = 04550, loss = 1.6752
2024-10-30 17:05:15: [2024-10-30 17:05:15] iter = 04560, loss = 2.9528
2024-10-30 17:05:16: [2024-10-30 17:05:16] iter = 04570, loss = 12.5517
2024-10-30 17:05:17: [2024-10-30 17:05:17] iter = 04580, loss = 1.9095
2024-10-30 17:05:18: [2024-10-30 17:05:18] iter = 04590, loss = 3.1839
2024-10-30 17:05:19: [2024-10-30 17:05:19] iter = 04600, loss = 3.5101
2024-10-30 17:05:20: [2024-10-30 17:05:20] iter = 04610, loss = 6.1850
2024-10-30 17:05:21: [2024-10-30 17:05:21] iter = 04620, loss = 3.5629
2024-10-30 17:05:22: [2024-10-30 17:05:22] iter = 04630, loss = 2.9629
2024-10-30 17:05:23: [2024-10-30 17:05:23] iter = 04640, loss = 1.7183
2024-10-30 17:05:24: [2024-10-30 17:05:24] iter = 04650, loss = 5.4714
2024-10-30 17:05:25: [2024-10-30 17:05:25] iter = 04660, loss = 3.4195
2024-10-30 17:05:26: [2024-10-30 17:05:26] iter = 04670, loss = 2.3507
2024-10-30 17:05:27: [2024-10-30 17:05:27] iter = 04680, loss = 1.3163
2024-10-30 17:05:28: [2024-10-30 17:05:28] iter = 04690, loss = 5.7030
2024-10-30 17:05:28: [2024-10-30 17:05:28] iter = 04700, loss = 2.2868
2024-10-30 17:05:29: [2024-10-30 17:05:29] iter = 04710, loss = 4.8032
2024-10-30 17:05:30: [2024-10-30 17:05:30] iter = 04720, loss = 2.6847
2024-10-30 17:05:31: [2024-10-30 17:05:31] iter = 04730, loss = 13.1644
2024-10-30 17:05:32: [2024-10-30 17:05:32] iter = 04740, loss = 4.8754
2024-10-30 17:05:32: [2024-10-30 17:05:32] iter = 04750, loss = 1.5556
2024-10-30 17:05:33: [2024-10-30 17:05:33] iter = 04760, loss = 2.4819
2024-10-30 17:05:34: [2024-10-30 17:05:34] iter = 04770, loss = 18.6290
2024-10-30 17:05:35: [2024-10-30 17:05:35] iter = 04780, loss = 1.9808
2024-10-30 17:05:35: [2024-10-30 17:05:35] iter = 04790, loss = 3.0581
2024-10-30 17:05:36: [2024-10-30 17:05:36] iter = 04800, loss = 1.8648
2024-10-30 17:05:36: [2024-10-30 17:05:36] iter = 04810, loss = 5.8053
2024-10-30 17:05:37: [2024-10-30 17:05:37] iter = 04820, loss = 3.7751
2024-10-30 17:05:38: [2024-10-30 17:05:38] iter = 04830, loss = 2.4556
2024-10-30 17:05:40: [2024-10-30 17:05:40] iter = 04840, loss = 2.3623
2024-10-30 17:05:41: [2024-10-30 17:05:41] iter = 04850, loss = 7.4227
2024-10-30 17:05:42: [2024-10-30 17:05:42] iter = 04860, loss = 3.4519
2024-10-30 17:05:42: [2024-10-30 17:05:42] iter = 04870, loss = 22.2543
2024-10-30 17:05:43: [2024-10-30 17:05:43] iter = 04880, loss = 3.3622
2024-10-30 17:05:44: [2024-10-30 17:05:44] iter = 04890, loss = 2.7436
2024-10-30 17:05:45: [2024-10-30 17:05:45] iter = 04900, loss = 1.7101
2024-10-30 17:05:46: [2024-10-30 17:05:46] iter = 04910, loss = 8.9802
2024-10-30 17:05:47: [2024-10-30 17:05:47] iter = 04920, loss = 3.7487
2024-10-30 17:05:48: [2024-10-30 17:05:48] iter = 04930, loss = 1.5712
2024-10-30 17:05:49: [2024-10-30 17:05:49] iter = 04940, loss = 8.9146
2024-10-30 17:05:50: [2024-10-30 17:05:50] iter = 04950, loss = 3.3943
2024-10-30 17:05:50: [2024-10-30 17:05:50] iter = 04960, loss = 14.7676
2024-10-30 17:05:52: [2024-10-30 17:05:52] iter = 04970, loss = 3.9049
2024-10-30 17:05:53: [2024-10-30 17:05:53] iter = 04980, loss = 2.8633
2024-10-30 17:05:54: [2024-10-30 17:05:54] iter = 04990, loss = 2.2146
2024-10-30 17:05:54: [2024-10-30 17:05:54] iter = 05000, loss = 14.6447
2024-10-30 17:05:55: [2024-10-30 17:05:55] iter = 05010, loss = 1.5878
2024-10-30 17:05:56: [2024-10-30 17:05:56] iter = 05020, loss = 8.3667
2024-10-30 17:05:57: [2024-10-30 17:05:57] iter = 05030, loss = 9.4848
2024-10-30 17:05:58: [2024-10-30 17:05:58] iter = 05040, loss = 11.7846
2024-10-30 17:05:59: [2024-10-30 17:05:59] iter = 05050, loss = 2.1643
2024-10-30 17:06:00: [2024-10-30 17:06:00] iter = 05060, loss = 1.5378
2024-10-30 17:06:01: [2024-10-30 17:06:01] iter = 05070, loss = 1.3770
2024-10-30 17:06:01: [2024-10-30 17:06:01] iter = 05080, loss = 3.7169
2024-10-30 17:06:02: [2024-10-30 17:06:02] iter = 05090, loss = 3.4544
2024-10-30 17:06:03: [2024-10-30 17:06:03] iter = 05100, loss = 3.1227
2024-10-30 17:06:04: [2024-10-30 17:06:04] iter = 05110, loss = 7.0986
2024-10-30 17:06:05: [2024-10-30 17:06:05] iter = 05120, loss = 5.5315
2024-10-30 17:06:05: [2024-10-30 17:06:05] iter = 05130, loss = 1.4578
2024-10-30 17:06:06: [2024-10-30 17:06:06] iter = 05140, loss = 5.5960
2024-10-30 17:06:07: [2024-10-30 17:06:07] iter = 05150, loss = 5.3231
2024-10-30 17:06:07: [2024-10-30 17:06:07] iter = 05160, loss = 3.3669
2024-10-30 17:06:08: [2024-10-30 17:06:08] iter = 05170, loss = 1.7802
2024-10-30 17:06:09: [2024-10-30 17:06:09] iter = 05180, loss = 2.9953
2024-10-30 17:06:10: [2024-10-30 17:06:10] iter = 05190, loss = 2.1440
2024-10-30 17:06:11: [2024-10-30 17:06:11] iter = 05200, loss = 15.9296
2024-10-30 17:06:12: [2024-10-30 17:06:12] iter = 05210, loss = 14.2054
2024-10-30 17:06:12: [2024-10-30 17:06:12] iter = 05220, loss = 1.4640
2024-10-30 17:06:13: [2024-10-30 17:06:13] iter = 05230, loss = 3.1040
2024-10-30 17:06:14: [2024-10-30 17:06:14] iter = 05240, loss = 1.8005
2024-10-30 17:06:15: [2024-10-30 17:06:15] iter = 05250, loss = 1.4053
2024-10-30 17:06:15: [2024-10-30 17:06:15] iter = 05260, loss = 4.0838
2024-10-30 17:06:16: [2024-10-30 17:06:16] iter = 05270, loss = 5.6755
2024-10-30 17:06:16: [2024-10-30 17:06:16] iter = 05280, loss = 5.0896
2024-10-30 17:06:17: [2024-10-30 17:06:17] iter = 05290, loss = 12.3545
2024-10-30 17:06:18: [2024-10-30 17:06:18] iter = 05300, loss = 1.6809
2024-10-30 17:06:19: [2024-10-30 17:06:19] iter = 05310, loss = 3.1502
2024-10-30 17:06:19: [2024-10-30 17:06:19] iter = 05320, loss = 10.4295
2024-10-30 17:06:20: [2024-10-30 17:06:20] iter = 05330, loss = 2.1649
2024-10-30 17:06:21: [2024-10-30 17:06:21] iter = 05340, loss = 10.2448
2024-10-30 17:06:21: [2024-10-30 17:06:21] iter = 05350, loss = 1.6426
2024-10-30 17:06:22: [2024-10-30 17:06:22] iter = 05360, loss = 1.7366
2024-10-30 17:06:23: [2024-10-30 17:06:23] iter = 05370, loss = 16.4706
2024-10-30 17:06:24: [2024-10-30 17:06:24] iter = 05380, loss = 5.9568
2024-10-30 17:06:25: [2024-10-30 17:06:25] iter = 05390, loss = 2.7414
2024-10-30 17:06:26: [2024-10-30 17:06:26] iter = 05400, loss = 2.6718
2024-10-30 17:06:26: [2024-10-30 17:06:26] iter = 05410, loss = 3.2274
2024-10-30 17:06:27: [2024-10-30 17:06:27] iter = 05420, loss = 2.6997
2024-10-30 17:06:28: [2024-10-30 17:06:28] iter = 05430, loss = 1.7276
2024-10-30 17:06:28: [2024-10-30 17:06:28] iter = 05440, loss = 5.2308
2024-10-30 17:06:29: [2024-10-30 17:06:29] iter = 05450, loss = 1.6878
2024-10-30 17:06:30: [2024-10-30 17:06:30] iter = 05460, loss = 1.3872
2024-10-30 17:06:31: [2024-10-30 17:06:31] iter = 05470, loss = 1.0367
2024-10-30 17:06:31: [2024-10-30 17:06:31] iter = 05480, loss = 1.8251
2024-10-30 17:06:32: [2024-10-30 17:06:32] iter = 05490, loss = 9.7754
2024-10-30 17:06:33: [2024-10-30 17:06:33] iter = 05500, loss = 4.9936
2024-10-30 17:06:34: [2024-10-30 17:06:34] iter = 05510, loss = 3.6309
2024-10-30 17:06:34: [2024-10-30 17:06:34] iter = 05520, loss = 4.4993
2024-10-30 17:06:35: [2024-10-30 17:06:35] iter = 05530, loss = 6.6509
2024-10-30 17:06:36: [2024-10-30 17:06:36] iter = 05540, loss = 1.3209
2024-10-30 17:06:37: [2024-10-30 17:06:37] iter = 05550, loss = 1.8574
2024-10-30 17:06:38: [2024-10-30 17:06:38] iter = 05560, loss = 6.3053
2024-10-30 17:06:39: [2024-10-30 17:06:39] iter = 05570, loss = 7.8367
2024-10-30 17:06:39: [2024-10-30 17:06:39] iter = 05580, loss = 1.5993
2024-10-30 17:06:40: [2024-10-30 17:06:40] iter = 05590, loss = 1.6326
2024-10-30 17:06:41: [2024-10-30 17:06:41] iter = 05600, loss = 2.9891
2024-10-30 17:06:41: [2024-10-30 17:06:41] iter = 05610, loss = 1.2703
2024-10-30 17:06:42: [2024-10-30 17:06:42] iter = 05620, loss = 1.1775
2024-10-30 17:06:43: [2024-10-30 17:06:43] iter = 05630, loss = 7.3128
2024-10-30 17:06:44: [2024-10-30 17:06:44] iter = 05640, loss = 1.6347
2024-10-30 17:06:45: [2024-10-30 17:06:45] iter = 05650, loss = 12.3470
2024-10-30 17:06:46: [2024-10-30 17:06:46] iter = 05660, loss = 5.3157
2024-10-30 17:06:47: [2024-10-30 17:06:47] iter = 05670, loss = 1.5904
2024-10-30 17:06:48: [2024-10-30 17:06:48] iter = 05680, loss = 2.0333
2024-10-30 17:06:49: [2024-10-30 17:06:49] iter = 05690, loss = 2.2375
2024-10-30 17:06:50: [2024-10-30 17:06:50] iter = 05700, loss = 2.2080
2024-10-30 17:06:51: [2024-10-30 17:06:51] iter = 05710, loss = 2.1517
2024-10-30 17:06:52: [2024-10-30 17:06:52] iter = 05720, loss = 7.5841
2024-10-30 17:06:53: [2024-10-30 17:06:53] iter = 05730, loss = 2.0090
2024-10-30 17:06:53: [2024-10-30 17:06:53] iter = 05740, loss = 3.9111
2024-10-30 17:06:54: [2024-10-30 17:06:54] iter = 05750, loss = 7.4512
2024-10-30 17:06:55: [2024-10-30 17:06:55] iter = 05760, loss = 1.8310
2024-10-30 17:06:56: [2024-10-30 17:06:56] iter = 05770, loss = 4.8048
2024-10-30 17:06:57: [2024-10-30 17:06:57] iter = 05780, loss = 6.2132
2024-10-30 17:06:57: [2024-10-30 17:06:57] iter = 05790, loss = 6.8792
2024-10-30 17:06:58: [2024-10-30 17:06:58] iter = 05800, loss = 15.1094
2024-10-30 17:06:59: [2024-10-30 17:06:59] iter = 05810, loss = 2.3787
2024-10-30 17:07:00: [2024-10-30 17:07:00] iter = 05820, loss = 3.9950
2024-10-30 17:07:01: [2024-10-30 17:07:01] iter = 05830, loss = 2.8648
2024-10-30 17:07:02: [2024-10-30 17:07:02] iter = 05840, loss = 3.4972
2024-10-30 17:07:03: [2024-10-30 17:07:03] iter = 05850, loss = 2.1196
2024-10-30 17:07:04: [2024-10-30 17:07:04] iter = 05860, loss = 10.4239
2024-10-30 17:07:05: [2024-10-30 17:07:05] iter = 05870, loss = 5.1132
2024-10-30 17:07:05: [2024-10-30 17:07:05] iter = 05880, loss = 2.1294
2024-10-30 17:07:06: [2024-10-30 17:07:06] iter = 05890, loss = 1.5485
2024-10-30 17:07:07: [2024-10-30 17:07:07] iter = 05900, loss = 1.4284
2024-10-30 17:07:07: [2024-10-30 17:07:07] iter = 05910, loss = 3.6247
2024-10-30 17:07:08: [2024-10-30 17:07:08] iter = 05920, loss = 8.9862
2024-10-30 17:07:09: [2024-10-30 17:07:09] iter = 05930, loss = 2.9666
2024-10-30 17:07:10: [2024-10-30 17:07:10] iter = 05940, loss = 5.4840
2024-10-30 17:07:11: [2024-10-30 17:07:11] iter = 05950, loss = 7.6203
2024-10-30 17:07:12: [2024-10-30 17:07:12] iter = 05960, loss = 4.4199
2024-10-30 17:07:12: [2024-10-30 17:07:12] iter = 05970, loss = 4.2624
2024-10-30 17:07:13: [2024-10-30 17:07:13] iter = 05980, loss = 1.3749
2024-10-30 17:07:14: [2024-10-30 17:07:14] iter = 05990, loss = 3.3053
2024-10-30 17:07:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 17:07:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:07:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 34736}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:08:44: Evaluate 5 random ConvNet, ACCmean = 0.6833 ACCstd = 0.0175
-------------------------
2024-10-30 17:08:44: Evaluate 5 random ConvNet, SENmean = 0.7142 SENstd = 0.0137
-------------------------
2024-10-30 17:08:44: Evaluate 5 random ConvNet, SPEmean = 0.7142 SPEstd = 0.0137
-------------------------
2024-10-30 17:08:44: Evaluate 5 random ConvNet, F!mean = 0.6599 F!std = 0.0159
-------------------------
2024-10-30 17:08:44: Evaluate 5 random ConvNet, mean = 0.6833 std = 0.0175
-------------------------
2024-10-30 17:08:44: [2024-10-30 17:08:44] iter = 06000, loss = 9.2500
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:08:45: [2024-10-30 17:08:45] iter = 06010, loss = 1.8382
2024-10-30 17:08:46: [2024-10-30 17:08:46] iter = 06020, loss = 2.0939
2024-10-30 17:08:47: [2024-10-30 17:08:47] iter = 06030, loss = 1.1597
2024-10-30 17:08:48: [2024-10-30 17:08:48] iter = 06040, loss = 5.4878
2024-10-30 17:08:49: [2024-10-30 17:08:49] iter = 06050, loss = 7.5177
2024-10-30 17:08:50: [2024-10-30 17:08:50] iter = 06060, loss = 19.3447
2024-10-30 17:08:51: [2024-10-30 17:08:51] iter = 06070, loss = 3.3293
2024-10-30 17:08:52: [2024-10-30 17:08:52] iter = 06080, loss = 1.7957
2024-10-30 17:08:53: [2024-10-30 17:08:53] iter = 06090, loss = 4.8058
2024-10-30 17:08:54: [2024-10-30 17:08:54] iter = 06100, loss = 7.5997
2024-10-30 17:08:54: [2024-10-30 17:08:54] iter = 06110, loss = 5.6168
2024-10-30 17:08:55: [2024-10-30 17:08:55] iter = 06120, loss = 3.4843
2024-10-30 17:08:56: [2024-10-30 17:08:56] iter = 06130, loss = 15.7796
2024-10-30 17:08:57: [2024-10-30 17:08:57] iter = 06140, loss = 5.2498
2024-10-30 17:08:58: [2024-10-30 17:08:58] iter = 06150, loss = 2.0945
2024-10-30 17:08:59: [2024-10-30 17:08:59] iter = 06160, loss = 2.6158
2024-10-30 17:09:00: [2024-10-30 17:09:00] iter = 06170, loss = 1.1808
2024-10-30 17:09:01: [2024-10-30 17:09:01] iter = 06180, loss = 14.0837
2024-10-30 17:09:01: [2024-10-30 17:09:01] iter = 06190, loss = 2.5251
2024-10-30 17:09:02: [2024-10-30 17:09:02] iter = 06200, loss = 5.2125
2024-10-30 17:09:03: [2024-10-30 17:09:03] iter = 06210, loss = 2.2104
2024-10-30 17:09:03: [2024-10-30 17:09:03] iter = 06220, loss = 1.8421
2024-10-30 17:09:04: [2024-10-30 17:09:04] iter = 06230, loss = 7.0444
2024-10-30 17:09:05: [2024-10-30 17:09:05] iter = 06240, loss = 5.0709
2024-10-30 17:09:05: [2024-10-30 17:09:05] iter = 06250, loss = 2.0131
2024-10-30 17:09:06: [2024-10-30 17:09:06] iter = 06260, loss = 1.6452
2024-10-30 17:09:07: [2024-10-30 17:09:07] iter = 06270, loss = 5.0704
2024-10-30 17:09:07: [2024-10-30 17:09:07] iter = 06280, loss = 4.0699
2024-10-30 17:09:08: [2024-10-30 17:09:08] iter = 06290, loss = 4.5572
2024-10-30 17:09:09: [2024-10-30 17:09:09] iter = 06300, loss = 2.0580
2024-10-30 17:09:10: [2024-10-30 17:09:10] iter = 06310, loss = 1.4563
2024-10-30 17:09:11: [2024-10-30 17:09:11] iter = 06320, loss = 1.7525
2024-10-30 17:09:11: [2024-10-30 17:09:11] iter = 06330, loss = 6.7340
2024-10-30 17:09:12: [2024-10-30 17:09:12] iter = 06340, loss = 1.5040
2024-10-30 17:09:13: [2024-10-30 17:09:13] iter = 06350, loss = 2.2073
2024-10-30 17:09:13: [2024-10-30 17:09:13] iter = 06360, loss = 1.3061
2024-10-30 17:09:14: [2024-10-30 17:09:14] iter = 06370, loss = 2.3972
2024-10-30 17:09:15: [2024-10-30 17:09:15] iter = 06380, loss = 1.2800
2024-10-30 17:09:16: [2024-10-30 17:09:16] iter = 06390, loss = 23.8473
2024-10-30 17:09:17: [2024-10-30 17:09:17] iter = 06400, loss = 2.2051
2024-10-30 17:09:18: [2024-10-30 17:09:18] iter = 06410, loss = 1.4682
2024-10-30 17:09:19: [2024-10-30 17:09:19] iter = 06420, loss = 2.7218
2024-10-30 17:09:20: [2024-10-30 17:09:20] iter = 06430, loss = 9.2569
2024-10-30 17:09:20: [2024-10-30 17:09:20] iter = 06440, loss = 1.8769
2024-10-30 17:09:21: [2024-10-30 17:09:21] iter = 06450, loss = 2.1138
2024-10-30 17:09:22: [2024-10-30 17:09:22] iter = 06460, loss = 1.8585
2024-10-30 17:09:23: [2024-10-30 17:09:23] iter = 06470, loss = 1.5055
2024-10-30 17:09:24: [2024-10-30 17:09:24] iter = 06480, loss = 0.9118
2024-10-30 17:09:25: [2024-10-30 17:09:25] iter = 06490, loss = 11.9948
2024-10-30 17:09:26: [2024-10-30 17:09:26] iter = 06500, loss = 8.7625
2024-10-30 17:09:27: [2024-10-30 17:09:27] iter = 06510, loss = 3.4008
2024-10-30 17:09:27: [2024-10-30 17:09:27] iter = 06520, loss = 6.0097
2024-10-30 17:09:28: [2024-10-30 17:09:28] iter = 06530, loss = 1.6156
2024-10-30 17:09:28: [2024-10-30 17:09:28] iter = 06540, loss = 1.2306
2024-10-30 17:09:29: [2024-10-30 17:09:29] iter = 06550, loss = 4.2508
2024-10-30 17:09:30: [2024-10-30 17:09:30] iter = 06560, loss = 1.2772
2024-10-30 17:09:31: [2024-10-30 17:09:31] iter = 06570, loss = 2.1721
2024-10-30 17:09:33: [2024-10-30 17:09:33] iter = 06580, loss = 1.4762
2024-10-30 17:09:34: [2024-10-30 17:09:34] iter = 06590, loss = 1.8614
2024-10-30 17:09:35: [2024-10-30 17:09:35] iter = 06600, loss = 3.6376
2024-10-30 17:09:36: [2024-10-30 17:09:36] iter = 06610, loss = 18.1374
2024-10-30 17:09:37: [2024-10-30 17:09:37] iter = 06620, loss = 4.3990
2024-10-30 17:09:38: [2024-10-30 17:09:38] iter = 06630, loss = 3.7347
2024-10-30 17:09:39: [2024-10-30 17:09:39] iter = 06640, loss = 2.0423
2024-10-30 17:09:40: [2024-10-30 17:09:40] iter = 06650, loss = 1.7819
2024-10-30 17:09:41: [2024-10-30 17:09:41] iter = 06660, loss = 5.7689
2024-10-30 17:09:41: [2024-10-30 17:09:41] iter = 06670, loss = 1.5455
2024-10-30 17:09:42: [2024-10-30 17:09:42] iter = 06680, loss = 2.1683
2024-10-30 17:09:43: [2024-10-30 17:09:43] iter = 06690, loss = 7.9221
2024-10-30 17:09:44: [2024-10-30 17:09:44] iter = 06700, loss = 2.7087
2024-10-30 17:09:45: [2024-10-30 17:09:45] iter = 06710, loss = 4.9851
2024-10-30 17:09:46: [2024-10-30 17:09:46] iter = 06720, loss = 3.5369
2024-10-30 17:09:47: [2024-10-30 17:09:47] iter = 06730, loss = 1.1849
2024-10-30 17:09:48: [2024-10-30 17:09:48] iter = 06740, loss = 11.6147
2024-10-30 17:09:49: [2024-10-30 17:09:49] iter = 06750, loss = 6.3257
2024-10-30 17:09:50: [2024-10-30 17:09:50] iter = 06760, loss = 2.0507
2024-10-30 17:09:50: [2024-10-30 17:09:50] iter = 06770, loss = 1.7913
2024-10-30 17:09:52: [2024-10-30 17:09:52] iter = 06780, loss = 2.6804
2024-10-30 17:09:52: [2024-10-30 17:09:52] iter = 06790, loss = 1.5120
2024-10-30 17:09:53: [2024-10-30 17:09:53] iter = 06800, loss = 0.9360
2024-10-30 17:09:54: [2024-10-30 17:09:54] iter = 06810, loss = 7.2715
2024-10-30 17:09:54: [2024-10-30 17:09:54] iter = 06820, loss = 1.6092
2024-10-30 17:09:55: [2024-10-30 17:09:55] iter = 06830, loss = 2.7845
2024-10-30 17:09:56: [2024-10-30 17:09:56] iter = 06840, loss = 1.8585
2024-10-30 17:09:57: [2024-10-30 17:09:57] iter = 06850, loss = 1.3748
2024-10-30 17:09:58: [2024-10-30 17:09:58] iter = 06860, loss = 5.1927
2024-10-30 17:09:59: [2024-10-30 17:09:59] iter = 06870, loss = 9.9376
2024-10-30 17:09:59: [2024-10-30 17:09:59] iter = 06880, loss = 2.7011
2024-10-30 17:10:00: [2024-10-30 17:10:00] iter = 06890, loss = 1.7240
2024-10-30 17:10:00: [2024-10-30 17:10:00] iter = 06900, loss = 1.7734
2024-10-30 17:10:01: [2024-10-30 17:10:01] iter = 06910, loss = 8.2115
2024-10-30 17:10:02: [2024-10-30 17:10:02] iter = 06920, loss = 13.4185
2024-10-30 17:10:03: [2024-10-30 17:10:03] iter = 06930, loss = 1.4326
2024-10-30 17:10:04: [2024-10-30 17:10:04] iter = 06940, loss = 1.4425
2024-10-30 17:10:05: [2024-10-30 17:10:05] iter = 06950, loss = 3.7857
2024-10-30 17:10:07: [2024-10-30 17:10:07] iter = 06960, loss = 2.0605
2024-10-30 17:10:07: [2024-10-30 17:10:07] iter = 06970, loss = 7.3066
2024-10-30 17:10:08: [2024-10-30 17:10:08] iter = 06980, loss = 15.6132
2024-10-30 17:10:09: [2024-10-30 17:10:09] iter = 06990, loss = 2.5943
2024-10-30 17:10:10: [2024-10-30 17:10:10] iter = 07000, loss = 1.8779
2024-10-30 17:10:10: [2024-10-30 17:10:10] iter = 07010, loss = 9.2086
2024-10-30 17:10:11: [2024-10-30 17:10:11] iter = 07020, loss = 2.2259
2024-10-30 17:10:12: [2024-10-30 17:10:12] iter = 07030, loss = 3.9140
2024-10-30 17:10:13: [2024-10-30 17:10:13] iter = 07040, loss = 3.8469
2024-10-30 17:10:14: [2024-10-30 17:10:14] iter = 07050, loss = 4.7066
2024-10-30 17:10:15: [2024-10-30 17:10:15] iter = 07060, loss = 2.3231
2024-10-30 17:10:16: [2024-10-30 17:10:16] iter = 07070, loss = 4.0464
2024-10-30 17:10:17: [2024-10-30 17:10:17] iter = 07080, loss = 2.9713
2024-10-30 17:10:18: [2024-10-30 17:10:18] iter = 07090, loss = 1.3349
2024-10-30 17:10:19: [2024-10-30 17:10:19] iter = 07100, loss = 4.6784
2024-10-30 17:10:19: [2024-10-30 17:10:19] iter = 07110, loss = 1.3990
2024-10-30 17:10:21: [2024-10-30 17:10:21] iter = 07120, loss = 3.1432
2024-10-30 17:10:21: [2024-10-30 17:10:21] iter = 07130, loss = 1.7784
2024-10-30 17:10:22: [2024-10-30 17:10:22] iter = 07140, loss = 1.2581
2024-10-30 17:10:23: [2024-10-30 17:10:23] iter = 07150, loss = 5.0032
2024-10-30 17:10:24: [2024-10-30 17:10:24] iter = 07160, loss = 7.3875
2024-10-30 17:10:24: [2024-10-30 17:10:24] iter = 07170, loss = 2.9274
2024-10-30 17:10:26: [2024-10-30 17:10:26] iter = 07180, loss = 2.0541
2024-10-30 17:10:27: [2024-10-30 17:10:27] iter = 07190, loss = 4.1541
2024-10-30 17:10:28: [2024-10-30 17:10:28] iter = 07200, loss = 4.1068
2024-10-30 17:10:28: [2024-10-30 17:10:28] iter = 07210, loss = 2.1091
2024-10-30 17:10:29: [2024-10-30 17:10:29] iter = 07220, loss = 6.0249
2024-10-30 17:10:30: [2024-10-30 17:10:30] iter = 07230, loss = 1.9387
2024-10-30 17:10:31: [2024-10-30 17:10:31] iter = 07240, loss = 2.6192
2024-10-30 17:10:31: [2024-10-30 17:10:31] iter = 07250, loss = 2.2833
2024-10-30 17:10:31: [2024-10-30 17:10:31] iter = 07260, loss = 10.0089
2024-10-30 17:10:32: [2024-10-30 17:10:32] iter = 07270, loss = 5.5797
2024-10-30 17:10:32: [2024-10-30 17:10:32] iter = 07280, loss = 1.8409
2024-10-30 17:10:33: [2024-10-30 17:10:33] iter = 07290, loss = 7.9804
2024-10-30 17:10:34: [2024-10-30 17:10:34] iter = 07300, loss = 2.9162
2024-10-30 17:10:35: [2024-10-30 17:10:35] iter = 07310, loss = 1.6674
2024-10-30 17:10:36: [2024-10-30 17:10:36] iter = 07320, loss = 7.1829
2024-10-30 17:10:37: [2024-10-30 17:10:37] iter = 07330, loss = 1.4788
2024-10-30 17:10:38: [2024-10-30 17:10:38] iter = 07340, loss = 10.9614
2024-10-30 17:10:38: [2024-10-30 17:10:38] iter = 07350, loss = 1.3802
2024-10-30 17:10:39: [2024-10-30 17:10:39] iter = 07360, loss = 3.4129
2024-10-30 17:10:40: [2024-10-30 17:10:40] iter = 07370, loss = 1.3430
2024-10-30 17:10:41: [2024-10-30 17:10:41] iter = 07380, loss = 1.9723
2024-10-30 17:10:42: [2024-10-30 17:10:42] iter = 07390, loss = 2.5541
2024-10-30 17:10:43: [2024-10-30 17:10:43] iter = 07400, loss = 4.6221
2024-10-30 17:10:43: [2024-10-30 17:10:43] iter = 07410, loss = 2.6159
2024-10-30 17:10:44: [2024-10-30 17:10:44] iter = 07420, loss = 3.6768
2024-10-30 17:10:45: [2024-10-30 17:10:45] iter = 07430, loss = 6.0527
2024-10-30 17:10:46: [2024-10-30 17:10:46] iter = 07440, loss = 3.5705
2024-10-30 17:10:47: [2024-10-30 17:10:47] iter = 07450, loss = 1.7042
2024-10-30 17:10:48: [2024-10-30 17:10:48] iter = 07460, loss = 2.3704
2024-10-30 17:10:48: [2024-10-30 17:10:48] iter = 07470, loss = 1.3835
2024-10-30 17:10:49: [2024-10-30 17:10:49] iter = 07480, loss = 1.9895
2024-10-30 17:10:49: [2024-10-30 17:10:49] iter = 07490, loss = 1.4791
2024-10-30 17:10:50: [2024-10-30 17:10:50] iter = 07500, loss = 1.1515
2024-10-30 17:10:50: [2024-10-30 17:10:50] iter = 07510, loss = 3.2901
2024-10-30 17:10:51: [2024-10-30 17:10:51] iter = 07520, loss = 2.5572
2024-10-30 17:10:52: [2024-10-30 17:10:52] iter = 07530, loss = 2.0494
2024-10-30 17:10:53: [2024-10-30 17:10:53] iter = 07540, loss = 1.7385
2024-10-30 17:10:53: [2024-10-30 17:10:53] iter = 07550, loss = 7.4615
2024-10-30 17:10:54: [2024-10-30 17:10:54] iter = 07560, loss = 3.4741
2024-10-30 17:10:55: [2024-10-30 17:10:55] iter = 07570, loss = 13.4940
2024-10-30 17:10:55: [2024-10-30 17:10:55] iter = 07580, loss = 2.0023
2024-10-30 17:10:56: [2024-10-30 17:10:56] iter = 07590, loss = 2.8661
2024-10-30 17:10:57: [2024-10-30 17:10:57] iter = 07600, loss = 2.3529
2024-10-30 17:10:58: [2024-10-30 17:10:58] iter = 07610, loss = 8.9794
2024-10-30 17:10:58: [2024-10-30 17:10:58] iter = 07620, loss = 2.8045
2024-10-30 17:10:59: [2024-10-30 17:10:59] iter = 07630, loss = 10.5119
2024-10-30 17:11:00: [2024-10-30 17:11:00] iter = 07640, loss = 4.9523
2024-10-30 17:11:01: [2024-10-30 17:11:01] iter = 07650, loss = 5.0157
2024-10-30 17:11:02: [2024-10-30 17:11:02] iter = 07660, loss = 6.5840
2024-10-30 17:11:03: [2024-10-30 17:11:03] iter = 07670, loss = 1.9788
2024-10-30 17:11:04: [2024-10-30 17:11:04] iter = 07680, loss = 2.2726
2024-10-30 17:11:05: [2024-10-30 17:11:05] iter = 07690, loss = 5.7352
2024-10-30 17:11:05: [2024-10-30 17:11:05] iter = 07700, loss = 4.8296
2024-10-30 17:11:06: [2024-10-30 17:11:06] iter = 07710, loss = 2.4754
2024-10-30 17:11:07: [2024-10-30 17:11:07] iter = 07720, loss = 1.8926
2024-10-30 17:11:08: [2024-10-30 17:11:08] iter = 07730, loss = 2.1954
2024-10-30 17:11:08: [2024-10-30 17:11:08] iter = 07740, loss = 12.5383
2024-10-30 17:11:09: [2024-10-30 17:11:09] iter = 07750, loss = 41.7444
2024-10-30 17:11:10: [2024-10-30 17:11:10] iter = 07760, loss = 2.1726
2024-10-30 17:11:11: [2024-10-30 17:11:11] iter = 07770, loss = 1.4701
2024-10-30 17:11:12: [2024-10-30 17:11:12] iter = 07780, loss = 1.4062
2024-10-30 17:11:12: [2024-10-30 17:11:12] iter = 07790, loss = 25.6324
2024-10-30 17:11:13: [2024-10-30 17:11:13] iter = 07800, loss = 8.3864
2024-10-30 17:11:14: [2024-10-30 17:11:14] iter = 07810, loss = 3.3473
2024-10-30 17:11:14: [2024-10-30 17:11:14] iter = 07820, loss = 3.4707
2024-10-30 17:11:15: [2024-10-30 17:11:15] iter = 07830, loss = 1.5730
2024-10-30 17:11:15: [2024-10-30 17:11:15] iter = 07840, loss = 1.1574
2024-10-30 17:11:16: [2024-10-30 17:11:16] iter = 07850, loss = 1.7293
2024-10-30 17:11:17: [2024-10-30 17:11:17] iter = 07860, loss = 6.9015
2024-10-30 17:11:17: [2024-10-30 17:11:17] iter = 07870, loss = 4.0436
2024-10-30 17:11:18: [2024-10-30 17:11:18] iter = 07880, loss = 3.9007
2024-10-30 17:11:19: [2024-10-30 17:11:19] iter = 07890, loss = 21.1958
2024-10-30 17:11:20: [2024-10-30 17:11:20] iter = 07900, loss = 3.3254
2024-10-30 17:11:21: [2024-10-30 17:11:21] iter = 07910, loss = 1.4250
2024-10-30 17:11:21: [2024-10-30 17:11:21] iter = 07920, loss = 1.2601
2024-10-30 17:11:22: [2024-10-30 17:11:22] iter = 07930, loss = 1.2366
2024-10-30 17:11:23: [2024-10-30 17:11:23] iter = 07940, loss = 3.4301
2024-10-30 17:11:24: [2024-10-30 17:11:24] iter = 07950, loss = 1.6143
2024-10-30 17:11:25: [2024-10-30 17:11:25] iter = 07960, loss = 3.2264
2024-10-30 17:11:26: [2024-10-30 17:11:26] iter = 07970, loss = 8.1009
2024-10-30 17:11:27: [2024-10-30 17:11:27] iter = 07980, loss = 1.8308
2024-10-30 17:11:28: [2024-10-30 17:11:28] iter = 07990, loss = 1.8975
2024-10-30 17:11:29: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 17:11:29: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:11:29: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 89198}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:12:53: Evaluate 5 random ConvNet, ACCmean = 0.7782 ACCstd = 0.0087
-------------------------
2024-10-30 17:12:53: Evaluate 5 random ConvNet, SENmean = 0.6919 SENstd = 0.0089
-------------------------
2024-10-30 17:12:53: Evaluate 5 random ConvNet, SPEmean = 0.6919 SPEstd = 0.0089
-------------------------
2024-10-30 17:12:53: Evaluate 5 random ConvNet, F!mean = 0.7018 F!std = 0.0102
-------------------------
2024-10-30 17:12:53: Evaluate 5 random ConvNet, mean = 0.7782 std = 0.0087
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:12:54: [2024-10-30 17:12:54] iter = 08000, loss = 3.8950
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:12:55: [2024-10-30 17:12:55] iter = 08010, loss = 1.7240
2024-10-30 17:12:55: [2024-10-30 17:12:55] iter = 08020, loss = 1.3515
2024-10-30 17:12:56: [2024-10-30 17:12:56] iter = 08030, loss = 12.9722
2024-10-30 17:12:57: [2024-10-30 17:12:57] iter = 08040, loss = 1.5684
2024-10-30 17:12:58: [2024-10-30 17:12:58] iter = 08050, loss = 1.7095
2024-10-30 17:12:58: [2024-10-30 17:12:58] iter = 08060, loss = 2.1836
2024-10-30 17:12:59: [2024-10-30 17:12:59] iter = 08070, loss = 1.1836
2024-10-30 17:12:59: [2024-10-30 17:12:59] iter = 08080, loss = 1.3720
2024-10-30 17:13:00: [2024-10-30 17:13:00] iter = 08090, loss = 4.0955
2024-10-30 17:13:00: [2024-10-30 17:13:00] iter = 08100, loss = 1.7957
2024-10-30 17:13:01: [2024-10-30 17:13:01] iter = 08110, loss = 12.5619
2024-10-30 17:13:02: [2024-10-30 17:13:02] iter = 08120, loss = 8.5888
2024-10-30 17:13:02: [2024-10-30 17:13:02] iter = 08130, loss = 2.6277
2024-10-30 17:13:03: [2024-10-30 17:13:03] iter = 08140, loss = 3.0307
2024-10-30 17:13:04: [2024-10-30 17:13:04] iter = 08150, loss = 3.9272
2024-10-30 17:13:05: [2024-10-30 17:13:05] iter = 08160, loss = 3.1821
2024-10-30 17:13:05: [2024-10-30 17:13:05] iter = 08170, loss = 6.4835
2024-10-30 17:13:06: [2024-10-30 17:13:06] iter = 08180, loss = 1.4577
2024-10-30 17:13:07: [2024-10-30 17:13:07] iter = 08190, loss = 1.7865
2024-10-30 17:13:08: [2024-10-30 17:13:08] iter = 08200, loss = 5.5772
2024-10-30 17:13:09: [2024-10-30 17:13:09] iter = 08210, loss = 1.4964
2024-10-30 17:13:09: [2024-10-30 17:13:09] iter = 08220, loss = 1.2950
2024-10-30 17:13:10: [2024-10-30 17:13:10] iter = 08230, loss = 6.3914
2024-10-30 17:13:11: [2024-10-30 17:13:11] iter = 08240, loss = 1.9884
2024-10-30 17:13:12: [2024-10-30 17:13:12] iter = 08250, loss = 1.5896
2024-10-30 17:13:13: [2024-10-30 17:13:13] iter = 08260, loss = 13.1389
2024-10-30 17:13:14: [2024-10-30 17:13:14] iter = 08270, loss = 1.6236
2024-10-30 17:13:15: [2024-10-30 17:13:15] iter = 08280, loss = 1.9362
2024-10-30 17:13:16: [2024-10-30 17:13:16] iter = 08290, loss = 3.0051
2024-10-30 17:13:17: [2024-10-30 17:13:17] iter = 08300, loss = 5.6647
2024-10-30 17:13:18: [2024-10-30 17:13:18] iter = 08310, loss = 5.1284
2024-10-30 17:13:19: [2024-10-30 17:13:19] iter = 08320, loss = 3.3247
2024-10-30 17:13:20: [2024-10-30 17:13:20] iter = 08330, loss = 1.3429
2024-10-30 17:13:20: [2024-10-30 17:13:20] iter = 08340, loss = 12.6313
2024-10-30 17:13:21: [2024-10-30 17:13:21] iter = 08350, loss = 1.4441
2024-10-30 17:13:22: [2024-10-30 17:13:22] iter = 08360, loss = 2.3336
2024-10-30 17:13:23: [2024-10-30 17:13:23] iter = 08370, loss = 2.2904
2024-10-30 17:13:24: [2024-10-30 17:13:24] iter = 08380, loss = 11.1177
2024-10-30 17:13:25: [2024-10-30 17:13:25] iter = 08390, loss = 2.9897
2024-10-30 17:13:26: [2024-10-30 17:13:26] iter = 08400, loss = 3.7096
2024-10-30 17:13:27: [2024-10-30 17:13:27] iter = 08410, loss = 1.8153
2024-10-30 17:13:29: [2024-10-30 17:13:29] iter = 08420, loss = 4.4635
2024-10-30 17:13:30: [2024-10-30 17:13:30] iter = 08430, loss = 2.4712
2024-10-30 17:13:31: [2024-10-30 17:13:31] iter = 08440, loss = 1.8967
2024-10-30 17:13:31: [2024-10-30 17:13:31] iter = 08450, loss = 7.2896
2024-10-30 17:13:32: [2024-10-30 17:13:32] iter = 08460, loss = 1.4277
2024-10-30 17:13:32: [2024-10-30 17:13:32] iter = 08470, loss = 1.3997
2024-10-30 17:13:33: [2024-10-30 17:13:33] iter = 08480, loss = 2.0374
2024-10-30 17:13:34: [2024-10-30 17:13:34] iter = 08490, loss = 1.8113
2024-10-30 17:13:35: [2024-10-30 17:13:35] iter = 08500, loss = 18.9400
2024-10-30 17:13:36: [2024-10-30 17:13:36] iter = 08510, loss = 3.7502
2024-10-30 17:13:36: [2024-10-30 17:13:36] iter = 08520, loss = 11.2373
2024-10-30 17:13:37: [2024-10-30 17:13:37] iter = 08530, loss = 7.0105
2024-10-30 17:13:38: [2024-10-30 17:13:38] iter = 08540, loss = 5.4833
2024-10-30 17:13:39: [2024-10-30 17:13:39] iter = 08550, loss = 18.1255
2024-10-30 17:13:40: [2024-10-30 17:13:40] iter = 08560, loss = 1.9489
2024-10-30 17:13:40: [2024-10-30 17:13:40] iter = 08570, loss = 2.2073
2024-10-30 17:13:41: [2024-10-30 17:13:41] iter = 08580, loss = 1.5115
2024-10-30 17:13:42: [2024-10-30 17:13:42] iter = 08590, loss = 1.4991
2024-10-30 17:13:43: [2024-10-30 17:13:43] iter = 08600, loss = 2.6060
2024-10-30 17:13:44: [2024-10-30 17:13:44] iter = 08610, loss = 5.7280
2024-10-30 17:13:44: [2024-10-30 17:13:44] iter = 08620, loss = 1.3692
2024-10-30 17:13:45: [2024-10-30 17:13:45] iter = 08630, loss = 1.2799
2024-10-30 17:13:46: [2024-10-30 17:13:46] iter = 08640, loss = 2.4916
2024-10-30 17:13:47: [2024-10-30 17:13:47] iter = 08650, loss = 9.5726
2024-10-30 17:13:48: [2024-10-30 17:13:48] iter = 08660, loss = 25.7529
2024-10-30 17:13:48: [2024-10-30 17:13:48] iter = 08670, loss = 2.9960
2024-10-30 17:13:50: [2024-10-30 17:13:50] iter = 08680, loss = 1.6924
2024-10-30 17:13:51: [2024-10-30 17:13:51] iter = 08690, loss = 2.0314
2024-10-30 17:13:52: [2024-10-30 17:13:52] iter = 08700, loss = 4.0705
2024-10-30 17:13:53: [2024-10-30 17:13:53] iter = 08710, loss = 2.7040
2024-10-30 17:13:53: [2024-10-30 17:13:53] iter = 08720, loss = 2.2045
2024-10-30 17:13:54: [2024-10-30 17:13:54] iter = 08730, loss = 2.4432
2024-10-30 17:13:55: [2024-10-30 17:13:55] iter = 08740, loss = 4.0691
2024-10-30 17:13:56: [2024-10-30 17:13:56] iter = 08750, loss = 3.9250
2024-10-30 17:13:57: [2024-10-30 17:13:57] iter = 08760, loss = 1.5286
2024-10-30 17:13:57: [2024-10-30 17:13:57] iter = 08770, loss = 2.8588
2024-10-30 17:13:58: [2024-10-30 17:13:58] iter = 08780, loss = 8.5860
2024-10-30 17:13:58: [2024-10-30 17:13:58] iter = 08790, loss = 3.3730
2024-10-30 17:13:59: [2024-10-30 17:13:59] iter = 08800, loss = 2.0420
2024-10-30 17:14:00: [2024-10-30 17:14:00] iter = 08810, loss = 3.0574
2024-10-30 17:14:01: [2024-10-30 17:14:01] iter = 08820, loss = 7.1592
2024-10-30 17:14:02: [2024-10-30 17:14:02] iter = 08830, loss = 4.1950
2024-10-30 17:14:02: [2024-10-30 17:14:02] iter = 08840, loss = 1.5649
2024-10-30 17:14:03: [2024-10-30 17:14:03] iter = 08850, loss = 1.8998
2024-10-30 17:14:04: [2024-10-30 17:14:04] iter = 08860, loss = 3.7134
2024-10-30 17:14:04: [2024-10-30 17:14:04] iter = 08870, loss = 3.0383
2024-10-30 17:14:05: [2024-10-30 17:14:05] iter = 08880, loss = 2.0730
2024-10-30 17:14:06: [2024-10-30 17:14:06] iter = 08890, loss = 13.5261
2024-10-30 17:14:07: [2024-10-30 17:14:07] iter = 08900, loss = 15.5391
2024-10-30 17:14:08: [2024-10-30 17:14:08] iter = 08910, loss = 2.0927
2024-10-30 17:14:09: [2024-10-30 17:14:09] iter = 08920, loss = 1.9355
2024-10-30 17:14:10: [2024-10-30 17:14:10] iter = 08930, loss = 3.8256
2024-10-30 17:14:10: [2024-10-30 17:14:10] iter = 08940, loss = 1.8072
2024-10-30 17:14:11: [2024-10-30 17:14:11] iter = 08950, loss = 3.5887
2024-10-30 17:14:11: [2024-10-30 17:14:11] iter = 08960, loss = 13.6259
2024-10-30 17:14:12: [2024-10-30 17:14:12] iter = 08970, loss = 2.7210
2024-10-30 17:14:13: [2024-10-30 17:14:13] iter = 08980, loss = 4.0220
2024-10-30 17:14:14: [2024-10-30 17:14:14] iter = 08990, loss = 1.5861
2024-10-30 17:14:15: [2024-10-30 17:14:15] iter = 09000, loss = 4.9266
2024-10-30 17:14:16: [2024-10-30 17:14:16] iter = 09010, loss = 6.3641
2024-10-30 17:14:17: [2024-10-30 17:14:17] iter = 09020, loss = 1.9252
2024-10-30 17:14:17: [2024-10-30 17:14:17] iter = 09030, loss = 1.6182
2024-10-30 17:14:18: [2024-10-30 17:14:18] iter = 09040, loss = 1.4567
2024-10-30 17:14:19: [2024-10-30 17:14:19] iter = 09050, loss = 3.7331
2024-10-30 17:14:20: [2024-10-30 17:14:20] iter = 09060, loss = 4.6135
2024-10-30 17:14:21: [2024-10-30 17:14:21] iter = 09070, loss = 6.0022
2024-10-30 17:14:22: [2024-10-30 17:14:22] iter = 09080, loss = 1.7906
2024-10-30 17:14:23: [2024-10-30 17:14:23] iter = 09090, loss = 2.4722
2024-10-30 17:14:24: [2024-10-30 17:14:24] iter = 09100, loss = 3.3776
2024-10-30 17:14:25: [2024-10-30 17:14:25] iter = 09110, loss = 1.6407
2024-10-30 17:14:26: [2024-10-30 17:14:26] iter = 09120, loss = 11.3133
2024-10-30 17:14:26: [2024-10-30 17:14:26] iter = 09130, loss = 1.7282
2024-10-30 17:14:27: [2024-10-30 17:14:27] iter = 09140, loss = 22.7195
2024-10-30 17:14:28: [2024-10-30 17:14:28] iter = 09150, loss = 2.5076
2024-10-30 17:14:29: [2024-10-30 17:14:29] iter = 09160, loss = 1.4622
2024-10-30 17:14:30: [2024-10-30 17:14:30] iter = 09170, loss = 7.1248
2024-10-30 17:14:31: [2024-10-30 17:14:31] iter = 09180, loss = 4.6775
2024-10-30 17:14:31: [2024-10-30 17:14:31] iter = 09190, loss = 2.1461
2024-10-30 17:14:33: [2024-10-30 17:14:33] iter = 09200, loss = 2.1129
2024-10-30 17:14:33: [2024-10-30 17:14:33] iter = 09210, loss = 2.8766
2024-10-30 17:14:34: [2024-10-30 17:14:34] iter = 09220, loss = 5.3531
2024-10-30 17:14:35: [2024-10-30 17:14:35] iter = 09230, loss = 10.4563
2024-10-30 17:14:36: [2024-10-30 17:14:36] iter = 09240, loss = 1.7967
2024-10-30 17:14:37: [2024-10-30 17:14:37] iter = 09250, loss = 1.4954
2024-10-30 17:14:38: [2024-10-30 17:14:38] iter = 09260, loss = 1.2690
2024-10-30 17:14:38: [2024-10-30 17:14:38] iter = 09270, loss = 1.4391
2024-10-30 17:14:39: [2024-10-30 17:14:39] iter = 09280, loss = 9.9150
2024-10-30 17:14:40: [2024-10-30 17:14:40] iter = 09290, loss = 1.6152
2024-10-30 17:14:40: [2024-10-30 17:14:40] iter = 09300, loss = 3.0525
2024-10-30 17:14:42: [2024-10-30 17:14:42] iter = 09310, loss = 5.1711
2024-10-30 17:14:42: [2024-10-30 17:14:42] iter = 09320, loss = 6.8420
2024-10-30 17:14:43: [2024-10-30 17:14:43] iter = 09330, loss = 1.7924
2024-10-30 17:14:44: [2024-10-30 17:14:44] iter = 09340, loss = 3.6770
2024-10-30 17:14:45: [2024-10-30 17:14:45] iter = 09350, loss = 11.4673
2024-10-30 17:14:45: [2024-10-30 17:14:45] iter = 09360, loss = 17.5746
2024-10-30 17:14:46: [2024-10-30 17:14:46] iter = 09370, loss = 21.4667
2024-10-30 17:14:47: [2024-10-30 17:14:47] iter = 09380, loss = 2.8740
2024-10-30 17:14:48: [2024-10-30 17:14:48] iter = 09390, loss = 6.3163
2024-10-30 17:14:49: [2024-10-30 17:14:49] iter = 09400, loss = 1.9546
2024-10-30 17:14:50: [2024-10-30 17:14:50] iter = 09410, loss = 19.4804
2024-10-30 17:14:50: [2024-10-30 17:14:50] iter = 09420, loss = 1.8359
2024-10-30 17:14:51: [2024-10-30 17:14:51] iter = 09430, loss = 8.1030
2024-10-30 17:14:52: [2024-10-30 17:14:52] iter = 09440, loss = 3.9618
2024-10-30 17:14:53: [2024-10-30 17:14:53] iter = 09450, loss = 9.4329
2024-10-30 17:14:54: [2024-10-30 17:14:54] iter = 09460, loss = 1.6936
2024-10-30 17:14:55: [2024-10-30 17:14:55] iter = 09470, loss = 2.1780
2024-10-30 17:14:55: [2024-10-30 17:14:55] iter = 09480, loss = 3.5798
2024-10-30 17:14:56: [2024-10-30 17:14:56] iter = 09490, loss = 1.9308
2024-10-30 17:14:57: [2024-10-30 17:14:57] iter = 09500, loss = 4.3000
2024-10-30 17:14:58: [2024-10-30 17:14:58] iter = 09510, loss = 5.0108
2024-10-30 17:14:59: [2024-10-30 17:14:59] iter = 09520, loss = 6.1521
2024-10-30 17:15:00: [2024-10-30 17:15:00] iter = 09530, loss = 4.5823
2024-10-30 17:15:01: [2024-10-30 17:15:01] iter = 09540, loss = 3.0720
2024-10-30 17:15:01: [2024-10-30 17:15:01] iter = 09550, loss = 1.9030
2024-10-30 17:15:02: [2024-10-30 17:15:02] iter = 09560, loss = 1.8148
2024-10-30 17:15:02: [2024-10-30 17:15:02] iter = 09570, loss = 2.1452
2024-10-30 17:15:03: [2024-10-30 17:15:03] iter = 09580, loss = 1.3132
2024-10-30 17:15:04: [2024-10-30 17:15:04] iter = 09590, loss = 4.1554
2024-10-30 17:15:05: [2024-10-30 17:15:05] iter = 09600, loss = 2.0921
2024-10-30 17:15:06: [2024-10-30 17:15:06] iter = 09610, loss = 1.8505
2024-10-30 17:15:07: [2024-10-30 17:15:07] iter = 09620, loss = 1.5722
2024-10-30 17:15:07: [2024-10-30 17:15:07] iter = 09630, loss = 1.2977
2024-10-30 17:15:08: [2024-10-30 17:15:08] iter = 09640, loss = 1.5516
2024-10-30 17:15:09: [2024-10-30 17:15:09] iter = 09650, loss = 6.1900
2024-10-30 17:15:10: [2024-10-30 17:15:10] iter = 09660, loss = 3.0502
2024-10-30 17:15:11: [2024-10-30 17:15:11] iter = 09670, loss = 1.6617
2024-10-30 17:15:12: [2024-10-30 17:15:12] iter = 09680, loss = 4.9570
2024-10-30 17:15:12: [2024-10-30 17:15:12] iter = 09690, loss = 1.7545
2024-10-30 17:15:13: [2024-10-30 17:15:13] iter = 09700, loss = 1.4125
2024-10-30 17:15:14: [2024-10-30 17:15:14] iter = 09710, loss = 2.9842
2024-10-30 17:15:15: [2024-10-30 17:15:15] iter = 09720, loss = 1.5918
2024-10-30 17:15:16: [2024-10-30 17:15:16] iter = 09730, loss = 20.1878
2024-10-30 17:15:18: [2024-10-30 17:15:18] iter = 09740, loss = 2.3534
2024-10-30 17:15:18: [2024-10-30 17:15:18] iter = 09750, loss = 4.1466
2024-10-30 17:15:19: [2024-10-30 17:15:19] iter = 09760, loss = 1.3093
2024-10-30 17:15:20: [2024-10-30 17:15:20] iter = 09770, loss = 1.1517
2024-10-30 17:15:21: [2024-10-30 17:15:21] iter = 09780, loss = 1.5382
2024-10-30 17:15:21: [2024-10-30 17:15:21] iter = 09790, loss = 5.5893
2024-10-30 17:15:22: [2024-10-30 17:15:22] iter = 09800, loss = 2.1309
2024-10-30 17:15:23: [2024-10-30 17:15:23] iter = 09810, loss = 2.1764
2024-10-30 17:15:23: [2024-10-30 17:15:23] iter = 09820, loss = 1.9664
2024-10-30 17:15:24: [2024-10-30 17:15:24] iter = 09830, loss = 4.2674
2024-10-30 17:15:25: [2024-10-30 17:15:25] iter = 09840, loss = 2.3919
2024-10-30 17:15:25: [2024-10-30 17:15:25] iter = 09850, loss = 4.8104
2024-10-30 17:15:26: [2024-10-30 17:15:26] iter = 09860, loss = 2.9527
2024-10-30 17:15:26: [2024-10-30 17:15:26] iter = 09870, loss = 4.6083
2024-10-30 17:15:27: [2024-10-30 17:15:27] iter = 09880, loss = 1.5849
2024-10-30 17:15:28: [2024-10-30 17:15:28] iter = 09890, loss = 12.1859
2024-10-30 17:15:29: [2024-10-30 17:15:29] iter = 09900, loss = 5.5698
2024-10-30 17:15:30: [2024-10-30 17:15:30] iter = 09910, loss = 8.2256
2024-10-30 17:15:31: [2024-10-30 17:15:31] iter = 09920, loss = 2.1704
2024-10-30 17:15:31: [2024-10-30 17:15:31] iter = 09930, loss = 8.7075
2024-10-30 17:15:32: [2024-10-30 17:15:32] iter = 09940, loss = 1.6863
2024-10-30 17:15:33: [2024-10-30 17:15:33] iter = 09950, loss = 1.2874
2024-10-30 17:15:34: [2024-10-30 17:15:34] iter = 09960, loss = 41.6676
2024-10-30 17:15:35: [2024-10-30 17:15:35] iter = 09970, loss = 5.9983
2024-10-30 17:15:36: [2024-10-30 17:15:36] iter = 09980, loss = 1.2609
2024-10-30 17:15:37: [2024-10-30 17:15:37] iter = 09990, loss = 8.0603
2024-10-30 17:15:38: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 17:15:38: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:15:38: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 38140}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:10: Evaluate 5 random ConvNet, ACCmean = 0.7577 ACCstd = 0.0154
-------------------------
2024-10-30 17:17:10: Evaluate 5 random ConvNet, SENmean = 0.7320 SENstd = 0.0095
-------------------------
2024-10-30 17:17:10: Evaluate 5 random ConvNet, SPEmean = 0.7320 SPEstd = 0.0095
-------------------------
2024-10-30 17:17:10: Evaluate 5 random ConvNet, F!mean = 0.7132 F!std = 0.0120
-------------------------
2024-10-30 17:17:10: Evaluate 5 random ConvNet, mean = 0.7577 std = 0.0154
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:10: [2024-10-30 17:17:10] iter = 10000, loss = 5.9552
2024-10-30 17:17:11: [2024-10-30 17:17:11] iter = 10010, loss = 5.5515
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:12: [2024-10-30 17:17:12] iter = 10020, loss = 5.3425
2024-10-30 17:17:13: [2024-10-30 17:17:13] iter = 10030, loss = 1.9174
2024-10-30 17:17:14: [2024-10-30 17:17:14] iter = 10040, loss = 2.6101
2024-10-30 17:17:15: [2024-10-30 17:17:15] iter = 10050, loss = 4.0269
2024-10-30 17:17:16: [2024-10-30 17:17:16] iter = 10060, loss = 2.9146
2024-10-30 17:17:16: [2024-10-30 17:17:16] iter = 10070, loss = 24.8643
2024-10-30 17:17:17: [2024-10-30 17:17:17] iter = 10080, loss = 2.2386
2024-10-30 17:17:18: [2024-10-30 17:17:18] iter = 10090, loss = 1.8264
2024-10-30 17:17:19: [2024-10-30 17:17:19] iter = 10100, loss = 1.1217
2024-10-30 17:17:20: [2024-10-30 17:17:20] iter = 10110, loss = 1.6662
2024-10-30 17:17:21: [2024-10-30 17:17:21] iter = 10120, loss = 1.5983
2024-10-30 17:17:21: [2024-10-30 17:17:21] iter = 10130, loss = 1.1813
2024-10-30 17:17:22: [2024-10-30 17:17:22] iter = 10140, loss = 1.9554
2024-10-30 17:17:23: [2024-10-30 17:17:23] iter = 10150, loss = 1.5464
2024-10-30 17:17:24: [2024-10-30 17:17:24] iter = 10160, loss = 4.0872
2024-10-30 17:17:25: [2024-10-30 17:17:25] iter = 10170, loss = 2.2052
2024-10-30 17:17:26: [2024-10-30 17:17:26] iter = 10180, loss = 4.3189
2024-10-30 17:17:27: [2024-10-30 17:17:27] iter = 10190, loss = 4.5123
2024-10-30 17:17:28: [2024-10-30 17:17:28] iter = 10200, loss = 6.3870
2024-10-30 17:17:29: [2024-10-30 17:17:29] iter = 10210, loss = 3.1811
2024-10-30 17:17:30: [2024-10-30 17:17:30] iter = 10220, loss = 4.3657
2024-10-30 17:17:31: [2024-10-30 17:17:31] iter = 10230, loss = 8.8869
2024-10-30 17:17:31: [2024-10-30 17:17:31] iter = 10240, loss = 3.2779
2024-10-30 17:17:32: [2024-10-30 17:17:32] iter = 10250, loss = 1.1660
2024-10-30 17:17:33: [2024-10-30 17:17:33] iter = 10260, loss = 11.9627
2024-10-30 17:17:34: [2024-10-30 17:17:34] iter = 10270, loss = 5.7601
2024-10-30 17:17:35: [2024-10-30 17:17:35] iter = 10280, loss = 2.9521
2024-10-30 17:17:36: [2024-10-30 17:17:36] iter = 10290, loss = 7.3808
2024-10-30 17:17:37: [2024-10-30 17:17:37] iter = 10300, loss = 2.7281
2024-10-30 17:17:38: [2024-10-30 17:17:38] iter = 10310, loss = 1.3693
2024-10-30 17:17:39: [2024-10-30 17:17:39] iter = 10320, loss = 1.8721
2024-10-30 17:17:40: [2024-10-30 17:17:40] iter = 10330, loss = 12.1403
2024-10-30 17:17:41: [2024-10-30 17:17:41] iter = 10340, loss = 2.7779
2024-10-30 17:17:42: [2024-10-30 17:17:42] iter = 10350, loss = 2.3803
2024-10-30 17:17:42: [2024-10-30 17:17:42] iter = 10360, loss = 1.2887
2024-10-30 17:17:43: [2024-10-30 17:17:43] iter = 10370, loss = 13.1514
2024-10-30 17:17:44: [2024-10-30 17:17:44] iter = 10380, loss = 2.5738
2024-10-30 17:17:45: [2024-10-30 17:17:45] iter = 10390, loss = 1.8860
2024-10-30 17:17:46: [2024-10-30 17:17:46] iter = 10400, loss = 3.1927
2024-10-30 17:17:47: [2024-10-30 17:17:47] iter = 10410, loss = 2.6290
2024-10-30 17:17:48: [2024-10-30 17:17:48] iter = 10420, loss = 2.0593
2024-10-30 17:17:49: [2024-10-30 17:17:49] iter = 10430, loss = 3.7517
2024-10-30 17:17:50: [2024-10-30 17:17:50] iter = 10440, loss = 1.2762
2024-10-30 17:17:51: [2024-10-30 17:17:51] iter = 10450, loss = 8.8551
2024-10-30 17:17:51: [2024-10-30 17:17:51] iter = 10460, loss = 1.5176
2024-10-30 17:17:52: [2024-10-30 17:17:52] iter = 10470, loss = 3.0631
2024-10-30 17:17:53: [2024-10-30 17:17:53] iter = 10480, loss = 2.8212
2024-10-30 17:17:54: [2024-10-30 17:17:54] iter = 10490, loss = 13.2063
2024-10-30 17:17:55: [2024-10-30 17:17:55] iter = 10500, loss = 2.9719
2024-10-30 17:17:56: [2024-10-30 17:17:56] iter = 10510, loss = 2.4077
2024-10-30 17:17:57: [2024-10-30 17:17:57] iter = 10520, loss = 1.4646
2024-10-30 17:17:58: [2024-10-30 17:17:58] iter = 10530, loss = 2.6231
2024-10-30 17:17:59: [2024-10-30 17:17:59] iter = 10540, loss = 5.2193
2024-10-30 17:18:00: [2024-10-30 17:18:00] iter = 10550, loss = 4.2879
2024-10-30 17:18:01: [2024-10-30 17:18:01] iter = 10560, loss = 7.5500
2024-10-30 17:18:02: [2024-10-30 17:18:02] iter = 10570, loss = 5.1895
2024-10-30 17:18:03: [2024-10-30 17:18:03] iter = 10580, loss = 3.7431
2024-10-30 17:18:04: [2024-10-30 17:18:04] iter = 10590, loss = 1.7841
2024-10-30 17:18:05: [2024-10-30 17:18:05] iter = 10600, loss = 2.0034
2024-10-30 17:18:06: [2024-10-30 17:18:06] iter = 10610, loss = 1.6805
2024-10-30 17:18:07: [2024-10-30 17:18:07] iter = 10620, loss = 7.9517
2024-10-30 17:18:08: [2024-10-30 17:18:08] iter = 10630, loss = 6.7401
2024-10-30 17:18:09: [2024-10-30 17:18:09] iter = 10640, loss = 4.7881
2024-10-30 17:18:10: [2024-10-30 17:18:10] iter = 10650, loss = 1.4434
2024-10-30 17:18:11: [2024-10-30 17:18:11] iter = 10660, loss = 3.6212
2024-10-30 17:18:12: [2024-10-30 17:18:12] iter = 10670, loss = 11.4876
2024-10-30 17:18:13: [2024-10-30 17:18:13] iter = 10680, loss = 3.5076
2024-10-30 17:18:14: [2024-10-30 17:18:14] iter = 10690, loss = 5.9827
2024-10-30 17:18:15: [2024-10-30 17:18:15] iter = 10700, loss = 1.6827
2024-10-30 17:18:15: [2024-10-30 17:18:15] iter = 10710, loss = 7.7053
2024-10-30 17:18:16: [2024-10-30 17:18:16] iter = 10720, loss = 5.9683
2024-10-30 17:18:17: [2024-10-30 17:18:17] iter = 10730, loss = 28.9757
2024-10-30 17:18:18: [2024-10-30 17:18:18] iter = 10740, loss = 11.9106
2024-10-30 17:18:19: [2024-10-30 17:18:19] iter = 10750, loss = 6.6261
2024-10-30 17:18:20: [2024-10-30 17:18:20] iter = 10760, loss = 2.5748
2024-10-30 17:18:21: [2024-10-30 17:18:21] iter = 10770, loss = 1.5866
2024-10-30 17:18:22: [2024-10-30 17:18:22] iter = 10780, loss = 17.7456
2024-10-30 17:18:23: [2024-10-30 17:18:23] iter = 10790, loss = 2.5132
2024-10-30 17:18:24: [2024-10-30 17:18:24] iter = 10800, loss = 1.4584
2024-10-30 17:18:25: [2024-10-30 17:18:25] iter = 10810, loss = 2.8686
2024-10-30 17:18:26: [2024-10-30 17:18:26] iter = 10820, loss = 10.4039
2024-10-30 17:18:27: [2024-10-30 17:18:27] iter = 10830, loss = 1.5989
2024-10-30 17:18:28: [2024-10-30 17:18:28] iter = 10840, loss = 1.5012
2024-10-30 17:18:29: [2024-10-30 17:18:29] iter = 10850, loss = 1.5328
2024-10-30 17:18:29: [2024-10-30 17:18:29] iter = 10860, loss = 1.2803
2024-10-30 17:18:30: [2024-10-30 17:18:30] iter = 10870, loss = 1.6578
2024-10-30 17:18:31: [2024-10-30 17:18:31] iter = 10880, loss = 1.8480
2024-10-30 17:18:32: [2024-10-30 17:18:32] iter = 10890, loss = 25.2756
2024-10-30 17:18:33: [2024-10-30 17:18:33] iter = 10900, loss = 2.1640
2024-10-30 17:18:34: [2024-10-30 17:18:34] iter = 10910, loss = 5.3553
2024-10-30 17:18:35: [2024-10-30 17:18:35] iter = 10920, loss = 1.3492
2024-10-30 17:18:37: [2024-10-30 17:18:37] iter = 10930, loss = 1.6030
2024-10-30 17:18:38: [2024-10-30 17:18:38] iter = 10940, loss = 1.8146
2024-10-30 17:18:38: [2024-10-30 17:18:38] iter = 10950, loss = 6.2423
2024-10-30 17:18:39: [2024-10-30 17:18:39] iter = 10960, loss = 1.6319
2024-10-30 17:18:40: [2024-10-30 17:18:40] iter = 10970, loss = 1.7957
2024-10-30 17:18:41: [2024-10-30 17:18:41] iter = 10980, loss = 1.4283
2024-10-30 17:18:42: [2024-10-30 17:18:42] iter = 10990, loss = 1.7377
2024-10-30 17:18:44: [2024-10-30 17:18:44] iter = 11000, loss = 5.0103
2024-10-30 17:18:45: [2024-10-30 17:18:45] iter = 11010, loss = 20.8560
2024-10-30 17:18:45: [2024-10-30 17:18:45] iter = 11020, loss = 4.7402
2024-10-30 17:18:46: [2024-10-30 17:18:46] iter = 11030, loss = 7.8099
2024-10-30 17:18:47: [2024-10-30 17:18:47] iter = 11040, loss = 2.2464
2024-10-30 17:18:48: [2024-10-30 17:18:48] iter = 11050, loss = 5.6638
2024-10-30 17:18:49: [2024-10-30 17:18:49] iter = 11060, loss = 4.3961
2024-10-30 17:18:50: [2024-10-30 17:18:50] iter = 11070, loss = 1.4990
2024-10-30 17:18:51: [2024-10-30 17:18:51] iter = 11080, loss = 2.6021
2024-10-30 17:18:52: [2024-10-30 17:18:52] iter = 11090, loss = 2.0541
2024-10-30 17:18:53: [2024-10-30 17:18:53] iter = 11100, loss = 3.1521
2024-10-30 17:18:54: [2024-10-30 17:18:54] iter = 11110, loss = 16.0785
2024-10-30 17:18:55: [2024-10-30 17:18:55] iter = 11120, loss = 1.4328
2024-10-30 17:18:55: [2024-10-30 17:18:55] iter = 11130, loss = 6.3978
2024-10-30 17:18:56: [2024-10-30 17:18:56] iter = 11140, loss = 3.9145
2024-10-30 17:18:57: [2024-10-30 17:18:57] iter = 11150, loss = 2.7130
2024-10-30 17:18:58: [2024-10-30 17:18:58] iter = 11160, loss = 1.6769
2024-10-30 17:18:59: [2024-10-30 17:18:59] iter = 11170, loss = 2.9587
2024-10-30 17:19:00: [2024-10-30 17:19:00] iter = 11180, loss = 4.9066
2024-10-30 17:19:01: [2024-10-30 17:19:01] iter = 11190, loss = 21.1950
2024-10-30 17:19:02: [2024-10-30 17:19:02] iter = 11200, loss = 1.9902
2024-10-30 17:19:03: [2024-10-30 17:19:03] iter = 11210, loss = 1.2372
2024-10-30 17:19:05: [2024-10-30 17:19:05] iter = 11220, loss = 3.0312
2024-10-30 17:19:06: [2024-10-30 17:19:06] iter = 11230, loss = 4.4263
2024-10-30 17:19:06: [2024-10-30 17:19:06] iter = 11240, loss = 2.4948
2024-10-30 17:19:07: [2024-10-30 17:19:07] iter = 11250, loss = 2.4270
2024-10-30 17:19:08: [2024-10-30 17:19:08] iter = 11260, loss = 1.7101
2024-10-30 17:19:09: [2024-10-30 17:19:09] iter = 11270, loss = 1.6036
2024-10-30 17:19:10: [2024-10-30 17:19:10] iter = 11280, loss = 6.7536
2024-10-30 17:19:11: [2024-10-30 17:19:11] iter = 11290, loss = 2.3987
2024-10-30 17:19:11: [2024-10-30 17:19:11] iter = 11300, loss = 1.3356
2024-10-30 17:19:12: [2024-10-30 17:19:12] iter = 11310, loss = 3.5593
2024-10-30 17:19:13: [2024-10-30 17:19:13] iter = 11320, loss = 23.0989
2024-10-30 17:19:14: [2024-10-30 17:19:14] iter = 11330, loss = 2.6790
2024-10-30 17:19:15: [2024-10-30 17:19:15] iter = 11340, loss = 7.2907
2024-10-30 17:19:16: [2024-10-30 17:19:16] iter = 11350, loss = 3.2211
2024-10-30 17:19:17: [2024-10-30 17:19:17] iter = 11360, loss = 2.4522
2024-10-30 17:19:18: [2024-10-30 17:19:18] iter = 11370, loss = 4.3821
2024-10-30 17:19:19: [2024-10-30 17:19:19] iter = 11380, loss = 4.8724
2024-10-30 17:19:20: [2024-10-30 17:19:20] iter = 11390, loss = 8.3232
2024-10-30 17:19:21: [2024-10-30 17:19:21] iter = 11400, loss = 4.2622
2024-10-30 17:19:22: [2024-10-30 17:19:22] iter = 11410, loss = 10.2090
2024-10-30 17:19:23: [2024-10-30 17:19:23] iter = 11420, loss = 1.6830
2024-10-30 17:19:24: [2024-10-30 17:19:24] iter = 11430, loss = 3.1616
2024-10-30 17:19:25: [2024-10-30 17:19:25] iter = 11440, loss = 5.5383
2024-10-30 17:19:26: [2024-10-30 17:19:26] iter = 11450, loss = 1.2713
2024-10-30 17:19:27: [2024-10-30 17:19:27] iter = 11460, loss = 1.0265
2024-10-30 17:19:28: [2024-10-30 17:19:28] iter = 11470, loss = 1.6798
2024-10-30 17:19:28: [2024-10-30 17:19:28] iter = 11480, loss = 4.3474
2024-10-30 17:19:29: [2024-10-30 17:19:29] iter = 11490, loss = 2.0255
2024-10-30 17:19:30: [2024-10-30 17:19:30] iter = 11500, loss = 2.5227
2024-10-30 17:19:31: [2024-10-30 17:19:31] iter = 11510, loss = 15.5131
2024-10-30 17:19:32: [2024-10-30 17:19:32] iter = 11520, loss = 15.9036
2024-10-30 17:19:33: [2024-10-30 17:19:33] iter = 11530, loss = 3.9183
2024-10-30 17:19:33: [2024-10-30 17:19:33] iter = 11540, loss = 1.8888
2024-10-30 17:19:34: [2024-10-30 17:19:34] iter = 11550, loss = 9.8175
2024-10-30 17:19:35: [2024-10-30 17:19:35] iter = 11560, loss = 1.7131
2024-10-30 17:19:36: [2024-10-30 17:19:36] iter = 11570, loss = 1.4695
2024-10-30 17:19:37: [2024-10-30 17:19:37] iter = 11580, loss = 1.6978
2024-10-30 17:19:37: [2024-10-30 17:19:37] iter = 11590, loss = 1.4613
2024-10-30 17:19:38: [2024-10-30 17:19:38] iter = 11600, loss = 4.5647
2024-10-30 17:19:39: [2024-10-30 17:19:39] iter = 11610, loss = 25.6706
2024-10-30 17:19:39: [2024-10-30 17:19:39] iter = 11620, loss = 3.1017
2024-10-30 17:19:40: [2024-10-30 17:19:40] iter = 11630, loss = 14.5654
2024-10-30 17:19:41: [2024-10-30 17:19:41] iter = 11640, loss = 25.9394
2024-10-30 17:19:42: [2024-10-30 17:19:42] iter = 11650, loss = 3.7080
2024-10-30 17:19:43: [2024-10-30 17:19:43] iter = 11660, loss = 2.0006
2024-10-30 17:19:44: [2024-10-30 17:19:44] iter = 11670, loss = 4.6465
2024-10-30 17:19:45: [2024-10-30 17:19:45] iter = 11680, loss = 3.9113
2024-10-30 17:19:46: [2024-10-30 17:19:46] iter = 11690, loss = 14.7554
2024-10-30 17:19:47: [2024-10-30 17:19:47] iter = 11700, loss = 1.6098
2024-10-30 17:19:48: [2024-10-30 17:19:48] iter = 11710, loss = 1.3006
2024-10-30 17:19:48: [2024-10-30 17:19:48] iter = 11720, loss = 1.2555
2024-10-30 17:19:49: [2024-10-30 17:19:49] iter = 11730, loss = 2.3458
2024-10-30 17:19:50: [2024-10-30 17:19:50] iter = 11740, loss = 1.0919
2024-10-30 17:19:51: [2024-10-30 17:19:51] iter = 11750, loss = 2.0978
2024-10-30 17:19:52: [2024-10-30 17:19:52] iter = 11760, loss = 3.6450
2024-10-30 17:19:53: [2024-10-30 17:19:52] iter = 11770, loss = 5.1217
2024-10-30 17:19:54: [2024-10-30 17:19:54] iter = 11780, loss = 7.2547
2024-10-30 17:19:54: [2024-10-30 17:19:54] iter = 11790, loss = 3.5792
2024-10-30 17:19:55: [2024-10-30 17:19:55] iter = 11800, loss = 1.6738
2024-10-30 17:19:56: [2024-10-30 17:19:56] iter = 11810, loss = 2.1521
2024-10-30 17:19:57: [2024-10-30 17:19:57] iter = 11820, loss = 6.7754
2024-10-30 17:19:58: [2024-10-30 17:19:58] iter = 11830, loss = 11.9633
2024-10-30 17:20:00: [2024-10-30 17:20:00] iter = 11840, loss = 4.3666
2024-10-30 17:20:00: [2024-10-30 17:20:00] iter = 11850, loss = 11.5624
2024-10-30 17:20:01: [2024-10-30 17:20:01] iter = 11860, loss = 2.4317
2024-10-30 17:20:02: [2024-10-30 17:20:02] iter = 11870, loss = 1.2815
2024-10-30 17:20:04: [2024-10-30 17:20:04] iter = 11880, loss = 4.6380
2024-10-30 17:20:04: [2024-10-30 17:20:04] iter = 11890, loss = 2.4892
2024-10-30 17:20:05: [2024-10-30 17:20:05] iter = 11900, loss = 27.7473
2024-10-30 17:20:06: [2024-10-30 17:20:06] iter = 11910, loss = 2.0274
2024-10-30 17:20:07: [2024-10-30 17:20:07] iter = 11920, loss = 16.3034
2024-10-30 17:20:08: [2024-10-30 17:20:08] iter = 11930, loss = 6.4433
2024-10-30 17:20:08: [2024-10-30 17:20:08] iter = 11940, loss = 5.2175
2024-10-30 17:20:09: [2024-10-30 17:20:09] iter = 11950, loss = 5.5824
2024-10-30 17:20:10: [2024-10-30 17:20:10] iter = 11960, loss = 2.3216
2024-10-30 17:20:11: [2024-10-30 17:20:11] iter = 11970, loss = 1.4522
2024-10-30 17:20:12: [2024-10-30 17:20:12] iter = 11980, loss = 1.6944
2024-10-30 17:20:13: [2024-10-30 17:20:13] iter = 11990, loss = 2.8438
2024-10-30 17:20:14: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 17:20:14: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:20:14: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 14062}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:21:41: Evaluate 5 random ConvNet, ACCmean = 0.7218 ACCstd = 0.0065
-------------------------
2024-10-30 17:21:41: Evaluate 5 random ConvNet, SENmean = 0.6142 SENstd = 0.0126
-------------------------
2024-10-30 17:21:41: Evaluate 5 random ConvNet, SPEmean = 0.6142 SPEstd = 0.0126
-------------------------
2024-10-30 17:21:41: Evaluate 5 random ConvNet, F!mean = 0.6201 F!std = 0.0124
-------------------------
2024-10-30 17:21:41: Evaluate 5 random ConvNet, mean = 0.7218 std = 0.0065
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:21:41: [2024-10-30 17:21:41] iter = 12000, loss = 3.5125
2024-10-30 17:21:42: [2024-10-30 17:21:42] iter = 12010, loss = 3.8282
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:21:43: [2024-10-30 17:21:43] iter = 12020, loss = 1.7783
2024-10-30 17:21:44: [2024-10-30 17:21:44] iter = 12030, loss = 2.5441
2024-10-30 17:21:46: [2024-10-30 17:21:46] iter = 12040, loss = 1.2184
2024-10-30 17:21:47: [2024-10-30 17:21:47] iter = 12050, loss = 1.1888
2024-10-30 17:21:48: [2024-10-30 17:21:48] iter = 12060, loss = 3.8328
2024-10-30 17:21:49: [2024-10-30 17:21:49] iter = 12070, loss = 1.1150
2024-10-30 17:21:49: [2024-10-30 17:21:49] iter = 12080, loss = 9.5127
2024-10-30 17:21:50: [2024-10-30 17:21:50] iter = 12090, loss = 0.9862
2024-10-30 17:21:51: [2024-10-30 17:21:51] iter = 12100, loss = 1.1157
2024-10-30 17:21:52: [2024-10-30 17:21:52] iter = 12110, loss = 4.0933
2024-10-30 17:21:53: [2024-10-30 17:21:53] iter = 12120, loss = 4.9870
2024-10-30 17:21:54: [2024-10-30 17:21:54] iter = 12130, loss = 3.4653
2024-10-30 17:21:55: [2024-10-30 17:21:54] iter = 12140, loss = 1.4421
2024-10-30 17:21:55: [2024-10-30 17:21:55] iter = 12150, loss = 2.3024
2024-10-30 17:21:56: [2024-10-30 17:21:56] iter = 12160, loss = 3.3678
2024-10-30 17:21:57: [2024-10-30 17:21:57] iter = 12170, loss = 3.1020
2024-10-30 17:21:57: [2024-10-30 17:21:57] iter = 12180, loss = 5.0617
2024-10-30 17:21:58: [2024-10-30 17:21:58] iter = 12190, loss = 2.8703
2024-10-30 17:21:59: [2024-10-30 17:21:59] iter = 12200, loss = 1.9550
2024-10-30 17:22:00: [2024-10-30 17:22:00] iter = 12210, loss = 10.3935
2024-10-30 17:22:00: [2024-10-30 17:22:00] iter = 12220, loss = 2.1491
2024-10-30 17:22:01: [2024-10-30 17:22:01] iter = 12230, loss = 2.9147
2024-10-30 17:22:03: [2024-10-30 17:22:03] iter = 12240, loss = 5.4527
2024-10-30 17:22:04: [2024-10-30 17:22:04] iter = 12250, loss = 2.0121
2024-10-30 17:22:04: [2024-10-30 17:22:04] iter = 12260, loss = 9.3972
2024-10-30 17:22:05: [2024-10-30 17:22:05] iter = 12270, loss = 5.0688
2024-10-30 17:22:06: [2024-10-30 17:22:06] iter = 12280, loss = 1.6394
2024-10-30 17:22:07: [2024-10-30 17:22:07] iter = 12290, loss = 1.2679
2024-10-30 17:22:08: [2024-10-30 17:22:08] iter = 12300, loss = 1.5189
2024-10-30 17:22:09: [2024-10-30 17:22:09] iter = 12310, loss = 5.1308
2024-10-30 17:22:10: [2024-10-30 17:22:10] iter = 12320, loss = 12.5022
2024-10-30 17:22:11: [2024-10-30 17:22:11] iter = 12330, loss = 9.4368
2024-10-30 17:22:11: [2024-10-30 17:22:11] iter = 12340, loss = 7.4675
2024-10-30 17:22:12: [2024-10-30 17:22:12] iter = 12350, loss = 6.7683
2024-10-30 17:22:13: [2024-10-30 17:22:13] iter = 12360, loss = 2.8324
2024-10-30 17:22:14: [2024-10-30 17:22:14] iter = 12370, loss = 2.1659
2024-10-30 17:22:15: [2024-10-30 17:22:15] iter = 12380, loss = 1.5805
2024-10-30 17:22:15: [2024-10-30 17:22:15] iter = 12390, loss = 1.3735
2024-10-30 17:22:16: [2024-10-30 17:22:16] iter = 12400, loss = 1.2822
2024-10-30 17:22:16: [2024-10-30 17:22:16] iter = 12410, loss = 1.5665
2024-10-30 17:22:17: [2024-10-30 17:22:17] iter = 12420, loss = 6.9919
2024-10-30 17:22:17: [2024-10-30 17:22:17] iter = 12430, loss = 2.2277
2024-10-30 17:22:18: [2024-10-30 17:22:18] iter = 12440, loss = 1.8672
2024-10-30 17:22:19: [2024-10-30 17:22:19] iter = 12450, loss = 4.9416
2024-10-30 17:22:20: [2024-10-30 17:22:20] iter = 12460, loss = 6.1880
2024-10-30 17:22:21: [2024-10-30 17:22:21] iter = 12470, loss = 2.9493
2024-10-30 17:22:21: [2024-10-30 17:22:21] iter = 12480, loss = 4.8405
2024-10-30 17:22:22: [2024-10-30 17:22:22] iter = 12490, loss = 1.5989
2024-10-30 17:22:23: [2024-10-30 17:22:23] iter = 12500, loss = 1.8496
2024-10-30 17:22:24: [2024-10-30 17:22:24] iter = 12510, loss = 5.5628
2024-10-30 17:22:24: [2024-10-30 17:22:24] iter = 12520, loss = 1.9883
2024-10-30 17:22:25: [2024-10-30 17:22:25] iter = 12530, loss = 1.7324
2024-10-30 17:22:27: [2024-10-30 17:22:27] iter = 12540, loss = 1.3925
2024-10-30 17:22:28: [2024-10-30 17:22:28] iter = 12550, loss = 3.3265
2024-10-30 17:22:29: [2024-10-30 17:22:29] iter = 12560, loss = 1.4295
2024-10-30 17:22:30: [2024-10-30 17:22:30] iter = 12570, loss = 2.3179
2024-10-30 17:22:31: [2024-10-30 17:22:31] iter = 12580, loss = 3.9039
2024-10-30 17:22:31: [2024-10-30 17:22:31] iter = 12590, loss = 6.2072
2024-10-30 17:22:32: [2024-10-30 17:22:32] iter = 12600, loss = 9.3506
2024-10-30 17:22:33: [2024-10-30 17:22:33] iter = 12610, loss = 3.4289
2024-10-30 17:22:33: [2024-10-30 17:22:33] iter = 12620, loss = 3.1804
2024-10-30 17:22:34: [2024-10-30 17:22:34] iter = 12630, loss = 1.4506
2024-10-30 17:22:34: [2024-10-30 17:22:34] iter = 12640, loss = 2.2618
2024-10-30 17:22:35: [2024-10-30 17:22:35] iter = 12650, loss = 1.2441
2024-10-30 17:22:36: [2024-10-30 17:22:36] iter = 12660, loss = 4.1261
2024-10-30 17:22:37: [2024-10-30 17:22:37] iter = 12670, loss = 1.9942
2024-10-30 17:22:37: [2024-10-30 17:22:37] iter = 12680, loss = 1.4491
2024-10-30 17:22:38: [2024-10-30 17:22:38] iter = 12690, loss = 6.6794
2024-10-30 17:22:39: [2024-10-30 17:22:39] iter = 12700, loss = 4.8327
2024-10-30 17:22:40: [2024-10-30 17:22:40] iter = 12710, loss = 8.8818
2024-10-30 17:22:41: [2024-10-30 17:22:41] iter = 12720, loss = 1.8100
2024-10-30 17:22:41: [2024-10-30 17:22:41] iter = 12730, loss = 9.0518
2024-10-30 17:22:42: [2024-10-30 17:22:42] iter = 12740, loss = 3.6517
2024-10-30 17:22:43: [2024-10-30 17:22:43] iter = 12750, loss = 2.0840
2024-10-30 17:22:43: [2024-10-30 17:22:43] iter = 12760, loss = 1.6166
2024-10-30 17:22:44: [2024-10-30 17:22:44] iter = 12770, loss = 2.1441
2024-10-30 17:22:45: [2024-10-30 17:22:45] iter = 12780, loss = 6.1993
2024-10-30 17:22:46: [2024-10-30 17:22:46] iter = 12790, loss = 1.0527
2024-10-30 17:22:47: [2024-10-30 17:22:47] iter = 12800, loss = 21.2649
2024-10-30 17:22:48: [2024-10-30 17:22:48] iter = 12810, loss = 12.5108
2024-10-30 17:22:49: [2024-10-30 17:22:49] iter = 12820, loss = 3.7490
2024-10-30 17:22:50: [2024-10-30 17:22:50] iter = 12830, loss = 4.0615
2024-10-30 17:22:51: [2024-10-30 17:22:51] iter = 12840, loss = 3.1155
2024-10-30 17:22:51: [2024-10-30 17:22:51] iter = 12850, loss = 1.5715
2024-10-30 17:22:52: [2024-10-30 17:22:52] iter = 12860, loss = 2.7315
2024-10-30 17:22:53: [2024-10-30 17:22:53] iter = 12870, loss = 1.3679
2024-10-30 17:22:54: [2024-10-30 17:22:54] iter = 12880, loss = 0.9416
2024-10-30 17:22:55: [2024-10-30 17:22:55] iter = 12890, loss = 1.2789
2024-10-30 17:22:56: [2024-10-30 17:22:55] iter = 12900, loss = 8.7515
2024-10-30 17:22:57: [2024-10-30 17:22:57] iter = 12910, loss = 1.1364
2024-10-30 17:22:57: [2024-10-30 17:22:57] iter = 12920, loss = 1.1538
2024-10-30 17:22:58: [2024-10-30 17:22:58] iter = 12930, loss = 1.8693
2024-10-30 17:22:59: [2024-10-30 17:22:59] iter = 12940, loss = 2.2906
2024-10-30 17:23:00: [2024-10-30 17:23:00] iter = 12950, loss = 1.0138
2024-10-30 17:23:01: [2024-10-30 17:23:01] iter = 12960, loss = 3.2761
2024-10-30 17:23:02: [2024-10-30 17:23:02] iter = 12970, loss = 1.4004
2024-10-30 17:23:03: [2024-10-30 17:23:03] iter = 12980, loss = 1.9473
2024-10-30 17:23:04: [2024-10-30 17:23:04] iter = 12990, loss = 1.5159
2024-10-30 17:23:05: [2024-10-30 17:23:05] iter = 13000, loss = 3.7234
2024-10-30 17:23:06: [2024-10-30 17:23:06] iter = 13010, loss = 1.5881
2024-10-30 17:23:07: [2024-10-30 17:23:07] iter = 13020, loss = 1.3015
2024-10-30 17:23:07: [2024-10-30 17:23:07] iter = 13030, loss = 1.8938
2024-10-30 17:23:08: [2024-10-30 17:23:08] iter = 13040, loss = 2.3243
2024-10-30 17:23:09: [2024-10-30 17:23:09] iter = 13050, loss = 6.3150
2024-10-30 17:23:11: [2024-10-30 17:23:11] iter = 13060, loss = 2.1301
2024-10-30 17:23:12: [2024-10-30 17:23:12] iter = 13070, loss = 2.5567
2024-10-30 17:23:13: [2024-10-30 17:23:13] iter = 13080, loss = 3.9986
2024-10-30 17:23:14: [2024-10-30 17:23:14] iter = 13090, loss = 1.9750
2024-10-30 17:23:15: [2024-10-30 17:23:15] iter = 13100, loss = 2.9836
2024-10-30 17:23:16: [2024-10-30 17:23:16] iter = 13110, loss = 6.4562
2024-10-30 17:23:17: [2024-10-30 17:23:17] iter = 13120, loss = 2.2602
2024-10-30 17:23:18: [2024-10-30 17:23:18] iter = 13130, loss = 0.9809
2024-10-30 17:23:19: [2024-10-30 17:23:19] iter = 13140, loss = 1.6503
2024-10-30 17:23:20: [2024-10-30 17:23:20] iter = 13150, loss = 1.2927
2024-10-30 17:23:21: [2024-10-30 17:23:21] iter = 13160, loss = 15.6803
2024-10-30 17:23:22: [2024-10-30 17:23:22] iter = 13170, loss = 2.1219
2024-10-30 17:23:23: [2024-10-30 17:23:23] iter = 13180, loss = 2.0273
2024-10-30 17:23:24: [2024-10-30 17:23:24] iter = 13190, loss = 4.3602
2024-10-30 17:23:24: [2024-10-30 17:23:24] iter = 13200, loss = 3.4387
2024-10-30 17:23:25: [2024-10-30 17:23:25] iter = 13210, loss = 12.3481
2024-10-30 17:23:26: [2024-10-30 17:23:26] iter = 13220, loss = 7.1275
2024-10-30 17:23:27: [2024-10-30 17:23:27] iter = 13230, loss = 1.4963
2024-10-30 17:23:28: [2024-10-30 17:23:28] iter = 13240, loss = 2.2951
2024-10-30 17:23:29: [2024-10-30 17:23:29] iter = 13250, loss = 21.8587
2024-10-30 17:23:29: [2024-10-30 17:23:29] iter = 13260, loss = 1.5634
2024-10-30 17:23:30: [2024-10-30 17:23:30] iter = 13270, loss = 4.8241
2024-10-30 17:23:31: [2024-10-30 17:23:31] iter = 13280, loss = 3.1065
2024-10-30 17:23:32: [2024-10-30 17:23:32] iter = 13290, loss = 1.3761
2024-10-30 17:23:33: [2024-10-30 17:23:33] iter = 13300, loss = 1.1541
2024-10-30 17:23:33: [2024-10-30 17:23:33] iter = 13310, loss = 1.4309
2024-10-30 17:23:34: [2024-10-30 17:23:34] iter = 13320, loss = 2.0193
2024-10-30 17:23:35: [2024-10-30 17:23:35] iter = 13330, loss = 2.0045
2024-10-30 17:23:35: [2024-10-30 17:23:35] iter = 13340, loss = 5.5009
2024-10-30 17:23:36: [2024-10-30 17:23:36] iter = 13350, loss = 7.1446
2024-10-30 17:23:37: [2024-10-30 17:23:37] iter = 13360, loss = 5.5884
2024-10-30 17:23:38: [2024-10-30 17:23:38] iter = 13370, loss = 2.2016
2024-10-30 17:23:39: [2024-10-30 17:23:39] iter = 13380, loss = 1.2910
2024-10-30 17:23:40: [2024-10-30 17:23:40] iter = 13390, loss = 3.9047
2024-10-30 17:23:41: [2024-10-30 17:23:41] iter = 13400, loss = 9.3144
2024-10-30 17:23:41: [2024-10-30 17:23:41] iter = 13410, loss = 26.0161
2024-10-30 17:23:42: [2024-10-30 17:23:42] iter = 13420, loss = 2.7204
2024-10-30 17:23:43: [2024-10-30 17:23:43] iter = 13430, loss = 3.3872
2024-10-30 17:23:44: [2024-10-30 17:23:44] iter = 13440, loss = 3.1503
2024-10-30 17:23:45: [2024-10-30 17:23:45] iter = 13450, loss = 1.5039
2024-10-30 17:23:46: [2024-10-30 17:23:46] iter = 13460, loss = 1.2148
2024-10-30 17:23:47: [2024-10-30 17:23:47] iter = 13470, loss = 2.3168
2024-10-30 17:23:47: [2024-10-30 17:23:47] iter = 13480, loss = 6.6547
2024-10-30 17:23:48: [2024-10-30 17:23:48] iter = 13490, loss = 8.6439
2024-10-30 17:23:49: [2024-10-30 17:23:49] iter = 13500, loss = 3.0201
2024-10-30 17:23:50: [2024-10-30 17:23:50] iter = 13510, loss = 44.3994
2024-10-30 17:23:50: [2024-10-30 17:23:50] iter = 13520, loss = 4.0907
2024-10-30 17:23:51: [2024-10-30 17:23:51] iter = 13530, loss = 2.0189
2024-10-30 17:23:52: [2024-10-30 17:23:52] iter = 13540, loss = 5.0849
2024-10-30 17:23:53: [2024-10-30 17:23:53] iter = 13550, loss = 2.3397
2024-10-30 17:23:53: [2024-10-30 17:23:53] iter = 13560, loss = 2.3754
2024-10-30 17:23:55: [2024-10-30 17:23:55] iter = 13570, loss = 17.6606
2024-10-30 17:23:56: [2024-10-30 17:23:56] iter = 13580, loss = 14.0023
2024-10-30 17:23:57: [2024-10-30 17:23:57] iter = 13590, loss = 2.4358
2024-10-30 17:23:58: [2024-10-30 17:23:58] iter = 13600, loss = 1.1564
2024-10-30 17:23:59: [2024-10-30 17:23:59] iter = 13610, loss = 3.7559
2024-10-30 17:24:00: [2024-10-30 17:24:00] iter = 13620, loss = 1.7761
2024-10-30 17:24:01: [2024-10-30 17:24:01] iter = 13630, loss = 2.4743
2024-10-30 17:24:02: [2024-10-30 17:24:02] iter = 13640, loss = 2.7445
2024-10-30 17:24:03: [2024-10-30 17:24:03] iter = 13650, loss = 14.7197
2024-10-30 17:24:04: [2024-10-30 17:24:04] iter = 13660, loss = 3.1607
2024-10-30 17:24:05: [2024-10-30 17:24:05] iter = 13670, loss = 2.0027
2024-10-30 17:24:05: [2024-10-30 17:24:05] iter = 13680, loss = 1.7777
2024-10-30 17:24:06: [2024-10-30 17:24:06] iter = 13690, loss = 2.1369
2024-10-30 17:24:07: [2024-10-30 17:24:07] iter = 13700, loss = 2.0246
2024-10-30 17:24:08: [2024-10-30 17:24:08] iter = 13710, loss = 3.3213
2024-10-30 17:24:08: [2024-10-30 17:24:08] iter = 13720, loss = 3.0761
2024-10-30 17:24:08: [2024-10-30 17:24:08] iter = 13730, loss = 1.3619
2024-10-30 17:24:09: [2024-10-30 17:24:09] iter = 13740, loss = 2.6211
2024-10-30 17:24:10: [2024-10-30 17:24:10] iter = 13750, loss = 2.9943
2024-10-30 17:24:11: [2024-10-30 17:24:11] iter = 13760, loss = 2.1456
2024-10-30 17:24:12: [2024-10-30 17:24:12] iter = 13770, loss = 2.1954
2024-10-30 17:24:13: [2024-10-30 17:24:13] iter = 13780, loss = 4.8923
2024-10-30 17:24:13: [2024-10-30 17:24:13] iter = 13790, loss = 7.1348
2024-10-30 17:24:14: [2024-10-30 17:24:14] iter = 13800, loss = 14.5382
2024-10-30 17:24:15: [2024-10-30 17:24:15] iter = 13810, loss = 1.8681
2024-10-30 17:24:16: [2024-10-30 17:24:16] iter = 13820, loss = 2.2922
2024-10-30 17:24:16: [2024-10-30 17:24:16] iter = 13830, loss = 2.9274
2024-10-30 17:24:17: [2024-10-30 17:24:17] iter = 13840, loss = 6.4104
2024-10-30 17:24:18: [2024-10-30 17:24:18] iter = 13850, loss = 0.9469
2024-10-30 17:24:19: [2024-10-30 17:24:19] iter = 13860, loss = 25.8873
2024-10-30 17:24:20: [2024-10-30 17:24:20] iter = 13870, loss = 4.1662
2024-10-30 17:24:20: [2024-10-30 17:24:20] iter = 13880, loss = 2.3318
2024-10-30 17:24:21: [2024-10-30 17:24:21] iter = 13890, loss = 1.8490
2024-10-30 17:24:22: [2024-10-30 17:24:22] iter = 13900, loss = 4.8759
2024-10-30 17:24:23: [2024-10-30 17:24:23] iter = 13910, loss = 4.8124
2024-10-30 17:24:24: [2024-10-30 17:24:24] iter = 13920, loss = 21.3101
2024-10-30 17:24:25: [2024-10-30 17:24:25] iter = 13930, loss = 1.7794
2024-10-30 17:24:26: [2024-10-30 17:24:26] iter = 13940, loss = 1.4009
2024-10-30 17:24:27: [2024-10-30 17:24:27] iter = 13950, loss = 2.1467
2024-10-30 17:24:28: [2024-10-30 17:24:28] iter = 13960, loss = 1.7152
2024-10-30 17:24:29: [2024-10-30 17:24:29] iter = 13970, loss = 7.2784
2024-10-30 17:24:30: [2024-10-30 17:24:30] iter = 13980, loss = 14.6517
2024-10-30 17:24:31: [2024-10-30 17:24:31] iter = 13990, loss = 8.2947
2024-10-30 17:24:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 17:24:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:24:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 72134}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:26:06: Evaluate 5 random ConvNet, ACCmean = 0.7782 ACCstd = 0.0184
-------------------------
2024-10-30 17:26:06: Evaluate 5 random ConvNet, SENmean = 0.7159 SENstd = 0.0188
-------------------------
2024-10-30 17:26:06: Evaluate 5 random ConvNet, SPEmean = 0.7159 SPEstd = 0.0188
-------------------------
2024-10-30 17:26:06: Evaluate 5 random ConvNet, F!mean = 0.7170 F!std = 0.0206
-------------------------
2024-10-30 17:26:06: Evaluate 5 random ConvNet, mean = 0.7782 std = 0.0184
-------------------------
2024-10-30 17:26:06: [2024-10-30 17:26:06] iter = 14000, loss = 15.1270
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:26:07: [2024-10-30 17:26:07] iter = 14010, loss = 3.1361
2024-10-30 17:26:08: [2024-10-30 17:26:08] iter = 14020, loss = 6.7839
2024-10-30 17:26:09: [2024-10-30 17:26:09] iter = 14030, loss = 2.1115
2024-10-30 17:26:10: [2024-10-30 17:26:10] iter = 14040, loss = 1.4824
2024-10-30 17:26:10: [2024-10-30 17:26:10] iter = 14050, loss = 1.9405
2024-10-30 17:26:11: [2024-10-30 17:26:11] iter = 14060, loss = 1.7812
2024-10-30 17:26:11: [2024-10-30 17:26:11] iter = 14070, loss = 5.3932
2024-10-30 17:26:12: [2024-10-30 17:26:12] iter = 14080, loss = 2.0050
2024-10-30 17:26:13: [2024-10-30 17:26:13] iter = 14090, loss = 10.6551
2024-10-30 17:26:14: [2024-10-30 17:26:14] iter = 14100, loss = 10.1427
2024-10-30 17:26:15: [2024-10-30 17:26:15] iter = 14110, loss = 1.9565
2024-10-30 17:26:16: [2024-10-30 17:26:16] iter = 14120, loss = 4.4466
2024-10-30 17:26:17: [2024-10-30 17:26:17] iter = 14130, loss = 14.8706
2024-10-30 17:26:17: [2024-10-30 17:26:17] iter = 14140, loss = 1.7798
2024-10-30 17:26:18: [2024-10-30 17:26:18] iter = 14150, loss = 0.9978
2024-10-30 17:26:19: [2024-10-30 17:26:19] iter = 14160, loss = 2.1344
2024-10-30 17:26:20: [2024-10-30 17:26:20] iter = 14170, loss = 15.3632
2024-10-30 17:26:21: [2024-10-30 17:26:21] iter = 14180, loss = 1.2946
2024-10-30 17:26:21: [2024-10-30 17:26:21] iter = 14190, loss = 1.1762
2024-10-30 17:26:22: [2024-10-30 17:26:22] iter = 14200, loss = 1.4942
2024-10-30 17:26:23: [2024-10-30 17:26:23] iter = 14210, loss = 1.0291
2024-10-30 17:26:24: [2024-10-30 17:26:24] iter = 14220, loss = 1.5497
2024-10-30 17:26:25: [2024-10-30 17:26:25] iter = 14230, loss = 1.4099
2024-10-30 17:26:26: [2024-10-30 17:26:26] iter = 14240, loss = 2.4077
2024-10-30 17:26:27: [2024-10-30 17:26:27] iter = 14250, loss = 1.2170
2024-10-30 17:26:28: [2024-10-30 17:26:28] iter = 14260, loss = 1.2751
2024-10-30 17:26:29: [2024-10-30 17:26:29] iter = 14270, loss = 25.8527
2024-10-30 17:26:30: [2024-10-30 17:26:30] iter = 14280, loss = 2.2766
2024-10-30 17:26:31: [2024-10-30 17:26:31] iter = 14290, loss = 3.2399
2024-10-30 17:26:32: [2024-10-30 17:26:32] iter = 14300, loss = 3.3460
2024-10-30 17:26:33: [2024-10-30 17:26:33] iter = 14310, loss = 4.9430
2024-10-30 17:26:33: [2024-10-30 17:26:33] iter = 14320, loss = 5.0714
2024-10-30 17:26:34: [2024-10-30 17:26:34] iter = 14330, loss = 1.7960
2024-10-30 17:26:35: [2024-10-30 17:26:35] iter = 14340, loss = 1.3458
2024-10-30 17:26:36: [2024-10-30 17:26:36] iter = 14350, loss = 2.3135
2024-10-30 17:26:37: [2024-10-30 17:26:37] iter = 14360, loss = 3.7238
2024-10-30 17:26:38: [2024-10-30 17:26:38] iter = 14370, loss = 1.8805
2024-10-30 17:26:39: [2024-10-30 17:26:39] iter = 14380, loss = 9.2791
2024-10-30 17:26:40: [2024-10-30 17:26:40] iter = 14390, loss = 1.4601
2024-10-30 17:26:41: [2024-10-30 17:26:41] iter = 14400, loss = 8.9131
2024-10-30 17:26:42: [2024-10-30 17:26:41] iter = 14410, loss = 1.3986
2024-10-30 17:26:42: [2024-10-30 17:26:42] iter = 14420, loss = 2.7399
2024-10-30 17:26:43: [2024-10-30 17:26:43] iter = 14430, loss = 12.0785
2024-10-30 17:26:44: [2024-10-30 17:26:44] iter = 14440, loss = 4.8774
2024-10-30 17:26:45: [2024-10-30 17:26:45] iter = 14450, loss = 2.1774
2024-10-30 17:26:46: [2024-10-30 17:26:46] iter = 14460, loss = 8.6280
2024-10-30 17:26:47: [2024-10-30 17:26:47] iter = 14470, loss = 1.8140
2024-10-30 17:26:48: [2024-10-30 17:26:48] iter = 14480, loss = 5.0797
2024-10-30 17:26:49: [2024-10-30 17:26:49] iter = 14490, loss = 10.2508
2024-10-30 17:26:50: [2024-10-30 17:26:50] iter = 14500, loss = 4.5243
2024-10-30 17:26:51: [2024-10-30 17:26:51] iter = 14510, loss = 1.1334
2024-10-30 17:26:53: [2024-10-30 17:26:53] iter = 14520, loss = 4.9179
2024-10-30 17:26:54: [2024-10-30 17:26:54] iter = 14530, loss = 2.2623
2024-10-30 17:26:55: [2024-10-30 17:26:55] iter = 14540, loss = 2.0625
2024-10-30 17:26:57: [2024-10-30 17:26:56] iter = 14550, loss = 2.4971
2024-10-30 17:26:57: [2024-10-30 17:26:57] iter = 14560, loss = 8.7225
2024-10-30 17:26:58: [2024-10-30 17:26:58] iter = 14570, loss = 1.6491
2024-10-30 17:26:59: [2024-10-30 17:26:59] iter = 14580, loss = 1.6979
2024-10-30 17:27:00: [2024-10-30 17:27:00] iter = 14590, loss = 2.8802
2024-10-30 17:27:00: [2024-10-30 17:27:00] iter = 14600, loss = 10.9081
2024-10-30 17:27:01: [2024-10-30 17:27:01] iter = 14610, loss = 8.8924
2024-10-30 17:27:02: [2024-10-30 17:27:02] iter = 14620, loss = 1.5732
2024-10-30 17:27:03: [2024-10-30 17:27:03] iter = 14630, loss = 2.7010
2024-10-30 17:27:04: [2024-10-30 17:27:04] iter = 14640, loss = 9.7343
2024-10-30 17:27:05: [2024-10-30 17:27:05] iter = 14650, loss = 4.8830
2024-10-30 17:27:06: [2024-10-30 17:27:06] iter = 14660, loss = 1.9544
2024-10-30 17:27:07: [2024-10-30 17:27:07] iter = 14670, loss = 6.9426
2024-10-30 17:27:07: [2024-10-30 17:27:07] iter = 14680, loss = 1.9303
2024-10-30 17:27:08: [2024-10-30 17:27:08] iter = 14690, loss = 4.0702
2024-10-30 17:27:09: [2024-10-30 17:27:09] iter = 14700, loss = 5.4793
2024-10-30 17:27:10: [2024-10-30 17:27:10] iter = 14710, loss = 1.8913
2024-10-30 17:27:11: [2024-10-30 17:27:11] iter = 14720, loss = 1.8046
2024-10-30 17:27:12: [2024-10-30 17:27:12] iter = 14730, loss = 1.7922
2024-10-30 17:27:13: [2024-10-30 17:27:13] iter = 14740, loss = 1.6661
2024-10-30 17:27:14: [2024-10-30 17:27:14] iter = 14750, loss = 1.8264
2024-10-30 17:27:15: [2024-10-30 17:27:15] iter = 14760, loss = 1.5889
2024-10-30 17:27:16: [2024-10-30 17:27:16] iter = 14770, loss = 1.4561
2024-10-30 17:27:18: [2024-10-30 17:27:18] iter = 14780, loss = 14.4867
2024-10-30 17:27:19: [2024-10-30 17:27:19] iter = 14790, loss = 1.7830
2024-10-30 17:27:20: [2024-10-30 17:27:20] iter = 14800, loss = 1.3397
2024-10-30 17:27:21: [2024-10-30 17:27:21] iter = 14810, loss = 3.1988
2024-10-30 17:27:22: [2024-10-30 17:27:22] iter = 14820, loss = 3.4622
2024-10-30 17:27:23: [2024-10-30 17:27:23] iter = 14830, loss = 2.7034
2024-10-30 17:27:24: [2024-10-30 17:27:24] iter = 14840, loss = 8.7167
2024-10-30 17:27:25: [2024-10-30 17:27:25] iter = 14850, loss = 1.3277
2024-10-30 17:27:26: [2024-10-30 17:27:26] iter = 14860, loss = 1.4519
2024-10-30 17:27:27: [2024-10-30 17:27:27] iter = 14870, loss = 1.4833
2024-10-30 17:27:28: [2024-10-30 17:27:28] iter = 14880, loss = 3.6091
2024-10-30 17:27:29: [2024-10-30 17:27:29] iter = 14890, loss = 2.4582
2024-10-30 17:27:30: [2024-10-30 17:27:30] iter = 14900, loss = 1.2886
2024-10-30 17:27:31: [2024-10-30 17:27:31] iter = 14910, loss = 1.6534
2024-10-30 17:27:32: [2024-10-30 17:27:32] iter = 14920, loss = 1.5643
2024-10-30 17:27:33: [2024-10-30 17:27:33] iter = 14930, loss = 13.8707
2024-10-30 17:27:34: [2024-10-30 17:27:34] iter = 14940, loss = 29.9170
2024-10-30 17:27:35: [2024-10-30 17:27:35] iter = 14950, loss = 5.8693
2024-10-30 17:27:35: [2024-10-30 17:27:35] iter = 14960, loss = 4.4461
2024-10-30 17:27:36: [2024-10-30 17:27:36] iter = 14970, loss = 2.8327
2024-10-30 17:27:37: [2024-10-30 17:27:37] iter = 14980, loss = 1.5015
2024-10-30 17:27:38: [2024-10-30 17:27:38] iter = 14990, loss = 6.1862
2024-10-30 17:27:39: [2024-10-30 17:27:39] iter = 15000, loss = 17.9241
2024-10-30 17:27:40: [2024-10-30 17:27:40] iter = 15010, loss = 1.4681
2024-10-30 17:27:40: [2024-10-30 17:27:40] iter = 15020, loss = 1.4493
2024-10-30 17:27:41: [2024-10-30 17:27:41] iter = 15030, loss = 5.6216
2024-10-30 17:27:42: [2024-10-30 17:27:42] iter = 15040, loss = 2.5942
2024-10-30 17:27:43: [2024-10-30 17:27:43] iter = 15050, loss = 7.5851
2024-10-30 17:27:44: [2024-10-30 17:27:44] iter = 15060, loss = 2.7574
2024-10-30 17:27:45: [2024-10-30 17:27:45] iter = 15070, loss = 2.1456
2024-10-30 17:27:46: [2024-10-30 17:27:46] iter = 15080, loss = 2.2790
2024-10-30 17:27:46: [2024-10-30 17:27:46] iter = 15090, loss = 9.3881
2024-10-30 17:27:47: [2024-10-30 17:27:47] iter = 15100, loss = 2.4345
2024-10-30 17:27:48: [2024-10-30 17:27:48] iter = 15110, loss = 1.6452
2024-10-30 17:27:48: [2024-10-30 17:27:48] iter = 15120, loss = 4.2518
2024-10-30 17:27:49: [2024-10-30 17:27:49] iter = 15130, loss = 3.1936
2024-10-30 17:27:49: [2024-10-30 17:27:49] iter = 15140, loss = 2.7057
2024-10-30 17:27:50: [2024-10-30 17:27:50] iter = 15150, loss = 5.0031
2024-10-30 17:27:51: [2024-10-30 17:27:51] iter = 15160, loss = 3.8961
2024-10-30 17:27:52: [2024-10-30 17:27:52] iter = 15170, loss = 6.6385
2024-10-30 17:27:53: [2024-10-30 17:27:53] iter = 15180, loss = 1.7956
2024-10-30 17:27:54: [2024-10-30 17:27:54] iter = 15190, loss = 0.9521
2024-10-30 17:27:55: [2024-10-30 17:27:55] iter = 15200, loss = 1.4193
2024-10-30 17:27:56: [2024-10-30 17:27:56] iter = 15210, loss = 3.5263
2024-10-30 17:27:57: [2024-10-30 17:27:57] iter = 15220, loss = 1.3989
2024-10-30 17:27:57: [2024-10-30 17:27:57] iter = 15230, loss = 2.3236
2024-10-30 17:27:58: [2024-10-30 17:27:58] iter = 15240, loss = 7.2610
2024-10-30 17:27:59: [2024-10-30 17:27:59] iter = 15250, loss = 1.5938
2024-10-30 17:28:00: [2024-10-30 17:28:00] iter = 15260, loss = 2.7555
2024-10-30 17:28:01: [2024-10-30 17:28:01] iter = 15270, loss = 12.7649
2024-10-30 17:28:02: [2024-10-30 17:28:02] iter = 15280, loss = 3.8350
2024-10-30 17:28:02: [2024-10-30 17:28:02] iter = 15290, loss = 4.3468
2024-10-30 17:28:03: [2024-10-30 17:28:03] iter = 15300, loss = 2.0952
2024-10-30 17:28:04: [2024-10-30 17:28:04] iter = 15310, loss = 2.7457
2024-10-30 17:28:05: [2024-10-30 17:28:05] iter = 15320, loss = 1.3345
2024-10-30 17:28:05: [2024-10-30 17:28:05] iter = 15330, loss = 5.2601
2024-10-30 17:28:06: [2024-10-30 17:28:06] iter = 15340, loss = 18.3189
2024-10-30 17:28:07: [2024-10-30 17:28:07] iter = 15350, loss = 1.5486
2024-10-30 17:28:07: [2024-10-30 17:28:07] iter = 15360, loss = 2.2608
2024-10-30 17:28:08: [2024-10-30 17:28:08] iter = 15370, loss = 5.1296
2024-10-30 17:28:08: [2024-10-30 17:28:08] iter = 15380, loss = 5.3011
2024-10-30 17:28:09: [2024-10-30 17:28:09] iter = 15390, loss = 3.1881
2024-10-30 17:28:10: [2024-10-30 17:28:10] iter = 15400, loss = 1.0289
2024-10-30 17:28:11: [2024-10-30 17:28:11] iter = 15410, loss = 1.7960
2024-10-30 17:28:11: [2024-10-30 17:28:11] iter = 15420, loss = 6.4737
2024-10-30 17:28:13: [2024-10-30 17:28:13] iter = 15430, loss = 9.9393
2024-10-30 17:28:14: [2024-10-30 17:28:14] iter = 15440, loss = 2.7331
2024-10-30 17:28:15: [2024-10-30 17:28:15] iter = 15450, loss = 1.1092
2024-10-30 17:28:16: [2024-10-30 17:28:16] iter = 15460, loss = 9.0130
2024-10-30 17:28:17: [2024-10-30 17:28:17] iter = 15470, loss = 2.1979
2024-10-30 17:28:18: [2024-10-30 17:28:18] iter = 15480, loss = 2.0600
2024-10-30 17:28:19: [2024-10-30 17:28:19] iter = 15490, loss = 4.1175
2024-10-30 17:28:20: [2024-10-30 17:28:20] iter = 15500, loss = 14.6604
2024-10-30 17:28:21: [2024-10-30 17:28:21] iter = 15510, loss = 2.5421
2024-10-30 17:28:22: [2024-10-30 17:28:22] iter = 15520, loss = 3.0118
2024-10-30 17:28:24: [2024-10-30 17:28:23] iter = 15530, loss = 3.4962
2024-10-30 17:28:24: [2024-10-30 17:28:24] iter = 15540, loss = 3.2919
2024-10-30 17:28:25: [2024-10-30 17:28:25] iter = 15550, loss = 1.9557
2024-10-30 17:28:26: [2024-10-30 17:28:26] iter = 15560, loss = 5.5931
2024-10-30 17:28:27: [2024-10-30 17:28:27] iter = 15570, loss = 3.8200
2024-10-30 17:28:28: [2024-10-30 17:28:28] iter = 15580, loss = 2.5829
2024-10-30 17:28:29: [2024-10-30 17:28:29] iter = 15590, loss = 2.0186
2024-10-30 17:28:30: [2024-10-30 17:28:30] iter = 15600, loss = 1.1803
2024-10-30 17:28:31: [2024-10-30 17:28:31] iter = 15610, loss = 1.8455
2024-10-30 17:28:32: [2024-10-30 17:28:32] iter = 15620, loss = 1.5752
2024-10-30 17:28:33: [2024-10-30 17:28:33] iter = 15630, loss = 17.5729
2024-10-30 17:28:33: [2024-10-30 17:28:33] iter = 15640, loss = 1.6505
2024-10-30 17:28:34: [2024-10-30 17:28:34] iter = 15650, loss = 3.2810
2024-10-30 17:28:35: [2024-10-30 17:28:35] iter = 15660, loss = 1.9007
2024-10-30 17:28:36: [2024-10-30 17:28:36] iter = 15670, loss = 6.1835
2024-10-30 17:28:37: [2024-10-30 17:28:37] iter = 15680, loss = 4.4872
2024-10-30 17:28:38: [2024-10-30 17:28:38] iter = 15690, loss = 1.2578
2024-10-30 17:28:39: [2024-10-30 17:28:39] iter = 15700, loss = 1.5520
2024-10-30 17:28:40: [2024-10-30 17:28:40] iter = 15710, loss = 1.4303
2024-10-30 17:28:41: [2024-10-30 17:28:41] iter = 15720, loss = 1.5371
2024-10-30 17:28:42: [2024-10-30 17:28:42] iter = 15730, loss = 2.0357
2024-10-30 17:28:43: [2024-10-30 17:28:43] iter = 15740, loss = 3.1904
2024-10-30 17:28:44: [2024-10-30 17:28:44] iter = 15750, loss = 9.0797
2024-10-30 17:28:45: [2024-10-30 17:28:45] iter = 15760, loss = 4.1618
2024-10-30 17:28:46: [2024-10-30 17:28:46] iter = 15770, loss = 2.0910
2024-10-30 17:28:47: [2024-10-30 17:28:47] iter = 15780, loss = 7.2643
2024-10-30 17:28:48: [2024-10-30 17:28:48] iter = 15790, loss = 1.5248
2024-10-30 17:28:49: [2024-10-30 17:28:49] iter = 15800, loss = 5.7275
2024-10-30 17:28:50: [2024-10-30 17:28:50] iter = 15810, loss = 3.1914
2024-10-30 17:28:51: [2024-10-30 17:28:51] iter = 15820, loss = 2.3631
2024-10-30 17:28:52: [2024-10-30 17:28:52] iter = 15830, loss = 1.7554
2024-10-30 17:28:53: [2024-10-30 17:28:53] iter = 15840, loss = 4.5398
2024-10-30 17:28:54: [2024-10-30 17:28:54] iter = 15850, loss = 3.1436
2024-10-30 17:28:55: [2024-10-30 17:28:55] iter = 15860, loss = 4.9648
2024-10-30 17:28:56: [2024-10-30 17:28:56] iter = 15870, loss = 1.6461
2024-10-30 17:28:57: [2024-10-30 17:28:57] iter = 15880, loss = 19.0197
2024-10-30 17:28:58: [2024-10-30 17:28:58] iter = 15890, loss = 1.7276
2024-10-30 17:29:00: [2024-10-30 17:29:00] iter = 15900, loss = 2.3793
2024-10-30 17:29:01: [2024-10-30 17:29:01] iter = 15910, loss = 7.6865
2024-10-30 17:29:02: [2024-10-30 17:29:02] iter = 15920, loss = 4.2810
2024-10-30 17:29:03: [2024-10-30 17:29:03] iter = 15930, loss = 11.4281
2024-10-30 17:29:04: [2024-10-30 17:29:04] iter = 15940, loss = 4.5395
2024-10-30 17:29:05: [2024-10-30 17:29:05] iter = 15950, loss = 3.1304
2024-10-30 17:29:06: [2024-10-30 17:29:06] iter = 15960, loss = 4.1606
2024-10-30 17:29:07: [2024-10-30 17:29:07] iter = 15970, loss = 10.7764
2024-10-30 17:29:08: [2024-10-30 17:29:08] iter = 15980, loss = 5.2121
2024-10-30 17:29:09: [2024-10-30 17:29:09] iter = 15990, loss = 2.1096
2024-10-30 17:29:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 17:29:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:29:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 49718}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:30:44: Evaluate 5 random ConvNet, ACCmean = 0.6154 ACCstd = 0.0177
-------------------------
2024-10-30 17:30:44: Evaluate 5 random ConvNet, SENmean = 0.6692 SENstd = 0.0160
-------------------------
2024-10-30 17:30:44: Evaluate 5 random ConvNet, SPEmean = 0.6692 SPEstd = 0.0160
-------------------------
2024-10-30 17:30:44: Evaluate 5 random ConvNet, F!mean = 0.6006 F!std = 0.0163
-------------------------
2024-10-30 17:30:44: Evaluate 5 random ConvNet, mean = 0.6154 std = 0.0177
-------------------------
2024-10-30 17:30:44: [2024-10-30 17:30:44] iter = 16000, loss = 4.1765
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:30:45: [2024-10-30 17:30:45] iter = 16010, loss = 4.1786
2024-10-30 17:30:46: [2024-10-30 17:30:46] iter = 16020, loss = 26.2969
2024-10-30 17:30:47: [2024-10-30 17:30:47] iter = 16030, loss = 3.2888
2024-10-30 17:30:48: [2024-10-30 17:30:48] iter = 16040, loss = 6.0300
2024-10-30 17:30:49: [2024-10-30 17:30:49] iter = 16050, loss = 19.5491
2024-10-30 17:30:50: [2024-10-30 17:30:50] iter = 16060, loss = 1.9210
2024-10-30 17:30:52: [2024-10-30 17:30:52] iter = 16070, loss = 2.7029
2024-10-30 17:30:53: [2024-10-30 17:30:53] iter = 16080, loss = 4.0397
2024-10-30 17:30:54: [2024-10-30 17:30:54] iter = 16090, loss = 1.2733
2024-10-30 17:30:54: [2024-10-30 17:30:54] iter = 16100, loss = 4.3656
2024-10-30 17:30:55: [2024-10-30 17:30:55] iter = 16110, loss = 13.9361
2024-10-30 17:30:56: [2024-10-30 17:30:56] iter = 16120, loss = 4.2446
2024-10-30 17:30:57: [2024-10-30 17:30:57] iter = 16130, loss = 3.5349
2024-10-30 17:30:58: [2024-10-30 17:30:58] iter = 16140, loss = 1.7820
2024-10-30 17:30:59: [2024-10-30 17:30:59] iter = 16150, loss = 13.7210
2024-10-30 17:31:00: [2024-10-30 17:31:00] iter = 16160, loss = 4.1338
2024-10-30 17:31:00: [2024-10-30 17:31:00] iter = 16170, loss = 7.3841
2024-10-30 17:31:01: [2024-10-30 17:31:01] iter = 16180, loss = 20.2988
2024-10-30 17:31:02: [2024-10-30 17:31:02] iter = 16190, loss = 1.8251
2024-10-30 17:31:03: [2024-10-30 17:31:03] iter = 16200, loss = 3.6698
2024-10-30 17:31:04: [2024-10-30 17:31:04] iter = 16210, loss = 1.7393
2024-10-30 17:31:05: [2024-10-30 17:31:05] iter = 16220, loss = 3.6458
2024-10-30 17:31:06: [2024-10-30 17:31:06] iter = 16230, loss = 1.5289
2024-10-30 17:31:07: [2024-10-30 17:31:07] iter = 16240, loss = 1.7528
2024-10-30 17:31:08: [2024-10-30 17:31:08] iter = 16250, loss = 1.8459
2024-10-30 17:31:09: [2024-10-30 17:31:09] iter = 16260, loss = 2.2872
2024-10-30 17:31:10: [2024-10-30 17:31:10] iter = 16270, loss = 4.2808
2024-10-30 17:31:11: [2024-10-30 17:31:11] iter = 16280, loss = 2.3381
2024-10-30 17:31:12: [2024-10-30 17:31:12] iter = 16290, loss = 6.0398
2024-10-30 17:31:13: [2024-10-30 17:31:13] iter = 16300, loss = 2.5880
2024-10-30 17:31:14: [2024-10-30 17:31:14] iter = 16310, loss = 1.2713
2024-10-30 17:31:15: [2024-10-30 17:31:15] iter = 16320, loss = 2.9387
2024-10-30 17:31:16: [2024-10-30 17:31:16] iter = 16330, loss = 37.8318
2024-10-30 17:31:16: [2024-10-30 17:31:16] iter = 16340, loss = 7.0390
2024-10-30 17:31:17: [2024-10-30 17:31:17] iter = 16350, loss = 1.2476
2024-10-30 17:31:18: [2024-10-30 17:31:18] iter = 16360, loss = 3.1217
2024-10-30 17:31:19: [2024-10-30 17:31:19] iter = 16370, loss = 4.7590
2024-10-30 17:31:21: [2024-10-30 17:31:21] iter = 16380, loss = 4.8277
2024-10-30 17:31:21: [2024-10-30 17:31:21] iter = 16390, loss = 2.3762
2024-10-30 17:31:22: [2024-10-30 17:31:22] iter = 16400, loss = 27.2113
2024-10-30 17:31:24: [2024-10-30 17:31:24] iter = 16410, loss = 1.3343
2024-10-30 17:31:25: [2024-10-30 17:31:25] iter = 16420, loss = 1.1283
2024-10-30 17:31:26: [2024-10-30 17:31:26] iter = 16430, loss = 24.8446
2024-10-30 17:31:27: [2024-10-30 17:31:27] iter = 16440, loss = 3.5143
2024-10-30 17:31:28: [2024-10-30 17:31:28] iter = 16450, loss = 1.2731
2024-10-30 17:31:29: [2024-10-30 17:31:29] iter = 16460, loss = 2.7548
2024-10-30 17:31:30: [2024-10-30 17:31:30] iter = 16470, loss = 1.2758
2024-10-30 17:31:31: [2024-10-30 17:31:31] iter = 16480, loss = 7.1098
2024-10-30 17:31:32: [2024-10-30 17:31:32] iter = 16490, loss = 2.9051
2024-10-30 17:31:33: [2024-10-30 17:31:33] iter = 16500, loss = 3.0186
2024-10-30 17:31:34: [2024-10-30 17:31:34] iter = 16510, loss = 12.0546
2024-10-30 17:31:35: [2024-10-30 17:31:35] iter = 16520, loss = 1.8681
2024-10-30 17:31:36: [2024-10-30 17:31:36] iter = 16530, loss = 5.5414
2024-10-30 17:31:37: [2024-10-30 17:31:37] iter = 16540, loss = 2.9168
2024-10-30 17:31:38: [2024-10-30 17:31:38] iter = 16550, loss = 1.7263
2024-10-30 17:31:38: [2024-10-30 17:31:38] iter = 16560, loss = 1.6069
2024-10-30 17:31:39: [2024-10-30 17:31:39] iter = 16570, loss = 2.8891
2024-10-30 17:31:40: [2024-10-30 17:31:40] iter = 16580, loss = 1.2077
2024-10-30 17:31:41: [2024-10-30 17:31:41] iter = 16590, loss = 1.9928
2024-10-30 17:31:42: [2024-10-30 17:31:42] iter = 16600, loss = 1.2078
2024-10-30 17:31:43: [2024-10-30 17:31:43] iter = 16610, loss = 2.0154
2024-10-30 17:31:44: [2024-10-30 17:31:44] iter = 16620, loss = 1.9223
2024-10-30 17:31:45: [2024-10-30 17:31:45] iter = 16630, loss = 4.3425
2024-10-30 17:31:46: [2024-10-30 17:31:46] iter = 16640, loss = 8.0911
2024-10-30 17:31:47: [2024-10-30 17:31:47] iter = 16650, loss = 1.7464
2024-10-30 17:31:48: [2024-10-30 17:31:48] iter = 16660, loss = 18.9816
2024-10-30 17:31:49: [2024-10-30 17:31:49] iter = 16670, loss = 2.9382
2024-10-30 17:31:50: [2024-10-30 17:31:50] iter = 16680, loss = 4.9112
2024-10-30 17:31:51: [2024-10-30 17:31:51] iter = 16690, loss = 1.4262
2024-10-30 17:31:52: [2024-10-30 17:31:52] iter = 16700, loss = 11.7263
2024-10-30 17:31:53: [2024-10-30 17:31:53] iter = 16710, loss = 1.0099
2024-10-30 17:31:54: [2024-10-30 17:31:54] iter = 16720, loss = 1.1246
2024-10-30 17:31:55: [2024-10-30 17:31:55] iter = 16730, loss = 1.1309
2024-10-30 17:31:56: [2024-10-30 17:31:56] iter = 16740, loss = 1.3506
2024-10-30 17:31:57: [2024-10-30 17:31:57] iter = 16750, loss = 1.9159
2024-10-30 17:31:58: [2024-10-30 17:31:58] iter = 16760, loss = 0.8790
2024-10-30 17:31:59: [2024-10-30 17:31:59] iter = 16770, loss = 1.8069
2024-10-30 17:32:00: [2024-10-30 17:32:00] iter = 16780, loss = 6.1779
2024-10-30 17:32:01: [2024-10-30 17:32:01] iter = 16790, loss = 6.0831
2024-10-30 17:32:02: [2024-10-30 17:32:02] iter = 16800, loss = 2.3904
2024-10-30 17:32:03: [2024-10-30 17:32:03] iter = 16810, loss = 18.6584
2024-10-30 17:32:04: [2024-10-30 17:32:04] iter = 16820, loss = 4.3488
2024-10-30 17:32:04: [2024-10-30 17:32:04] iter = 16830, loss = 4.0235
2024-10-30 17:32:06: [2024-10-30 17:32:06] iter = 16840, loss = 2.5119
2024-10-30 17:32:07: [2024-10-30 17:32:07] iter = 16850, loss = 2.8409
2024-10-30 17:32:08: [2024-10-30 17:32:08] iter = 16860, loss = 1.7080
2024-10-30 17:32:09: [2024-10-30 17:32:09] iter = 16870, loss = 6.6222
2024-10-30 17:32:10: [2024-10-30 17:32:10] iter = 16880, loss = 4.9584
2024-10-30 17:32:11: [2024-10-30 17:32:11] iter = 16890, loss = 2.9452
2024-10-30 17:32:12: [2024-10-30 17:32:12] iter = 16900, loss = 3.9117
2024-10-30 17:32:13: [2024-10-30 17:32:13] iter = 16910, loss = 3.7423
2024-10-30 17:32:14: [2024-10-30 17:32:14] iter = 16920, loss = 2.9200
2024-10-30 17:32:14: [2024-10-30 17:32:14] iter = 16930, loss = 16.3953
2024-10-30 17:32:15: [2024-10-30 17:32:15] iter = 16940, loss = 3.2409
2024-10-30 17:32:16: [2024-10-30 17:32:16] iter = 16950, loss = 4.8483
2024-10-30 17:32:17: [2024-10-30 17:32:17] iter = 16960, loss = 20.4599
2024-10-30 17:32:18: [2024-10-30 17:32:18] iter = 16970, loss = 12.0996
2024-10-30 17:32:18: [2024-10-30 17:32:18] iter = 16980, loss = 1.7643
2024-10-30 17:32:20: [2024-10-30 17:32:20] iter = 16990, loss = 15.9708
2024-10-30 17:32:21: [2024-10-30 17:32:21] iter = 17000, loss = 3.2124
2024-10-30 17:32:22: [2024-10-30 17:32:22] iter = 17010, loss = 1.3470
2024-10-30 17:32:23: [2024-10-30 17:32:23] iter = 17020, loss = 1.7903
2024-10-30 17:32:24: [2024-10-30 17:32:24] iter = 17030, loss = 1.5382
2024-10-30 17:32:24: [2024-10-30 17:32:24] iter = 17040, loss = 3.0363
2024-10-30 17:32:25: [2024-10-30 17:32:25] iter = 17050, loss = 2.1645
2024-10-30 17:32:26: [2024-10-30 17:32:26] iter = 17060, loss = 33.5715
2024-10-30 17:32:27: [2024-10-30 17:32:27] iter = 17070, loss = 3.4433
2024-10-30 17:32:27: [2024-10-30 17:32:27] iter = 17080, loss = 1.6965
2024-10-30 17:32:28: [2024-10-30 17:32:28] iter = 17090, loss = 2.5000
2024-10-30 17:32:29: [2024-10-30 17:32:29] iter = 17100, loss = 6.6206
2024-10-30 17:32:30: [2024-10-30 17:32:30] iter = 17110, loss = 10.5807
2024-10-30 17:32:31: [2024-10-30 17:32:31] iter = 17120, loss = 2.9740
2024-10-30 17:32:32: [2024-10-30 17:32:32] iter = 17130, loss = 3.6067
2024-10-30 17:32:33: [2024-10-30 17:32:33] iter = 17140, loss = 20.2260
2024-10-30 17:32:34: [2024-10-30 17:32:34] iter = 17150, loss = 2.3429
2024-10-30 17:32:35: [2024-10-30 17:32:35] iter = 17160, loss = 1.3859
2024-10-30 17:32:35: [2024-10-30 17:32:35] iter = 17170, loss = 8.9994
2024-10-30 17:32:36: [2024-10-30 17:32:36] iter = 17180, loss = 2.1147
2024-10-30 17:32:37: [2024-10-30 17:32:37] iter = 17190, loss = 1.9250
2024-10-30 17:32:38: [2024-10-30 17:32:38] iter = 17200, loss = 5.4551
2024-10-30 17:32:39: [2024-10-30 17:32:39] iter = 17210, loss = 1.4018
2024-10-30 17:32:39: [2024-10-30 17:32:39] iter = 17220, loss = 3.3785
2024-10-30 17:32:40: [2024-10-30 17:32:40] iter = 17230, loss = 3.6032
2024-10-30 17:32:41: [2024-10-30 17:32:41] iter = 17240, loss = 26.7642
2024-10-30 17:32:42: [2024-10-30 17:32:42] iter = 17250, loss = 1.3777
2024-10-30 17:32:42: [2024-10-30 17:32:42] iter = 17260, loss = 5.1669
2024-10-30 17:32:43: [2024-10-30 17:32:43] iter = 17270, loss = 1.5585
2024-10-30 17:32:44: [2024-10-30 17:32:44] iter = 17280, loss = 4.8268
2024-10-30 17:32:45: [2024-10-30 17:32:45] iter = 17290, loss = 1.2860
2024-10-30 17:32:47: [2024-10-30 17:32:47] iter = 17300, loss = 5.6781
2024-10-30 17:32:48: [2024-10-30 17:32:48] iter = 17310, loss = 2.9995
2024-10-30 17:32:48: [2024-10-30 17:32:48] iter = 17320, loss = 2.0643
2024-10-30 17:32:49: [2024-10-30 17:32:49] iter = 17330, loss = 13.0789
2024-10-30 17:32:49: [2024-10-30 17:32:49] iter = 17340, loss = 2.7490
2024-10-30 17:32:50: [2024-10-30 17:32:50] iter = 17350, loss = 2.1410
2024-10-30 17:32:51: [2024-10-30 17:32:51] iter = 17360, loss = 16.5745
2024-10-30 17:32:52: [2024-10-30 17:32:52] iter = 17370, loss = 4.0598
2024-10-30 17:32:53: [2024-10-30 17:32:53] iter = 17380, loss = 7.0045
2024-10-30 17:32:54: [2024-10-30 17:32:54] iter = 17390, loss = 1.5446
2024-10-30 17:32:55: [2024-10-30 17:32:55] iter = 17400, loss = 1.3815
2024-10-30 17:32:56: [2024-10-30 17:32:56] iter = 17410, loss = 4.2523
2024-10-30 17:32:57: [2024-10-30 17:32:57] iter = 17420, loss = 3.2195
2024-10-30 17:32:57: [2024-10-30 17:32:57] iter = 17430, loss = 5.5286
2024-10-30 17:32:58: [2024-10-30 17:32:58] iter = 17440, loss = 1.2559
2024-10-30 17:32:59: [2024-10-30 17:32:59] iter = 17450, loss = 6.8549
2024-10-30 17:33:00: [2024-10-30 17:33:00] iter = 17460, loss = 1.5546
2024-10-30 17:33:01: [2024-10-30 17:33:01] iter = 17470, loss = 1.2252
2024-10-30 17:33:02: [2024-10-30 17:33:02] iter = 17480, loss = 1.1792
2024-10-30 17:33:04: [2024-10-30 17:33:04] iter = 17490, loss = 2.6260
2024-10-30 17:33:04: [2024-10-30 17:33:04] iter = 17500, loss = 2.0660
2024-10-30 17:33:05: [2024-10-30 17:33:05] iter = 17510, loss = 4.6952
2024-10-30 17:33:06: [2024-10-30 17:33:06] iter = 17520, loss = 1.4090
2024-10-30 17:33:07: [2024-10-30 17:33:07] iter = 17530, loss = 3.1657
2024-10-30 17:33:08: [2024-10-30 17:33:08] iter = 17540, loss = 2.8740
2024-10-30 17:33:08: [2024-10-30 17:33:08] iter = 17550, loss = 1.4022
2024-10-30 17:33:09: [2024-10-30 17:33:09] iter = 17560, loss = 25.8811
2024-10-30 17:33:10: [2024-10-30 17:33:10] iter = 17570, loss = 1.6839
2024-10-30 17:33:11: [2024-10-30 17:33:11] iter = 17580, loss = 1.1106
2024-10-30 17:33:12: [2024-10-30 17:33:12] iter = 17590, loss = 1.5172
2024-10-30 17:33:13: [2024-10-30 17:33:13] iter = 17600, loss = 5.2967
2024-10-30 17:33:14: [2024-10-30 17:33:14] iter = 17610, loss = 6.9482
2024-10-30 17:33:15: [2024-10-30 17:33:15] iter = 17620, loss = 2.8680
2024-10-30 17:33:16: [2024-10-30 17:33:16] iter = 17630, loss = 7.5892
2024-10-30 17:33:17: [2024-10-30 17:33:17] iter = 17640, loss = 5.7277
2024-10-30 17:33:18: [2024-10-30 17:33:18] iter = 17650, loss = 2.0186
2024-10-30 17:33:19: [2024-10-30 17:33:19] iter = 17660, loss = 5.8204
2024-10-30 17:33:19: [2024-10-30 17:33:19] iter = 17670, loss = 2.0940
2024-10-30 17:33:20: [2024-10-30 17:33:20] iter = 17680, loss = 6.4043
2024-10-30 17:33:21: [2024-10-30 17:33:21] iter = 17690, loss = 1.4054
2024-10-30 17:33:22: [2024-10-30 17:33:22] iter = 17700, loss = 2.1105
2024-10-30 17:33:23: [2024-10-30 17:33:23] iter = 17710, loss = 1.5202
2024-10-30 17:33:24: [2024-10-30 17:33:24] iter = 17720, loss = 4.7698
2024-10-30 17:33:25: [2024-10-30 17:33:25] iter = 17730, loss = 8.3098
2024-10-30 17:33:26: [2024-10-30 17:33:26] iter = 17740, loss = 4.8637
2024-10-30 17:33:27: [2024-10-30 17:33:27] iter = 17750, loss = 13.1019
2024-10-30 17:33:28: [2024-10-30 17:33:28] iter = 17760, loss = 4.7137
2024-10-30 17:33:29: [2024-10-30 17:33:29] iter = 17770, loss = 2.4528
2024-10-30 17:33:30: [2024-10-30 17:33:30] iter = 17780, loss = 5.1699
2024-10-30 17:33:31: [2024-10-30 17:33:31] iter = 17790, loss = 3.5482
2024-10-30 17:33:32: [2024-10-30 17:33:32] iter = 17800, loss = 2.0112
2024-10-30 17:33:33: [2024-10-30 17:33:33] iter = 17810, loss = 5.3261
2024-10-30 17:33:34: [2024-10-30 17:33:34] iter = 17820, loss = 3.6297
2024-10-30 17:33:35: [2024-10-30 17:33:35] iter = 17830, loss = 3.9766
2024-10-30 17:33:36: [2024-10-30 17:33:36] iter = 17840, loss = 11.0040
2024-10-30 17:33:37: [2024-10-30 17:33:37] iter = 17850, loss = 15.1109
2024-10-30 17:33:38: [2024-10-30 17:33:38] iter = 17860, loss = 2.2775
2024-10-30 17:33:39: [2024-10-30 17:33:39] iter = 17870, loss = 1.6585
2024-10-30 17:33:40: [2024-10-30 17:33:40] iter = 17880, loss = 2.3447
2024-10-30 17:33:41: [2024-10-30 17:33:41] iter = 17890, loss = 13.8053
2024-10-30 17:33:41: [2024-10-30 17:33:41] iter = 17900, loss = 2.4441
2024-10-30 17:33:42: [2024-10-30 17:33:42] iter = 17910, loss = 1.6714
2024-10-30 17:33:43: [2024-10-30 17:33:43] iter = 17920, loss = 7.2496
2024-10-30 17:33:44: [2024-10-30 17:33:44] iter = 17930, loss = 1.8659
2024-10-30 17:33:45: [2024-10-30 17:33:45] iter = 17940, loss = 7.4725
2024-10-30 17:33:46: [2024-10-30 17:33:46] iter = 17950, loss = 5.6878
2024-10-30 17:33:47: [2024-10-30 17:33:47] iter = 17960, loss = 4.6787
2024-10-30 17:33:48: [2024-10-30 17:33:48] iter = 17970, loss = 2.4247
2024-10-30 17:33:48: [2024-10-30 17:33:48] iter = 17980, loss = 2.4145
2024-10-30 17:33:49: [2024-10-30 17:33:49] iter = 17990, loss = 2.9697
2024-10-30 17:33:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 17:33:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:33:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30715}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:21: Evaluate 5 random ConvNet, ACCmean = 0.7462 ACCstd = 0.0096
-------------------------
2024-10-30 17:35:21: Evaluate 5 random ConvNet, SENmean = 0.5902 SENstd = 0.0201
-------------------------
2024-10-30 17:35:21: Evaluate 5 random ConvNet, SPEmean = 0.5902 SPEstd = 0.0201
-------------------------
2024-10-30 17:35:21: Evaluate 5 random ConvNet, F!mean = 0.5945 F!std = 0.0255
-------------------------
2024-10-30 17:35:21: Evaluate 5 random ConvNet, mean = 0.7462 std = 0.0096
-------------------------
2024-10-30 17:35:21: [2024-10-30 17:35:21] iter = 18000, loss = 4.4320
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:35:22: [2024-10-30 17:35:22] iter = 18010, loss = 4.2561
2024-10-30 17:35:23: [2024-10-30 17:35:23] iter = 18020, loss = 5.7646
2024-10-30 17:35:24: [2024-10-30 17:35:24] iter = 18030, loss = 1.8052
2024-10-30 17:35:25: [2024-10-30 17:35:25] iter = 18040, loss = 4.1030
2024-10-30 17:35:26: [2024-10-30 17:35:26] iter = 18050, loss = 1.5010
2024-10-30 17:35:27: [2024-10-30 17:35:27] iter = 18060, loss = 1.4541
2024-10-30 17:35:28: [2024-10-30 17:35:28] iter = 18070, loss = 1.4735
2024-10-30 17:35:29: [2024-10-30 17:35:29] iter = 18080, loss = 1.1268
2024-10-30 17:35:30: [2024-10-30 17:35:30] iter = 18090, loss = 1.7091
2024-10-30 17:35:30: [2024-10-30 17:35:30] iter = 18100, loss = 1.8315
2024-10-30 17:35:31: [2024-10-30 17:35:31] iter = 18110, loss = 1.6654
2024-10-30 17:35:31: [2024-10-30 17:35:31] iter = 18120, loss = 14.6912
2024-10-30 17:35:33: [2024-10-30 17:35:33] iter = 18130, loss = 5.1618
2024-10-30 17:35:33: [2024-10-30 17:35:33] iter = 18140, loss = 3.7786
2024-10-30 17:35:34: [2024-10-30 17:35:34] iter = 18150, loss = 1.9403
2024-10-30 17:35:35: [2024-10-30 17:35:35] iter = 18160, loss = 1.4872
2024-10-30 17:35:37: [2024-10-30 17:35:37] iter = 18170, loss = 1.3361
2024-10-30 17:35:38: [2024-10-30 17:35:38] iter = 18180, loss = 4.5191
2024-10-30 17:35:39: [2024-10-30 17:35:39] iter = 18190, loss = 1.7341
2024-10-30 17:35:39: [2024-10-30 17:35:39] iter = 18200, loss = 4.1095
2024-10-30 17:35:40: [2024-10-30 17:35:40] iter = 18210, loss = 2.0564
2024-10-30 17:35:40: [2024-10-30 17:35:40] iter = 18220, loss = 1.9863
2024-10-30 17:35:41: [2024-10-30 17:35:41] iter = 18230, loss = 2.8928
2024-10-30 17:35:42: [2024-10-30 17:35:42] iter = 18240, loss = 6.7953
2024-10-30 17:35:43: [2024-10-30 17:35:43] iter = 18250, loss = 4.8176
2024-10-30 17:35:44: [2024-10-30 17:35:44] iter = 18260, loss = 2.8189
2024-10-30 17:35:44: [2024-10-30 17:35:44] iter = 18270, loss = 1.7124
2024-10-30 17:35:45: [2024-10-30 17:35:45] iter = 18280, loss = 1.3420
2024-10-30 17:35:46: [2024-10-30 17:35:46] iter = 18290, loss = 10.1740
2024-10-30 17:35:47: [2024-10-30 17:35:47] iter = 18300, loss = 1.7268
2024-10-30 17:35:48: [2024-10-30 17:35:48] iter = 18310, loss = 1.6593
2024-10-30 17:35:48: [2024-10-30 17:35:48] iter = 18320, loss = 4.2106
2024-10-30 17:35:49: [2024-10-30 17:35:49] iter = 18330, loss = 1.1138
2024-10-30 17:35:50: [2024-10-30 17:35:50] iter = 18340, loss = 3.8330
2024-10-30 17:35:51: [2024-10-30 17:35:51] iter = 18350, loss = 2.7898
2024-10-30 17:35:52: [2024-10-30 17:35:52] iter = 18360, loss = 4.1870
2024-10-30 17:35:53: [2024-10-30 17:35:53] iter = 18370, loss = 1.8059
2024-10-30 17:35:54: [2024-10-30 17:35:54] iter = 18380, loss = 15.6662
2024-10-30 17:35:55: [2024-10-30 17:35:55] iter = 18390, loss = 1.2781
2024-10-30 17:35:56: [2024-10-30 17:35:56] iter = 18400, loss = 1.0137
2024-10-30 17:35:57: [2024-10-30 17:35:57] iter = 18410, loss = 2.3841
2024-10-30 17:35:57: [2024-10-30 17:35:57] iter = 18420, loss = 2.4797
2024-10-30 17:35:58: [2024-10-30 17:35:58] iter = 18430, loss = 5.2485
2024-10-30 17:35:59: [2024-10-30 17:35:59] iter = 18440, loss = 3.7552
2024-10-30 17:36:00: [2024-10-30 17:36:00] iter = 18450, loss = 2.6734
2024-10-30 17:36:01: [2024-10-30 17:36:01] iter = 18460, loss = 1.8517
2024-10-30 17:36:02: [2024-10-30 17:36:02] iter = 18470, loss = 3.2570
2024-10-30 17:36:03: [2024-10-30 17:36:03] iter = 18480, loss = 3.6385
2024-10-30 17:36:03: [2024-10-30 17:36:03] iter = 18490, loss = 1.9036
2024-10-30 17:36:04: [2024-10-30 17:36:04] iter = 18500, loss = 17.9694
2024-10-30 17:36:05: [2024-10-30 17:36:05] iter = 18510, loss = 10.0050
2024-10-30 17:36:06: [2024-10-30 17:36:06] iter = 18520, loss = 1.3977
2024-10-30 17:36:07: [2024-10-30 17:36:07] iter = 18530, loss = 4.6798
2024-10-30 17:36:08: [2024-10-30 17:36:08] iter = 18540, loss = 4.1045
2024-10-30 17:36:09: [2024-10-30 17:36:09] iter = 18550, loss = 3.1027
2024-10-30 17:36:10: [2024-10-30 17:36:10] iter = 18560, loss = 2.1547
2024-10-30 17:36:10: [2024-10-30 17:36:10] iter = 18570, loss = 3.1921
2024-10-30 17:36:11: [2024-10-30 17:36:11] iter = 18580, loss = 6.9590
2024-10-30 17:36:12: [2024-10-30 17:36:12] iter = 18590, loss = 1.8518
2024-10-30 17:36:12: [2024-10-30 17:36:12] iter = 18600, loss = 3.3607
2024-10-30 17:36:12: [2024-10-30 17:36:12] iter = 18610, loss = 7.5041
2024-10-30 17:36:13: [2024-10-30 17:36:13] iter = 18620, loss = 2.9981
2024-10-30 17:36:14: [2024-10-30 17:36:14] iter = 18630, loss = 2.3319
2024-10-30 17:36:14: [2024-10-30 17:36:14] iter = 18640, loss = 4.7134
2024-10-30 17:36:15: [2024-10-30 17:36:15] iter = 18650, loss = 1.9281
2024-10-30 17:36:16: [2024-10-30 17:36:16] iter = 18660, loss = 8.5283
2024-10-30 17:36:17: [2024-10-30 17:36:17] iter = 18670, loss = 1.6988
2024-10-30 17:36:17: [2024-10-30 17:36:17] iter = 18680, loss = 1.2497
2024-10-30 17:36:18: [2024-10-30 17:36:18] iter = 18690, loss = 1.1953
2024-10-30 17:36:19: [2024-10-30 17:36:19] iter = 18700, loss = 15.8604
2024-10-30 17:36:20: [2024-10-30 17:36:20] iter = 18710, loss = 2.9150
2024-10-30 17:36:21: [2024-10-30 17:36:21] iter = 18720, loss = 1.5485
2024-10-30 17:36:22: [2024-10-30 17:36:22] iter = 18730, loss = 1.1171
2024-10-30 17:36:23: [2024-10-30 17:36:23] iter = 18740, loss = 1.3523
2024-10-30 17:36:23: [2024-10-30 17:36:23] iter = 18750, loss = 2.2247
2024-10-30 17:36:24: [2024-10-30 17:36:24] iter = 18760, loss = 5.9860
2024-10-30 17:36:25: [2024-10-30 17:36:25] iter = 18770, loss = 42.4376
2024-10-30 17:36:26: [2024-10-30 17:36:26] iter = 18780, loss = 18.4940
2024-10-30 17:36:27: [2024-10-30 17:36:27] iter = 18790, loss = 2.4967
2024-10-30 17:36:28: [2024-10-30 17:36:28] iter = 18800, loss = 6.4231
2024-10-30 17:36:29: [2024-10-30 17:36:29] iter = 18810, loss = 5.6929
2024-10-30 17:36:30: [2024-10-30 17:36:30] iter = 18820, loss = 1.4369
2024-10-30 17:36:30: [2024-10-30 17:36:30] iter = 18830, loss = 1.5349
2024-10-30 17:36:31: [2024-10-30 17:36:31] iter = 18840, loss = 2.8466
2024-10-30 17:36:32: [2024-10-30 17:36:32] iter = 18850, loss = 6.0446
2024-10-30 17:36:33: [2024-10-30 17:36:33] iter = 18860, loss = 6.4445
2024-10-30 17:36:34: [2024-10-30 17:36:34] iter = 18870, loss = 1.5563
2024-10-30 17:36:35: [2024-10-30 17:36:35] iter = 18880, loss = 1.5432
2024-10-30 17:36:36: [2024-10-30 17:36:36] iter = 18890, loss = 2.5313
2024-10-30 17:36:37: [2024-10-30 17:36:37] iter = 18900, loss = 1.3125
2024-10-30 17:36:38: [2024-10-30 17:36:38] iter = 18910, loss = 14.1421
2024-10-30 17:36:39: [2024-10-30 17:36:39] iter = 18920, loss = 3.3074
2024-10-30 17:36:40: [2024-10-30 17:36:40] iter = 18930, loss = 1.1618
2024-10-30 17:36:41: [2024-10-30 17:36:41] iter = 18940, loss = 1.1112
2024-10-30 17:36:42: [2024-10-30 17:36:42] iter = 18950, loss = 1.4141
2024-10-30 17:36:43: [2024-10-30 17:36:43] iter = 18960, loss = 1.2627
2024-10-30 17:36:44: [2024-10-30 17:36:44] iter = 18970, loss = 1.7959
2024-10-30 17:36:45: [2024-10-30 17:36:45] iter = 18980, loss = 1.2078
2024-10-30 17:36:46: [2024-10-30 17:36:46] iter = 18990, loss = 1.1482
2024-10-30 17:36:47: [2024-10-30 17:36:47] iter = 19000, loss = 2.1466
2024-10-30 17:36:48: [2024-10-30 17:36:48] iter = 19010, loss = 2.3463
2024-10-30 17:36:48: [2024-10-30 17:36:48] iter = 19020, loss = 15.1646
2024-10-30 17:36:49: [2024-10-30 17:36:49] iter = 19030, loss = 5.3893
2024-10-30 17:36:49: [2024-10-30 17:36:49] iter = 19040, loss = 1.8833
2024-10-30 17:36:50: [2024-10-30 17:36:50] iter = 19050, loss = 1.7264
2024-10-30 17:36:51: [2024-10-30 17:36:51] iter = 19060, loss = 3.6167
2024-10-30 17:36:52: [2024-10-30 17:36:52] iter = 19070, loss = 1.3891
2024-10-30 17:36:52: [2024-10-30 17:36:52] iter = 19080, loss = 5.5091
2024-10-30 17:36:53: [2024-10-30 17:36:53] iter = 19090, loss = 2.8146
2024-10-30 17:36:54: [2024-10-30 17:36:54] iter = 19100, loss = 1.7462
2024-10-30 17:36:55: [2024-10-30 17:36:55] iter = 19110, loss = 3.7350
2024-10-30 17:36:56: [2024-10-30 17:36:56] iter = 19120, loss = 1.2741
2024-10-30 17:36:56: [2024-10-30 17:36:56] iter = 19130, loss = 1.3515
2024-10-30 17:36:57: [2024-10-30 17:36:57] iter = 19140, loss = 2.4906
2024-10-30 17:36:58: [2024-10-30 17:36:58] iter = 19150, loss = 1.5979
2024-10-30 17:36:58: [2024-10-30 17:36:58] iter = 19160, loss = 3.4349
2024-10-30 17:36:59: [2024-10-30 17:36:59] iter = 19170, loss = 1.6108
2024-10-30 17:37:00: [2024-10-30 17:37:00] iter = 19180, loss = 1.7659
2024-10-30 17:37:01: [2024-10-30 17:37:01] iter = 19190, loss = 5.1555
2024-10-30 17:37:02: [2024-10-30 17:37:02] iter = 19200, loss = 15.2713
2024-10-30 17:37:02: [2024-10-30 17:37:02] iter = 19210, loss = 2.6976
2024-10-30 17:37:03: [2024-10-30 17:37:03] iter = 19220, loss = 2.3418
2024-10-30 17:37:03: [2024-10-30 17:37:03] iter = 19230, loss = 1.9556
2024-10-30 17:37:04: [2024-10-30 17:37:04] iter = 19240, loss = 2.6795
2024-10-30 17:37:05: [2024-10-30 17:37:05] iter = 19250, loss = 3.7604
2024-10-30 17:37:06: [2024-10-30 17:37:06] iter = 19260, loss = 1.7656
2024-10-30 17:37:07: [2024-10-30 17:37:07] iter = 19270, loss = 2.1542
2024-10-30 17:37:08: [2024-10-30 17:37:08] iter = 19280, loss = 3.0886
2024-10-30 17:37:09: [2024-10-30 17:37:09] iter = 19290, loss = 2.2341
2024-10-30 17:37:11: [2024-10-30 17:37:11] iter = 19300, loss = 41.1532
2024-10-30 17:37:12: [2024-10-30 17:37:12] iter = 19310, loss = 1.6941
2024-10-30 17:37:13: [2024-10-30 17:37:13] iter = 19320, loss = 1.9577
2024-10-30 17:37:14: [2024-10-30 17:37:14] iter = 19330, loss = 1.1824
2024-10-30 17:37:15: [2024-10-30 17:37:15] iter = 19340, loss = 8.1340
2024-10-30 17:37:16: [2024-10-30 17:37:16] iter = 19350, loss = 3.4294
2024-10-30 17:37:17: [2024-10-30 17:37:17] iter = 19360, loss = 2.4662
2024-10-30 17:37:18: [2024-10-30 17:37:18] iter = 19370, loss = 1.5091
2024-10-30 17:37:18: [2024-10-30 17:37:18] iter = 19380, loss = 1.1063
2024-10-30 17:37:19: [2024-10-30 17:37:19] iter = 19390, loss = 1.6950
2024-10-30 17:37:20: [2024-10-30 17:37:20] iter = 19400, loss = 1.7147
2024-10-30 17:37:20: [2024-10-30 17:37:20] iter = 19410, loss = 1.0109
2024-10-30 17:37:21: [2024-10-30 17:37:21] iter = 19420, loss = 1.2015
2024-10-30 17:37:22: [2024-10-30 17:37:22] iter = 19430, loss = 1.6677
2024-10-30 17:37:23: [2024-10-30 17:37:23] iter = 19440, loss = 3.1728
2024-10-30 17:37:23: [2024-10-30 17:37:23] iter = 19450, loss = 1.5146
2024-10-30 17:37:24: [2024-10-30 17:37:24] iter = 19460, loss = 1.7705
2024-10-30 17:37:25: [2024-10-30 17:37:25] iter = 19470, loss = 2.7401
2024-10-30 17:37:26: [2024-10-30 17:37:26] iter = 19480, loss = 3.3036
2024-10-30 17:37:26: [2024-10-30 17:37:26] iter = 19490, loss = 3.5130
2024-10-30 17:37:27: [2024-10-30 17:37:27] iter = 19500, loss = 6.3684
2024-10-30 17:37:28: [2024-10-30 17:37:28] iter = 19510, loss = 4.6544
2024-10-30 17:37:29: [2024-10-30 17:37:29] iter = 19520, loss = 2.0010
2024-10-30 17:37:29: [2024-10-30 17:37:29] iter = 19530, loss = 7.0601
2024-10-30 17:37:30: [2024-10-30 17:37:30] iter = 19540, loss = 1.6958
2024-10-30 17:37:31: [2024-10-30 17:37:31] iter = 19550, loss = 4.4283
2024-10-30 17:37:32: [2024-10-30 17:37:32] iter = 19560, loss = 5.7911
2024-10-30 17:37:33: [2024-10-30 17:37:33] iter = 19570, loss = 1.5803
2024-10-30 17:37:34: [2024-10-30 17:37:34] iter = 19580, loss = 1.3701
2024-10-30 17:37:35: [2024-10-30 17:37:35] iter = 19590, loss = 1.5851
2024-10-30 17:37:36: [2024-10-30 17:37:36] iter = 19600, loss = 1.4945
2024-10-30 17:37:37: [2024-10-30 17:37:37] iter = 19610, loss = 1.8989
2024-10-30 17:37:38: [2024-10-30 17:37:38] iter = 19620, loss = 8.2235
2024-10-30 17:37:38: [2024-10-30 17:37:38] iter = 19630, loss = 3.2952
2024-10-30 17:37:39: [2024-10-30 17:37:39] iter = 19640, loss = 6.6667
2024-10-30 17:37:40: [2024-10-30 17:37:40] iter = 19650, loss = 2.5815
2024-10-30 17:37:41: [2024-10-30 17:37:41] iter = 19660, loss = 1.7440
2024-10-30 17:37:41: [2024-10-30 17:37:41] iter = 19670, loss = 2.9431
2024-10-30 17:37:42: [2024-10-30 17:37:42] iter = 19680, loss = 13.2561
2024-10-30 17:37:43: [2024-10-30 17:37:43] iter = 19690, loss = 9.6704
2024-10-30 17:37:43: [2024-10-30 17:37:43] iter = 19700, loss = 2.6241
2024-10-30 17:37:44: [2024-10-30 17:37:44] iter = 19710, loss = 20.3031
2024-10-30 17:37:45: [2024-10-30 17:37:45] iter = 19720, loss = 5.6595
2024-10-30 17:37:46: [2024-10-30 17:37:46] iter = 19730, loss = 2.9844
2024-10-30 17:37:47: [2024-10-30 17:37:47] iter = 19740, loss = 17.3993
2024-10-30 17:37:48: [2024-10-30 17:37:48] iter = 19750, loss = 3.2364
2024-10-30 17:37:48: [2024-10-30 17:37:48] iter = 19760, loss = 54.4442
2024-10-30 17:37:49: [2024-10-30 17:37:49] iter = 19770, loss = 2.2025
2024-10-30 17:37:51: [2024-10-30 17:37:51] iter = 19780, loss = 2.8364
2024-10-30 17:37:51: [2024-10-30 17:37:51] iter = 19790, loss = 8.0987
2024-10-30 17:37:52: [2024-10-30 17:37:52] iter = 19800, loss = 8.9247
2024-10-30 17:37:53: [2024-10-30 17:37:53] iter = 19810, loss = 31.9650
2024-10-30 17:37:54: [2024-10-30 17:37:54] iter = 19820, loss = 1.6469
2024-10-30 17:37:55: [2024-10-30 17:37:55] iter = 19830, loss = 2.0250
2024-10-30 17:37:56: [2024-10-30 17:37:56] iter = 19840, loss = 1.6093
2024-10-30 17:37:57: [2024-10-30 17:37:57] iter = 19850, loss = 2.4892
2024-10-30 17:37:58: [2024-10-30 17:37:58] iter = 19860, loss = 23.6014
2024-10-30 17:37:59: [2024-10-30 17:37:59] iter = 19870, loss = 2.9702
2024-10-30 17:37:59: [2024-10-30 17:37:59] iter = 19880, loss = 8.0359
2024-10-30 17:38:00: [2024-10-30 17:38:00] iter = 19890, loss = 7.3940
2024-10-30 17:38:01: [2024-10-30 17:38:01] iter = 19900, loss = 1.4907
2024-10-30 17:38:02: [2024-10-30 17:38:02] iter = 19910, loss = 3.7225
2024-10-30 17:38:03: [2024-10-30 17:38:03] iter = 19920, loss = 6.0219
2024-10-30 17:38:05: [2024-10-30 17:38:05] iter = 19930, loss = 1.5614
2024-10-30 17:38:05: [2024-10-30 17:38:05] iter = 19940, loss = 2.4954
2024-10-30 17:38:06: [2024-10-30 17:38:06] iter = 19950, loss = 12.3344
2024-10-30 17:38:07: [2024-10-30 17:38:07] iter = 19960, loss = 11.0813
2024-10-30 17:38:09: [2024-10-30 17:38:09] iter = 19970, loss = 1.3339
2024-10-30 17:38:09: [2024-10-30 17:38:09] iter = 19980, loss = 1.8010
2024-10-30 17:38:10: [2024-10-30 17:38:10] iter = 19990, loss = 3.3370
2024-10-30 17:38:11: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 17:38:11: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:38:11: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 91462}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:39:44: Evaluate 5 random ConvNet, ACCmean = 0.7321 ACCstd = 0.0110
-------------------------
2024-10-30 17:39:44: Evaluate 5 random ConvNet, SENmean = 0.7294 SENstd = 0.0153
-------------------------
2024-10-30 17:39:44: Evaluate 5 random ConvNet, SPEmean = 0.7294 SPEstd = 0.0153
-------------------------
2024-10-30 17:39:44: Evaluate 5 random ConvNet, F!mean = 0.6964 F!std = 0.0124
-------------------------
2024-10-30 17:39:44: Evaluate 5 random ConvNet, mean = 0.7321 std = 0.0110
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:39:44: [2024-10-30 17:39:44] iter = 20000, loss = 1.9468
2024-10-30 17:39:44: 
==================== Final Results ====================

2024-10-30 17:39:44: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 72.41%  std = 3.84%

[2024-10-30 17:03:12] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000245 train acc = 1.0000, test acc = 0.7372, test_sen =0.7450, test_spe =0.7450, test_f1 =0.7057
[2024-10-30 17:03:34] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.008958 train acc = 1.0000, test acc = 0.7372, test_sen =0.7525, test_spe =0.7525, test_f1 =0.7084
[2024-10-30 17:03:53] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000323 train acc = 1.0000, test acc = 0.7628, test_sen =0.7776, test_spe =0.7776, test_f1 =0.7344
[2024-10-30 17:04:10] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.001760 train acc = 1.0000, test acc = 0.7244, test_sen =0.7137, test_spe =0.7137, test_f1 =0.6852
[2024-10-30 17:04:27] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.006799 train acc = 1.0000, test acc = 0.7244, test_sen =0.7212, test_spe =0.7212, test_f1 =0.6884
[2024-10-30 17:07:31] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000177 train acc = 1.0000, test acc = 0.6859, test_sen =0.7174, test_spe =0.7174, test_f1 =0.6626
[2024-10-30 17:07:47] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.000117 train acc = 1.0000, test acc = 0.6987, test_sen =0.7262, test_spe =0.7262, test_f1 =0.6739
[2024-10-30 17:08:06] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.000407 train acc = 1.0000, test acc = 0.7051, test_sen =0.7306, test_spe =0.7306, test_f1 =0.6796
[2024-10-30 17:08:26] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.034703 train acc = 1.0000, test acc = 0.6603, test_sen =0.6999, test_spe =0.6999, test_f1 =0.6400
[2024-10-30 17:08:44] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.004695 train acc = 1.0000, test acc = 0.6667, test_sen =0.6967, test_spe =0.6967, test_f1 =0.6432
[2024-10-30 17:11:46] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.001912 train acc = 1.0000, test acc = 0.7756, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6983
[2024-10-30 17:12:04] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.000051 train acc = 1.0000, test acc = 0.7949, test_sen =0.7093, test_spe =0.7093, test_f1 =0.7217
[2024-10-30 17:12:20] Evaluate_02: epoch = 1000 train time = 16 s train loss = 0.001648 train acc = 1.0000, test acc = 0.7692, test_sen =0.6842, test_spe =0.6842, test_f1 =0.6923
[2024-10-30 17:12:35] Evaluate_03: epoch = 1000 train time = 15 s train loss = 0.000596 train acc = 1.0000, test acc = 0.7756, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6983
[2024-10-30 17:12:53] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000606 train acc = 1.0000, test acc = 0.7756, test_sen =0.6886, test_spe =0.6886, test_f1 =0.6983
[2024-10-30 17:15:58] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.004202 train acc = 1.0000, test acc = 0.7564, test_sen =0.7281, test_spe =0.7281, test_f1 =0.7107
[2024-10-30 17:16:18] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.006760 train acc = 1.0000, test acc = 0.7564, test_sen =0.7356, test_spe =0.7356, test_f1 =0.7141
[2024-10-30 17:16:33] Evaluate_02: epoch = 1000 train time = 14 s train loss = 0.000295 train acc = 1.0000, test acc = 0.7756, test_sen =0.7487, test_spe =0.7487, test_f1 =0.7319
[2024-10-30 17:16:52] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.001234 train acc = 1.0000, test acc = 0.7308, test_sen =0.7256, test_spe =0.7256, test_f1 =0.6941
[2024-10-30 17:17:10] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.000488 train acc = 1.0000, test acc = 0.7692, test_sen =0.7218, test_spe =0.7218, test_f1 =0.7151
[2024-10-30 17:20:32] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000453 train acc = 1.0000, test acc = 0.7244, test_sen =0.6310, test_spe =0.6310, test_f1 =0.6356
[2024-10-30 17:20:51] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.000382 train acc = 1.0000, test acc = 0.7115, test_sen =0.5921, test_spe =0.5921, test_f1 =0.5976
[2024-10-30 17:21:08] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.000216 train acc = 1.0000, test acc = 0.7179, test_sen =0.6190, test_spe =0.6190, test_f1 =0.6239
[2024-10-30 17:21:25] Evaluate_03: epoch = 1000 train time = 16 s train loss = 0.000289 train acc = 1.0000, test acc = 0.7308, test_sen =0.6128, test_spe =0.6128, test_f1 =0.6208
[2024-10-30 17:21:41] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.001527 train acc = 1.0000, test acc = 0.7244, test_sen =0.6159, test_spe =0.6159, test_f1 =0.6226
[2024-10-30 17:24:51] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.000415 train acc = 1.0000, test acc = 0.7756, test_sen =0.7112, test_spe =0.7112, test_f1 =0.7127
[2024-10-30 17:25:10] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.003285 train acc = 1.0000, test acc = 0.7500, test_sen =0.6936, test_spe =0.6936, test_f1 =0.6892
[2024-10-30 17:25:28] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.001555 train acc = 1.0000, test acc = 0.7756, test_sen =0.7036, test_spe =0.7036, test_f1 =0.7082
[2024-10-30 17:25:48] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.005790 train acc = 1.0000, test acc = 0.8077, test_sen =0.7481, test_spe =0.7481, test_f1 =0.7519
[2024-10-30 17:26:06] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.000501 train acc = 1.0000, test acc = 0.7821, test_sen =0.7231, test_spe =0.7231, test_f1 =0.7231
[2024-10-30 17:29:29] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.000718 train acc = 1.0000, test acc = 0.5897, test_sen =0.6441, test_spe =0.6441, test_f1 =0.5761
[2024-10-30 17:29:45] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.021265 train acc = 1.0000, test acc = 0.6090, test_sen =0.6723, test_spe =0.6723, test_f1 =0.5969
[2024-10-30 17:30:05] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.000239 train acc = 1.0000, test acc = 0.6282, test_sen =0.6704, test_spe =0.6704, test_f1 =0.6097
[2024-10-30 17:30:24] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.003461 train acc = 1.0000, test acc = 0.6090, test_sen =0.6648, test_spe =0.6648, test_f1 =0.5950
[2024-10-30 17:30:44] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.001198 train acc = 1.0000, test acc = 0.6410, test_sen =0.6942, test_spe =0.6942, test_f1 =0.6253
[2024-10-30 17:34:07] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.000786 train acc = 1.0000, test acc = 0.7564, test_sen =0.5927, test_spe =0.5927, test_f1 =0.5976
[2024-10-30 17:34:26] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.000145 train acc = 1.0000, test acc = 0.7436, test_sen =0.5915, test_spe =0.5915, test_f1 =0.5974
[2024-10-30 17:34:43] Evaluate_02: epoch = 1000 train time = 17 s train loss = 0.002176 train acc = 1.0000, test acc = 0.7564, test_sen =0.6228, test_spe =0.6228, test_f1 =0.6349
[2024-10-30 17:35:02] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.000326 train acc = 1.0000, test acc = 0.7308, test_sen =0.5602, test_spe =0.5602, test_f1 =0.5553
[2024-10-30 17:35:21] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.028115 train acc = 1.0000, test acc = 0.7436, test_sen =0.5840, test_spe =0.5840, test_f1 =0.5873
[2024-10-30 17:38:30] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.000960 train acc = 1.0000, test acc = 0.7500, test_sen =0.7538, test_spe =0.7538, test_f1 =0.7174
[2024-10-30 17:38:48] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.004372 train acc = 1.0000, test acc = 0.7179, test_sen =0.7168, test_spe =0.7168, test_f1 =0.6827
[2024-10-30 17:39:05] Evaluate_02: epoch = 1000 train time = 16 s train loss = 0.010552 train acc = 1.0000, test acc = 0.7372, test_sen =0.7375, test_spe =0.7375, test_f1 =0.7029
[2024-10-30 17:39:24] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.001407 train acc = 1.0000, test acc = 0.7308, test_sen =0.7105, test_spe =0.7105, test_f1 =0.6876
[2024-10-30 17:39:44] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.005137 train acc = 1.0000, test acc = 0.7244, test_sen =0.7287, test_spe =0.7287, test_f1 =0.6914
