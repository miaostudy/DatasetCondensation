nohup: ignoring input
2024-10-29 11:48:43: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
2024-10-29 11:48:43: 
================== Exp 0 ==================
 
2024-10-29 11:48:43: Hyper-parameters: 
{'dataset': 'OCTMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faf200e8730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OCTMNIST (INFO)>}
2024-10-29 11:48:43: Evaluation model pool: ['ConvNet']
2024-10-29 11:48:48: class c = 0: 33484 real images
2024-10-29 11:48:48: class c = 1: 10213 real images
2024-10-29 11:48:48: class c = 2: 7754 real images
2024-10-29 11:48:48: class c = 3: 46026 real images
2024-10-29 11:48:48: real images channel 0, mean = 0.1889, std = 0.1963
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 11:48:48: initialize synthetic data from random real images
2024-10-29 11:48:48: [2024-10-29 11:48:48] training begins
2024-10-29 11:48:48: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 11:48:48: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:48:48: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:49:14: Evaluate 5 random ConvNet, ACCmean = 0.4058 ACCstd = 0.0052
-------------------------
2024-10-29 11:49:14: Evaluate 5 random ConvNet, SENmean = 0.4058 SENstd = 0.0052
-------------------------
2024-10-29 11:49:14: Evaluate 5 random ConvNet, SPEmean = 0.8019 SPEstd = 0.0017
-------------------------
2024-10-29 11:49:14: Evaluate 5 random ConvNet, F!mean = 0.4097 F!std = 0.0061
-------------------------
2024-10-29 11:49:14: Evaluate 5 random ConvNet, mean = 0.4058 std = 0.0052
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:49:14: [2024-10-29 11:49:14] iter = 00000, loss = 13.1583
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:49:14: [2024-10-29 11:49:14] iter = 00010, loss = 24.9153
2024-10-29 11:49:14: [2024-10-29 11:49:14] iter = 00020, loss = 5.3691
2024-10-29 11:49:15: [2024-10-29 11:49:15] iter = 00030, loss = 6.0494
2024-10-29 11:49:16: [2024-10-29 11:49:16] iter = 00040, loss = 6.9623
2024-10-29 11:49:16: [2024-10-29 11:49:16] iter = 00050, loss = 26.7336
2024-10-29 11:49:17: [2024-10-29 11:49:17] iter = 00060, loss = 9.4346
2024-10-29 11:49:17: [2024-10-29 11:49:17] iter = 00070, loss = 8.8106
2024-10-29 11:49:17: [2024-10-29 11:49:17] iter = 00080, loss = 6.3273
2024-10-29 11:49:18: [2024-10-29 11:49:18] iter = 00090, loss = 6.1486
2024-10-29 11:49:18: [2024-10-29 11:49:18] iter = 00100, loss = 5.3811
2024-10-29 11:49:19: [2024-10-29 11:49:19] iter = 00110, loss = 2.9251
2024-10-29 11:49:19: [2024-10-29 11:49:19] iter = 00120, loss = 12.7870
2024-10-29 11:49:20: [2024-10-29 11:49:20] iter = 00130, loss = 18.4662
2024-10-29 11:49:20: [2024-10-29 11:49:20] iter = 00140, loss = 16.9931
2024-10-29 11:49:21: [2024-10-29 11:49:21] iter = 00150, loss = 25.2176
2024-10-29 11:49:21: [2024-10-29 11:49:21] iter = 00160, loss = 8.1387
2024-10-29 11:49:21: [2024-10-29 11:49:21] iter = 00170, loss = 19.3611
2024-10-29 11:49:22: [2024-10-29 11:49:22] iter = 00180, loss = 4.1927
2024-10-29 11:49:22: [2024-10-29 11:49:22] iter = 00190, loss = 8.9318
2024-10-29 11:49:23: [2024-10-29 11:49:23] iter = 00200, loss = 29.1877
2024-10-29 11:49:23: [2024-10-29 11:49:23] iter = 00210, loss = 9.1546
2024-10-29 11:49:24: [2024-10-29 11:49:24] iter = 00220, loss = 3.3595
2024-10-29 11:49:24: [2024-10-29 11:49:24] iter = 00230, loss = 3.9207
2024-10-29 11:49:24: [2024-10-29 11:49:24] iter = 00240, loss = 6.6582
2024-10-29 11:49:25: [2024-10-29 11:49:25] iter = 00250, loss = 45.3080
2024-10-29 11:49:25: [2024-10-29 11:49:25] iter = 00260, loss = 5.5588
2024-10-29 11:49:26: [2024-10-29 11:49:26] iter = 00270, loss = 3.2918
2024-10-29 11:49:26: [2024-10-29 11:49:26] iter = 00280, loss = 8.3605
2024-10-29 11:49:27: [2024-10-29 11:49:26] iter = 00290, loss = 7.1113
2024-10-29 11:49:27: [2024-10-29 11:49:27] iter = 00300, loss = 5.3464
2024-10-29 11:49:27: [2024-10-29 11:49:27] iter = 00310, loss = 2.5227
2024-10-29 11:49:28: [2024-10-29 11:49:28] iter = 00320, loss = 4.6231
2024-10-29 11:49:28: [2024-10-29 11:49:28] iter = 00330, loss = 13.4521
2024-10-29 11:49:29: [2024-10-29 11:49:29] iter = 00340, loss = 4.6793
2024-10-29 11:49:29: [2024-10-29 11:49:29] iter = 00350, loss = 8.7308
2024-10-29 11:49:30: [2024-10-29 11:49:30] iter = 00360, loss = 5.8321
2024-10-29 11:49:30: [2024-10-29 11:49:30] iter = 00370, loss = 7.9963
2024-10-29 11:49:31: [2024-10-29 11:49:31] iter = 00380, loss = 16.8701
2024-10-29 11:49:31: [2024-10-29 11:49:31] iter = 00390, loss = 4.9069
2024-10-29 11:49:32: [2024-10-29 11:49:32] iter = 00400, loss = 4.7420
2024-10-29 11:49:32: [2024-10-29 11:49:32] iter = 00410, loss = 4.2926
2024-10-29 11:49:33: [2024-10-29 11:49:33] iter = 00420, loss = 3.3361
2024-10-29 11:49:33: [2024-10-29 11:49:33] iter = 00430, loss = 11.5204
2024-10-29 11:49:34: [2024-10-29 11:49:34] iter = 00440, loss = 3.3398
2024-10-29 11:49:34: [2024-10-29 11:49:34] iter = 00450, loss = 5.3631
2024-10-29 11:49:34: [2024-10-29 11:49:34] iter = 00460, loss = 2.4277
2024-10-29 11:49:35: [2024-10-29 11:49:35] iter = 00470, loss = 3.8130
2024-10-29 11:49:35: [2024-10-29 11:49:35] iter = 00480, loss = 5.9753
2024-10-29 11:49:36: [2024-10-29 11:49:36] iter = 00490, loss = 4.2512
2024-10-29 11:49:36: [2024-10-29 11:49:36] iter = 00500, loss = 2.7354
2024-10-29 11:49:36: [2024-10-29 11:49:36] iter = 00510, loss = 3.1838
2024-10-29 11:49:37: [2024-10-29 11:49:37] iter = 00520, loss = 3.9227
2024-10-29 11:49:37: [2024-10-29 11:49:37] iter = 00530, loss = 9.4233
2024-10-29 11:49:38: [2024-10-29 11:49:38] iter = 00540, loss = 2.8864
2024-10-29 11:49:38: [2024-10-29 11:49:38] iter = 00550, loss = 8.2884
2024-10-29 11:49:39: [2024-10-29 11:49:39] iter = 00560, loss = 5.2461
2024-10-29 11:49:39: [2024-10-29 11:49:39] iter = 00570, loss = 8.0327
2024-10-29 11:49:40: [2024-10-29 11:49:40] iter = 00580, loss = 4.5855
2024-10-29 11:49:40: [2024-10-29 11:49:40] iter = 00590, loss = 3.7864
2024-10-29 11:49:41: [2024-10-29 11:49:41] iter = 00600, loss = 7.2096
2024-10-29 11:49:41: [2024-10-29 11:49:41] iter = 00610, loss = 2.7671
2024-10-29 11:49:41: [2024-10-29 11:49:41] iter = 00620, loss = 4.5977
2024-10-29 11:49:42: [2024-10-29 11:49:42] iter = 00630, loss = 2.1535
2024-10-29 11:49:42: [2024-10-29 11:49:42] iter = 00640, loss = 4.2245
2024-10-29 11:49:43: [2024-10-29 11:49:43] iter = 00650, loss = 41.0905
2024-10-29 11:49:43: [2024-10-29 11:49:43] iter = 00660, loss = 4.4826
2024-10-29 11:49:44: [2024-10-29 11:49:44] iter = 00670, loss = 28.8223
2024-10-29 11:49:44: [2024-10-29 11:49:44] iter = 00680, loss = 8.7722
2024-10-29 11:49:45: [2024-10-29 11:49:45] iter = 00690, loss = 5.9170
2024-10-29 11:49:45: [2024-10-29 11:49:45] iter = 00700, loss = 5.3392
2024-10-29 11:49:46: [2024-10-29 11:49:46] iter = 00710, loss = 26.1498
2024-10-29 11:49:46: [2024-10-29 11:49:46] iter = 00720, loss = 3.1800
2024-10-29 11:49:47: [2024-10-29 11:49:47] iter = 00730, loss = 4.6094
2024-10-29 11:49:47: [2024-10-29 11:49:47] iter = 00740, loss = 10.7353
2024-10-29 11:49:48: [2024-10-29 11:49:48] iter = 00750, loss = 7.1729
2024-10-29 11:49:48: [2024-10-29 11:49:48] iter = 00760, loss = 4.4740
2024-10-29 11:49:49: [2024-10-29 11:49:49] iter = 00770, loss = 13.7159
2024-10-29 11:49:49: [2024-10-29 11:49:49] iter = 00780, loss = 3.5548
2024-10-29 11:49:49: [2024-10-29 11:49:49] iter = 00790, loss = 3.8759
2024-10-29 11:49:50: [2024-10-29 11:49:50] iter = 00800, loss = 8.5477
2024-10-29 11:49:50: [2024-10-29 11:49:50] iter = 00810, loss = 6.6542
2024-10-29 11:49:51: [2024-10-29 11:49:51] iter = 00820, loss = 2.6423
2024-10-29 11:49:51: [2024-10-29 11:49:51] iter = 00830, loss = 7.1170
2024-10-29 11:49:52: [2024-10-29 11:49:52] iter = 00840, loss = 6.0268
2024-10-29 11:49:52: [2024-10-29 11:49:52] iter = 00850, loss = 5.3279
2024-10-29 11:49:53: [2024-10-29 11:49:53] iter = 00860, loss = 6.9823
2024-10-29 11:49:53: [2024-10-29 11:49:53] iter = 00870, loss = 5.3741
2024-10-29 11:49:54: [2024-10-29 11:49:54] iter = 00880, loss = 3.0264
2024-10-29 11:49:54: [2024-10-29 11:49:54] iter = 00890, loss = 4.9913
2024-10-29 11:49:54: [2024-10-29 11:49:54] iter = 00900, loss = 8.5820
2024-10-29 11:49:55: [2024-10-29 11:49:55] iter = 00910, loss = 6.1917
2024-10-29 11:49:55: [2024-10-29 11:49:55] iter = 00920, loss = 4.0525
2024-10-29 11:49:56: [2024-10-29 11:49:56] iter = 00930, loss = 4.7870
2024-10-29 11:49:56: [2024-10-29 11:49:56] iter = 00940, loss = 30.4925
2024-10-29 11:49:57: [2024-10-29 11:49:57] iter = 00950, loss = 2.8837
2024-10-29 11:49:57: [2024-10-29 11:49:57] iter = 00960, loss = 3.2293
2024-10-29 11:49:58: [2024-10-29 11:49:58] iter = 00970, loss = 3.1156
2024-10-29 11:49:58: [2024-10-29 11:49:58] iter = 00980, loss = 7.1839
2024-10-29 11:49:59: [2024-10-29 11:49:59] iter = 00990, loss = 8.9737
2024-10-29 11:49:59: [2024-10-29 11:49:59] iter = 01000, loss = 2.9105
2024-10-29 11:50:00: [2024-10-29 11:50:00] iter = 01010, loss = 3.8186
2024-10-29 11:50:00: [2024-10-29 11:50:00] iter = 01020, loss = 7.3474
2024-10-29 11:50:00: [2024-10-29 11:50:00] iter = 01030, loss = 40.4110
2024-10-29 11:50:01: [2024-10-29 11:50:01] iter = 01040, loss = 4.5621
2024-10-29 11:50:01: [2024-10-29 11:50:01] iter = 01050, loss = 4.6241
2024-10-29 11:50:02: [2024-10-29 11:50:02] iter = 01060, loss = 11.7712
2024-10-29 11:50:02: [2024-10-29 11:50:02] iter = 01070, loss = 9.7015
2024-10-29 11:50:03: [2024-10-29 11:50:03] iter = 01080, loss = 3.4299
2024-10-29 11:50:03: [2024-10-29 11:50:03] iter = 01090, loss = 5.8113
2024-10-29 11:50:03: [2024-10-29 11:50:03] iter = 01100, loss = 48.8051
2024-10-29 11:50:04: [2024-10-29 11:50:04] iter = 01110, loss = 2.6012
2024-10-29 11:50:04: [2024-10-29 11:50:04] iter = 01120, loss = 3.1424
2024-10-29 11:50:05: [2024-10-29 11:50:05] iter = 01130, loss = 27.5185
2024-10-29 11:50:05: [2024-10-29 11:50:05] iter = 01140, loss = 2.9917
2024-10-29 11:50:06: [2024-10-29 11:50:06] iter = 01150, loss = 13.5085
2024-10-29 11:50:06: [2024-10-29 11:50:06] iter = 01160, loss = 5.4553
2024-10-29 11:50:06: [2024-10-29 11:50:06] iter = 01170, loss = 7.4018
2024-10-29 11:50:07: [2024-10-29 11:50:07] iter = 01180, loss = 4.0628
2024-10-29 11:50:07: [2024-10-29 11:50:07] iter = 01190, loss = 13.1941
2024-10-29 11:50:08: [2024-10-29 11:50:08] iter = 01200, loss = 7.2440
2024-10-29 11:50:08: [2024-10-29 11:50:08] iter = 01210, loss = 12.3639
2024-10-29 11:50:09: [2024-10-29 11:50:09] iter = 01220, loss = 2.7312
2024-10-29 11:50:09: [2024-10-29 11:50:09] iter = 01230, loss = 26.6387
2024-10-29 11:50:10: [2024-10-29 11:50:10] iter = 01240, loss = 4.8839
2024-10-29 11:50:10: [2024-10-29 11:50:10] iter = 01250, loss = 8.2382
2024-10-29 11:50:11: [2024-10-29 11:50:11] iter = 01260, loss = 18.8564
2024-10-29 11:50:11: [2024-10-29 11:50:11] iter = 01270, loss = 9.6165
2024-10-29 11:50:12: [2024-10-29 11:50:12] iter = 01280, loss = 4.8356
2024-10-29 11:50:12: [2024-10-29 11:50:12] iter = 01290, loss = 2.8219
2024-10-29 11:50:13: [2024-10-29 11:50:13] iter = 01300, loss = 5.0655
2024-10-29 11:50:13: [2024-10-29 11:50:13] iter = 01310, loss = 6.1112
2024-10-29 11:50:14: [2024-10-29 11:50:14] iter = 01320, loss = 3.8202
2024-10-29 11:50:14: [2024-10-29 11:50:14] iter = 01330, loss = 22.7815
2024-10-29 11:50:15: [2024-10-29 11:50:15] iter = 01340, loss = 3.8413
2024-10-29 11:50:15: [2024-10-29 11:50:15] iter = 01350, loss = 3.4502
2024-10-29 11:50:15: [2024-10-29 11:50:15] iter = 01360, loss = 32.2947
2024-10-29 11:50:16: [2024-10-29 11:50:16] iter = 01370, loss = 5.0633
2024-10-29 11:50:16: [2024-10-29 11:50:16] iter = 01380, loss = 4.1057
2024-10-29 11:50:17: [2024-10-29 11:50:17] iter = 01390, loss = 4.8320
2024-10-29 11:50:17: [2024-10-29 11:50:17] iter = 01400, loss = 7.9724
2024-10-29 11:50:18: [2024-10-29 11:50:18] iter = 01410, loss = 8.1108
2024-10-29 11:50:18: [2024-10-29 11:50:18] iter = 01420, loss = 2.5105
2024-10-29 11:50:18: [2024-10-29 11:50:18] iter = 01430, loss = 21.2712
2024-10-29 11:50:19: [2024-10-29 11:50:19] iter = 01440, loss = 3.8770
2024-10-29 11:50:20: [2024-10-29 11:50:20] iter = 01450, loss = 11.6461
2024-10-29 11:50:20: [2024-10-29 11:50:20] iter = 01460, loss = 5.8794
2024-10-29 11:50:21: [2024-10-29 11:50:21] iter = 01470, loss = 5.9615
2024-10-29 11:50:21: [2024-10-29 11:50:21] iter = 01480, loss = 21.1561
2024-10-29 11:50:22: [2024-10-29 11:50:22] iter = 01490, loss = 12.0987
2024-10-29 11:50:23: [2024-10-29 11:50:23] iter = 01500, loss = 3.4661
2024-10-29 11:50:23: [2024-10-29 11:50:23] iter = 01510, loss = 5.8741
2024-10-29 11:50:23: [2024-10-29 11:50:23] iter = 01520, loss = 6.4673
2024-10-29 11:50:24: [2024-10-29 11:50:24] iter = 01530, loss = 11.9059
2024-10-29 11:50:24: [2024-10-29 11:50:24] iter = 01540, loss = 7.3895
2024-10-29 11:50:25: [2024-10-29 11:50:25] iter = 01550, loss = 6.1857
2024-10-29 11:50:25: [2024-10-29 11:50:25] iter = 01560, loss = 4.9608
2024-10-29 11:50:25: [2024-10-29 11:50:25] iter = 01570, loss = 16.1554
2024-10-29 11:50:26: [2024-10-29 11:50:26] iter = 01580, loss = 13.7315
2024-10-29 11:50:26: [2024-10-29 11:50:26] iter = 01590, loss = 2.3030
2024-10-29 11:50:26: [2024-10-29 11:50:26] iter = 01600, loss = 2.8285
2024-10-29 11:50:27: [2024-10-29 11:50:27] iter = 01610, loss = 12.6023
2024-10-29 11:50:27: [2024-10-29 11:50:27] iter = 01620, loss = 18.7570
2024-10-29 11:50:28: [2024-10-29 11:50:28] iter = 01630, loss = 32.4780
2024-10-29 11:50:28: [2024-10-29 11:50:28] iter = 01640, loss = 9.5815
2024-10-29 11:50:29: [2024-10-29 11:50:29] iter = 01650, loss = 4.9648
2024-10-29 11:50:29: [2024-10-29 11:50:29] iter = 01660, loss = 6.0424
2024-10-29 11:50:30: [2024-10-29 11:50:30] iter = 01670, loss = 2.9464
2024-10-29 11:50:30: [2024-10-29 11:50:30] iter = 01680, loss = 5.2710
2024-10-29 11:50:31: [2024-10-29 11:50:31] iter = 01690, loss = 5.6475
2024-10-29 11:50:31: [2024-10-29 11:50:31] iter = 01700, loss = 2.8573
2024-10-29 11:50:32: [2024-10-29 11:50:32] iter = 01710, loss = 5.4922
2024-10-29 11:50:32: [2024-10-29 11:50:32] iter = 01720, loss = 3.7917
2024-10-29 11:50:33: [2024-10-29 11:50:33] iter = 01730, loss = 7.9550
2024-10-29 11:50:33: [2024-10-29 11:50:33] iter = 01740, loss = 4.3694
2024-10-29 11:50:33: [2024-10-29 11:50:33] iter = 01750, loss = 6.2033
2024-10-29 11:50:34: [2024-10-29 11:50:34] iter = 01760, loss = 2.9609
2024-10-29 11:50:34: [2024-10-29 11:50:34] iter = 01770, loss = 21.2784
2024-10-29 11:50:35: [2024-10-29 11:50:35] iter = 01780, loss = 2.7273
2024-10-29 11:50:35: [2024-10-29 11:50:35] iter = 01790, loss = 6.9701
2024-10-29 11:50:35: [2024-10-29 11:50:35] iter = 01800, loss = 29.2172
2024-10-29 11:50:36: [2024-10-29 11:50:36] iter = 01810, loss = 10.3692
2024-10-29 11:50:36: [2024-10-29 11:50:36] iter = 01820, loss = 3.0436
2024-10-29 11:50:37: [2024-10-29 11:50:37] iter = 01830, loss = 8.9780
2024-10-29 11:50:37: [2024-10-29 11:50:37] iter = 01840, loss = 2.7644
2024-10-29 11:50:37: [2024-10-29 11:50:37] iter = 01850, loss = 3.8006
2024-10-29 11:50:38: [2024-10-29 11:50:38] iter = 01860, loss = 3.0809
2024-10-29 11:50:38: [2024-10-29 11:50:38] iter = 01870, loss = 2.5098
2024-10-29 11:50:39: [2024-10-29 11:50:39] iter = 01880, loss = 34.6518
2024-10-29 11:50:39: [2024-10-29 11:50:39] iter = 01890, loss = 5.5873
2024-10-29 11:50:40: [2024-10-29 11:50:40] iter = 01900, loss = 6.5722
2024-10-29 11:50:40: [2024-10-29 11:50:40] iter = 01910, loss = 4.8836
2024-10-29 11:50:41: [2024-10-29 11:50:41] iter = 01920, loss = 3.3013
2024-10-29 11:50:41: [2024-10-29 11:50:41] iter = 01930, loss = 5.0054
2024-10-29 11:50:41: [2024-10-29 11:50:41] iter = 01940, loss = 33.1700
2024-10-29 11:50:42: [2024-10-29 11:50:42] iter = 01950, loss = 8.2208
2024-10-29 11:50:42: [2024-10-29 11:50:42] iter = 01960, loss = 6.5476
2024-10-29 11:50:43: [2024-10-29 11:50:43] iter = 01970, loss = 4.7986
2024-10-29 11:50:43: [2024-10-29 11:50:43] iter = 01980, loss = 2.9036
2024-10-29 11:50:43: [2024-10-29 11:50:43] iter = 01990, loss = 18.9795
2024-10-29 11:50:44: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 11:50:44: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:50:44: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 44201}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:51:07: Evaluate 5 random ConvNet, ACCmean = 0.5172 ACCstd = 0.0129
-------------------------
2024-10-29 11:51:07: Evaluate 5 random ConvNet, SENmean = 0.5172 SENstd = 0.0129
-------------------------
2024-10-29 11:51:07: Evaluate 5 random ConvNet, SPEmean = 0.8391 SPEstd = 0.0043
-------------------------
2024-10-29 11:51:07: Evaluate 5 random ConvNet, F!mean = 0.4770 F!std = 0.0143
-------------------------
2024-10-29 11:51:07: Evaluate 5 random ConvNet, mean = 0.5172 std = 0.0129
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:51:07: [2024-10-29 11:51:07] iter = 02000, loss = 3.2761
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:51:07: [2024-10-29 11:51:07] iter = 02010, loss = 5.0188
2024-10-29 11:51:08: [2024-10-29 11:51:08] iter = 02020, loss = 7.5127
2024-10-29 11:51:08: [2024-10-29 11:51:08] iter = 02030, loss = 9.2876
2024-10-29 11:51:08: [2024-10-29 11:51:08] iter = 02040, loss = 5.5358
2024-10-29 11:51:09: [2024-10-29 11:51:09] iter = 02050, loss = 4.8014
2024-10-29 11:51:09: [2024-10-29 11:51:09] iter = 02060, loss = 12.8492
2024-10-29 11:51:10: [2024-10-29 11:51:10] iter = 02070, loss = 11.9971
2024-10-29 11:51:10: [2024-10-29 11:51:10] iter = 02080, loss = 10.4138
2024-10-29 11:51:11: [2024-10-29 11:51:11] iter = 02090, loss = 5.8909
2024-10-29 11:51:11: [2024-10-29 11:51:11] iter = 02100, loss = 9.7447
2024-10-29 11:51:12: [2024-10-29 11:51:12] iter = 02110, loss = 5.0576
2024-10-29 11:51:12: [2024-10-29 11:51:12] iter = 02120, loss = 11.1355
2024-10-29 11:51:12: [2024-10-29 11:51:12] iter = 02130, loss = 27.0870
2024-10-29 11:51:13: [2024-10-29 11:51:13] iter = 02140, loss = 5.8902
2024-10-29 11:51:13: [2024-10-29 11:51:13] iter = 02150, loss = 3.1217
2024-10-29 11:51:14: [2024-10-29 11:51:14] iter = 02160, loss = 9.9847
2024-10-29 11:51:14: [2024-10-29 11:51:14] iter = 02170, loss = 5.0700
2024-10-29 11:51:15: [2024-10-29 11:51:15] iter = 02180, loss = 6.5206
2024-10-29 11:51:15: [2024-10-29 11:51:15] iter = 02190, loss = 3.1042
2024-10-29 11:51:15: [2024-10-29 11:51:15] iter = 02200, loss = 6.2353
2024-10-29 11:51:16: [2024-10-29 11:51:16] iter = 02210, loss = 5.4144
2024-10-29 11:51:16: [2024-10-29 11:51:16] iter = 02220, loss = 4.1347
2024-10-29 11:51:17: [2024-10-29 11:51:17] iter = 02230, loss = 17.9303
2024-10-29 11:51:17: [2024-10-29 11:51:17] iter = 02240, loss = 14.9028
2024-10-29 11:51:18: [2024-10-29 11:51:18] iter = 02250, loss = 4.6969
2024-10-29 11:51:18: [2024-10-29 11:51:18] iter = 02260, loss = 5.5203
2024-10-29 11:51:19: [2024-10-29 11:51:19] iter = 02270, loss = 17.4359
2024-10-29 11:51:19: [2024-10-29 11:51:19] iter = 02280, loss = 6.6927
2024-10-29 11:51:20: [2024-10-29 11:51:20] iter = 02290, loss = 6.9582
2024-10-29 11:51:20: [2024-10-29 11:51:20] iter = 02300, loss = 7.1747
2024-10-29 11:51:21: [2024-10-29 11:51:21] iter = 02310, loss = 15.9374
2024-10-29 11:51:21: [2024-10-29 11:51:21] iter = 02320, loss = 15.0929
2024-10-29 11:51:22: [2024-10-29 11:51:22] iter = 02330, loss = 3.2011
2024-10-29 11:51:22: [2024-10-29 11:51:22] iter = 02340, loss = 5.4776
2024-10-29 11:51:22: [2024-10-29 11:51:22] iter = 02350, loss = 25.4990
2024-10-29 11:51:23: [2024-10-29 11:51:23] iter = 02360, loss = 5.6032
2024-10-29 11:51:23: [2024-10-29 11:51:23] iter = 02370, loss = 8.3659
2024-10-29 11:51:24: [2024-10-29 11:51:24] iter = 02380, loss = 7.1619
2024-10-29 11:51:24: [2024-10-29 11:51:24] iter = 02390, loss = 4.5732
2024-10-29 11:51:25: [2024-10-29 11:51:25] iter = 02400, loss = 22.6905
2024-10-29 11:51:25: [2024-10-29 11:51:25] iter = 02410, loss = 9.1467
2024-10-29 11:51:26: [2024-10-29 11:51:26] iter = 02420, loss = 9.0061
2024-10-29 11:51:26: [2024-10-29 11:51:26] iter = 02430, loss = 14.3905
2024-10-29 11:51:26: [2024-10-29 11:51:26] iter = 02440, loss = 4.4150
2024-10-29 11:51:27: [2024-10-29 11:51:27] iter = 02450, loss = 3.3737
2024-10-29 11:51:27: [2024-10-29 11:51:27] iter = 02460, loss = 5.6279
2024-10-29 11:51:28: [2024-10-29 11:51:28] iter = 02470, loss = 6.7383
2024-10-29 11:51:28: [2024-10-29 11:51:28] iter = 02480, loss = 14.5641
2024-10-29 11:51:28: [2024-10-29 11:51:28] iter = 02490, loss = 16.0655
2024-10-29 11:51:29: [2024-10-29 11:51:29] iter = 02500, loss = 27.4528
2024-10-29 11:51:29: [2024-10-29 11:51:29] iter = 02510, loss = 6.2069
2024-10-29 11:51:30: [2024-10-29 11:51:30] iter = 02520, loss = 4.7135
2024-10-29 11:51:30: [2024-10-29 11:51:30] iter = 02530, loss = 5.1660
2024-10-29 11:51:30: [2024-10-29 11:51:30] iter = 02540, loss = 2.5850
2024-10-29 11:51:31: [2024-10-29 11:51:31] iter = 02550, loss = 6.5581
2024-10-29 11:51:31: [2024-10-29 11:51:31] iter = 02560, loss = 4.5247
2024-10-29 11:51:32: [2024-10-29 11:51:32] iter = 02570, loss = 9.2029
2024-10-29 11:51:32: [2024-10-29 11:51:32] iter = 02580, loss = 4.8315
2024-10-29 11:51:32: [2024-10-29 11:51:32] iter = 02590, loss = 8.4447
2024-10-29 11:51:33: [2024-10-29 11:51:33] iter = 02600, loss = 4.8921
2024-10-29 11:51:33: [2024-10-29 11:51:33] iter = 02610, loss = 11.4473
2024-10-29 11:51:34: [2024-10-29 11:51:34] iter = 02620, loss = 3.4251
2024-10-29 11:51:34: [2024-10-29 11:51:34] iter = 02630, loss = 3.3854
2024-10-29 11:51:35: [2024-10-29 11:51:35] iter = 02640, loss = 35.1893
2024-10-29 11:51:35: [2024-10-29 11:51:35] iter = 02650, loss = 4.8060
2024-10-29 11:51:36: [2024-10-29 11:51:36] iter = 02660, loss = 12.4768
2024-10-29 11:51:36: [2024-10-29 11:51:36] iter = 02670, loss = 6.4559
2024-10-29 11:51:37: [2024-10-29 11:51:37] iter = 02680, loss = 2.4562
2024-10-29 11:51:37: [2024-10-29 11:51:37] iter = 02690, loss = 3.4907
2024-10-29 11:51:38: [2024-10-29 11:51:38] iter = 02700, loss = 43.5018
2024-10-29 11:51:38: [2024-10-29 11:51:38] iter = 02710, loss = 19.1245
2024-10-29 11:51:39: [2024-10-29 11:51:39] iter = 02720, loss = 4.3048
2024-10-29 11:51:39: [2024-10-29 11:51:39] iter = 02730, loss = 7.0256
2024-10-29 11:51:40: [2024-10-29 11:51:40] iter = 02740, loss = 10.4513
2024-10-29 11:51:40: [2024-10-29 11:51:40] iter = 02750, loss = 3.8375
2024-10-29 11:51:40: [2024-10-29 11:51:40] iter = 02760, loss = 22.2717
2024-10-29 11:51:41: [2024-10-29 11:51:41] iter = 02770, loss = 7.2753
2024-10-29 11:51:41: [2024-10-29 11:51:41] iter = 02780, loss = 49.8694
2024-10-29 11:51:42: [2024-10-29 11:51:42] iter = 02790, loss = 3.3232
2024-10-29 11:51:42: [2024-10-29 11:51:42] iter = 02800, loss = 24.0422
2024-10-29 11:51:42: [2024-10-29 11:51:42] iter = 02810, loss = 9.0593
2024-10-29 11:51:43: [2024-10-29 11:51:43] iter = 02820, loss = 22.2749
2024-10-29 11:51:43: [2024-10-29 11:51:43] iter = 02830, loss = 5.6809
2024-10-29 11:51:44: [2024-10-29 11:51:44] iter = 02840, loss = 11.3736
2024-10-29 11:51:44: [2024-10-29 11:51:44] iter = 02850, loss = 13.5063
2024-10-29 11:51:45: [2024-10-29 11:51:45] iter = 02860, loss = 5.6302
2024-10-29 11:51:45: [2024-10-29 11:51:45] iter = 02870, loss = 9.0768
2024-10-29 11:51:46: [2024-10-29 11:51:46] iter = 02880, loss = 4.2457
2024-10-29 11:51:46: [2024-10-29 11:51:46] iter = 02890, loss = 6.2111
2024-10-29 11:51:47: [2024-10-29 11:51:47] iter = 02900, loss = 26.9539
2024-10-29 11:51:47: [2024-10-29 11:51:47] iter = 02910, loss = 3.9765
2024-10-29 11:51:48: [2024-10-29 11:51:48] iter = 02920, loss = 72.2922
2024-10-29 11:51:48: [2024-10-29 11:51:48] iter = 02930, loss = 4.4563
2024-10-29 11:51:49: [2024-10-29 11:51:49] iter = 02940, loss = 5.6932
2024-10-29 11:51:49: [2024-10-29 11:51:49] iter = 02950, loss = 7.1332
2024-10-29 11:51:49: [2024-10-29 11:51:49] iter = 02960, loss = 7.5694
2024-10-29 11:51:50: [2024-10-29 11:51:50] iter = 02970, loss = 9.7163
2024-10-29 11:51:50: [2024-10-29 11:51:50] iter = 02980, loss = 25.3815
2024-10-29 11:51:51: [2024-10-29 11:51:51] iter = 02990, loss = 4.0103
2024-10-29 11:51:51: [2024-10-29 11:51:51] iter = 03000, loss = 5.1005
2024-10-29 11:51:51: [2024-10-29 11:51:51] iter = 03010, loss = 9.3560
2024-10-29 11:51:52: [2024-10-29 11:51:52] iter = 03020, loss = 5.1279
2024-10-29 11:51:52: [2024-10-29 11:51:52] iter = 03030, loss = 8.7916
2024-10-29 11:51:53: [2024-10-29 11:51:53] iter = 03040, loss = 54.0997
2024-10-29 11:51:53: [2024-10-29 11:51:53] iter = 03050, loss = 3.4479
2024-10-29 11:51:54: [2024-10-29 11:51:54] iter = 03060, loss = 11.8469
2024-10-29 11:51:55: [2024-10-29 11:51:55] iter = 03070, loss = 15.5897
2024-10-29 11:51:55: [2024-10-29 11:51:55] iter = 03080, loss = 9.7193
2024-10-29 11:51:55: [2024-10-29 11:51:55] iter = 03090, loss = 3.4461
2024-10-29 11:51:56: [2024-10-29 11:51:56] iter = 03100, loss = 3.7365
2024-10-29 11:51:56: [2024-10-29 11:51:56] iter = 03110, loss = 3.0867
2024-10-29 11:51:57: [2024-10-29 11:51:57] iter = 03120, loss = 11.2871
2024-10-29 11:51:57: [2024-10-29 11:51:57] iter = 03130, loss = 7.9898
2024-10-29 11:51:58: [2024-10-29 11:51:58] iter = 03140, loss = 4.6958
2024-10-29 11:51:58: [2024-10-29 11:51:58] iter = 03150, loss = 6.1315
2024-10-29 11:51:58: [2024-10-29 11:51:58] iter = 03160, loss = 4.7760
2024-10-29 11:51:59: [2024-10-29 11:51:59] iter = 03170, loss = 6.4899
2024-10-29 11:51:59: [2024-10-29 11:51:59] iter = 03180, loss = 5.6829
2024-10-29 11:52:00: [2024-10-29 11:52:00] iter = 03190, loss = 3.4275
2024-10-29 11:52:00: [2024-10-29 11:52:00] iter = 03200, loss = 8.1534
2024-10-29 11:52:01: [2024-10-29 11:52:01] iter = 03210, loss = 6.7732
2024-10-29 11:52:01: [2024-10-29 11:52:01] iter = 03220, loss = 6.6277
2024-10-29 11:52:02: [2024-10-29 11:52:02] iter = 03230, loss = 19.7019
2024-10-29 11:52:02: [2024-10-29 11:52:02] iter = 03240, loss = 3.9471
2024-10-29 11:52:02: [2024-10-29 11:52:02] iter = 03250, loss = 3.1375
2024-10-29 11:52:03: [2024-10-29 11:52:03] iter = 03260, loss = 7.5513
2024-10-29 11:52:03: [2024-10-29 11:52:03] iter = 03270, loss = 4.7119
2024-10-29 11:52:04: [2024-10-29 11:52:04] iter = 03280, loss = 18.9190
2024-10-29 11:52:04: [2024-10-29 11:52:04] iter = 03290, loss = 7.6753
2024-10-29 11:52:05: [2024-10-29 11:52:05] iter = 03300, loss = 49.9330
2024-10-29 11:52:05: [2024-10-29 11:52:05] iter = 03310, loss = 10.9053
2024-10-29 11:52:05: [2024-10-29 11:52:05] iter = 03320, loss = 3.0971
2024-10-29 11:52:06: [2024-10-29 11:52:06] iter = 03330, loss = 11.7418
2024-10-29 11:52:06: [2024-10-29 11:52:06] iter = 03340, loss = 4.2093
2024-10-29 11:52:07: [2024-10-29 11:52:07] iter = 03350, loss = 3.7011
2024-10-29 11:52:07: [2024-10-29 11:52:07] iter = 03360, loss = 52.8462
2024-10-29 11:52:07: [2024-10-29 11:52:07] iter = 03370, loss = 45.1193
2024-10-29 11:52:08: [2024-10-29 11:52:08] iter = 03380, loss = 3.9133
2024-10-29 11:52:08: [2024-10-29 11:52:08] iter = 03390, loss = 11.7414
2024-10-29 11:52:09: [2024-10-29 11:52:09] iter = 03400, loss = 3.2299
2024-10-29 11:52:09: [2024-10-29 11:52:09] iter = 03410, loss = 8.2017
2024-10-29 11:52:10: [2024-10-29 11:52:10] iter = 03420, loss = 3.4255
2024-10-29 11:52:10: [2024-10-29 11:52:10] iter = 03430, loss = 3.3230
2024-10-29 11:52:11: [2024-10-29 11:52:11] iter = 03440, loss = 5.8695
2024-10-29 11:52:11: [2024-10-29 11:52:11] iter = 03450, loss = 2.3034
2024-10-29 11:52:11: [2024-10-29 11:52:11] iter = 03460, loss = 46.7454
2024-10-29 11:52:12: [2024-10-29 11:52:12] iter = 03470, loss = 5.4239
2024-10-29 11:52:12: [2024-10-29 11:52:12] iter = 03480, loss = 5.3861
2024-10-29 11:52:13: [2024-10-29 11:52:13] iter = 03490, loss = 7.9271
2024-10-29 11:52:13: [2024-10-29 11:52:13] iter = 03500, loss = 4.0537
2024-10-29 11:52:14: [2024-10-29 11:52:13] iter = 03510, loss = 14.5577
2024-10-29 11:52:14: [2024-10-29 11:52:14] iter = 03520, loss = 3.1832
2024-10-29 11:52:14: [2024-10-29 11:52:14] iter = 03530, loss = 5.5983
2024-10-29 11:52:15: [2024-10-29 11:52:15] iter = 03540, loss = 4.8812
2024-10-29 11:52:15: [2024-10-29 11:52:15] iter = 03550, loss = 26.2636
2024-10-29 11:52:16: [2024-10-29 11:52:16] iter = 03560, loss = 2.8422
2024-10-29 11:52:16: [2024-10-29 11:52:16] iter = 03570, loss = 3.8565
2024-10-29 11:52:17: [2024-10-29 11:52:17] iter = 03580, loss = 11.9080
2024-10-29 11:52:17: [2024-10-29 11:52:17] iter = 03590, loss = 7.6535
2024-10-29 11:52:17: [2024-10-29 11:52:17] iter = 03600, loss = 3.7880
2024-10-29 11:52:18: [2024-10-29 11:52:18] iter = 03610, loss = 5.5708
2024-10-29 11:52:18: [2024-10-29 11:52:18] iter = 03620, loss = 6.4195
2024-10-29 11:52:19: [2024-10-29 11:52:19] iter = 03630, loss = 3.1532
2024-10-29 11:52:19: [2024-10-29 11:52:19] iter = 03640, loss = 6.4393
2024-10-29 11:52:20: [2024-10-29 11:52:20] iter = 03650, loss = 16.0502
2024-10-29 11:52:20: [2024-10-29 11:52:20] iter = 03660, loss = 10.4010
2024-10-29 11:52:21: [2024-10-29 11:52:21] iter = 03670, loss = 33.2176
2024-10-29 11:52:21: [2024-10-29 11:52:21] iter = 03680, loss = 8.0332
2024-10-29 11:52:22: [2024-10-29 11:52:22] iter = 03690, loss = 8.5943
2024-10-29 11:52:22: [2024-10-29 11:52:22] iter = 03700, loss = 3.3088
2024-10-29 11:52:23: [2024-10-29 11:52:23] iter = 03710, loss = 3.6785
2024-10-29 11:52:23: [2024-10-29 11:52:23] iter = 03720, loss = 15.9114
2024-10-29 11:52:24: [2024-10-29 11:52:24] iter = 03730, loss = 2.6648
2024-10-29 11:52:24: [2024-10-29 11:52:24] iter = 03740, loss = 3.2470
2024-10-29 11:52:25: [2024-10-29 11:52:25] iter = 03750, loss = 3.0767
2024-10-29 11:52:25: [2024-10-29 11:52:25] iter = 03760, loss = 3.1618
2024-10-29 11:52:26: [2024-10-29 11:52:26] iter = 03770, loss = 5.9493
2024-10-29 11:52:27: [2024-10-29 11:52:27] iter = 03780, loss = 3.1884
2024-10-29 11:52:27: [2024-10-29 11:52:27] iter = 03790, loss = 13.5217
2024-10-29 11:52:28: [2024-10-29 11:52:28] iter = 03800, loss = 12.8306
2024-10-29 11:52:28: [2024-10-29 11:52:28] iter = 03810, loss = 5.1360
2024-10-29 11:52:29: [2024-10-29 11:52:29] iter = 03820, loss = 2.6055
2024-10-29 11:52:29: [2024-10-29 11:52:29] iter = 03830, loss = 8.4003
2024-10-29 11:52:30: [2024-10-29 11:52:30] iter = 03840, loss = 6.7208
2024-10-29 11:52:30: [2024-10-29 11:52:30] iter = 03850, loss = 55.0580
2024-10-29 11:52:31: [2024-10-29 11:52:31] iter = 03860, loss = 9.5766
2024-10-29 11:52:31: [2024-10-29 11:52:31] iter = 03870, loss = 26.7264
2024-10-29 11:52:32: [2024-10-29 11:52:32] iter = 03880, loss = 3.2227
2024-10-29 11:52:32: [2024-10-29 11:52:32] iter = 03890, loss = 2.8624
2024-10-29 11:52:33: [2024-10-29 11:52:33] iter = 03900, loss = 5.4030
2024-10-29 11:52:33: [2024-10-29 11:52:33] iter = 03910, loss = 49.8974
2024-10-29 11:52:33: [2024-10-29 11:52:33] iter = 03920, loss = 9.1390
2024-10-29 11:52:34: [2024-10-29 11:52:34] iter = 03930, loss = 20.3614
2024-10-29 11:52:34: [2024-10-29 11:52:34] iter = 03940, loss = 2.0858
2024-10-29 11:52:35: [2024-10-29 11:52:35] iter = 03950, loss = 14.1200
2024-10-29 11:52:35: [2024-10-29 11:52:35] iter = 03960, loss = 7.3037
2024-10-29 11:52:36: [2024-10-29 11:52:36] iter = 03970, loss = 7.7907
2024-10-29 11:52:36: [2024-10-29 11:52:36] iter = 03980, loss = 7.0823
2024-10-29 11:52:36: [2024-10-29 11:52:36] iter = 03990, loss = 45.6568
2024-10-29 11:52:37: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 11:52:37: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:52:37: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57499}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:53:01: Evaluate 5 random ConvNet, ACCmean = 0.4768 ACCstd = 0.0176
-------------------------
2024-10-29 11:53:01: Evaluate 5 random ConvNet, SENmean = 0.4768 SENstd = 0.0176
-------------------------
2024-10-29 11:53:01: Evaluate 5 random ConvNet, SPEmean = 0.8256 SPEstd = 0.0059
-------------------------
2024-10-29 11:53:01: Evaluate 5 random ConvNet, F!mean = 0.4620 F!std = 0.0219
-------------------------
2024-10-29 11:53:01: Evaluate 5 random ConvNet, mean = 0.4768 std = 0.0176
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:53:01: [2024-10-29 11:53:01] iter = 04000, loss = 5.3082
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:53:01: [2024-10-29 11:53:01] iter = 04010, loss = 5.4719
2024-10-29 11:53:02: [2024-10-29 11:53:02] iter = 04020, loss = 8.6981
2024-10-29 11:53:02: [2024-10-29 11:53:02] iter = 04030, loss = 3.4175
2024-10-29 11:53:03: [2024-10-29 11:53:03] iter = 04040, loss = 13.6279
2024-10-29 11:53:03: [2024-10-29 11:53:03] iter = 04050, loss = 45.7387
2024-10-29 11:53:03: [2024-10-29 11:53:03] iter = 04060, loss = 2.8998
2024-10-29 11:53:04: [2024-10-29 11:53:04] iter = 04070, loss = 12.4766
2024-10-29 11:53:04: [2024-10-29 11:53:04] iter = 04080, loss = 9.6182
2024-10-29 11:53:04: [2024-10-29 11:53:04] iter = 04090, loss = 5.4480
2024-10-29 11:53:05: [2024-10-29 11:53:05] iter = 04100, loss = 15.3684
2024-10-29 11:53:06: [2024-10-29 11:53:05] iter = 04110, loss = 4.5626
2024-10-29 11:53:06: [2024-10-29 11:53:06] iter = 04120, loss = 18.3594
2024-10-29 11:53:07: [2024-10-29 11:53:07] iter = 04130, loss = 3.5642
2024-10-29 11:53:07: [2024-10-29 11:53:07] iter = 04140, loss = 5.4075
2024-10-29 11:53:07: [2024-10-29 11:53:07] iter = 04150, loss = 12.4168
2024-10-29 11:53:08: [2024-10-29 11:53:08] iter = 04160, loss = 3.6400
2024-10-29 11:53:08: [2024-10-29 11:53:08] iter = 04170, loss = 2.4092
2024-10-29 11:53:09: [2024-10-29 11:53:09] iter = 04180, loss = 9.4424
2024-10-29 11:53:09: [2024-10-29 11:53:09] iter = 04190, loss = 11.3759
2024-10-29 11:53:10: [2024-10-29 11:53:10] iter = 04200, loss = 5.0354
2024-10-29 11:53:10: [2024-10-29 11:53:10] iter = 04210, loss = 6.4097
2024-10-29 11:53:11: [2024-10-29 11:53:11] iter = 04220, loss = 3.2984
2024-10-29 11:53:11: [2024-10-29 11:53:11] iter = 04230, loss = 5.9560
2024-10-29 11:53:12: [2024-10-29 11:53:12] iter = 04240, loss = 33.2792
2024-10-29 11:53:12: [2024-10-29 11:53:12] iter = 04250, loss = 9.2937
2024-10-29 11:53:13: [2024-10-29 11:53:13] iter = 04260, loss = 4.2912
2024-10-29 11:53:13: [2024-10-29 11:53:13] iter = 04270, loss = 4.0640
2024-10-29 11:53:14: [2024-10-29 11:53:14] iter = 04280, loss = 6.4520
2024-10-29 11:53:14: [2024-10-29 11:53:14] iter = 04290, loss = 8.5308
2024-10-29 11:53:15: [2024-10-29 11:53:15] iter = 04300, loss = 8.3569
2024-10-29 11:53:15: [2024-10-29 11:53:15] iter = 04310, loss = 6.1793
2024-10-29 11:53:15: [2024-10-29 11:53:15] iter = 04320, loss = 4.5177
2024-10-29 11:53:16: [2024-10-29 11:53:16] iter = 04330, loss = 13.7073
2024-10-29 11:53:16: [2024-10-29 11:53:16] iter = 04340, loss = 6.6460
2024-10-29 11:53:17: [2024-10-29 11:53:17] iter = 04350, loss = 3.9470
2024-10-29 11:53:17: [2024-10-29 11:53:17] iter = 04360, loss = 34.5090
2024-10-29 11:53:18: [2024-10-29 11:53:18] iter = 04370, loss = 9.9909
2024-10-29 11:53:18: [2024-10-29 11:53:18] iter = 04380, loss = 11.4765
2024-10-29 11:53:18: [2024-10-29 11:53:18] iter = 04390, loss = 6.9503
2024-10-29 11:53:19: [2024-10-29 11:53:19] iter = 04400, loss = 2.2665
2024-10-29 11:53:19: [2024-10-29 11:53:19] iter = 04410, loss = 33.0004
2024-10-29 11:53:19: [2024-10-29 11:53:19] iter = 04420, loss = 7.1097
2024-10-29 11:53:20: [2024-10-29 11:53:20] iter = 04430, loss = 2.7795
2024-10-29 11:53:20: [2024-10-29 11:53:20] iter = 04440, loss = 28.1686
2024-10-29 11:53:20: [2024-10-29 11:53:20] iter = 04450, loss = 5.0233
2024-10-29 11:53:21: [2024-10-29 11:53:21] iter = 04460, loss = 6.0828
2024-10-29 11:53:21: [2024-10-29 11:53:21] iter = 04470, loss = 15.3126
2024-10-29 11:53:22: [2024-10-29 11:53:22] iter = 04480, loss = 6.5757
2024-10-29 11:53:22: [2024-10-29 11:53:22] iter = 04490, loss = 5.1068
2024-10-29 11:53:23: [2024-10-29 11:53:23] iter = 04500, loss = 5.2433
2024-10-29 11:53:23: [2024-10-29 11:53:23] iter = 04510, loss = 5.5787
2024-10-29 11:53:24: [2024-10-29 11:53:24] iter = 04520, loss = 10.6947
2024-10-29 11:53:24: [2024-10-29 11:53:24] iter = 04530, loss = 5.3581
2024-10-29 11:53:25: [2024-10-29 11:53:25] iter = 04540, loss = 24.3313
2024-10-29 11:53:25: [2024-10-29 11:53:25] iter = 04550, loss = 4.9578
2024-10-29 11:53:26: [2024-10-29 11:53:26] iter = 04560, loss = 6.3244
2024-10-29 11:53:26: [2024-10-29 11:53:26] iter = 04570, loss = 4.2912
2024-10-29 11:53:27: [2024-10-29 11:53:27] iter = 04580, loss = 4.3249
2024-10-29 11:53:27: [2024-10-29 11:53:27] iter = 04590, loss = 3.6518
2024-10-29 11:53:27: [2024-10-29 11:53:27] iter = 04600, loss = 35.9015
2024-10-29 11:53:28: [2024-10-29 11:53:28] iter = 04610, loss = 12.8080
2024-10-29 11:53:28: [2024-10-29 11:53:28] iter = 04620, loss = 3.0276
2024-10-29 11:53:29: [2024-10-29 11:53:29] iter = 04630, loss = 2.2808
2024-10-29 11:53:29: [2024-10-29 11:53:29] iter = 04640, loss = 3.2676
2024-10-29 11:53:30: [2024-10-29 11:53:30] iter = 04650, loss = 3.4240
2024-10-29 11:53:30: [2024-10-29 11:53:30] iter = 04660, loss = 12.6954
2024-10-29 11:53:31: [2024-10-29 11:53:31] iter = 04670, loss = 4.7796
2024-10-29 11:53:31: [2024-10-29 11:53:31] iter = 04680, loss = 12.5995
2024-10-29 11:53:32: [2024-10-29 11:53:32] iter = 04690, loss = 11.1103
2024-10-29 11:53:32: [2024-10-29 11:53:32] iter = 04700, loss = 3.8029
2024-10-29 11:53:33: [2024-10-29 11:53:33] iter = 04710, loss = 2.7201
2024-10-29 11:53:33: [2024-10-29 11:53:33] iter = 04720, loss = 6.2960
2024-10-29 11:53:34: [2024-10-29 11:53:34] iter = 04730, loss = 9.4275
2024-10-29 11:53:34: [2024-10-29 11:53:34] iter = 04740, loss = 3.9708
2024-10-29 11:53:35: [2024-10-29 11:53:35] iter = 04750, loss = 6.8859
2024-10-29 11:53:35: [2024-10-29 11:53:35] iter = 04760, loss = 9.3035
2024-10-29 11:53:36: [2024-10-29 11:53:36] iter = 04770, loss = 8.3876
2024-10-29 11:53:36: [2024-10-29 11:53:36] iter = 04780, loss = 7.2794
2024-10-29 11:53:36: [2024-10-29 11:53:36] iter = 04790, loss = 10.7703
2024-10-29 11:53:37: [2024-10-29 11:53:37] iter = 04800, loss = 27.6859
2024-10-29 11:53:37: [2024-10-29 11:53:37] iter = 04810, loss = 8.8605
2024-10-29 11:53:38: [2024-10-29 11:53:38] iter = 04820, loss = 40.0555
2024-10-29 11:53:38: [2024-10-29 11:53:38] iter = 04830, loss = 9.5538
2024-10-29 11:53:39: [2024-10-29 11:53:39] iter = 04840, loss = 13.2830
2024-10-29 11:53:39: [2024-10-29 11:53:39] iter = 04850, loss = 3.5219
2024-10-29 11:53:39: [2024-10-29 11:53:39] iter = 04860, loss = 45.9904
2024-10-29 11:53:40: [2024-10-29 11:53:40] iter = 04870, loss = 10.3618
2024-10-29 11:53:40: [2024-10-29 11:53:40] iter = 04880, loss = 6.9828
2024-10-29 11:53:41: [2024-10-29 11:53:41] iter = 04890, loss = 12.2222
2024-10-29 11:53:41: [2024-10-29 11:53:41] iter = 04900, loss = 43.0420
2024-10-29 11:53:41: [2024-10-29 11:53:41] iter = 04910, loss = 12.3407
2024-10-29 11:53:42: [2024-10-29 11:53:42] iter = 04920, loss = 3.2365
2024-10-29 11:53:42: [2024-10-29 11:53:42] iter = 04930, loss = 2.9751
2024-10-29 11:53:43: [2024-10-29 11:53:43] iter = 04940, loss = 2.7487
2024-10-29 11:53:43: [2024-10-29 11:53:43] iter = 04950, loss = 15.2901
2024-10-29 11:53:44: [2024-10-29 11:53:44] iter = 04960, loss = 6.1357
2024-10-29 11:53:44: [2024-10-29 11:53:44] iter = 04970, loss = 15.5936
2024-10-29 11:53:44: [2024-10-29 11:53:44] iter = 04980, loss = 5.9591
2024-10-29 11:53:45: [2024-10-29 11:53:45] iter = 04990, loss = 5.2053
2024-10-29 11:53:45: [2024-10-29 11:53:45] iter = 05000, loss = 12.2353
2024-10-29 11:53:46: [2024-10-29 11:53:46] iter = 05010, loss = 3.5286
2024-10-29 11:53:46: [2024-10-29 11:53:46] iter = 05020, loss = 5.7303
2024-10-29 11:53:47: [2024-10-29 11:53:47] iter = 05030, loss = 2.4877
2024-10-29 11:53:47: [2024-10-29 11:53:47] iter = 05040, loss = 4.0496
2024-10-29 11:53:48: [2024-10-29 11:53:48] iter = 05050, loss = 32.9011
2024-10-29 11:53:48: [2024-10-29 11:53:48] iter = 05060, loss = 11.6140
2024-10-29 11:53:49: [2024-10-29 11:53:49] iter = 05070, loss = 50.7722
2024-10-29 11:53:49: [2024-10-29 11:53:49] iter = 05080, loss = 11.9694
2024-10-29 11:53:50: [2024-10-29 11:53:50] iter = 05090, loss = 11.6911
2024-10-29 11:53:50: [2024-10-29 11:53:50] iter = 05100, loss = 4.1692
2024-10-29 11:53:51: [2024-10-29 11:53:51] iter = 05110, loss = 23.5560
2024-10-29 11:53:51: [2024-10-29 11:53:51] iter = 05120, loss = 24.2066
2024-10-29 11:53:52: [2024-10-29 11:53:52] iter = 05130, loss = 3.7370
2024-10-29 11:53:52: [2024-10-29 11:53:52] iter = 05140, loss = 18.9432
2024-10-29 11:53:53: [2024-10-29 11:53:53] iter = 05150, loss = 4.5481
2024-10-29 11:53:53: [2024-10-29 11:53:53] iter = 05160, loss = 2.7357
2024-10-29 11:53:53: [2024-10-29 11:53:53] iter = 05170, loss = 3.3719
2024-10-29 11:53:54: [2024-10-29 11:53:54] iter = 05180, loss = 15.4145
2024-10-29 11:53:54: [2024-10-29 11:53:54] iter = 05190, loss = 6.7387
2024-10-29 11:53:55: [2024-10-29 11:53:55] iter = 05200, loss = 21.8542
2024-10-29 11:53:55: [2024-10-29 11:53:55] iter = 05210, loss = 32.9253
2024-10-29 11:53:55: [2024-10-29 11:53:55] iter = 05220, loss = 2.8073
2024-10-29 11:53:56: [2024-10-29 11:53:56] iter = 05230, loss = 26.6012
2024-10-29 11:53:56: [2024-10-29 11:53:56] iter = 05240, loss = 5.5481
2024-10-29 11:53:57: [2024-10-29 11:53:57] iter = 05250, loss = 9.7982
2024-10-29 11:53:57: [2024-10-29 11:53:57] iter = 05260, loss = 7.6761
2024-10-29 11:53:58: [2024-10-29 11:53:58] iter = 05270, loss = 2.8794
2024-10-29 11:53:58: [2024-10-29 11:53:58] iter = 05280, loss = 2.6542
2024-10-29 11:53:59: [2024-10-29 11:53:59] iter = 05290, loss = 5.1753
2024-10-29 11:53:59: [2024-10-29 11:53:59] iter = 05300, loss = 8.7995
2024-10-29 11:54:00: [2024-10-29 11:54:00] iter = 05310, loss = 6.6148
2024-10-29 11:54:00: [2024-10-29 11:54:00] iter = 05320, loss = 3.0980
2024-10-29 11:54:00: [2024-10-29 11:54:00] iter = 05330, loss = 2.9492
2024-10-29 11:54:01: [2024-10-29 11:54:01] iter = 05340, loss = 31.6182
2024-10-29 11:54:01: [2024-10-29 11:54:01] iter = 05350, loss = 4.7148
2024-10-29 11:54:02: [2024-10-29 11:54:02] iter = 05360, loss = 8.5760
2024-10-29 11:54:02: [2024-10-29 11:54:02] iter = 05370, loss = 6.4460
2024-10-29 11:54:02: [2024-10-29 11:54:02] iter = 05380, loss = 22.8175
2024-10-29 11:54:03: [2024-10-29 11:54:03] iter = 05390, loss = 12.4184
2024-10-29 11:54:03: [2024-10-29 11:54:03] iter = 05400, loss = 25.4521
2024-10-29 11:54:03: [2024-10-29 11:54:03] iter = 05410, loss = 59.0040
2024-10-29 11:54:04: [2024-10-29 11:54:04] iter = 05420, loss = 26.4015
2024-10-29 11:54:04: [2024-10-29 11:54:04] iter = 05430, loss = 57.9768
2024-10-29 11:54:05: [2024-10-29 11:54:05] iter = 05440, loss = 4.2740
2024-10-29 11:54:05: [2024-10-29 11:54:05] iter = 05450, loss = 3.8196
2024-10-29 11:54:06: [2024-10-29 11:54:06] iter = 05460, loss = 48.4951
2024-10-29 11:54:06: [2024-10-29 11:54:06] iter = 05470, loss = 4.1223
2024-10-29 11:54:07: [2024-10-29 11:54:07] iter = 05480, loss = 8.5476
2024-10-29 11:54:07: [2024-10-29 11:54:07] iter = 05490, loss = 5.9442
2024-10-29 11:54:08: [2024-10-29 11:54:08] iter = 05500, loss = 4.5561
2024-10-29 11:54:08: [2024-10-29 11:54:08] iter = 05510, loss = 3.8761
2024-10-29 11:54:08: [2024-10-29 11:54:08] iter = 05520, loss = 6.4845
2024-10-29 11:54:09: [2024-10-29 11:54:09] iter = 05530, loss = 3.8090
2024-10-29 11:54:09: [2024-10-29 11:54:09] iter = 05540, loss = 2.4217
2024-10-29 11:54:10: [2024-10-29 11:54:10] iter = 05550, loss = 4.8522
2024-10-29 11:54:10: [2024-10-29 11:54:10] iter = 05560, loss = 9.9173
2024-10-29 11:54:10: [2024-10-29 11:54:10] iter = 05570, loss = 2.7216
2024-10-29 11:54:11: [2024-10-29 11:54:11] iter = 05580, loss = 3.6551
2024-10-29 11:54:11: [2024-10-29 11:54:11] iter = 05590, loss = 12.9502
2024-10-29 11:54:12: [2024-10-29 11:54:12] iter = 05600, loss = 3.8783
2024-10-29 11:54:12: [2024-10-29 11:54:12] iter = 05610, loss = 27.3277
2024-10-29 11:54:12: [2024-10-29 11:54:12] iter = 05620, loss = 3.6708
2024-10-29 11:54:13: [2024-10-29 11:54:13] iter = 05630, loss = 4.6904
2024-10-29 11:54:13: [2024-10-29 11:54:13] iter = 05640, loss = 21.5877
2024-10-29 11:54:14: [2024-10-29 11:54:14] iter = 05650, loss = 3.8229
2024-10-29 11:54:14: [2024-10-29 11:54:14] iter = 05660, loss = 2.0977
2024-10-29 11:54:15: [2024-10-29 11:54:15] iter = 05670, loss = 2.3049
2024-10-29 11:54:15: [2024-10-29 11:54:15] iter = 05680, loss = 7.2735
2024-10-29 11:54:15: [2024-10-29 11:54:15] iter = 05690, loss = 3.1713
2024-10-29 11:54:16: [2024-10-29 11:54:16] iter = 05700, loss = 8.0209
2024-10-29 11:54:16: [2024-10-29 11:54:16] iter = 05710, loss = 2.8982
2024-10-29 11:54:17: [2024-10-29 11:54:17] iter = 05720, loss = 2.8579
2024-10-29 11:54:17: [2024-10-29 11:54:17] iter = 05730, loss = 8.6697
2024-10-29 11:54:17: [2024-10-29 11:54:17] iter = 05740, loss = 39.2987
2024-10-29 11:54:18: [2024-10-29 11:54:18] iter = 05750, loss = 27.8589
2024-10-29 11:54:18: [2024-10-29 11:54:18] iter = 05760, loss = 3.6890
2024-10-29 11:54:19: [2024-10-29 11:54:19] iter = 05770, loss = 19.3992
2024-10-29 11:54:19: [2024-10-29 11:54:19] iter = 05780, loss = 11.6518
2024-10-29 11:54:20: [2024-10-29 11:54:20] iter = 05790, loss = 3.2597
2024-10-29 11:54:20: [2024-10-29 11:54:20] iter = 05800, loss = 55.7378
2024-10-29 11:54:21: [2024-10-29 11:54:21] iter = 05810, loss = 3.3360
2024-10-29 11:54:21: [2024-10-29 11:54:21] iter = 05820, loss = 9.0764
2024-10-29 11:54:21: [2024-10-29 11:54:21] iter = 05830, loss = 3.2648
2024-10-29 11:54:22: [2024-10-29 11:54:22] iter = 05840, loss = 2.8999
2024-10-29 11:54:22: [2024-10-29 11:54:22] iter = 05850, loss = 11.0028
2024-10-29 11:54:23: [2024-10-29 11:54:23] iter = 05860, loss = 13.9059
2024-10-29 11:54:23: [2024-10-29 11:54:23] iter = 05870, loss = 6.7928
2024-10-29 11:54:24: [2024-10-29 11:54:24] iter = 05880, loss = 9.4426
2024-10-29 11:54:24: [2024-10-29 11:54:24] iter = 05890, loss = 10.3588
2024-10-29 11:54:25: [2024-10-29 11:54:25] iter = 05900, loss = 5.5201
2024-10-29 11:54:25: [2024-10-29 11:54:25] iter = 05910, loss = 22.1535
2024-10-29 11:54:26: [2024-10-29 11:54:26] iter = 05920, loss = 5.2627
2024-10-29 11:54:26: [2024-10-29 11:54:26] iter = 05930, loss = 2.9887
2024-10-29 11:54:27: [2024-10-29 11:54:27] iter = 05940, loss = 3.7879
2024-10-29 11:54:27: [2024-10-29 11:54:27] iter = 05950, loss = 4.5879
2024-10-29 11:54:28: [2024-10-29 11:54:28] iter = 05960, loss = 2.9784
2024-10-29 11:54:28: [2024-10-29 11:54:28] iter = 05970, loss = 38.9830
2024-10-29 11:54:29: [2024-10-29 11:54:29] iter = 05980, loss = 8.7161
2024-10-29 11:54:29: [2024-10-29 11:54:29] iter = 05990, loss = 7.5502
2024-10-29 11:54:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 11:54:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:54:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 70033}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:54:54: Evaluate 5 random ConvNet, ACCmean = 0.4752 ACCstd = 0.0060
-------------------------
2024-10-29 11:54:54: Evaluate 5 random ConvNet, SENmean = 0.4752 SENstd = 0.0060
-------------------------
2024-10-29 11:54:54: Evaluate 5 random ConvNet, SPEmean = 0.8251 SPEstd = 0.0020
-------------------------
2024-10-29 11:54:54: Evaluate 5 random ConvNet, F!mean = 0.3973 F!std = 0.0044
-------------------------
2024-10-29 11:54:54: Evaluate 5 random ConvNet, mean = 0.4752 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:54:54: [2024-10-29 11:54:54] iter = 06000, loss = 4.9234
2024-10-29 11:54:54: [2024-10-29 11:54:54] iter = 06010, loss = 4.3749
2024-10-29 11:54:55: [2024-10-29 11:54:55] iter = 06020, loss = 5.2099
2024-10-29 11:54:55: [2024-10-29 11:54:55] iter = 06030, loss = 2.8914
2024-10-29 11:54:56: [2024-10-29 11:54:56] iter = 06040, loss = 2.7905
2024-10-29 11:54:56: [2024-10-29 11:54:56] iter = 06050, loss = 12.4520
2024-10-29 11:54:57: [2024-10-29 11:54:57] iter = 06060, loss = 3.7138
2024-10-29 11:54:57: [2024-10-29 11:54:57] iter = 06070, loss = 4.4169
2024-10-29 11:54:57: [2024-10-29 11:54:57] iter = 06080, loss = 3.3274
2024-10-29 11:54:58: [2024-10-29 11:54:58] iter = 06090, loss = 14.9242
2024-10-29 11:54:58: [2024-10-29 11:54:58] iter = 06100, loss = 2.9991
2024-10-29 11:54:59: [2024-10-29 11:54:59] iter = 06110, loss = 3.7279
2024-10-29 11:54:59: [2024-10-29 11:54:59] iter = 06120, loss = 9.9692
2024-10-29 11:55:00: [2024-10-29 11:55:00] iter = 06130, loss = 2.8389
2024-10-29 11:55:00: [2024-10-29 11:55:00] iter = 06140, loss = 5.2894
2024-10-29 11:55:01: [2024-10-29 11:55:01] iter = 06150, loss = 8.9814
2024-10-29 11:55:01: [2024-10-29 11:55:01] iter = 06160, loss = 6.2568
2024-10-29 11:55:01: [2024-10-29 11:55:01] iter = 06170, loss = 4.2893
2024-10-29 11:55:02: [2024-10-29 11:55:02] iter = 06180, loss = 9.8274
2024-10-29 11:55:02: [2024-10-29 11:55:02] iter = 06190, loss = 5.7586
2024-10-29 11:55:03: [2024-10-29 11:55:03] iter = 06200, loss = 7.6596
2024-10-29 11:55:03: [2024-10-29 11:55:03] iter = 06210, loss = 9.9465
2024-10-29 11:55:04: [2024-10-29 11:55:04] iter = 06220, loss = 2.8996
2024-10-29 11:55:04: [2024-10-29 11:55:04] iter = 06230, loss = 5.0454
2024-10-29 11:55:05: [2024-10-29 11:55:05] iter = 06240, loss = 40.1740
2024-10-29 11:55:05: [2024-10-29 11:55:05] iter = 06250, loss = 12.8087
2024-10-29 11:55:06: [2024-10-29 11:55:06] iter = 06260, loss = 8.8325
2024-10-29 11:55:06: [2024-10-29 11:55:06] iter = 06270, loss = 49.6828
2024-10-29 11:55:06: [2024-10-29 11:55:06] iter = 06280, loss = 8.8286
2024-10-29 11:55:07: [2024-10-29 11:55:07] iter = 06290, loss = 4.6840
2024-10-29 11:55:07: [2024-10-29 11:55:07] iter = 06300, loss = 46.5646
2024-10-29 11:55:08: [2024-10-29 11:55:08] iter = 06310, loss = 8.5598
2024-10-29 11:55:08: [2024-10-29 11:55:08] iter = 06320, loss = 13.6079
2024-10-29 11:55:09: [2024-10-29 11:55:09] iter = 06330, loss = 4.4791
2024-10-29 11:55:09: [2024-10-29 11:55:09] iter = 06340, loss = 16.6964
2024-10-29 11:55:10: [2024-10-29 11:55:10] iter = 06350, loss = 26.6936
2024-10-29 11:55:10: [2024-10-29 11:55:10] iter = 06360, loss = 5.7380
2024-10-29 11:55:11: [2024-10-29 11:55:11] iter = 06370, loss = 2.6400
2024-10-29 11:55:11: [2024-10-29 11:55:11] iter = 06380, loss = 3.2862
2024-10-29 11:55:12: [2024-10-29 11:55:12] iter = 06390, loss = 4.2860
2024-10-29 11:55:12: [2024-10-29 11:55:12] iter = 06400, loss = 19.8231
2024-10-29 11:55:13: [2024-10-29 11:55:13] iter = 06410, loss = 6.7883
2024-10-29 11:55:13: [2024-10-29 11:55:13] iter = 06420, loss = 18.2806
2024-10-29 11:55:14: [2024-10-29 11:55:14] iter = 06430, loss = 9.8119
2024-10-29 11:55:14: [2024-10-29 11:55:14] iter = 06440, loss = 50.0288
2024-10-29 11:55:14: [2024-10-29 11:55:14] iter = 06450, loss = 30.5654
2024-10-29 11:55:15: [2024-10-29 11:55:15] iter = 06460, loss = 4.5577
2024-10-29 11:55:15: [2024-10-29 11:55:15] iter = 06470, loss = 5.4082
2024-10-29 11:55:16: [2024-10-29 11:55:16] iter = 06480, loss = 4.9368
2024-10-29 11:55:16: [2024-10-29 11:55:16] iter = 06490, loss = 12.8284
2024-10-29 11:55:17: [2024-10-29 11:55:17] iter = 06500, loss = 11.3269
2024-10-29 11:55:17: [2024-10-29 11:55:17] iter = 06510, loss = 4.8100
2024-10-29 11:55:17: [2024-10-29 11:55:17] iter = 06520, loss = 2.7708
2024-10-29 11:55:18: [2024-10-29 11:55:18] iter = 06530, loss = 5.3477
2024-10-29 11:55:18: [2024-10-29 11:55:18] iter = 06540, loss = 8.2648
2024-10-29 11:55:19: [2024-10-29 11:55:19] iter = 06550, loss = 3.5862
2024-10-29 11:55:19: [2024-10-29 11:55:19] iter = 06560, loss = 48.7372
2024-10-29 11:55:20: [2024-10-29 11:55:20] iter = 06570, loss = 42.9652
2024-10-29 11:55:20: [2024-10-29 11:55:20] iter = 06580, loss = 4.3964
2024-10-29 11:55:20: [2024-10-29 11:55:20] iter = 06590, loss = 4.7297
2024-10-29 11:55:21: [2024-10-29 11:55:21] iter = 06600, loss = 4.7898
2024-10-29 11:55:21: [2024-10-29 11:55:21] iter = 06610, loss = 21.4885
2024-10-29 11:55:22: [2024-10-29 11:55:22] iter = 06620, loss = 2.8987
2024-10-29 11:55:22: [2024-10-29 11:55:22] iter = 06630, loss = 3.7089
2024-10-29 11:55:23: [2024-10-29 11:55:23] iter = 06640, loss = 10.0915
2024-10-29 11:55:23: [2024-10-29 11:55:23] iter = 06650, loss = 3.4735
2024-10-29 11:55:24: [2024-10-29 11:55:24] iter = 06660, loss = 4.5272
2024-10-29 11:55:24: [2024-10-29 11:55:24] iter = 06670, loss = 5.5406
2024-10-29 11:55:25: [2024-10-29 11:55:25] iter = 06680, loss = 11.0078
2024-10-29 11:55:25: [2024-10-29 11:55:25] iter = 06690, loss = 7.0663
2024-10-29 11:55:25: [2024-10-29 11:55:25] iter = 06700, loss = 4.7671
2024-10-29 11:55:26: [2024-10-29 11:55:26] iter = 06710, loss = 3.9056
2024-10-29 11:55:26: [2024-10-29 11:55:26] iter = 06720, loss = 4.3860
2024-10-29 11:55:26: [2024-10-29 11:55:26] iter = 06730, loss = 25.3766
2024-10-29 11:55:27: [2024-10-29 11:55:27] iter = 06740, loss = 6.1935
2024-10-29 11:55:27: [2024-10-29 11:55:27] iter = 06750, loss = 3.6111
2024-10-29 11:55:27: [2024-10-29 11:55:27] iter = 06760, loss = 5.0432
2024-10-29 11:55:28: [2024-10-29 11:55:28] iter = 06770, loss = 3.4351
2024-10-29 11:55:28: [2024-10-29 11:55:28] iter = 06780, loss = 3.0678
2024-10-29 11:55:28: [2024-10-29 11:55:28] iter = 06790, loss = 3.4353
2024-10-29 11:55:29: [2024-10-29 11:55:29] iter = 06800, loss = 12.9562
2024-10-29 11:55:29: [2024-10-29 11:55:29] iter = 06810, loss = 5.9157
2024-10-29 11:55:30: [2024-10-29 11:55:30] iter = 06820, loss = 4.4187
2024-10-29 11:55:30: [2024-10-29 11:55:30] iter = 06830, loss = 50.7710
2024-10-29 11:55:30: [2024-10-29 11:55:30] iter = 06840, loss = 5.4564
2024-10-29 11:55:31: [2024-10-29 11:55:31] iter = 06850, loss = 3.6280
2024-10-29 11:55:31: [2024-10-29 11:55:31] iter = 06860, loss = 6.1766
2024-10-29 11:55:32: [2024-10-29 11:55:32] iter = 06870, loss = 7.4686
2024-10-29 11:55:32: [2024-10-29 11:55:32] iter = 06880, loss = 2.2725
2024-10-29 11:55:33: [2024-10-29 11:55:33] iter = 06890, loss = 2.7896
2024-10-29 11:55:33: [2024-10-29 11:55:33] iter = 06900, loss = 3.1706
2024-10-29 11:55:34: [2024-10-29 11:55:34] iter = 06910, loss = 6.4196
2024-10-29 11:55:34: [2024-10-29 11:55:34] iter = 06920, loss = 13.7051
2024-10-29 11:55:34: [2024-10-29 11:55:34] iter = 06930, loss = 30.3911
2024-10-29 11:55:35: [2024-10-29 11:55:35] iter = 06940, loss = 3.9236
2024-10-29 11:55:35: [2024-10-29 11:55:35] iter = 06950, loss = 3.5514
2024-10-29 11:55:36: [2024-10-29 11:55:36] iter = 06960, loss = 3.5930
2024-10-29 11:55:36: [2024-10-29 11:55:36] iter = 06970, loss = 7.0614
2024-10-29 11:55:37: [2024-10-29 11:55:37] iter = 06980, loss = 4.2678
2024-10-29 11:55:37: [2024-10-29 11:55:37] iter = 06990, loss = 4.2409
2024-10-29 11:55:37: [2024-10-29 11:55:37] iter = 07000, loss = 9.9975
2024-10-29 11:55:38: [2024-10-29 11:55:38] iter = 07010, loss = 4.5542
2024-10-29 11:55:38: [2024-10-29 11:55:38] iter = 07020, loss = 3.0149
2024-10-29 11:55:39: [2024-10-29 11:55:39] iter = 07030, loss = 3.0270
2024-10-29 11:55:39: [2024-10-29 11:55:39] iter = 07040, loss = 3.7747
2024-10-29 11:55:40: [2024-10-29 11:55:40] iter = 07050, loss = 7.9933
2024-10-29 11:55:40: [2024-10-29 11:55:40] iter = 07060, loss = 16.8711
2024-10-29 11:55:41: [2024-10-29 11:55:41] iter = 07070, loss = 4.6711
2024-10-29 11:55:41: [2024-10-29 11:55:41] iter = 07080, loss = 9.5024
2024-10-29 11:55:42: [2024-10-29 11:55:42] iter = 07090, loss = 6.1645
2024-10-29 11:55:42: [2024-10-29 11:55:42] iter = 07100, loss = 4.8302
2024-10-29 11:55:43: [2024-10-29 11:55:43] iter = 07110, loss = 4.5319
2024-10-29 11:55:43: [2024-10-29 11:55:43] iter = 07120, loss = 6.4488
2024-10-29 11:55:44: [2024-10-29 11:55:44] iter = 07130, loss = 3.9222
2024-10-29 11:55:44: [2024-10-29 11:55:44] iter = 07140, loss = 6.1260
2024-10-29 11:55:45: [2024-10-29 11:55:45] iter = 07150, loss = 3.4149
2024-10-29 11:55:45: [2024-10-29 11:55:45] iter = 07160, loss = 51.5835
2024-10-29 11:55:46: [2024-10-29 11:55:46] iter = 07170, loss = 3.2454
2024-10-29 11:55:46: [2024-10-29 11:55:46] iter = 07180, loss = 14.1948
2024-10-29 11:55:47: [2024-10-29 11:55:47] iter = 07190, loss = 2.4887
2024-10-29 11:55:47: [2024-10-29 11:55:47] iter = 07200, loss = 8.2565
2024-10-29 11:55:48: [2024-10-29 11:55:48] iter = 07210, loss = 67.4668
2024-10-29 11:55:48: [2024-10-29 11:55:48] iter = 07220, loss = 9.5678
2024-10-29 11:55:49: [2024-10-29 11:55:49] iter = 07230, loss = 2.3388
2024-10-29 11:55:49: [2024-10-29 11:55:49] iter = 07240, loss = 5.7132
2024-10-29 11:55:49: [2024-10-29 11:55:49] iter = 07250, loss = 57.4106
2024-10-29 11:55:50: [2024-10-29 11:55:50] iter = 07260, loss = 26.2423
2024-10-29 11:55:50: [2024-10-29 11:55:50] iter = 07270, loss = 3.2048
2024-10-29 11:55:51: [2024-10-29 11:55:51] iter = 07280, loss = 2.7844
2024-10-29 11:55:51: [2024-10-29 11:55:51] iter = 07290, loss = 2.3727
2024-10-29 11:55:52: [2024-10-29 11:55:52] iter = 07300, loss = 17.4965
2024-10-29 11:55:52: [2024-10-29 11:55:52] iter = 07310, loss = 5.5497
2024-10-29 11:55:53: [2024-10-29 11:55:53] iter = 07320, loss = 26.4656
2024-10-29 11:55:53: [2024-10-29 11:55:53] iter = 07330, loss = 7.6356
2024-10-29 11:55:53: [2024-10-29 11:55:53] iter = 07340, loss = 8.2376
2024-10-29 11:55:54: [2024-10-29 11:55:54] iter = 07350, loss = 25.1334
2024-10-29 11:55:54: [2024-10-29 11:55:54] iter = 07360, loss = 4.7982
2024-10-29 11:55:55: [2024-10-29 11:55:55] iter = 07370, loss = 7.8211
2024-10-29 11:55:55: [2024-10-29 11:55:55] iter = 07380, loss = 2.5293
2024-10-29 11:55:56: [2024-10-29 11:55:56] iter = 07390, loss = 5.3388
2024-10-29 11:55:56: [2024-10-29 11:55:56] iter = 07400, loss = 17.0997
2024-10-29 11:55:57: [2024-10-29 11:55:57] iter = 07410, loss = 26.8575
2024-10-29 11:55:57: [2024-10-29 11:55:57] iter = 07420, loss = 7.5430
2024-10-29 11:55:57: [2024-10-29 11:55:57] iter = 07430, loss = 2.8390
2024-10-29 11:55:58: [2024-10-29 11:55:58] iter = 07440, loss = 65.1170
2024-10-29 11:55:58: [2024-10-29 11:55:58] iter = 07450, loss = 13.2391
2024-10-29 11:55:59: [2024-10-29 11:55:59] iter = 07460, loss = 46.1126
2024-10-29 11:55:59: [2024-10-29 11:55:59] iter = 07470, loss = 3.9446
2024-10-29 11:55:59: [2024-10-29 11:55:59] iter = 07480, loss = 3.2803
2024-10-29 11:56:00: [2024-10-29 11:56:00] iter = 07490, loss = 12.6703
2024-10-29 11:56:00: [2024-10-29 11:56:00] iter = 07500, loss = 5.0724
2024-10-29 11:56:01: [2024-10-29 11:56:01] iter = 07510, loss = 2.7818
2024-10-29 11:56:01: [2024-10-29 11:56:01] iter = 07520, loss = 3.5450
2024-10-29 11:56:02: [2024-10-29 11:56:02] iter = 07530, loss = 4.2205
2024-10-29 11:56:02: [2024-10-29 11:56:02] iter = 07540, loss = 4.0048
2024-10-29 11:56:02: [2024-10-29 11:56:02] iter = 07550, loss = 11.0666
2024-10-29 11:56:03: [2024-10-29 11:56:03] iter = 07560, loss = 41.7868
2024-10-29 11:56:03: [2024-10-29 11:56:03] iter = 07570, loss = 8.5431
2024-10-29 11:56:04: [2024-10-29 11:56:04] iter = 07580, loss = 5.0185
2024-10-29 11:56:04: [2024-10-29 11:56:04] iter = 07590, loss = 52.0480
2024-10-29 11:56:04: [2024-10-29 11:56:04] iter = 07600, loss = 4.6949
2024-10-29 11:56:05: [2024-10-29 11:56:05] iter = 07610, loss = 8.5619
2024-10-29 11:56:05: [2024-10-29 11:56:05] iter = 07620, loss = 4.5020
2024-10-29 11:56:06: [2024-10-29 11:56:06] iter = 07630, loss = 8.0333
2024-10-29 11:56:06: [2024-10-29 11:56:06] iter = 07640, loss = 14.6378
2024-10-29 11:56:07: [2024-10-29 11:56:07] iter = 07650, loss = 4.0956
2024-10-29 11:56:07: [2024-10-29 11:56:07] iter = 07660, loss = 3.4845
2024-10-29 11:56:07: [2024-10-29 11:56:07] iter = 07670, loss = 2.5878
2024-10-29 11:56:08: [2024-10-29 11:56:08] iter = 07680, loss = 16.6161
2024-10-29 11:56:08: [2024-10-29 11:56:08] iter = 07690, loss = 9.3564
2024-10-29 11:56:09: [2024-10-29 11:56:09] iter = 07700, loss = 2.6597
2024-10-29 11:56:09: [2024-10-29 11:56:09] iter = 07710, loss = 16.3435
2024-10-29 11:56:09: [2024-10-29 11:56:09] iter = 07720, loss = 59.6824
2024-10-29 11:56:10: [2024-10-29 11:56:10] iter = 07730, loss = 2.6403
2024-10-29 11:56:10: [2024-10-29 11:56:10] iter = 07740, loss = 5.1894
2024-10-29 11:56:11: [2024-10-29 11:56:11] iter = 07750, loss = 4.9071
2024-10-29 11:56:11: [2024-10-29 11:56:11] iter = 07760, loss = 8.5904
2024-10-29 11:56:12: [2024-10-29 11:56:12] iter = 07770, loss = 27.2677
2024-10-29 11:56:12: [2024-10-29 11:56:12] iter = 07780, loss = 8.0687
2024-10-29 11:56:12: [2024-10-29 11:56:12] iter = 07790, loss = 5.0229
2024-10-29 11:56:13: [2024-10-29 11:56:13] iter = 07800, loss = 3.3057
2024-10-29 11:56:13: [2024-10-29 11:56:13] iter = 07810, loss = 5.9456
2024-10-29 11:56:14: [2024-10-29 11:56:14] iter = 07820, loss = 5.8561
2024-10-29 11:56:14: [2024-10-29 11:56:14] iter = 07830, loss = 7.9225
2024-10-29 11:56:15: [2024-10-29 11:56:15] iter = 07840, loss = 7.7113
2024-10-29 11:56:15: [2024-10-29 11:56:15] iter = 07850, loss = 2.9217
2024-10-29 11:56:16: [2024-10-29 11:56:16] iter = 07860, loss = 9.1161
2024-10-29 11:56:16: [2024-10-29 11:56:16] iter = 07870, loss = 2.5988
2024-10-29 11:56:17: [2024-10-29 11:56:17] iter = 07880, loss = 3.8343
2024-10-29 11:56:17: [2024-10-29 11:56:17] iter = 07890, loss = 4.8408
2024-10-29 11:56:17: [2024-10-29 11:56:17] iter = 07900, loss = 7.8034
2024-10-29 11:56:18: [2024-10-29 11:56:18] iter = 07910, loss = 3.4966
2024-10-29 11:56:18: [2024-10-29 11:56:18] iter = 07920, loss = 2.9250
2024-10-29 11:56:19: [2024-10-29 11:56:19] iter = 07930, loss = 5.2192
2024-10-29 11:56:19: [2024-10-29 11:56:19] iter = 07940, loss = 4.1353
2024-10-29 11:56:20: [2024-10-29 11:56:20] iter = 07950, loss = 13.0882
2024-10-29 11:56:20: [2024-10-29 11:56:20] iter = 07960, loss = 7.3545
2024-10-29 11:56:20: [2024-10-29 11:56:20] iter = 07970, loss = 7.4295
2024-10-29 11:56:21: [2024-10-29 11:56:21] iter = 07980, loss = 2.9704
2024-10-29 11:56:21: [2024-10-29 11:56:21] iter = 07990, loss = 35.0035
2024-10-29 11:56:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 11:56:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:56:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 82024}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:56:44: Evaluate 5 random ConvNet, ACCmean = 0.4468 ACCstd = 0.0100
-------------------------
2024-10-29 11:56:44: Evaluate 5 random ConvNet, SENmean = 0.4468 SENstd = 0.0100
-------------------------
2024-10-29 11:56:44: Evaluate 5 random ConvNet, SPEmean = 0.8156 SPEstd = 0.0033
-------------------------
2024-10-29 11:56:44: Evaluate 5 random ConvNet, F!mean = 0.4208 F!std = 0.0107
-------------------------
2024-10-29 11:56:44: Evaluate 5 random ConvNet, mean = 0.4468 std = 0.0100
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:56:44: [2024-10-29 11:56:44] iter = 08000, loss = 8.7110
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:56:45: [2024-10-29 11:56:45] iter = 08010, loss = 4.6733
2024-10-29 11:56:45: [2024-10-29 11:56:45] iter = 08020, loss = 3.2621
2024-10-29 11:56:46: [2024-10-29 11:56:46] iter = 08030, loss = 5.4444
2024-10-29 11:56:46: [2024-10-29 11:56:46] iter = 08040, loss = 54.3680
2024-10-29 11:56:47: [2024-10-29 11:56:47] iter = 08050, loss = 4.9225
2024-10-29 11:56:47: [2024-10-29 11:56:47] iter = 08060, loss = 13.4603
2024-10-29 11:56:48: [2024-10-29 11:56:48] iter = 08070, loss = 53.1791
2024-10-29 11:56:48: [2024-10-29 11:56:48] iter = 08080, loss = 2.7933
2024-10-29 11:56:49: [2024-10-29 11:56:49] iter = 08090, loss = 4.3203
2024-10-29 11:56:50: [2024-10-29 11:56:50] iter = 08100, loss = 14.2558
2024-10-29 11:56:50: [2024-10-29 11:56:50] iter = 08110, loss = 5.0314
2024-10-29 11:56:51: [2024-10-29 11:56:51] iter = 08120, loss = 8.0219
2024-10-29 11:56:51: [2024-10-29 11:56:51] iter = 08130, loss = 3.3253
2024-10-29 11:56:51: [2024-10-29 11:56:51] iter = 08140, loss = 9.8608
2024-10-29 11:56:52: [2024-10-29 11:56:52] iter = 08150, loss = 3.4447
2024-10-29 11:56:53: [2024-10-29 11:56:53] iter = 08160, loss = 9.5559
2024-10-29 11:56:53: [2024-10-29 11:56:53] iter = 08170, loss = 4.6361
2024-10-29 11:56:53: [2024-10-29 11:56:53] iter = 08180, loss = 6.5243
2024-10-29 11:56:54: [2024-10-29 11:56:54] iter = 08190, loss = 4.3283
2024-10-29 11:56:54: [2024-10-29 11:56:54] iter = 08200, loss = 12.2840
2024-10-29 11:56:55: [2024-10-29 11:56:55] iter = 08210, loss = 23.2324
2024-10-29 11:56:55: [2024-10-29 11:56:55] iter = 08220, loss = 6.5582
2024-10-29 11:56:55: [2024-10-29 11:56:55] iter = 08230, loss = 6.1115
2024-10-29 11:56:56: [2024-10-29 11:56:56] iter = 08240, loss = 2.4489
2024-10-29 11:56:56: [2024-10-29 11:56:56] iter = 08250, loss = 4.2345
2024-10-29 11:56:57: [2024-10-29 11:56:57] iter = 08260, loss = 11.2424
2024-10-29 11:56:57: [2024-10-29 11:56:57] iter = 08270, loss = 11.3372
2024-10-29 11:56:58: [2024-10-29 11:56:58] iter = 08280, loss = 6.3096
2024-10-29 11:56:58: [2024-10-29 11:56:58] iter = 08290, loss = 6.9146
2024-10-29 11:56:58: [2024-10-29 11:56:58] iter = 08300, loss = 11.5616
2024-10-29 11:56:59: [2024-10-29 11:56:59] iter = 08310, loss = 5.2235
2024-10-29 11:56:59: [2024-10-29 11:56:59] iter = 08320, loss = 9.5785
2024-10-29 11:57:00: [2024-10-29 11:57:00] iter = 08330, loss = 8.7198
2024-10-29 11:57:00: [2024-10-29 11:57:00] iter = 08340, loss = 3.4688
2024-10-29 11:57:00: [2024-10-29 11:57:00] iter = 08350, loss = 3.6930
2024-10-29 11:57:01: [2024-10-29 11:57:01] iter = 08360, loss = 7.4610
2024-10-29 11:57:01: [2024-10-29 11:57:01] iter = 08370, loss = 10.7566
2024-10-29 11:57:02: [2024-10-29 11:57:02] iter = 08380, loss = 3.7039
2024-10-29 11:57:02: [2024-10-29 11:57:02] iter = 08390, loss = 4.2096
2024-10-29 11:57:02: [2024-10-29 11:57:02] iter = 08400, loss = 4.3100
2024-10-29 11:57:03: [2024-10-29 11:57:03] iter = 08410, loss = 12.9771
2024-10-29 11:57:03: [2024-10-29 11:57:03] iter = 08420, loss = 17.2720
2024-10-29 11:57:04: [2024-10-29 11:57:04] iter = 08430, loss = 4.3569
2024-10-29 11:57:04: [2024-10-29 11:57:04] iter = 08440, loss = 3.2429
2024-10-29 11:57:04: [2024-10-29 11:57:04] iter = 08450, loss = 20.5526
2024-10-29 11:57:05: [2024-10-29 11:57:05] iter = 08460, loss = 7.4722
2024-10-29 11:57:05: [2024-10-29 11:57:05] iter = 08470, loss = 5.2937
2024-10-29 11:57:06: [2024-10-29 11:57:06] iter = 08480, loss = 41.5231
2024-10-29 11:57:06: [2024-10-29 11:57:06] iter = 08490, loss = 23.5458
2024-10-29 11:57:06: [2024-10-29 11:57:06] iter = 08500, loss = 9.3268
2024-10-29 11:57:07: [2024-10-29 11:57:07] iter = 08510, loss = 3.4910
2024-10-29 11:57:07: [2024-10-29 11:57:07] iter = 08520, loss = 45.1671
2024-10-29 11:57:08: [2024-10-29 11:57:08] iter = 08530, loss = 5.9029
2024-10-29 11:57:08: [2024-10-29 11:57:08] iter = 08540, loss = 14.9758
2024-10-29 11:57:09: [2024-10-29 11:57:09] iter = 08550, loss = 11.3854
2024-10-29 11:57:09: [2024-10-29 11:57:09] iter = 08560, loss = 5.8186
2024-10-29 11:57:10: [2024-10-29 11:57:10] iter = 08570, loss = 3.1497
2024-10-29 11:57:10: [2024-10-29 11:57:10] iter = 08580, loss = 5.0507
2024-10-29 11:57:11: [2024-10-29 11:57:11] iter = 08590, loss = 3.1127
2024-10-29 11:57:11: [2024-10-29 11:57:11] iter = 08600, loss = 13.3810
2024-10-29 11:57:12: [2024-10-29 11:57:12] iter = 08610, loss = 18.6415
2024-10-29 11:57:12: [2024-10-29 11:57:12] iter = 08620, loss = 13.1389
2024-10-29 11:57:13: [2024-10-29 11:57:13] iter = 08630, loss = 10.2538
2024-10-29 11:57:13: [2024-10-29 11:57:13] iter = 08640, loss = 10.4749
2024-10-29 11:57:13: [2024-10-29 11:57:13] iter = 08650, loss = 3.4997
2024-10-29 11:57:14: [2024-10-29 11:57:14] iter = 08660, loss = 15.3873
2024-10-29 11:57:14: [2024-10-29 11:57:14] iter = 08670, loss = 45.8012
2024-10-29 11:57:15: [2024-10-29 11:57:15] iter = 08680, loss = 3.7541
2024-10-29 11:57:15: [2024-10-29 11:57:15] iter = 08690, loss = 5.4674
2024-10-29 11:57:16: [2024-10-29 11:57:16] iter = 08700, loss = 11.1818
2024-10-29 11:57:16: [2024-10-29 11:57:16] iter = 08710, loss = 34.2823
2024-10-29 11:57:17: [2024-10-29 11:57:17] iter = 08720, loss = 8.3846
2024-10-29 11:57:17: [2024-10-29 11:57:17] iter = 08730, loss = 5.2225
2024-10-29 11:57:17: [2024-10-29 11:57:17] iter = 08740, loss = 4.5595
2024-10-29 11:57:18: [2024-10-29 11:57:18] iter = 08750, loss = 2.7932
2024-10-29 11:57:18: [2024-10-29 11:57:18] iter = 08760, loss = 16.2268
2024-10-29 11:57:19: [2024-10-29 11:57:19] iter = 08770, loss = 3.9915
2024-10-29 11:57:19: [2024-10-29 11:57:19] iter = 08780, loss = 4.6418
2024-10-29 11:57:20: [2024-10-29 11:57:20] iter = 08790, loss = 4.5189
2024-10-29 11:57:20: [2024-10-29 11:57:20] iter = 08800, loss = 4.1172
2024-10-29 11:57:21: [2024-10-29 11:57:21] iter = 08810, loss = 5.7567
2024-10-29 11:57:21: [2024-10-29 11:57:21] iter = 08820, loss = 5.1799
2024-10-29 11:57:22: [2024-10-29 11:57:22] iter = 08830, loss = 22.0477
2024-10-29 11:57:22: [2024-10-29 11:57:22] iter = 08840, loss = 3.4886
2024-10-29 11:57:22: [2024-10-29 11:57:22] iter = 08850, loss = 6.9807
2024-10-29 11:57:23: [2024-10-29 11:57:23] iter = 08860, loss = 12.8137
2024-10-29 11:57:23: [2024-10-29 11:57:23] iter = 08870, loss = 2.9927
2024-10-29 11:57:24: [2024-10-29 11:57:24] iter = 08880, loss = 4.2581
2024-10-29 11:57:24: [2024-10-29 11:57:24] iter = 08890, loss = 11.2291
2024-10-29 11:57:25: [2024-10-29 11:57:25] iter = 08900, loss = 16.6632
2024-10-29 11:57:25: [2024-10-29 11:57:25] iter = 08910, loss = 3.5286
2024-10-29 11:57:26: [2024-10-29 11:57:26] iter = 08920, loss = 7.0792
2024-10-29 11:57:26: [2024-10-29 11:57:26] iter = 08930, loss = 6.9146
2024-10-29 11:57:27: [2024-10-29 11:57:27] iter = 08940, loss = 3.6976
2024-10-29 11:57:27: [2024-10-29 11:57:27] iter = 08950, loss = 4.5589
2024-10-29 11:57:27: [2024-10-29 11:57:27] iter = 08960, loss = 17.8931
2024-10-29 11:57:28: [2024-10-29 11:57:28] iter = 08970, loss = 5.2906
2024-10-29 11:57:28: [2024-10-29 11:57:28] iter = 08980, loss = 3.6747
2024-10-29 11:57:29: [2024-10-29 11:57:29] iter = 08990, loss = 5.9761
2024-10-29 11:57:29: [2024-10-29 11:57:29] iter = 09000, loss = 8.0791
2024-10-29 11:57:30: [2024-10-29 11:57:30] iter = 09010, loss = 3.8450
2024-10-29 11:57:30: [2024-10-29 11:57:30] iter = 09020, loss = 4.7658
2024-10-29 11:57:31: [2024-10-29 11:57:31] iter = 09030, loss = 13.0483
2024-10-29 11:57:31: [2024-10-29 11:57:31] iter = 09040, loss = 2.6401
2024-10-29 11:57:31: [2024-10-29 11:57:31] iter = 09050, loss = 11.4596
2024-10-29 11:57:32: [2024-10-29 11:57:32] iter = 09060, loss = 3.6800
2024-10-29 11:57:32: [2024-10-29 11:57:32] iter = 09070, loss = 12.4570
2024-10-29 11:57:33: [2024-10-29 11:57:33] iter = 09080, loss = 5.6971
2024-10-29 11:57:33: [2024-10-29 11:57:33] iter = 09090, loss = 4.8819
2024-10-29 11:57:34: [2024-10-29 11:57:34] iter = 09100, loss = 2.4774
2024-10-29 11:57:34: [2024-10-29 11:57:34] iter = 09110, loss = 3.5461
2024-10-29 11:57:35: [2024-10-29 11:57:35] iter = 09120, loss = 14.8048
2024-10-29 11:57:35: [2024-10-29 11:57:35] iter = 09130, loss = 3.1769
2024-10-29 11:57:36: [2024-10-29 11:57:36] iter = 09140, loss = 4.3651
2024-10-29 11:57:36: [2024-10-29 11:57:36] iter = 09150, loss = 3.8664
2024-10-29 11:57:36: [2024-10-29 11:57:36] iter = 09160, loss = 6.7706
2024-10-29 11:57:37: [2024-10-29 11:57:37] iter = 09170, loss = 5.1985
2024-10-29 11:57:37: [2024-10-29 11:57:37] iter = 09180, loss = 2.3050
2024-10-29 11:57:38: [2024-10-29 11:57:38] iter = 09190, loss = 16.7738
2024-10-29 11:57:38: [2024-10-29 11:57:38] iter = 09200, loss = 4.5355
2024-10-29 11:57:39: [2024-10-29 11:57:39] iter = 09210, loss = 4.6044
2024-10-29 11:57:39: [2024-10-29 11:57:39] iter = 09220, loss = 3.5913
2024-10-29 11:57:40: [2024-10-29 11:57:40] iter = 09230, loss = 41.0313
2024-10-29 11:57:40: [2024-10-29 11:57:40] iter = 09240, loss = 3.3296
2024-10-29 11:57:40: [2024-10-29 11:57:40] iter = 09250, loss = 6.1317
2024-10-29 11:57:41: [2024-10-29 11:57:41] iter = 09260, loss = 3.8667
2024-10-29 11:57:41: [2024-10-29 11:57:41] iter = 09270, loss = 13.8475
2024-10-29 11:57:42: [2024-10-29 11:57:42] iter = 09280, loss = 2.7337
2024-10-29 11:57:42: [2024-10-29 11:57:42] iter = 09290, loss = 8.4411
2024-10-29 11:57:43: [2024-10-29 11:57:43] iter = 09300, loss = 3.7575
2024-10-29 11:57:43: [2024-10-29 11:57:43] iter = 09310, loss = 9.3037
2024-10-29 11:57:44: [2024-10-29 11:57:44] iter = 09320, loss = 7.8023
2024-10-29 11:57:44: [2024-10-29 11:57:44] iter = 09330, loss = 3.7935
2024-10-29 11:57:45: [2024-10-29 11:57:45] iter = 09340, loss = 4.6286
2024-10-29 11:57:45: [2024-10-29 11:57:45] iter = 09350, loss = 33.3046
2024-10-29 11:57:45: [2024-10-29 11:57:45] iter = 09360, loss = 3.2351
2024-10-29 11:57:46: [2024-10-29 11:57:46] iter = 09370, loss = 2.1443
2024-10-29 11:57:46: [2024-10-29 11:57:46] iter = 09380, loss = 20.7076
2024-10-29 11:57:46: [2024-10-29 11:57:46] iter = 09390, loss = 3.3329
2024-10-29 11:57:47: [2024-10-29 11:57:47] iter = 09400, loss = 2.5262
2024-10-29 11:57:47: [2024-10-29 11:57:47] iter = 09410, loss = 14.5824
2024-10-29 11:57:48: [2024-10-29 11:57:48] iter = 09420, loss = 3.1365
2024-10-29 11:57:48: [2024-10-29 11:57:48] iter = 09430, loss = 2.4117
2024-10-29 11:57:49: [2024-10-29 11:57:49] iter = 09440, loss = 2.1963
2024-10-29 11:57:49: [2024-10-29 11:57:49] iter = 09450, loss = 62.4333
2024-10-29 11:57:49: [2024-10-29 11:57:49] iter = 09460, loss = 3.8558
2024-10-29 11:57:50: [2024-10-29 11:57:50] iter = 09470, loss = 8.4683
2024-10-29 11:57:50: [2024-10-29 11:57:50] iter = 09480, loss = 4.2188
2024-10-29 11:57:51: [2024-10-29 11:57:51] iter = 09490, loss = 4.1640
2024-10-29 11:57:51: [2024-10-29 11:57:51] iter = 09500, loss = 2.8751
2024-10-29 11:57:52: [2024-10-29 11:57:52] iter = 09510, loss = 3.5088
2024-10-29 11:57:52: [2024-10-29 11:57:52] iter = 09520, loss = 10.5734
2024-10-29 11:57:53: [2024-10-29 11:57:53] iter = 09530, loss = 11.7343
2024-10-29 11:57:53: [2024-10-29 11:57:53] iter = 09540, loss = 19.3001
2024-10-29 11:57:54: [2024-10-29 11:57:54] iter = 09550, loss = 6.5048
2024-10-29 11:57:54: [2024-10-29 11:57:54] iter = 09560, loss = 8.1377
2024-10-29 11:57:55: [2024-10-29 11:57:55] iter = 09570, loss = 9.0564
2024-10-29 11:57:56: [2024-10-29 11:57:56] iter = 09580, loss = 4.0490
2024-10-29 11:57:56: [2024-10-29 11:57:56] iter = 09590, loss = 11.1655
2024-10-29 11:57:57: [2024-10-29 11:57:57] iter = 09600, loss = 2.5181
2024-10-29 11:57:57: [2024-10-29 11:57:57] iter = 09610, loss = 2.9366
2024-10-29 11:57:58: [2024-10-29 11:57:58] iter = 09620, loss = 23.3218
2024-10-29 11:57:59: [2024-10-29 11:57:59] iter = 09630, loss = 5.1679
2024-10-29 11:57:59: [2024-10-29 11:57:59] iter = 09640, loss = 39.9685
2024-10-29 11:58:00: [2024-10-29 11:58:00] iter = 09650, loss = 12.3405
2024-10-29 11:58:00: [2024-10-29 11:58:00] iter = 09660, loss = 12.9418
2024-10-29 11:58:01: [2024-10-29 11:58:01] iter = 09670, loss = 10.1739
2024-10-29 11:58:01: [2024-10-29 11:58:01] iter = 09680, loss = 5.0504
2024-10-29 11:58:02: [2024-10-29 11:58:02] iter = 09690, loss = 19.4886
2024-10-29 11:58:02: [2024-10-29 11:58:02] iter = 09700, loss = 2.9954
2024-10-29 11:58:03: [2024-10-29 11:58:03] iter = 09710, loss = 2.5967
2024-10-29 11:58:03: [2024-10-29 11:58:03] iter = 09720, loss = 5.2297
2024-10-29 11:58:03: [2024-10-29 11:58:03] iter = 09730, loss = 7.3263
2024-10-29 11:58:04: [2024-10-29 11:58:04] iter = 09740, loss = 16.1517
2024-10-29 11:58:05: [2024-10-29 11:58:05] iter = 09750, loss = 6.4225
2024-10-29 11:58:05: [2024-10-29 11:58:05] iter = 09760, loss = 6.1143
2024-10-29 11:58:06: [2024-10-29 11:58:06] iter = 09770, loss = 3.9100
2024-10-29 11:58:06: [2024-10-29 11:58:06] iter = 09780, loss = 10.0863
2024-10-29 11:58:07: [2024-10-29 11:58:07] iter = 09790, loss = 4.8917
2024-10-29 11:58:07: [2024-10-29 11:58:07] iter = 09800, loss = 4.1278
2024-10-29 11:58:08: [2024-10-29 11:58:08] iter = 09810, loss = 8.1158
2024-10-29 11:58:08: [2024-10-29 11:58:08] iter = 09820, loss = 4.6776
2024-10-29 11:58:08: [2024-10-29 11:58:08] iter = 09830, loss = 14.4352
2024-10-29 11:58:09: [2024-10-29 11:58:09] iter = 09840, loss = 28.0882
2024-10-29 11:58:09: [2024-10-29 11:58:09] iter = 09850, loss = 21.7281
2024-10-29 11:58:10: [2024-10-29 11:58:10] iter = 09860, loss = 11.8188
2024-10-29 11:58:10: [2024-10-29 11:58:10] iter = 09870, loss = 4.3090
2024-10-29 11:58:11: [2024-10-29 11:58:11] iter = 09880, loss = 36.7794
2024-10-29 11:58:11: [2024-10-29 11:58:11] iter = 09890, loss = 13.4770
2024-10-29 11:58:12: [2024-10-29 11:58:12] iter = 09900, loss = 6.0548
2024-10-29 11:58:12: [2024-10-29 11:58:12] iter = 09910, loss = 6.8465
2024-10-29 11:58:13: [2024-10-29 11:58:13] iter = 09920, loss = 2.5695
2024-10-29 11:58:13: [2024-10-29 11:58:13] iter = 09930, loss = 2.5574
2024-10-29 11:58:13: [2024-10-29 11:58:13] iter = 09940, loss = 12.3162
2024-10-29 11:58:14: [2024-10-29 11:58:14] iter = 09950, loss = 6.7433
2024-10-29 11:58:14: [2024-10-29 11:58:14] iter = 09960, loss = 30.9441
2024-10-29 11:58:15: [2024-10-29 11:58:15] iter = 09970, loss = 2.7789
2024-10-29 11:58:15: [2024-10-29 11:58:15] iter = 09980, loss = 3.1001
2024-10-29 11:58:16: [2024-10-29 11:58:16] iter = 09990, loss = 3.9001
2024-10-29 11:58:16: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 11:58:16: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 11:58:16: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 96304}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:58:39: Evaluate 5 random ConvNet, ACCmean = 0.4412 ACCstd = 0.0079
-------------------------
2024-10-29 11:58:39: Evaluate 5 random ConvNet, SENmean = 0.4412 SENstd = 0.0079
-------------------------
2024-10-29 11:58:39: Evaluate 5 random ConvNet, SPEmean = 0.8137 SPEstd = 0.0026
-------------------------
2024-10-29 11:58:39: Evaluate 5 random ConvNet, F!mean = 0.3400 F!std = 0.0124
-------------------------
2024-10-29 11:58:39: Evaluate 5 random ConvNet, mean = 0.4412 std = 0.0079
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 11:58:39: [2024-10-29 11:58:39] iter = 10000, loss = 4.3404
2024-10-29 11:58:40: [2024-10-29 11:58:40] iter = 10010, loss = 11.6826
2024-10-29 11:58:40: [2024-10-29 11:58:40] iter = 10020, loss = 6.7709
2024-10-29 11:58:41: [2024-10-29 11:58:41] iter = 10030, loss = 7.3225
2024-10-29 11:58:41: [2024-10-29 11:58:41] iter = 10040, loss = 5.4825
2024-10-29 11:58:42: [2024-10-29 11:58:42] iter = 10050, loss = 18.5991
2024-10-29 11:58:42: [2024-10-29 11:58:42] iter = 10060, loss = 6.4865
2024-10-29 11:58:42: [2024-10-29 11:58:42] iter = 10070, loss = 9.3577
2024-10-29 11:58:43: [2024-10-29 11:58:43] iter = 10080, loss = 18.0824
2024-10-29 11:58:43: [2024-10-29 11:58:43] iter = 10090, loss = 42.7828
2024-10-29 11:58:44: [2024-10-29 11:58:44] iter = 10100, loss = 23.2630
2024-10-29 11:58:44: [2024-10-29 11:58:44] iter = 10110, loss = 10.2361
2024-10-29 11:58:45: [2024-10-29 11:58:45] iter = 10120, loss = 12.0701
2024-10-29 11:58:45: [2024-10-29 11:58:45] iter = 10130, loss = 4.4680
2024-10-29 11:58:45: [2024-10-29 11:58:45] iter = 10140, loss = 3.3721
2024-10-29 11:58:46: [2024-10-29 11:58:46] iter = 10150, loss = 3.6604
2024-10-29 11:58:46: [2024-10-29 11:58:46] iter = 10160, loss = 9.2072
2024-10-29 11:58:47: [2024-10-29 11:58:47] iter = 10170, loss = 14.3371
2024-10-29 11:58:47: [2024-10-29 11:58:47] iter = 10180, loss = 6.7104
2024-10-29 11:58:48: [2024-10-29 11:58:48] iter = 10190, loss = 3.3717
2024-10-29 11:58:48: [2024-10-29 11:58:48] iter = 10200, loss = 6.4536
2024-10-29 11:58:48: [2024-10-29 11:58:48] iter = 10210, loss = 11.3584
2024-10-29 11:58:49: [2024-10-29 11:58:49] iter = 10220, loss = 11.2259
2024-10-29 11:58:49: [2024-10-29 11:58:49] iter = 10230, loss = 38.0497
2024-10-29 11:58:50: [2024-10-29 11:58:50] iter = 10240, loss = 6.7686
2024-10-29 11:58:50: [2024-10-29 11:58:50] iter = 10250, loss = 4.2180
2024-10-29 11:58:51: [2024-10-29 11:58:51] iter = 10260, loss = 14.7719
2024-10-29 11:58:51: [2024-10-29 11:58:51] iter = 10270, loss = 25.1795
2024-10-29 11:58:52: [2024-10-29 11:58:52] iter = 10280, loss = 8.1340
2024-10-29 11:58:52: [2024-10-29 11:58:52] iter = 10290, loss = 6.7569
2024-10-29 11:58:53: [2024-10-29 11:58:53] iter = 10300, loss = 4.0468
2024-10-29 11:58:53: [2024-10-29 11:58:53] iter = 10310, loss = 2.7232
2024-10-29 11:58:53: [2024-10-29 11:58:53] iter = 10320, loss = 4.0988
2024-10-29 11:58:54: [2024-10-29 11:58:54] iter = 10330, loss = 9.2194
2024-10-29 11:58:54: [2024-10-29 11:58:54] iter = 10340, loss = 12.6801
2024-10-29 11:58:55: [2024-10-29 11:58:55] iter = 10350, loss = 5.6844
2024-10-29 11:58:55: [2024-10-29 11:58:55] iter = 10360, loss = 13.5222
2024-10-29 11:58:55: [2024-10-29 11:58:55] iter = 10370, loss = 24.1856
2024-10-29 11:58:56: [2024-10-29 11:58:56] iter = 10380, loss = 11.5056
2024-10-29 11:58:56: [2024-10-29 11:58:56] iter = 10390, loss = 6.0021
2024-10-29 11:58:57: [2024-10-29 11:58:57] iter = 10400, loss = 20.0207
2024-10-29 11:58:57: [2024-10-29 11:58:57] iter = 10410, loss = 3.5606
2024-10-29 11:58:58: [2024-10-29 11:58:58] iter = 10420, loss = 3.6750
2024-10-29 11:58:58: [2024-10-29 11:58:58] iter = 10430, loss = 11.7577
2024-10-29 11:58:59: [2024-10-29 11:58:59] iter = 10440, loss = 3.8357
2024-10-29 11:58:59: [2024-10-29 11:58:59] iter = 10450, loss = 1.8323
2024-10-29 11:58:59: [2024-10-29 11:58:59] iter = 10460, loss = 29.9376
2024-10-29 11:59:00: [2024-10-29 11:59:00] iter = 10470, loss = 13.7693
2024-10-29 11:59:00: [2024-10-29 11:59:00] iter = 10480, loss = 3.7191
2024-10-29 11:59:01: [2024-10-29 11:59:01] iter = 10490, loss = 8.4895
2024-10-29 11:59:01: [2024-10-29 11:59:01] iter = 10500, loss = 13.2605
2024-10-29 11:59:02: [2024-10-29 11:59:02] iter = 10510, loss = 9.5087
2024-10-29 11:59:03: [2024-10-29 11:59:03] iter = 10520, loss = 26.3293
2024-10-29 11:59:03: [2024-10-29 11:59:03] iter = 10530, loss = 3.5911
2024-10-29 11:59:03: [2024-10-29 11:59:03] iter = 10540, loss = 2.9518
2024-10-29 11:59:04: [2024-10-29 11:59:04] iter = 10550, loss = 2.9708
2024-10-29 11:59:05: [2024-10-29 11:59:05] iter = 10560, loss = 6.8354
2024-10-29 11:59:05: [2024-10-29 11:59:05] iter = 10570, loss = 5.4754
2024-10-29 11:59:06: [2024-10-29 11:59:06] iter = 10580, loss = 8.2220
2024-10-29 11:59:06: [2024-10-29 11:59:06] iter = 10590, loss = 6.1581
2024-10-29 11:59:07: [2024-10-29 11:59:07] iter = 10600, loss = 4.2255
2024-10-29 11:59:07: [2024-10-29 11:59:07] iter = 10610, loss = 3.0667
2024-10-29 11:59:07: [2024-10-29 11:59:07] iter = 10620, loss = 25.1161
2024-10-29 11:59:08: [2024-10-29 11:59:08] iter = 10630, loss = 20.0028
2024-10-29 11:59:08: [2024-10-29 11:59:08] iter = 10640, loss = 8.2235
2024-10-29 11:59:08: [2024-10-29 11:59:08] iter = 10650, loss = 5.4978
2024-10-29 11:59:09: [2024-10-29 11:59:09] iter = 10660, loss = 7.1349
2024-10-29 11:59:09: [2024-10-29 11:59:09] iter = 10670, loss = 6.3537
2024-10-29 11:59:10: [2024-10-29 11:59:10] iter = 10680, loss = 7.0357
2024-10-29 11:59:10: [2024-10-29 11:59:10] iter = 10690, loss = 8.1606
2024-10-29 11:59:11: [2024-10-29 11:59:11] iter = 10700, loss = 10.1697
2024-10-29 11:59:11: [2024-10-29 11:59:11] iter = 10710, loss = 2.5648
2024-10-29 11:59:12: [2024-10-29 11:59:12] iter = 10720, loss = 4.8467
2024-10-29 11:59:12: [2024-10-29 11:59:12] iter = 10730, loss = 8.6184
2024-10-29 11:59:13: [2024-10-29 11:59:13] iter = 10740, loss = 3.6423
2024-10-29 11:59:13: [2024-10-29 11:59:13] iter = 10750, loss = 4.8368
2024-10-29 11:59:13: [2024-10-29 11:59:13] iter = 10760, loss = 2.9691
2024-10-29 11:59:14: [2024-10-29 11:59:14] iter = 10770, loss = 8.3192
2024-10-29 11:59:14: [2024-10-29 11:59:14] iter = 10780, loss = 4.8565
2024-10-29 11:59:14: [2024-10-29 11:59:14] iter = 10790, loss = 19.6699
2024-10-29 11:59:15: [2024-10-29 11:59:15] iter = 10800, loss = 16.6822
2024-10-29 11:59:15: [2024-10-29 11:59:15] iter = 10810, loss = 3.5789
2024-10-29 11:59:16: [2024-10-29 11:59:16] iter = 10820, loss = 1.8010
2024-10-29 11:59:16: [2024-10-29 11:59:16] iter = 10830, loss = 2.1048
2024-10-29 11:59:16: [2024-10-29 11:59:16] iter = 10840, loss = 3.6844
2024-10-29 11:59:17: [2024-10-29 11:59:17] iter = 10850, loss = 16.9881
2024-10-29 11:59:17: [2024-10-29 11:59:17] iter = 10860, loss = 38.5457
2024-10-29 11:59:18: [2024-10-29 11:59:18] iter = 10870, loss = 61.1135
2024-10-29 11:59:18: [2024-10-29 11:59:18] iter = 10880, loss = 39.0810
2024-10-29 11:59:19: [2024-10-29 11:59:19] iter = 10890, loss = 11.0886
2024-10-29 11:59:19: [2024-10-29 11:59:19] iter = 10900, loss = 4.2387
2024-10-29 11:59:20: [2024-10-29 11:59:20] iter = 10910, loss = 20.1098
2024-10-29 11:59:20: [2024-10-29 11:59:20] iter = 10920, loss = 49.8683
2024-10-29 11:59:21: [2024-10-29 11:59:21] iter = 10930, loss = 21.1743
2024-10-29 11:59:21: [2024-10-29 11:59:21] iter = 10940, loss = 7.1189
2024-10-29 11:59:21: [2024-10-29 11:59:21] iter = 10950, loss = 4.5515
2024-10-29 11:59:22: [2024-10-29 11:59:22] iter = 10960, loss = 7.2021
2024-10-29 11:59:22: [2024-10-29 11:59:22] iter = 10970, loss = 13.1991
2024-10-29 11:59:23: [2024-10-29 11:59:23] iter = 10980, loss = 8.7847
2024-10-29 11:59:23: [2024-10-29 11:59:23] iter = 10990, loss = 40.5117
2024-10-29 11:59:24: [2024-10-29 11:59:24] iter = 11000, loss = 15.5481
2024-10-29 11:59:24: [2024-10-29 11:59:24] iter = 11010, loss = 3.6186
2024-10-29 11:59:24: [2024-10-29 11:59:24] iter = 11020, loss = 15.6394
2024-10-29 11:59:25: [2024-10-29 11:59:25] iter = 11030, loss = 6.8011
2024-10-29 11:59:25: [2024-10-29 11:59:25] iter = 11040, loss = 16.0650
2024-10-29 11:59:26: [2024-10-29 11:59:26] iter = 11050, loss = 4.8931
2024-10-29 11:59:26: [2024-10-29 11:59:26] iter = 11060, loss = 7.1359
2024-10-29 11:59:27: [2024-10-29 11:59:27] iter = 11070, loss = 6.7224
2024-10-29 11:59:27: [2024-10-29 11:59:27] iter = 11080, loss = 14.0093
2024-10-29 11:59:28: [2024-10-29 11:59:28] iter = 11090, loss = 12.9830
2024-10-29 11:59:28: [2024-10-29 11:59:28] iter = 11100, loss = 6.2033
2024-10-29 11:59:29: [2024-10-29 11:59:29] iter = 11110, loss = 7.2921
2024-10-29 11:59:29: [2024-10-29 11:59:29] iter = 11120, loss = 3.3890
2024-10-29 11:59:29: [2024-10-29 11:59:29] iter = 11130, loss = 35.5903
2024-10-29 11:59:30: [2024-10-29 11:59:30] iter = 11140, loss = 4.1989
2024-10-29 11:59:30: [2024-10-29 11:59:30] iter = 11150, loss = 32.4685
2024-10-29 11:59:31: [2024-10-29 11:59:31] iter = 11160, loss = 6.6221
2024-10-29 11:59:31: [2024-10-29 11:59:31] iter = 11170, loss = 22.9607
2024-10-29 11:59:32: [2024-10-29 11:59:32] iter = 11180, loss = 5.6174
2024-10-29 11:59:32: [2024-10-29 11:59:32] iter = 11190, loss = 23.0500
2024-10-29 11:59:33: [2024-10-29 11:59:33] iter = 11200, loss = 5.0971
2024-10-29 11:59:33: [2024-10-29 11:59:33] iter = 11210, loss = 4.7476
2024-10-29 11:59:34: [2024-10-29 11:59:34] iter = 11220, loss = 11.9726
2024-10-29 11:59:34: [2024-10-29 11:59:34] iter = 11230, loss = 2.8522
2024-10-29 11:59:34: [2024-10-29 11:59:34] iter = 11240, loss = 5.6287
2024-10-29 11:59:35: [2024-10-29 11:59:35] iter = 11250, loss = 3.4235
2024-10-29 11:59:35: [2024-10-29 11:59:35] iter = 11260, loss = 2.6592
2024-10-29 11:59:36: [2024-10-29 11:59:36] iter = 11270, loss = 7.9529
2024-10-29 11:59:36: [2024-10-29 11:59:36] iter = 11280, loss = 29.5698
2024-10-29 11:59:37: [2024-10-29 11:59:37] iter = 11290, loss = 37.4970
2024-10-29 11:59:37: [2024-10-29 11:59:37] iter = 11300, loss = 4.5524
2024-10-29 11:59:37: [2024-10-29 11:59:37] iter = 11310, loss = 3.9124
2024-10-29 11:59:38: [2024-10-29 11:59:38] iter = 11320, loss = 4.1133
2024-10-29 11:59:38: [2024-10-29 11:59:38] iter = 11330, loss = 4.5780
2024-10-29 11:59:38: [2024-10-29 11:59:38] iter = 11340, loss = 7.4175
2024-10-29 11:59:39: [2024-10-29 11:59:39] iter = 11350, loss = 6.9960
2024-10-29 11:59:39: [2024-10-29 11:59:39] iter = 11360, loss = 10.7367
2024-10-29 11:59:39: [2024-10-29 11:59:39] iter = 11370, loss = 10.0295
2024-10-29 11:59:40: [2024-10-29 11:59:40] iter = 11380, loss = 3.2164
2024-10-29 11:59:40: [2024-10-29 11:59:40] iter = 11390, loss = 19.6286
2024-10-29 11:59:40: [2024-10-29 11:59:40] iter = 11400, loss = 9.5768
2024-10-29 11:59:41: [2024-10-29 11:59:41] iter = 11410, loss = 7.5081
2024-10-29 11:59:41: [2024-10-29 11:59:41] iter = 11420, loss = 2.6695
2024-10-29 11:59:42: [2024-10-29 11:59:42] iter = 11430, loss = 4.1475
2024-10-29 11:59:42: [2024-10-29 11:59:42] iter = 11440, loss = 5.2114
2024-10-29 11:59:43: [2024-10-29 11:59:43] iter = 11450, loss = 46.3725
2024-10-29 11:59:43: [2024-10-29 11:59:43] iter = 11460, loss = 26.2346
2024-10-29 11:59:43: [2024-10-29 11:59:43] iter = 11470, loss = 9.8451
2024-10-29 11:59:44: [2024-10-29 11:59:44] iter = 11480, loss = 10.5307
2024-10-29 11:59:44: [2024-10-29 11:59:44] iter = 11490, loss = 4.7447
2024-10-29 11:59:44: [2024-10-29 11:59:44] iter = 11500, loss = 7.5607
2024-10-29 11:59:45: [2024-10-29 11:59:45] iter = 11510, loss = 53.7458
2024-10-29 11:59:45: [2024-10-29 11:59:45] iter = 11520, loss = 3.4615
2024-10-29 11:59:46: [2024-10-29 11:59:46] iter = 11530, loss = 3.6691
2024-10-29 11:59:46: [2024-10-29 11:59:46] iter = 11540, loss = 8.9535
2024-10-29 11:59:47: [2024-10-29 11:59:47] iter = 11550, loss = 8.0722
2024-10-29 11:59:47: [2024-10-29 11:59:47] iter = 11560, loss = 4.1642
2024-10-29 11:59:47: [2024-10-29 11:59:47] iter = 11570, loss = 7.1999
2024-10-29 11:59:48: [2024-10-29 11:59:48] iter = 11580, loss = 3.5509
2024-10-29 11:59:48: [2024-10-29 11:59:48] iter = 11590, loss = 3.2297
2024-10-29 11:59:49: [2024-10-29 11:59:49] iter = 11600, loss = 3.1055
2024-10-29 11:59:49: [2024-10-29 11:59:49] iter = 11610, loss = 3.8320
2024-10-29 11:59:49: [2024-10-29 11:59:49] iter = 11620, loss = 16.4962
2024-10-29 11:59:50: [2024-10-29 11:59:50] iter = 11630, loss = 5.0294
2024-10-29 11:59:50: [2024-10-29 11:59:50] iter = 11640, loss = 3.6963
2024-10-29 11:59:51: [2024-10-29 11:59:51] iter = 11650, loss = 9.8509
2024-10-29 11:59:51: [2024-10-29 11:59:51] iter = 11660, loss = 15.7267
2024-10-29 11:59:51: [2024-10-29 11:59:51] iter = 11670, loss = 6.6297
2024-10-29 11:59:52: [2024-10-29 11:59:52] iter = 11680, loss = 5.2790
2024-10-29 11:59:52: [2024-10-29 11:59:52] iter = 11690, loss = 4.3730
2024-10-29 11:59:53: [2024-10-29 11:59:53] iter = 11700, loss = 21.4908
2024-10-29 11:59:53: [2024-10-29 11:59:53] iter = 11710, loss = 12.3762
2024-10-29 11:59:54: [2024-10-29 11:59:54] iter = 11720, loss = 5.9721
2024-10-29 11:59:54: [2024-10-29 11:59:54] iter = 11730, loss = 8.3045
2024-10-29 11:59:55: [2024-10-29 11:59:55] iter = 11740, loss = 7.2159
2024-10-29 11:59:55: [2024-10-29 11:59:55] iter = 11750, loss = 8.1256
2024-10-29 11:59:56: [2024-10-29 11:59:56] iter = 11760, loss = 3.3245
2024-10-29 11:59:56: [2024-10-29 11:59:56] iter = 11770, loss = 3.4025
2024-10-29 11:59:56: [2024-10-29 11:59:56] iter = 11780, loss = 8.7513
2024-10-29 11:59:57: [2024-10-29 11:59:57] iter = 11790, loss = 3.8131
2024-10-29 11:59:57: [2024-10-29 11:59:57] iter = 11800, loss = 17.8655
2024-10-29 11:59:58: [2024-10-29 11:59:58] iter = 11810, loss = 14.8377
2024-10-29 11:59:58: [2024-10-29 11:59:58] iter = 11820, loss = 5.8661
2024-10-29 11:59:59: [2024-10-29 11:59:59] iter = 11830, loss = 11.8497
2024-10-29 11:59:59: [2024-10-29 11:59:59] iter = 11840, loss = 25.3054
2024-10-29 12:00:00: [2024-10-29 12:00:00] iter = 11850, loss = 15.2049
2024-10-29 12:00:00: [2024-10-29 12:00:00] iter = 11860, loss = 4.9018
2024-10-29 12:00:01: [2024-10-29 12:00:01] iter = 11870, loss = 3.3839
2024-10-29 12:00:01: [2024-10-29 12:00:01] iter = 11880, loss = 5.2282
2024-10-29 12:00:01: [2024-10-29 12:00:01] iter = 11890, loss = 5.9979
2024-10-29 12:00:02: [2024-10-29 12:00:02] iter = 11900, loss = 4.3677
2024-10-29 12:00:02: [2024-10-29 12:00:02] iter = 11910, loss = 4.5722
2024-10-29 12:00:03: [2024-10-29 12:00:03] iter = 11920, loss = 10.7526
2024-10-29 12:00:03: [2024-10-29 12:00:03] iter = 11930, loss = 27.2296
2024-10-29 12:00:04: [2024-10-29 12:00:04] iter = 11940, loss = 5.7652
2024-10-29 12:00:04: [2024-10-29 12:00:04] iter = 11950, loss = 10.1352
2024-10-29 12:00:04: [2024-10-29 12:00:04] iter = 11960, loss = 22.4301
2024-10-29 12:00:05: [2024-10-29 12:00:05] iter = 11970, loss = 5.4481
2024-10-29 12:00:05: [2024-10-29 12:00:05] iter = 11980, loss = 9.3356
2024-10-29 12:00:06: [2024-10-29 12:00:06] iter = 11990, loss = 6.4691
2024-10-29 12:00:06: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 12:00:06: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:00:06: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 6625}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:00:31: Evaluate 5 random ConvNet, ACCmean = 0.4484 ACCstd = 0.0084
-------------------------
2024-10-29 12:00:31: Evaluate 5 random ConvNet, SENmean = 0.4484 SENstd = 0.0084
-------------------------
2024-10-29 12:00:31: Evaluate 5 random ConvNet, SPEmean = 0.8161 SPEstd = 0.0028
-------------------------
2024-10-29 12:00:31: Evaluate 5 random ConvNet, F!mean = 0.3945 F!std = 0.0084
-------------------------
2024-10-29 12:00:31: Evaluate 5 random ConvNet, mean = 0.4484 std = 0.0084
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:00:31: [2024-10-29 12:00:31] iter = 12000, loss = 4.8482
2024-10-29 12:00:31: [2024-10-29 12:00:31] iter = 12010, loss = 5.5262
2024-10-29 12:00:32: [2024-10-29 12:00:32] iter = 12020, loss = 16.5354
2024-10-29 12:00:32: [2024-10-29 12:00:32] iter = 12030, loss = 4.6489
2024-10-29 12:00:33: [2024-10-29 12:00:33] iter = 12040, loss = 4.7368
2024-10-29 12:00:33: [2024-10-29 12:00:33] iter = 12050, loss = 19.0188
2024-10-29 12:00:33: [2024-10-29 12:00:33] iter = 12060, loss = 11.3791
2024-10-29 12:00:34: [2024-10-29 12:00:34] iter = 12070, loss = 11.3345
2024-10-29 12:00:34: [2024-10-29 12:00:34] iter = 12080, loss = 4.6178
2024-10-29 12:00:34: [2024-10-29 12:00:34] iter = 12090, loss = 3.6160
2024-10-29 12:00:35: [2024-10-29 12:00:35] iter = 12100, loss = 9.5133
2024-10-29 12:00:35: [2024-10-29 12:00:35] iter = 12110, loss = 14.7886
2024-10-29 12:00:36: [2024-10-29 12:00:36] iter = 12120, loss = 2.8621
2024-10-29 12:00:36: [2024-10-29 12:00:36] iter = 12130, loss = 3.3748
2024-10-29 12:00:37: [2024-10-29 12:00:37] iter = 12140, loss = 2.9661
2024-10-29 12:00:37: [2024-10-29 12:00:37] iter = 12150, loss = 3.3215
2024-10-29 12:00:38: [2024-10-29 12:00:38] iter = 12160, loss = 2.1934
2024-10-29 12:00:38: [2024-10-29 12:00:38] iter = 12170, loss = 2.3069
2024-10-29 12:00:39: [2024-10-29 12:00:39] iter = 12180, loss = 4.4775
2024-10-29 12:00:39: [2024-10-29 12:00:39] iter = 12190, loss = 4.3681
2024-10-29 12:00:40: [2024-10-29 12:00:40] iter = 12200, loss = 7.0425
2024-10-29 12:00:41: [2024-10-29 12:00:41] iter = 12210, loss = 9.0793
2024-10-29 12:00:41: [2024-10-29 12:00:41] iter = 12220, loss = 12.5727
2024-10-29 12:00:42: [2024-10-29 12:00:42] iter = 12230, loss = 39.3198
2024-10-29 12:00:42: [2024-10-29 12:00:42] iter = 12240, loss = 10.2800
2024-10-29 12:00:43: [2024-10-29 12:00:43] iter = 12250, loss = 3.5486
2024-10-29 12:00:43: [2024-10-29 12:00:43] iter = 12260, loss = 12.9191
2024-10-29 12:00:43: [2024-10-29 12:00:43] iter = 12270, loss = 5.1018
2024-10-29 12:00:44: [2024-10-29 12:00:44] iter = 12280, loss = 12.1848
2024-10-29 12:00:44: [2024-10-29 12:00:44] iter = 12290, loss = 3.6972
2024-10-29 12:00:45: [2024-10-29 12:00:45] iter = 12300, loss = 3.1255
2024-10-29 12:00:45: [2024-10-29 12:00:45] iter = 12310, loss = 3.6513
2024-10-29 12:00:45: [2024-10-29 12:00:45] iter = 12320, loss = 7.6575
2024-10-29 12:00:46: [2024-10-29 12:00:46] iter = 12330, loss = 3.0138
2024-10-29 12:00:46: [2024-10-29 12:00:46] iter = 12340, loss = 32.8532
2024-10-29 12:00:47: [2024-10-29 12:00:47] iter = 12350, loss = 18.3938
2024-10-29 12:00:47: [2024-10-29 12:00:47] iter = 12360, loss = 3.4696
2024-10-29 12:00:47: [2024-10-29 12:00:47] iter = 12370, loss = 15.0741
2024-10-29 12:00:48: [2024-10-29 12:00:48] iter = 12380, loss = 4.6247
2024-10-29 12:00:48: [2024-10-29 12:00:48] iter = 12390, loss = 16.2833
2024-10-29 12:00:49: [2024-10-29 12:00:49] iter = 12400, loss = 4.1302
2024-10-29 12:00:49: [2024-10-29 12:00:49] iter = 12410, loss = 3.2337
2024-10-29 12:00:50: [2024-10-29 12:00:50] iter = 12420, loss = 2.4675
2024-10-29 12:00:50: [2024-10-29 12:00:50] iter = 12430, loss = 3.2521
2024-10-29 12:00:51: [2024-10-29 12:00:51] iter = 12440, loss = 5.0086
2024-10-29 12:00:51: [2024-10-29 12:00:51] iter = 12450, loss = 2.7194
2024-10-29 12:00:51: [2024-10-29 12:00:51] iter = 12460, loss = 8.9729
2024-10-29 12:00:52: [2024-10-29 12:00:52] iter = 12470, loss = 67.8168
2024-10-29 12:00:52: [2024-10-29 12:00:52] iter = 12480, loss = 4.3309
2024-10-29 12:00:53: [2024-10-29 12:00:53] iter = 12490, loss = 3.0112
2024-10-29 12:00:53: [2024-10-29 12:00:53] iter = 12500, loss = 6.5729
2024-10-29 12:00:53: [2024-10-29 12:00:53] iter = 12510, loss = 2.7342
2024-10-29 12:00:54: [2024-10-29 12:00:54] iter = 12520, loss = 14.2786
2024-10-29 12:00:54: [2024-10-29 12:00:54] iter = 12530, loss = 2.9554
2024-10-29 12:00:55: [2024-10-29 12:00:55] iter = 12540, loss = 3.6649
2024-10-29 12:00:55: [2024-10-29 12:00:55] iter = 12550, loss = 2.5640
2024-10-29 12:00:56: [2024-10-29 12:00:56] iter = 12560, loss = 2.1700
2024-10-29 12:00:56: [2024-10-29 12:00:56] iter = 12570, loss = 3.2872
2024-10-29 12:00:56: [2024-10-29 12:00:56] iter = 12580, loss = 26.2546
2024-10-29 12:00:57: [2024-10-29 12:00:57] iter = 12590, loss = 9.2333
2024-10-29 12:00:57: [2024-10-29 12:00:57] iter = 12600, loss = 1.9778
2024-10-29 12:00:58: [2024-10-29 12:00:58] iter = 12610, loss = 6.3861
2024-10-29 12:00:58: [2024-10-29 12:00:58] iter = 12620, loss = 9.8665
2024-10-29 12:00:59: [2024-10-29 12:00:59] iter = 12630, loss = 30.2466
2024-10-29 12:00:59: [2024-10-29 12:00:59] iter = 12640, loss = 3.7020
2024-10-29 12:00:59: [2024-10-29 12:00:59] iter = 12650, loss = 14.5444
2024-10-29 12:01:00: [2024-10-29 12:01:00] iter = 12660, loss = 4.7975
2024-10-29 12:01:00: [2024-10-29 12:01:00] iter = 12670, loss = 6.0484
2024-10-29 12:01:01: [2024-10-29 12:01:01] iter = 12680, loss = 7.5326
2024-10-29 12:01:01: [2024-10-29 12:01:01] iter = 12690, loss = 31.5321
2024-10-29 12:01:02: [2024-10-29 12:01:02] iter = 12700, loss = 4.9337
2024-10-29 12:01:02: [2024-10-29 12:01:02] iter = 12710, loss = 4.4308
2024-10-29 12:01:03: [2024-10-29 12:01:03] iter = 12720, loss = 4.7000
2024-10-29 12:01:03: [2024-10-29 12:01:03] iter = 12730, loss = 9.3970
2024-10-29 12:01:03: [2024-10-29 12:01:03] iter = 12740, loss = 36.0590
2024-10-29 12:01:04: [2024-10-29 12:01:04] iter = 12750, loss = 20.9655
2024-10-29 12:01:04: [2024-10-29 12:01:04] iter = 12760, loss = 16.4985
2024-10-29 12:01:05: [2024-10-29 12:01:05] iter = 12770, loss = 4.3101
2024-10-29 12:01:05: [2024-10-29 12:01:05] iter = 12780, loss = 3.9050
2024-10-29 12:01:06: [2024-10-29 12:01:06] iter = 12790, loss = 4.5349
2024-10-29 12:01:06: [2024-10-29 12:01:06] iter = 12800, loss = 2.4799
2024-10-29 12:01:06: [2024-10-29 12:01:06] iter = 12810, loss = 3.7376
2024-10-29 12:01:07: [2024-10-29 12:01:07] iter = 12820, loss = 20.9116
2024-10-29 12:01:07: [2024-10-29 12:01:07] iter = 12830, loss = 47.7460
2024-10-29 12:01:08: [2024-10-29 12:01:08] iter = 12840, loss = 13.2760
2024-10-29 12:01:08: [2024-10-29 12:01:08] iter = 12850, loss = 8.5045
2024-10-29 12:01:09: [2024-10-29 12:01:09] iter = 12860, loss = 3.2563
2024-10-29 12:01:09: [2024-10-29 12:01:09] iter = 12870, loss = 5.7284
2024-10-29 12:01:09: [2024-10-29 12:01:09] iter = 12880, loss = 2.4932
2024-10-29 12:01:10: [2024-10-29 12:01:10] iter = 12890, loss = 3.3035
2024-10-29 12:01:10: [2024-10-29 12:01:10] iter = 12900, loss = 4.3580
2024-10-29 12:01:11: [2024-10-29 12:01:11] iter = 12910, loss = 26.9769
2024-10-29 12:01:11: [2024-10-29 12:01:11] iter = 12920, loss = 10.6507
2024-10-29 12:01:11: [2024-10-29 12:01:11] iter = 12930, loss = 6.1573
2024-10-29 12:01:12: [2024-10-29 12:01:12] iter = 12940, loss = 49.4315
2024-10-29 12:01:12: [2024-10-29 12:01:12] iter = 12950, loss = 5.6885
2024-10-29 12:01:13: [2024-10-29 12:01:13] iter = 12960, loss = 4.1568
2024-10-29 12:01:13: [2024-10-29 12:01:13] iter = 12970, loss = 23.9039
2024-10-29 12:01:14: [2024-10-29 12:01:14] iter = 12980, loss = 3.4156
2024-10-29 12:01:14: [2024-10-29 12:01:14] iter = 12990, loss = 27.1247
2024-10-29 12:01:15: [2024-10-29 12:01:15] iter = 13000, loss = 19.0989
2024-10-29 12:01:15: [2024-10-29 12:01:15] iter = 13010, loss = 2.9806
2024-10-29 12:01:16: [2024-10-29 12:01:16] iter = 13020, loss = 10.7913
2024-10-29 12:01:16: [2024-10-29 12:01:16] iter = 13030, loss = 9.8356
2024-10-29 12:01:17: [2024-10-29 12:01:17] iter = 13040, loss = 4.0912
2024-10-29 12:01:17: [2024-10-29 12:01:17] iter = 13050, loss = 4.8759
2024-10-29 12:01:18: [2024-10-29 12:01:18] iter = 13060, loss = 9.0727
2024-10-29 12:01:18: [2024-10-29 12:01:18] iter = 13070, loss = 4.4594
2024-10-29 12:01:19: [2024-10-29 12:01:19] iter = 13080, loss = 54.6179
2024-10-29 12:01:19: [2024-10-29 12:01:19] iter = 13090, loss = 3.7382
2024-10-29 12:01:20: [2024-10-29 12:01:20] iter = 13100, loss = 97.8471
2024-10-29 12:01:20: [2024-10-29 12:01:20] iter = 13110, loss = 5.4991
2024-10-29 12:01:21: [2024-10-29 12:01:21] iter = 13120, loss = 9.7250
2024-10-29 12:01:22: [2024-10-29 12:01:22] iter = 13130, loss = 22.8659
2024-10-29 12:01:22: [2024-10-29 12:01:22] iter = 13140, loss = 21.1985
2024-10-29 12:01:23: [2024-10-29 12:01:23] iter = 13150, loss = 3.5567
2024-10-29 12:01:23: [2024-10-29 12:01:23] iter = 13160, loss = 11.1808
2024-10-29 12:01:24: [2024-10-29 12:01:24] iter = 13170, loss = 5.6924
2024-10-29 12:01:24: [2024-10-29 12:01:24] iter = 13180, loss = 6.2915
2024-10-29 12:01:25: [2024-10-29 12:01:25] iter = 13190, loss = 14.4354
2024-10-29 12:01:25: [2024-10-29 12:01:25] iter = 13200, loss = 25.1061
2024-10-29 12:01:25: [2024-10-29 12:01:25] iter = 13210, loss = 31.9192
2024-10-29 12:01:26: [2024-10-29 12:01:26] iter = 13220, loss = 3.8714
2024-10-29 12:01:26: [2024-10-29 12:01:26] iter = 13230, loss = 2.8030
2024-10-29 12:01:27: [2024-10-29 12:01:27] iter = 13240, loss = 6.7504
2024-10-29 12:01:27: [2024-10-29 12:01:27] iter = 13250, loss = 9.3632
2024-10-29 12:01:28: [2024-10-29 12:01:28] iter = 13260, loss = 9.8586
2024-10-29 12:01:28: [2024-10-29 12:01:28] iter = 13270, loss = 2.8046
2024-10-29 12:01:29: [2024-10-29 12:01:29] iter = 13280, loss = 3.2074
2024-10-29 12:01:29: [2024-10-29 12:01:29] iter = 13290, loss = 3.2158
2024-10-29 12:01:30: [2024-10-29 12:01:30] iter = 13300, loss = 13.7449
2024-10-29 12:01:30: [2024-10-29 12:01:30] iter = 13310, loss = 5.5003
2024-10-29 12:01:31: [2024-10-29 12:01:31] iter = 13320, loss = 2.8122
2024-10-29 12:01:31: [2024-10-29 12:01:31] iter = 13330, loss = 8.5616
2024-10-29 12:01:31: [2024-10-29 12:01:31] iter = 13340, loss = 5.3309
2024-10-29 12:01:32: [2024-10-29 12:01:32] iter = 13350, loss = 2.8919
2024-10-29 12:01:32: [2024-10-29 12:01:32] iter = 13360, loss = 3.4033
2024-10-29 12:01:33: [2024-10-29 12:01:33] iter = 13370, loss = 4.4508
2024-10-29 12:01:33: [2024-10-29 12:01:33] iter = 13380, loss = 4.2593
2024-10-29 12:01:33: [2024-10-29 12:01:33] iter = 13390, loss = 7.9369
2024-10-29 12:01:34: [2024-10-29 12:01:34] iter = 13400, loss = 41.4280
2024-10-29 12:01:34: [2024-10-29 12:01:34] iter = 13410, loss = 3.5336
2024-10-29 12:01:35: [2024-10-29 12:01:35] iter = 13420, loss = 18.4381
2024-10-29 12:01:35: [2024-10-29 12:01:35] iter = 13430, loss = 3.6034
2024-10-29 12:01:36: [2024-10-29 12:01:36] iter = 13440, loss = 3.4400
2024-10-29 12:01:36: [2024-10-29 12:01:36] iter = 13450, loss = 41.6085
2024-10-29 12:01:37: [2024-10-29 12:01:37] iter = 13460, loss = 3.1014
2024-10-29 12:01:37: [2024-10-29 12:01:37] iter = 13470, loss = 13.8295
2024-10-29 12:01:37: [2024-10-29 12:01:37] iter = 13480, loss = 7.1326
2024-10-29 12:01:38: [2024-10-29 12:01:38] iter = 13490, loss = 5.8380
2024-10-29 12:01:38: [2024-10-29 12:01:38] iter = 13500, loss = 3.5697
2024-10-29 12:01:39: [2024-10-29 12:01:39] iter = 13510, loss = 3.8800
2024-10-29 12:01:39: [2024-10-29 12:01:39] iter = 13520, loss = 3.8203
2024-10-29 12:01:40: [2024-10-29 12:01:40] iter = 13530, loss = 3.2300
2024-10-29 12:01:40: [2024-10-29 12:01:40] iter = 13540, loss = 13.4154
2024-10-29 12:01:40: [2024-10-29 12:01:40] iter = 13550, loss = 10.7326
2024-10-29 12:01:41: [2024-10-29 12:01:41] iter = 13560, loss = 25.1402
2024-10-29 12:01:41: [2024-10-29 12:01:41] iter = 13570, loss = 18.7935
2024-10-29 12:01:42: [2024-10-29 12:01:42] iter = 13580, loss = 27.2503
2024-10-29 12:01:42: [2024-10-29 12:01:42] iter = 13590, loss = 5.9210
2024-10-29 12:01:43: [2024-10-29 12:01:43] iter = 13600, loss = 10.4535
2024-10-29 12:01:43: [2024-10-29 12:01:43] iter = 13610, loss = 8.4138
2024-10-29 12:01:43: [2024-10-29 12:01:43] iter = 13620, loss = 5.6952
2024-10-29 12:01:44: [2024-10-29 12:01:44] iter = 13630, loss = 12.8973
2024-10-29 12:01:44: [2024-10-29 12:01:44] iter = 13640, loss = 6.0411
2024-10-29 12:01:45: [2024-10-29 12:01:45] iter = 13650, loss = 28.8626
2024-10-29 12:01:45: [2024-10-29 12:01:45] iter = 13660, loss = 3.7038
2024-10-29 12:01:46: [2024-10-29 12:01:46] iter = 13670, loss = 6.3180
2024-10-29 12:01:46: [2024-10-29 12:01:46] iter = 13680, loss = 6.5838
2024-10-29 12:01:47: [2024-10-29 12:01:47] iter = 13690, loss = 4.3898
2024-10-29 12:01:47: [2024-10-29 12:01:47] iter = 13700, loss = 7.1427
2024-10-29 12:01:47: [2024-10-29 12:01:47] iter = 13710, loss = 58.5270
2024-10-29 12:01:48: [2024-10-29 12:01:48] iter = 13720, loss = 7.3484
2024-10-29 12:01:48: [2024-10-29 12:01:48] iter = 13730, loss = 6.0270
2024-10-29 12:01:49: [2024-10-29 12:01:49] iter = 13740, loss = 5.2895
2024-10-29 12:01:49: [2024-10-29 12:01:49] iter = 13750, loss = 6.3191
2024-10-29 12:01:49: [2024-10-29 12:01:49] iter = 13760, loss = 5.7766
2024-10-29 12:01:50: [2024-10-29 12:01:50] iter = 13770, loss = 3.1171
2024-10-29 12:01:50: [2024-10-29 12:01:50] iter = 13780, loss = 51.4919
2024-10-29 12:01:51: [2024-10-29 12:01:51] iter = 13790, loss = 18.6140
2024-10-29 12:01:51: [2024-10-29 12:01:51] iter = 13800, loss = 41.9594
2024-10-29 12:01:52: [2024-10-29 12:01:52] iter = 13810, loss = 2.7301
2024-10-29 12:01:52: [2024-10-29 12:01:52] iter = 13820, loss = 53.7846
2024-10-29 12:01:52: [2024-10-29 12:01:52] iter = 13830, loss = 8.2449
2024-10-29 12:01:53: [2024-10-29 12:01:53] iter = 13840, loss = 9.2943
2024-10-29 12:01:53: [2024-10-29 12:01:53] iter = 13850, loss = 5.9637
2024-10-29 12:01:54: [2024-10-29 12:01:54] iter = 13860, loss = 48.3051
2024-10-29 12:01:54: [2024-10-29 12:01:54] iter = 13870, loss = 39.8492
2024-10-29 12:01:55: [2024-10-29 12:01:55] iter = 13880, loss = 6.9536
2024-10-29 12:01:55: [2024-10-29 12:01:55] iter = 13890, loss = 3.8916
2024-10-29 12:01:55: [2024-10-29 12:01:55] iter = 13900, loss = 4.3447
2024-10-29 12:01:56: [2024-10-29 12:01:56] iter = 13910, loss = 9.6455
2024-10-29 12:01:56: [2024-10-29 12:01:56] iter = 13920, loss = 9.1567
2024-10-29 12:01:57: [2024-10-29 12:01:57] iter = 13930, loss = 8.3334
2024-10-29 12:01:57: [2024-10-29 12:01:57] iter = 13940, loss = 8.9290
2024-10-29 12:01:57: [2024-10-29 12:01:57] iter = 13950, loss = 9.4420
2024-10-29 12:01:58: [2024-10-29 12:01:58] iter = 13960, loss = 3.0092
2024-10-29 12:01:58: [2024-10-29 12:01:58] iter = 13970, loss = 12.8986
2024-10-29 12:01:58: [2024-10-29 12:01:58] iter = 13980, loss = 5.3489
2024-10-29 12:01:59: [2024-10-29 12:01:59] iter = 13990, loss = 6.3842
2024-10-29 12:01:59: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 12:01:59: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:01:59: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 19488}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:02:23: Evaluate 5 random ConvNet, ACCmean = 0.4408 ACCstd = 0.0143
-------------------------
2024-10-29 12:02:23: Evaluate 5 random ConvNet, SENmean = 0.4408 SENstd = 0.0143
-------------------------
2024-10-29 12:02:23: Evaluate 5 random ConvNet, SPEmean = 0.8136 SPEstd = 0.0048
-------------------------
2024-10-29 12:02:23: Evaluate 5 random ConvNet, F!mean = 0.4109 F!std = 0.0180
-------------------------
2024-10-29 12:02:23: Evaluate 5 random ConvNet, mean = 0.4408 std = 0.0143
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:02:23: [2024-10-29 12:02:23] iter = 14000, loss = 5.3058
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:02:23: [2024-10-29 12:02:23] iter = 14010, loss = 7.2392
2024-10-29 12:02:24: [2024-10-29 12:02:24] iter = 14020, loss = 12.5383
2024-10-29 12:02:24: [2024-10-29 12:02:24] iter = 14030, loss = 6.9749
2024-10-29 12:02:25: [2024-10-29 12:02:25] iter = 14040, loss = 15.2846
2024-10-29 12:02:25: [2024-10-29 12:02:25] iter = 14050, loss = 2.7917
2024-10-29 12:02:26: [2024-10-29 12:02:26] iter = 14060, loss = 2.9923
2024-10-29 12:02:26: [2024-10-29 12:02:26] iter = 14070, loss = 7.3315
2024-10-29 12:02:27: [2024-10-29 12:02:27] iter = 14080, loss = 6.3927
2024-10-29 12:02:27: [2024-10-29 12:02:27] iter = 14090, loss = 3.3046
2024-10-29 12:02:28: [2024-10-29 12:02:28] iter = 14100, loss = 4.5818
2024-10-29 12:02:28: [2024-10-29 12:02:28] iter = 14110, loss = 3.7311
2024-10-29 12:02:28: [2024-10-29 12:02:28] iter = 14120, loss = 13.3743
2024-10-29 12:02:29: [2024-10-29 12:02:29] iter = 14130, loss = 2.2139
2024-10-29 12:02:29: [2024-10-29 12:02:29] iter = 14140, loss = 3.3102
2024-10-29 12:02:30: [2024-10-29 12:02:30] iter = 14150, loss = 7.4164
2024-10-29 12:02:30: [2024-10-29 12:02:30] iter = 14160, loss = 9.2112
2024-10-29 12:02:30: [2024-10-29 12:02:30] iter = 14170, loss = 39.8284
2024-10-29 12:02:31: [2024-10-29 12:02:31] iter = 14180, loss = 3.4921
2024-10-29 12:02:31: [2024-10-29 12:02:31] iter = 14190, loss = 6.8708
2024-10-29 12:02:32: [2024-10-29 12:02:32] iter = 14200, loss = 10.8398
2024-10-29 12:02:32: [2024-10-29 12:02:32] iter = 14210, loss = 4.2491
2024-10-29 12:02:33: [2024-10-29 12:02:33] iter = 14220, loss = 1.9747
2024-10-29 12:02:33: [2024-10-29 12:02:33] iter = 14230, loss = 5.0621
2024-10-29 12:02:34: [2024-10-29 12:02:34] iter = 14240, loss = 9.3358
2024-10-29 12:02:34: [2024-10-29 12:02:34] iter = 14250, loss = 8.5345
2024-10-29 12:02:34: [2024-10-29 12:02:34] iter = 14260, loss = 4.3821
2024-10-29 12:02:35: [2024-10-29 12:02:35] iter = 14270, loss = 4.7353
2024-10-29 12:02:35: [2024-10-29 12:02:35] iter = 14280, loss = 4.3695
2024-10-29 12:02:36: [2024-10-29 12:02:36] iter = 14290, loss = 5.3817
2024-10-29 12:02:36: [2024-10-29 12:02:36] iter = 14300, loss = 4.5106
2024-10-29 12:02:37: [2024-10-29 12:02:37] iter = 14310, loss = 4.3399
2024-10-29 12:02:37: [2024-10-29 12:02:37] iter = 14320, loss = 2.3096
2024-10-29 12:02:37: [2024-10-29 12:02:37] iter = 14330, loss = 8.9184
2024-10-29 12:02:38: [2024-10-29 12:02:38] iter = 14340, loss = 16.3981
2024-10-29 12:02:38: [2024-10-29 12:02:38] iter = 14350, loss = 8.1418
2024-10-29 12:02:39: [2024-10-29 12:02:39] iter = 14360, loss = 3.5677
2024-10-29 12:02:39: [2024-10-29 12:02:39] iter = 14370, loss = 2.7449
2024-10-29 12:02:40: [2024-10-29 12:02:40] iter = 14380, loss = 2.5094
2024-10-29 12:02:40: [2024-10-29 12:02:40] iter = 14390, loss = 27.9304
2024-10-29 12:02:41: [2024-10-29 12:02:41] iter = 14400, loss = 1.8220
2024-10-29 12:02:41: [2024-10-29 12:02:41] iter = 14410, loss = 3.0634
2024-10-29 12:02:42: [2024-10-29 12:02:42] iter = 14420, loss = 4.9716
2024-10-29 12:02:42: [2024-10-29 12:02:42] iter = 14430, loss = 3.0551
2024-10-29 12:02:42: [2024-10-29 12:02:42] iter = 14440, loss = 59.9543
2024-10-29 12:02:43: [2024-10-29 12:02:43] iter = 14450, loss = 6.1100
2024-10-29 12:02:43: [2024-10-29 12:02:43] iter = 14460, loss = 8.6573
2024-10-29 12:02:44: [2024-10-29 12:02:44] iter = 14470, loss = 17.2934
2024-10-29 12:02:44: [2024-10-29 12:02:44] iter = 14480, loss = 3.1567
2024-10-29 12:02:45: [2024-10-29 12:02:45] iter = 14490, loss = 14.6869
2024-10-29 12:02:45: [2024-10-29 12:02:45] iter = 14500, loss = 14.4119
2024-10-29 12:02:46: [2024-10-29 12:02:46] iter = 14510, loss = 14.6333
2024-10-29 12:02:46: [2024-10-29 12:02:46] iter = 14520, loss = 4.3640
2024-10-29 12:02:47: [2024-10-29 12:02:47] iter = 14530, loss = 5.8729
2024-10-29 12:02:47: [2024-10-29 12:02:47] iter = 14540, loss = 17.3496
2024-10-29 12:02:48: [2024-10-29 12:02:48] iter = 14550, loss = 5.5577
2024-10-29 12:02:48: [2024-10-29 12:02:48] iter = 14560, loss = 15.2178
2024-10-29 12:02:49: [2024-10-29 12:02:49] iter = 14570, loss = 2.9396
2024-10-29 12:02:49: [2024-10-29 12:02:49] iter = 14580, loss = 8.5757
2024-10-29 12:02:50: [2024-10-29 12:02:50] iter = 14590, loss = 13.0543
2024-10-29 12:02:50: [2024-10-29 12:02:50] iter = 14600, loss = 5.1730
2024-10-29 12:02:51: [2024-10-29 12:02:51] iter = 14610, loss = 7.1366
2024-10-29 12:02:51: [2024-10-29 12:02:51] iter = 14620, loss = 8.5426
2024-10-29 12:02:52: [2024-10-29 12:02:52] iter = 14630, loss = 3.9261
2024-10-29 12:02:52: [2024-10-29 12:02:52] iter = 14640, loss = 29.4921
2024-10-29 12:02:52: [2024-10-29 12:02:52] iter = 14650, loss = 10.9709
2024-10-29 12:02:53: [2024-10-29 12:02:53] iter = 14660, loss = 5.3936
2024-10-29 12:02:53: [2024-10-29 12:02:53] iter = 14670, loss = 2.8668
2024-10-29 12:02:54: [2024-10-29 12:02:54] iter = 14680, loss = 9.6619
2024-10-29 12:02:54: [2024-10-29 12:02:54] iter = 14690, loss = 3.7069
2024-10-29 12:02:55: [2024-10-29 12:02:55] iter = 14700, loss = 12.7956
2024-10-29 12:02:55: [2024-10-29 12:02:55] iter = 14710, loss = 4.0537
2024-10-29 12:02:55: [2024-10-29 12:02:55] iter = 14720, loss = 4.5809
2024-10-29 12:02:56: [2024-10-29 12:02:56] iter = 14730, loss = 3.5278
2024-10-29 12:02:56: [2024-10-29 12:02:56] iter = 14740, loss = 3.7935
2024-10-29 12:02:57: [2024-10-29 12:02:57] iter = 14750, loss = 3.4530
2024-10-29 12:02:57: [2024-10-29 12:02:57] iter = 14760, loss = 40.5141
2024-10-29 12:02:58: [2024-10-29 12:02:58] iter = 14770, loss = 4.4286
2024-10-29 12:02:58: [2024-10-29 12:02:58] iter = 14780, loss = 3.1670
2024-10-29 12:02:58: [2024-10-29 12:02:58] iter = 14790, loss = 7.3837
2024-10-29 12:02:59: [2024-10-29 12:02:59] iter = 14800, loss = 7.8942
2024-10-29 12:02:59: [2024-10-29 12:02:59] iter = 14810, loss = 22.9244
2024-10-29 12:03:00: [2024-10-29 12:03:00] iter = 14820, loss = 4.0293
2024-10-29 12:03:00: [2024-10-29 12:03:00] iter = 14830, loss = 11.0881
2024-10-29 12:03:01: [2024-10-29 12:03:01] iter = 14840, loss = 27.2985
2024-10-29 12:03:01: [2024-10-29 12:03:01] iter = 14850, loss = 14.1237
2024-10-29 12:03:02: [2024-10-29 12:03:02] iter = 14860, loss = 3.9613
2024-10-29 12:03:02: [2024-10-29 12:03:02] iter = 14870, loss = 9.6565
2024-10-29 12:03:03: [2024-10-29 12:03:03] iter = 14880, loss = 34.8274
2024-10-29 12:03:03: [2024-10-29 12:03:03] iter = 14890, loss = 3.6348
2024-10-29 12:03:04: [2024-10-29 12:03:04] iter = 14900, loss = 24.1090
2024-10-29 12:03:04: [2024-10-29 12:03:04] iter = 14910, loss = 4.1792
2024-10-29 12:03:05: [2024-10-29 12:03:05] iter = 14920, loss = 7.8615
2024-10-29 12:03:05: [2024-10-29 12:03:05] iter = 14930, loss = 7.1443
2024-10-29 12:03:06: [2024-10-29 12:03:06] iter = 14940, loss = 12.0487
2024-10-29 12:03:06: [2024-10-29 12:03:06] iter = 14950, loss = 3.0336
2024-10-29 12:03:07: [2024-10-29 12:03:07] iter = 14960, loss = 7.4417
2024-10-29 12:03:07: [2024-10-29 12:03:07] iter = 14970, loss = 6.4187
2024-10-29 12:03:08: [2024-10-29 12:03:08] iter = 14980, loss = 3.0789
2024-10-29 12:03:08: [2024-10-29 12:03:08] iter = 14990, loss = 5.3831
2024-10-29 12:03:08: [2024-10-29 12:03:08] iter = 15000, loss = 4.5744
2024-10-29 12:03:09: [2024-10-29 12:03:09] iter = 15010, loss = 5.7045
2024-10-29 12:03:09: [2024-10-29 12:03:09] iter = 15020, loss = 3.1350
2024-10-29 12:03:10: [2024-10-29 12:03:10] iter = 15030, loss = 2.7316
2024-10-29 12:03:10: [2024-10-29 12:03:10] iter = 15040, loss = 5.3518
2024-10-29 12:03:11: [2024-10-29 12:03:11] iter = 15050, loss = 6.0814
2024-10-29 12:03:11: [2024-10-29 12:03:11] iter = 15060, loss = 2.5459
2024-10-29 12:03:11: [2024-10-29 12:03:11] iter = 15070, loss = 27.6194
2024-10-29 12:03:12: [2024-10-29 12:03:12] iter = 15080, loss = 23.3436
2024-10-29 12:03:12: [2024-10-29 12:03:12] iter = 15090, loss = 40.1710
2024-10-29 12:03:13: [2024-10-29 12:03:13] iter = 15100, loss = 11.3227
2024-10-29 12:03:13: [2024-10-29 12:03:13] iter = 15110, loss = 7.0185
2024-10-29 12:03:14: [2024-10-29 12:03:14] iter = 15120, loss = 22.6389
2024-10-29 12:03:14: [2024-10-29 12:03:14] iter = 15130, loss = 4.7108
2024-10-29 12:03:15: [2024-10-29 12:03:15] iter = 15140, loss = 2.9329
2024-10-29 12:03:15: [2024-10-29 12:03:15] iter = 15150, loss = 7.4173
2024-10-29 12:03:15: [2024-10-29 12:03:15] iter = 15160, loss = 8.1667
2024-10-29 12:03:16: [2024-10-29 12:03:16] iter = 15170, loss = 5.3422
2024-10-29 12:03:16: [2024-10-29 12:03:16] iter = 15180, loss = 4.1315
2024-10-29 12:03:17: [2024-10-29 12:03:17] iter = 15190, loss = 3.4325
2024-10-29 12:03:17: [2024-10-29 12:03:17] iter = 15200, loss = 2.8167
2024-10-29 12:03:17: [2024-10-29 12:03:17] iter = 15210, loss = 2.6720
2024-10-29 12:03:18: [2024-10-29 12:03:18] iter = 15220, loss = 4.8335
2024-10-29 12:03:18: [2024-10-29 12:03:18] iter = 15230, loss = 6.2745
2024-10-29 12:03:19: [2024-10-29 12:03:19] iter = 15240, loss = 6.8822
2024-10-29 12:03:19: [2024-10-29 12:03:19] iter = 15250, loss = 2.9223
2024-10-29 12:03:20: [2024-10-29 12:03:20] iter = 15260, loss = 3.6845
2024-10-29 12:03:20: [2024-10-29 12:03:20] iter = 15270, loss = 11.4940
2024-10-29 12:03:21: [2024-10-29 12:03:21] iter = 15280, loss = 8.8278
2024-10-29 12:03:21: [2024-10-29 12:03:21] iter = 15290, loss = 5.8568
2024-10-29 12:03:22: [2024-10-29 12:03:22] iter = 15300, loss = 2.8122
2024-10-29 12:03:22: [2024-10-29 12:03:22] iter = 15310, loss = 8.0315
2024-10-29 12:03:22: [2024-10-29 12:03:22] iter = 15320, loss = 9.7939
2024-10-29 12:03:23: [2024-10-29 12:03:23] iter = 15330, loss = 4.2263
2024-10-29 12:03:24: [2024-10-29 12:03:24] iter = 15340, loss = 4.1982
2024-10-29 12:03:24: [2024-10-29 12:03:24] iter = 15350, loss = 18.0625
2024-10-29 12:03:25: [2024-10-29 12:03:25] iter = 15360, loss = 13.3730
2024-10-29 12:03:25: [2024-10-29 12:03:25] iter = 15370, loss = 4.4006
2024-10-29 12:03:26: [2024-10-29 12:03:26] iter = 15380, loss = 3.6715
2024-10-29 12:03:26: [2024-10-29 12:03:26] iter = 15390, loss = 7.3133
2024-10-29 12:03:27: [2024-10-29 12:03:27] iter = 15400, loss = 7.3931
2024-10-29 12:03:27: [2024-10-29 12:03:27] iter = 15410, loss = 6.7710
2024-10-29 12:03:28: [2024-10-29 12:03:28] iter = 15420, loss = 5.2958
2024-10-29 12:03:28: [2024-10-29 12:03:28] iter = 15430, loss = 3.0863
2024-10-29 12:03:29: [2024-10-29 12:03:29] iter = 15440, loss = 3.3363
2024-10-29 12:03:29: [2024-10-29 12:03:29] iter = 15450, loss = 7.4008
2024-10-29 12:03:30: [2024-10-29 12:03:30] iter = 15460, loss = 3.7380
2024-10-29 12:03:31: [2024-10-29 12:03:31] iter = 15470, loss = 10.1204
2024-10-29 12:03:31: [2024-10-29 12:03:31] iter = 15480, loss = 8.1392
2024-10-29 12:03:31: [2024-10-29 12:03:31] iter = 15490, loss = 4.0130
2024-10-29 12:03:32: [2024-10-29 12:03:32] iter = 15500, loss = 4.6584
2024-10-29 12:03:33: [2024-10-29 12:03:33] iter = 15510, loss = 2.7716
2024-10-29 12:03:33: [2024-10-29 12:03:33] iter = 15520, loss = 8.0076
2024-10-29 12:03:34: [2024-10-29 12:03:34] iter = 15530, loss = 26.1525
2024-10-29 12:03:34: [2024-10-29 12:03:34] iter = 15540, loss = 11.2406
2024-10-29 12:03:35: [2024-10-29 12:03:35] iter = 15550, loss = 8.0510
2024-10-29 12:03:35: [2024-10-29 12:03:35] iter = 15560, loss = 5.3472
2024-10-29 12:03:35: [2024-10-29 12:03:35] iter = 15570, loss = 8.6876
2024-10-29 12:03:36: [2024-10-29 12:03:36] iter = 15580, loss = 14.6127
2024-10-29 12:03:37: [2024-10-29 12:03:37] iter = 15590, loss = 3.1213
2024-10-29 12:03:37: [2024-10-29 12:03:37] iter = 15600, loss = 3.9625
2024-10-29 12:03:37: [2024-10-29 12:03:37] iter = 15610, loss = 2.1868
2024-10-29 12:03:38: [2024-10-29 12:03:38] iter = 15620, loss = 14.4395
2024-10-29 12:03:38: [2024-10-29 12:03:38] iter = 15630, loss = 14.7177
2024-10-29 12:03:39: [2024-10-29 12:03:39] iter = 15640, loss = 5.5178
2024-10-29 12:03:39: [2024-10-29 12:03:39] iter = 15650, loss = 8.8525
2024-10-29 12:03:40: [2024-10-29 12:03:40] iter = 15660, loss = 10.2720
2024-10-29 12:03:40: [2024-10-29 12:03:40] iter = 15670, loss = 15.5764
2024-10-29 12:03:41: [2024-10-29 12:03:41] iter = 15680, loss = 12.0437
2024-10-29 12:03:41: [2024-10-29 12:03:41] iter = 15690, loss = 4.8777
2024-10-29 12:03:41: [2024-10-29 12:03:41] iter = 15700, loss = 3.4847
2024-10-29 12:03:42: [2024-10-29 12:03:42] iter = 15710, loss = 2.7185
2024-10-29 12:03:42: [2024-10-29 12:03:42] iter = 15720, loss = 5.5444
2024-10-29 12:03:43: [2024-10-29 12:03:43] iter = 15730, loss = 16.0182
2024-10-29 12:03:43: [2024-10-29 12:03:43] iter = 15740, loss = 14.8493
2024-10-29 12:03:43: [2024-10-29 12:03:43] iter = 15750, loss = 8.1813
2024-10-29 12:03:44: [2024-10-29 12:03:44] iter = 15760, loss = 10.9932
2024-10-29 12:03:44: [2024-10-29 12:03:44] iter = 15770, loss = 5.0516
2024-10-29 12:03:45: [2024-10-29 12:03:45] iter = 15780, loss = 12.5257
2024-10-29 12:03:45: [2024-10-29 12:03:45] iter = 15790, loss = 4.4265
2024-10-29 12:03:46: [2024-10-29 12:03:46] iter = 15800, loss = 2.7916
2024-10-29 12:03:46: [2024-10-29 12:03:46] iter = 15810, loss = 2.9478
2024-10-29 12:03:47: [2024-10-29 12:03:47] iter = 15820, loss = 4.5681
2024-10-29 12:03:47: [2024-10-29 12:03:47] iter = 15830, loss = 8.3595
2024-10-29 12:03:48: [2024-10-29 12:03:48] iter = 15840, loss = 2.9481
2024-10-29 12:03:48: [2024-10-29 12:03:48] iter = 15850, loss = 6.5374
2024-10-29 12:03:49: [2024-10-29 12:03:49] iter = 15860, loss = 3.7339
2024-10-29 12:03:49: [2024-10-29 12:03:49] iter = 15870, loss = 3.8936
2024-10-29 12:03:49: [2024-10-29 12:03:49] iter = 15880, loss = 5.5513
2024-10-29 12:03:50: [2024-10-29 12:03:50] iter = 15890, loss = 4.1881
2024-10-29 12:03:50: [2024-10-29 12:03:50] iter = 15900, loss = 5.9660
2024-10-29 12:03:51: [2024-10-29 12:03:51] iter = 15910, loss = 9.1715
2024-10-29 12:03:51: [2024-10-29 12:03:51] iter = 15920, loss = 2.8698
2024-10-29 12:03:52: [2024-10-29 12:03:52] iter = 15930, loss = 5.5242
2024-10-29 12:03:53: [2024-10-29 12:03:53] iter = 15940, loss = 34.0171
2024-10-29 12:03:53: [2024-10-29 12:03:53] iter = 15950, loss = 5.9068
2024-10-29 12:03:53: [2024-10-29 12:03:53] iter = 15960, loss = 16.8730
2024-10-29 12:03:54: [2024-10-29 12:03:54] iter = 15970, loss = 29.0938
2024-10-29 12:03:54: [2024-10-29 12:03:54] iter = 15980, loss = 6.7361
2024-10-29 12:03:55: [2024-10-29 12:03:55] iter = 15990, loss = 12.3981
2024-10-29 12:03:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 12:03:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:03:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 35532}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/octmnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/octmnist.npz
Loaded the dataset:OCTMNIST
[2024-10-29 11:48:53] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.003851 train acc = 1.0000, test acc = 0.4030, test_sen =0.4030, test_spe =0.8010, test_f1 =0.4058
[2024-10-29 11:48:59] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.019228 train acc = 1.0000, test acc = 0.4040, test_sen =0.4040, test_spe =0.8013, test_f1 =0.4076
[2024-10-29 11:49:03] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.008728 train acc = 1.0000, test acc = 0.4090, test_sen =0.4090, test_spe =0.8030, test_f1 =0.4148
[2024-10-29 11:49:08] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.004734 train acc = 1.0000, test acc = 0.3990, test_sen =0.3990, test_spe =0.7997, test_f1 =0.4019
[2024-10-29 11:49:14] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.023316 train acc = 1.0000, test acc = 0.4140, test_sen =0.4140, test_spe =0.8047, test_f1 =0.4185
[2024-10-29 11:50:48] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.004544 train acc = 1.0000, test acc = 0.5300, test_sen =0.5300, test_spe =0.8433, test_f1 =0.4904
[2024-10-29 11:50:52] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.003442 train acc = 1.0000, test acc = 0.5010, test_sen =0.5010, test_spe =0.8337, test_f1 =0.4599
[2024-10-29 11:50:57] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001846 train acc = 1.0000, test acc = 0.5020, test_sen =0.5020, test_spe =0.8340, test_f1 =0.4593
[2024-10-29 11:51:02] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.009128 train acc = 1.0000, test acc = 0.5270, test_sen =0.5270, test_spe =0.8423, test_f1 =0.4867
[2024-10-29 11:51:07] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002110 train acc = 1.0000, test acc = 0.5260, test_sen =0.5260, test_spe =0.8420, test_f1 =0.4888
[2024-10-29 11:52:42] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.021998 train acc = 1.0000, test acc = 0.4750, test_sen =0.4750, test_spe =0.8250, test_f1 =0.4669
[2024-10-29 11:52:47] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001252 train acc = 1.0000, test acc = 0.4830, test_sen =0.4830, test_spe =0.8277, test_f1 =0.4703
[2024-10-29 11:52:51] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003449 train acc = 1.0000, test acc = 0.4530, test_sen =0.4530, test_spe =0.8177, test_f1 =0.4338
[2024-10-29 11:52:56] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.009705 train acc = 1.0000, test acc = 0.5060, test_sen =0.5060, test_spe =0.8353, test_f1 =0.4958
[2024-10-29 11:53:01] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001920 train acc = 1.0000, test acc = 0.4670, test_sen =0.4670, test_spe =0.8223, test_f1 =0.4431
[2024-10-29 11:54:35] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.024561 train acc = 1.0000, test acc = 0.4760, test_sen =0.4760, test_spe =0.8253, test_f1 =0.4007
[2024-10-29 11:54:39] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.001886 train acc = 1.0000, test acc = 0.4680, test_sen =0.4680, test_spe =0.8227, test_f1 =0.3918
[2024-10-29 11:54:44] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003250 train acc = 1.0000, test acc = 0.4720, test_sen =0.4720, test_spe =0.8240, test_f1 =0.3939
[2024-10-29 11:54:49] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.033471 train acc = 1.0000, test acc = 0.4860, test_sen =0.4860, test_spe =0.8287, test_f1 =0.4039
[2024-10-29 11:54:54] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001427 train acc = 1.0000, test acc = 0.4740, test_sen =0.4740, test_spe =0.8247, test_f1 =0.3964
[2024-10-29 11:56:26] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002138 train acc = 1.0000, test acc = 0.4640, test_sen =0.4640, test_spe =0.8213, test_f1 =0.4387
[2024-10-29 11:56:30] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.002660 train acc = 1.0000, test acc = 0.4380, test_sen =0.4380, test_spe =0.8127, test_f1 =0.4155
[2024-10-29 11:56:35] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.041026 train acc = 1.0000, test acc = 0.4360, test_sen =0.4360, test_spe =0.8120, test_f1 =0.4076
[2024-10-29 11:56:39] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.001297 train acc = 1.0000, test acc = 0.4460, test_sen =0.4460, test_spe =0.8153, test_f1 =0.4258
[2024-10-29 11:56:44] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002293 train acc = 1.0000, test acc = 0.4500, test_sen =0.4500, test_spe =0.8167, test_f1 =0.4162
[2024-10-29 11:58:21] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001283 train acc = 1.0000, test acc = 0.4290, test_sen =0.4290, test_spe =0.8097, test_f1 =0.3260
[2024-10-29 11:58:25] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.003873 train acc = 1.0000, test acc = 0.4380, test_sen =0.4380, test_spe =0.8127, test_f1 =0.3308
[2024-10-29 11:58:30] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.051986 train acc = 1.0000, test acc = 0.4530, test_sen =0.4530, test_spe =0.8177, test_f1 =0.3543
[2024-10-29 11:58:34] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.000648 train acc = 1.0000, test acc = 0.4450, test_sen =0.4450, test_spe =0.8150, test_f1 =0.3555
[2024-10-29 11:58:39] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001190 train acc = 1.0000, test acc = 0.4410, test_sen =0.4410, test_spe =0.8137, test_f1 =0.3331
[2024-10-29 12:00:12] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002485 train acc = 1.0000, test acc = 0.4390, test_sen =0.4390, test_spe =0.8130, test_f1 =0.3916
[2024-10-29 12:00:16] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004410 train acc = 1.0000, test acc = 0.4620, test_sen =0.4620, test_spe =0.8207, test_f1 =0.4071
[2024-10-29 12:00:21] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.029767 train acc = 1.0000, test acc = 0.4410, test_sen =0.4410, test_spe =0.8137, test_f1 =0.3816
[2024-10-29 12:00:26] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.001958 train acc = 1.0000, test acc = 0.4530, test_sen =0.4530, test_spe =0.8177, test_f1 =0.3984
[2024-10-29 12:00:31] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.061662 train acc = 0.9750, test acc = 0.4470, test_sen =0.4470, test_spe =0.8157, test_f1 =0.3939
[2024-10-29 12:02:04] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000881 train acc = 1.0000, test acc = 0.4430, test_sen =0.4430, test_spe =0.8143, test_f1 =0.4150
[2024-10-29 12:02:09] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.003455 train acc = 1.0000, test acc = 0.4560, test_sen =0.4560, test_spe =0.8187, test_f1 =0.4287
[2024-10-29 12:02:14] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001572 train acc = 1.0000, test acc = 0.4560, test_sen =0.4560, test_spe =0.8187, test_f1 =0.4306
[2024-10-29 12:02:18] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.001317 train acc = 1.0000, test acc = 0.4280, test_sen =0.4280, test_spe =0.8093, test_f1 =0.3946
[2024-10-29 12:02:23] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.003054 train acc = 1.0000, test acc = 0.4210, test_sen =0.4210, test_spe =0.8070, test_f1 =0.3858
[2024-10-29 12:04:00] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.042091 train acc = 1.0000, test acc = 0.5150, test_sen =0.5150, test_spe =0.8383, test_f1 =0.4523
[2024-10-29 12:04:05] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.018221 train acc = 1.0000, test acc = 0.5200, test_sen =0.5200, test_spe =0.8400, test_f1 =0.4701
[2024-10-29 12:04:10] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.001203 train acc = 1.0000, test acc = 0.5050, test_sen =0.5050, test_spe =0.8350, test_f1 =0.4495
[2024-10-29 12:04:15] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.011424 train acc = 1.0000, test acc = 0.5110, test_sen =0.5110, test_spe =0.8370, test_f1 =0.4479
[2024-10-29 12:04:20] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.027129 train acc = 1.0000, test acc = 0.4910, test_sen =0.4910, test_spe =0.8303, test_f1 =0.4311/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:04:20: Evaluate 5 random ConvNet, ACCmean = 0.5084 ACCstd = 0.0100
-------------------------
2024-10-29 12:04:20: Evaluate 5 random ConvNet, SENmean = 0.5084 SENstd = 0.0100
-------------------------
2024-10-29 12:04:20: Evaluate 5 random ConvNet, SPEmean = 0.8361 SPEstd = 0.0033
-------------------------
2024-10-29 12:04:20: Evaluate 5 random ConvNet, F!mean = 0.4502 F!std = 0.0124
-------------------------
2024-10-29 12:04:20: Evaluate 5 random ConvNet, mean = 0.5084 std = 0.0100
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:04:20: [2024-10-29 12:04:20] iter = 16000, loss = 4.9754
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:04:20: [2024-10-29 12:04:20] iter = 16010, loss = 21.6987
2024-10-29 12:04:21: [2024-10-29 12:04:21] iter = 16020, loss = 3.1719
2024-10-29 12:04:21: [2024-10-29 12:04:21] iter = 16030, loss = 5.4504
2024-10-29 12:04:22: [2024-10-29 12:04:22] iter = 16040, loss = 5.9537
2024-10-29 12:04:22: [2024-10-29 12:04:22] iter = 16050, loss = 7.9717
2024-10-29 12:04:23: [2024-10-29 12:04:23] iter = 16060, loss = 5.6234
2024-10-29 12:04:23: [2024-10-29 12:04:23] iter = 16070, loss = 3.9616
2024-10-29 12:04:24: [2024-10-29 12:04:24] iter = 16080, loss = 3.1783
2024-10-29 12:04:24: [2024-10-29 12:04:24] iter = 16090, loss = 30.4001
2024-10-29 12:04:25: [2024-10-29 12:04:25] iter = 16100, loss = 6.7403
2024-10-29 12:04:25: [2024-10-29 12:04:25] iter = 16110, loss = 2.8973
2024-10-29 12:04:25: [2024-10-29 12:04:25] iter = 16120, loss = 49.6946
2024-10-29 12:04:26: [2024-10-29 12:04:26] iter = 16130, loss = 2.3688
2024-10-29 12:04:26: [2024-10-29 12:04:26] iter = 16140, loss = 5.0190
2024-10-29 12:04:27: [2024-10-29 12:04:27] iter = 16150, loss = 8.0680
2024-10-29 12:04:27: [2024-10-29 12:04:27] iter = 16160, loss = 10.2047
2024-10-29 12:04:28: [2024-10-29 12:04:27] iter = 16170, loss = 4.8869
2024-10-29 12:04:28: [2024-10-29 12:04:28] iter = 16180, loss = 5.6881
2024-10-29 12:04:29: [2024-10-29 12:04:29] iter = 16190, loss = 15.6455
2024-10-29 12:04:29: [2024-10-29 12:04:29] iter = 16200, loss = 3.3608
2024-10-29 12:04:30: [2024-10-29 12:04:30] iter = 16210, loss = 8.9885
2024-10-29 12:04:30: [2024-10-29 12:04:30] iter = 16220, loss = 3.4966
2024-10-29 12:04:31: [2024-10-29 12:04:31] iter = 16230, loss = 4.4994
2024-10-29 12:04:31: [2024-10-29 12:04:31] iter = 16240, loss = 17.1605
2024-10-29 12:04:32: [2024-10-29 12:04:32] iter = 16250, loss = 6.0657
2024-10-29 12:04:32: [2024-10-29 12:04:32] iter = 16260, loss = 8.5999
2024-10-29 12:04:33: [2024-10-29 12:04:33] iter = 16270, loss = 4.0139
2024-10-29 12:04:33: [2024-10-29 12:04:33] iter = 16280, loss = 12.3501
2024-10-29 12:04:34: [2024-10-29 12:04:34] iter = 16290, loss = 13.0847
2024-10-29 12:04:34: [2024-10-29 12:04:34] iter = 16300, loss = 9.2085
2024-10-29 12:04:35: [2024-10-29 12:04:35] iter = 16310, loss = 5.0234
2024-10-29 12:04:35: [2024-10-29 12:04:35] iter = 16320, loss = 6.0710
2024-10-29 12:04:36: [2024-10-29 12:04:36] iter = 16330, loss = 44.5769
2024-10-29 12:04:36: [2024-10-29 12:04:36] iter = 16340, loss = 6.4644
2024-10-29 12:04:37: [2024-10-29 12:04:37] iter = 16350, loss = 4.0878
2024-10-29 12:04:37: [2024-10-29 12:04:37] iter = 16360, loss = 3.8305
2024-10-29 12:04:38: [2024-10-29 12:04:38] iter = 16370, loss = 31.7563
2024-10-29 12:04:39: [2024-10-29 12:04:39] iter = 16380, loss = 3.8646
2024-10-29 12:04:39: [2024-10-29 12:04:39] iter = 16390, loss = 8.2098
2024-10-29 12:04:39: [2024-10-29 12:04:39] iter = 16400, loss = 13.9569
2024-10-29 12:04:40: [2024-10-29 12:04:40] iter = 16410, loss = 44.3837
2024-10-29 12:04:41: [2024-10-29 12:04:41] iter = 16420, loss = 7.1440
2024-10-29 12:04:41: [2024-10-29 12:04:41] iter = 16430, loss = 5.1462
2024-10-29 12:04:42: [2024-10-29 12:04:42] iter = 16440, loss = 8.5439
2024-10-29 12:04:42: [2024-10-29 12:04:42] iter = 16450, loss = 3.6890
2024-10-29 12:04:42: [2024-10-29 12:04:42] iter = 16460, loss = 11.8830
2024-10-29 12:04:43: [2024-10-29 12:04:43] iter = 16470, loss = 8.7094
2024-10-29 12:04:43: [2024-10-29 12:04:43] iter = 16480, loss = 9.7649
2024-10-29 12:04:44: [2024-10-29 12:04:44] iter = 16490, loss = 42.3469
2024-10-29 12:04:44: [2024-10-29 12:04:44] iter = 16500, loss = 2.8966
2024-10-29 12:04:45: [2024-10-29 12:04:45] iter = 16510, loss = 2.9504
2024-10-29 12:04:45: [2024-10-29 12:04:45] iter = 16520, loss = 10.8641
2024-10-29 12:04:46: [2024-10-29 12:04:46] iter = 16530, loss = 5.3401
2024-10-29 12:04:46: [2024-10-29 12:04:46] iter = 16540, loss = 2.9049
2024-10-29 12:04:47: [2024-10-29 12:04:47] iter = 16550, loss = 8.9653
2024-10-29 12:04:47: [2024-10-29 12:04:47] iter = 16560, loss = 20.3507
2024-10-29 12:04:48: [2024-10-29 12:04:48] iter = 16570, loss = 8.8090
2024-10-29 12:04:48: [2024-10-29 12:04:48] iter = 16580, loss = 4.8145
2024-10-29 12:04:49: [2024-10-29 12:04:49] iter = 16590, loss = 4.5734
2024-10-29 12:04:49: [2024-10-29 12:04:49] iter = 16600, loss = 7.7420
2024-10-29 12:04:50: [2024-10-29 12:04:50] iter = 16610, loss = 3.5125
2024-10-29 12:04:50: [2024-10-29 12:04:50] iter = 16620, loss = 3.4106
2024-10-29 12:04:51: [2024-10-29 12:04:51] iter = 16630, loss = 9.8997
2024-10-29 12:04:51: [2024-10-29 12:04:51] iter = 16640, loss = 6.9859
2024-10-29 12:04:52: [2024-10-29 12:04:52] iter = 16650, loss = 5.7654
2024-10-29 12:04:52: [2024-10-29 12:04:52] iter = 16660, loss = 6.1006
2024-10-29 12:04:53: [2024-10-29 12:04:53] iter = 16670, loss = 4.8031
2024-10-29 12:04:53: [2024-10-29 12:04:53] iter = 16680, loss = 5.2328
2024-10-29 12:04:54: [2024-10-29 12:04:54] iter = 16690, loss = 32.5392
2024-10-29 12:04:54: [2024-10-29 12:04:54] iter = 16700, loss = 4.7761
2024-10-29 12:04:55: [2024-10-29 12:04:55] iter = 16710, loss = 17.6272
2024-10-29 12:04:55: [2024-10-29 12:04:55] iter = 16720, loss = 3.9795
2024-10-29 12:04:55: [2024-10-29 12:04:55] iter = 16730, loss = 11.0082
2024-10-29 12:04:56: [2024-10-29 12:04:56] iter = 16740, loss = 4.5818
2024-10-29 12:04:56: [2024-10-29 12:04:56] iter = 16750, loss = 8.8812
2024-10-29 12:04:57: [2024-10-29 12:04:57] iter = 16760, loss = 26.0330
2024-10-29 12:04:57: [2024-10-29 12:04:57] iter = 16770, loss = 3.1948
2024-10-29 12:04:58: [2024-10-29 12:04:58] iter = 16780, loss = 25.0001
2024-10-29 12:04:58: [2024-10-29 12:04:58] iter = 16790, loss = 3.7910
2024-10-29 12:04:59: [2024-10-29 12:04:59] iter = 16800, loss = 30.2788
2024-10-29 12:04:59: [2024-10-29 12:04:59] iter = 16810, loss = 7.2790
2024-10-29 12:05:00: [2024-10-29 12:05:00] iter = 16820, loss = 9.0037
2024-10-29 12:05:00: [2024-10-29 12:05:00] iter = 16830, loss = 2.3286
2024-10-29 12:05:01: [2024-10-29 12:05:01] iter = 16840, loss = 8.9461
2024-10-29 12:05:01: [2024-10-29 12:05:01] iter = 16850, loss = 6.7356
2024-10-29 12:05:01: [2024-10-29 12:05:01] iter = 16860, loss = 4.0799
2024-10-29 12:05:02: [2024-10-29 12:05:02] iter = 16870, loss = 3.3763
2024-10-29 12:05:02: [2024-10-29 12:05:02] iter = 16880, loss = 43.7581
2024-10-29 12:05:03: [2024-10-29 12:05:03] iter = 16890, loss = 28.4478
2024-10-29 12:05:03: [2024-10-29 12:05:03] iter = 16900, loss = 4.7211
2024-10-29 12:05:04: [2024-10-29 12:05:04] iter = 16910, loss = 5.1880
2024-10-29 12:05:04: [2024-10-29 12:05:04] iter = 16920, loss = 4.2100
2024-10-29 12:05:05: [2024-10-29 12:05:05] iter = 16930, loss = 8.2999
2024-10-29 12:05:05: [2024-10-29 12:05:05] iter = 16940, loss = 5.1811
2024-10-29 12:05:06: [2024-10-29 12:05:06] iter = 16950, loss = 6.0811
2024-10-29 12:05:06: [2024-10-29 12:05:06] iter = 16960, loss = 8.9425
2024-10-29 12:05:07: [2024-10-29 12:05:07] iter = 16970, loss = 3.1393
2024-10-29 12:05:07: [2024-10-29 12:05:07] iter = 16980, loss = 9.0179
2024-10-29 12:05:08: [2024-10-29 12:05:08] iter = 16990, loss = 23.6576
2024-10-29 12:05:08: [2024-10-29 12:05:08] iter = 17000, loss = 10.0818
2024-10-29 12:05:09: [2024-10-29 12:05:09] iter = 17010, loss = 10.0857
2024-10-29 12:05:09: [2024-10-29 12:05:09] iter = 17020, loss = 9.2159
2024-10-29 12:05:10: [2024-10-29 12:05:10] iter = 17030, loss = 10.4276
2024-10-29 12:05:10: [2024-10-29 12:05:10] iter = 17040, loss = 14.8197
2024-10-29 12:05:10: [2024-10-29 12:05:10] iter = 17050, loss = 4.6664
2024-10-29 12:05:11: [2024-10-29 12:05:11] iter = 17060, loss = 3.5045
2024-10-29 12:05:11: [2024-10-29 12:05:11] iter = 17070, loss = 6.2623
2024-10-29 12:05:12: [2024-10-29 12:05:12] iter = 17080, loss = 5.4287
2024-10-29 12:05:12: [2024-10-29 12:05:12] iter = 17090, loss = 3.5171
2024-10-29 12:05:13: [2024-10-29 12:05:13] iter = 17100, loss = 2.9381
2024-10-29 12:05:13: [2024-10-29 12:05:13] iter = 17110, loss = 2.7234
2024-10-29 12:05:13: [2024-10-29 12:05:13] iter = 17120, loss = 8.3597
2024-10-29 12:05:14: [2024-10-29 12:05:14] iter = 17130, loss = 11.3391
2024-10-29 12:05:14: [2024-10-29 12:05:14] iter = 17140, loss = 7.9777
2024-10-29 12:05:15: [2024-10-29 12:05:15] iter = 17150, loss = 4.8218
2024-10-29 12:05:15: [2024-10-29 12:05:15] iter = 17160, loss = 9.3883
2024-10-29 12:05:16: [2024-10-29 12:05:16] iter = 17170, loss = 7.0048
2024-10-29 12:05:16: [2024-10-29 12:05:16] iter = 17180, loss = 4.8204
2024-10-29 12:05:16: [2024-10-29 12:05:16] iter = 17190, loss = 3.2260
2024-10-29 12:05:17: [2024-10-29 12:05:17] iter = 17200, loss = 4.0460
2024-10-29 12:05:17: [2024-10-29 12:05:17] iter = 17210, loss = 2.8434
2024-10-29 12:05:17: [2024-10-29 12:05:17] iter = 17220, loss = 29.4578
2024-10-29 12:05:18: [2024-10-29 12:05:18] iter = 17230, loss = 11.2459
2024-10-29 12:05:18: [2024-10-29 12:05:18] iter = 17240, loss = 23.6743
2024-10-29 12:05:19: [2024-10-29 12:05:19] iter = 17250, loss = 17.5983
2024-10-29 12:05:19: [2024-10-29 12:05:19] iter = 17260, loss = 3.7015
2024-10-29 12:05:19: [2024-10-29 12:05:19] iter = 17270, loss = 3.7248
2024-10-29 12:05:20: [2024-10-29 12:05:20] iter = 17280, loss = 2.5735
2024-10-29 12:05:20: [2024-10-29 12:05:20] iter = 17290, loss = 3.9579
2024-10-29 12:05:21: [2024-10-29 12:05:21] iter = 17300, loss = 5.5476
2024-10-29 12:05:21: [2024-10-29 12:05:21] iter = 17310, loss = 8.6824
2024-10-29 12:05:22: [2024-10-29 12:05:22] iter = 17320, loss = 6.5063
2024-10-29 12:05:22: [2024-10-29 12:05:22] iter = 17330, loss = 2.8183
2024-10-29 12:05:22: [2024-10-29 12:05:22] iter = 17340, loss = 4.2928
2024-10-29 12:05:23: [2024-10-29 12:05:23] iter = 17350, loss = 12.2821
2024-10-29 12:05:23: [2024-10-29 12:05:23] iter = 17360, loss = 2.6905
2024-10-29 12:05:24: [2024-10-29 12:05:24] iter = 17370, loss = 9.6065
2024-10-29 12:05:24: [2024-10-29 12:05:24] iter = 17380, loss = 7.8152
2024-10-29 12:05:24: [2024-10-29 12:05:24] iter = 17390, loss = 31.0711
2024-10-29 12:05:25: [2024-10-29 12:05:25] iter = 17400, loss = 40.1844
2024-10-29 12:05:25: [2024-10-29 12:05:25] iter = 17410, loss = 3.7335
2024-10-29 12:05:26: [2024-10-29 12:05:26] iter = 17420, loss = 3.4364
2024-10-29 12:05:26: [2024-10-29 12:05:26] iter = 17430, loss = 5.6355
2024-10-29 12:05:26: [2024-10-29 12:05:26] iter = 17440, loss = 3.8723
2024-10-29 12:05:27: [2024-10-29 12:05:27] iter = 17450, loss = 15.2048
2024-10-29 12:05:27: [2024-10-29 12:05:27] iter = 17460, loss = 5.5856
2024-10-29 12:05:28: [2024-10-29 12:05:28] iter = 17470, loss = 50.0586
2024-10-29 12:05:28: [2024-10-29 12:05:28] iter = 17480, loss = 15.8908
2024-10-29 12:05:29: [2024-10-29 12:05:29] iter = 17490, loss = 8.4676
2024-10-29 12:05:29: [2024-10-29 12:05:29] iter = 17500, loss = 9.7806
2024-10-29 12:05:30: [2024-10-29 12:05:30] iter = 17510, loss = 14.0258
2024-10-29 12:05:30: [2024-10-29 12:05:30] iter = 17520, loss = 4.7081
2024-10-29 12:05:31: [2024-10-29 12:05:31] iter = 17530, loss = 10.6291
2024-10-29 12:05:31: [2024-10-29 12:05:31] iter = 17540, loss = 3.6274
2024-10-29 12:05:32: [2024-10-29 12:05:32] iter = 17550, loss = 3.3334
2024-10-29 12:05:32: [2024-10-29 12:05:32] iter = 17560, loss = 5.6548
2024-10-29 12:05:33: [2024-10-29 12:05:33] iter = 17570, loss = 7.7477
2024-10-29 12:05:33: [2024-10-29 12:05:33] iter = 17580, loss = 14.8297
2024-10-29 12:05:33: [2024-10-29 12:05:33] iter = 17590, loss = 3.2360
2024-10-29 12:05:34: [2024-10-29 12:05:34] iter = 17600, loss = 4.0955
2024-10-29 12:05:34: [2024-10-29 12:05:34] iter = 17610, loss = 3.5795
2024-10-29 12:05:35: [2024-10-29 12:05:35] iter = 17620, loss = 8.4551
2024-10-29 12:05:35: [2024-10-29 12:05:35] iter = 17630, loss = 6.8419
2024-10-29 12:05:35: [2024-10-29 12:05:35] iter = 17640, loss = 4.1065
2024-10-29 12:05:36: [2024-10-29 12:05:36] iter = 17650, loss = 22.2070
2024-10-29 12:05:36: [2024-10-29 12:05:36] iter = 17660, loss = 28.4392
2024-10-29 12:05:37: [2024-10-29 12:05:37] iter = 17670, loss = 12.7121
2024-10-29 12:05:37: [2024-10-29 12:05:37] iter = 17680, loss = 10.6078
2024-10-29 12:05:38: [2024-10-29 12:05:38] iter = 17690, loss = 6.9687
2024-10-29 12:05:38: [2024-10-29 12:05:38] iter = 17700, loss = 2.0593
2024-10-29 12:05:39: [2024-10-29 12:05:39] iter = 17710, loss = 8.9427
2024-10-29 12:05:39: [2024-10-29 12:05:39] iter = 17720, loss = 13.2598
2024-10-29 12:05:40: [2024-10-29 12:05:40] iter = 17730, loss = 4.4089
2024-10-29 12:05:40: [2024-10-29 12:05:40] iter = 17740, loss = 5.2105
2024-10-29 12:05:40: [2024-10-29 12:05:40] iter = 17750, loss = 5.8290
2024-10-29 12:05:41: [2024-10-29 12:05:41] iter = 17760, loss = 3.1593
2024-10-29 12:05:41: [2024-10-29 12:05:41] iter = 17770, loss = 5.9516
2024-10-29 12:05:41: [2024-10-29 12:05:41] iter = 17780, loss = 12.5617
2024-10-29 12:05:42: [2024-10-29 12:05:42] iter = 17790, loss = 15.0945
2024-10-29 12:05:42: [2024-10-29 12:05:42] iter = 17800, loss = 2.8564
2024-10-29 12:05:43: [2024-10-29 12:05:43] iter = 17810, loss = 4.2853
2024-10-29 12:05:43: [2024-10-29 12:05:43] iter = 17820, loss = 33.8546
2024-10-29 12:05:43: [2024-10-29 12:05:43] iter = 17830, loss = 3.3389
2024-10-29 12:05:44: [2024-10-29 12:05:44] iter = 17840, loss = 4.0890
2024-10-29 12:05:44: [2024-10-29 12:05:44] iter = 17850, loss = 5.1223
2024-10-29 12:05:45: [2024-10-29 12:05:45] iter = 17860, loss = 7.7003
2024-10-29 12:05:45: [2024-10-29 12:05:45] iter = 17870, loss = 15.4493
2024-10-29 12:05:46: [2024-10-29 12:05:46] iter = 17880, loss = 9.0226
2024-10-29 12:05:46: [2024-10-29 12:05:46] iter = 17890, loss = 5.5656
2024-10-29 12:05:47: [2024-10-29 12:05:47] iter = 17900, loss = 14.6051
2024-10-29 12:05:47: [2024-10-29 12:05:47] iter = 17910, loss = 7.3439
2024-10-29 12:05:48: [2024-10-29 12:05:48] iter = 17920, loss = 9.6367
2024-10-29 12:05:48: [2024-10-29 12:05:48] iter = 17930, loss = 2.8803
2024-10-29 12:05:49: [2024-10-29 12:05:49] iter = 17940, loss = 5.5523
2024-10-29 12:05:49: [2024-10-29 12:05:49] iter = 17950, loss = 2.1381
2024-10-29 12:05:50: [2024-10-29 12:05:50] iter = 17960, loss = 37.3973
2024-10-29 12:05:50: [2024-10-29 12:05:50] iter = 17970, loss = 7.3254
2024-10-29 12:05:51: [2024-10-29 12:05:51] iter = 17980, loss = 3.9081
2024-10-29 12:05:51: [2024-10-29 12:05:51] iter = 17990, loss = 13.2937
2024-10-29 12:05:51: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 12:05:51: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:05:51: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 51931}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:06:15: Evaluate 5 random ConvNet, ACCmean = 0.4374 ACCstd = 0.0049
-------------------------
2024-10-29 12:06:15: Evaluate 5 random ConvNet, SENmean = 0.4374 SENstd = 0.0049
-------------------------
2024-10-29 12:06:15: Evaluate 5 random ConvNet, SPEmean = 0.8125 SPEstd = 0.0016
-------------------------
2024-10-29 12:06:15: Evaluate 5 random ConvNet, F!mean = 0.3484 F!std = 0.0093
-------------------------
2024-10-29 12:06:15: Evaluate 5 random ConvNet, mean = 0.4374 std = 0.0049
-------------------------
2024-10-29 12:06:15: [2024-10-29 12:06:15] iter = 18000, loss = 2.9439
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:06:15: [2024-10-29 12:06:15] iter = 18010, loss = 28.1967
2024-10-29 12:06:15: [2024-10-29 12:06:15] iter = 18020, loss = 30.3754
2024-10-29 12:06:16: [2024-10-29 12:06:16] iter = 18030, loss = 5.4460
2024-10-29 12:06:16: [2024-10-29 12:06:16] iter = 18040, loss = 3.0527
2024-10-29 12:06:17: [2024-10-29 12:06:17] iter = 18050, loss = 9.3481
2024-10-29 12:06:17: [2024-10-29 12:06:17] iter = 18060, loss = 9.2119
2024-10-29 12:06:18: [2024-10-29 12:06:18] iter = 18070, loss = 6.0804
2024-10-29 12:06:18: [2024-10-29 12:06:18] iter = 18080, loss = 2.5944
2024-10-29 12:06:19: [2024-10-29 12:06:19] iter = 18090, loss = 3.1114
2024-10-29 12:06:19: [2024-10-29 12:06:19] iter = 18100, loss = 4.7322
2024-10-29 12:06:19: [2024-10-29 12:06:19] iter = 18110, loss = 4.7666
2024-10-29 12:06:20: [2024-10-29 12:06:20] iter = 18120, loss = 8.6490
2024-10-29 12:06:20: [2024-10-29 12:06:20] iter = 18130, loss = 29.1084
2024-10-29 12:06:20: [2024-10-29 12:06:20] iter = 18140, loss = 7.5834
2024-10-29 12:06:21: [2024-10-29 12:06:21] iter = 18150, loss = 29.6377
2024-10-29 12:06:21: [2024-10-29 12:06:21] iter = 18160, loss = 5.9175
2024-10-29 12:06:22: [2024-10-29 12:06:22] iter = 18170, loss = 3.7613
2024-10-29 12:06:22: [2024-10-29 12:06:22] iter = 18180, loss = 3.1285
2024-10-29 12:06:22: [2024-10-29 12:06:22] iter = 18190, loss = 4.4087
2024-10-29 12:06:23: [2024-10-29 12:06:23] iter = 18200, loss = 8.8799
2024-10-29 12:06:23: [2024-10-29 12:06:23] iter = 18210, loss = 5.5935
2024-10-29 12:06:24: [2024-10-29 12:06:24] iter = 18220, loss = 3.2594
2024-10-29 12:06:24: [2024-10-29 12:06:24] iter = 18230, loss = 11.1665
2024-10-29 12:06:25: [2024-10-29 12:06:25] iter = 18240, loss = 3.1720
2024-10-29 12:06:25: [2024-10-29 12:06:25] iter = 18250, loss = 10.6719
2024-10-29 12:06:26: [2024-10-29 12:06:26] iter = 18260, loss = 5.8004
2024-10-29 12:06:26: [2024-10-29 12:06:26] iter = 18270, loss = 7.6305
2024-10-29 12:06:27: [2024-10-29 12:06:27] iter = 18280, loss = 5.6256
2024-10-29 12:06:27: [2024-10-29 12:06:27] iter = 18290, loss = 3.9684
2024-10-29 12:06:27: [2024-10-29 12:06:27] iter = 18300, loss = 13.3880
2024-10-29 12:06:28: [2024-10-29 12:06:28] iter = 18310, loss = 3.6178
2024-10-29 12:06:28: [2024-10-29 12:06:28] iter = 18320, loss = 4.4350
2024-10-29 12:06:29: [2024-10-29 12:06:29] iter = 18330, loss = 16.4797
2024-10-29 12:06:29: [2024-10-29 12:06:29] iter = 18340, loss = 24.4222
2024-10-29 12:06:29: [2024-10-29 12:06:29] iter = 18350, loss = 3.2177
2024-10-29 12:06:30: [2024-10-29 12:06:30] iter = 18360, loss = 9.9402
2024-10-29 12:06:30: [2024-10-29 12:06:30] iter = 18370, loss = 4.4962
2024-10-29 12:06:31: [2024-10-29 12:06:31] iter = 18380, loss = 20.0786
2024-10-29 12:06:31: [2024-10-29 12:06:31] iter = 18390, loss = 3.6774
2024-10-29 12:06:32: [2024-10-29 12:06:32] iter = 18400, loss = 17.5693
2024-10-29 12:06:32: [2024-10-29 12:06:32] iter = 18410, loss = 21.2315
2024-10-29 12:06:32: [2024-10-29 12:06:32] iter = 18420, loss = 3.1256
2024-10-29 12:06:33: [2024-10-29 12:06:33] iter = 18430, loss = 3.5645
2024-10-29 12:06:33: [2024-10-29 12:06:33] iter = 18440, loss = 3.0335
2024-10-29 12:06:34: [2024-10-29 12:06:34] iter = 18450, loss = 4.4045
2024-10-29 12:06:34: [2024-10-29 12:06:34] iter = 18460, loss = 4.0540
2024-10-29 12:06:35: [2024-10-29 12:06:35] iter = 18470, loss = 22.8903
2024-10-29 12:06:35: [2024-10-29 12:06:35] iter = 18480, loss = 4.3721
2024-10-29 12:06:35: [2024-10-29 12:06:35] iter = 18490, loss = 18.7114
2024-10-29 12:06:36: [2024-10-29 12:06:36] iter = 18500, loss = 4.2682
2024-10-29 12:06:36: [2024-10-29 12:06:36] iter = 18510, loss = 5.2210
2024-10-29 12:06:37: [2024-10-29 12:06:37] iter = 18520, loss = 4.9423
2024-10-29 12:06:37: [2024-10-29 12:06:37] iter = 18530, loss = 9.0386
2024-10-29 12:06:37: [2024-10-29 12:06:37] iter = 18540, loss = 3.3179
2024-10-29 12:06:38: [2024-10-29 12:06:38] iter = 18550, loss = 64.3845
2024-10-29 12:06:38: [2024-10-29 12:06:38] iter = 18560, loss = 2.5811
2024-10-29 12:06:39: [2024-10-29 12:06:39] iter = 18570, loss = 7.8036
2024-10-29 12:06:39: [2024-10-29 12:06:39] iter = 18580, loss = 4.1254
2024-10-29 12:06:40: [2024-10-29 12:06:40] iter = 18590, loss = 9.9993
2024-10-29 12:06:40: [2024-10-29 12:06:40] iter = 18600, loss = 3.6280
2024-10-29 12:06:41: [2024-10-29 12:06:41] iter = 18610, loss = 7.1622
2024-10-29 12:06:41: [2024-10-29 12:06:41] iter = 18620, loss = 8.7272
2024-10-29 12:06:41: [2024-10-29 12:06:41] iter = 18630, loss = 6.8961
2024-10-29 12:06:42: [2024-10-29 12:06:42] iter = 18640, loss = 5.6156
2024-10-29 12:06:42: [2024-10-29 12:06:42] iter = 18650, loss = 2.5797
2024-10-29 12:06:43: [2024-10-29 12:06:43] iter = 18660, loss = 2.8504
2024-10-29 12:06:43: [2024-10-29 12:06:43] iter = 18670, loss = 4.5556
2024-10-29 12:06:44: [2024-10-29 12:06:44] iter = 18680, loss = 3.4477
2024-10-29 12:06:44: [2024-10-29 12:06:44] iter = 18690, loss = 5.0891
2024-10-29 12:06:45: [2024-10-29 12:06:45] iter = 18700, loss = 12.2666
2024-10-29 12:06:45: [2024-10-29 12:06:45] iter = 18710, loss = 2.6429
2024-10-29 12:06:46: [2024-10-29 12:06:46] iter = 18720, loss = 9.0490
2024-10-29 12:06:46: [2024-10-29 12:06:46] iter = 18730, loss = 8.7999
2024-10-29 12:06:47: [2024-10-29 12:06:47] iter = 18740, loss = 42.2306
2024-10-29 12:06:47: [2024-10-29 12:06:47] iter = 18750, loss = 51.3160
2024-10-29 12:06:47: [2024-10-29 12:06:47] iter = 18760, loss = 5.2680
2024-10-29 12:06:48: [2024-10-29 12:06:48] iter = 18770, loss = 6.0894
2024-10-29 12:06:48: [2024-10-29 12:06:48] iter = 18780, loss = 4.3895
2024-10-29 12:06:48: [2024-10-29 12:06:48] iter = 18790, loss = 33.8026
2024-10-29 12:06:49: [2024-10-29 12:06:49] iter = 18800, loss = 4.9641
2024-10-29 12:06:49: [2024-10-29 12:06:49] iter = 18810, loss = 8.0643
2024-10-29 12:06:50: [2024-10-29 12:06:50] iter = 18820, loss = 24.0037
2024-10-29 12:06:50: [2024-10-29 12:06:50] iter = 18830, loss = 3.8298
2024-10-29 12:06:50: [2024-10-29 12:06:50] iter = 18840, loss = 6.0407
2024-10-29 12:06:51: [2024-10-29 12:06:51] iter = 18850, loss = 6.4829
2024-10-29 12:06:51: [2024-10-29 12:06:51] iter = 18860, loss = 4.3514
2024-10-29 12:06:52: [2024-10-29 12:06:52] iter = 18870, loss = 10.9726
2024-10-29 12:06:52: [2024-10-29 12:06:52] iter = 18880, loss = 3.6327
2024-10-29 12:06:53: [2024-10-29 12:06:53] iter = 18890, loss = 7.8673
2024-10-29 12:06:53: [2024-10-29 12:06:53] iter = 18900, loss = 2.8118
2024-10-29 12:06:54: [2024-10-29 12:06:54] iter = 18910, loss = 4.0635
2024-10-29 12:06:54: [2024-10-29 12:06:54] iter = 18920, loss = 5.4717
2024-10-29 12:06:55: [2024-10-29 12:06:55] iter = 18930, loss = 4.9170
2024-10-29 12:06:55: [2024-10-29 12:06:55] iter = 18940, loss = 3.7468
2024-10-29 12:06:56: [2024-10-29 12:06:56] iter = 18950, loss = 3.6989
2024-10-29 12:06:56: [2024-10-29 12:06:56] iter = 18960, loss = 3.4344
2024-10-29 12:06:57: [2024-10-29 12:06:57] iter = 18970, loss = 3.9812
2024-10-29 12:06:57: [2024-10-29 12:06:57] iter = 18980, loss = 3.7179
2024-10-29 12:06:58: [2024-10-29 12:06:58] iter = 18990, loss = 14.5843
2024-10-29 12:06:58: [2024-10-29 12:06:58] iter = 19000, loss = 3.6108
2024-10-29 12:06:59: [2024-10-29 12:06:59] iter = 19010, loss = 4.0604
2024-10-29 12:06:59: [2024-10-29 12:06:59] iter = 19020, loss = 3.6189
2024-10-29 12:06:59: [2024-10-29 12:06:59] iter = 19030, loss = 4.8258
2024-10-29 12:07:00: [2024-10-29 12:07:00] iter = 19040, loss = 7.7728
2024-10-29 12:07:00: [2024-10-29 12:07:00] iter = 19050, loss = 4.4746
2024-10-29 12:07:01: [2024-10-29 12:07:01] iter = 19060, loss = 3.5460
2024-10-29 12:07:01: [2024-10-29 12:07:01] iter = 19070, loss = 6.3006
2024-10-29 12:07:02: [2024-10-29 12:07:02] iter = 19080, loss = 8.1801
2024-10-29 12:07:02: [2024-10-29 12:07:02] iter = 19090, loss = 2.8509
2024-10-29 12:07:02: [2024-10-29 12:07:02] iter = 19100, loss = 7.9203
2024-10-29 12:07:03: [2024-10-29 12:07:03] iter = 19110, loss = 5.4725
2024-10-29 12:07:04: [2024-10-29 12:07:04] iter = 19120, loss = 3.1476
2024-10-29 12:07:04: [2024-10-29 12:07:04] iter = 19130, loss = 19.9567
2024-10-29 12:07:05: [2024-10-29 12:07:05] iter = 19140, loss = 4.7629
2024-10-29 12:07:05: [2024-10-29 12:07:05] iter = 19150, loss = 6.3177
2024-10-29 12:07:05: [2024-10-29 12:07:05] iter = 19160, loss = 2.4757
2024-10-29 12:07:06: [2024-10-29 12:07:06] iter = 19170, loss = 11.4603
2024-10-29 12:07:06: [2024-10-29 12:07:06] iter = 19180, loss = 20.0304
2024-10-29 12:07:07: [2024-10-29 12:07:07] iter = 19190, loss = 4.6190
2024-10-29 12:07:07: [2024-10-29 12:07:07] iter = 19200, loss = 4.0400
2024-10-29 12:07:08: [2024-10-29 12:07:08] iter = 19210, loss = 7.8984
2024-10-29 12:07:08: [2024-10-29 12:07:08] iter = 19220, loss = 10.8291
2024-10-29 12:07:09: [2024-10-29 12:07:09] iter = 19230, loss = 7.7782
2024-10-29 12:07:09: [2024-10-29 12:07:09] iter = 19240, loss = 61.6934
2024-10-29 12:07:09: [2024-10-29 12:07:09] iter = 19250, loss = 2.7168
2024-10-29 12:07:10: [2024-10-29 12:07:10] iter = 19260, loss = 3.0255
2024-10-29 12:07:10: [2024-10-29 12:07:10] iter = 19270, loss = 4.9558
2024-10-29 12:07:10: [2024-10-29 12:07:10] iter = 19280, loss = 5.6606
2024-10-29 12:07:11: [2024-10-29 12:07:11] iter = 19290, loss = 7.6022
2024-10-29 12:07:11: [2024-10-29 12:07:11] iter = 19300, loss = 10.5026
2024-10-29 12:07:11: [2024-10-29 12:07:11] iter = 19310, loss = 7.6253
2024-10-29 12:07:12: [2024-10-29 12:07:12] iter = 19320, loss = 5.3223
2024-10-29 12:07:12: [2024-10-29 12:07:12] iter = 19330, loss = 3.2457
2024-10-29 12:07:13: [2024-10-29 12:07:13] iter = 19340, loss = 5.0929
2024-10-29 12:07:13: [2024-10-29 12:07:13] iter = 19350, loss = 9.9495
2024-10-29 12:07:14: [2024-10-29 12:07:14] iter = 19360, loss = 6.2842
2024-10-29 12:07:14: [2024-10-29 12:07:14] iter = 19370, loss = 8.3959
2024-10-29 12:07:15: [2024-10-29 12:07:15] iter = 19380, loss = 34.9373
2024-10-29 12:07:15: [2024-10-29 12:07:15] iter = 19390, loss = 14.1836
2024-10-29 12:07:15: [2024-10-29 12:07:15] iter = 19400, loss = 3.1069
2024-10-29 12:07:16: [2024-10-29 12:07:16] iter = 19410, loss = 6.2489
2024-10-29 12:07:16: [2024-10-29 12:07:16] iter = 19420, loss = 3.1215
2024-10-29 12:07:17: [2024-10-29 12:07:17] iter = 19430, loss = 9.0581
2024-10-29 12:07:17: [2024-10-29 12:07:17] iter = 19440, loss = 30.5950
2024-10-29 12:07:18: [2024-10-29 12:07:18] iter = 19450, loss = 24.1496
2024-10-29 12:07:18: [2024-10-29 12:07:18] iter = 19460, loss = 2.3417
2024-10-29 12:07:19: [2024-10-29 12:07:19] iter = 19470, loss = 21.0571
2024-10-29 12:07:19: [2024-10-29 12:07:19] iter = 19480, loss = 7.0620
2024-10-29 12:07:20: [2024-10-29 12:07:20] iter = 19490, loss = 5.9700
2024-10-29 12:07:20: [2024-10-29 12:07:20] iter = 19500, loss = 4.8204
2024-10-29 12:07:20: [2024-10-29 12:07:20] iter = 19510, loss = 7.1890
2024-10-29 12:07:21: [2024-10-29 12:07:21] iter = 19520, loss = 12.8729
2024-10-29 12:07:21: [2024-10-29 12:07:21] iter = 19530, loss = 2.4827
2024-10-29 12:07:22: [2024-10-29 12:07:22] iter = 19540, loss = 14.8026
2024-10-29 12:07:22: [2024-10-29 12:07:22] iter = 19550, loss = 2.9060
2024-10-29 12:07:23: [2024-10-29 12:07:22] iter = 19560, loss = 6.6074
2024-10-29 12:07:23: [2024-10-29 12:07:23] iter = 19570, loss = 3.6145
2024-10-29 12:07:23: [2024-10-29 12:07:23] iter = 19580, loss = 31.9298
2024-10-29 12:07:24: [2024-10-29 12:07:24] iter = 19590, loss = 4.8165
2024-10-29 12:07:24: [2024-10-29 12:07:24] iter = 19600, loss = 3.5329
2024-10-29 12:07:25: [2024-10-29 12:07:25] iter = 19610, loss = 22.3256
2024-10-29 12:07:25: [2024-10-29 12:07:25] iter = 19620, loss = 20.7599
2024-10-29 12:07:26: [2024-10-29 12:07:26] iter = 19630, loss = 3.0489
2024-10-29 12:07:26: [2024-10-29 12:07:26] iter = 19640, loss = 17.7479
2024-10-29 12:07:27: [2024-10-29 12:07:27] iter = 19650, loss = 3.8352
2024-10-29 12:07:27: [2024-10-29 12:07:27] iter = 19660, loss = 3.1229
2024-10-29 12:07:27: [2024-10-29 12:07:27] iter = 19670, loss = 41.6971
2024-10-29 12:07:28: [2024-10-29 12:07:28] iter = 19680, loss = 5.1153
2024-10-29 12:07:28: [2024-10-29 12:07:28] iter = 19690, loss = 7.1216
2024-10-29 12:07:29: [2024-10-29 12:07:29] iter = 19700, loss = 3.6892
2024-10-29 12:07:29: [2024-10-29 12:07:29] iter = 19710, loss = 3.9845
2024-10-29 12:07:29: [2024-10-29 12:07:29] iter = 19720, loss = 19.6798
2024-10-29 12:07:30: [2024-10-29 12:07:30] iter = 19730, loss = 5.0315
2024-10-29 12:07:30: [2024-10-29 12:07:30] iter = 19740, loss = 11.7705
2024-10-29 12:07:31: [2024-10-29 12:07:31] iter = 19750, loss = 11.0280
2024-10-29 12:07:31: [2024-10-29 12:07:31] iter = 19760, loss = 3.7668
2024-10-29 12:07:32: [2024-10-29 12:07:32] iter = 19770, loss = 7.1995
2024-10-29 12:07:32: [2024-10-29 12:07:32] iter = 19780, loss = 8.7511
2024-10-29 12:07:33: [2024-10-29 12:07:33] iter = 19790, loss = 16.1608
2024-10-29 12:07:33: [2024-10-29 12:07:33] iter = 19800, loss = 6.0459
2024-10-29 12:07:34: [2024-10-29 12:07:34] iter = 19810, loss = 4.4977
2024-10-29 12:07:34: [2024-10-29 12:07:34] iter = 19820, loss = 1.7818
2024-10-29 12:07:34: [2024-10-29 12:07:34] iter = 19830, loss = 17.7682
2024-10-29 12:07:35: [2024-10-29 12:07:35] iter = 19840, loss = 4.7044
2024-10-29 12:07:35: [2024-10-29 12:07:35] iter = 19850, loss = 3.0973
2024-10-29 12:07:36: [2024-10-29 12:07:36] iter = 19860, loss = 6.5494
2024-10-29 12:07:36: [2024-10-29 12:07:36] iter = 19870, loss = 2.7967
2024-10-29 12:07:37: [2024-10-29 12:07:37] iter = 19880, loss = 8.4367
2024-10-29 12:07:37: [2024-10-29 12:07:37] iter = 19890, loss = 25.1190
2024-10-29 12:07:38: [2024-10-29 12:07:38] iter = 19900, loss = 10.4570
2024-10-29 12:07:38: [2024-10-29 12:07:38] iter = 19910, loss = 7.4669
2024-10-29 12:07:39: [2024-10-29 12:07:39] iter = 19920, loss = 4.0450
2024-10-29 12:07:39: [2024-10-29 12:07:39] iter = 19930, loss = 7.9905
2024-10-29 12:07:39: [2024-10-29 12:07:39] iter = 19940, loss = 16.7311
2024-10-29 12:07:40: [2024-10-29 12:07:40] iter = 19950, loss = 43.8441
2024-10-29 12:07:40: [2024-10-29 12:07:40] iter = 19960, loss = 5.3726
2024-10-29 12:07:41: [2024-10-29 12:07:41] iter = 19970, loss = 14.5766
2024-10-29 12:07:41: [2024-10-29 12:07:41] iter = 19980, loss = 5.3645
2024-10-29 12:07:41: [2024-10-29 12:07:41] iter = 19990, loss = 57.2383
2024-10-29 12:07:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 12:07:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:07:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62359}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:08:07: Evaluate 5 random ConvNet, ACCmean = 0.5408 ACCstd = 0.0145
-------------------------
2024-10-29 12:08:07: Evaluate 5 random ConvNet, SENmean = 0.5408 SENstd = 0.0145
-------------------------
2024-10-29 12:08:07: Evaluate 5 random ConvNet, SPEmean = 0.8469 SPEstd = 0.0048
-------------------------
2024-10-29 12:08:07: Evaluate 5 random ConvNet, F!mean = 0.5189 F!std = 0.0144
-------------------------
2024-10-29 12:08:07: Evaluate 5 random ConvNet, mean = 0.5408 std = 0.0145
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:08:07: [2024-10-29 12:08:07] iter = 20000, loss = 4.0545
2024-10-29 12:08:07: 
================== Exp 1 ==================
 
2024-10-29 12:08:07: Hyper-parameters: 
{'dataset': 'OCTMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faf200e8730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OCTMNIST (INFO)>}
2024-10-29 12:08:07: Evaluation model pool: ['ConvNet']
2024-10-29 12:08:09: class c = 0: 33484 real images
2024-10-29 12:08:09: class c = 1: 10213 real images
2024-10-29 12:08:09: class c = 2: 7754 real images
2024-10-29 12:08:09: class c = 3: 46026 real images
2024-10-29 12:08:09: real images channel 0, mean = 0.1889, std = 0.1963
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 12:08:09: initialize synthetic data from random real images
2024-10-29 12:08:09: [2024-10-29 12:08:09] training begins
2024-10-29 12:08:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 12:08:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:08:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87040}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:08:32: Evaluate 5 random ConvNet, ACCmean = 0.4108 ACCstd = 0.0037
-------------------------
2024-10-29 12:08:32: Evaluate 5 random ConvNet, SENmean = 0.4108 SENstd = 0.0037
-------------------------
2024-10-29 12:08:32: Evaluate 5 random ConvNet, SPEmean = 0.8036 SPEstd = 0.0012
-------------------------
2024-10-29 12:08:32: Evaluate 5 random ConvNet, F!mean = 0.4140 F!std = 0.0032
-------------------------
2024-10-29 12:08:32: Evaluate 5 random ConvNet, mean = 0.4108 std = 0.0037
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:08:32: [2024-10-29 12:08:32] iter = 00000, loss = 23.0765
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:08:33: [2024-10-29 12:08:33] iter = 00010, loss = 18.8486
2024-10-29 12:08:33: [2024-10-29 12:08:33] iter = 00020, loss = 11.9772
2024-10-29 12:08:34: [2024-10-29 12:08:34] iter = 00030, loss = 45.8634
2024-10-29 12:08:34: [2024-10-29 12:08:34] iter = 00040, loss = 6.4524
2024-10-29 12:08:35: [2024-10-29 12:08:35] iter = 00050, loss = 24.0364
2024-10-29 12:08:35: [2024-10-29 12:08:35] iter = 00060, loss = 10.6118
2024-10-29 12:08:35: [2024-10-29 12:08:35] iter = 00070, loss = 5.0202
2024-10-29 12:08:36: [2024-10-29 12:08:36] iter = 00080, loss = 6.3861
2024-10-29 12:08:36: [2024-10-29 12:08:36] iter = 00090, loss = 14.7794
2024-10-29 12:08:37: [2024-10-29 12:08:37] iter = 00100, loss = 4.9380
2024-10-29 12:08:37: [2024-10-29 12:08:37] iter = 00110, loss = 3.0647
2024-10-29 12:08:38: [2024-10-29 12:08:38] iter = 00120, loss = 4.0714
2024-10-29 12:08:38: [2024-10-29 12:08:38] iter = 00130, loss = 5.3715
2024-10-29 12:08:38: [2024-10-29 12:08:38] iter = 00140, loss = 9.8839
2024-10-29 12:08:39: [2024-10-29 12:08:39] iter = 00150, loss = 5.3276
2024-10-29 12:08:39: [2024-10-29 12:08:39] iter = 00160, loss = 5.1835
2024-10-29 12:08:40: [2024-10-29 12:08:40] iter = 00170, loss = 2.9672
2024-10-29 12:08:40: [2024-10-29 12:08:40] iter = 00180, loss = 3.6117
2024-10-29 12:08:41: [2024-10-29 12:08:41] iter = 00190, loss = 3.5135
2024-10-29 12:08:41: [2024-10-29 12:08:41] iter = 00200, loss = 3.1089
2024-10-29 12:08:42: [2024-10-29 12:08:42] iter = 00210, loss = 5.5702
2024-10-29 12:08:42: [2024-10-29 12:08:42] iter = 00220, loss = 2.7808
2024-10-29 12:08:43: [2024-10-29 12:08:43] iter = 00230, loss = 6.0666
2024-10-29 12:08:43: [2024-10-29 12:08:43] iter = 00240, loss = 38.2993
2024-10-29 12:08:43: [2024-10-29 12:08:43] iter = 00250, loss = 13.3994
2024-10-29 12:08:44: [2024-10-29 12:08:44] iter = 00260, loss = 6.0019
2024-10-29 12:08:44: [2024-10-29 12:08:44] iter = 00270, loss = 5.8435
2024-10-29 12:08:45: [2024-10-29 12:08:45] iter = 00280, loss = 9.6964
2024-10-29 12:08:45: [2024-10-29 12:08:45] iter = 00290, loss = 3.3916
2024-10-29 12:08:45: [2024-10-29 12:08:45] iter = 00300, loss = 7.2050
2024-10-29 12:08:46: [2024-10-29 12:08:46] iter = 00310, loss = 10.2637
2024-10-29 12:08:46: [2024-10-29 12:08:46] iter = 00320, loss = 4.8537
2024-10-29 12:08:47: [2024-10-29 12:08:47] iter = 00330, loss = 31.9832
2024-10-29 12:08:47: [2024-10-29 12:08:47] iter = 00340, loss = 6.5673
2024-10-29 12:08:48: [2024-10-29 12:08:48] iter = 00350, loss = 8.3283
2024-10-29 12:08:48: [2024-10-29 12:08:48] iter = 00360, loss = 5.6019
2024-10-29 12:08:48: [2024-10-29 12:08:48] iter = 00370, loss = 7.6415
2024-10-29 12:08:49: [2024-10-29 12:08:49] iter = 00380, loss = 3.4439
2024-10-29 12:08:49: [2024-10-29 12:08:49] iter = 00390, loss = 13.4204
2024-10-29 12:08:50: [2024-10-29 12:08:50] iter = 00400, loss = 3.6706
2024-10-29 12:08:50: [2024-10-29 12:08:50] iter = 00410, loss = 3.0615
2024-10-29 12:08:51: [2024-10-29 12:08:51] iter = 00420, loss = 4.7536
2024-10-29 12:08:51: [2024-10-29 12:08:51] iter = 00430, loss = 2.5955
2024-10-29 12:08:52: [2024-10-29 12:08:52] iter = 00440, loss = 3.3510
2024-10-29 12:08:52: [2024-10-29 12:08:52] iter = 00450, loss = 1.9287
2024-10-29 12:08:53: [2024-10-29 12:08:53] iter = 00460, loss = 3.6781
2024-10-29 12:08:53: [2024-10-29 12:08:53] iter = 00470, loss = 3.8655
2024-10-29 12:08:54: [2024-10-29 12:08:54] iter = 00480, loss = 4.0923
2024-10-29 12:08:54: [2024-10-29 12:08:54] iter = 00490, loss = 4.3994
2024-10-29 12:08:55: [2024-10-29 12:08:55] iter = 00500, loss = 15.8937
2024-10-29 12:08:55: [2024-10-29 12:08:55] iter = 00510, loss = 7.3549
2024-10-29 12:08:55: [2024-10-29 12:08:55] iter = 00520, loss = 24.1161
2024-10-29 12:08:56: [2024-10-29 12:08:56] iter = 00530, loss = 3.8375
2024-10-29 12:08:56: [2024-10-29 12:08:56] iter = 00540, loss = 3.4547
2024-10-29 12:08:57: [2024-10-29 12:08:57] iter = 00550, loss = 3.9667
2024-10-29 12:08:57: [2024-10-29 12:08:57] iter = 00560, loss = 3.5031
2024-10-29 12:08:58: [2024-10-29 12:08:58] iter = 00570, loss = 5.9704
2024-10-29 12:08:58: [2024-10-29 12:08:58] iter = 00580, loss = 4.2449
2024-10-29 12:08:59: [2024-10-29 12:08:59] iter = 00590, loss = 10.1878
2024-10-29 12:08:59: [2024-10-29 12:08:59] iter = 00600, loss = 3.9651
2024-10-29 12:08:59: [2024-10-29 12:08:59] iter = 00610, loss = 7.0199
2024-10-29 12:09:00: [2024-10-29 12:09:00] iter = 00620, loss = 8.0985
2024-10-29 12:09:00: [2024-10-29 12:09:00] iter = 00630, loss = 3.1987
2024-10-29 12:09:01: [2024-10-29 12:09:01] iter = 00640, loss = 2.7848
2024-10-29 12:09:01: [2024-10-29 12:09:01] iter = 00650, loss = 4.1620
2024-10-29 12:09:01: [2024-10-29 12:09:01] iter = 00660, loss = 7.7720
2024-10-29 12:09:02: [2024-10-29 12:09:02] iter = 00670, loss = 3.1513
2024-10-29 12:09:02: [2024-10-29 12:09:02] iter = 00680, loss = 3.7517
2024-10-29 12:09:03: [2024-10-29 12:09:03] iter = 00690, loss = 2.8811
2024-10-29 12:09:03: [2024-10-29 12:09:03] iter = 00700, loss = 6.7961
2024-10-29 12:09:03: [2024-10-29 12:09:03] iter = 00710, loss = 12.4439
2024-10-29 12:09:04: [2024-10-29 12:09:04] iter = 00720, loss = 31.7591
2024-10-29 12:09:04: [2024-10-29 12:09:04] iter = 00730, loss = 16.8546
2024-10-29 12:09:05: [2024-10-29 12:09:05] iter = 00740, loss = 4.2266
2024-10-29 12:09:05: [2024-10-29 12:09:05] iter = 00750, loss = 2.7956
2024-10-29 12:09:06: [2024-10-29 12:09:06] iter = 00760, loss = 5.5897
2024-10-29 12:09:06: [2024-10-29 12:09:06] iter = 00770, loss = 18.8374
2024-10-29 12:09:07: [2024-10-29 12:09:07] iter = 00780, loss = 3.4933
2024-10-29 12:09:07: [2024-10-29 12:09:07] iter = 00790, loss = 3.8121
2024-10-29 12:09:07: [2024-10-29 12:09:07] iter = 00800, loss = 4.3118
2024-10-29 12:09:08: [2024-10-29 12:09:08] iter = 00810, loss = 12.4413
2024-10-29 12:09:08: [2024-10-29 12:09:08] iter = 00820, loss = 3.6218
2024-10-29 12:09:09: [2024-10-29 12:09:09] iter = 00830, loss = 3.3046
2024-10-29 12:09:09: [2024-10-29 12:09:09] iter = 00840, loss = 27.7399
2024-10-29 12:09:10: [2024-10-29 12:09:10] iter = 00850, loss = 5.4012
2024-10-29 12:09:10: [2024-10-29 12:09:10] iter = 00860, loss = 32.9461
2024-10-29 12:09:11: [2024-10-29 12:09:11] iter = 00870, loss = 4.0937
2024-10-29 12:09:11: [2024-10-29 12:09:11] iter = 00880, loss = 5.9350
2024-10-29 12:09:12: [2024-10-29 12:09:12] iter = 00890, loss = 3.7086
2024-10-29 12:09:12: [2024-10-29 12:09:12] iter = 00900, loss = 2.2403
2024-10-29 12:09:13: [2024-10-29 12:09:13] iter = 00910, loss = 3.8275
2024-10-29 12:09:13: [2024-10-29 12:09:13] iter = 00920, loss = 2.8324
2024-10-29 12:09:14: [2024-10-29 12:09:14] iter = 00930, loss = 3.0049
2024-10-29 12:09:14: [2024-10-29 12:09:14] iter = 00940, loss = 5.0936
2024-10-29 12:09:15: [2024-10-29 12:09:15] iter = 00950, loss = 5.7029
2024-10-29 12:09:15: [2024-10-29 12:09:15] iter = 00960, loss = 6.3428
2024-10-29 12:09:16: [2024-10-29 12:09:16] iter = 00970, loss = 3.9106
2024-10-29 12:09:16: [2024-10-29 12:09:16] iter = 00980, loss = 5.2799
2024-10-29 12:09:17: [2024-10-29 12:09:17] iter = 00990, loss = 3.3113
2024-10-29 12:09:17: [2024-10-29 12:09:17] iter = 01000, loss = 11.3380
2024-10-29 12:09:17: [2024-10-29 12:09:17] iter = 01010, loss = 5.5599
2024-10-29 12:09:18: [2024-10-29 12:09:18] iter = 01020, loss = 23.1722
2024-10-29 12:09:18: [2024-10-29 12:09:18] iter = 01030, loss = 19.2605
2024-10-29 12:09:19: [2024-10-29 12:09:19] iter = 01040, loss = 25.0981
2024-10-29 12:09:19: [2024-10-29 12:09:19] iter = 01050, loss = 19.8674
2024-10-29 12:09:20: [2024-10-29 12:09:20] iter = 01060, loss = 4.0243
2024-10-29 12:09:20: [2024-10-29 12:09:20] iter = 01070, loss = 6.4540
2024-10-29 12:09:21: [2024-10-29 12:09:21] iter = 01080, loss = 13.1271
2024-10-29 12:09:21: [2024-10-29 12:09:21] iter = 01090, loss = 13.2928
2024-10-29 12:09:22: [2024-10-29 12:09:22] iter = 01100, loss = 6.7736
2024-10-29 12:09:22: [2024-10-29 12:09:22] iter = 01110, loss = 8.8372
2024-10-29 12:09:23: [2024-10-29 12:09:23] iter = 01120, loss = 2.7771
2024-10-29 12:09:23: [2024-10-29 12:09:23] iter = 01130, loss = 9.7120
2024-10-29 12:09:23: [2024-10-29 12:09:23] iter = 01140, loss = 18.4807
2024-10-29 12:09:24: [2024-10-29 12:09:24] iter = 01150, loss = 29.8652
2024-10-29 12:09:24: [2024-10-29 12:09:24] iter = 01160, loss = 2.7443
2024-10-29 12:09:24: [2024-10-29 12:09:24] iter = 01170, loss = 3.8366
2024-10-29 12:09:25: [2024-10-29 12:09:25] iter = 01180, loss = 2.8658
2024-10-29 12:09:25: [2024-10-29 12:09:25] iter = 01190, loss = 3.9682
2024-10-29 12:09:26: [2024-10-29 12:09:26] iter = 01200, loss = 9.5851
2024-10-29 12:09:26: [2024-10-29 12:09:26] iter = 01210, loss = 5.2013
2024-10-29 12:09:27: [2024-10-29 12:09:27] iter = 01220, loss = 3.4262
2024-10-29 12:09:27: [2024-10-29 12:09:27] iter = 01230, loss = 36.2278
2024-10-29 12:09:27: [2024-10-29 12:09:27] iter = 01240, loss = 16.1478
2024-10-29 12:09:28: [2024-10-29 12:09:28] iter = 01250, loss = 2.6151
2024-10-29 12:09:28: [2024-10-29 12:09:28] iter = 01260, loss = 3.7558
2024-10-29 12:09:29: [2024-10-29 12:09:29] iter = 01270, loss = 10.3027
2024-10-29 12:09:29: [2024-10-29 12:09:29] iter = 01280, loss = 4.8018
2024-10-29 12:09:30: [2024-10-29 12:09:30] iter = 01290, loss = 7.3255
2024-10-29 12:09:30: [2024-10-29 12:09:30] iter = 01300, loss = 5.2988
2024-10-29 12:09:30: [2024-10-29 12:09:30] iter = 01310, loss = 21.5636
2024-10-29 12:09:31: [2024-10-29 12:09:31] iter = 01320, loss = 3.6395
2024-10-29 12:09:31: [2024-10-29 12:09:31] iter = 01330, loss = 8.2834
2024-10-29 12:09:31: [2024-10-29 12:09:31] iter = 01340, loss = 11.3351
2024-10-29 12:09:32: [2024-10-29 12:09:32] iter = 01350, loss = 2.6484
2024-10-29 12:09:32: [2024-10-29 12:09:32] iter = 01360, loss = 32.2994
2024-10-29 12:09:33: [2024-10-29 12:09:33] iter = 01370, loss = 21.0018
2024-10-29 12:09:33: [2024-10-29 12:09:33] iter = 01380, loss = 6.3590
2024-10-29 12:09:34: [2024-10-29 12:09:34] iter = 01390, loss = 3.4603
2024-10-29 12:09:34: [2024-10-29 12:09:34] iter = 01400, loss = 3.1369
2024-10-29 12:09:35: [2024-10-29 12:09:35] iter = 01410, loss = 12.1391
2024-10-29 12:09:35: [2024-10-29 12:09:35] iter = 01420, loss = 11.7094
2024-10-29 12:09:36: [2024-10-29 12:09:36] iter = 01430, loss = 10.6919
2024-10-29 12:09:36: [2024-10-29 12:09:36] iter = 01440, loss = 4.1131
2024-10-29 12:09:36: [2024-10-29 12:09:36] iter = 01450, loss = 4.7243
2024-10-29 12:09:37: [2024-10-29 12:09:37] iter = 01460, loss = 3.0814
2024-10-29 12:09:37: [2024-10-29 12:09:37] iter = 01470, loss = 4.7256
2024-10-29 12:09:37: [2024-10-29 12:09:37] iter = 01480, loss = 3.7686
2024-10-29 12:09:38: [2024-10-29 12:09:38] iter = 01490, loss = 2.2305
2024-10-29 12:09:38: [2024-10-29 12:09:38] iter = 01500, loss = 5.7381
2024-10-29 12:09:39: [2024-10-29 12:09:39] iter = 01510, loss = 4.6764
2024-10-29 12:09:39: [2024-10-29 12:09:39] iter = 01520, loss = 79.5070
2024-10-29 12:09:40: [2024-10-29 12:09:40] iter = 01530, loss = 4.0827
2024-10-29 12:09:40: [2024-10-29 12:09:40] iter = 01540, loss = 3.5119
2024-10-29 12:09:40: [2024-10-29 12:09:40] iter = 01550, loss = 23.1463
2024-10-29 12:09:41: [2024-10-29 12:09:41] iter = 01560, loss = 22.8050
2024-10-29 12:09:41: [2024-10-29 12:09:41] iter = 01570, loss = 11.5146
2024-10-29 12:09:42: [2024-10-29 12:09:42] iter = 01580, loss = 37.1711
2024-10-29 12:09:42: [2024-10-29 12:09:42] iter = 01590, loss = 8.5214
2024-10-29 12:09:43: [2024-10-29 12:09:43] iter = 01600, loss = 3.0012
2024-10-29 12:09:43: [2024-10-29 12:09:43] iter = 01610, loss = 2.6066
2024-10-29 12:09:44: [2024-10-29 12:09:44] iter = 01620, loss = 8.1298
2024-10-29 12:09:44: [2024-10-29 12:09:44] iter = 01630, loss = 3.5628
2024-10-29 12:09:45: [2024-10-29 12:09:45] iter = 01640, loss = 2.3572
2024-10-29 12:09:45: [2024-10-29 12:09:45] iter = 01650, loss = 6.8496
2024-10-29 12:09:45: [2024-10-29 12:09:45] iter = 01660, loss = 10.8467
2024-10-29 12:09:46: [2024-10-29 12:09:46] iter = 01670, loss = 9.9618
2024-10-29 12:09:47: [2024-10-29 12:09:47] iter = 01680, loss = 5.3158
2024-10-29 12:09:47: [2024-10-29 12:09:47] iter = 01690, loss = 3.0239
2024-10-29 12:09:47: [2024-10-29 12:09:47] iter = 01700, loss = 29.2519
2024-10-29 12:09:48: [2024-10-29 12:09:48] iter = 01710, loss = 23.7024
2024-10-29 12:09:48: [2024-10-29 12:09:48] iter = 01720, loss = 2.6170
2024-10-29 12:09:49: [2024-10-29 12:09:49] iter = 01730, loss = 2.7095
2024-10-29 12:09:49: [2024-10-29 12:09:49] iter = 01740, loss = 10.0215
2024-10-29 12:09:49: [2024-10-29 12:09:49] iter = 01750, loss = 3.8325
2024-10-29 12:09:50: [2024-10-29 12:09:50] iter = 01760, loss = 6.6734
2024-10-29 12:09:50: [2024-10-29 12:09:50] iter = 01770, loss = 11.4283
2024-10-29 12:09:51: [2024-10-29 12:09:51] iter = 01780, loss = 2.9092
2024-10-29 12:09:51: [2024-10-29 12:09:51] iter = 01790, loss = 7.5212
2024-10-29 12:09:51: [2024-10-29 12:09:51] iter = 01800, loss = 3.6880
2024-10-29 12:09:52: [2024-10-29 12:09:52] iter = 01810, loss = 6.1774
2024-10-29 12:09:52: [2024-10-29 12:09:52] iter = 01820, loss = 4.5248
2024-10-29 12:09:53: [2024-10-29 12:09:53] iter = 01830, loss = 8.5491
2024-10-29 12:09:53: [2024-10-29 12:09:53] iter = 01840, loss = 3.1048
2024-10-29 12:09:54: [2024-10-29 12:09:54] iter = 01850, loss = 4.7731
2024-10-29 12:09:54: [2024-10-29 12:09:54] iter = 01860, loss = 3.0453
2024-10-29 12:09:55: [2024-10-29 12:09:55] iter = 01870, loss = 3.6123
2024-10-29 12:09:55: [2024-10-29 12:09:55] iter = 01880, loss = 3.9730
2024-10-29 12:09:55: [2024-10-29 12:09:55] iter = 01890, loss = 4.8967
2024-10-29 12:09:56: [2024-10-29 12:09:56] iter = 01900, loss = 11.3420
2024-10-29 12:09:56: [2024-10-29 12:09:56] iter = 01910, loss = 15.8459
2024-10-29 12:09:57: [2024-10-29 12:09:57] iter = 01920, loss = 60.2701
2024-10-29 12:09:57: [2024-10-29 12:09:57] iter = 01930, loss = 11.1619
2024-10-29 12:09:58: [2024-10-29 12:09:58] iter = 01940, loss = 4.0886
2024-10-29 12:09:58: [2024-10-29 12:09:58] iter = 01950, loss = 62.3287
2024-10-29 12:09:59: [2024-10-29 12:09:59] iter = 01960, loss = 7.3472
2024-10-29 12:09:59: [2024-10-29 12:09:59] iter = 01970, loss = 11.1641
2024-10-29 12:09:59: [2024-10-29 12:09:59] iter = 01980, loss = 6.9658
2024-10-29 12:10:00: [2024-10-29 12:10:00] iter = 01990, loss = 9.2794
2024-10-29 12:10:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 12:10:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:10:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 867}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:10:24: Evaluate 5 random ConvNet, ACCmean = 0.5164 ACCstd = 0.0125
-------------------------
2024-10-29 12:10:24: Evaluate 5 random ConvNet, SENmean = 0.5164 SENstd = 0.0125
-------------------------
2024-10-29 12:10:24: Evaluate 5 random ConvNet, SPEmean = 0.8388 SPEstd = 0.0042
-------------------------
2024-10-29 12:10:24: Evaluate 5 random ConvNet, F!mean = 0.4468 F!std = 0.0088
-------------------------
2024-10-29 12:10:24: Evaluate 5 random ConvNet, mean = 0.5164 std = 0.0125
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:10:24: [2024-10-29 12:10:24] iter = 02000, loss = 2.8334
2024-10-29 12:10:25: [2024-10-29 12:10:25] iter = 02010, loss = 8.0510
2024-10-29 12:10:25: [2024-10-29 12:10:25] iter = 02020, loss = 20.6907
2024-10-29 12:10:26: [2024-10-29 12:10:26] iter = 02030, loss = 3.7351
2024-10-29 12:10:26: [2024-10-29 12:10:26] iter = 02040, loss = 5.9385
2024-10-29 12:10:27: [2024-10-29 12:10:27] iter = 02050, loss = 4.8064
2024-10-29 12:10:27: [2024-10-29 12:10:27] iter = 02060, loss = 3.0909
2024-10-29 12:10:28: [2024-10-29 12:10:28] iter = 02070, loss = 4.3558
2024-10-29 12:10:28: [2024-10-29 12:10:28] iter = 02080, loss = 2.1877
2024-10-29 12:10:28: [2024-10-29 12:10:28] iter = 02090, loss = 30.7791
2024-10-29 12:10:29: [2024-10-29 12:10:29] iter = 02100, loss = 3.9869
2024-10-29 12:10:29: [2024-10-29 12:10:29] iter = 02110, loss = 3.4465
2024-10-29 12:10:30: [2024-10-29 12:10:30] iter = 02120, loss = 11.1651
2024-10-29 12:10:30: [2024-10-29 12:10:30] iter = 02130, loss = 3.6200
2024-10-29 12:10:30: [2024-10-29 12:10:30] iter = 02140, loss = 4.4258
2024-10-29 12:10:31: [2024-10-29 12:10:31] iter = 02150, loss = 10.3446
2024-10-29 12:10:31: [2024-10-29 12:10:31] iter = 02160, loss = 2.7324
2024-10-29 12:10:32: [2024-10-29 12:10:32] iter = 02170, loss = 5.8097
2024-10-29 12:10:32: [2024-10-29 12:10:32] iter = 02180, loss = 3.1128
2024-10-29 12:10:32: [2024-10-29 12:10:32] iter = 02190, loss = 18.6220
2024-10-29 12:10:33: [2024-10-29 12:10:33] iter = 02200, loss = 5.7853
2024-10-29 12:10:33: [2024-10-29 12:10:33] iter = 02210, loss = 2.6190
2024-10-29 12:10:34: [2024-10-29 12:10:34] iter = 02220, loss = 16.1948
2024-10-29 12:10:34: [2024-10-29 12:10:34] iter = 02230, loss = 2.3653
2024-10-29 12:10:35: [2024-10-29 12:10:35] iter = 02240, loss = 4.5279
2024-10-29 12:10:35: [2024-10-29 12:10:35] iter = 02250, loss = 59.8480
2024-10-29 12:10:35: [2024-10-29 12:10:35] iter = 02260, loss = 20.6261
2024-10-29 12:10:36: [2024-10-29 12:10:36] iter = 02270, loss = 25.2000
2024-10-29 12:10:36: [2024-10-29 12:10:36] iter = 02280, loss = 4.2655
2024-10-29 12:10:37: [2024-10-29 12:10:37] iter = 02290, loss = 24.0916
2024-10-29 12:10:37: [2024-10-29 12:10:37] iter = 02300, loss = 3.0191
2024-10-29 12:10:38: [2024-10-29 12:10:38] iter = 02310, loss = 44.6985
2024-10-29 12:10:38: [2024-10-29 12:10:38] iter = 02320, loss = 3.0661
2024-10-29 12:10:39: [2024-10-29 12:10:39] iter = 02330, loss = 5.9034
2024-10-29 12:10:39: [2024-10-29 12:10:39] iter = 02340, loss = 7.8767
2024-10-29 12:10:40: [2024-10-29 12:10:40] iter = 02350, loss = 3.2146
2024-10-29 12:10:40: [2024-10-29 12:10:40] iter = 02360, loss = 21.7534
2024-10-29 12:10:40: [2024-10-29 12:10:40] iter = 02370, loss = 9.7954
2024-10-29 12:10:41: [2024-10-29 12:10:41] iter = 02380, loss = 9.8237
2024-10-29 12:10:41: [2024-10-29 12:10:41] iter = 02390, loss = 5.9552
2024-10-29 12:10:41: [2024-10-29 12:10:41] iter = 02400, loss = 37.9785
2024-10-29 12:10:42: [2024-10-29 12:10:42] iter = 02410, loss = 2.8382
2024-10-29 12:10:42: [2024-10-29 12:10:42] iter = 02420, loss = 8.5765
2024-10-29 12:10:42: [2024-10-29 12:10:42] iter = 02430, loss = 53.7928
2024-10-29 12:10:43: [2024-10-29 12:10:43] iter = 02440, loss = 8.7062
2024-10-29 12:10:43: [2024-10-29 12:10:43] iter = 02450, loss = 9.2870
2024-10-29 12:10:43: [2024-10-29 12:10:43] iter = 02460, loss = 5.8446
2024-10-29 12:10:44: [2024-10-29 12:10:44] iter = 02470, loss = 5.8673
2024-10-29 12:10:44: [2024-10-29 12:10:44] iter = 02480, loss = 8.9637
2024-10-29 12:10:45: [2024-10-29 12:10:45] iter = 02490, loss = 5.6992
2024-10-29 12:10:45: [2024-10-29 12:10:45] iter = 02500, loss = 22.0328
2024-10-29 12:10:46: [2024-10-29 12:10:46] iter = 02510, loss = 7.4743
2024-10-29 12:10:46: [2024-10-29 12:10:46] iter = 02520, loss = 4.0823
2024-10-29 12:10:46: [2024-10-29 12:10:46] iter = 02530, loss = 8.2646
2024-10-29 12:10:47: [2024-10-29 12:10:47] iter = 02540, loss = 2.6763
2024-10-29 12:10:47: [2024-10-29 12:10:47] iter = 02550, loss = 18.2700
2024-10-29 12:10:48: [2024-10-29 12:10:48] iter = 02560, loss = 10.0930
2024-10-29 12:10:48: [2024-10-29 12:10:48] iter = 02570, loss = 8.1036
2024-10-29 12:10:49: [2024-10-29 12:10:49] iter = 02580, loss = 7.5474
2024-10-29 12:10:49: [2024-10-29 12:10:49] iter = 02590, loss = 5.0569
2024-10-29 12:10:49: [2024-10-29 12:10:49] iter = 02600, loss = 4.7308
2024-10-29 12:10:50: [2024-10-29 12:10:50] iter = 02610, loss = 4.2288
2024-10-29 12:10:50: [2024-10-29 12:10:50] iter = 02620, loss = 5.7832
2024-10-29 12:10:51: [2024-10-29 12:10:51] iter = 02630, loss = 10.7327
2024-10-29 12:10:51: [2024-10-29 12:10:51] iter = 02640, loss = 9.3238
2024-10-29 12:10:52: [2024-10-29 12:10:52] iter = 02650, loss = 5.3497
2024-10-29 12:10:52: [2024-10-29 12:10:52] iter = 02660, loss = 42.9195
2024-10-29 12:10:52: [2024-10-29 12:10:52] iter = 02670, loss = 38.3986
2024-10-29 12:10:53: [2024-10-29 12:10:53] iter = 02680, loss = 9.6170
2024-10-29 12:10:53: [2024-10-29 12:10:53] iter = 02690, loss = 10.8133
2024-10-29 12:10:54: [2024-10-29 12:10:54] iter = 02700, loss = 6.0408
2024-10-29 12:10:54: [2024-10-29 12:10:54] iter = 02710, loss = 11.2240
2024-10-29 12:10:54: [2024-10-29 12:10:54] iter = 02720, loss = 9.5003
2024-10-29 12:10:55: [2024-10-29 12:10:55] iter = 02730, loss = 26.3670
2024-10-29 12:10:55: [2024-10-29 12:10:55] iter = 02740, loss = 2.6975
2024-10-29 12:10:56: [2024-10-29 12:10:56] iter = 02750, loss = 5.5842
2024-10-29 12:10:56: [2024-10-29 12:10:56] iter = 02760, loss = 3.2629
2024-10-29 12:10:57: [2024-10-29 12:10:57] iter = 02770, loss = 28.2069
2024-10-29 12:10:57: [2024-10-29 12:10:57] iter = 02780, loss = 3.6704
2024-10-29 12:10:57: [2024-10-29 12:10:57] iter = 02790, loss = 3.4643
2024-10-29 12:10:58: [2024-10-29 12:10:58] iter = 02800, loss = 11.3269
2024-10-29 12:10:58: [2024-10-29 12:10:58] iter = 02810, loss = 14.4707
2024-10-29 12:10:59: [2024-10-29 12:10:59] iter = 02820, loss = 4.4261
2024-10-29 12:10:59: [2024-10-29 12:10:59] iter = 02830, loss = 3.2575
2024-10-29 12:11:00: [2024-10-29 12:11:00] iter = 02840, loss = 9.0705
2024-10-29 12:11:00: [2024-10-29 12:11:00] iter = 02850, loss = 5.3614
2024-10-29 12:11:01: [2024-10-29 12:11:01] iter = 02860, loss = 3.1539
2024-10-29 12:11:01: [2024-10-29 12:11:01] iter = 02870, loss = 5.3154
2024-10-29 12:11:01: [2024-10-29 12:11:01] iter = 02880, loss = 3.7755
2024-10-29 12:11:02: [2024-10-29 12:11:02] iter = 02890, loss = 13.7901
2024-10-29 12:11:02: [2024-10-29 12:11:02] iter = 02900, loss = 6.3784
2024-10-29 12:11:03: [2024-10-29 12:11:03] iter = 02910, loss = 42.6372
2024-10-29 12:11:03: [2024-10-29 12:11:03] iter = 02920, loss = 2.7492
2024-10-29 12:11:04: [2024-10-29 12:11:04] iter = 02930, loss = 3.3446
2024-10-29 12:11:04: [2024-10-29 12:11:04] iter = 02940, loss = 4.3078
2024-10-29 12:11:04: [2024-10-29 12:11:04] iter = 02950, loss = 7.9387
2024-10-29 12:11:05: [2024-10-29 12:11:05] iter = 02960, loss = 5.4882
2024-10-29 12:11:05: [2024-10-29 12:11:05] iter = 02970, loss = 4.9959
2024-10-29 12:11:06: [2024-10-29 12:11:06] iter = 02980, loss = 16.8054
2024-10-29 12:11:06: [2024-10-29 12:11:06] iter = 02990, loss = 3.2063
2024-10-29 12:11:07: [2024-10-29 12:11:07] iter = 03000, loss = 4.9781
2024-10-29 12:11:07: [2024-10-29 12:11:07] iter = 03010, loss = 2.7159
2024-10-29 12:11:07: [2024-10-29 12:11:07] iter = 03020, loss = 9.0575
2024-10-29 12:11:08: [2024-10-29 12:11:08] iter = 03030, loss = 3.2144
2024-10-29 12:11:08: [2024-10-29 12:11:08] iter = 03040, loss = 12.3572
2024-10-29 12:11:09: [2024-10-29 12:11:09] iter = 03050, loss = 5.1479
2024-10-29 12:11:09: [2024-10-29 12:11:09] iter = 03060, loss = 7.0612
2024-10-29 12:11:10: [2024-10-29 12:11:10] iter = 03070, loss = 7.3832
2024-10-29 12:11:10: [2024-10-29 12:11:10] iter = 03080, loss = 4.6099
2024-10-29 12:11:10: [2024-10-29 12:11:10] iter = 03090, loss = 3.3480
2024-10-29 12:11:11: [2024-10-29 12:11:11] iter = 03100, loss = 3.3317
2024-10-29 12:11:11: [2024-10-29 12:11:11] iter = 03110, loss = 15.1623
2024-10-29 12:11:12: [2024-10-29 12:11:12] iter = 03120, loss = 12.1690
2024-10-29 12:11:12: [2024-10-29 12:11:12] iter = 03130, loss = 18.1751
2024-10-29 12:11:13: [2024-10-29 12:11:13] iter = 03140, loss = 6.2053
2024-10-29 12:11:13: [2024-10-29 12:11:13] iter = 03150, loss = 2.3444
2024-10-29 12:11:13: [2024-10-29 12:11:13] iter = 03160, loss = 5.1860
2024-10-29 12:11:14: [2024-10-29 12:11:14] iter = 03170, loss = 12.7879
2024-10-29 12:11:14: [2024-10-29 12:11:14] iter = 03180, loss = 11.5788
2024-10-29 12:11:15: [2024-10-29 12:11:15] iter = 03190, loss = 11.8726
2024-10-29 12:11:15: [2024-10-29 12:11:15] iter = 03200, loss = 23.3170
2024-10-29 12:11:16: [2024-10-29 12:11:16] iter = 03210, loss = 6.1763
2024-10-29 12:11:16: [2024-10-29 12:11:16] iter = 03220, loss = 3.2958
2024-10-29 12:11:17: [2024-10-29 12:11:17] iter = 03230, loss = 2.5312
2024-10-29 12:11:17: [2024-10-29 12:11:17] iter = 03240, loss = 26.4410
2024-10-29 12:11:17: [2024-10-29 12:11:17] iter = 03250, loss = 4.0113
2024-10-29 12:11:18: [2024-10-29 12:11:18] iter = 03260, loss = 30.3709
2024-10-29 12:11:18: [2024-10-29 12:11:18] iter = 03270, loss = 2.8822
2024-10-29 12:11:18: [2024-10-29 12:11:18] iter = 03280, loss = 19.5884
2024-10-29 12:11:19: [2024-10-29 12:11:19] iter = 03290, loss = 21.6622
2024-10-29 12:11:19: [2024-10-29 12:11:19] iter = 03300, loss = 7.9174
2024-10-29 12:11:20: [2024-10-29 12:11:20] iter = 03310, loss = 28.1386
2024-10-29 12:11:20: [2024-10-29 12:11:20] iter = 03320, loss = 3.0515
2024-10-29 12:11:20: [2024-10-29 12:11:20] iter = 03330, loss = 2.7346
2024-10-29 12:11:21: [2024-10-29 12:11:21] iter = 03340, loss = 3.7340
2024-10-29 12:11:22: [2024-10-29 12:11:22] iter = 03350, loss = 4.5473
2024-10-29 12:11:22: [2024-10-29 12:11:22] iter = 03360, loss = 5.7248
2024-10-29 12:11:22: [2024-10-29 12:11:22] iter = 03370, loss = 3.5354
2024-10-29 12:11:23: [2024-10-29 12:11:23] iter = 03380, loss = 44.5553
2024-10-29 12:11:23: [2024-10-29 12:11:23] iter = 03390, loss = 24.2053
2024-10-29 12:11:24: [2024-10-29 12:11:24] iter = 03400, loss = 8.2694
2024-10-29 12:11:24: [2024-10-29 12:11:24] iter = 03410, loss = 5.7753
2024-10-29 12:11:25: [2024-10-29 12:11:25] iter = 03420, loss = 31.0092
2024-10-29 12:11:25: [2024-10-29 12:11:25] iter = 03430, loss = 47.6785
2024-10-29 12:11:26: [2024-10-29 12:11:26] iter = 03440, loss = 4.2480
2024-10-29 12:11:26: [2024-10-29 12:11:26] iter = 03450, loss = 5.6893
2024-10-29 12:11:27: [2024-10-29 12:11:27] iter = 03460, loss = 33.7930
2024-10-29 12:11:27: [2024-10-29 12:11:27] iter = 03470, loss = 3.0268
2024-10-29 12:11:28: [2024-10-29 12:11:28] iter = 03480, loss = 8.7414
2024-10-29 12:11:28: [2024-10-29 12:11:28] iter = 03490, loss = 4.2283
2024-10-29 12:11:29: [2024-10-29 12:11:29] iter = 03500, loss = 3.4540
2024-10-29 12:11:29: [2024-10-29 12:11:29] iter = 03510, loss = 14.7196
2024-10-29 12:11:30: [2024-10-29 12:11:30] iter = 03520, loss = 6.7826
2024-10-29 12:11:30: [2024-10-29 12:11:30] iter = 03530, loss = 7.3723
2024-10-29 12:11:30: [2024-10-29 12:11:30] iter = 03540, loss = 4.8693
2024-10-29 12:11:31: [2024-10-29 12:11:31] iter = 03550, loss = 7.8167
2024-10-29 12:11:31: [2024-10-29 12:11:31] iter = 03560, loss = 4.6316
2024-10-29 12:11:32: [2024-10-29 12:11:32] iter = 03570, loss = 3.7090
2024-10-29 12:11:32: [2024-10-29 12:11:32] iter = 03580, loss = 7.5302
2024-10-29 12:11:33: [2024-10-29 12:11:33] iter = 03590, loss = 8.6806
2024-10-29 12:11:33: [2024-10-29 12:11:33] iter = 03600, loss = 8.7202
2024-10-29 12:11:34: [2024-10-29 12:11:33] iter = 03610, loss = 23.8172
2024-10-29 12:11:34: [2024-10-29 12:11:34] iter = 03620, loss = 9.4221
2024-10-29 12:11:34: [2024-10-29 12:11:34] iter = 03630, loss = 6.3992
2024-10-29 12:11:35: [2024-10-29 12:11:35] iter = 03640, loss = 6.9618
2024-10-29 12:11:35: [2024-10-29 12:11:35] iter = 03650, loss = 4.9419
2024-10-29 12:11:36: [2024-10-29 12:11:36] iter = 03660, loss = 52.3506
2024-10-29 12:11:36: [2024-10-29 12:11:36] iter = 03670, loss = 10.4736
2024-10-29 12:11:36: [2024-10-29 12:11:36] iter = 03680, loss = 11.0250
2024-10-29 12:11:37: [2024-10-29 12:11:37] iter = 03690, loss = 6.2780
2024-10-29 12:11:37: [2024-10-29 12:11:37] iter = 03700, loss = 8.5716
2024-10-29 12:11:38: [2024-10-29 12:11:38] iter = 03710, loss = 10.7636
2024-10-29 12:11:38: [2024-10-29 12:11:38] iter = 03720, loss = 5.2032
2024-10-29 12:11:38: [2024-10-29 12:11:38] iter = 03730, loss = 5.0510
2024-10-29 12:11:39: [2024-10-29 12:11:39] iter = 03740, loss = 36.2862
2024-10-29 12:11:39: [2024-10-29 12:11:39] iter = 03750, loss = 5.9074
2024-10-29 12:11:40: [2024-10-29 12:11:40] iter = 03760, loss = 2.5806
2024-10-29 12:11:40: [2024-10-29 12:11:40] iter = 03770, loss = 50.2364
2024-10-29 12:11:40: [2024-10-29 12:11:40] iter = 03780, loss = 14.7554
2024-10-29 12:11:41: [2024-10-29 12:11:41] iter = 03790, loss = 17.4224
2024-10-29 12:11:41: [2024-10-29 12:11:41] iter = 03800, loss = 8.6221
2024-10-29 12:11:42: [2024-10-29 12:11:41] iter = 03810, loss = 2.8814
2024-10-29 12:11:42: [2024-10-29 12:11:42] iter = 03820, loss = 2.6355
2024-10-29 12:11:43: [2024-10-29 12:11:43] iter = 03830, loss = 2.6689
2024-10-29 12:11:43: [2024-10-29 12:11:43] iter = 03840, loss = 5.1274
2024-10-29 12:11:43: [2024-10-29 12:11:43] iter = 03850, loss = 5.0347
2024-10-29 12:11:44: [2024-10-29 12:11:44] iter = 03860, loss = 15.4061
2024-10-29 12:11:44: [2024-10-29 12:11:44] iter = 03870, loss = 5.9213
2024-10-29 12:11:45: [2024-10-29 12:11:45] iter = 03880, loss = 9.0907
2024-10-29 12:11:45: [2024-10-29 12:11:45] iter = 03890, loss = 16.7312
2024-10-29 12:11:46: [2024-10-29 12:11:46] iter = 03900, loss = 3.8267
2024-10-29 12:11:46: [2024-10-29 12:11:46] iter = 03910, loss = 10.3318
2024-10-29 12:11:46: [2024-10-29 12:11:46] iter = 03920, loss = 6.4678
2024-10-29 12:11:47: [2024-10-29 12:11:47] iter = 03930, loss = 3.5246
2024-10-29 12:11:47: [2024-10-29 12:11:47] iter = 03940, loss = 5.3955
2024-10-29 12:11:48: [2024-10-29 12:11:48] iter = 03950, loss = 4.4270
2024-10-29 12:11:48: [2024-10-29 12:11:48] iter = 03960, loss = 11.6452
2024-10-29 12:11:48: [2024-10-29 12:11:48] iter = 03970, loss = 7.5089
2024-10-29 12:11:49: [2024-10-29 12:11:49] iter = 03980, loss = 3.2362
2024-10-29 12:11:49: [2024-10-29 12:11:49] iter = 03990, loss = 11.1485
2024-10-29 12:11:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 12:11:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:11:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10267}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:12:13: Evaluate 5 random ConvNet, ACCmean = 0.5008 ACCstd = 0.0048
-------------------------
2024-10-29 12:12:13: Evaluate 5 random ConvNet, SENmean = 0.5008 SENstd = 0.0048
-------------------------
2024-10-29 12:12:13: Evaluate 5 random ConvNet, SPEmean = 0.8336 SPEstd = 0.0016
-------------------------
2024-10-29 12:12:13: Evaluate 5 random ConvNet, F!mean = 0.4717 F!std = 0.0026
-------------------------
2024-10-29 12:12:13: Evaluate 5 random ConvNet, mean = 0.5008 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:12:13: [2024-10-29 12:12:13] iter = 04000, loss = 2.6690
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:12:14: [2024-10-29 12:12:14] iter = 04010, loss = 4.7853
2024-10-29 12:12:14: [2024-10-29 12:12:14] iter = 04020, loss = 3.7710
2024-10-29 12:12:15: [2024-10-29 12:12:15] iter = 04030, loss = 4.8993
2024-10-29 12:12:15: [2024-10-29 12:12:15] iter = 04040, loss = 7.4122
2024-10-29 12:12:16: [2024-10-29 12:12:16] iter = 04050, loss = 4.8167
2024-10-29 12:12:16: [2024-10-29 12:12:16] iter = 04060, loss = 10.1018
2024-10-29 12:12:16: [2024-10-29 12:12:16] iter = 04070, loss = 22.4878
2024-10-29 12:12:17: [2024-10-29 12:12:17] iter = 04080, loss = 4.7356
2024-10-29 12:12:17: [2024-10-29 12:12:17] iter = 04090, loss = 14.4898
2024-10-29 12:12:18: [2024-10-29 12:12:18] iter = 04100, loss = 24.2902
2024-10-29 12:12:18: [2024-10-29 12:12:18] iter = 04110, loss = 2.5716
2024-10-29 12:12:19: [2024-10-29 12:12:19] iter = 04120, loss = 9.2181
2024-10-29 12:12:19: [2024-10-29 12:12:19] iter = 04130, loss = 13.7159
2024-10-29 12:12:19: [2024-10-29 12:12:19] iter = 04140, loss = 6.3474
2024-10-29 12:12:20: [2024-10-29 12:12:20] iter = 04150, loss = 22.8010
2024-10-29 12:12:20: [2024-10-29 12:12:20] iter = 04160, loss = 6.2054
2024-10-29 12:12:21: [2024-10-29 12:12:21] iter = 04170, loss = 13.8925
2024-10-29 12:12:21: [2024-10-29 12:12:21] iter = 04180, loss = 11.9989
2024-10-29 12:12:22: [2024-10-29 12:12:22] iter = 04190, loss = 6.5601
2024-10-29 12:12:22: [2024-10-29 12:12:22] iter = 04200, loss = 2.0685
2024-10-29 12:12:22: [2024-10-29 12:12:22] iter = 04210, loss = 5.3796
2024-10-29 12:12:23: [2024-10-29 12:12:23] iter = 04220, loss = 5.5817
2024-10-29 12:12:23: [2024-10-29 12:12:23] iter = 04230, loss = 4.9519
2024-10-29 12:12:24: [2024-10-29 12:12:24] iter = 04240, loss = 15.4508
2024-10-29 12:12:24: [2024-10-29 12:12:24] iter = 04250, loss = 11.2254
2024-10-29 12:12:25: [2024-10-29 12:12:25] iter = 04260, loss = 3.3928
2024-10-29 12:12:25: [2024-10-29 12:12:25] iter = 04270, loss = 3.4339
2024-10-29 12:12:26: [2024-10-29 12:12:26] iter = 04280, loss = 8.5616
2024-10-29 12:12:26: [2024-10-29 12:12:26] iter = 04290, loss = 2.7061
2024-10-29 12:12:27: [2024-10-29 12:12:27] iter = 04300, loss = 22.2653
2024-10-29 12:12:27: [2024-10-29 12:12:27] iter = 04310, loss = 3.5135
2024-10-29 12:12:28: [2024-10-29 12:12:28] iter = 04320, loss = 13.1779
2024-10-29 12:12:28: [2024-10-29 12:12:28] iter = 04330, loss = 5.6356
2024-10-29 12:12:29: [2024-10-29 12:12:29] iter = 04340, loss = 15.1705
2024-10-29 12:12:29: [2024-10-29 12:12:29] iter = 04350, loss = 6.3823
2024-10-29 12:12:30: [2024-10-29 12:12:30] iter = 04360, loss = 6.8748
2024-10-29 12:12:30: [2024-10-29 12:12:30] iter = 04370, loss = 10.0522
2024-10-29 12:12:31: [2024-10-29 12:12:31] iter = 04380, loss = 15.9226
2024-10-29 12:12:31: [2024-10-29 12:12:31] iter = 04390, loss = 39.5081
2024-10-29 12:12:31: [2024-10-29 12:12:31] iter = 04400, loss = 21.4949
2024-10-29 12:12:32: [2024-10-29 12:12:32] iter = 04410, loss = 3.7103
2024-10-29 12:12:32: [2024-10-29 12:12:32] iter = 04420, loss = 9.9734
2024-10-29 12:12:33: [2024-10-29 12:12:33] iter = 04430, loss = 3.5973
2024-10-29 12:12:33: [2024-10-29 12:12:33] iter = 04440, loss = 18.8721
2024-10-29 12:12:34: [2024-10-29 12:12:34] iter = 04450, loss = 35.8787
2024-10-29 12:12:34: [2024-10-29 12:12:34] iter = 04460, loss = 3.2549
2024-10-29 12:12:35: [2024-10-29 12:12:35] iter = 04470, loss = 5.6358
2024-10-29 12:12:35: [2024-10-29 12:12:35] iter = 04480, loss = 10.1656
2024-10-29 12:12:36: [2024-10-29 12:12:36] iter = 04490, loss = 2.9485
2024-10-29 12:12:36: [2024-10-29 12:12:36] iter = 04500, loss = 5.9776
2024-10-29 12:12:37: [2024-10-29 12:12:37] iter = 04510, loss = 2.3781
2024-10-29 12:12:37: [2024-10-29 12:12:37] iter = 04520, loss = 2.7098
2024-10-29 12:12:38: [2024-10-29 12:12:38] iter = 04530, loss = 12.9503
2024-10-29 12:12:38: [2024-10-29 12:12:38] iter = 04540, loss = 8.8291
2024-10-29 12:12:39: [2024-10-29 12:12:39] iter = 04550, loss = 7.2927
2024-10-29 12:12:39: [2024-10-29 12:12:39] iter = 04560, loss = 9.2074
2024-10-29 12:12:40: [2024-10-29 12:12:40] iter = 04570, loss = 23.8284
2024-10-29 12:12:40: [2024-10-29 12:12:40] iter = 04580, loss = 11.0730
2024-10-29 12:12:41: [2024-10-29 12:12:41] iter = 04590, loss = 3.8374
2024-10-29 12:12:41: [2024-10-29 12:12:41] iter = 04600, loss = 7.7156
2024-10-29 12:12:42: [2024-10-29 12:12:42] iter = 04610, loss = 7.9584
2024-10-29 12:12:42: [2024-10-29 12:12:42] iter = 04620, loss = 5.5231
2024-10-29 12:12:43: [2024-10-29 12:12:43] iter = 04630, loss = 14.6434
2024-10-29 12:12:43: [2024-10-29 12:12:43] iter = 04640, loss = 23.7669
2024-10-29 12:12:43: [2024-10-29 12:12:43] iter = 04650, loss = 3.7472
2024-10-29 12:12:44: [2024-10-29 12:12:44] iter = 04660, loss = 9.6232
2024-10-29 12:12:44: [2024-10-29 12:12:44] iter = 04670, loss = 8.7340
2024-10-29 12:12:45: [2024-10-29 12:12:45] iter = 04680, loss = 7.8739
2024-10-29 12:12:45: [2024-10-29 12:12:45] iter = 04690, loss = 10.3576
2024-10-29 12:12:46: [2024-10-29 12:12:46] iter = 04700, loss = 8.7958
2024-10-29 12:12:46: [2024-10-29 12:12:46] iter = 04710, loss = 5.5924
2024-10-29 12:12:47: [2024-10-29 12:12:47] iter = 04720, loss = 44.3058
2024-10-29 12:12:47: [2024-10-29 12:12:47] iter = 04730, loss = 6.1145
2024-10-29 12:12:47: [2024-10-29 12:12:47] iter = 04740, loss = 5.3462
2024-10-29 12:12:48: [2024-10-29 12:12:48] iter = 04750, loss = 10.5915
2024-10-29 12:12:48: [2024-10-29 12:12:48] iter = 04760, loss = 45.0000
2024-10-29 12:12:49: [2024-10-29 12:12:49] iter = 04770, loss = 3.8760
2024-10-29 12:12:49: [2024-10-29 12:12:49] iter = 04780, loss = 8.8949
2024-10-29 12:12:50: [2024-10-29 12:12:50] iter = 04790, loss = 11.6040
2024-10-29 12:12:50: [2024-10-29 12:12:50] iter = 04800, loss = 4.6945
2024-10-29 12:12:50: [2024-10-29 12:12:50] iter = 04810, loss = 4.5126
2024-10-29 12:12:51: [2024-10-29 12:12:51] iter = 04820, loss = 3.2909
2024-10-29 12:12:51: [2024-10-29 12:12:51] iter = 04830, loss = 30.7262
2024-10-29 12:12:52: [2024-10-29 12:12:52] iter = 04840, loss = 6.5465
2024-10-29 12:12:52: [2024-10-29 12:12:52] iter = 04850, loss = 5.3333
2024-10-29 12:12:53: [2024-10-29 12:12:52] iter = 04860, loss = 13.2034
2024-10-29 12:12:53: [2024-10-29 12:12:53] iter = 04870, loss = 3.5382
2024-10-29 12:12:53: [2024-10-29 12:12:53] iter = 04880, loss = 6.6619
2024-10-29 12:12:54: [2024-10-29 12:12:54] iter = 04890, loss = 5.8490
2024-10-29 12:12:54: [2024-10-29 12:12:54] iter = 04900, loss = 12.0737
2024-10-29 12:12:55: [2024-10-29 12:12:55] iter = 04910, loss = 4.6230
2024-10-29 12:12:55: [2024-10-29 12:12:55] iter = 04920, loss = 2.4754
2024-10-29 12:12:56: [2024-10-29 12:12:56] iter = 04930, loss = 5.3716
2024-10-29 12:12:56: [2024-10-29 12:12:56] iter = 04940, loss = 7.4702
2024-10-29 12:12:56: [2024-10-29 12:12:56] iter = 04950, loss = 3.3990
2024-10-29 12:12:57: [2024-10-29 12:12:57] iter = 04960, loss = 2.3063
2024-10-29 12:12:57: [2024-10-29 12:12:57] iter = 04970, loss = 6.6071
2024-10-29 12:12:58: [2024-10-29 12:12:58] iter = 04980, loss = 2.9961
2024-10-29 12:12:58: [2024-10-29 12:12:58] iter = 04990, loss = 4.6005
2024-10-29 12:12:58: [2024-10-29 12:12:58] iter = 05000, loss = 4.2046
2024-10-29 12:12:59: [2024-10-29 12:12:59] iter = 05010, loss = 13.8992
2024-10-29 12:12:59: [2024-10-29 12:12:59] iter = 05020, loss = 11.4596
2024-10-29 12:13:00: [2024-10-29 12:13:00] iter = 05030, loss = 4.7732
2024-10-29 12:13:00: [2024-10-29 12:13:00] iter = 05040, loss = 2.8677
2024-10-29 12:13:01: [2024-10-29 12:13:01] iter = 05050, loss = 4.4831
2024-10-29 12:13:01: [2024-10-29 12:13:01] iter = 05060, loss = 6.6254
2024-10-29 12:13:02: [2024-10-29 12:13:02] iter = 05070, loss = 13.7441
2024-10-29 12:13:02: [2024-10-29 12:13:02] iter = 05080, loss = 3.0841
2024-10-29 12:13:03: [2024-10-29 12:13:02] iter = 05090, loss = 11.9054
2024-10-29 12:13:03: [2024-10-29 12:13:03] iter = 05100, loss = 9.6623
2024-10-29 12:13:03: [2024-10-29 12:13:03] iter = 05110, loss = 2.6405
2024-10-29 12:13:04: [2024-10-29 12:13:04] iter = 05120, loss = 10.3101
2024-10-29 12:13:04: [2024-10-29 12:13:04] iter = 05130, loss = 4.5742
2024-10-29 12:13:04: [2024-10-29 12:13:04] iter = 05140, loss = 4.5222
2024-10-29 12:13:05: [2024-10-29 12:13:05] iter = 05150, loss = 8.3111
2024-10-29 12:13:05: [2024-10-29 12:13:05] iter = 05160, loss = 4.0559
2024-10-29 12:13:05: [2024-10-29 12:13:05] iter = 05170, loss = 6.0983
2024-10-29 12:13:06: [2024-10-29 12:13:06] iter = 05180, loss = 29.9595
2024-10-29 12:13:06: [2024-10-29 12:13:06] iter = 05190, loss = 3.9872
2024-10-29 12:13:07: [2024-10-29 12:13:07] iter = 05200, loss = 2.5431
2024-10-29 12:13:07: [2024-10-29 12:13:07] iter = 05210, loss = 7.1780
2024-10-29 12:13:08: [2024-10-29 12:13:08] iter = 05220, loss = 8.5838
2024-10-29 12:13:08: [2024-10-29 12:13:08] iter = 05230, loss = 8.7131
2024-10-29 12:13:08: [2024-10-29 12:13:08] iter = 05240, loss = 18.9500
2024-10-29 12:13:09: [2024-10-29 12:13:09] iter = 05250, loss = 3.2349
2024-10-29 12:13:09: [2024-10-29 12:13:09] iter = 05260, loss = 10.5143
2024-10-29 12:13:10: [2024-10-29 12:13:10] iter = 05270, loss = 2.8418
2024-10-29 12:13:10: [2024-10-29 12:13:10] iter = 05280, loss = 12.8606
2024-10-29 12:13:11: [2024-10-29 12:13:11] iter = 05290, loss = 2.8530
2024-10-29 12:13:11: [2024-10-29 12:13:11] iter = 05300, loss = 33.5350
2024-10-29 12:13:12: [2024-10-29 12:13:12] iter = 05310, loss = 27.3485
2024-10-29 12:13:12: [2024-10-29 12:13:12] iter = 05320, loss = 3.3552
2024-10-29 12:13:12: [2024-10-29 12:13:12] iter = 05330, loss = 10.4902
2024-10-29 12:13:13: [2024-10-29 12:13:13] iter = 05340, loss = 12.1857
2024-10-29 12:13:13: [2024-10-29 12:13:13] iter = 05350, loss = 14.7186
2024-10-29 12:13:14: [2024-10-29 12:13:14] iter = 05360, loss = 17.9539
2024-10-29 12:13:14: [2024-10-29 12:13:14] iter = 05370, loss = 12.0456
2024-10-29 12:13:15: [2024-10-29 12:13:15] iter = 05380, loss = 9.9569
2024-10-29 12:13:15: [2024-10-29 12:13:15] iter = 05390, loss = 11.8816
2024-10-29 12:13:15: [2024-10-29 12:13:15] iter = 05400, loss = 11.8161
2024-10-29 12:13:16: [2024-10-29 12:13:16] iter = 05410, loss = 3.7445
2024-10-29 12:13:16: [2024-10-29 12:13:16] iter = 05420, loss = 19.0782
2024-10-29 12:13:17: [2024-10-29 12:13:17] iter = 05430, loss = 3.4808
2024-10-29 12:13:17: [2024-10-29 12:13:17] iter = 05440, loss = 8.9444
2024-10-29 12:13:18: [2024-10-29 12:13:18] iter = 05450, loss = 3.1844
2024-10-29 12:13:18: [2024-10-29 12:13:18] iter = 05460, loss = 5.7391
2024-10-29 12:13:19: [2024-10-29 12:13:19] iter = 05470, loss = 5.3860
2024-10-29 12:13:19: [2024-10-29 12:13:19] iter = 05480, loss = 6.4596
2024-10-29 12:13:20: [2024-10-29 12:13:20] iter = 05490, loss = 2.5846
2024-10-29 12:13:20: [2024-10-29 12:13:20] iter = 05500, loss = 5.5779
2024-10-29 12:13:20: [2024-10-29 12:13:20] iter = 05510, loss = 3.7448
2024-10-29 12:13:21: [2024-10-29 12:13:21] iter = 05520, loss = 6.8783
2024-10-29 12:13:21: [2024-10-29 12:13:21] iter = 05530, loss = 4.6671
2024-10-29 12:13:21: [2024-10-29 12:13:21] iter = 05540, loss = 4.6332
2024-10-29 12:13:22: [2024-10-29 12:13:22] iter = 05550, loss = 33.4723
2024-10-29 12:13:22: [2024-10-29 12:13:22] iter = 05560, loss = 4.5554
2024-10-29 12:13:23: [2024-10-29 12:13:23] iter = 05570, loss = 6.3982
2024-10-29 12:13:23: [2024-10-29 12:13:23] iter = 05580, loss = 2.5890
2024-10-29 12:13:24: [2024-10-29 12:13:24] iter = 05590, loss = 2.7594
2024-10-29 12:13:24: [2024-10-29 12:13:24] iter = 05600, loss = 5.5921
2024-10-29 12:13:25: [2024-10-29 12:13:25] iter = 05610, loss = 5.3538
2024-10-29 12:13:25: [2024-10-29 12:13:25] iter = 05620, loss = 17.5584
2024-10-29 12:13:25: [2024-10-29 12:13:25] iter = 05630, loss = 8.0296
2024-10-29 12:13:26: [2024-10-29 12:13:26] iter = 05640, loss = 2.3922
2024-10-29 12:13:26: [2024-10-29 12:13:26] iter = 05650, loss = 3.1805
2024-10-29 12:13:27: [2024-10-29 12:13:27] iter = 05660, loss = 18.1147
2024-10-29 12:13:27: [2024-10-29 12:13:27] iter = 05670, loss = 12.3917
2024-10-29 12:13:27: [2024-10-29 12:13:27] iter = 05680, loss = 4.4512
2024-10-29 12:13:28: [2024-10-29 12:13:28] iter = 05690, loss = 7.3377
2024-10-29 12:13:28: [2024-10-29 12:13:28] iter = 05700, loss = 13.9396
2024-10-29 12:13:28: [2024-10-29 12:13:28] iter = 05710, loss = 8.1582
2024-10-29 12:13:29: [2024-10-29 12:13:29] iter = 05720, loss = 4.7504
2024-10-29 12:13:29: [2024-10-29 12:13:29] iter = 05730, loss = 3.7990
2024-10-29 12:13:30: [2024-10-29 12:13:30] iter = 05740, loss = 4.0073
2024-10-29 12:13:30: [2024-10-29 12:13:30] iter = 05750, loss = 4.3743
2024-10-29 12:13:31: [2024-10-29 12:13:31] iter = 05760, loss = 13.2427
2024-10-29 12:13:31: [2024-10-29 12:13:31] iter = 05770, loss = 5.0561
2024-10-29 12:13:31: [2024-10-29 12:13:31] iter = 05780, loss = 3.6179
2024-10-29 12:13:32: [2024-10-29 12:13:32] iter = 05790, loss = 2.6109
2024-10-29 12:13:32: [2024-10-29 12:13:32] iter = 05800, loss = 11.9147
2024-10-29 12:13:33: [2024-10-29 12:13:33] iter = 05810, loss = 2.4775
2024-10-29 12:13:33: [2024-10-29 12:13:33] iter = 05820, loss = 4.2243
2024-10-29 12:13:34: [2024-10-29 12:13:34] iter = 05830, loss = 2.9111
2024-10-29 12:13:34: [2024-10-29 12:13:34] iter = 05840, loss = 32.3261
2024-10-29 12:13:34: [2024-10-29 12:13:34] iter = 05850, loss = 2.5920
2024-10-29 12:13:35: [2024-10-29 12:13:35] iter = 05860, loss = 6.7896
2024-10-29 12:13:35: [2024-10-29 12:13:35] iter = 05870, loss = 15.5320
2024-10-29 12:13:36: [2024-10-29 12:13:36] iter = 05880, loss = 8.8318
2024-10-29 12:13:36: [2024-10-29 12:13:36] iter = 05890, loss = 6.1966
2024-10-29 12:13:37: [2024-10-29 12:13:37] iter = 05900, loss = 3.4754
2024-10-29 12:13:37: [2024-10-29 12:13:37] iter = 05910, loss = 5.4675
2024-10-29 12:13:37: [2024-10-29 12:13:37] iter = 05920, loss = 3.2741
2024-10-29 12:13:38: [2024-10-29 12:13:38] iter = 05930, loss = 3.3765
2024-10-29 12:13:39: [2024-10-29 12:13:38] iter = 05940, loss = 3.3407
2024-10-29 12:13:39: [2024-10-29 12:13:39] iter = 05950, loss = 6.7944
2024-10-29 12:13:39: [2024-10-29 12:13:39] iter = 05960, loss = 5.2145
2024-10-29 12:13:40: [2024-10-29 12:13:40] iter = 05970, loss = 2.7117
2024-10-29 12:13:41: [2024-10-29 12:13:41] iter = 05980, loss = 5.6934
2024-10-29 12:13:41: [2024-10-29 12:13:41] iter = 05990, loss = 11.2558
2024-10-29 12:13:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 12:13:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:13:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 22263}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:14:05: Evaluate 5 random ConvNet, ACCmean = 0.5054 ACCstd = 0.0101
-------------------------
2024-10-29 12:14:05: Evaluate 5 random ConvNet, SENmean = 0.5054 SENstd = 0.0101
-------------------------
2024-10-29 12:14:05: Evaluate 5 random ConvNet, SPEmean = 0.8351 SPEstd = 0.0034
-------------------------
2024-10-29 12:14:05: Evaluate 5 random ConvNet, F!mean = 0.4878 F!std = 0.0120
-------------------------
2024-10-29 12:14:05: Evaluate 5 random ConvNet, mean = 0.5054 std = 0.0101
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:14:05: [2024-10-29 12:14:05] iter = 06000, loss = 19.3097
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:14:05: [2024-10-29 12:14:05] iter = 06010, loss = 3.3524
2024-10-29 12:14:06: [2024-10-29 12:14:06] iter = 06020, loss = 9.2404
2024-10-29 12:14:06: [2024-10-29 12:14:06] iter = 06030, loss = 6.9569
2024-10-29 12:14:07: [2024-10-29 12:14:07] iter = 06040, loss = 5.5015
2024-10-29 12:14:07: [2024-10-29 12:14:07] iter = 06050, loss = 3.6873
2024-10-29 12:14:07: [2024-10-29 12:14:07] iter = 06060, loss = 5.9773
2024-10-29 12:14:08: [2024-10-29 12:14:08] iter = 06070, loss = 9.6867
2024-10-29 12:14:08: [2024-10-29 12:14:08] iter = 06080, loss = 15.3814
2024-10-29 12:14:09: [2024-10-29 12:14:09] iter = 06090, loss = 9.3245
2024-10-29 12:14:09: [2024-10-29 12:14:09] iter = 06100, loss = 8.1360
2024-10-29 12:14:09: [2024-10-29 12:14:09] iter = 06110, loss = 2.6682
2024-10-29 12:14:10: [2024-10-29 12:14:10] iter = 06120, loss = 11.3871
2024-10-29 12:14:10: [2024-10-29 12:14:10] iter = 06130, loss = 6.4613
2024-10-29 12:14:11: [2024-10-29 12:14:11] iter = 06140, loss = 20.2820
2024-10-29 12:14:11: [2024-10-29 12:14:11] iter = 06150, loss = 49.5271
2024-10-29 12:14:11: [2024-10-29 12:14:11] iter = 06160, loss = 7.0448
2024-10-29 12:14:12: [2024-10-29 12:14:12] iter = 06170, loss = 7.6911
2024-10-29 12:14:12: [2024-10-29 12:14:12] iter = 06180, loss = 3.7578
2024-10-29 12:14:13: [2024-10-29 12:14:13] iter = 06190, loss = 4.7340
2024-10-29 12:14:13: [2024-10-29 12:14:13] iter = 06200, loss = 7.6583
2024-10-29 12:14:13: [2024-10-29 12:14:13] iter = 06210, loss = 10.9534
2024-10-29 12:14:14: [2024-10-29 12:14:14] iter = 06220, loss = 37.5837
2024-10-29 12:14:14: [2024-10-29 12:14:14] iter = 06230, loss = 2.9105
2024-10-29 12:14:15: [2024-10-29 12:14:15] iter = 06240, loss = 3.0529
2024-10-29 12:14:15: [2024-10-29 12:14:15] iter = 06250, loss = 2.8149
2024-10-29 12:14:16: [2024-10-29 12:14:16] iter = 06260, loss = 7.1275
2024-10-29 12:14:16: [2024-10-29 12:14:16] iter = 06270, loss = 27.3141
2024-10-29 12:14:16: [2024-10-29 12:14:16] iter = 06280, loss = 9.9768
2024-10-29 12:14:17: [2024-10-29 12:14:17] iter = 06290, loss = 4.6447
2024-10-29 12:14:17: [2024-10-29 12:14:17] iter = 06300, loss = 21.0821
2024-10-29 12:14:18: [2024-10-29 12:14:18] iter = 06310, loss = 11.0831
2024-10-29 12:14:18: [2024-10-29 12:14:18] iter = 06320, loss = 5.3906
2024-10-29 12:14:18: [2024-10-29 12:14:18] iter = 06330, loss = 9.1300
2024-10-29 12:14:19: [2024-10-29 12:14:19] iter = 06340, loss = 38.7560
2024-10-29 12:14:19: [2024-10-29 12:14:19] iter = 06350, loss = 31.7149
2024-10-29 12:14:20: [2024-10-29 12:14:20] iter = 06360, loss = 31.0368
2024-10-29 12:14:20: [2024-10-29 12:14:20] iter = 06370, loss = 9.4962
2024-10-29 12:14:20: [2024-10-29 12:14:20] iter = 06380, loss = 33.5402
2024-10-29 12:14:21: [2024-10-29 12:14:21] iter = 06390, loss = 2.7679
2024-10-29 12:14:21: [2024-10-29 12:14:21] iter = 06400, loss = 24.6522
2024-10-29 12:14:22: [2024-10-29 12:14:22] iter = 06410, loss = 3.2250
2024-10-29 12:14:22: [2024-10-29 12:14:22] iter = 06420, loss = 5.9089
2024-10-29 12:14:23: [2024-10-29 12:14:23] iter = 06430, loss = 6.2764
2024-10-29 12:14:23: [2024-10-29 12:14:23] iter = 06440, loss = 8.4826
2024-10-29 12:14:24: [2024-10-29 12:14:24] iter = 06450, loss = 4.6751
2024-10-29 12:14:24: [2024-10-29 12:14:24] iter = 06460, loss = 7.4869
2024-10-29 12:14:25: [2024-10-29 12:14:25] iter = 06470, loss = 32.2281
2024-10-29 12:14:25: [2024-10-29 12:14:25] iter = 06480, loss = 6.0935
2024-10-29 12:14:25: [2024-10-29 12:14:25] iter = 06490, loss = 17.9349
2024-10-29 12:14:26: [2024-10-29 12:14:26] iter = 06500, loss = 2.8676
2024-10-29 12:14:26: [2024-10-29 12:14:26] iter = 06510, loss = 34.1975
2024-10-29 12:14:27: [2024-10-29 12:14:27] iter = 06520, loss = 10.9144
2024-10-29 12:14:27: [2024-10-29 12:14:27] iter = 06530, loss = 38.9288
2024-10-29 12:14:28: [2024-10-29 12:14:28] iter = 06540, loss = 59.1676
2024-10-29 12:14:28: [2024-10-29 12:14:28] iter = 06550, loss = 4.8740
2024-10-29 12:14:29: [2024-10-29 12:14:29] iter = 06560, loss = 16.4986
2024-10-29 12:14:29: [2024-10-29 12:14:29] iter = 06570, loss = 21.4880
2024-10-29 12:14:29: [2024-10-29 12:14:29] iter = 06580, loss = 3.6245
2024-10-29 12:14:30: [2024-10-29 12:14:30] iter = 06590, loss = 14.3739
2024-10-29 12:14:30: [2024-10-29 12:14:30] iter = 06600, loss = 8.1074
2024-10-29 12:14:31: [2024-10-29 12:14:31] iter = 06610, loss = 3.9542
2024-10-29 12:14:31: [2024-10-29 12:14:31] iter = 06620, loss = 5.2779
2024-10-29 12:14:32: [2024-10-29 12:14:32] iter = 06630, loss = 4.0659
2024-10-29 12:14:32: [2024-10-29 12:14:32] iter = 06640, loss = 4.9588
2024-10-29 12:14:32: [2024-10-29 12:14:32] iter = 06650, loss = 3.7531
2024-10-29 12:14:33: [2024-10-29 12:14:33] iter = 06660, loss = 5.4680
2024-10-29 12:14:33: [2024-10-29 12:14:33] iter = 06670, loss = 6.5282
2024-10-29 12:14:34: [2024-10-29 12:14:34] iter = 06680, loss = 8.1236
2024-10-29 12:14:34: [2024-10-29 12:14:34] iter = 06690, loss = 19.5878
2024-10-29 12:14:35: [2024-10-29 12:14:35] iter = 06700, loss = 3.6589
2024-10-29 12:14:35: [2024-10-29 12:14:35] iter = 06710, loss = 48.7676
2024-10-29 12:14:36: [2024-10-29 12:14:36] iter = 06720, loss = 5.5158
2024-10-29 12:14:36: [2024-10-29 12:14:36] iter = 06730, loss = 5.2046
2024-10-29 12:14:37: [2024-10-29 12:14:37] iter = 06740, loss = 5.2423
2024-10-29 12:14:37: [2024-10-29 12:14:37] iter = 06750, loss = 6.1731
2024-10-29 12:14:38: [2024-10-29 12:14:38] iter = 06760, loss = 2.8039
2024-10-29 12:14:38: [2024-10-29 12:14:38] iter = 06770, loss = 3.5012
2024-10-29 12:14:38: [2024-10-29 12:14:38] iter = 06780, loss = 8.7102
2024-10-29 12:14:39: [2024-10-29 12:14:39] iter = 06790, loss = 20.7790
2024-10-29 12:14:39: [2024-10-29 12:14:39] iter = 06800, loss = 5.5108
2024-10-29 12:14:40: [2024-10-29 12:14:40] iter = 06810, loss = 16.0187
2024-10-29 12:14:40: [2024-10-29 12:14:40] iter = 06820, loss = 5.9734
2024-10-29 12:14:40: [2024-10-29 12:14:40] iter = 06830, loss = 6.7005
2024-10-29 12:14:41: [2024-10-29 12:14:41] iter = 06840, loss = 4.2828
2024-10-29 12:14:41: [2024-10-29 12:14:41] iter = 06850, loss = 8.5253
2024-10-29 12:14:41: [2024-10-29 12:14:41] iter = 06860, loss = 11.3343
2024-10-29 12:14:42: [2024-10-29 12:14:42] iter = 06870, loss = 9.6835
2024-10-29 12:14:43: [2024-10-29 12:14:43] iter = 06880, loss = 4.1073
2024-10-29 12:14:43: [2024-10-29 12:14:43] iter = 06890, loss = 9.0779
2024-10-29 12:14:43: [2024-10-29 12:14:43] iter = 06900, loss = 4.0245
2024-10-29 12:14:44: [2024-10-29 12:14:44] iter = 06910, loss = 28.1051
2024-10-29 12:14:44: [2024-10-29 12:14:44] iter = 06920, loss = 4.8727
2024-10-29 12:14:45: [2024-10-29 12:14:45] iter = 06930, loss = 5.7880
2024-10-29 12:14:46: [2024-10-29 12:14:46] iter = 06940, loss = 6.8973
2024-10-29 12:14:46: [2024-10-29 12:14:46] iter = 06950, loss = 38.6023
2024-10-29 12:14:46: [2024-10-29 12:14:46] iter = 06960, loss = 4.5497
2024-10-29 12:14:47: [2024-10-29 12:14:47] iter = 06970, loss = 6.8232
2024-10-29 12:14:47: [2024-10-29 12:14:47] iter = 06980, loss = 3.9827
2024-10-29 12:14:48: [2024-10-29 12:14:48] iter = 06990, loss = 4.8016
2024-10-29 12:14:48: [2024-10-29 12:14:48] iter = 07000, loss = 3.7262
2024-10-29 12:14:49: [2024-10-29 12:14:49] iter = 07010, loss = 2.4849
2024-10-29 12:14:49: [2024-10-29 12:14:49] iter = 07020, loss = 3.3988
2024-10-29 12:14:50: [2024-10-29 12:14:50] iter = 07030, loss = 2.3055
2024-10-29 12:14:51: [2024-10-29 12:14:51] iter = 07040, loss = 9.4062
2024-10-29 12:14:51: [2024-10-29 12:14:51] iter = 07050, loss = 8.9800
2024-10-29 12:14:52: [2024-10-29 12:14:52] iter = 07060, loss = 7.0991
2024-10-29 12:14:52: [2024-10-29 12:14:52] iter = 07070, loss = 44.3693
2024-10-29 12:14:53: [2024-10-29 12:14:53] iter = 07080, loss = 5.0154
2024-10-29 12:14:53: [2024-10-29 12:14:53] iter = 07090, loss = 4.8716
2024-10-29 12:14:53: [2024-10-29 12:14:53] iter = 07100, loss = 43.8313
2024-10-29 12:14:54: [2024-10-29 12:14:54] iter = 07110, loss = 12.7380
2024-10-29 12:14:55: [2024-10-29 12:14:55] iter = 07120, loss = 14.2885
2024-10-29 12:14:55: [2024-10-29 12:14:55] iter = 07130, loss = 12.2712
2024-10-29 12:14:56: [2024-10-29 12:14:56] iter = 07140, loss = 6.0512
2024-10-29 12:14:56: [2024-10-29 12:14:56] iter = 07150, loss = 10.8474
2024-10-29 12:14:56: [2024-10-29 12:14:56] iter = 07160, loss = 5.3627
2024-10-29 12:14:57: [2024-10-29 12:14:57] iter = 07170, loss = 4.7395
2024-10-29 12:14:57: [2024-10-29 12:14:57] iter = 07180, loss = 4.9118
2024-10-29 12:14:58: [2024-10-29 12:14:58] iter = 07190, loss = 7.3790
2024-10-29 12:14:58: [2024-10-29 12:14:58] iter = 07200, loss = 16.1357
2024-10-29 12:14:59: [2024-10-29 12:14:59] iter = 07210, loss = 10.2377
2024-10-29 12:14:59: [2024-10-29 12:14:59] iter = 07220, loss = 7.7675
2024-10-29 12:14:59: [2024-10-29 12:14:59] iter = 07230, loss = 3.0562
2024-10-29 12:15:00: [2024-10-29 12:15:00] iter = 07240, loss = 2.5195
2024-10-29 12:15:00: [2024-10-29 12:15:00] iter = 07250, loss = 17.9464
2024-10-29 12:15:01: [2024-10-29 12:15:01] iter = 07260, loss = 7.4428
2024-10-29 12:15:01: [2024-10-29 12:15:01] iter = 07270, loss = 5.0604
2024-10-29 12:15:01: [2024-10-29 12:15:01] iter = 07280, loss = 7.3083
2024-10-29 12:15:02: [2024-10-29 12:15:02] iter = 07290, loss = 23.3445
2024-10-29 12:15:02: [2024-10-29 12:15:02] iter = 07300, loss = 45.2620
2024-10-29 12:15:03: [2024-10-29 12:15:03] iter = 07310, loss = 4.4141
2024-10-29 12:15:03: [2024-10-29 12:15:03] iter = 07320, loss = 4.3614
2024-10-29 12:15:04: [2024-10-29 12:15:04] iter = 07330, loss = 8.5784
2024-10-29 12:15:04: [2024-10-29 12:15:04] iter = 07340, loss = 10.5133
2024-10-29 12:15:05: [2024-10-29 12:15:05] iter = 07350, loss = 12.1817
2024-10-29 12:15:05: [2024-10-29 12:15:05] iter = 07360, loss = 24.6034
2024-10-29 12:15:05: [2024-10-29 12:15:05] iter = 07370, loss = 5.6291
2024-10-29 12:15:06: [2024-10-29 12:15:06] iter = 07380, loss = 2.3492
2024-10-29 12:15:06: [2024-10-29 12:15:06] iter = 07390, loss = 31.2116
2024-10-29 12:15:07: [2024-10-29 12:15:07] iter = 07400, loss = 8.8640
2024-10-29 12:15:07: [2024-10-29 12:15:07] iter = 07410, loss = 10.8565
2024-10-29 12:15:08: [2024-10-29 12:15:08] iter = 07420, loss = 20.3997
2024-10-29 12:15:08: [2024-10-29 12:15:08] iter = 07430, loss = 2.6929
2024-10-29 12:15:08: [2024-10-29 12:15:08] iter = 07440, loss = 25.7254
2024-10-29 12:15:09: [2024-10-29 12:15:09] iter = 07450, loss = 2.8444
2024-10-29 12:15:09: [2024-10-29 12:15:09] iter = 07460, loss = 4.8212
2024-10-29 12:15:10: [2024-10-29 12:15:10] iter = 07470, loss = 6.8042
2024-10-29 12:15:10: [2024-10-29 12:15:10] iter = 07480, loss = 2.3872
2024-10-29 12:15:11: [2024-10-29 12:15:11] iter = 07490, loss = 2.9826
2024-10-29 12:15:11: [2024-10-29 12:15:11] iter = 07500, loss = 1.9971
2024-10-29 12:15:11: [2024-10-29 12:15:11] iter = 07510, loss = 4.3660
2024-10-29 12:15:12: [2024-10-29 12:15:12] iter = 07520, loss = 45.4250
2024-10-29 12:15:12: [2024-10-29 12:15:12] iter = 07530, loss = 2.9136
2024-10-29 12:15:13: [2024-10-29 12:15:13] iter = 07540, loss = 9.4078
2024-10-29 12:15:13: [2024-10-29 12:15:13] iter = 07550, loss = 4.1121
2024-10-29 12:15:14: [2024-10-29 12:15:14] iter = 07560, loss = 7.7294
2024-10-29 12:15:14: [2024-10-29 12:15:14] iter = 07570, loss = 30.6808
2024-10-29 12:15:15: [2024-10-29 12:15:15] iter = 07580, loss = 52.7492
2024-10-29 12:15:15: [2024-10-29 12:15:15] iter = 07590, loss = 2.1905
2024-10-29 12:15:15: [2024-10-29 12:15:15] iter = 07600, loss = 4.5923
2024-10-29 12:15:16: [2024-10-29 12:15:16] iter = 07610, loss = 12.2308
2024-10-29 12:15:16: [2024-10-29 12:15:16] iter = 07620, loss = 4.1650
2024-10-29 12:15:17: [2024-10-29 12:15:17] iter = 07630, loss = 2.9527
2024-10-29 12:15:17: [2024-10-29 12:15:17] iter = 07640, loss = 5.3520
2024-10-29 12:15:18: [2024-10-29 12:15:18] iter = 07650, loss = 3.7335
2024-10-29 12:15:18: [2024-10-29 12:15:18] iter = 07660, loss = 12.9959
2024-10-29 12:15:18: [2024-10-29 12:15:18] iter = 07670, loss = 2.6363
2024-10-29 12:15:19: [2024-10-29 12:15:19] iter = 07680, loss = 8.4251
2024-10-29 12:15:19: [2024-10-29 12:15:19] iter = 07690, loss = 5.2243
2024-10-29 12:15:20: [2024-10-29 12:15:20] iter = 07700, loss = 5.1033
2024-10-29 12:15:20: [2024-10-29 12:15:20] iter = 07710, loss = 21.8797
2024-10-29 12:15:21: [2024-10-29 12:15:21] iter = 07720, loss = 15.7983
2024-10-29 12:15:21: [2024-10-29 12:15:21] iter = 07730, loss = 5.1002
2024-10-29 12:15:21: [2024-10-29 12:15:21] iter = 07740, loss = 3.2454
2024-10-29 12:15:22: [2024-10-29 12:15:22] iter = 07750, loss = 3.9379
2024-10-29 12:15:22: [2024-10-29 12:15:22] iter = 07760, loss = 4.8785
2024-10-29 12:15:23: [2024-10-29 12:15:23] iter = 07770, loss = 2.3065
2024-10-29 12:15:23: [2024-10-29 12:15:23] iter = 07780, loss = 3.3435
2024-10-29 12:15:24: [2024-10-29 12:15:23] iter = 07790, loss = 11.4313
2024-10-29 12:15:24: [2024-10-29 12:15:24] iter = 07800, loss = 8.4384
2024-10-29 12:15:24: [2024-10-29 12:15:24] iter = 07810, loss = 8.5606
2024-10-29 12:15:25: [2024-10-29 12:15:25] iter = 07820, loss = 4.5979
2024-10-29 12:15:25: [2024-10-29 12:15:25] iter = 07830, loss = 3.5155
2024-10-29 12:15:26: [2024-10-29 12:15:26] iter = 07840, loss = 41.1512
2024-10-29 12:15:26: [2024-10-29 12:15:26] iter = 07850, loss = 2.5235
2024-10-29 12:15:27: [2024-10-29 12:15:27] iter = 07860, loss = 35.2112
2024-10-29 12:15:27: [2024-10-29 12:15:27] iter = 07870, loss = 7.7078
2024-10-29 12:15:27: [2024-10-29 12:15:27] iter = 07880, loss = 24.1189
2024-10-29 12:15:28: [2024-10-29 12:15:28] iter = 07890, loss = 31.6333
2024-10-29 12:15:28: [2024-10-29 12:15:28] iter = 07900, loss = 3.2033
2024-10-29 12:15:29: [2024-10-29 12:15:29] iter = 07910, loss = 17.8140
2024-10-29 12:15:29: [2024-10-29 12:15:29] iter = 07920, loss = 3.1771
2024-10-29 12:15:29: [2024-10-29 12:15:29] iter = 07930, loss = 3.6438
2024-10-29 12:15:30: [2024-10-29 12:15:30] iter = 07940, loss = 3.5578
2024-10-29 12:15:30: [2024-10-29 12:15:30] iter = 07950, loss = 10.9456
2024-10-29 12:15:31: [2024-10-29 12:15:31] iter = 07960, loss = 2.3882
2024-10-29 12:15:31: [2024-10-29 12:15:31] iter = 07970, loss = 2.8090
2024-10-29 12:15:32: [2024-10-29 12:15:32] iter = 07980, loss = 23.8695
2024-10-29 12:15:32: [2024-10-29 12:15:32] iter = 07990, loss = 5.3334
2024-10-29 12:15:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 12:15:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:15:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 33006}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:15:55: Evaluate 5 random ConvNet, ACCmean = 0.4972 ACCstd = 0.0114
-------------------------
2024-10-29 12:15:55: Evaluate 5 random ConvNet, SENmean = 0.4972 SENstd = 0.0114
-------------------------
2024-10-29 12:15:55: Evaluate 5 random ConvNet, SPEmean = 0.8324 SPEstd = 0.0038
-------------------------
2024-10-29 12:15:55: Evaluate 5 random ConvNet, F!mean = 0.4298 F!std = 0.0110
-------------------------
2024-10-29 12:15:55: Evaluate 5 random ConvNet, mean = 0.4972 std = 0.0114
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:15:55: [2024-10-29 12:15:55] iter = 08000, loss = 5.6232
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:15:56: [2024-10-29 12:15:56] iter = 08010, loss = 9.1315
2024-10-29 12:15:56: [2024-10-29 12:15:56] iter = 08020, loss = 9.5939
2024-10-29 12:15:57: [2024-10-29 12:15:57] iter = 08030, loss = 22.9719
2024-10-29 12:15:57: [2024-10-29 12:15:57] iter = 08040, loss = 3.1351
2024-10-29 12:15:58: [2024-10-29 12:15:58] iter = 08050, loss = 20.3159
2024-10-29 12:15:58: [2024-10-29 12:15:58] iter = 08060, loss = 4.9043
2024-10-29 12:15:58: [2024-10-29 12:15:58] iter = 08070, loss = 8.2636
2024-10-29 12:15:59: [2024-10-29 12:15:59] iter = 08080, loss = 4.6955
2024-10-29 12:15:59: [2024-10-29 12:15:59] iter = 08090, loss = 6.1217
2024-10-29 12:16:00: [2024-10-29 12:16:00] iter = 08100, loss = 3.4484
2024-10-29 12:16:00: [2024-10-29 12:16:00] iter = 08110, loss = 8.1190
2024-10-29 12:16:01: [2024-10-29 12:16:01] iter = 08120, loss = 22.9297
2024-10-29 12:16:01: [2024-10-29 12:16:01] iter = 08130, loss = 4.2345
2024-10-29 12:16:01: [2024-10-29 12:16:01] iter = 08140, loss = 9.9361
2024-10-29 12:16:02: [2024-10-29 12:16:02] iter = 08150, loss = 41.0909
2024-10-29 12:16:02: [2024-10-29 12:16:02] iter = 08160, loss = 8.5011
2024-10-29 12:16:03: [2024-10-29 12:16:03] iter = 08170, loss = 4.4543
2024-10-29 12:16:03: [2024-10-29 12:16:03] iter = 08180, loss = 7.5387
2024-10-29 12:16:04: [2024-10-29 12:16:04] iter = 08190, loss = 2.8476
2024-10-29 12:16:04: [2024-10-29 12:16:04] iter = 08200, loss = 4.1503
2024-10-29 12:16:04: [2024-10-29 12:16:04] iter = 08210, loss = 10.2274
2024-10-29 12:16:05: [2024-10-29 12:16:05] iter = 08220, loss = 4.3218
2024-10-29 12:16:05: [2024-10-29 12:16:05] iter = 08230, loss = 13.5899
2024-10-29 12:16:06: [2024-10-29 12:16:06] iter = 08240, loss = 11.1594
2024-10-29 12:16:06: [2024-10-29 12:16:06] iter = 08250, loss = 8.4722
2024-10-29 12:16:07: [2024-10-29 12:16:07] iter = 08260, loss = 2.7564
2024-10-29 12:16:07: [2024-10-29 12:16:07] iter = 08270, loss = 5.4295
2024-10-29 12:16:08: [2024-10-29 12:16:08] iter = 08280, loss = 12.6884
2024-10-29 12:16:08: [2024-10-29 12:16:08] iter = 08290, loss = 2.1718
2024-10-29 12:16:09: [2024-10-29 12:16:09] iter = 08300, loss = 3.7621
2024-10-29 12:16:09: [2024-10-29 12:16:09] iter = 08310, loss = 3.7232
2024-10-29 12:16:09: [2024-10-29 12:16:09] iter = 08320, loss = 5.4159
2024-10-29 12:16:10: [2024-10-29 12:16:10] iter = 08330, loss = 9.4897
2024-10-29 12:16:10: [2024-10-29 12:16:10] iter = 08340, loss = 3.0699
2024-10-29 12:16:11: [2024-10-29 12:16:11] iter = 08350, loss = 2.8018
2024-10-29 12:16:11: [2024-10-29 12:16:11] iter = 08360, loss = 5.5018
2024-10-29 12:16:12: [2024-10-29 12:16:12] iter = 08370, loss = 6.3820
2024-10-29 12:16:12: [2024-10-29 12:16:12] iter = 08380, loss = 5.2906
2024-10-29 12:16:12: [2024-10-29 12:16:12] iter = 08390, loss = 10.0225
2024-10-29 12:16:13: [2024-10-29 12:16:13] iter = 08400, loss = 3.3748
2024-10-29 12:16:13: [2024-10-29 12:16:13] iter = 08410, loss = 4.0749
2024-10-29 12:16:14: [2024-10-29 12:16:14] iter = 08420, loss = 5.2990
2024-10-29 12:16:14: [2024-10-29 12:16:14] iter = 08430, loss = 31.6063
2024-10-29 12:16:15: [2024-10-29 12:16:15] iter = 08440, loss = 5.6453
2024-10-29 12:16:15: [2024-10-29 12:16:15] iter = 08450, loss = 4.0462
2024-10-29 12:16:15: [2024-10-29 12:16:15] iter = 08460, loss = 7.9770
2024-10-29 12:16:16: [2024-10-29 12:16:16] iter = 08470, loss = 11.7989
2024-10-29 12:16:16: [2024-10-29 12:16:16] iter = 08480, loss = 4.5725
2024-10-29 12:16:17: [2024-10-29 12:16:17] iter = 08490, loss = 5.0258
2024-10-29 12:16:17: [2024-10-29 12:16:17] iter = 08500, loss = 12.1836
2024-10-29 12:16:17: [2024-10-29 12:16:17] iter = 08510, loss = 51.2710
2024-10-29 12:16:18: [2024-10-29 12:16:18] iter = 08520, loss = 3.8554
2024-10-29 12:16:18: [2024-10-29 12:16:18] iter = 08530, loss = 3.7874
2024-10-29 12:16:19: [2024-10-29 12:16:19] iter = 08540, loss = 4.9241
2024-10-29 12:16:19: [2024-10-29 12:16:19] iter = 08550, loss = 4.8841
2024-10-29 12:16:19: [2024-10-29 12:16:19] iter = 08560, loss = 6.0338
2024-10-29 12:16:20: [2024-10-29 12:16:20] iter = 08570, loss = 36.1217
2024-10-29 12:16:20: [2024-10-29 12:16:20] iter = 08580, loss = 15.0569
2024-10-29 12:16:21: [2024-10-29 12:16:21] iter = 08590, loss = 14.6174
2024-10-29 12:16:21: [2024-10-29 12:16:21] iter = 08600, loss = 2.7535
2024-10-29 12:16:21: [2024-10-29 12:16:21] iter = 08610, loss = 4.7848
2024-10-29 12:16:22: [2024-10-29 12:16:22] iter = 08620, loss = 9.4947
2024-10-29 12:16:22: [2024-10-29 12:16:22] iter = 08630, loss = 4.5690
2024-10-29 12:16:23: [2024-10-29 12:16:23] iter = 08640, loss = 14.2819
2024-10-29 12:16:23: [2024-10-29 12:16:23] iter = 08650, loss = 3.4543
2024-10-29 12:16:24: [2024-10-29 12:16:24] iter = 08660, loss = 6.0264
2024-10-29 12:16:24: [2024-10-29 12:16:24] iter = 08670, loss = 5.2531
2024-10-29 12:16:24: [2024-10-29 12:16:24] iter = 08680, loss = 9.4631
2024-10-29 12:16:25: [2024-10-29 12:16:25] iter = 08690, loss = 38.8928
2024-10-29 12:16:25: [2024-10-29 12:16:25] iter = 08700, loss = 3.1756
2024-10-29 12:16:26: [2024-10-29 12:16:26] iter = 08710, loss = 5.2803
2024-10-29 12:16:26: [2024-10-29 12:16:26] iter = 08720, loss = 3.1324
2024-10-29 12:16:27: [2024-10-29 12:16:27] iter = 08730, loss = 10.0878
2024-10-29 12:16:27: [2024-10-29 12:16:27] iter = 08740, loss = 5.8186
2024-10-29 12:16:28: [2024-10-29 12:16:28] iter = 08750, loss = 2.6714
2024-10-29 12:16:28: [2024-10-29 12:16:28] iter = 08760, loss = 4.6199
2024-10-29 12:16:28: [2024-10-29 12:16:28] iter = 08770, loss = 7.8510
2024-10-29 12:16:29: [2024-10-29 12:16:29] iter = 08780, loss = 3.3672
2024-10-29 12:16:29: [2024-10-29 12:16:29] iter = 08790, loss = 7.5836
2024-10-29 12:16:29: [2024-10-29 12:16:29] iter = 08800, loss = 2.1758
2024-10-29 12:16:30: [2024-10-29 12:16:30] iter = 08810, loss = 6.6371
2024-10-29 12:16:30: [2024-10-29 12:16:30] iter = 08820, loss = 4.4662
2024-10-29 12:16:30: [2024-10-29 12:16:30] iter = 08830, loss = 8.7502
2024-10-29 12:16:31: [2024-10-29 12:16:31] iter = 08840, loss = 4.4039
2024-10-29 12:16:31: [2024-10-29 12:16:31] iter = 08850, loss = 27.8576
2024-10-29 12:16:32: [2024-10-29 12:16:32] iter = 08860, loss = 37.8120
2024-10-29 12:16:32: [2024-10-29 12:16:32] iter = 08870, loss = 7.5089
2024-10-29 12:16:33: [2024-10-29 12:16:33] iter = 08880, loss = 12.3489
2024-10-29 12:16:33: [2024-10-29 12:16:33] iter = 08890, loss = 6.8701
2024-10-29 12:16:34: [2024-10-29 12:16:34] iter = 08900, loss = 33.0006
2024-10-29 12:16:34: [2024-10-29 12:16:34] iter = 08910, loss = 7.3488
2024-10-29 12:16:35: [2024-10-29 12:16:35] iter = 08920, loss = 5.4382
2024-10-29 12:16:35: [2024-10-29 12:16:35] iter = 08930, loss = 8.4266
2024-10-29 12:16:36: [2024-10-29 12:16:36] iter = 08940, loss = 29.2202
2024-10-29 12:16:36: [2024-10-29 12:16:36] iter = 08950, loss = 13.5862
2024-10-29 12:16:36: [2024-10-29 12:16:36] iter = 08960, loss = 3.0313
2024-10-29 12:16:37: [2024-10-29 12:16:37] iter = 08970, loss = 2.2016
2024-10-29 12:16:37: [2024-10-29 12:16:37] iter = 08980, loss = 3.0094
2024-10-29 12:16:38: [2024-10-29 12:16:38] iter = 08990, loss = 7.5014
2024-10-29 12:16:38: [2024-10-29 12:16:38] iter = 09000, loss = 3.4461
2024-10-29 12:16:39: [2024-10-29 12:16:39] iter = 09010, loss = 6.3357
2024-10-29 12:16:39: [2024-10-29 12:16:39] iter = 09020, loss = 5.7087
2024-10-29 12:16:39: [2024-10-29 12:16:39] iter = 09030, loss = 2.9091
2024-10-29 12:16:40: [2024-10-29 12:16:40] iter = 09040, loss = 6.1895
2024-10-29 12:16:40: [2024-10-29 12:16:40] iter = 09050, loss = 4.3834
2024-10-29 12:16:41: [2024-10-29 12:16:41] iter = 09060, loss = 5.0862
2024-10-29 12:16:41: [2024-10-29 12:16:41] iter = 09070, loss = 2.8793
2024-10-29 12:16:42: [2024-10-29 12:16:42] iter = 09080, loss = 56.3513
2024-10-29 12:16:42: [2024-10-29 12:16:42] iter = 09090, loss = 9.4985
2024-10-29 12:16:42: [2024-10-29 12:16:42] iter = 09100, loss = 4.0054
2024-10-29 12:16:43: [2024-10-29 12:16:43] iter = 09110, loss = 32.3528
2024-10-29 12:16:43: [2024-10-29 12:16:43] iter = 09120, loss = 28.6709
2024-10-29 12:16:44: [2024-10-29 12:16:44] iter = 09130, loss = 2.7432
2024-10-29 12:16:44: [2024-10-29 12:16:44] iter = 09140, loss = 4.8564
2024-10-29 12:16:45: [2024-10-29 12:16:45] iter = 09150, loss = 3.1629
2024-10-29 12:16:45: [2024-10-29 12:16:45] iter = 09160, loss = 26.9308
2024-10-29 12:16:46: [2024-10-29 12:16:46] iter = 09170, loss = 3.9208
2024-10-29 12:16:46: [2024-10-29 12:16:46] iter = 09180, loss = 14.9121
2024-10-29 12:16:46: [2024-10-29 12:16:46] iter = 09190, loss = 16.6399
2024-10-29 12:16:47: [2024-10-29 12:16:47] iter = 09200, loss = 5.7790
2024-10-29 12:16:47: [2024-10-29 12:16:47] iter = 09210, loss = 34.1320
2024-10-29 12:16:48: [2024-10-29 12:16:48] iter = 09220, loss = 24.0439
2024-10-29 12:16:48: [2024-10-29 12:16:48] iter = 09230, loss = 6.6013
2024-10-29 12:16:48: [2024-10-29 12:16:48] iter = 09240, loss = 5.1261
2024-10-29 12:16:49: [2024-10-29 12:16:49] iter = 09250, loss = 2.3454
2024-10-29 12:16:49: [2024-10-29 12:16:49] iter = 09260, loss = 28.5508
2024-10-29 12:16:50: [2024-10-29 12:16:50] iter = 09270, loss = 4.1448
2024-10-29 12:16:50: [2024-10-29 12:16:50] iter = 09280, loss = 30.7435
2024-10-29 12:16:51: [2024-10-29 12:16:51] iter = 09290, loss = 3.3805
2024-10-29 12:16:51: [2024-10-29 12:16:51] iter = 09300, loss = 3.9443
2024-10-29 12:16:51: [2024-10-29 12:16:51] iter = 09310, loss = 7.4624
2024-10-29 12:16:52: [2024-10-29 12:16:52] iter = 09320, loss = 4.2608
2024-10-29 12:16:52: [2024-10-29 12:16:52] iter = 09330, loss = 9.4584
2024-10-29 12:16:53: [2024-10-29 12:16:53] iter = 09340, loss = 4.9553
2024-10-29 12:16:53: [2024-10-29 12:16:53] iter = 09350, loss = 23.0254
2024-10-29 12:16:53: [2024-10-29 12:16:53] iter = 09360, loss = 4.6545
2024-10-29 12:16:54: [2024-10-29 12:16:54] iter = 09370, loss = 12.6177
2024-10-29 12:16:54: [2024-10-29 12:16:54] iter = 09380, loss = 9.0994
2024-10-29 12:16:55: [2024-10-29 12:16:55] iter = 09390, loss = 5.2884
2024-10-29 12:16:55: [2024-10-29 12:16:55] iter = 09400, loss = 3.5389
2024-10-29 12:16:56: [2024-10-29 12:16:56] iter = 09410, loss = 9.7259
2024-10-29 12:16:56: [2024-10-29 12:16:56] iter = 09420, loss = 3.8275
2024-10-29 12:16:56: [2024-10-29 12:16:56] iter = 09430, loss = 4.0260
2024-10-29 12:16:57: [2024-10-29 12:16:57] iter = 09440, loss = 6.1531
2024-10-29 12:16:57: [2024-10-29 12:16:57] iter = 09450, loss = 2.8836
2024-10-29 12:16:58: [2024-10-29 12:16:58] iter = 09460, loss = 2.1444
2024-10-29 12:16:58: [2024-10-29 12:16:58] iter = 09470, loss = 5.4014
2024-10-29 12:16:59: [2024-10-29 12:16:59] iter = 09480, loss = 6.9062
2024-10-29 12:16:59: [2024-10-29 12:16:59] iter = 09490, loss = 14.7983
2024-10-29 12:16:59: [2024-10-29 12:16:59] iter = 09500, loss = 3.4690
2024-10-29 12:17:00: [2024-10-29 12:17:00] iter = 09510, loss = 9.1835
2024-10-29 12:17:00: [2024-10-29 12:17:00] iter = 09520, loss = 2.9025
2024-10-29 12:17:01: [2024-10-29 12:17:01] iter = 09530, loss = 7.8828
2024-10-29 12:17:01: [2024-10-29 12:17:01] iter = 09540, loss = 10.8107
2024-10-29 12:17:02: [2024-10-29 12:17:02] iter = 09550, loss = 5.2623
2024-10-29 12:17:02: [2024-10-29 12:17:02] iter = 09560, loss = 3.0914
2024-10-29 12:17:02: [2024-10-29 12:17:02] iter = 09570, loss = 38.0153
2024-10-29 12:17:03: [2024-10-29 12:17:03] iter = 09580, loss = 12.6571
2024-10-29 12:17:03: [2024-10-29 12:17:03] iter = 09590, loss = 3.5971
2024-10-29 12:17:04: [2024-10-29 12:17:04] iter = 09600, loss = 4.0272
2024-10-29 12:17:04: [2024-10-29 12:17:04] iter = 09610, loss = 4.1250
2024-10-29 12:17:04: [2024-10-29 12:17:04] iter = 09620, loss = 3.0721
2024-10-29 12:17:05: [2024-10-29 12:17:05] iter = 09630, loss = 3.3492
2024-10-29 12:17:05: [2024-10-29 12:17:05] iter = 09640, loss = 2.7136
2024-10-29 12:17:06: [2024-10-29 12:17:06] iter = 09650, loss = 37.2505
2024-10-29 12:17:06: [2024-10-29 12:17:06] iter = 09660, loss = 9.4652
2024-10-29 12:17:07: [2024-10-29 12:17:07] iter = 09670, loss = 6.7973
2024-10-29 12:17:07: [2024-10-29 12:17:07] iter = 09680, loss = 32.1998
2024-10-29 12:17:08: [2024-10-29 12:17:08] iter = 09690, loss = 2.9239
2024-10-29 12:17:08: [2024-10-29 12:17:08] iter = 09700, loss = 5.0593
2024-10-29 12:17:08: [2024-10-29 12:17:08] iter = 09710, loss = 10.4018
2024-10-29 12:17:09: [2024-10-29 12:17:09] iter = 09720, loss = 13.3468
2024-10-29 12:17:09: [2024-10-29 12:17:09] iter = 09730, loss = 3.1013
2024-10-29 12:17:10: [2024-10-29 12:17:10] iter = 09740, loss = 7.1860
2024-10-29 12:17:10: [2024-10-29 12:17:10] iter = 09750, loss = 7.3733
2024-10-29 12:17:11: [2024-10-29 12:17:11] iter = 09760, loss = 6.7877
2024-10-29 12:17:11: [2024-10-29 12:17:11] iter = 09770, loss = 3.5896
2024-10-29 12:17:11: [2024-10-29 12:17:11] iter = 09780, loss = 40.2714
2024-10-29 12:17:12: [2024-10-29 12:17:12] iter = 09790, loss = 12.4875
2024-10-29 12:17:12: [2024-10-29 12:17:12] iter = 09800, loss = 5.5343
2024-10-29 12:17:13: [2024-10-29 12:17:13] iter = 09810, loss = 5.5744
2024-10-29 12:17:13: [2024-10-29 12:17:13] iter = 09820, loss = 5.9204
2024-10-29 12:17:14: [2024-10-29 12:17:14] iter = 09830, loss = 3.5362
2024-10-29 12:17:14: [2024-10-29 12:17:14] iter = 09840, loss = 5.6034
2024-10-29 12:17:15: [2024-10-29 12:17:15] iter = 09850, loss = 5.5566
2024-10-29 12:17:15: [2024-10-29 12:17:15] iter = 09860, loss = 3.2757
2024-10-29 12:17:16: [2024-10-29 12:17:16] iter = 09870, loss = 5.4920
2024-10-29 12:17:16: [2024-10-29 12:17:16] iter = 09880, loss = 2.9138
2024-10-29 12:17:16: [2024-10-29 12:17:16] iter = 09890, loss = 8.6361
2024-10-29 12:17:17: [2024-10-29 12:17:17] iter = 09900, loss = 7.4934
2024-10-29 12:17:17: [2024-10-29 12:17:17] iter = 09910, loss = 2.6348
2024-10-29 12:17:18: [2024-10-29 12:17:18] iter = 09920, loss = 2.0634
2024-10-29 12:17:18: [2024-10-29 12:17:18] iter = 09930, loss = 4.2040
2024-10-29 12:17:19: [2024-10-29 12:17:19] iter = 09940, loss = 21.5277
2024-10-29 12:17:19: [2024-10-29 12:17:19] iter = 09950, loss = 2.8872
2024-10-29 12:17:20: [2024-10-29 12:17:20] iter = 09960, loss = 5.1702
2024-10-29 12:17:20: [2024-10-29 12:17:20] iter = 09970, loss = 9.8101
2024-10-29 12:17:21: [2024-10-29 12:17:21] iter = 09980, loss = 16.5640
2024-10-29 12:17:21: [2024-10-29 12:17:21] iter = 09990, loss = 5.7056
2024-10-29 12:17:21: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 12:17:21: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:17:21: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 41842}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:17:43: Evaluate 5 random ConvNet, ACCmean = 0.4690 ACCstd = 0.0160
-------------------------
2024-10-29 12:17:43: Evaluate 5 random ConvNet, SENmean = 0.4690 SENstd = 0.0160
-------------------------
2024-10-29 12:17:43: Evaluate 5 random ConvNet, SPEmean = 0.8230 SPEstd = 0.0053
-------------------------
2024-10-29 12:17:43: Evaluate 5 random ConvNet, F!mean = 0.4292 F!std = 0.0214
-------------------------
2024-10-29 12:17:43: Evaluate 5 random ConvNet, mean = 0.4690 std = 0.0160
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:17:44: [2024-10-29 12:17:44] iter = 10000, loss = 4.6387
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:17:44: [2024-10-29 12:17:44] iter = 10010, loss = 2.5742
2024-10-29 12:17:44: [2024-10-29 12:17:44] iter = 10020, loss = 5.4435
2024-10-29 12:17:45: [2024-10-29 12:17:45] iter = 10030, loss = 9.9187
2024-10-29 12:17:45: [2024-10-29 12:17:45] iter = 10040, loss = 6.4051
2024-10-29 12:17:46: [2024-10-29 12:17:46] iter = 10050, loss = 16.7669
2024-10-29 12:17:46: [2024-10-29 12:17:46] iter = 10060, loss = 3.7113
2024-10-29 12:17:46: [2024-10-29 12:17:46] iter = 10070, loss = 3.8907
2024-10-29 12:17:47: [2024-10-29 12:17:47] iter = 10080, loss = 11.1602
2024-10-29 12:17:47: [2024-10-29 12:17:47] iter = 10090, loss = 2.8707
2024-10-29 12:17:48: [2024-10-29 12:17:48] iter = 10100, loss = 15.3408
2024-10-29 12:17:48: [2024-10-29 12:17:48] iter = 10110, loss = 3.3846
2024-10-29 12:17:49: [2024-10-29 12:17:49] iter = 10120, loss = 4.4750
2024-10-29 12:17:49: [2024-10-29 12:17:49] iter = 10130, loss = 8.2723
2024-10-29 12:17:50: [2024-10-29 12:17:50] iter = 10140, loss = 4.4561
2024-10-29 12:17:50: [2024-10-29 12:17:50] iter = 10150, loss = 3.3822
2024-10-29 12:17:51: [2024-10-29 12:17:51] iter = 10160, loss = 2.8941
2024-10-29 12:17:51: [2024-10-29 12:17:51] iter = 10170, loss = 3.1080
2024-10-29 12:17:51: [2024-10-29 12:17:51] iter = 10180, loss = 2.4892
2024-10-29 12:17:52: [2024-10-29 12:17:52] iter = 10190, loss = 4.1349
2024-10-29 12:17:52: [2024-10-29 12:17:52] iter = 10200, loss = 4.2708
2024-10-29 12:17:53: [2024-10-29 12:17:53] iter = 10210, loss = 2.9711
2024-10-29 12:17:53: [2024-10-29 12:17:53] iter = 10220, loss = 5.8013
2024-10-29 12:17:54: [2024-10-29 12:17:54] iter = 10230, loss = 10.5526
2024-10-29 12:17:54: [2024-10-29 12:17:54] iter = 10240, loss = 2.9146
2024-10-29 12:17:55: [2024-10-29 12:17:55] iter = 10250, loss = 7.3456
2024-10-29 12:17:55: [2024-10-29 12:17:55] iter = 10260, loss = 6.9885
2024-10-29 12:17:55: [2024-10-29 12:17:55] iter = 10270, loss = 13.2160
2024-10-29 12:17:56: [2024-10-29 12:17:56] iter = 10280, loss = 3.7018
2024-10-29 12:17:56: [2024-10-29 12:17:56] iter = 10290, loss = 5.3893
2024-10-29 12:17:57: [2024-10-29 12:17:57] iter = 10300, loss = 72.1441
2024-10-29 12:17:57: [2024-10-29 12:17:57] iter = 10310, loss = 7.1020
2024-10-29 12:17:58: [2024-10-29 12:17:58] iter = 10320, loss = 2.9843
2024-10-29 12:17:58: [2024-10-29 12:17:58] iter = 10330, loss = 2.1678
2024-10-29 12:17:59: [2024-10-29 12:17:59] iter = 10340, loss = 6.5276
2024-10-29 12:17:59: [2024-10-29 12:17:59] iter = 10350, loss = 7.8218
2024-10-29 12:17:59: [2024-10-29 12:17:59] iter = 10360, loss = 3.5304
2024-10-29 12:18:00: [2024-10-29 12:18:00] iter = 10370, loss = 16.1233
2024-10-29 12:18:00: [2024-10-29 12:18:00] iter = 10380, loss = 3.9571
2024-10-29 12:18:01: [2024-10-29 12:18:01] iter = 10390, loss = 5.9325
2024-10-29 12:18:01: [2024-10-29 12:18:01] iter = 10400, loss = 2.7962
2024-10-29 12:18:02: [2024-10-29 12:18:02] iter = 10410, loss = 3.7048
2024-10-29 12:18:02: [2024-10-29 12:18:02] iter = 10420, loss = 11.4166
2024-10-29 12:18:03: [2024-10-29 12:18:03] iter = 10430, loss = 3.3713
2024-10-29 12:18:03: [2024-10-29 12:18:03] iter = 10440, loss = 6.1925
2024-10-29 12:18:03: [2024-10-29 12:18:03] iter = 10450, loss = 4.6779
2024-10-29 12:18:04: [2024-10-29 12:18:04] iter = 10460, loss = 4.1306
2024-10-29 12:18:04: [2024-10-29 12:18:04] iter = 10470, loss = 3.6213
2024-10-29 12:18:05: [2024-10-29 12:18:05] iter = 10480, loss = 3.0687
2024-10-29 12:18:05: [2024-10-29 12:18:05] iter = 10490, loss = 7.0538
2024-10-29 12:18:06: [2024-10-29 12:18:06] iter = 10500, loss = 20.0078
2024-10-29 12:18:06: [2024-10-29 12:18:06] iter = 10510, loss = 9.1942
2024-10-29 12:18:07: [2024-10-29 12:18:07] iter = 10520, loss = 9.5495
2024-10-29 12:18:07: [2024-10-29 12:18:07] iter = 10530, loss = 5.5544
2024-10-29 12:18:08: [2024-10-29 12:18:08] iter = 10540, loss = 3.0537
2024-10-29 12:18:08: [2024-10-29 12:18:08] iter = 10550, loss = 6.3685
2024-10-29 12:18:08: [2024-10-29 12:18:08] iter = 10560, loss = 17.1338
2024-10-29 12:18:09: [2024-10-29 12:18:09] iter = 10570, loss = 15.2975
2024-10-29 12:18:09: [2024-10-29 12:18:09] iter = 10580, loss = 9.5946
2024-10-29 12:18:10: [2024-10-29 12:18:10] iter = 10590, loss = 3.7894
2024-10-29 12:18:10: [2024-10-29 12:18:10] iter = 10600, loss = 3.5809
2024-10-29 12:18:11: [2024-10-29 12:18:11] iter = 10610, loss = 5.7815
2024-10-29 12:18:11: [2024-10-29 12:18:11] iter = 10620, loss = 3.8439
2024-10-29 12:18:11: [2024-10-29 12:18:11] iter = 10630, loss = 4.1228
2024-10-29 12:18:12: [2024-10-29 12:18:12] iter = 10640, loss = 33.8150
2024-10-29 12:18:12: [2024-10-29 12:18:12] iter = 10650, loss = 10.5107
2024-10-29 12:18:13: [2024-10-29 12:18:13] iter = 10660, loss = 8.3948
2024-10-29 12:18:13: [2024-10-29 12:18:13] iter = 10670, loss = 9.2202
2024-10-29 12:18:14: [2024-10-29 12:18:14] iter = 10680, loss = 3.1790
2024-10-29 12:18:14: [2024-10-29 12:18:14] iter = 10690, loss = 2.9946
2024-10-29 12:18:15: [2024-10-29 12:18:15] iter = 10700, loss = 7.7779
2024-10-29 12:18:15: [2024-10-29 12:18:15] iter = 10710, loss = 9.1073
2024-10-29 12:18:16: [2024-10-29 12:18:16] iter = 10720, loss = 18.6652
2024-10-29 12:18:16: [2024-10-29 12:18:16] iter = 10730, loss = 3.2978
2024-10-29 12:18:16: [2024-10-29 12:18:16] iter = 10740, loss = 10.9220
2024-10-29 12:18:17: [2024-10-29 12:18:17] iter = 10750, loss = 8.6996
2024-10-29 12:18:17: [2024-10-29 12:18:17] iter = 10760, loss = 2.1111
2024-10-29 12:18:18: [2024-10-29 12:18:18] iter = 10770, loss = 8.5675
2024-10-29 12:18:18: [2024-10-29 12:18:18] iter = 10780, loss = 13.0979
2024-10-29 12:18:19: [2024-10-29 12:18:19] iter = 10790, loss = 2.3395
2024-10-29 12:18:19: [2024-10-29 12:18:19] iter = 10800, loss = 5.3768
2024-10-29 12:18:19: [2024-10-29 12:18:19] iter = 10810, loss = 5.2384
2024-10-29 12:18:20: [2024-10-29 12:18:20] iter = 10820, loss = 23.3706
2024-10-29 12:18:20: [2024-10-29 12:18:20] iter = 10830, loss = 3.9258
2024-10-29 12:18:21: [2024-10-29 12:18:21] iter = 10840, loss = 41.1104
2024-10-29 12:18:21: [2024-10-29 12:18:21] iter = 10850, loss = 30.7976
2024-10-29 12:18:22: [2024-10-29 12:18:22] iter = 10860, loss = 29.2816
2024-10-29 12:18:22: [2024-10-29 12:18:22] iter = 10870, loss = 6.2585
2024-10-29 12:18:23: [2024-10-29 12:18:23] iter = 10880, loss = 3.4182
2024-10-29 12:18:23: [2024-10-29 12:18:23] iter = 10890, loss = 3.9797
2024-10-29 12:18:23: [2024-10-29 12:18:23] iter = 10900, loss = 3.8301
2024-10-29 12:18:24: [2024-10-29 12:18:24] iter = 10910, loss = 3.4050
2024-10-29 12:18:24: [2024-10-29 12:18:24] iter = 10920, loss = 5.4024
2024-10-29 12:18:25: [2024-10-29 12:18:25] iter = 10930, loss = 3.2245
2024-10-29 12:18:25: [2024-10-29 12:18:25] iter = 10940, loss = 4.3541
2024-10-29 12:18:26: [2024-10-29 12:18:26] iter = 10950, loss = 7.7204
2024-10-29 12:18:26: [2024-10-29 12:18:26] iter = 10960, loss = 12.8433
2024-10-29 12:18:27: [2024-10-29 12:18:27] iter = 10970, loss = 22.4275
2024-10-29 12:18:27: [2024-10-29 12:18:27] iter = 10980, loss = 10.2591
2024-10-29 12:18:28: [2024-10-29 12:18:28] iter = 10990, loss = 5.1965
2024-10-29 12:18:28: [2024-10-29 12:18:28] iter = 11000, loss = 4.6593
2024-10-29 12:18:29: [2024-10-29 12:18:29] iter = 11010, loss = 4.4830
2024-10-29 12:18:29: [2024-10-29 12:18:29] iter = 11020, loss = 4.8505
2024-10-29 12:18:30: [2024-10-29 12:18:30] iter = 11030, loss = 20.1332
2024-10-29 12:18:30: [2024-10-29 12:18:30] iter = 11040, loss = 4.3562
2024-10-29 12:18:30: [2024-10-29 12:18:30] iter = 11050, loss = 10.5485
2024-10-29 12:18:31: [2024-10-29 12:18:31] iter = 11060, loss = 32.8722
2024-10-29 12:18:31: [2024-10-29 12:18:31] iter = 11070, loss = 37.3036
2024-10-29 12:18:32: [2024-10-29 12:18:32] iter = 11080, loss = 24.5789
2024-10-29 12:18:32: [2024-10-29 12:18:32] iter = 11090, loss = 15.2268
2024-10-29 12:18:33: [2024-10-29 12:18:33] iter = 11100, loss = 4.4845
2024-10-29 12:18:33: [2024-10-29 12:18:33] iter = 11110, loss = 3.7435
2024-10-29 12:18:34: [2024-10-29 12:18:34] iter = 11120, loss = 3.6371
2024-10-29 12:18:34: [2024-10-29 12:18:34] iter = 11130, loss = 3.6143
2024-10-29 12:18:34: [2024-10-29 12:18:34] iter = 11140, loss = 3.7834
2024-10-29 12:18:35: [2024-10-29 12:18:35] iter = 11150, loss = 2.8667
2024-10-29 12:18:35: [2024-10-29 12:18:35] iter = 11160, loss = 6.1783
2024-10-29 12:18:36: [2024-10-29 12:18:36] iter = 11170, loss = 2.6164
2024-10-29 12:18:36: [2024-10-29 12:18:36] iter = 11180, loss = 3.3663
2024-10-29 12:18:37: [2024-10-29 12:18:37] iter = 11190, loss = 4.8958
2024-10-29 12:18:37: [2024-10-29 12:18:37] iter = 11200, loss = 11.7302
2024-10-29 12:18:37: [2024-10-29 12:18:37] iter = 11210, loss = 3.9744
2024-10-29 12:18:38: [2024-10-29 12:18:38] iter = 11220, loss = 3.8456
2024-10-29 12:18:38: [2024-10-29 12:18:38] iter = 11230, loss = 4.5794
2024-10-29 12:18:39: [2024-10-29 12:18:39] iter = 11240, loss = 23.1872
2024-10-29 12:18:39: [2024-10-29 12:18:39] iter = 11250, loss = 3.1796
2024-10-29 12:18:40: [2024-10-29 12:18:40] iter = 11260, loss = 59.2109
2024-10-29 12:18:40: [2024-10-29 12:18:40] iter = 11270, loss = 3.4766
2024-10-29 12:18:40: [2024-10-29 12:18:40] iter = 11280, loss = 7.4083
2024-10-29 12:18:41: [2024-10-29 12:18:41] iter = 11290, loss = 4.9621
2024-10-29 12:18:41: [2024-10-29 12:18:41] iter = 11300, loss = 8.5166
2024-10-29 12:18:42: [2024-10-29 12:18:42] iter = 11310, loss = 3.1369
2024-10-29 12:18:42: [2024-10-29 12:18:42] iter = 11320, loss = 11.2130
2024-10-29 12:18:42: [2024-10-29 12:18:42] iter = 11330, loss = 3.9065
2024-10-29 12:18:43: [2024-10-29 12:18:43] iter = 11340, loss = 5.3565
2024-10-29 12:18:43: [2024-10-29 12:18:43] iter = 11350, loss = 11.2174
2024-10-29 12:18:44: [2024-10-29 12:18:44] iter = 11360, loss = 5.0897
2024-10-29 12:18:44: [2024-10-29 12:18:44] iter = 11370, loss = 4.2853
2024-10-29 12:18:44: [2024-10-29 12:18:44] iter = 11380, loss = 50.3405
2024-10-29 12:18:45: [2024-10-29 12:18:45] iter = 11390, loss = 5.3904
2024-10-29 12:18:45: [2024-10-29 12:18:45] iter = 11400, loss = 10.1078
2024-10-29 12:18:46: [2024-10-29 12:18:46] iter = 11410, loss = 5.3251
2024-10-29 12:18:46: [2024-10-29 12:18:46] iter = 11420, loss = 4.4598
2024-10-29 12:18:47: [2024-10-29 12:18:47] iter = 11430, loss = 3.1827
2024-10-29 12:18:47: [2024-10-29 12:18:47] iter = 11440, loss = 11.0558
2024-10-29 12:18:47: [2024-10-29 12:18:47] iter = 11450, loss = 5.5035
2024-10-29 12:18:48: [2024-10-29 12:18:48] iter = 11460, loss = 4.0272
2024-10-29 12:18:48: [2024-10-29 12:18:48] iter = 11470, loss = 3.6121
2024-10-29 12:18:49: [2024-10-29 12:18:49] iter = 11480, loss = 6.2423
2024-10-29 12:18:49: [2024-10-29 12:18:49] iter = 11490, loss = 5.1269
2024-10-29 12:18:49: [2024-10-29 12:18:49] iter = 11500, loss = 4.8326
2024-10-29 12:18:50: [2024-10-29 12:18:50] iter = 11510, loss = 14.6552
2024-10-29 12:18:50: [2024-10-29 12:18:50] iter = 11520, loss = 7.8256
2024-10-29 12:18:51: [2024-10-29 12:18:51] iter = 11530, loss = 5.0888
2024-10-29 12:18:51: [2024-10-29 12:18:51] iter = 11540, loss = 3.9719
2024-10-29 12:18:51: [2024-10-29 12:18:51] iter = 11550, loss = 2.8505
2024-10-29 12:18:52: [2024-10-29 12:18:52] iter = 11560, loss = 2.2990
2024-10-29 12:18:52: [2024-10-29 12:18:52] iter = 11570, loss = 5.3013
2024-10-29 12:18:53: [2024-10-29 12:18:53] iter = 11580, loss = 12.0512
2024-10-29 12:18:53: [2024-10-29 12:18:53] iter = 11590, loss = 5.9872
2024-10-29 12:18:54: [2024-10-29 12:18:54] iter = 11600, loss = 5.0266
2024-10-29 12:18:54: [2024-10-29 12:18:54] iter = 11610, loss = 36.8009
2024-10-29 12:18:54: [2024-10-29 12:18:54] iter = 11620, loss = 5.5403
2024-10-29 12:18:55: [2024-10-29 12:18:55] iter = 11630, loss = 8.3533
2024-10-29 12:18:55: [2024-10-29 12:18:55] iter = 11640, loss = 8.0707
2024-10-29 12:18:56: [2024-10-29 12:18:56] iter = 11650, loss = 10.4251
2024-10-29 12:18:56: [2024-10-29 12:18:56] iter = 11660, loss = 7.3648
2024-10-29 12:18:57: [2024-10-29 12:18:57] iter = 11670, loss = 5.3013
2024-10-29 12:18:57: [2024-10-29 12:18:57] iter = 11680, loss = 8.1250
2024-10-29 12:18:58: [2024-10-29 12:18:58] iter = 11690, loss = 2.7665
2024-10-29 12:18:58: [2024-10-29 12:18:58] iter = 11700, loss = 8.0408
2024-10-29 12:18:58: [2024-10-29 12:18:58] iter = 11710, loss = 13.1431
2024-10-29 12:18:59: [2024-10-29 12:18:59] iter = 11720, loss = 4.3564
2024-10-29 12:18:59: [2024-10-29 12:18:59] iter = 11730, loss = 4.2097
2024-10-29 12:19:00: [2024-10-29 12:19:00] iter = 11740, loss = 4.0819
2024-10-29 12:19:00: [2024-10-29 12:19:00] iter = 11750, loss = 3.4707
2024-10-29 12:19:01: [2024-10-29 12:19:01] iter = 11760, loss = 5.0030
2024-10-29 12:19:01: [2024-10-29 12:19:01] iter = 11770, loss = 4.5770
2024-10-29 12:19:01: [2024-10-29 12:19:01] iter = 11780, loss = 8.1554
2024-10-29 12:19:02: [2024-10-29 12:19:02] iter = 11790, loss = 4.9784
2024-10-29 12:19:02: [2024-10-29 12:19:02] iter = 11800, loss = 19.2671
2024-10-29 12:19:03: [2024-10-29 12:19:03] iter = 11810, loss = 3.0672
2024-10-29 12:19:03: [2024-10-29 12:19:03] iter = 11820, loss = 3.8373
2024-10-29 12:19:04: [2024-10-29 12:19:04] iter = 11830, loss = 9.1965
2024-10-29 12:19:04: [2024-10-29 12:19:04] iter = 11840, loss = 10.2423
2024-10-29 12:19:05: [2024-10-29 12:19:05] iter = 11850, loss = 30.5921
2024-10-29 12:19:05: [2024-10-29 12:19:05] iter = 11860, loss = 3.0268
2024-10-29 12:19:06: [2024-10-29 12:19:06] iter = 11870, loss = 41.4681
2024-10-29 12:19:06: [2024-10-29 12:19:06] iter = 11880, loss = 8.5961
2024-10-29 12:19:07: [2024-10-29 12:19:07] iter = 11890, loss = 3.2946
2024-10-29 12:19:07: [2024-10-29 12:19:07] iter = 11900, loss = 6.5529
2024-10-29 12:19:07: [2024-10-29 12:19:07] iter = 11910, loss = 9.7649
2024-10-29 12:19:08: [2024-10-29 12:19:08] iter = 11920, loss = 21.4617
2024-10-29 12:19:08: [2024-10-29 12:19:08] iter = 11930, loss = 5.6456
2024-10-29 12:19:09: [2024-10-29 12:19:09] iter = 11940, loss = 7.7139
2024-10-29 12:19:09: [2024-10-29 12:19:09] iter = 11950, loss = 3.2486
2024-10-29 12:19:10: [2024-10-29 12:19:10] iter = 11960, loss = 5.5130
2024-10-29 12:19:10: [2024-10-29 12:19:10] iter = 11970, loss = 1.9920
2024-10-29 12:19:11: [2024-10-29 12:19:11] iter = 11980, loss = 19.7067
2024-10-29 12:19:11: [2024-10-29 12:19:11] iter = 11990, loss = 3.0506
2024-10-29 12:19:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 12:19:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:19:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52032}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:19:35: Evaluate 5 random ConvNet, ACCmean = 0.5534 ACCstd = 0.0056
-------------------------
2024-10-29 12:19:35: Evaluate 5 random ConvNet, SENmean = 0.5534 SENstd = 0.0056
-------------------------
2024-10-29 12:19:35: Evaluate 5 random ConvNet, SPEmean = 0.8511 SPEstd = 0.0019
-------------------------
2024-10-29 12:19:35: Evaluate 5 random ConvNet, F!mean = 0.5413 F!std = 0.0068
-------------------------
2024-10-29 12:19:35: Evaluate 5 random ConvNet, mean = 0.5534 std = 0.0056
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:19:35: [2024-10-29 12:19:35] iter = 12000, loss = 2.5896
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:19:36: [2024-10-29 12:19:36] iter = 12010, loss = 2.6353
2024-10-29 12:19:36: [2024-10-29 12:19:36] iter = 12020, loss = 3.6947
2024-10-29 12:19:36: [2024-10-29 12:19:36] iter = 12030, loss = 5.7933
2024-10-29 12:19:37: [2024-10-29 12:19:37] iter = 12040, loss = 3.1994
2024-10-29 12:19:37: [2024-10-29 12:19:37] iter = 12050, loss = 10.0451
2024-10-29 12:19:38: [2024-10-29 12:19:38] iter = 12060, loss = 5.9385
2024-10-29 12:19:38: [2024-10-29 12:19:38] iter = 12070, loss = 13.5334
2024-10-29 12:19:39: [2024-10-29 12:19:39] iter = 12080, loss = 3.7627
2024-10-29 12:19:39: [2024-10-29 12:19:39] iter = 12090, loss = 2.7023
2024-10-29 12:19:40: [2024-10-29 12:19:40] iter = 12100, loss = 15.9217
2024-10-29 12:19:40: [2024-10-29 12:19:40] iter = 12110, loss = 3.4112
2024-10-29 12:19:40: [2024-10-29 12:19:40] iter = 12120, loss = 7.3259
2024-10-29 12:19:41: [2024-10-29 12:19:41] iter = 12130, loss = 5.3577
2024-10-29 12:19:41: [2024-10-29 12:19:41] iter = 12140, loss = 2.8984
2024-10-29 12:19:42: [2024-10-29 12:19:42] iter = 12150, loss = 20.4719
2024-10-29 12:19:42: [2024-10-29 12:19:42] iter = 12160, loss = 8.1168
2024-10-29 12:19:43: [2024-10-29 12:19:43] iter = 12170, loss = 33.9003
2024-10-29 12:19:43: [2024-10-29 12:19:43] iter = 12180, loss = 5.0109
2024-10-29 12:19:43: [2024-10-29 12:19:43] iter = 12190, loss = 49.0283
2024-10-29 12:19:44: [2024-10-29 12:19:44] iter = 12200, loss = 3.7899
2024-10-29 12:19:44: [2024-10-29 12:19:44] iter = 12210, loss = 21.0625
2024-10-29 12:19:45: [2024-10-29 12:19:45] iter = 12220, loss = 2.0721
2024-10-29 12:19:45: [2024-10-29 12:19:45] iter = 12230, loss = 4.4539
2024-10-29 12:19:45: [2024-10-29 12:19:45] iter = 12240, loss = 50.8524
2024-10-29 12:19:46: [2024-10-29 12:19:46] iter = 12250, loss = 3.1314
2024-10-29 12:19:46: [2024-10-29 12:19:46] iter = 12260, loss = 4.7487
2024-10-29 12:19:47: [2024-10-29 12:19:47] iter = 12270, loss = 10.6897
2024-10-29 12:19:47: [2024-10-29 12:19:47] iter = 12280, loss = 12.0761
2024-10-29 12:19:48: [2024-10-29 12:19:48] iter = 12290, loss = 11.6416
2024-10-29 12:19:48: [2024-10-29 12:19:48] iter = 12300, loss = 7.0391
2024-10-29 12:19:49: [2024-10-29 12:19:49] iter = 12310, loss = 35.8864
2024-10-29 12:19:49: [2024-10-29 12:19:49] iter = 12320, loss = 18.9734
2024-10-29 12:19:50: [2024-10-29 12:19:50] iter = 12330, loss = 3.4372
2024-10-29 12:19:50: [2024-10-29 12:19:50] iter = 12340, loss = 3.5973
2024-10-29 12:19:50: [2024-10-29 12:19:50] iter = 12350, loss = 12.5374
2024-10-29 12:19:51: [2024-10-29 12:19:51] iter = 12360, loss = 10.0831
2024-10-29 12:19:51: [2024-10-29 12:19:51] iter = 12370, loss = 3.5918
2024-10-29 12:19:51: [2024-10-29 12:19:51] iter = 12380, loss = 3.1802
2024-10-29 12:19:52: [2024-10-29 12:19:52] iter = 12390, loss = 2.5223
2024-10-29 12:19:52: [2024-10-29 12:19:52] iter = 12400, loss = 4.6073
2024-10-29 12:19:52: [2024-10-29 12:19:52] iter = 12410, loss = 3.3604
2024-10-29 12:19:53: [2024-10-29 12:19:53] iter = 12420, loss = 3.2029
2024-10-29 12:19:53: [2024-10-29 12:19:53] iter = 12430, loss = 9.1500
2024-10-29 12:19:53: [2024-10-29 12:19:53] iter = 12440, loss = 3.5864
2024-10-29 12:19:54: [2024-10-29 12:19:54] iter = 12450, loss = 9.7970
2024-10-29 12:19:54: [2024-10-29 12:19:54] iter = 12460, loss = 3.2447
2024-10-29 12:19:55: [2024-10-29 12:19:55] iter = 12470, loss = 4.0324
2024-10-29 12:19:55: [2024-10-29 12:19:55] iter = 12480, loss = 7.3665
2024-10-29 12:19:55: [2024-10-29 12:19:55] iter = 12490, loss = 3.8166
2024-10-29 12:19:56: [2024-10-29 12:19:56] iter = 12500, loss = 3.8899
2024-10-29 12:19:56: [2024-10-29 12:19:56] iter = 12510, loss = 14.3125
2024-10-29 12:19:57: [2024-10-29 12:19:57] iter = 12520, loss = 16.4983
2024-10-29 12:19:57: [2024-10-29 12:19:57] iter = 12530, loss = 12.3360
2024-10-29 12:19:57: [2024-10-29 12:19:57] iter = 12540, loss = 7.4806
2024-10-29 12:19:58: [2024-10-29 12:19:58] iter = 12550, loss = 7.1052
2024-10-29 12:19:58: [2024-10-29 12:19:58] iter = 12560, loss = 4.8433
2024-10-29 12:19:59: [2024-10-29 12:19:59] iter = 12570, loss = 34.7626
2024-10-29 12:19:59: [2024-10-29 12:19:59] iter = 12580, loss = 4.4864
2024-10-29 12:20:00: [2024-10-29 12:20:00] iter = 12590, loss = 5.1288
2024-10-29 12:20:00: [2024-10-29 12:20:00] iter = 12600, loss = 2.6709
2024-10-29 12:20:01: [2024-10-29 12:20:01] iter = 12610, loss = 11.9938
2024-10-29 12:20:01: [2024-10-29 12:20:01] iter = 12620, loss = 3.4715
2024-10-29 12:20:01: [2024-10-29 12:20:01] iter = 12630, loss = 3.1794
2024-10-29 12:20:02: [2024-10-29 12:20:02] iter = 12640, loss = 5.2606
2024-10-29 12:20:02: [2024-10-29 12:20:02] iter = 12650, loss = 34.7364
2024-10-29 12:20:03: [2024-10-29 12:20:03] iter = 12660, loss = 14.8831
2024-10-29 12:20:03: [2024-10-29 12:20:03] iter = 12670, loss = 6.1910
2024-10-29 12:20:03: [2024-10-29 12:20:03] iter = 12680, loss = 4.6314
2024-10-29 12:20:04: [2024-10-29 12:20:04] iter = 12690, loss = 3.5586
2024-10-29 12:20:04: [2024-10-29 12:20:04] iter = 12700, loss = 3.9146
2024-10-29 12:20:05: [2024-10-29 12:20:05] iter = 12710, loss = 6.7227
2024-10-29 12:20:05: [2024-10-29 12:20:05] iter = 12720, loss = 40.0500
2024-10-29 12:20:05: [2024-10-29 12:20:05] iter = 12730, loss = 4.1143
2024-10-29 12:20:06: [2024-10-29 12:20:06] iter = 12740, loss = 25.7458
2024-10-29 12:20:06: [2024-10-29 12:20:06] iter = 12750, loss = 23.5430
2024-10-29 12:20:07: [2024-10-29 12:20:07] iter = 12760, loss = 3.7149
2024-10-29 12:20:07: [2024-10-29 12:20:07] iter = 12770, loss = 3.5800
2024-10-29 12:20:08: [2024-10-29 12:20:08] iter = 12780, loss = 6.0964
2024-10-29 12:20:08: [2024-10-29 12:20:08] iter = 12790, loss = 16.7279
2024-10-29 12:20:08: [2024-10-29 12:20:08] iter = 12800, loss = 5.1297
2024-10-29 12:20:09: [2024-10-29 12:20:09] iter = 12810, loss = 2.4914
2024-10-29 12:20:09: [2024-10-29 12:20:09] iter = 12820, loss = 40.9435
2024-10-29 12:20:10: [2024-10-29 12:20:10] iter = 12830, loss = 7.6211
2024-10-29 12:20:10: [2024-10-29 12:20:10] iter = 12840, loss = 9.4477
2024-10-29 12:20:10: [2024-10-29 12:20:10] iter = 12850, loss = 64.7202
2024-10-29 12:20:11: [2024-10-29 12:20:11] iter = 12860, loss = 13.3270
2024-10-29 12:20:11: [2024-10-29 12:20:11] iter = 12870, loss = 2.8663
2024-10-29 12:20:12: [2024-10-29 12:20:12] iter = 12880, loss = 6.0037
2024-10-29 12:20:12: [2024-10-29 12:20:12] iter = 12890, loss = 5.9207
2024-10-29 12:20:13: [2024-10-29 12:20:13] iter = 12900, loss = 16.3567
2024-10-29 12:20:13: [2024-10-29 12:20:13] iter = 12910, loss = 52.9904
2024-10-29 12:20:13: [2024-10-29 12:20:13] iter = 12920, loss = 5.7690
2024-10-29 12:20:14: [2024-10-29 12:20:14] iter = 12930, loss = 6.3448
2024-10-29 12:20:14: [2024-10-29 12:20:14] iter = 12940, loss = 33.0132
2024-10-29 12:20:15: [2024-10-29 12:20:15] iter = 12950, loss = 6.6076
2024-10-29 12:20:15: [2024-10-29 12:20:15] iter = 12960, loss = 4.5766
2024-10-29 12:20:16: [2024-10-29 12:20:16] iter = 12970, loss = 4.3579
2024-10-29 12:20:16: [2024-10-29 12:20:16] iter = 12980, loss = 50.8415
2024-10-29 12:20:17: [2024-10-29 12:20:17] iter = 12990, loss = 7.8086
2024-10-29 12:20:17: [2024-10-29 12:20:17] iter = 13000, loss = 4.5533
2024-10-29 12:20:17: [2024-10-29 12:20:17] iter = 13010, loss = 4.3442
2024-10-29 12:20:18: [2024-10-29 12:20:18] iter = 13020, loss = 5.3576
2024-10-29 12:20:18: [2024-10-29 12:20:18] iter = 13030, loss = 4.7310
2024-10-29 12:20:19: [2024-10-29 12:20:19] iter = 13040, loss = 2.9543
2024-10-29 12:20:19: [2024-10-29 12:20:19] iter = 13050, loss = 3.5719
2024-10-29 12:20:20: [2024-10-29 12:20:20] iter = 13060, loss = 16.1592
2024-10-29 12:20:20: [2024-10-29 12:20:20] iter = 13070, loss = 3.2573
2024-10-29 12:20:21: [2024-10-29 12:20:21] iter = 13080, loss = 3.9973
2024-10-29 12:20:21: [2024-10-29 12:20:21] iter = 13090, loss = 31.4772
2024-10-29 12:20:22: [2024-10-29 12:20:22] iter = 13100, loss = 4.3583
2024-10-29 12:20:22: [2024-10-29 12:20:22] iter = 13110, loss = 2.2704
2024-10-29 12:20:23: [2024-10-29 12:20:23] iter = 13120, loss = 14.3877
2024-10-29 12:20:23: [2024-10-29 12:20:23] iter = 13130, loss = 2.6870
2024-10-29 12:20:24: [2024-10-29 12:20:24] iter = 13140, loss = 4.6415
2024-10-29 12:20:24: [2024-10-29 12:20:24] iter = 13150, loss = 17.5057
2024-10-29 12:20:24: [2024-10-29 12:20:24] iter = 13160, loss = 7.8893
2024-10-29 12:20:25: [2024-10-29 12:20:25] iter = 13170, loss = 10.1606
2024-10-29 12:20:25: [2024-10-29 12:20:25] iter = 13180, loss = 13.7920
2024-10-29 12:20:26: [2024-10-29 12:20:26] iter = 13190, loss = 3.7188
2024-10-29 12:20:26: [2024-10-29 12:20:26] iter = 13200, loss = 8.7458
2024-10-29 12:20:27: [2024-10-29 12:20:27] iter = 13210, loss = 12.8333
2024-10-29 12:20:27: [2024-10-29 12:20:27] iter = 13220, loss = 4.6216
2024-10-29 12:20:28: [2024-10-29 12:20:28] iter = 13230, loss = 7.8139
2024-10-29 12:20:28: [2024-10-29 12:20:28] iter = 13240, loss = 4.0160
2024-10-29 12:20:28: [2024-10-29 12:20:28] iter = 13250, loss = 6.4401
2024-10-29 12:20:29: [2024-10-29 12:20:29] iter = 13260, loss = 4.7286
2024-10-29 12:20:29: [2024-10-29 12:20:29] iter = 13270, loss = 8.7404
2024-10-29 12:20:30: [2024-10-29 12:20:30] iter = 13280, loss = 2.4177
2024-10-29 12:20:30: [2024-10-29 12:20:30] iter = 13290, loss = 7.6610
2024-10-29 12:20:31: [2024-10-29 12:20:31] iter = 13300, loss = 9.4954
2024-10-29 12:20:31: [2024-10-29 12:20:31] iter = 13310, loss = 38.0550
2024-10-29 12:20:32: [2024-10-29 12:20:32] iter = 13320, loss = 4.9129
2024-10-29 12:20:32: [2024-10-29 12:20:32] iter = 13330, loss = 4.3482
2024-10-29 12:20:32: [2024-10-29 12:20:32] iter = 13340, loss = 5.0485
2024-10-29 12:20:33: [2024-10-29 12:20:33] iter = 13350, loss = 4.3398
2024-10-29 12:20:33: [2024-10-29 12:20:33] iter = 13360, loss = 6.4831
2024-10-29 12:20:34: [2024-10-29 12:20:34] iter = 13370, loss = 17.1243
2024-10-29 12:20:34: [2024-10-29 12:20:34] iter = 13380, loss = 6.9660
2024-10-29 12:20:35: [2024-10-29 12:20:35] iter = 13390, loss = 60.5520
2024-10-29 12:20:35: [2024-10-29 12:20:35] iter = 13400, loss = 11.0691
2024-10-29 12:20:36: [2024-10-29 12:20:36] iter = 13410, loss = 5.2047
2024-10-29 12:20:36: [2024-10-29 12:20:36] iter = 13420, loss = 9.4591
2024-10-29 12:20:36: [2024-10-29 12:20:36] iter = 13430, loss = 3.6008
2024-10-29 12:20:37: [2024-10-29 12:20:37] iter = 13440, loss = 5.8410
2024-10-29 12:20:37: [2024-10-29 12:20:37] iter = 13450, loss = 10.1366
2024-10-29 12:20:38: [2024-10-29 12:20:38] iter = 13460, loss = 5.6326
2024-10-29 12:20:38: [2024-10-29 12:20:38] iter = 13470, loss = 4.2852
2024-10-29 12:20:39: [2024-10-29 12:20:39] iter = 13480, loss = 3.0360
2024-10-29 12:20:39: [2024-10-29 12:20:39] iter = 13490, loss = 25.4587
2024-10-29 12:20:39: [2024-10-29 12:20:39] iter = 13500, loss = 3.9002
2024-10-29 12:20:40: [2024-10-29 12:20:40] iter = 13510, loss = 90.3606
2024-10-29 12:20:40: [2024-10-29 12:20:40] iter = 13520, loss = 3.2705
2024-10-29 12:20:41: [2024-10-29 12:20:41] iter = 13530, loss = 4.1356
2024-10-29 12:20:41: [2024-10-29 12:20:41] iter = 13540, loss = 6.0106
2024-10-29 12:20:42: [2024-10-29 12:20:42] iter = 13550, loss = 10.5083
2024-10-29 12:20:42: [2024-10-29 12:20:42] iter = 13560, loss = 35.0979
2024-10-29 12:20:43: [2024-10-29 12:20:43] iter = 13570, loss = 3.0271
2024-10-29 12:20:43: [2024-10-29 12:20:43] iter = 13580, loss = 10.6086
2024-10-29 12:20:43: [2024-10-29 12:20:43] iter = 13590, loss = 2.1601
2024-10-29 12:20:44: [2024-10-29 12:20:44] iter = 13600, loss = 5.9068
2024-10-29 12:20:44: [2024-10-29 12:20:44] iter = 13610, loss = 11.0271
2024-10-29 12:20:45: [2024-10-29 12:20:45] iter = 13620, loss = 16.3158
2024-10-29 12:20:45: [2024-10-29 12:20:45] iter = 13630, loss = 21.0882
2024-10-29 12:20:46: [2024-10-29 12:20:46] iter = 13640, loss = 17.0951
2024-10-29 12:20:46: [2024-10-29 12:20:46] iter = 13650, loss = 6.3572
2024-10-29 12:20:46: [2024-10-29 12:20:46] iter = 13660, loss = 7.6648
2024-10-29 12:20:47: [2024-10-29 12:20:47] iter = 13670, loss = 3.2257
2024-10-29 12:20:47: [2024-10-29 12:20:47] iter = 13680, loss = 27.4369
2024-10-29 12:20:48: [2024-10-29 12:20:48] iter = 13690, loss = 5.8737
2024-10-29 12:20:48: [2024-10-29 12:20:48] iter = 13700, loss = 2.9184
2024-10-29 12:20:49: [2024-10-29 12:20:49] iter = 13710, loss = 3.8111
2024-10-29 12:20:49: [2024-10-29 12:20:49] iter = 13720, loss = 12.3230
2024-10-29 12:20:49: [2024-10-29 12:20:49] iter = 13730, loss = 24.5061
2024-10-29 12:20:50: [2024-10-29 12:20:50] iter = 13740, loss = 8.0130
2024-10-29 12:20:50: [2024-10-29 12:20:50] iter = 13750, loss = 45.7354
2024-10-29 12:20:51: [2024-10-29 12:20:51] iter = 13760, loss = 9.2320
2024-10-29 12:20:51: [2024-10-29 12:20:51] iter = 13770, loss = 6.8738
2024-10-29 12:20:51: [2024-10-29 12:20:51] iter = 13780, loss = 14.3504
2024-10-29 12:20:52: [2024-10-29 12:20:52] iter = 13790, loss = 4.3693
2024-10-29 12:20:52: [2024-10-29 12:20:52] iter = 13800, loss = 10.0379
2024-10-29 12:20:53: [2024-10-29 12:20:53] iter = 13810, loss = 24.8402
2024-10-29 12:20:53: [2024-10-29 12:20:53] iter = 13820, loss = 13.3828
2024-10-29 12:20:54: [2024-10-29 12:20:54] iter = 13830, loss = 3.9340
2024-10-29 12:20:54: [2024-10-29 12:20:54] iter = 13840, loss = 5.3604
2024-10-29 12:20:55: [2024-10-29 12:20:55] iter = 13850, loss = 4.4670
2024-10-29 12:20:55: [2024-10-29 12:20:55] iter = 13860, loss = 4.8627
2024-10-29 12:20:55: [2024-10-29 12:20:55] iter = 13870, loss = 3.2377
2024-10-29 12:20:56: [2024-10-29 12:20:56] iter = 13880, loss = 7.8167
2024-10-29 12:20:56: [2024-10-29 12:20:56] iter = 13890, loss = 5.6365
2024-10-29 12:20:57: [2024-10-29 12:20:57] iter = 13900, loss = 6.1579
2024-10-29 12:20:57: [2024-10-29 12:20:57] iter = 13910, loss = 4.8183
2024-10-29 12:20:58: [2024-10-29 12:20:58] iter = 13920, loss = 4.6717
2024-10-29 12:20:58: [2024-10-29 12:20:58] iter = 13930, loss = 12.0373
2024-10-29 12:20:58: [2024-10-29 12:20:58] iter = 13940, loss = 5.5756
2024-10-29 12:20:59: [2024-10-29 12:20:59] iter = 13950, loss = 19.0684
2024-10-29 12:20:59: [2024-10-29 12:20:59] iter = 13960, loss = 2.2429
2024-10-29 12:21:00: [2024-10-29 12:21:00] iter = 13970, loss = 3.6493
2024-10-29 12:21:00: [2024-10-29 12:21:00] iter = 13980, loss = 4.7494
2024-10-29 12:21:01: [2024-10-29 12:21:01] iter = 13990, loss = 4.7094
2024-10-29 12:21:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 12:21:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:21:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 61475}

[2024-10-29 12:05:56] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.006837 train acc = 1.0000, test acc = 0.4430, test_sen =0.4430, test_spe =0.8143, test_f1 =0.3475
[2024-10-29 12:06:01] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.002856 train acc = 1.0000, test acc = 0.4310, test_sen =0.4310, test_spe =0.8103, test_f1 =0.3441
[2024-10-29 12:06:05] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.023912 train acc = 1.0000, test acc = 0.4400, test_sen =0.4400, test_spe =0.8133, test_f1 =0.3629
[2024-10-29 12:06:10] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.006287 train acc = 1.0000, test acc = 0.4320, test_sen =0.4320, test_spe =0.8107, test_f1 =0.3348
[2024-10-29 12:06:15] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.007114 train acc = 1.0000, test acc = 0.4410, test_sen =0.4410, test_spe =0.8137, test_f1 =0.3526
[2024-10-29 12:07:46] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002211 train acc = 1.0000, test acc = 0.5420, test_sen =0.5420, test_spe =0.8473, test_f1 =0.5241
[2024-10-29 12:07:51] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.000597 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8413, test_f1 =0.5019
[2024-10-29 12:07:56] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.003474 train acc = 1.0000, test acc = 0.5250, test_sen =0.5250, test_spe =0.8417, test_f1 =0.5019
[2024-10-29 12:08:01] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001542 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8533, test_f1 =0.5360
[2024-10-29 12:08:06] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001057 train acc = 1.0000, test acc = 0.5530, test_sen =0.5530, test_spe =0.8510, test_f1 =0.5305
[2024-10-29 12:08:14] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.005550 train acc = 1.0000, test acc = 0.4120, test_sen =0.4120, test_spe =0.8040, test_f1 =0.4157
[2024-10-29 12:08:19] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.009351 train acc = 1.0000, test acc = 0.4060, test_sen =0.4060, test_spe =0.8020, test_f1 =0.4114
[2024-10-29 12:08:24] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002293 train acc = 1.0000, test acc = 0.4170, test_sen =0.4170, test_spe =0.8057, test_f1 =0.4195
[2024-10-29 12:08:28] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002294 train acc = 1.0000, test acc = 0.4100, test_sen =0.4100, test_spe =0.8033, test_f1 =0.4119
[2024-10-29 12:08:32] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.020152 train acc = 1.0000, test acc = 0.4090, test_sen =0.4090, test_spe =0.8030, test_f1 =0.4114
[2024-10-29 12:10:05] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002750 train acc = 1.0000, test acc = 0.4950, test_sen =0.4950, test_spe =0.8317, test_f1 =0.4350
[2024-10-29 12:10:10] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.003515 train acc = 1.0000, test acc = 0.5320, test_sen =0.5320, test_spe =0.8440, test_f1 =0.4570
[2024-10-29 12:10:14] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001795 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8413, test_f1 =0.4567
[2024-10-29 12:10:20] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001790 train acc = 1.0000, test acc = 0.5120, test_sen =0.5120, test_spe =0.8373, test_f1 =0.4403
[2024-10-29 12:10:24] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001943 train acc = 1.0000, test acc = 0.5190, test_sen =0.5190, test_spe =0.8397, test_f1 =0.4452
[2024-10-29 12:11:55] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002183 train acc = 1.0000, test acc = 0.5010, test_sen =0.5010, test_spe =0.8337, test_f1 =0.4706
[2024-10-29 12:12:00] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.010591 train acc = 1.0000, test acc = 0.5080, test_sen =0.5080, test_spe =0.8360, test_f1 =0.4723
[2024-10-29 12:12:05] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.004565 train acc = 1.0000, test acc = 0.5020, test_sen =0.5020, test_spe =0.8340, test_f1 =0.4689
[2024-10-29 12:12:09] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.024146 train acc = 1.0000, test acc = 0.5000, test_sen =0.5000, test_spe =0.8333, test_f1 =0.4765
[2024-10-29 12:12:13] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002003 train acc = 1.0000, test acc = 0.4930, test_sen =0.4930, test_spe =0.8310, test_f1 =0.4705
[2024-10-29 12:13:47] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.020642 train acc = 1.0000, test acc = 0.5230, test_sen =0.5230, test_spe =0.8410, test_f1 =0.5103
[2024-10-29 12:13:51] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.027194 train acc = 1.0000, test acc = 0.5030, test_sen =0.5030, test_spe =0.8343, test_f1 =0.4863
[2024-10-29 12:13:56] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.025616 train acc = 1.0000, test acc = 0.5080, test_sen =0.5080, test_spe =0.8360, test_f1 =0.4855
[2024-10-29 12:14:00] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.016028 train acc = 1.0000, test acc = 0.4930, test_sen =0.4930, test_spe =0.8310, test_f1 =0.4742
[2024-10-29 12:14:05] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.027979 train acc = 1.0000, test acc = 0.5000, test_sen =0.5000, test_spe =0.8333, test_f1 =0.4828
[2024-10-29 12:15:37] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.012671 train acc = 1.0000, test acc = 0.4790, test_sen =0.4790, test_spe =0.8263, test_f1 =0.4129
[2024-10-29 12:15:42] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.001950 train acc = 1.0000, test acc = 0.5110, test_sen =0.5110, test_spe =0.8370, test_f1 =0.4418
[2024-10-29 12:15:46] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.031384 train acc = 1.0000, test acc = 0.4970, test_sen =0.4970, test_spe =0.8323, test_f1 =0.4340
[2024-10-29 12:15:50] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.010939 train acc = 1.0000, test acc = 0.4920, test_sen =0.4920, test_spe =0.8307, test_f1 =0.4214
[2024-10-29 12:15:55] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002179 train acc = 1.0000, test acc = 0.5070, test_sen =0.5070, test_spe =0.8357, test_f1 =0.4391
[2024-10-29 12:17:26] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001091 train acc = 1.0000, test acc = 0.4700, test_sen =0.4700, test_spe =0.8233, test_f1 =0.4360
[2024-10-29 12:17:31] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.005157 train acc = 1.0000, test acc = 0.4780, test_sen =0.4780, test_spe =0.8260, test_f1 =0.4524
[2024-10-29 12:17:35] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002667 train acc = 1.0000, test acc = 0.4380, test_sen =0.4380, test_spe =0.8127, test_f1 =0.3886
[2024-10-29 12:17:39] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.025299 train acc = 1.0000, test acc = 0.4830, test_sen =0.4830, test_spe =0.8277, test_f1 =0.4328
[2024-10-29 12:17:43] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.000376 train acc = 1.0000, test acc = 0.4760, test_sen =0.4760, test_spe =0.8253, test_f1 =0.4363
[2024-10-29 12:19:17] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002643 train acc = 1.0000, test acc = 0.5470, test_sen =0.5470, test_spe =0.8490, test_f1 =0.5357
[2024-10-29 12:19:21] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.005055 train acc = 1.0000, test acc = 0.5630, test_sen =0.5630, test_spe =0.8543, test_f1 =0.5509
[2024-10-29 12:19:26] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001891 train acc = 1.0000, test acc = 0.5510, test_sen =0.5510, test_spe =0.8503, test_f1 =0.5341
[2024-10-29 12:19:31] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002271 train acc = 1.0000, test acc = 0.5560, test_sen =0.5560, test_spe =0.8520, test_f1 =0.5479
[2024-10-29 12:19:35] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.019015 train acc = 1.0000, test acc = 0.5500, test_sen =0.5500, test_spe =0.8500, test_f1 =0.5379
[2024-10-29 12:21:05] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.006158 train acc = 1.0000, test acc = 0.4800, test_sen =0.4800, test_spe =0.8267, test_f1 =0.4370
[2024-10-29 12:21:10] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.002283 train acc = 1.0000, test acc = 0.4740, test_sen =0.4740, test_spe =0.8247, test_f1 =0.4219/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:21:24: Evaluate 5 random ConvNet, ACCmean = 0.4710 ACCstd = 0.0117
-------------------------
2024-10-29 12:21:24: Evaluate 5 random ConvNet, SENmean = 0.4710 SENstd = 0.0117
-------------------------
2024-10-29 12:21:24: Evaluate 5 random ConvNet, SPEmean = 0.8237 SPEstd = 0.0039
-------------------------
2024-10-29 12:21:24: Evaluate 5 random ConvNet, F!mean = 0.4158 F!std = 0.0250
-------------------------
2024-10-29 12:21:24: Evaluate 5 random ConvNet, mean = 0.4710 std = 0.0117
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:21:24: [2024-10-29 12:21:24] iter = 14000, loss = 56.2959
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:21:25: [2024-10-29 12:21:25] iter = 14010, loss = 6.1076
2024-10-29 12:21:25: [2024-10-29 12:21:25] iter = 14020, loss = 5.4326
2024-10-29 12:21:26: [2024-10-29 12:21:26] iter = 14030, loss = 27.0998
2024-10-29 12:21:26: [2024-10-29 12:21:26] iter = 14040, loss = 7.9401
2024-10-29 12:21:27: [2024-10-29 12:21:27] iter = 14050, loss = 3.0476
2024-10-29 12:21:27: [2024-10-29 12:21:27] iter = 14060, loss = 3.4841
2024-10-29 12:21:28: [2024-10-29 12:21:28] iter = 14070, loss = 2.6684
2024-10-29 12:21:28: [2024-10-29 12:21:28] iter = 14080, loss = 4.1707
2024-10-29 12:21:28: [2024-10-29 12:21:28] iter = 14090, loss = 21.4854
2024-10-29 12:21:29: [2024-10-29 12:21:29] iter = 14100, loss = 19.3205
2024-10-29 12:21:29: [2024-10-29 12:21:29] iter = 14110, loss = 8.7353
2024-10-29 12:21:30: [2024-10-29 12:21:30] iter = 14120, loss = 3.8395
2024-10-29 12:21:30: [2024-10-29 12:21:30] iter = 14130, loss = 6.5443
2024-10-29 12:21:31: [2024-10-29 12:21:31] iter = 14140, loss = 5.7670
2024-10-29 12:21:31: [2024-10-29 12:21:31] iter = 14150, loss = 2.8470
2024-10-29 12:21:32: [2024-10-29 12:21:32] iter = 14160, loss = 3.8836
2024-10-29 12:21:32: [2024-10-29 12:21:32] iter = 14170, loss = 9.1651
2024-10-29 12:21:32: [2024-10-29 12:21:32] iter = 14180, loss = 15.9224
2024-10-29 12:21:33: [2024-10-29 12:21:33] iter = 14190, loss = 3.4320
2024-10-29 12:21:33: [2024-10-29 12:21:33] iter = 14200, loss = 43.1956
2024-10-29 12:21:34: [2024-10-29 12:21:34] iter = 14210, loss = 23.8163
2024-10-29 12:21:34: [2024-10-29 12:21:34] iter = 14220, loss = 12.9176
2024-10-29 12:21:34: [2024-10-29 12:21:34] iter = 14230, loss = 5.2620
2024-10-29 12:21:35: [2024-10-29 12:21:35] iter = 14240, loss = 18.6386
2024-10-29 12:21:35: [2024-10-29 12:21:35] iter = 14250, loss = 10.5878
2024-10-29 12:21:36: [2024-10-29 12:21:36] iter = 14260, loss = 17.5336
2024-10-29 12:21:36: [2024-10-29 12:21:36] iter = 14270, loss = 3.0382
2024-10-29 12:21:36: [2024-10-29 12:21:36] iter = 14280, loss = 7.2606
2024-10-29 12:21:37: [2024-10-29 12:21:37] iter = 14290, loss = 60.0707
2024-10-29 12:21:37: [2024-10-29 12:21:37] iter = 14300, loss = 3.5454
2024-10-29 12:21:37: [2024-10-29 12:21:37] iter = 14310, loss = 66.5287
2024-10-29 12:21:38: [2024-10-29 12:21:38] iter = 14320, loss = 2.9145
2024-10-29 12:21:38: [2024-10-29 12:21:38] iter = 14330, loss = 26.3431
2024-10-29 12:21:39: [2024-10-29 12:21:39] iter = 14340, loss = 5.3578
2024-10-29 12:21:39: [2024-10-29 12:21:39] iter = 14350, loss = 7.0542
2024-10-29 12:21:40: [2024-10-29 12:21:40] iter = 14360, loss = 2.8100
2024-10-29 12:21:40: [2024-10-29 12:21:40] iter = 14370, loss = 4.3688
2024-10-29 12:21:40: [2024-10-29 12:21:40] iter = 14380, loss = 27.2254
2024-10-29 12:21:41: [2024-10-29 12:21:41] iter = 14390, loss = 16.9440
2024-10-29 12:21:41: [2024-10-29 12:21:41] iter = 14400, loss = 7.6339
2024-10-29 12:21:42: [2024-10-29 12:21:42] iter = 14410, loss = 11.5110
2024-10-29 12:21:42: [2024-10-29 12:21:42] iter = 14420, loss = 8.1669
2024-10-29 12:21:43: [2024-10-29 12:21:43] iter = 14430, loss = 4.6414
2024-10-29 12:21:43: [2024-10-29 12:21:43] iter = 14440, loss = 6.0594
2024-10-29 12:21:43: [2024-10-29 12:21:43] iter = 14450, loss = 3.2596
2024-10-29 12:21:44: [2024-10-29 12:21:44] iter = 14460, loss = 3.4995
2024-10-29 12:21:44: [2024-10-29 12:21:44] iter = 14470, loss = 11.4591
2024-10-29 12:21:45: [2024-10-29 12:21:45] iter = 14480, loss = 6.1788
2024-10-29 12:21:45: [2024-10-29 12:21:45] iter = 14490, loss = 4.0489
2024-10-29 12:21:46: [2024-10-29 12:21:46] iter = 14500, loss = 8.4340
2024-10-29 12:21:46: [2024-10-29 12:21:46] iter = 14510, loss = 8.4979
2024-10-29 12:21:47: [2024-10-29 12:21:47] iter = 14520, loss = 8.8500
2024-10-29 12:21:47: [2024-10-29 12:21:47] iter = 14530, loss = 7.9224
2024-10-29 12:21:47: [2024-10-29 12:21:47] iter = 14540, loss = 8.7422
2024-10-29 12:21:48: [2024-10-29 12:21:48] iter = 14550, loss = 10.1205
2024-10-29 12:21:48: [2024-10-29 12:21:48] iter = 14560, loss = 11.1180
2024-10-29 12:21:49: [2024-10-29 12:21:49] iter = 14570, loss = 8.0310
2024-10-29 12:21:49: [2024-10-29 12:21:49] iter = 14580, loss = 13.1286
2024-10-29 12:21:50: [2024-10-29 12:21:50] iter = 14590, loss = 9.2543
2024-10-29 12:21:50: [2024-10-29 12:21:50] iter = 14600, loss = 35.4488
2024-10-29 12:21:50: [2024-10-29 12:21:50] iter = 14610, loss = 9.2930
2024-10-29 12:21:51: [2024-10-29 12:21:51] iter = 14620, loss = 5.7786
2024-10-29 12:21:51: [2024-10-29 12:21:51] iter = 14630, loss = 3.7536
2024-10-29 12:21:52: [2024-10-29 12:21:52] iter = 14640, loss = 10.0346
2024-10-29 12:21:52: [2024-10-29 12:21:52] iter = 14650, loss = 17.6930
2024-10-29 12:21:53: [2024-10-29 12:21:53] iter = 14660, loss = 7.5890
2024-10-29 12:21:53: [2024-10-29 12:21:53] iter = 14670, loss = 4.2573
2024-10-29 12:21:54: [2024-10-29 12:21:54] iter = 14680, loss = 3.3260
2024-10-29 12:21:54: [2024-10-29 12:21:54] iter = 14690, loss = 3.7706
2024-10-29 12:21:54: [2024-10-29 12:21:54] iter = 14700, loss = 3.7521
2024-10-29 12:21:55: [2024-10-29 12:21:55] iter = 14710, loss = 15.9136
2024-10-29 12:21:55: [2024-10-29 12:21:55] iter = 14720, loss = 31.5951
2024-10-29 12:21:56: [2024-10-29 12:21:56] iter = 14730, loss = 4.2187
2024-10-29 12:21:56: [2024-10-29 12:21:56] iter = 14740, loss = 11.6802
2024-10-29 12:21:57: [2024-10-29 12:21:57] iter = 14750, loss = 11.0344
2024-10-29 12:21:57: [2024-10-29 12:21:57] iter = 14760, loss = 2.8893
2024-10-29 12:21:58: [2024-10-29 12:21:58] iter = 14770, loss = 1.9324
2024-10-29 12:21:58: [2024-10-29 12:21:58] iter = 14780, loss = 5.6778
2024-10-29 12:21:59: [2024-10-29 12:21:59] iter = 14790, loss = 3.0860
2024-10-29 12:21:59: [2024-10-29 12:21:59] iter = 14800, loss = 5.0050
2024-10-29 12:22:00: [2024-10-29 12:22:00] iter = 14810, loss = 18.7084
2024-10-29 12:22:00: [2024-10-29 12:22:00] iter = 14820, loss = 4.8733
2024-10-29 12:22:00: [2024-10-29 12:22:00] iter = 14830, loss = 7.5619
2024-10-29 12:22:01: [2024-10-29 12:22:01] iter = 14840, loss = 25.5898
2024-10-29 12:22:01: [2024-10-29 12:22:01] iter = 14850, loss = 10.1055
2024-10-29 12:22:02: [2024-10-29 12:22:02] iter = 14860, loss = 2.5656
2024-10-29 12:22:02: [2024-10-29 12:22:02] iter = 14870, loss = 3.6021
2024-10-29 12:22:03: [2024-10-29 12:22:03] iter = 14880, loss = 2.7453
2024-10-29 12:22:03: [2024-10-29 12:22:03] iter = 14890, loss = 15.1096
2024-10-29 12:22:04: [2024-10-29 12:22:04] iter = 14900, loss = 4.9673
2024-10-29 12:22:04: [2024-10-29 12:22:04] iter = 14910, loss = 16.8346
2024-10-29 12:22:04: [2024-10-29 12:22:04] iter = 14920, loss = 4.0616
2024-10-29 12:22:05: [2024-10-29 12:22:05] iter = 14930, loss = 38.2067
2024-10-29 12:22:05: [2024-10-29 12:22:05] iter = 14940, loss = 8.2809
2024-10-29 12:22:05: [2024-10-29 12:22:05] iter = 14950, loss = 10.8902
2024-10-29 12:22:06: [2024-10-29 12:22:06] iter = 14960, loss = 10.4906
2024-10-29 12:22:06: [2024-10-29 12:22:06] iter = 14970, loss = 5.0773
2024-10-29 12:22:07: [2024-10-29 12:22:07] iter = 14980, loss = 13.0994
2024-10-29 12:22:07: [2024-10-29 12:22:07] iter = 14990, loss = 2.6793
2024-10-29 12:22:08: [2024-10-29 12:22:08] iter = 15000, loss = 3.7477
2024-10-29 12:22:08: [2024-10-29 12:22:08] iter = 15010, loss = 3.6627
2024-10-29 12:22:09: [2024-10-29 12:22:09] iter = 15020, loss = 10.5088
2024-10-29 12:22:09: [2024-10-29 12:22:09] iter = 15030, loss = 6.3629
2024-10-29 12:22:09: [2024-10-29 12:22:09] iter = 15040, loss = 4.8782
2024-10-29 12:22:10: [2024-10-29 12:22:10] iter = 15050, loss = 47.7890
2024-10-29 12:22:10: [2024-10-29 12:22:10] iter = 15060, loss = 15.3373
2024-10-29 12:22:11: [2024-10-29 12:22:11] iter = 15070, loss = 69.6878
2024-10-29 12:22:11: [2024-10-29 12:22:11] iter = 15080, loss = 9.8515
2024-10-29 12:22:11: [2024-10-29 12:22:11] iter = 15090, loss = 3.5905
2024-10-29 12:22:12: [2024-10-29 12:22:12] iter = 15100, loss = 6.9594
2024-10-29 12:22:12: [2024-10-29 12:22:12] iter = 15110, loss = 46.3134
2024-10-29 12:22:13: [2024-10-29 12:22:13] iter = 15120, loss = 7.3224
2024-10-29 12:22:13: [2024-10-29 12:22:13] iter = 15130, loss = 5.2878
2024-10-29 12:22:13: [2024-10-29 12:22:13] iter = 15140, loss = 6.9718
2024-10-29 12:22:14: [2024-10-29 12:22:14] iter = 15150, loss = 4.6641
2024-10-29 12:22:14: [2024-10-29 12:22:14] iter = 15160, loss = 3.3726
2024-10-29 12:22:15: [2024-10-29 12:22:15] iter = 15170, loss = 3.4611
2024-10-29 12:22:15: [2024-10-29 12:22:15] iter = 15180, loss = 9.1714
2024-10-29 12:22:16: [2024-10-29 12:22:16] iter = 15190, loss = 5.2225
2024-10-29 12:22:16: [2024-10-29 12:22:16] iter = 15200, loss = 4.7895
2024-10-29 12:22:17: [2024-10-29 12:22:17] iter = 15210, loss = 3.3468
2024-10-29 12:22:17: [2024-10-29 12:22:17] iter = 15220, loss = 6.9944
2024-10-29 12:22:18: [2024-10-29 12:22:18] iter = 15230, loss = 2.7552
2024-10-29 12:22:18: [2024-10-29 12:22:18] iter = 15240, loss = 9.1007
2024-10-29 12:22:19: [2024-10-29 12:22:19] iter = 15250, loss = 5.6317
2024-10-29 12:22:19: [2024-10-29 12:22:19] iter = 15260, loss = 4.2616
2024-10-29 12:22:20: [2024-10-29 12:22:20] iter = 15270, loss = 11.1681
2024-10-29 12:22:20: [2024-10-29 12:22:20] iter = 15280, loss = 8.9247
2024-10-29 12:22:21: [2024-10-29 12:22:21] iter = 15290, loss = 3.4261
2024-10-29 12:22:21: [2024-10-29 12:22:21] iter = 15300, loss = 16.1795
2024-10-29 12:22:21: [2024-10-29 12:22:21] iter = 15310, loss = 9.1258
2024-10-29 12:22:22: [2024-10-29 12:22:22] iter = 15320, loss = 10.2940
2024-10-29 12:22:22: [2024-10-29 12:22:22] iter = 15330, loss = 22.3318
2024-10-29 12:22:23: [2024-10-29 12:22:23] iter = 15340, loss = 4.4440
2024-10-29 12:22:23: [2024-10-29 12:22:23] iter = 15350, loss = 4.0374
2024-10-29 12:22:24: [2024-10-29 12:22:24] iter = 15360, loss = 8.4565
2024-10-29 12:22:24: [2024-10-29 12:22:24] iter = 15370, loss = 6.3901
2024-10-29 12:22:25: [2024-10-29 12:22:25] iter = 15380, loss = 13.6948
2024-10-29 12:22:25: [2024-10-29 12:22:25] iter = 15390, loss = 9.1813
2024-10-29 12:22:25: [2024-10-29 12:22:25] iter = 15400, loss = 4.6243
2024-10-29 12:22:26: [2024-10-29 12:22:26] iter = 15410, loss = 2.2183
2024-10-29 12:22:27: [2024-10-29 12:22:27] iter = 15420, loss = 3.4146
2024-10-29 12:22:27: [2024-10-29 12:22:27] iter = 15430, loss = 21.1940
2024-10-29 12:22:28: [2024-10-29 12:22:28] iter = 15440, loss = 6.5876
2024-10-29 12:22:29: [2024-10-29 12:22:29] iter = 15450, loss = 3.6773
2024-10-29 12:22:29: [2024-10-29 12:22:29] iter = 15460, loss = 4.8972
2024-10-29 12:22:30: [2024-10-29 12:22:30] iter = 15470, loss = 4.7419
2024-10-29 12:22:30: [2024-10-29 12:22:30] iter = 15480, loss = 2.8852
2024-10-29 12:22:31: [2024-10-29 12:22:31] iter = 15490, loss = 14.6531
2024-10-29 12:22:31: [2024-10-29 12:22:31] iter = 15500, loss = 7.6269
2024-10-29 12:22:31: [2024-10-29 12:22:31] iter = 15510, loss = 6.9543
2024-10-29 12:22:32: [2024-10-29 12:22:32] iter = 15520, loss = 3.5760
2024-10-29 12:22:32: [2024-10-29 12:22:32] iter = 15530, loss = 9.8847
2024-10-29 12:22:33: [2024-10-29 12:22:33] iter = 15540, loss = 8.7650
2024-10-29 12:22:33: [2024-10-29 12:22:33] iter = 15550, loss = 7.3999
2024-10-29 12:22:34: [2024-10-29 12:22:34] iter = 15560, loss = 2.5602
2024-10-29 12:22:34: [2024-10-29 12:22:34] iter = 15570, loss = 2.8390
2024-10-29 12:22:35: [2024-10-29 12:22:35] iter = 15580, loss = 4.3669
2024-10-29 12:22:35: [2024-10-29 12:22:35] iter = 15590, loss = 42.0412
2024-10-29 12:22:36: [2024-10-29 12:22:36] iter = 15600, loss = 6.1341
2024-10-29 12:22:36: [2024-10-29 12:22:36] iter = 15610, loss = 12.8656
2024-10-29 12:22:37: [2024-10-29 12:22:37] iter = 15620, loss = 5.0398
2024-10-29 12:22:38: [2024-10-29 12:22:38] iter = 15630, loss = 14.8087
2024-10-29 12:22:38: [2024-10-29 12:22:38] iter = 15640, loss = 21.0556
2024-10-29 12:22:39: [2024-10-29 12:22:39] iter = 15650, loss = 9.7221
2024-10-29 12:22:40: [2024-10-29 12:22:40] iter = 15660, loss = 5.2912
2024-10-29 12:22:40: [2024-10-29 12:22:40] iter = 15670, loss = 8.1001
2024-10-29 12:22:40: [2024-10-29 12:22:40] iter = 15680, loss = 3.3681
2024-10-29 12:22:41: [2024-10-29 12:22:41] iter = 15690, loss = 5.1638
2024-10-29 12:22:41: [2024-10-29 12:22:41] iter = 15700, loss = 6.7884
2024-10-29 12:22:42: [2024-10-29 12:22:42] iter = 15710, loss = 10.8074
2024-10-29 12:22:42: [2024-10-29 12:22:42] iter = 15720, loss = 6.9146
2024-10-29 12:22:43: [2024-10-29 12:22:43] iter = 15730, loss = 33.3780
2024-10-29 12:22:43: [2024-10-29 12:22:43] iter = 15740, loss = 6.7045
2024-10-29 12:22:44: [2024-10-29 12:22:44] iter = 15750, loss = 2.3020
2024-10-29 12:22:44: [2024-10-29 12:22:44] iter = 15760, loss = 21.2044
2024-10-29 12:22:45: [2024-10-29 12:22:45] iter = 15770, loss = 4.0374
2024-10-29 12:22:45: [2024-10-29 12:22:45] iter = 15780, loss = 12.2359
2024-10-29 12:22:46: [2024-10-29 12:22:46] iter = 15790, loss = 2.8134
2024-10-29 12:22:46: [2024-10-29 12:22:46] iter = 15800, loss = 6.7554
2024-10-29 12:22:46: [2024-10-29 12:22:46] iter = 15810, loss = 6.2761
2024-10-29 12:22:47: [2024-10-29 12:22:47] iter = 15820, loss = 14.5151
2024-10-29 12:22:47: [2024-10-29 12:22:47] iter = 15830, loss = 55.6116
2024-10-29 12:22:48: [2024-10-29 12:22:48] iter = 15840, loss = 7.6636
2024-10-29 12:22:48: [2024-10-29 12:22:48] iter = 15850, loss = 5.7018
2024-10-29 12:22:49: [2024-10-29 12:22:49] iter = 15860, loss = 5.3011
2024-10-29 12:22:49: [2024-10-29 12:22:49] iter = 15870, loss = 9.6807
2024-10-29 12:22:50: [2024-10-29 12:22:50] iter = 15880, loss = 4.1665
2024-10-29 12:22:50: [2024-10-29 12:22:50] iter = 15890, loss = 7.7630
2024-10-29 12:22:50: [2024-10-29 12:22:50] iter = 15900, loss = 4.1560
2024-10-29 12:22:51: [2024-10-29 12:22:51] iter = 15910, loss = 6.7696
2024-10-29 12:22:51: [2024-10-29 12:22:51] iter = 15920, loss = 4.3740
2024-10-29 12:22:52: [2024-10-29 12:22:52] iter = 15930, loss = 4.5847
2024-10-29 12:22:52: [2024-10-29 12:22:52] iter = 15940, loss = 4.0217
2024-10-29 12:22:53: [2024-10-29 12:22:53] iter = 15950, loss = 5.9846
2024-10-29 12:22:53: [2024-10-29 12:22:53] iter = 15960, loss = 3.2912
2024-10-29 12:22:54: [2024-10-29 12:22:54] iter = 15970, loss = 11.3229
2024-10-29 12:22:54: [2024-10-29 12:22:54] iter = 15980, loss = 8.3233
2024-10-29 12:22:55: [2024-10-29 12:22:55] iter = 15990, loss = 30.4117
2024-10-29 12:22:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 12:22:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:22:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 75763}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:23:19: Evaluate 5 random ConvNet, ACCmean = 0.4992 ACCstd = 0.0113
-------------------------
2024-10-29 12:23:19: Evaluate 5 random ConvNet, SENmean = 0.4992 SENstd = 0.0113
-------------------------
2024-10-29 12:23:19: Evaluate 5 random ConvNet, SPEmean = 0.8331 SPEstd = 0.0038
-------------------------
2024-10-29 12:23:19: Evaluate 5 random ConvNet, F!mean = 0.4407 F!std = 0.0138
-------------------------
2024-10-29 12:23:19: Evaluate 5 random ConvNet, mean = 0.4992 std = 0.0113
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:23:19: [2024-10-29 12:23:19] iter = 16000, loss = 21.6516
2024-10-29 12:23:20: [2024-10-29 12:23:20] iter = 16010, loss = 12.6423
2024-10-29 12:23:20: [2024-10-29 12:23:20] iter = 16020, loss = 6.8733
2024-10-29 12:23:20: [2024-10-29 12:23:20] iter = 16030, loss = 26.1230
2024-10-29 12:23:21: [2024-10-29 12:23:21] iter = 16040, loss = 3.9137
2024-10-29 12:23:21: [2024-10-29 12:23:21] iter = 16050, loss = 5.5478
2024-10-29 12:23:22: [2024-10-29 12:23:22] iter = 16060, loss = 6.1927
2024-10-29 12:23:22: [2024-10-29 12:23:22] iter = 16070, loss = 12.7966
2024-10-29 12:23:23: [2024-10-29 12:23:23] iter = 16080, loss = 9.6711
2024-10-29 12:23:23: [2024-10-29 12:23:23] iter = 16090, loss = 4.1600
2024-10-29 12:23:24: [2024-10-29 12:23:24] iter = 16100, loss = 5.6477
2024-10-29 12:23:24: [2024-10-29 12:23:24] iter = 16110, loss = 3.9761
2024-10-29 12:23:25: [2024-10-29 12:23:25] iter = 16120, loss = 3.9889
2024-10-29 12:23:25: [2024-10-29 12:23:25] iter = 16130, loss = 3.9299
2024-10-29 12:23:26: [2024-10-29 12:23:26] iter = 16140, loss = 11.3420
2024-10-29 12:23:26: [2024-10-29 12:23:26] iter = 16150, loss = 2.7537
2024-10-29 12:23:27: [2024-10-29 12:23:27] iter = 16160, loss = 5.0126
2024-10-29 12:23:27: [2024-10-29 12:23:27] iter = 16170, loss = 3.9350
2024-10-29 12:23:28: [2024-10-29 12:23:28] iter = 16180, loss = 7.5396
2024-10-29 12:23:28: [2024-10-29 12:23:28] iter = 16190, loss = 5.5460
2024-10-29 12:23:29: [2024-10-29 12:23:29] iter = 16200, loss = 3.4567
2024-10-29 12:23:29: [2024-10-29 12:23:29] iter = 16210, loss = 10.3932
2024-10-29 12:23:29: [2024-10-29 12:23:29] iter = 16220, loss = 3.8521
2024-10-29 12:23:30: [2024-10-29 12:23:30] iter = 16230, loss = 17.8885
2024-10-29 12:23:30: [2024-10-29 12:23:30] iter = 16240, loss = 5.3309
2024-10-29 12:23:31: [2024-10-29 12:23:31] iter = 16250, loss = 2.9826
2024-10-29 12:23:31: [2024-10-29 12:23:31] iter = 16260, loss = 2.6329
2024-10-29 12:23:32: [2024-10-29 12:23:32] iter = 16270, loss = 60.2336
2024-10-29 12:23:32: [2024-10-29 12:23:32] iter = 16280, loss = 2.4359
2024-10-29 12:23:33: [2024-10-29 12:23:33] iter = 16290, loss = 4.2917
2024-10-29 12:23:33: [2024-10-29 12:23:33] iter = 16300, loss = 3.4841
2024-10-29 12:23:34: [2024-10-29 12:23:34] iter = 16310, loss = 2.3879
2024-10-29 12:23:34: [2024-10-29 12:23:34] iter = 16320, loss = 41.0079
2024-10-29 12:23:35: [2024-10-29 12:23:35] iter = 16330, loss = 37.8102
2024-10-29 12:23:35: [2024-10-29 12:23:35] iter = 16340, loss = 8.0237
2024-10-29 12:23:35: [2024-10-29 12:23:35] iter = 16350, loss = 34.5477
2024-10-29 12:23:36: [2024-10-29 12:23:36] iter = 16360, loss = 5.0009
2024-10-29 12:23:37: [2024-10-29 12:23:37] iter = 16370, loss = 4.2339
2024-10-29 12:23:37: [2024-10-29 12:23:37] iter = 16380, loss = 3.0909
2024-10-29 12:23:38: [2024-10-29 12:23:38] iter = 16390, loss = 31.1741
2024-10-29 12:23:38: [2024-10-29 12:23:38] iter = 16400, loss = 5.0307
2024-10-29 12:23:39: [2024-10-29 12:23:39] iter = 16410, loss = 2.4315
2024-10-29 12:23:39: [2024-10-29 12:23:39] iter = 16420, loss = 2.9005
2024-10-29 12:23:39: [2024-10-29 12:23:39] iter = 16430, loss = 5.5654
2024-10-29 12:23:40: [2024-10-29 12:23:40] iter = 16440, loss = 2.9187
2024-10-29 12:23:40: [2024-10-29 12:23:40] iter = 16450, loss = 3.4501
2024-10-29 12:23:41: [2024-10-29 12:23:41] iter = 16460, loss = 4.8500
2024-10-29 12:23:41: [2024-10-29 12:23:41] iter = 16470, loss = 5.4788
2024-10-29 12:23:42: [2024-10-29 12:23:42] iter = 16480, loss = 3.1130
2024-10-29 12:23:42: [2024-10-29 12:23:42] iter = 16490, loss = 7.1151
2024-10-29 12:23:43: [2024-10-29 12:23:43] iter = 16500, loss = 3.2606
2024-10-29 12:23:43: [2024-10-29 12:23:43] iter = 16510, loss = 7.2816
2024-10-29 12:23:43: [2024-10-29 12:23:43] iter = 16520, loss = 4.9628
2024-10-29 12:23:44: [2024-10-29 12:23:44] iter = 16530, loss = 9.2191
2024-10-29 12:23:45: [2024-10-29 12:23:45] iter = 16540, loss = 61.3743
2024-10-29 12:23:45: [2024-10-29 12:23:45] iter = 16550, loss = 10.3616
2024-10-29 12:23:45: [2024-10-29 12:23:45] iter = 16560, loss = 6.7557
2024-10-29 12:23:46: [2024-10-29 12:23:46] iter = 16570, loss = 5.8148
2024-10-29 12:23:46: [2024-10-29 12:23:46] iter = 16580, loss = 8.7917
2024-10-29 12:23:47: [2024-10-29 12:23:47] iter = 16590, loss = 22.6431
2024-10-29 12:23:47: [2024-10-29 12:23:47] iter = 16600, loss = 9.7886
2024-10-29 12:23:48: [2024-10-29 12:23:48] iter = 16610, loss = 9.0700
2024-10-29 12:23:48: [2024-10-29 12:23:48] iter = 16620, loss = 11.9952
2024-10-29 12:23:49: [2024-10-29 12:23:49] iter = 16630, loss = 5.6168
2024-10-29 12:23:49: [2024-10-29 12:23:49] iter = 16640, loss = 6.7989
2024-10-29 12:23:50: [2024-10-29 12:23:50] iter = 16650, loss = 15.4705
2024-10-29 12:23:50: [2024-10-29 12:23:50] iter = 16660, loss = 8.9599
2024-10-29 12:23:51: [2024-10-29 12:23:51] iter = 16670, loss = 3.3014
2024-10-29 12:23:51: [2024-10-29 12:23:51] iter = 16680, loss = 5.2622
2024-10-29 12:23:52: [2024-10-29 12:23:52] iter = 16690, loss = 2.4884
2024-10-29 12:23:52: [2024-10-29 12:23:52] iter = 16700, loss = 7.4507
2024-10-29 12:23:52: [2024-10-29 12:23:52] iter = 16710, loss = 4.0716
2024-10-29 12:23:53: [2024-10-29 12:23:53] iter = 16720, loss = 5.1051
2024-10-29 12:23:53: [2024-10-29 12:23:53] iter = 16730, loss = 4.3061
2024-10-29 12:23:54: [2024-10-29 12:23:54] iter = 16740, loss = 19.3748
2024-10-29 12:23:54: [2024-10-29 12:23:54] iter = 16750, loss = 9.2373
2024-10-29 12:23:55: [2024-10-29 12:23:55] iter = 16760, loss = 7.7224
2024-10-29 12:23:55: [2024-10-29 12:23:55] iter = 16770, loss = 22.1065
2024-10-29 12:23:56: [2024-10-29 12:23:56] iter = 16780, loss = 7.6675
2024-10-29 12:23:56: [2024-10-29 12:23:56] iter = 16790, loss = 6.4791
2024-10-29 12:23:57: [2024-10-29 12:23:57] iter = 16800, loss = 3.3666
2024-10-29 12:23:57: [2024-10-29 12:23:57] iter = 16810, loss = 22.8050
2024-10-29 12:23:58: [2024-10-29 12:23:58] iter = 16820, loss = 12.8518
2024-10-29 12:23:58: [2024-10-29 12:23:58] iter = 16830, loss = 54.0511
2024-10-29 12:23:59: [2024-10-29 12:23:59] iter = 16840, loss = 3.3286
2024-10-29 12:23:59: [2024-10-29 12:23:59] iter = 16850, loss = 5.2386
2024-10-29 12:23:59: [2024-10-29 12:23:59] iter = 16860, loss = 7.7837
2024-10-29 12:24:00: [2024-10-29 12:24:00] iter = 16870, loss = 6.2787
2024-10-29 12:24:00: [2024-10-29 12:24:00] iter = 16880, loss = 7.2039
2024-10-29 12:24:01: [2024-10-29 12:24:01] iter = 16890, loss = 35.8076
2024-10-29 12:24:01: [2024-10-29 12:24:01] iter = 16900, loss = 21.4262
2024-10-29 12:24:02: [2024-10-29 12:24:02] iter = 16910, loss = 8.7911
2024-10-29 12:24:02: [2024-10-29 12:24:02] iter = 16920, loss = 3.4748
2024-10-29 12:24:03: [2024-10-29 12:24:03] iter = 16930, loss = 3.1644
2024-10-29 12:24:03: [2024-10-29 12:24:03] iter = 16940, loss = 9.9226
2024-10-29 12:24:04: [2024-10-29 12:24:04] iter = 16950, loss = 7.3506
2024-10-29 12:24:04: [2024-10-29 12:24:04] iter = 16960, loss = 4.2106
2024-10-29 12:24:04: [2024-10-29 12:24:04] iter = 16970, loss = 8.9437
2024-10-29 12:24:05: [2024-10-29 12:24:05] iter = 16980, loss = 10.2935
2024-10-29 12:24:05: [2024-10-29 12:24:05] iter = 16990, loss = 4.7498
2024-10-29 12:24:06: [2024-10-29 12:24:06] iter = 17000, loss = 7.4333
2024-10-29 12:24:07: [2024-10-29 12:24:07] iter = 17010, loss = 5.5174
2024-10-29 12:24:07: [2024-10-29 12:24:07] iter = 17020, loss = 4.4613
2024-10-29 12:24:08: [2024-10-29 12:24:08] iter = 17030, loss = 3.2749
2024-10-29 12:24:08: [2024-10-29 12:24:08] iter = 17040, loss = 15.1201
2024-10-29 12:24:09: [2024-10-29 12:24:09] iter = 17050, loss = 7.1275
2024-10-29 12:24:09: [2024-10-29 12:24:09] iter = 17060, loss = 23.3095
2024-10-29 12:24:09: [2024-10-29 12:24:09] iter = 17070, loss = 4.3666
2024-10-29 12:24:10: [2024-10-29 12:24:10] iter = 17080, loss = 14.0684
2024-10-29 12:24:10: [2024-10-29 12:24:10] iter = 17090, loss = 9.0843
2024-10-29 12:24:11: [2024-10-29 12:24:11] iter = 17100, loss = 8.4158
2024-10-29 12:24:11: [2024-10-29 12:24:11] iter = 17110, loss = 9.8357
2024-10-29 12:24:12: [2024-10-29 12:24:12] iter = 17120, loss = 6.8294
2024-10-29 12:24:12: [2024-10-29 12:24:12] iter = 17130, loss = 10.6659
2024-10-29 12:24:13: [2024-10-29 12:24:13] iter = 17140, loss = 50.3982
2024-10-29 12:24:13: [2024-10-29 12:24:13] iter = 17150, loss = 4.6204
2024-10-29 12:24:14: [2024-10-29 12:24:14] iter = 17160, loss = 6.6149
2024-10-29 12:24:14: [2024-10-29 12:24:14] iter = 17170, loss = 4.5721
2024-10-29 12:24:14: [2024-10-29 12:24:14] iter = 17180, loss = 5.5019
2024-10-29 12:24:15: [2024-10-29 12:24:15] iter = 17190, loss = 4.2915
2024-10-29 12:24:15: [2024-10-29 12:24:15] iter = 17200, loss = 3.9438
2024-10-29 12:24:16: [2024-10-29 12:24:16] iter = 17210, loss = 11.5590
2024-10-29 12:24:16: [2024-10-29 12:24:16] iter = 17220, loss = 3.3206
2024-10-29 12:24:17: [2024-10-29 12:24:17] iter = 17230, loss = 2.5927
2024-10-29 12:24:17: [2024-10-29 12:24:17] iter = 17240, loss = 4.3534
2024-10-29 12:24:18: [2024-10-29 12:24:18] iter = 17250, loss = 4.3861
2024-10-29 12:24:18: [2024-10-29 12:24:18] iter = 17260, loss = 4.5883
2024-10-29 12:24:19: [2024-10-29 12:24:19] iter = 17270, loss = 11.4033
2024-10-29 12:24:19: [2024-10-29 12:24:19] iter = 17280, loss = 5.3590
2024-10-29 12:24:20: [2024-10-29 12:24:20] iter = 17290, loss = 4.6837
2024-10-29 12:24:20: [2024-10-29 12:24:20] iter = 17300, loss = 3.2608
2024-10-29 12:24:21: [2024-10-29 12:24:21] iter = 17310, loss = 3.1834
2024-10-29 12:24:21: [2024-10-29 12:24:21] iter = 17320, loss = 45.8994
2024-10-29 12:24:21: [2024-10-29 12:24:21] iter = 17330, loss = 5.4285
2024-10-29 12:24:22: [2024-10-29 12:24:22] iter = 17340, loss = 3.4202
2024-10-29 12:24:22: [2024-10-29 12:24:22] iter = 17350, loss = 4.8084
2024-10-29 12:24:23: [2024-10-29 12:24:23] iter = 17360, loss = 35.0973
2024-10-29 12:24:23: [2024-10-29 12:24:23] iter = 17370, loss = 6.1305
2024-10-29 12:24:24: [2024-10-29 12:24:24] iter = 17380, loss = 2.3629
2024-10-29 12:24:24: [2024-10-29 12:24:24] iter = 17390, loss = 40.8003
2024-10-29 12:24:24: [2024-10-29 12:24:24] iter = 17400, loss = 18.3504
2024-10-29 12:24:25: [2024-10-29 12:24:25] iter = 17410, loss = 18.8989
2024-10-29 12:24:25: [2024-10-29 12:24:25] iter = 17420, loss = 12.1638
2024-10-29 12:24:26: [2024-10-29 12:24:26] iter = 17430, loss = 10.0541
2024-10-29 12:24:26: [2024-10-29 12:24:26] iter = 17440, loss = 3.5166
2024-10-29 12:24:27: [2024-10-29 12:24:27] iter = 17450, loss = 7.2298
2024-10-29 12:24:27: [2024-10-29 12:24:27] iter = 17460, loss = 2.1225
2024-10-29 12:24:28: [2024-10-29 12:24:28] iter = 17470, loss = 4.6543
2024-10-29 12:24:28: [2024-10-29 12:24:28] iter = 17480, loss = 45.5709
2024-10-29 12:24:29: [2024-10-29 12:24:29] iter = 17490, loss = 3.5290
2024-10-29 12:24:29: [2024-10-29 12:24:29] iter = 17500, loss = 7.7318
2024-10-29 12:24:30: [2024-10-29 12:24:30] iter = 17510, loss = 7.7872
2024-10-29 12:24:30: [2024-10-29 12:24:30] iter = 17520, loss = 53.6518
2024-10-29 12:24:30: [2024-10-29 12:24:30] iter = 17530, loss = 8.2654
2024-10-29 12:24:31: [2024-10-29 12:24:31] iter = 17540, loss = 4.6266
2024-10-29 12:24:31: [2024-10-29 12:24:31] iter = 17550, loss = 9.6694
2024-10-29 12:24:32: [2024-10-29 12:24:32] iter = 17560, loss = 2.9440
2024-10-29 12:24:32: [2024-10-29 12:24:32] iter = 17570, loss = 4.5275
2024-10-29 12:24:33: [2024-10-29 12:24:33] iter = 17580, loss = 8.6233
2024-10-29 12:24:33: [2024-10-29 12:24:33] iter = 17590, loss = 16.6861
2024-10-29 12:24:34: [2024-10-29 12:24:34] iter = 17600, loss = 18.3053
2024-10-29 12:24:34: [2024-10-29 12:24:34] iter = 17610, loss = 16.3409
2024-10-29 12:24:35: [2024-10-29 12:24:35] iter = 17620, loss = 3.2640
2024-10-29 12:24:35: [2024-10-29 12:24:35] iter = 17630, loss = 5.7536
2024-10-29 12:24:36: [2024-10-29 12:24:36] iter = 17640, loss = 9.9457
2024-10-29 12:24:36: [2024-10-29 12:24:36] iter = 17650, loss = 17.2808
2024-10-29 12:24:36: [2024-10-29 12:24:36] iter = 17660, loss = 4.0041
2024-10-29 12:24:37: [2024-10-29 12:24:37] iter = 17670, loss = 24.0844
2024-10-29 12:24:37: [2024-10-29 12:24:37] iter = 17680, loss = 9.0742
2024-10-29 12:24:38: [2024-10-29 12:24:38] iter = 17690, loss = 3.3468
2024-10-29 12:24:38: [2024-10-29 12:24:38] iter = 17700, loss = 18.4731
2024-10-29 12:24:39: [2024-10-29 12:24:39] iter = 17710, loss = 11.4162
2024-10-29 12:24:39: [2024-10-29 12:24:39] iter = 17720, loss = 20.9118
2024-10-29 12:24:40: [2024-10-29 12:24:40] iter = 17730, loss = 3.3010
2024-10-29 12:24:40: [2024-10-29 12:24:40] iter = 17740, loss = 5.8260
2024-10-29 12:24:41: [2024-10-29 12:24:41] iter = 17750, loss = 5.6590
2024-10-29 12:24:41: [2024-10-29 12:24:41] iter = 17760, loss = 3.0499
2024-10-29 12:24:42: [2024-10-29 12:24:42] iter = 17770, loss = 6.2920
2024-10-29 12:24:42: [2024-10-29 12:24:42] iter = 17780, loss = 24.2453
2024-10-29 12:24:43: [2024-10-29 12:24:43] iter = 17790, loss = 3.5794
2024-10-29 12:24:43: [2024-10-29 12:24:43] iter = 17800, loss = 9.8279
2024-10-29 12:24:44: [2024-10-29 12:24:44] iter = 17810, loss = 4.7845
2024-10-29 12:24:45: [2024-10-29 12:24:45] iter = 17820, loss = 6.4410
2024-10-29 12:24:45: [2024-10-29 12:24:45] iter = 17830, loss = 30.6783
2024-10-29 12:24:46: [2024-10-29 12:24:46] iter = 17840, loss = 20.9340
2024-10-29 12:24:46: [2024-10-29 12:24:46] iter = 17850, loss = 7.5473
2024-10-29 12:24:47: [2024-10-29 12:24:47] iter = 17860, loss = 7.1384
2024-10-29 12:24:47: [2024-10-29 12:24:47] iter = 17870, loss = 27.2049
2024-10-29 12:24:48: [2024-10-29 12:24:48] iter = 17880, loss = 17.9019
2024-10-29 12:24:48: [2024-10-29 12:24:48] iter = 17890, loss = 12.1111
2024-10-29 12:24:49: [2024-10-29 12:24:49] iter = 17900, loss = 45.2512
2024-10-29 12:24:49: [2024-10-29 12:24:49] iter = 17910, loss = 4.0745
2024-10-29 12:24:50: [2024-10-29 12:24:50] iter = 17920, loss = 24.9542
2024-10-29 12:24:50: [2024-10-29 12:24:50] iter = 17930, loss = 4.1476
2024-10-29 12:24:51: [2024-10-29 12:24:51] iter = 17940, loss = 2.4645
2024-10-29 12:24:51: [2024-10-29 12:24:51] iter = 17950, loss = 5.5523
2024-10-29 12:24:52: [2024-10-29 12:24:52] iter = 17960, loss = 10.5389
2024-10-29 12:24:52: [2024-10-29 12:24:52] iter = 17970, loss = 10.8607
2024-10-29 12:24:53: [2024-10-29 12:24:53] iter = 17980, loss = 17.1847
2024-10-29 12:24:53: [2024-10-29 12:24:53] iter = 17990, loss = 36.6975
2024-10-29 12:24:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 12:24:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:24:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 94135}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:25:18: Evaluate 5 random ConvNet, ACCmean = 0.4776 ACCstd = 0.0135
-------------------------
2024-10-29 12:25:18: Evaluate 5 random ConvNet, SENmean = 0.4776 SENstd = 0.0135
-------------------------
2024-10-29 12:25:18: Evaluate 5 random ConvNet, SPEmean = 0.8259 SPEstd = 0.0045
-------------------------
2024-10-29 12:25:18: Evaluate 5 random ConvNet, F!mean = 0.4743 F!std = 0.0141
-------------------------
2024-10-29 12:25:18: Evaluate 5 random ConvNet, mean = 0.4776 std = 0.0135
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:25:18: [2024-10-29 12:25:18] iter = 18000, loss = 13.9874
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:25:19: [2024-10-29 12:25:19] iter = 18010, loss = 2.6293
2024-10-29 12:25:19: [2024-10-29 12:25:19] iter = 18020, loss = 7.7080
2024-10-29 12:25:20: [2024-10-29 12:25:20] iter = 18030, loss = 3.0205
2024-10-29 12:25:20: [2024-10-29 12:25:20] iter = 18040, loss = 2.9707
2024-10-29 12:25:20: [2024-10-29 12:25:20] iter = 18050, loss = 4.1158
2024-10-29 12:25:21: [2024-10-29 12:25:21] iter = 18060, loss = 4.4788
2024-10-29 12:25:21: [2024-10-29 12:25:21] iter = 18070, loss = 9.0001
2024-10-29 12:25:22: [2024-10-29 12:25:22] iter = 18080, loss = 20.7260
2024-10-29 12:25:22: [2024-10-29 12:25:22] iter = 18090, loss = 4.3910
2024-10-29 12:25:22: [2024-10-29 12:25:22] iter = 18100, loss = 3.1506
2024-10-29 12:25:23: [2024-10-29 12:25:23] iter = 18110, loss = 3.5313
2024-10-29 12:25:23: [2024-10-29 12:25:23] iter = 18120, loss = 9.9683
2024-10-29 12:25:24: [2024-10-29 12:25:24] iter = 18130, loss = 4.1386
2024-10-29 12:25:24: [2024-10-29 12:25:24] iter = 18140, loss = 15.6377
2024-10-29 12:25:25: [2024-10-29 12:25:25] iter = 18150, loss = 5.9158
2024-10-29 12:25:25: [2024-10-29 12:25:25] iter = 18160, loss = 9.9128
2024-10-29 12:25:25: [2024-10-29 12:25:25] iter = 18170, loss = 7.7233
2024-10-29 12:25:26: [2024-10-29 12:25:26] iter = 18180, loss = 3.7650
2024-10-29 12:25:26: [2024-10-29 12:25:26] iter = 18190, loss = 14.4614
2024-10-29 12:25:27: [2024-10-29 12:25:27] iter = 18200, loss = 45.6298
2024-10-29 12:25:27: [2024-10-29 12:25:27] iter = 18210, loss = 8.3592
2024-10-29 12:25:28: [2024-10-29 12:25:28] iter = 18220, loss = 6.2319
2024-10-29 12:25:28: [2024-10-29 12:25:28] iter = 18230, loss = 5.6324
2024-10-29 12:25:28: [2024-10-29 12:25:28] iter = 18240, loss = 3.5937
2024-10-29 12:25:29: [2024-10-29 12:25:29] iter = 18250, loss = 37.7700
2024-10-29 12:25:29: [2024-10-29 12:25:29] iter = 18260, loss = 4.9686
2024-10-29 12:25:30: [2024-10-29 12:25:30] iter = 18270, loss = 6.0249
2024-10-29 12:25:30: [2024-10-29 12:25:30] iter = 18280, loss = 5.0555
2024-10-29 12:25:31: [2024-10-29 12:25:31] iter = 18290, loss = 4.0506
2024-10-29 12:25:31: [2024-10-29 12:25:31] iter = 18300, loss = 4.5535
2024-10-29 12:25:31: [2024-10-29 12:25:31] iter = 18310, loss = 5.5918
2024-10-29 12:25:32: [2024-10-29 12:25:32] iter = 18320, loss = 3.6730
2024-10-29 12:25:32: [2024-10-29 12:25:32] iter = 18330, loss = 9.1201
2024-10-29 12:25:33: [2024-10-29 12:25:33] iter = 18340, loss = 3.7314
2024-10-29 12:25:33: [2024-10-29 12:25:33] iter = 18350, loss = 3.3680
2024-10-29 12:25:33: [2024-10-29 12:25:33] iter = 18360, loss = 3.5878
2024-10-29 12:25:34: [2024-10-29 12:25:34] iter = 18370, loss = 9.7336
2024-10-29 12:25:34: [2024-10-29 12:25:34] iter = 18380, loss = 9.5127
2024-10-29 12:25:35: [2024-10-29 12:25:35] iter = 18390, loss = 6.0681
2024-10-29 12:25:35: [2024-10-29 12:25:35] iter = 18400, loss = 2.8861
2024-10-29 12:25:36: [2024-10-29 12:25:36] iter = 18410, loss = 2.8228
2024-10-29 12:25:36: [2024-10-29 12:25:36] iter = 18420, loss = 5.1085
2024-10-29 12:25:37: [2024-10-29 12:25:37] iter = 18430, loss = 8.2580
2024-10-29 12:25:37: [2024-10-29 12:25:37] iter = 18440, loss = 7.2383
2024-10-29 12:25:37: [2024-10-29 12:25:37] iter = 18450, loss = 2.8164
2024-10-29 12:25:38: [2024-10-29 12:25:38] iter = 18460, loss = 16.2893
2024-10-29 12:25:38: [2024-10-29 12:25:38] iter = 18470, loss = 3.2599
2024-10-29 12:25:39: [2024-10-29 12:25:39] iter = 18480, loss = 9.2414
2024-10-29 12:25:39: [2024-10-29 12:25:39] iter = 18490, loss = 15.9941
2024-10-29 12:25:40: [2024-10-29 12:25:40] iter = 18500, loss = 5.4443
2024-10-29 12:25:40: [2024-10-29 12:25:40] iter = 18510, loss = 9.9639
2024-10-29 12:25:40: [2024-10-29 12:25:40] iter = 18520, loss = 4.0770
2024-10-29 12:25:41: [2024-10-29 12:25:41] iter = 18530, loss = 5.8501
2024-10-29 12:25:41: [2024-10-29 12:25:41] iter = 18540, loss = 28.3519
2024-10-29 12:25:42: [2024-10-29 12:25:42] iter = 18550, loss = 2.8587
2024-10-29 12:25:43: [2024-10-29 12:25:43] iter = 18560, loss = 4.8800
2024-10-29 12:25:43: [2024-10-29 12:25:43] iter = 18570, loss = 2.8427
2024-10-29 12:25:43: [2024-10-29 12:25:43] iter = 18580, loss = 7.3742
2024-10-29 12:25:44: [2024-10-29 12:25:44] iter = 18590, loss = 2.6435
2024-10-29 12:25:44: [2024-10-29 12:25:44] iter = 18600, loss = 15.4424
2024-10-29 12:25:45: [2024-10-29 12:25:45] iter = 18610, loss = 4.1780
2024-10-29 12:25:45: [2024-10-29 12:25:45] iter = 18620, loss = 3.6136
2024-10-29 12:25:46: [2024-10-29 12:25:46] iter = 18630, loss = 12.9064
2024-10-29 12:25:46: [2024-10-29 12:25:46] iter = 18640, loss = 5.6565
2024-10-29 12:25:47: [2024-10-29 12:25:47] iter = 18650, loss = 4.6439
2024-10-29 12:25:47: [2024-10-29 12:25:47] iter = 18660, loss = 4.6943
2024-10-29 12:25:47: [2024-10-29 12:25:47] iter = 18670, loss = 17.9150
2024-10-29 12:25:48: [2024-10-29 12:25:48] iter = 18680, loss = 7.5837
2024-10-29 12:25:48: [2024-10-29 12:25:48] iter = 18690, loss = 4.6546
2024-10-29 12:25:49: [2024-10-29 12:25:49] iter = 18700, loss = 3.5159
2024-10-29 12:25:49: [2024-10-29 12:25:49] iter = 18710, loss = 7.6418
2024-10-29 12:25:50: [2024-10-29 12:25:50] iter = 18720, loss = 6.7362
2024-10-29 12:25:50: [2024-10-29 12:25:50] iter = 18730, loss = 2.8886
2024-10-29 12:25:51: [2024-10-29 12:25:51] iter = 18740, loss = 13.3633
2024-10-29 12:25:51: [2024-10-29 12:25:51] iter = 18750, loss = 14.9268
2024-10-29 12:25:52: [2024-10-29 12:25:52] iter = 18760, loss = 5.7424
2024-10-29 12:25:52: [2024-10-29 12:25:52] iter = 18770, loss = 4.0479
2024-10-29 12:25:52: [2024-10-29 12:25:52] iter = 18780, loss = 17.4578
2024-10-29 12:25:53: [2024-10-29 12:25:53] iter = 18790, loss = 11.2470
2024-10-29 12:25:53: [2024-10-29 12:25:53] iter = 18800, loss = 4.6317
2024-10-29 12:25:54: [2024-10-29 12:25:54] iter = 18810, loss = 6.7938
2024-10-29 12:25:54: [2024-10-29 12:25:54] iter = 18820, loss = 5.2753
2024-10-29 12:25:55: [2024-10-29 12:25:55] iter = 18830, loss = 13.0303
2024-10-29 12:25:55: [2024-10-29 12:25:55] iter = 18840, loss = 3.5186
2024-10-29 12:25:56: [2024-10-29 12:25:56] iter = 18850, loss = 67.9499
2024-10-29 12:25:56: [2024-10-29 12:25:56] iter = 18860, loss = 22.4520
2024-10-29 12:25:57: [2024-10-29 12:25:57] iter = 18870, loss = 5.6505
2024-10-29 12:25:57: [2024-10-29 12:25:57] iter = 18880, loss = 3.2257
2024-10-29 12:25:57: [2024-10-29 12:25:57] iter = 18890, loss = 3.3992
2024-10-29 12:25:58: [2024-10-29 12:25:58] iter = 18900, loss = 22.5811
2024-10-29 12:25:58: [2024-10-29 12:25:58] iter = 18910, loss = 25.4786
2024-10-29 12:25:59: [2024-10-29 12:25:59] iter = 18920, loss = 27.2368
2024-10-29 12:25:59: [2024-10-29 12:25:59] iter = 18930, loss = 12.0213
2024-10-29 12:26:00: [2024-10-29 12:26:00] iter = 18940, loss = 5.0999
2024-10-29 12:26:00: [2024-10-29 12:26:00] iter = 18950, loss = 16.0364
2024-10-29 12:26:01: [2024-10-29 12:26:01] iter = 18960, loss = 3.8769
2024-10-29 12:26:01: [2024-10-29 12:26:01] iter = 18970, loss = 33.5786
2024-10-29 12:26:02: [2024-10-29 12:26:02] iter = 18980, loss = 4.8720
2024-10-29 12:26:02: [2024-10-29 12:26:02] iter = 18990, loss = 5.7431
2024-10-29 12:26:03: [2024-10-29 12:26:03] iter = 19000, loss = 5.3325
2024-10-29 12:26:03: [2024-10-29 12:26:03] iter = 19010, loss = 19.8218
2024-10-29 12:26:03: [2024-10-29 12:26:03] iter = 19020, loss = 34.9951
2024-10-29 12:26:04: [2024-10-29 12:26:04] iter = 19030, loss = 4.9211
2024-10-29 12:26:04: [2024-10-29 12:26:04] iter = 19040, loss = 14.7536
2024-10-29 12:26:05: [2024-10-29 12:26:05] iter = 19050, loss = 6.2490
2024-10-29 12:26:05: [2024-10-29 12:26:05] iter = 19060, loss = 6.7716
2024-10-29 12:26:06: [2024-10-29 12:26:06] iter = 19070, loss = 12.9697
2024-10-29 12:26:06: [2024-10-29 12:26:06] iter = 19080, loss = 2.5038
2024-10-29 12:26:07: [2024-10-29 12:26:07] iter = 19090, loss = 5.5455
2024-10-29 12:26:07: [2024-10-29 12:26:07] iter = 19100, loss = 2.3801
2024-10-29 12:26:07: [2024-10-29 12:26:07] iter = 19110, loss = 4.7130
2024-10-29 12:26:08: [2024-10-29 12:26:08] iter = 19120, loss = 3.2885
2024-10-29 12:26:08: [2024-10-29 12:26:08] iter = 19130, loss = 7.6577
2024-10-29 12:26:09: [2024-10-29 12:26:09] iter = 19140, loss = 21.2176
2024-10-29 12:26:09: [2024-10-29 12:26:09] iter = 19150, loss = 7.1022
2024-10-29 12:26:10: [2024-10-29 12:26:10] iter = 19160, loss = 2.8448
2024-10-29 12:26:10: [2024-10-29 12:26:10] iter = 19170, loss = 5.5090
2024-10-29 12:26:11: [2024-10-29 12:26:11] iter = 19180, loss = 2.3669
2024-10-29 12:26:11: [2024-10-29 12:26:11] iter = 19190, loss = 3.8788
2024-10-29 12:26:12: [2024-10-29 12:26:12] iter = 19200, loss = 34.6879
2024-10-29 12:26:12: [2024-10-29 12:26:12] iter = 19210, loss = 4.7860
2024-10-29 12:26:13: [2024-10-29 12:26:13] iter = 19220, loss = 2.8199
2024-10-29 12:26:13: [2024-10-29 12:26:13] iter = 19230, loss = 7.0171
2024-10-29 12:26:14: [2024-10-29 12:26:14] iter = 19240, loss = 2.4924
2024-10-29 12:26:14: [2024-10-29 12:26:14] iter = 19250, loss = 40.1869
2024-10-29 12:26:15: [2024-10-29 12:26:15] iter = 19260, loss = 14.1970
2024-10-29 12:26:15: [2024-10-29 12:26:15] iter = 19270, loss = 4.2088
2024-10-29 12:26:16: [2024-10-29 12:26:16] iter = 19280, loss = 5.0592
2024-10-29 12:26:16: [2024-10-29 12:26:16] iter = 19290, loss = 23.2506
2024-10-29 12:26:17: [2024-10-29 12:26:17] iter = 19300, loss = 7.6864
2024-10-29 12:26:17: [2024-10-29 12:26:17] iter = 19310, loss = 17.0726
2024-10-29 12:26:18: [2024-10-29 12:26:18] iter = 19320, loss = 4.4561
2024-10-29 12:26:18: [2024-10-29 12:26:18] iter = 19330, loss = 3.6773
2024-10-29 12:26:18: [2024-10-29 12:26:18] iter = 19340, loss = 7.5468
2024-10-29 12:26:19: [2024-10-29 12:26:19] iter = 19350, loss = 26.2540
2024-10-29 12:26:19: [2024-10-29 12:26:19] iter = 19360, loss = 7.7960
2024-10-29 12:26:20: [2024-10-29 12:26:20] iter = 19370, loss = 3.1027
2024-10-29 12:26:20: [2024-10-29 12:26:20] iter = 19380, loss = 5.2679
2024-10-29 12:26:21: [2024-10-29 12:26:21] iter = 19390, loss = 3.2375
2024-10-29 12:26:21: [2024-10-29 12:26:21] iter = 19400, loss = 32.1911
2024-10-29 12:26:22: [2024-10-29 12:26:22] iter = 19410, loss = 3.7777
2024-10-29 12:26:22: [2024-10-29 12:26:22] iter = 19420, loss = 3.5096
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 19430, loss = 6.9423
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 19440, loss = 10.8514
2024-10-29 12:26:23: [2024-10-29 12:26:23] iter = 19450, loss = 6.5446
2024-10-29 12:26:24: [2024-10-29 12:26:24] iter = 19460, loss = 17.2162
2024-10-29 12:26:25: [2024-10-29 12:26:25] iter = 19470, loss = 18.8286
2024-10-29 12:26:25: [2024-10-29 12:26:25] iter = 19480, loss = 6.2635
2024-10-29 12:26:26: [2024-10-29 12:26:26] iter = 19490, loss = 6.6964
2024-10-29 12:26:26: [2024-10-29 12:26:26] iter = 19500, loss = 8.6669
2024-10-29 12:26:26: [2024-10-29 12:26:26] iter = 19510, loss = 6.1173
2024-10-29 12:26:27: [2024-10-29 12:26:27] iter = 19520, loss = 5.4726
2024-10-29 12:26:27: [2024-10-29 12:26:27] iter = 19530, loss = 12.8082
2024-10-29 12:26:28: [2024-10-29 12:26:28] iter = 19540, loss = 9.1915
2024-10-29 12:26:28: [2024-10-29 12:26:28] iter = 19550, loss = 23.5193
2024-10-29 12:26:29: [2024-10-29 12:26:29] iter = 19560, loss = 2.7776
2024-10-29 12:26:29: [2024-10-29 12:26:29] iter = 19570, loss = 19.5680
2024-10-29 12:26:30: [2024-10-29 12:26:30] iter = 19580, loss = 7.8079
2024-10-29 12:26:30: [2024-10-29 12:26:30] iter = 19590, loss = 5.8671
2024-10-29 12:26:31: [2024-10-29 12:26:31] iter = 19600, loss = 40.3979
2024-10-29 12:26:31: [2024-10-29 12:26:31] iter = 19610, loss = 16.8691
2024-10-29 12:26:32: [2024-10-29 12:26:32] iter = 19620, loss = 26.6923
2024-10-29 12:26:32: [2024-10-29 12:26:32] iter = 19630, loss = 6.5815
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 19640, loss = 7.7367
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 19650, loss = 2.8689
2024-10-29 12:26:33: [2024-10-29 12:26:33] iter = 19660, loss = 10.5854
2024-10-29 12:26:34: [2024-10-29 12:26:34] iter = 19670, loss = 39.0013
2024-10-29 12:26:34: [2024-10-29 12:26:34] iter = 19680, loss = 7.5591
2024-10-29 12:26:35: [2024-10-29 12:26:35] iter = 19690, loss = 5.8639
2024-10-29 12:26:36: [2024-10-29 12:26:36] iter = 19700, loss = 6.1594
2024-10-29 12:26:36: [2024-10-29 12:26:36] iter = 19710, loss = 2.9831
2024-10-29 12:26:37: [2024-10-29 12:26:37] iter = 19720, loss = 5.7001
2024-10-29 12:26:37: [2024-10-29 12:26:37] iter = 19730, loss = 11.1278
2024-10-29 12:26:38: [2024-10-29 12:26:38] iter = 19740, loss = 4.8732
2024-10-29 12:26:38: [2024-10-29 12:26:38] iter = 19750, loss = 8.5195
2024-10-29 12:26:39: [2024-10-29 12:26:39] iter = 19760, loss = 7.3563
2024-10-29 12:26:39: [2024-10-29 12:26:39] iter = 19770, loss = 10.9461
2024-10-29 12:26:40: [2024-10-29 12:26:40] iter = 19780, loss = 3.2455
2024-10-29 12:26:40: [2024-10-29 12:26:40] iter = 19790, loss = 3.4683
2024-10-29 12:26:41: [2024-10-29 12:26:41] iter = 19800, loss = 9.9227
2024-10-29 12:26:42: [2024-10-29 12:26:42] iter = 19810, loss = 5.5975
2024-10-29 12:26:42: [2024-10-29 12:26:42] iter = 19820, loss = 5.7674
2024-10-29 12:26:43: [2024-10-29 12:26:43] iter = 19830, loss = 4.0861
2024-10-29 12:26:43: [2024-10-29 12:26:43] iter = 19840, loss = 3.8897
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 19850, loss = 3.3399
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 19860, loss = 7.6400
2024-10-29 12:26:44: [2024-10-29 12:26:44] iter = 19870, loss = 3.0218
2024-10-29 12:26:45: [2024-10-29 12:26:45] iter = 19880, loss = 2.9614
2024-10-29 12:26:45: [2024-10-29 12:26:45] iter = 19890, loss = 4.5143
2024-10-29 12:26:46: [2024-10-29 12:26:46] iter = 19900, loss = 11.8832
2024-10-29 12:26:46: [2024-10-29 12:26:46] iter = 19910, loss = 2.8660
2024-10-29 12:26:47: [2024-10-29 12:26:47] iter = 19920, loss = 4.2067
2024-10-29 12:26:47: [2024-10-29 12:26:47] iter = 19930, loss = 6.0443
2024-10-29 12:26:48: [2024-10-29 12:26:48] iter = 19940, loss = 3.4253
2024-10-29 12:26:48: [2024-10-29 12:26:48] iter = 19950, loss = 3.1874
2024-10-29 12:26:49: [2024-10-29 12:26:49] iter = 19960, loss = 4.1108
2024-10-29 12:26:49: [2024-10-29 12:26:49] iter = 19970, loss = 18.3046
2024-10-29 12:26:49: [2024-10-29 12:26:49] iter = 19980, loss = 3.0142
2024-10-29 12:26:50: [2024-10-29 12:26:50] iter = 19990, loss = 2.9275
2024-10-29 12:26:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 12:26:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:26:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 10951}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:27:15: Evaluate 5 random ConvNet, ACCmean = 0.5578 ACCstd = 0.0048
-------------------------
2024-10-29 12:27:15: Evaluate 5 random ConvNet, SENmean = 0.5578 SENstd = 0.0048
-------------------------
2024-10-29 12:27:15: Evaluate 5 random ConvNet, SPEmean = 0.8526 SPEstd = 0.0016
-------------------------
2024-10-29 12:27:15: Evaluate 5 random ConvNet, F!mean = 0.5632 F!std = 0.0045
-------------------------
2024-10-29 12:27:15: Evaluate 5 random ConvNet, mean = 0.5578 std = 0.0048
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:27:15: [2024-10-29 12:27:15] iter = 20000, loss = 2.4968
2024-10-29 12:27:15: 
================== Exp 2 ==================
 
2024-10-29 12:27:15: Hyper-parameters: 
{'dataset': 'OCTMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faf200e8730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OCTMNIST (INFO)>}
2024-10-29 12:27:15: Evaluation model pool: ['ConvNet']
2024-10-29 12:27:17: class c = 0: 33484 real images
2024-10-29 12:27:17: class c = 1: 10213 real images
2024-10-29 12:27:17: class c = 2: 7754 real images
2024-10-29 12:27:17: class c = 3: 46026 real images
2024-10-29 12:27:17: real images channel 0, mean = 0.1889, std = 0.1963
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 12:27:17: initialize synthetic data from random real images
2024-10-29 12:27:18: [2024-10-29 12:27:18] training begins
2024-10-29 12:27:18: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 12:27:18: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:27:18: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 35099}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:27:42: Evaluate 5 random ConvNet, ACCmean = 0.4190 ACCstd = 0.0050
-------------------------
2024-10-29 12:27:42: Evaluate 5 random ConvNet, SENmean = 0.4190 SENstd = 0.0050
-------------------------
2024-10-29 12:27:42: Evaluate 5 random ConvNet, SPEmean = 0.8063 SPEstd = 0.0017
-------------------------
2024-10-29 12:27:42: Evaluate 5 random ConvNet, F!mean = 0.4146 F!std = 0.0064
-------------------------
2024-10-29 12:27:42: Evaluate 5 random ConvNet, mean = 0.4190 std = 0.0050
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:27:42: [2024-10-29 12:27:42] iter = 00000, loss = 13.6977
2024-10-29 12:27:43: [2024-10-29 12:27:43] iter = 00010, loss = 19.7247
2024-10-29 12:27:43: [2024-10-29 12:27:43] iter = 00020, loss = 11.1367
2024-10-29 12:27:44: [2024-10-29 12:27:44] iter = 00030, loss = 26.4694
2024-10-29 12:27:44: [2024-10-29 12:27:44] iter = 00040, loss = 15.0637
2024-10-29 12:27:45: [2024-10-29 12:27:45] iter = 00050, loss = 5.9437
2024-10-29 12:27:45: [2024-10-29 12:27:45] iter = 00060, loss = 15.0384
2024-10-29 12:27:46: [2024-10-29 12:27:46] iter = 00070, loss = 6.2245
2024-10-29 12:27:46: [2024-10-29 12:27:46] iter = 00080, loss = 7.1646
2024-10-29 12:27:46: [2024-10-29 12:27:46] iter = 00090, loss = 8.3109
2024-10-29 12:27:47: [2024-10-29 12:27:47] iter = 00100, loss = 4.5578
2024-10-29 12:27:48: [2024-10-29 12:27:48] iter = 00110, loss = 8.9223
2024-10-29 12:27:48: [2024-10-29 12:27:48] iter = 00120, loss = 32.3990
2024-10-29 12:27:49: [2024-10-29 12:27:49] iter = 00130, loss = 14.7480
2024-10-29 12:27:50: [2024-10-29 12:27:50] iter = 00140, loss = 4.4219
2024-10-29 12:27:50: [2024-10-29 12:27:50] iter = 00150, loss = 12.2063
2024-10-29 12:27:51: [2024-10-29 12:27:51] iter = 00160, loss = 6.1500
2024-10-29 12:27:51: [2024-10-29 12:27:51] iter = 00170, loss = 8.3999
2024-10-29 12:27:52: [2024-10-29 12:27:52] iter = 00180, loss = 6.3366
2024-10-29 12:27:52: [2024-10-29 12:27:52] iter = 00190, loss = 4.2376
2024-10-29 12:27:53: [2024-10-29 12:27:53] iter = 00200, loss = 4.3602
2024-10-29 12:27:53: [2024-10-29 12:27:53] iter = 00210, loss = 12.7291
2024-10-29 12:27:54: [2024-10-29 12:27:54] iter = 00220, loss = 12.5859
2024-10-29 12:27:54: [2024-10-29 12:27:54] iter = 00230, loss = 9.2220
2024-10-29 12:27:55: [2024-10-29 12:27:55] iter = 00240, loss = 4.5925
2024-10-29 12:27:55: [2024-10-29 12:27:55] iter = 00250, loss = 3.7473
2024-10-29 12:27:56: [2024-10-29 12:27:56] iter = 00260, loss = 15.1539
2024-10-29 12:27:56: [2024-10-29 12:27:56] iter = 00270, loss = 13.9164
2024-10-29 12:27:57: [2024-10-29 12:27:57] iter = 00280, loss = 7.8488
2024-10-29 12:27:57: [2024-10-29 12:27:57] iter = 00290, loss = 4.5312
2024-10-29 12:27:58: [2024-10-29 12:27:58] iter = 00300, loss = 4.1087
2024-10-29 12:27:58: [2024-10-29 12:27:58] iter = 00310, loss = 5.9722
2024-10-29 12:27:59: [2024-10-29 12:27:59] iter = 00320, loss = 4.0088
2024-10-29 12:27:59: [2024-10-29 12:27:59] iter = 00330, loss = 2.8244
2024-10-29 12:27:59: [2024-10-29 12:27:59] iter = 00340, loss = 5.8022
2024-10-29 12:28:00: [2024-10-29 12:28:00] iter = 00350, loss = 41.8780
2024-10-29 12:28:00: [2024-10-29 12:28:00] iter = 00360, loss = 74.2261
2024-10-29 12:28:01: [2024-10-29 12:28:01] iter = 00370, loss = 5.2632
2024-10-29 12:28:01: [2024-10-29 12:28:01] iter = 00380, loss = 39.4039
2024-10-29 12:28:02: [2024-10-29 12:28:02] iter = 00390, loss = 6.9924
2024-10-29 12:28:02: [2024-10-29 12:28:02] iter = 00400, loss = 36.7826
2024-10-29 12:28:03: [2024-10-29 12:28:03] iter = 00410, loss = 2.9209
2024-10-29 12:28:03: [2024-10-29 12:28:03] iter = 00420, loss = 19.8323
2024-10-29 12:28:04: [2024-10-29 12:28:04] iter = 00430, loss = 3.2211
2024-10-29 12:28:04: [2024-10-29 12:28:04] iter = 00440, loss = 10.6154
2024-10-29 12:28:04: [2024-10-29 12:28:04] iter = 00450, loss = 7.2638
2024-10-29 12:28:05: [2024-10-29 12:28:05] iter = 00460, loss = 7.1819
2024-10-29 12:28:05: [2024-10-29 12:28:05] iter = 00470, loss = 8.1710
2024-10-29 12:28:06: [2024-10-29 12:28:06] iter = 00480, loss = 42.6450
2024-10-29 12:28:06: [2024-10-29 12:28:06] iter = 00490, loss = 6.3204
2024-10-29 12:28:07: [2024-10-29 12:28:07] iter = 00500, loss = 17.7656
2024-10-29 12:28:07: [2024-10-29 12:28:07] iter = 00510, loss = 6.8950
2024-10-29 12:28:08: [2024-10-29 12:28:08] iter = 00520, loss = 2.8229
2024-10-29 12:28:08: [2024-10-29 12:28:08] iter = 00530, loss = 23.0389
2024-10-29 12:28:09: [2024-10-29 12:28:09] iter = 00540, loss = 2.9983
2024-10-29 12:28:09: [2024-10-29 12:28:09] iter = 00550, loss = 2.8414
2024-10-29 12:28:10: [2024-10-29 12:28:10] iter = 00560, loss = 10.4781
2024-10-29 12:28:10: [2024-10-29 12:28:10] iter = 00570, loss = 6.3556
2024-10-29 12:28:10: [2024-10-29 12:28:10] iter = 00580, loss = 4.5559
2024-10-29 12:28:11: [2024-10-29 12:28:11] iter = 00590, loss = 2.9055
2024-10-29 12:28:11: [2024-10-29 12:28:11] iter = 00600, loss = 4.5033
2024-10-29 12:28:12: [2024-10-29 12:28:12] iter = 00610, loss = 6.5369
2024-10-29 12:28:12: [2024-10-29 12:28:12] iter = 00620, loss = 12.8452
2024-10-29 12:28:13: [2024-10-29 12:28:13] iter = 00630, loss = 36.4417
2024-10-29 12:28:13: [2024-10-29 12:28:13] iter = 00640, loss = 7.7431
2024-10-29 12:28:14: [2024-10-29 12:28:14] iter = 00650, loss = 7.7124
2024-10-29 12:28:14: [2024-10-29 12:28:14] iter = 00660, loss = 4.3929
2024-10-29 12:28:15: [2024-10-29 12:28:15] iter = 00670, loss = 2.4743
2024-10-29 12:28:15: [2024-10-29 12:28:15] iter = 00680, loss = 9.5778
2024-10-29 12:28:16: [2024-10-29 12:28:16] iter = 00690, loss = 3.7951
2024-10-29 12:28:16: [2024-10-29 12:28:16] iter = 00700, loss = 3.4542
2024-10-29 12:28:17: [2024-10-29 12:28:17] iter = 00710, loss = 10.5388
2024-10-29 12:28:17: [2024-10-29 12:28:17] iter = 00720, loss = 4.7771
2024-10-29 12:28:18: [2024-10-29 12:28:18] iter = 00730, loss = 10.2125
2024-10-29 12:28:18: [2024-10-29 12:28:18] iter = 00740, loss = 3.8229
2024-10-29 12:28:19: [2024-10-29 12:28:18] iter = 00750, loss = 3.6361
2024-10-29 12:28:19: [2024-10-29 12:28:19] iter = 00760, loss = 7.8926
2024-10-29 12:28:19: [2024-10-29 12:28:19] iter = 00770, loss = 4.9267
2024-10-29 12:28:20: [2024-10-29 12:28:20] iter = 00780, loss = 4.2481
2024-10-29 12:28:20: [2024-10-29 12:28:20] iter = 00790, loss = 3.6723
2024-10-29 12:28:21: [2024-10-29 12:28:21] iter = 00800, loss = 19.1520
2024-10-29 12:28:21: [2024-10-29 12:28:21] iter = 00810, loss = 3.1796
2024-10-29 12:28:22: [2024-10-29 12:28:22] iter = 00820, loss = 12.7804
2024-10-29 12:28:22: [2024-10-29 12:28:22] iter = 00830, loss = 4.1213
2024-10-29 12:28:23: [2024-10-29 12:28:23] iter = 00840, loss = 10.1767
2024-10-29 12:28:23: [2024-10-29 12:28:23] iter = 00850, loss = 2.9732
2024-10-29 12:28:24: [2024-10-29 12:28:24] iter = 00860, loss = 6.4193
2024-10-29 12:28:24: [2024-10-29 12:28:24] iter = 00870, loss = 14.0124
2024-10-29 12:28:25: [2024-10-29 12:28:25] iter = 00880, loss = 8.6820
2024-10-29 12:28:25: [2024-10-29 12:28:25] iter = 00890, loss = 25.4825
2024-10-29 12:28:26: [2024-10-29 12:28:26] iter = 00900, loss = 5.2990
2024-10-29 12:28:26: [2024-10-29 12:28:26] iter = 00910, loss = 5.2893
2024-10-29 12:28:27: [2024-10-29 12:28:27] iter = 00920, loss = 7.7505
2024-10-29 12:28:27: [2024-10-29 12:28:27] iter = 00930, loss = 7.4301
2024-10-29 12:28:28: [2024-10-29 12:28:28] iter = 00940, loss = 8.2437
2024-10-29 12:28:28: [2024-10-29 12:28:28] iter = 00950, loss = 4.4494
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 00960, loss = 3.4995
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 00970, loss = 11.6462
2024-10-29 12:28:29: [2024-10-29 12:28:29] iter = 00980, loss = 4.0496
2024-10-29 12:28:30: [2024-10-29 12:28:30] iter = 00990, loss = 10.2446
2024-10-29 12:28:31: [2024-10-29 12:28:31] iter = 01000, loss = 4.0153
2024-10-29 12:28:31: [2024-10-29 12:28:31] iter = 01010, loss = 4.2903
2024-10-29 12:28:32: [2024-10-29 12:28:32] iter = 01020, loss = 3.2849
2024-10-29 12:28:32: [2024-10-29 12:28:32] iter = 01030, loss = 2.6420
2024-10-29 12:28:33: [2024-10-29 12:28:33] iter = 01040, loss = 12.5503
2024-10-29 12:28:33: [2024-10-29 12:28:33] iter = 01050, loss = 2.9346
2024-10-29 12:28:34: [2024-10-29 12:28:34] iter = 01060, loss = 5.2250
2024-10-29 12:28:35: [2024-10-29 12:28:35] iter = 01070, loss = 27.7702
2024-10-29 12:28:35: [2024-10-29 12:28:35] iter = 01080, loss = 20.1386
2024-10-29 12:28:36: [2024-10-29 12:28:36] iter = 01090, loss = 26.5750
2024-10-29 12:28:36: [2024-10-29 12:28:36] iter = 01100, loss = 12.7552
2024-10-29 12:28:37: [2024-10-29 12:28:37] iter = 01110, loss = 5.7474
2024-10-29 12:28:38: [2024-10-29 12:28:38] iter = 01120, loss = 3.1269
2024-10-29 12:28:38: [2024-10-29 12:28:38] iter = 01130, loss = 6.2765
2024-10-29 12:28:39: [2024-10-29 12:28:39] iter = 01140, loss = 3.3297
2024-10-29 12:28:39: [2024-10-29 12:28:39] iter = 01150, loss = 6.0088
2024-10-29 12:28:40: [2024-10-29 12:28:40] iter = 01160, loss = 4.0330
2024-10-29 12:28:40: [2024-10-29 12:28:40] iter = 01170, loss = 8.0599
2024-10-29 12:28:41: [2024-10-29 12:28:41] iter = 01180, loss = 14.1406
2024-10-29 12:28:41: [2024-10-29 12:28:41] iter = 01190, loss = 9.8844
2024-10-29 12:28:42: [2024-10-29 12:28:42] iter = 01200, loss = 4.6039
2024-10-29 12:28:42: [2024-10-29 12:28:42] iter = 01210, loss = 2.9644
2024-10-29 12:28:43: [2024-10-29 12:28:43] iter = 01220, loss = 22.8255
2024-10-29 12:28:43: [2024-10-29 12:28:43] iter = 01230, loss = 7.9854
2024-10-29 12:28:43: [2024-10-29 12:28:43] iter = 01240, loss = 4.7167
2024-10-29 12:28:44: [2024-10-29 12:28:44] iter = 01250, loss = 8.3345
2024-10-29 12:28:44: [2024-10-29 12:28:44] iter = 01260, loss = 4.1388
2024-10-29 12:28:45: [2024-10-29 12:28:45] iter = 01270, loss = 3.1133
2024-10-29 12:28:45: [2024-10-29 12:28:45] iter = 01280, loss = 2.5529
2024-10-29 12:28:46: [2024-10-29 12:28:46] iter = 01290, loss = 9.9399
2024-10-29 12:28:46: [2024-10-29 12:28:46] iter = 01300, loss = 3.5654
2024-10-29 12:28:47: [2024-10-29 12:28:47] iter = 01310, loss = 7.9440
2024-10-29 12:28:47: [2024-10-29 12:28:47] iter = 01320, loss = 19.4528
2024-10-29 12:28:48: [2024-10-29 12:28:48] iter = 01330, loss = 43.0805
2024-10-29 12:28:48: [2024-10-29 12:28:48] iter = 01340, loss = 4.6874
2024-10-29 12:28:49: [2024-10-29 12:28:48] iter = 01350, loss = 7.7333
2024-10-29 12:28:49: [2024-10-29 12:28:49] iter = 01360, loss = 3.5551
2024-10-29 12:28:50: [2024-10-29 12:28:50] iter = 01370, loss = 4.4737
2024-10-29 12:28:50: [2024-10-29 12:28:50] iter = 01380, loss = 5.1773
2024-10-29 12:28:51: [2024-10-29 12:28:51] iter = 01390, loss = 50.6709
2024-10-29 12:28:51: [2024-10-29 12:28:51] iter = 01400, loss = 5.0051
2024-10-29 12:28:52: [2024-10-29 12:28:51] iter = 01410, loss = 5.8759
2024-10-29 12:28:52: [2024-10-29 12:28:52] iter = 01420, loss = 7.2216
2024-10-29 12:28:53: [2024-10-29 12:28:53] iter = 01430, loss = 3.0282
2024-10-29 12:28:53: [2024-10-29 12:28:53] iter = 01440, loss = 2.7441
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 01450, loss = 2.6416
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 01460, loss = 5.8343
2024-10-29 12:28:54: [2024-10-29 12:28:54] iter = 01470, loss = 13.9471
2024-10-29 12:28:55: [2024-10-29 12:28:55] iter = 01480, loss = 17.6056
2024-10-29 12:28:55: [2024-10-29 12:28:55] iter = 01490, loss = 20.5481
2024-10-29 12:28:56: [2024-10-29 12:28:56] iter = 01500, loss = 10.1711
2024-10-29 12:28:56: [2024-10-29 12:28:56] iter = 01510, loss = 24.0290
2024-10-29 12:28:57: [2024-10-29 12:28:57] iter = 01520, loss = 4.4868
2024-10-29 12:28:57: [2024-10-29 12:28:57] iter = 01530, loss = 4.9395
2024-10-29 12:28:58: [2024-10-29 12:28:58] iter = 01540, loss = 2.7709
2024-10-29 12:28:58: [2024-10-29 12:28:58] iter = 01550, loss = 3.5174
2024-10-29 12:28:59: [2024-10-29 12:28:59] iter = 01560, loss = 4.3319
2024-10-29 12:28:59: [2024-10-29 12:28:59] iter = 01570, loss = 8.8404
2024-10-29 12:29:00: [2024-10-29 12:29:00] iter = 01580, loss = 15.9641
2024-10-29 12:29:01: [2024-10-29 12:29:01] iter = 01590, loss = 5.6756
2024-10-29 12:29:01: [2024-10-29 12:29:01] iter = 01600, loss = 5.9208
2024-10-29 12:29:02: [2024-10-29 12:29:02] iter = 01610, loss = 3.5350
2024-10-29 12:29:02: [2024-10-29 12:29:02] iter = 01620, loss = 3.5478
2024-10-29 12:29:03: [2024-10-29 12:29:03] iter = 01630, loss = 16.9403
2024-10-29 12:29:03: [2024-10-29 12:29:03] iter = 01640, loss = 11.0388
2024-10-29 12:29:04: [2024-10-29 12:29:04] iter = 01650, loss = 3.6461
2024-10-29 12:29:04: [2024-10-29 12:29:04] iter = 01660, loss = 7.8964
2024-10-29 12:29:05: [2024-10-29 12:29:05] iter = 01670, loss = 4.6185
2024-10-29 12:29:05: [2024-10-29 12:29:05] iter = 01680, loss = 4.1367
2024-10-29 12:29:06: [2024-10-29 12:29:06] iter = 01690, loss = 4.0568
2024-10-29 12:29:06: [2024-10-29 12:29:06] iter = 01700, loss = 17.2554
2024-10-29 12:29:07: [2024-10-29 12:29:07] iter = 01710, loss = 2.9686
2024-10-29 12:29:07: [2024-10-29 12:29:07] iter = 01720, loss = 4.8972
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 01730, loss = 10.5428
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 01740, loss = 12.8406
2024-10-29 12:29:08: [2024-10-29 12:29:08] iter = 01750, loss = 3.3818
2024-10-29 12:29:09: [2024-10-29 12:29:09] iter = 01760, loss = 8.3281
2024-10-29 12:29:09: [2024-10-29 12:29:09] iter = 01770, loss = 16.1563
2024-10-29 12:29:10: [2024-10-29 12:29:10] iter = 01780, loss = 6.6222
2024-10-29 12:29:10: [2024-10-29 12:29:10] iter = 01790, loss = 5.6152
2024-10-29 12:29:11: [2024-10-29 12:29:11] iter = 01800, loss = 6.9532
2024-10-29 12:29:11: [2024-10-29 12:29:11] iter = 01810, loss = 9.7499
2024-10-29 12:29:12: [2024-10-29 12:29:12] iter = 01820, loss = 8.0007
2024-10-29 12:29:12: [2024-10-29 12:29:12] iter = 01830, loss = 4.6653
2024-10-29 12:29:13: [2024-10-29 12:29:13] iter = 01840, loss = 19.1898
2024-10-29 12:29:13: [2024-10-29 12:29:13] iter = 01850, loss = 8.0401
2024-10-29 12:29:14: [2024-10-29 12:29:14] iter = 01860, loss = 2.5991
2024-10-29 12:29:14: [2024-10-29 12:29:14] iter = 01870, loss = 4.7414
2024-10-29 12:29:14: [2024-10-29 12:29:14] iter = 01880, loss = 3.4287
2024-10-29 12:29:15: [2024-10-29 12:29:15] iter = 01890, loss = 3.1723
2024-10-29 12:29:16: [2024-10-29 12:29:16] iter = 01900, loss = 2.7125
2024-10-29 12:29:16: [2024-10-29 12:29:16] iter = 01910, loss = 20.2532
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 01920, loss = 4.6779
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 01930, loss = 3.2844
2024-10-29 12:29:17: [2024-10-29 12:29:17] iter = 01940, loss = 4.1652
2024-10-29 12:29:18: [2024-10-29 12:29:18] iter = 01950, loss = 12.2651
2024-10-29 12:29:19: [2024-10-29 12:29:19] iter = 01960, loss = 12.8326
2024-10-29 12:29:19: [2024-10-29 12:29:19] iter = 01970, loss = 3.9241
2024-10-29 12:29:19: [2024-10-29 12:29:19] iter = 01980, loss = 16.8029
2024-10-29 12:29:20: [2024-10-29 12:29:20] iter = 01990, loss = 4.3583
2024-10-29 12:29:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 12:29:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:29:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60840}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:29:45: Evaluate 5 random ConvNet, ACCmean = 0.4688 ACCstd = 0.0040
-------------------------
2024-10-29 12:29:45: Evaluate 5 random ConvNet, SENmean = 0.4688 SENstd = 0.0040
-------------------------
2024-10-29 12:29:45: Evaluate 5 random ConvNet, SPEmean = 0.8229 SPEstd = 0.0013
-------------------------
2024-10-29 12:29:45: Evaluate 5 random ConvNet, F!mean = 0.3751 F!std = 0.0062
-------------------------
2024-10-29 12:29:45: Evaluate 5 random ConvNet, mean = 0.4688 std = 0.0040
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:29:45: [2024-10-29 12:29:45] iter = 02000, loss = 8.9704
2024-10-29 12:29:45: [2024-10-29 12:29:45] iter = 02010, loss = 41.0423
2024-10-29 12:29:46: [2024-10-29 12:29:46] iter = 02020, loss = 11.1039
2024-10-29 12:29:46: [2024-10-29 12:29:46] iter = 02030, loss = 58.3315
2024-10-29 12:29:47: [2024-10-29 12:29:47] iter = 02040, loss = 5.8002
2024-10-29 12:29:47: [2024-10-29 12:29:47] iter = 02050, loss = 21.0746
2024-10-29 12:29:48: [2024-10-29 12:29:48] iter = 02060, loss = 13.2131
2024-10-29 12:29:48: [2024-10-29 12:29:48] iter = 02070, loss = 25.5286
2024-10-29 12:29:49: [2024-10-29 12:29:49] iter = 02080, loss = 4.5040
2024-10-29 12:29:49: [2024-10-29 12:29:49] iter = 02090, loss = 4.2146
2024-10-29 12:29:50: [2024-10-29 12:29:50] iter = 02100, loss = 11.3674
2024-10-29 12:29:50: [2024-10-29 12:29:50] iter = 02110, loss = 3.3226
2024-10-29 12:29:51: [2024-10-29 12:29:51] iter = 02120, loss = 8.9887
2024-10-29 12:29:51: [2024-10-29 12:29:51] iter = 02130, loss = 8.8722
2024-10-29 12:29:52: [2024-10-29 12:29:52] iter = 02140, loss = 13.4619
2024-10-29 12:29:52: [2024-10-29 12:29:52] iter = 02150, loss = 11.7759
2024-10-29 12:29:53: [2024-10-29 12:29:53] iter = 02160, loss = 6.5463
2024-10-29 12:29:53: [2024-10-29 12:29:53] iter = 02170, loss = 2.9784
2024-10-29 12:29:54: [2024-10-29 12:29:54] iter = 02180, loss = 7.8017
2024-10-29 12:29:54: [2024-10-29 12:29:54] iter = 02190, loss = 4.9521
2024-10-29 12:29:55: [2024-10-29 12:29:55] iter = 02200, loss = 6.8177
2024-10-29 12:29:55: [2024-10-29 12:29:55] iter = 02210, loss = 2.9194
2024-10-29 12:29:56: [2024-10-29 12:29:56] iter = 02220, loss = 7.8562
2024-10-29 12:29:56: [2024-10-29 12:29:56] iter = 02230, loss = 4.9469
2024-10-29 12:29:57: [2024-10-29 12:29:57] iter = 02240, loss = 5.3401
2024-10-29 12:29:57: [2024-10-29 12:29:57] iter = 02250, loss = 5.7058
2024-10-29 12:29:58: [2024-10-29 12:29:58] iter = 02260, loss = 9.9059
2024-10-29 12:29:58: [2024-10-29 12:29:58] iter = 02270, loss = 5.4564
2024-10-29 12:29:59: [2024-10-29 12:29:59] iter = 02280, loss = 3.9003
2024-10-29 12:30:00: [2024-10-29 12:30:00] iter = 02290, loss = 5.6475
2024-10-29 12:30:00: [2024-10-29 12:30:00] iter = 02300, loss = 20.0152
2024-10-29 12:30:01: [2024-10-29 12:30:01] iter = 02310, loss = 5.8706
2024-10-29 12:30:02: [2024-10-29 12:30:02] iter = 02320, loss = 20.5331
2024-10-29 12:30:02: [2024-10-29 12:30:02] iter = 02330, loss = 52.2855
2024-10-29 12:30:03: [2024-10-29 12:30:03] iter = 02340, loss = 25.8719
2024-10-29 12:30:04: [2024-10-29 12:30:04] iter = 02350, loss = 9.8713
2024-10-29 12:30:04: [2024-10-29 12:30:04] iter = 02360, loss = 8.2294
2024-10-29 12:30:05: [2024-10-29 12:30:05] iter = 02370, loss = 47.9435
2024-10-29 12:30:05: [2024-10-29 12:30:05] iter = 02380, loss = 58.7906
2024-10-29 12:30:06: [2024-10-29 12:30:06] iter = 02390, loss = 3.9064
2024-10-29 12:30:07: [2024-10-29 12:30:07] iter = 02400, loss = 4.3570
2024-10-29 12:30:07: [2024-10-29 12:30:07] iter = 02410, loss = 25.2973
2024-10-29 12:30:08: [2024-10-29 12:30:08] iter = 02420, loss = 4.3004
2024-10-29 12:30:09: [2024-10-29 12:30:09] iter = 02430, loss = 5.3085
2024-10-29 12:30:09: [2024-10-29 12:30:09] iter = 02440, loss = 5.5251
2024-10-29 12:30:10: [2024-10-29 12:30:10] iter = 02450, loss = 9.9180
2024-10-29 12:30:10: [2024-10-29 12:30:10] iter = 02460, loss = 48.0923
2024-10-29 12:30:11: [2024-10-29 12:30:11] iter = 02470, loss = 5.0716
2024-10-29 12:30:11: [2024-10-29 12:30:11] iter = 02480, loss = 14.3060
2024-10-29 12:30:12: [2024-10-29 12:30:12] iter = 02490, loss = 9.0414
2024-10-29 12:30:12: [2024-10-29 12:30:12] iter = 02500, loss = 4.3661
2024-10-29 12:30:13: [2024-10-29 12:30:13] iter = 02510, loss = 13.5371
2024-10-29 12:30:13: [2024-10-29 12:30:13] iter = 02520, loss = 8.0487
2024-10-29 12:30:14: [2024-10-29 12:30:14] iter = 02530, loss = 8.0971
2024-10-29 12:30:14: [2024-10-29 12:30:14] iter = 02540, loss = 3.2348
2024-10-29 12:30:15: [2024-10-29 12:30:15] iter = 02550, loss = 14.1190
2024-10-29 12:30:15: [2024-10-29 12:30:15] iter = 02560, loss = 6.0838
2024-10-29 12:30:16: [2024-10-29 12:30:16] iter = 02570, loss = 9.0320
2024-10-29 12:30:16: [2024-10-29 12:30:16] iter = 02580, loss = 24.9231
2024-10-29 12:30:17: [2024-10-29 12:30:17] iter = 02590, loss = 2.9719
2024-10-29 12:30:17: [2024-10-29 12:30:17] iter = 02600, loss = 5.9991
2024-10-29 12:30:18: [2024-10-29 12:30:18] iter = 02610, loss = 5.0132
2024-10-29 12:30:18: [2024-10-29 12:30:18] iter = 02620, loss = 6.1225
2024-10-29 12:30:19: [2024-10-29 12:30:19] iter = 02630, loss = 2.7811
2024-10-29 12:30:19: [2024-10-29 12:30:19] iter = 02640, loss = 4.4712
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 02650, loss = 3.3073
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 02660, loss = 4.5603
2024-10-29 12:30:20: [2024-10-29 12:30:20] iter = 02670, loss = 6.7313
2024-10-29 12:30:21: [2024-10-29 12:30:21] iter = 02680, loss = 18.1343
2024-10-29 12:30:21: [2024-10-29 12:30:21] iter = 02690, loss = 3.9162
2024-10-29 12:30:22: [2024-10-29 12:30:22] iter = 02700, loss = 24.0794
2024-10-29 12:30:22: [2024-10-29 12:30:22] iter = 02710, loss = 4.8683
2024-10-29 12:30:23: [2024-10-29 12:30:23] iter = 02720, loss = 20.5228
2024-10-29 12:30:23: [2024-10-29 12:30:23] iter = 02730, loss = 4.5629
2024-10-29 12:30:24: [2024-10-29 12:30:24] iter = 02740, loss = 17.6855
2024-10-29 12:30:24: [2024-10-29 12:30:24] iter = 02750, loss = 6.7252
2024-10-29 12:30:25: [2024-10-29 12:30:25] iter = 02760, loss = 4.0265
2024-10-29 12:30:25: [2024-10-29 12:30:25] iter = 02770, loss = 20.8863
2024-10-29 12:30:26: [2024-10-29 12:30:26] iter = 02780, loss = 11.1239
2024-10-29 12:30:26: [2024-10-29 12:30:26] iter = 02790, loss = 9.5505
2024-10-29 12:30:27: [2024-10-29 12:30:27] iter = 02800, loss = 4.9049
2024-10-29 12:30:27: [2024-10-29 12:30:27] iter = 02810, loss = 13.6361
2024-10-29 12:30:28: [2024-10-29 12:30:28] iter = 02820, loss = 4.3341
2024-10-29 12:30:28: [2024-10-29 12:30:28] iter = 02830, loss = 16.2535
2024-10-29 12:30:28: [2024-10-29 12:30:28] iter = 02840, loss = 7.2477
2024-10-29 12:30:29: [2024-10-29 12:30:29] iter = 02850, loss = 2.9766
2024-10-29 12:30:29: [2024-10-29 12:30:29] iter = 02860, loss = 4.1977
2024-10-29 12:30:30: [2024-10-29 12:30:30] iter = 02870, loss = 35.0462
2024-10-29 12:30:30: [2024-10-29 12:30:30] iter = 02880, loss = 4.3988
2024-10-29 12:30:31: [2024-10-29 12:30:31] iter = 02890, loss = 4.5320
2024-10-29 12:30:31: [2024-10-29 12:30:31] iter = 02900, loss = 49.1073
2024-10-29 12:30:32: [2024-10-29 12:30:32] iter = 02910, loss = 3.6059
2024-10-29 12:30:32: [2024-10-29 12:30:32] iter = 02920, loss = 22.2789
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 02930, loss = 5.8510
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 02940, loss = 2.3200
2024-10-29 12:30:33: [2024-10-29 12:30:33] iter = 02950, loss = 10.5866
2024-10-29 12:30:34: [2024-10-29 12:30:34] iter = 02960, loss = 4.2238
2024-10-29 12:30:34: [2024-10-29 12:30:34] iter = 02970, loss = 3.9259
2024-10-29 12:30:35: [2024-10-29 12:30:35] iter = 02980, loss = 4.5317
2024-10-29 12:30:35: [2024-10-29 12:30:35] iter = 02990, loss = 12.3151
2024-10-29 12:30:36: [2024-10-29 12:30:36] iter = 03000, loss = 3.1934
2024-10-29 12:30:36: [2024-10-29 12:30:36] iter = 03010, loss = 44.5311
2024-10-29 12:30:37: [2024-10-29 12:30:37] iter = 03020, loss = 14.3453
2024-10-29 12:30:37: [2024-10-29 12:30:37] iter = 03030, loss = 2.7611
2024-10-29 12:30:37: [2024-10-29 12:30:37] iter = 03040, loss = 3.1551
2024-10-29 12:30:38: [2024-10-29 12:30:38] iter = 03050, loss = 4.1778
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 03060, loss = 2.5495
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 03070, loss = 6.8357
2024-10-29 12:30:39: [2024-10-29 12:30:39] iter = 03080, loss = 39.6687
2024-10-29 12:30:40: [2024-10-29 12:30:40] iter = 03090, loss = 5.1530
2024-10-29 12:30:40: [2024-10-29 12:30:40] iter = 03100, loss = 4.1314
2024-10-29 12:30:41: [2024-10-29 12:30:41] iter = 03110, loss = 10.5254
2024-10-29 12:30:41: [2024-10-29 12:30:41] iter = 03120, loss = 11.9753
2024-10-29 12:30:42: [2024-10-29 12:30:42] iter = 03130, loss = 3.5726
2024-10-29 12:30:42: [2024-10-29 12:30:42] iter = 03140, loss = 17.7407
2024-10-29 12:30:43: [2024-10-29 12:30:43] iter = 03150, loss = 4.4537
2024-10-29 12:30:43: [2024-10-29 12:30:43] iter = 03160, loss = 4.7889
2024-10-29 12:30:44: [2024-10-29 12:30:44] iter = 03170, loss = 7.6913
2024-10-29 12:30:44: [2024-10-29 12:30:44] iter = 03180, loss = 3.8593
2024-10-29 12:30:45: [2024-10-29 12:30:45] iter = 03190, loss = 7.1662
2024-10-29 12:30:45: [2024-10-29 12:30:45] iter = 03200, loss = 2.7589
2024-10-29 12:30:46: [2024-10-29 12:30:46] iter = 03210, loss = 2.1642
2024-10-29 12:30:46: [2024-10-29 12:30:46] iter = 03220, loss = 4.9196
2024-10-29 12:30:46: [2024-10-29 12:30:46] iter = 03230, loss = 7.3234
2024-10-29 12:30:47: [2024-10-29 12:30:47] iter = 03240, loss = 10.9893
2024-10-29 12:30:47: [2024-10-29 12:30:47] iter = 03250, loss = 36.8768
2024-10-29 12:30:48: [2024-10-29 12:30:48] iter = 03260, loss = 3.3952
2024-10-29 12:30:48: [2024-10-29 12:30:48] iter = 03270, loss = 5.7074
2024-10-29 12:30:49: [2024-10-29 12:30:49] iter = 03280, loss = 37.6270
2024-10-29 12:30:50: [2024-10-29 12:30:50] iter = 03290, loss = 9.8888
2024-10-29 12:30:50: [2024-10-29 12:30:50] iter = 03300, loss = 6.3930
2024-10-29 12:30:51: [2024-10-29 12:30:51] iter = 03310, loss = 6.5620
2024-10-29 12:30:51: [2024-10-29 12:30:51] iter = 03320, loss = 8.6995
2024-10-29 12:30:52: [2024-10-29 12:30:52] iter = 03330, loss = 3.6434
2024-10-29 12:30:52: [2024-10-29 12:30:52] iter = 03340, loss = 10.9640
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 03350, loss = 5.5899
2024-10-29 12:30:53: [2024-10-29 12:30:53] iter = 03360, loss = 4.3597
2024-10-29 12:30:54: [2024-10-29 12:30:54] iter = 03370, loss = 2.9661
2024-10-29 12:30:54: [2024-10-29 12:30:54] iter = 03380, loss = 7.2713
2024-10-29 12:30:55: [2024-10-29 12:30:55] iter = 03390, loss = 29.2330
2024-10-29 12:30:55: [2024-10-29 12:30:55] iter = 03400, loss = 4.1790
2024-10-29 12:30:56: [2024-10-29 12:30:56] iter = 03410, loss = 58.7630
2024-10-29 12:30:56: [2024-10-29 12:30:56] iter = 03420, loss = 3.7145
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 03430, loss = 25.0155
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 03440, loss = 3.6586
2024-10-29 12:30:57: [2024-10-29 12:30:57] iter = 03450, loss = 6.1559
2024-10-29 12:30:58: [2024-10-29 12:30:58] iter = 03460, loss = 8.4471
2024-10-29 12:30:58: [2024-10-29 12:30:58] iter = 03470, loss = 9.3860
2024-10-29 12:30:59: [2024-10-29 12:30:59] iter = 03480, loss = 9.7751
2024-10-29 12:30:59: [2024-10-29 12:30:59] iter = 03490, loss = 28.3067
2024-10-29 12:31:00: [2024-10-29 12:31:00] iter = 03500, loss = 24.0416
2024-10-29 12:31:00: [2024-10-29 12:31:00] iter = 03510, loss = 3.3668
2024-10-29 12:31:01: [2024-10-29 12:31:01] iter = 03520, loss = 23.9281
2024-10-29 12:31:01: [2024-10-29 12:31:01] iter = 03530, loss = 5.0009
2024-10-29 12:31:02: [2024-10-29 12:31:02] iter = 03540, loss = 2.4533
2024-10-29 12:31:02: [2024-10-29 12:31:02] iter = 03550, loss = 12.7583
2024-10-29 12:31:03: [2024-10-29 12:31:03] iter = 03560, loss = 11.0195
2024-10-29 12:31:03: [2024-10-29 12:31:03] iter = 03570, loss = 7.3442
2024-10-29 12:31:04: [2024-10-29 12:31:04] iter = 03580, loss = 7.8666
2024-10-29 12:31:04: [2024-10-29 12:31:04] iter = 03590, loss = 3.1296
2024-10-29 12:31:05: [2024-10-29 12:31:05] iter = 03600, loss = 9.6670
2024-10-29 12:31:05: [2024-10-29 12:31:05] iter = 03610, loss = 3.3691
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 03620, loss = 15.3663
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 03630, loss = 2.8843
2024-10-29 12:31:06: [2024-10-29 12:31:06] iter = 03640, loss = 4.2533
2024-10-29 12:31:07: [2024-10-29 12:31:07] iter = 03650, loss = 7.3761
2024-10-29 12:31:07: [2024-10-29 12:31:07] iter = 03660, loss = 4.8841
2024-10-29 12:31:08: [2024-10-29 12:31:08] iter = 03670, loss = 4.1616
2024-10-29 12:31:08: [2024-10-29 12:31:08] iter = 03680, loss = 12.7023
2024-10-29 12:31:09: [2024-10-29 12:31:09] iter = 03690, loss = 5.3593
2024-10-29 12:31:09: [2024-10-29 12:31:09] iter = 03700, loss = 9.9404
2024-10-29 12:31:10: [2024-10-29 12:31:10] iter = 03710, loss = 14.4620
2024-10-29 12:31:10: [2024-10-29 12:31:10] iter = 03720, loss = 5.6659
2024-10-29 12:31:11: [2024-10-29 12:31:11] iter = 03730, loss = 2.7946
2024-10-29 12:31:11: [2024-10-29 12:31:11] iter = 03740, loss = 4.7200
2024-10-29 12:31:12: [2024-10-29 12:31:12] iter = 03750, loss = 11.7447
2024-10-29 12:31:12: [2024-10-29 12:31:12] iter = 03760, loss = 5.1977
2024-10-29 12:31:13: [2024-10-29 12:31:13] iter = 03770, loss = 5.3207
2024-10-29 12:31:14: [2024-10-29 12:31:14] iter = 03780, loss = 3.9932
2024-10-29 12:31:14: [2024-10-29 12:31:14] iter = 03790, loss = 14.3666
2024-10-29 12:31:15: [2024-10-29 12:31:15] iter = 03800, loss = 12.0450
2024-10-29 12:31:15: [2024-10-29 12:31:15] iter = 03810, loss = 12.9104
2024-10-29 12:31:16: [2024-10-29 12:31:16] iter = 03820, loss = 11.6326
2024-10-29 12:31:16: [2024-10-29 12:31:16] iter = 03830, loss = 12.6845
2024-10-29 12:31:17: [2024-10-29 12:31:17] iter = 03840, loss = 38.9599
2024-10-29 12:31:17: [2024-10-29 12:31:17] iter = 03850, loss = 19.3127
2024-10-29 12:31:18: [2024-10-29 12:31:18] iter = 03860, loss = 8.4394
2024-10-29 12:31:18: [2024-10-29 12:31:18] iter = 03870, loss = 10.8906
2024-10-29 12:31:18: [2024-10-29 12:31:18] iter = 03880, loss = 4.6852
2024-10-29 12:31:19: [2024-10-29 12:31:19] iter = 03890, loss = 9.6304
2024-10-29 12:31:19: [2024-10-29 12:31:19] iter = 03900, loss = 14.3512
2024-10-29 12:31:20: [2024-10-29 12:31:20] iter = 03910, loss = 6.3300
2024-10-29 12:31:21: [2024-10-29 12:31:21] iter = 03920, loss = 4.6508
2024-10-29 12:31:21: [2024-10-29 12:31:21] iter = 03930, loss = 4.4812
2024-10-29 12:31:22: [2024-10-29 12:31:22] iter = 03940, loss = 2.8600
2024-10-29 12:31:23: [2024-10-29 12:31:23] iter = 03950, loss = 8.5709
2024-10-29 12:31:23: [2024-10-29 12:31:23] iter = 03960, loss = 3.3410
2024-10-29 12:31:24: [2024-10-29 12:31:24] iter = 03970, loss = 3.1955
2024-10-29 12:31:24: [2024-10-29 12:31:24] iter = 03980, loss = 5.3707
2024-10-29 12:31:25: [2024-10-29 12:31:25] iter = 03990, loss = 5.1386
2024-10-29 12:31:25: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 12:31:25: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:31:25: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 85966}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:51: Evaluate 5 random ConvNet, ACCmean = 0.5138 ACCstd = 0.0088
-------------------------
2024-10-29 12:31:51: Evaluate 5 random ConvNet, SENmean = 0.5138 SENstd = 0.0088
-------------------------
2024-10-29 12:31:51: Evaluate 5 random ConvNet, SPEmean = 0.8379 SPEstd = 0.0029
-------------------------
2024-10-29 12:31:51: Evaluate 5 random ConvNet, F!mean = 0.4602 F!std = 0.0061
-------------------------
2024-10-29 12:31:51: Evaluate 5 random ConvNet, mean = 0.5138 std = 0.0088
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:51: [2024-10-29 12:31:51] iter = 04000, loss = 9.6213
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:31:51: [2024-10-29 12:31:51] iter = 04010, loss = 3.9126
2024-10-29 12:31:52: [2024-10-29 12:31:52] iter = 04020, loss = 13.1514
2024-10-29 12:31:52: [2024-10-29 12:31:52] iter = 04030, loss = 5.8030
2024-10-29 12:31:53: [2024-10-29 12:31:53] iter = 04040, loss = 2.6835
2024-10-29 12:31:53: [2024-10-29 12:31:53] iter = 04050, loss = 5.9140
2024-10-29 12:31:54: [2024-10-29 12:31:54] iter = 04060, loss = 2.7669
2024-10-29 12:31:54: [2024-10-29 12:31:54] iter = 04070, loss = 3.9995
2024-10-29 12:31:54: [2024-10-29 12:31:54] iter = 04080, loss = 3.0471
2024-10-29 12:31:55: [2024-10-29 12:31:55] iter = 04090, loss = 2.2815
2024-10-29 12:31:56: [2024-10-29 12:31:56] iter = 04100, loss = 3.7603
2024-10-29 12:31:56: [2024-10-29 12:31:56] iter = 04110, loss = 4.0772
2024-10-29 12:31:57: [2024-10-29 12:31:57] iter = 04120, loss = 3.3886
2024-10-29 12:31:57: [2024-10-29 12:31:57] iter = 04130, loss = 8.4450
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 04140, loss = 3.3163
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 04150, loss = 4.8054
2024-10-29 12:31:58: [2024-10-29 12:31:58] iter = 04160, loss = 10.4240
2024-10-29 12:31:59: [2024-10-29 12:31:59] iter = 04170, loss = 3.1148
2024-10-29 12:31:59: [2024-10-29 12:31:59] iter = 04180, loss = 6.4507
2024-10-29 12:32:00: [2024-10-29 12:32:00] iter = 04190, loss = 4.0639
2024-10-29 12:32:00: [2024-10-29 12:32:00] iter = 04200, loss = 4.0346
2024-10-29 12:32:01: [2024-10-29 12:32:01] iter = 04210, loss = 4.9338
2024-10-29 12:32:01: [2024-10-29 12:32:01] iter = 04220, loss = 5.6832
2024-10-29 12:32:02: [2024-10-29 12:32:02] iter = 04230, loss = 26.5272
2024-10-29 12:32:02: [2024-10-29 12:32:02] iter = 04240, loss = 3.5715
2024-10-29 12:32:03: [2024-10-29 12:32:03] iter = 04250, loss = 9.5187
2024-10-29 12:32:03: [2024-10-29 12:32:03] iter = 04260, loss = 17.6774
2024-10-29 12:32:04: [2024-10-29 12:32:04] iter = 04270, loss = 26.9633
2024-10-29 12:32:04: [2024-10-29 12:32:04] iter = 04280, loss = 9.5583
2024-10-29 12:32:05: [2024-10-29 12:32:05] iter = 04290, loss = 9.2801
2024-10-29 12:32:05: [2024-10-29 12:32:05] iter = 04300, loss = 3.5206
2024-10-29 12:32:06: [2024-10-29 12:32:06] iter = 04310, loss = 17.8079
2024-10-29 12:32:07: [2024-10-29 12:32:06] iter = 04320, loss = 5.2963
2024-10-29 12:32:07: [2024-10-29 12:32:07] iter = 04330, loss = 3.1095
2024-10-29 12:32:08: [2024-10-29 12:32:08] iter = 04340, loss = 6.6575
2024-10-29 12:32:08: [2024-10-29 12:32:08] iter = 04350, loss = 3.7253
2024-10-29 12:32:09: [2024-10-29 12:32:09] iter = 04360, loss = 4.9729
2024-10-29 12:32:09: [2024-10-29 12:32:09] iter = 04370, loss = 5.9693
2024-10-29 12:32:10: [2024-10-29 12:32:10] iter = 04380, loss = 7.4787
2024-10-29 12:32:10: [2024-10-29 12:32:10] iter = 04390, loss = 5.0656
2024-10-29 12:32:11: [2024-10-29 12:32:11] iter = 04400, loss = 6.2686
2024-10-29 12:32:11: [2024-10-29 12:32:11] iter = 04410, loss = 10.5494
2024-10-29 12:32:12: [2024-10-29 12:32:12] iter = 04420, loss = 4.4544
2024-10-29 12:32:12: [2024-10-29 12:32:12] iter = 04430, loss = 3.7350
2024-10-29 12:32:13: [2024-10-29 12:32:13] iter = 04440, loss = 9.1986
2024-10-29 12:32:13: [2024-10-29 12:32:13] iter = 04450, loss = 13.8430
2024-10-29 12:32:14: [2024-10-29 12:32:14] iter = 04460, loss = 11.9899
2024-10-29 12:32:14: [2024-10-29 12:32:14] iter = 04470, loss = 3.4016
2024-10-29 12:32:15: [2024-10-29 12:32:15] iter = 04480, loss = 5.4108
2024-10-29 12:32:15: [2024-10-29 12:32:15] iter = 04490, loss = 47.2119
2024-10-29 12:32:16: [2024-10-29 12:32:16] iter = 04500, loss = 3.6975
2024-10-29 12:32:16: [2024-10-29 12:32:16] iter = 04510, loss = 3.3439
2024-10-29 12:32:17: [2024-10-29 12:32:17] iter = 04520, loss = 2.9318
2024-10-29 12:32:17: [2024-10-29 12:32:17] iter = 04530, loss = 8.0385
2024-10-29 12:32:18: [2024-10-29 12:32:18] iter = 04540, loss = 4.2309
2024-10-29 12:32:18: [2024-10-29 12:32:18] iter = 04550, loss = 2.6620
2024-10-29 12:32:19: [2024-10-29 12:32:19] iter = 04560, loss = 6.0468
2024-10-29 12:32:19: [2024-10-29 12:32:19] iter = 04570, loss = 6.4788
2024-10-29 12:32:20: [2024-10-29 12:32:20] iter = 04580, loss = 15.7134
2024-10-29 12:32:20: [2024-10-29 12:32:20] iter = 04590, loss = 7.5569
2024-10-29 12:32:20: [2024-10-29 12:32:20] iter = 04600, loss = 18.8321
2024-10-29 12:32:21: [2024-10-29 12:32:21] iter = 04610, loss = 34.4410
2024-10-29 12:32:21: [2024-10-29 12:32:21] iter = 04620, loss = 8.3496
2024-10-29 12:32:22: [2024-10-29 12:32:22] iter = 04630, loss = 7.4090
2024-10-29 12:32:22: [2024-10-29 12:32:22] iter = 04640, loss = 44.9769
2024-10-29 12:32:23: [2024-10-29 12:32:23] iter = 04650, loss = 2.8643
2024-10-29 12:32:23: [2024-10-29 12:32:23] iter = 04660, loss = 6.1093
2024-10-29 12:32:24: [2024-10-29 12:32:24] iter = 04670, loss = 5.6124
2024-10-29 12:32:24: [2024-10-29 12:32:24] iter = 04680, loss = 3.1249
2024-10-29 12:32:25: [2024-10-29 12:32:25] iter = 04690, loss = 10.2551
2024-10-29 12:32:25: [2024-10-29 12:32:25] iter = 04700, loss = 4.7639
2024-10-29 12:32:26: [2024-10-29 12:32:26] iter = 04710, loss = 3.1094
2024-10-29 12:32:26: [2024-10-29 12:32:26] iter = 04720, loss = 48.5679
2024-10-29 12:32:27: [2024-10-29 12:32:27] iter = 04730, loss = 4.0539
2024-10-29 12:32:27: [2024-10-29 12:32:27] iter = 04740, loss = 5.5263
2024-10-29 12:32:28: [2024-10-29 12:32:28] iter = 04750, loss = 5.3309
2024-10-29 12:32:28: [2024-10-29 12:32:28] iter = 04760, loss = 13.8067
2024-10-29 12:32:29: [2024-10-29 12:32:29] iter = 04770, loss = 3.5841
2024-10-29 12:32:30: [2024-10-29 12:32:30] iter = 04780, loss = 9.9319
2024-10-29 12:32:31: [2024-10-29 12:32:31] iter = 04790, loss = 3.3596
2024-10-29 12:32:31: [2024-10-29 12:32:31] iter = 04800, loss = 7.0854
2024-10-29 12:32:32: [2024-10-29 12:32:32] iter = 04810, loss = 5.5753
2024-10-29 12:32:32: [2024-10-29 12:32:32] iter = 04820, loss = 6.2306
2024-10-29 12:32:33: [2024-10-29 12:32:33] iter = 04830, loss = 12.1760
2024-10-29 12:32:34: [2024-10-29 12:32:34] iter = 04840, loss = 2.6448
2024-10-29 12:32:34: [2024-10-29 12:32:34] iter = 04850, loss = 3.2553
2024-10-29 12:32:35: [2024-10-29 12:32:35] iter = 04860, loss = 19.3668
2024-10-29 12:32:35: [2024-10-29 12:32:35] iter = 04870, loss = 2.5381
2024-10-29 12:32:36: [2024-10-29 12:32:36] iter = 04880, loss = 12.6292
2024-10-29 12:32:37: [2024-10-29 12:32:37] iter = 04890, loss = 6.4811
2024-10-29 12:32:37: [2024-10-29 12:32:37] iter = 04900, loss = 25.1722
2024-10-29 12:32:38: [2024-10-29 12:32:38] iter = 04910, loss = 6.9306
2024-10-29 12:32:38: [2024-10-29 12:32:38] iter = 04920, loss = 10.4867
2024-10-29 12:32:39: [2024-10-29 12:32:39] iter = 04930, loss = 4.0320
2024-10-29 12:32:39: [2024-10-29 12:32:39] iter = 04940, loss = 5.0609
2024-10-29 12:32:40: [2024-10-29 12:32:40] iter = 04950, loss = 3.0332
2024-10-29 12:32:40: [2024-10-29 12:32:40] iter = 04960, loss = 11.7056
2024-10-29 12:32:40: [2024-10-29 12:32:40] iter = 04970, loss = 30.0978
2024-10-29 12:32:41: [2024-10-29 12:32:41] iter = 04980, loss = 9.8046
2024-10-29 12:32:41: [2024-10-29 12:32:41] iter = 04990, loss = 2.8917
2024-10-29 12:32:42: [2024-10-29 12:32:42] iter = 05000, loss = 6.9447
2024-10-29 12:32:42: [2024-10-29 12:32:42] iter = 05010, loss = 13.2284
2024-10-29 12:32:43: [2024-10-29 12:32:43] iter = 05020, loss = 35.8808
2024-10-29 12:32:43: [2024-10-29 12:32:43] iter = 05030, loss = 2.2097
2024-10-29 12:32:44: [2024-10-29 12:32:44] iter = 05040, loss = 17.8595
2024-10-29 12:32:44: [2024-10-29 12:32:44] iter = 05050, loss = 15.6034
2024-10-29 12:32:45: [2024-10-29 12:32:45] iter = 05060, loss = 7.2641
2024-10-29 12:32:45: [2024-10-29 12:32:45] iter = 05070, loss = 6.4254
2024-10-29 12:32:46: [2024-10-29 12:32:46] iter = 05080, loss = 2.7732
2024-10-29 12:32:46: [2024-10-29 12:32:46] iter = 05090, loss = 5.2340
2024-10-29 12:32:47: [2024-10-29 12:32:47] iter = 05100, loss = 35.3253
2024-10-29 12:32:47: [2024-10-29 12:32:47] iter = 05110, loss = 13.2976
2024-10-29 12:32:48: [2024-10-29 12:32:48] iter = 05120, loss = 9.6694
2024-10-29 12:32:48: [2024-10-29 12:32:48] iter = 05130, loss = 9.0474
2024-10-29 12:32:49: [2024-10-29 12:32:49] iter = 05140, loss = 19.9755
2024-10-29 12:32:49: [2024-10-29 12:32:49] iter = 05150, loss = 40.7724
2024-10-29 12:32:50: [2024-10-29 12:32:50] iter = 05160, loss = 7.9607
2024-10-29 12:32:51: [2024-10-29 12:32:51] iter = 05170, loss = 6.7592
2024-10-29 12:32:51: [2024-10-29 12:32:51] iter = 05180, loss = 6.7996
2024-10-29 12:32:52: [2024-10-29 12:32:52] iter = 05190, loss = 12.9063
2024-10-29 12:32:52: [2024-10-29 12:32:52] iter = 05200, loss = 9.3588
2024-10-29 12:32:53: [2024-10-29 12:32:53] iter = 05210, loss = 11.8090
2024-10-29 12:32:53: [2024-10-29 12:32:53] iter = 05220, loss = 3.2619
2024-10-29 12:32:54: [2024-10-29 12:32:54] iter = 05230, loss = 5.3009
2024-10-29 12:32:54: [2024-10-29 12:32:54] iter = 05240, loss = 2.8889
2024-10-29 12:32:55: [2024-10-29 12:32:55] iter = 05250, loss = 17.6997
2024-10-29 12:32:55: [2024-10-29 12:32:55] iter = 05260, loss = 3.2838
2024-10-29 12:32:56: [2024-10-29 12:32:56] iter = 05270, loss = 5.3253
2024-10-29 12:32:56: [2024-10-29 12:32:56] iter = 05280, loss = 6.7092
2024-10-29 12:32:57: [2024-10-29 12:32:57] iter = 05290, loss = 6.8163
2024-10-29 12:32:57: [2024-10-29 12:32:57] iter = 05300, loss = 3.5395
2024-10-29 12:32:58: [2024-10-29 12:32:58] iter = 05310, loss = 47.7664
2024-10-29 12:32:58: [2024-10-29 12:32:58] iter = 05320, loss = 4.7093
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 05330, loss = 3.4092
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 05340, loss = 5.1990
2024-10-29 12:32:59: [2024-10-29 12:32:59] iter = 05350, loss = 14.6438
2024-10-29 12:33:00: [2024-10-29 12:33:00] iter = 05360, loss = 2.9860
2024-10-29 12:33:00: [2024-10-29 12:33:00] iter = 05370, loss = 9.4177
2024-10-29 12:33:01: [2024-10-29 12:33:01] iter = 05380, loss = 4.8771
2024-10-29 12:33:01: [2024-10-29 12:33:01] iter = 05390, loss = 35.9539
2024-10-29 12:33:02: [2024-10-29 12:33:02] iter = 05400, loss = 3.4400
2024-10-29 12:33:02: [2024-10-29 12:33:02] iter = 05410, loss = 13.9000
2024-10-29 12:33:03: [2024-10-29 12:33:03] iter = 05420, loss = 2.6798
2024-10-29 12:33:03: [2024-10-29 12:33:03] iter = 05430, loss = 3.8186
2024-10-29 12:33:04: [2024-10-29 12:33:04] iter = 05440, loss = 6.0455
2024-10-29 12:33:04: [2024-10-29 12:33:04] iter = 05450, loss = 4.0212
2024-10-29 12:33:05: [2024-10-29 12:33:05] iter = 05460, loss = 5.9857
2024-10-29 12:33:05: [2024-10-29 12:33:05] iter = 05470, loss = 36.8486
2024-10-29 12:33:06: [2024-10-29 12:33:06] iter = 05480, loss = 15.4615
2024-10-29 12:33:06: [2024-10-29 12:33:06] iter = 05490, loss = 4.7262
2024-10-29 12:33:07: [2024-10-29 12:33:07] iter = 05500, loss = 34.7939
2024-10-29 12:33:07: [2024-10-29 12:33:07] iter = 05510, loss = 9.6145
2024-10-29 12:33:08: [2024-10-29 12:33:08] iter = 05520, loss = 4.2102
2024-10-29 12:33:08: [2024-10-29 12:33:08] iter = 05530, loss = 3.0951
2024-10-29 12:33:09: [2024-10-29 12:33:09] iter = 05540, loss = 5.1694
2024-10-29 12:33:09: [2024-10-29 12:33:09] iter = 05550, loss = 3.0842
2024-10-29 12:33:10: [2024-10-29 12:33:10] iter = 05560, loss = 4.4940
2024-10-29 12:33:10: [2024-10-29 12:33:10] iter = 05570, loss = 4.4259
2024-10-29 12:33:11: [2024-10-29 12:33:11] iter = 05580, loss = 3.9172
2024-10-29 12:33:11: [2024-10-29 12:33:11] iter = 05590, loss = 3.5269
2024-10-29 12:33:12: [2024-10-29 12:33:12] iter = 05600, loss = 9.5517
2024-10-29 12:33:12: [2024-10-29 12:33:12] iter = 05610, loss = 3.7138
2024-10-29 12:33:13: [2024-10-29 12:33:13] iter = 05620, loss = 2.0672
2024-10-29 12:33:13: [2024-10-29 12:33:13] iter = 05630, loss = 17.5248
2024-10-29 12:33:14: [2024-10-29 12:33:14] iter = 05640, loss = 3.4369
2024-10-29 12:33:15: [2024-10-29 12:33:14] iter = 05650, loss = 2.2145
2024-10-29 12:33:15: [2024-10-29 12:33:15] iter = 05660, loss = 10.1024
2024-10-29 12:33:16: [2024-10-29 12:33:16] iter = 05670, loss = 5.6440
2024-10-29 12:33:16: [2024-10-29 12:33:16] iter = 05680, loss = 4.6601
2024-10-29 12:33:17: [2024-10-29 12:33:17] iter = 05690, loss = 2.4895
2024-10-29 12:33:18: [2024-10-29 12:33:18] iter = 05700, loss = 3.5759
2024-10-29 12:33:18: [2024-10-29 12:33:18] iter = 05710, loss = 3.8690
2024-10-29 12:33:19: [2024-10-29 12:33:19] iter = 05720, loss = 3.8758
2024-10-29 12:33:19: [2024-10-29 12:33:19] iter = 05730, loss = 6.1157
2024-10-29 12:33:20: [2024-10-29 12:33:20] iter = 05740, loss = 16.5658
2024-10-29 12:33:20: [2024-10-29 12:33:20] iter = 05750, loss = 2.6083
2024-10-29 12:33:21: [2024-10-29 12:33:21] iter = 05760, loss = 4.3386
2024-10-29 12:33:22: [2024-10-29 12:33:22] iter = 05770, loss = 3.4914
2024-10-29 12:33:22: [2024-10-29 12:33:22] iter = 05780, loss = 3.2006
2024-10-29 12:33:23: [2024-10-29 12:33:23] iter = 05790, loss = 32.3297
2024-10-29 12:33:23: [2024-10-29 12:33:23] iter = 05800, loss = 2.9194
2024-10-29 12:33:24: [2024-10-29 12:33:24] iter = 05810, loss = 4.2618
2024-10-29 12:33:24: [2024-10-29 12:33:24] iter = 05820, loss = 4.6337
2024-10-29 12:33:25: [2024-10-29 12:33:25] iter = 05830, loss = 10.1369
2024-10-29 12:33:26: [2024-10-29 12:33:26] iter = 05840, loss = 2.9018
2024-10-29 12:33:26: [2024-10-29 12:33:26] iter = 05850, loss = 7.2065
2024-10-29 12:33:26: [2024-10-29 12:33:26] iter = 05860, loss = 5.4800
2024-10-29 12:33:27: [2024-10-29 12:33:27] iter = 05870, loss = 12.7525
2024-10-29 12:33:28: [2024-10-29 12:33:28] iter = 05880, loss = 7.5609
2024-10-29 12:33:28: [2024-10-29 12:33:28] iter = 05890, loss = 6.1779
2024-10-29 12:33:29: [2024-10-29 12:33:29] iter = 05900, loss = 3.6467
2024-10-29 12:33:29: [2024-10-29 12:33:29] iter = 05910, loss = 6.7783
2024-10-29 12:33:30: [2024-10-29 12:33:30] iter = 05920, loss = 11.5894
2024-10-29 12:33:30: [2024-10-29 12:33:30] iter = 05930, loss = 4.3049
2024-10-29 12:33:31: [2024-10-29 12:33:31] iter = 05940, loss = 6.2413
2024-10-29 12:33:31: [2024-10-29 12:33:31] iter = 05950, loss = 3.6274
2024-10-29 12:33:31: [2024-10-29 12:33:31] iter = 05960, loss = 3.3369
2024-10-29 12:33:32: [2024-10-29 12:33:32] iter = 05970, loss = 4.7805
2024-10-29 12:33:32: [2024-10-29 12:33:32] iter = 05980, loss = 5.8494
2024-10-29 12:33:33: [2024-10-29 12:33:33] iter = 05990, loss = 2.6715
2024-10-29 12:33:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 12:33:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:33:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 13968}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:34:00: Evaluate 5 random ConvNet, ACCmean = 0.5758 ACCstd = 0.0108
-------------------------
2024-10-29 12:34:00: Evaluate 5 random ConvNet, SENmean = 0.5758 SENstd = 0.0108
-------------------------
2024-10-29 12:34:00: Evaluate 5 random ConvNet, SPEmean = 0.8586 SPEstd = 0.0036
-------------------------
2024-10-29 12:34:00: Evaluate 5 random ConvNet, F!mean = 0.5731 F!std = 0.0126
-------------------------
2024-10-29 12:34:00: Evaluate 5 random ConvNet, mean = 0.5758 std = 0.0108
-------------------------
2024-10-29 12:34:00: [2024-10-29 12:34:00] iter = 06000, loss = 2.9502
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:34:01: [2024-10-29 12:34:01] iter = 06010, loss = 10.2205
2024-10-29 12:34:01: [2024-10-29 12:34:01] iter = 06020, loss = 9.4921
2024-10-29 12:34:02: [2024-10-29 12:34:02] iter = 06030, loss = 6.2357
2024-10-29 12:34:02: [2024-10-29 12:34:02] iter = 06040, loss = 13.6061
2024-10-29 12:34:03: [2024-10-29 12:34:03] iter = 06050, loss = 2.3181
2024-10-29 12:34:03: [2024-10-29 12:34:03] iter = 06060, loss = 2.6243
2024-10-29 12:34:04: [2024-10-29 12:34:04] iter = 06070, loss = 4.1558
2024-10-29 12:34:04: [2024-10-29 12:34:04] iter = 06080, loss = 2.8613
2024-10-29 12:34:05: [2024-10-29 12:34:05] iter = 06090, loss = 5.8896
2024-10-29 12:34:05: [2024-10-29 12:34:05] iter = 06100, loss = 2.8449
2024-10-29 12:34:06: [2024-10-29 12:34:06] iter = 06110, loss = 4.5301
2024-10-29 12:34:06: [2024-10-29 12:34:06] iter = 06120, loss = 3.7335
2024-10-29 12:34:07: [2024-10-29 12:34:07] iter = 06130, loss = 2.7685
2024-10-29 12:34:07: [2024-10-29 12:34:07] iter = 06140, loss = 2.4370
2024-10-29 12:34:08: [2024-10-29 12:34:08] iter = 06150, loss = 3.1716
2024-10-29 12:34:08: [2024-10-29 12:34:08] iter = 06160, loss = 6.9581
2024-10-29 12:34:09: [2024-10-29 12:34:09] iter = 06170, loss = 8.8794
2024-10-29 12:34:09: [2024-10-29 12:34:09] iter = 06180, loss = 3.8050
2024-10-29 12:34:10: [2024-10-29 12:34:10] iter = 06190, loss = 4.4706
2024-10-29 12:34:10: [2024-10-29 12:34:10] iter = 06200, loss = 3.2069
2024-10-29 12:34:11: [2024-10-29 12:34:11] iter = 06210, loss = 8.2723
2024-10-29 12:34:11: [2024-10-29 12:34:11] iter = 06220, loss = 5.5872
2024-10-29 12:34:12: [2024-10-29 12:34:12] iter = 06230, loss = 2.9722
2024-10-29 12:34:12: [2024-10-29 12:34:12] iter = 06240, loss = 7.4133
2024-10-29 12:34:13: [2024-10-29 12:34:13] iter = 06250, loss = 4.8409
2024-10-29 12:34:13: [2024-10-29 12:34:13] iter = 06260, loss = 3.9928
2024-10-29 12:34:14: [2024-10-29 12:34:14] iter = 06270, loss = 9.0144
2024-10-29 12:34:14: [2024-10-29 12:34:14] iter = 06280, loss = 2.8802
2024-10-29 12:34:15: [2024-10-29 12:34:15] iter = 06290, loss = 3.7441
2024-10-29 12:34:15: [2024-10-29 12:34:15] iter = 06300, loss = 2.9559
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 06310, loss = 5.7543
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 06320, loss = 2.9582
2024-10-29 12:34:16: [2024-10-29 12:34:16] iter = 06330, loss = 9.4414
2024-10-29 12:34:17: [2024-10-29 12:34:17] iter = 06340, loss = 22.3824
2024-10-29 12:34:17: [2024-10-29 12:34:17] iter = 06350, loss = 53.2940
2024-10-29 12:34:18: [2024-10-29 12:34:18] iter = 06360, loss = 6.1267
2024-10-29 12:34:18: [2024-10-29 12:34:18] iter = 06370, loss = 7.4614
2024-10-29 12:34:19: [2024-10-29 12:34:19] iter = 06380, loss = 12.5801
2024-10-29 12:34:19: [2024-10-29 12:34:19] iter = 06390, loss = 54.5421
2024-10-29 12:34:20: [2024-10-29 12:34:20] iter = 06400, loss = 8.5574
2024-10-29 12:34:20: [2024-10-29 12:34:20] iter = 06410, loss = 4.9775
2024-10-29 12:34:21: [2024-10-29 12:34:21] iter = 06420, loss = 31.7716
2024-10-29 12:34:21: [2024-10-29 12:34:21] iter = 06430, loss = 6.2739
2024-10-29 12:34:22: [2024-10-29 12:34:22] iter = 06440, loss = 2.9471
2024-10-29 12:34:22: [2024-10-29 12:34:22] iter = 06450, loss = 4.8584
2024-10-29 12:34:23: [2024-10-29 12:34:23] iter = 06460, loss = 3.1599
2024-10-29 12:34:23: [2024-10-29 12:34:23] iter = 06470, loss = 3.5133
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 06480, loss = 8.8440
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 06490, loss = 9.7853
2024-10-29 12:34:24: [2024-10-29 12:34:24] iter = 06500, loss = 5.5946
2024-10-29 12:34:25: [2024-10-29 12:34:25] iter = 06510, loss = 9.6736
2024-10-29 12:34:25: [2024-10-29 12:34:25] iter = 06520, loss = 9.9045
2024-10-29 12:34:26: [2024-10-29 12:34:26] iter = 06530, loss = 4.0166
2024-10-29 12:34:26: [2024-10-29 12:34:26] iter = 06540, loss = 10.1313
2024-10-29 12:34:27: [2024-10-29 12:34:27] iter = 06550, loss = 2.2028
2024-10-29 12:34:27: [2024-10-29 12:34:27] iter = 06560, loss = 2.2341
2024-10-29 12:34:28: [2024-10-29 12:34:28] iter = 06570, loss = 5.9734
2024-10-29 12:34:28: [2024-10-29 12:34:28] iter = 06580, loss = 44.5476
2024-10-29 12:34:29: [2024-10-29 12:34:29] iter = 06590, loss = 6.2778
2024-10-29 12:34:29: [2024-10-29 12:34:29] iter = 06600, loss = 13.4500
2024-10-29 12:34:30: [2024-10-29 12:34:30] iter = 06610, loss = 10.6206
2024-10-29 12:34:30: [2024-10-29 12:34:30] iter = 06620, loss = 7.3470
2024-10-29 12:34:31: [2024-10-29 12:34:31] iter = 06630, loss = 4.9645
2024-10-29 12:34:31: [2024-10-29 12:34:31] iter = 06640, loss = 8.6529
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 06650, loss = 7.3378
2024-10-29 12:34:32: [2024-10-29 12:34:32] iter = 06660, loss = 7.2097
2024-10-29 12:34:33: [2024-10-29 12:34:33] iter = 06670, loss = 4.5350
2024-10-29 12:34:33: [2024-10-29 12:34:33] iter = 06680, loss = 9.4733
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 06690, loss = 4.1382
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 06700, loss = 4.9857
2024-10-29 12:34:34: [2024-10-29 12:34:34] iter = 06710, loss = 21.9477
2024-10-29 12:34:35: [2024-10-29 12:34:35] iter = 06720, loss = 3.1645
2024-10-29 12:34:35: [2024-10-29 12:34:35] iter = 06730, loss = 3.3451
2024-10-29 12:34:36: [2024-10-29 12:34:36] iter = 06740, loss = 4.3402
2024-10-29 12:34:36: [2024-10-29 12:34:36] iter = 06750, loss = 2.3751
2024-10-29 12:34:37: [2024-10-29 12:34:37] iter = 06760, loss = 15.3019
2024-10-29 12:34:37: [2024-10-29 12:34:37] iter = 06770, loss = 13.5767
2024-10-29 12:34:38: [2024-10-29 12:34:38] iter = 06780, loss = 7.7914
2024-10-29 12:34:38: [2024-10-29 12:34:38] iter = 06790, loss = 3.2198
2024-10-29 12:34:39: [2024-10-29 12:34:39] iter = 06800, loss = 17.5387
2024-10-29 12:34:39: [2024-10-29 12:34:39] iter = 06810, loss = 15.9410
2024-10-29 12:34:40: [2024-10-29 12:34:40] iter = 06820, loss = 23.8025
2024-10-29 12:34:40: [2024-10-29 12:34:40] iter = 06830, loss = 7.2238
2024-10-29 12:34:41: [2024-10-29 12:34:41] iter = 06840, loss = 9.2931
2024-10-29 12:34:41: [2024-10-29 12:34:41] iter = 06850, loss = 7.4175
2024-10-29 12:34:42: [2024-10-29 12:34:42] iter = 06860, loss = 3.0297
2024-10-29 12:34:42: [2024-10-29 12:34:42] iter = 06870, loss = 3.3475
2024-10-29 12:34:43: [2024-10-29 12:34:43] iter = 06880, loss = 4.8023
2024-10-29 12:34:43: [2024-10-29 12:34:43] iter = 06890, loss = 8.3573
2024-10-29 12:34:44: [2024-10-29 12:34:43] iter = 06900, loss = 2.4760
2024-10-29 12:34:44: [2024-10-29 12:34:44] iter = 06910, loss = 15.0617
2024-10-29 12:34:45: [2024-10-29 12:34:45] iter = 06920, loss = 16.2471
2024-10-29 12:34:46: [2024-10-29 12:34:46] iter = 06930, loss = 7.2537
2024-10-29 12:34:46: [2024-10-29 12:34:46] iter = 06940, loss = 8.7666
2024-10-29 12:34:47: [2024-10-29 12:34:47] iter = 06950, loss = 4.4886
2024-10-29 12:34:47: [2024-10-29 12:34:47] iter = 06960, loss = 24.3612
2024-10-29 12:34:48: [2024-10-29 12:34:48] iter = 06970, loss = 23.3842
2024-10-29 12:34:48: [2024-10-29 12:34:48] iter = 06980, loss = 60.2655
2024-10-29 12:34:49: [2024-10-29 12:34:49] iter = 06990, loss = 4.9601
2024-10-29 12:34:50: [2024-10-29 12:34:50] iter = 07000, loss = 4.3126
2024-10-29 12:34:50: [2024-10-29 12:34:50] iter = 07010, loss = 3.7527
2024-10-29 12:34:51: [2024-10-29 12:34:51] iter = 07020, loss = 2.8258
2024-10-29 12:34:51: [2024-10-29 12:34:51] iter = 07030, loss = 13.5878
2024-10-29 12:34:52: [2024-10-29 12:34:52] iter = 07040, loss = 19.3878
2024-10-29 12:34:52: [2024-10-29 12:34:52] iter = 07050, loss = 3.2209
2024-10-29 12:34:52: [2024-10-29 12:34:52] iter = 07060, loss = 42.6702
2024-10-29 12:34:53: [2024-10-29 12:34:53] iter = 07070, loss = 42.6077
2024-10-29 12:34:53: [2024-10-29 12:34:53] iter = 07080, loss = 4.2247
2024-10-29 12:34:54: [2024-10-29 12:34:54] iter = 07090, loss = 3.5323
2024-10-29 12:34:54: [2024-10-29 12:34:54] iter = 07100, loss = 30.1097
2024-10-29 12:34:55: [2024-10-29 12:34:55] iter = 07110, loss = 11.0988
2024-10-29 12:34:55: [2024-10-29 12:34:55] iter = 07120, loss = 4.0625
2024-10-29 12:34:56: [2024-10-29 12:34:56] iter = 07130, loss = 9.3645
2024-10-29 12:34:56: [2024-10-29 12:34:56] iter = 07140, loss = 24.4754
2024-10-29 12:34:57: [2024-10-29 12:34:57] iter = 07150, loss = 4.3190
2024-10-29 12:34:57: [2024-10-29 12:34:57] iter = 07160, loss = 2.9422
2024-10-29 12:34:58: [2024-10-29 12:34:58] iter = 07170, loss = 7.4634
2024-10-29 12:34:59: [2024-10-29 12:34:59] iter = 07180, loss = 7.5428
2024-10-29 12:34:59: [2024-10-29 12:34:59] iter = 07190, loss = 8.5284
2024-10-29 12:35:00: [2024-10-29 12:35:00] iter = 07200, loss = 7.8243
2024-10-29 12:35:01: [2024-10-29 12:35:01] iter = 07210, loss = 5.3285
2024-10-29 12:35:01: [2024-10-29 12:35:01] iter = 07220, loss = 33.9622
2024-10-29 12:35:02: [2024-10-29 12:35:02] iter = 07230, loss = 6.6902
2024-10-29 12:35:03: [2024-10-29 12:35:03] iter = 07240, loss = 3.7475
2024-10-29 12:35:03: [2024-10-29 12:35:03] iter = 07250, loss = 9.8981
2024-10-29 12:35:04: [2024-10-29 12:35:04] iter = 07260, loss = 3.0109
2024-10-29 12:35:04: [2024-10-29 12:35:04] iter = 07270, loss = 8.3005
2024-10-29 12:35:05: [2024-10-29 12:35:05] iter = 07280, loss = 7.7119
2024-10-29 12:35:06: [2024-10-29 12:35:06] iter = 07290, loss = 37.8826
2024-10-29 12:35:06: [2024-10-29 12:35:06] iter = 07300, loss = 21.2876
2024-10-29 12:35:07: [2024-10-29 12:35:07] iter = 07310, loss = 4.5191
2024-10-29 12:35:07: [2024-10-29 12:35:07] iter = 07320, loss = 8.8585
2024-10-29 12:35:08: [2024-10-29 12:35:08] iter = 07330, loss = 19.1543
2024-10-29 12:35:08: [2024-10-29 12:35:08] iter = 07340, loss = 7.9225
2024-10-29 12:35:09: [2024-10-29 12:35:09] iter = 07350, loss = 3.7841
2024-10-29 12:35:09: [2024-10-29 12:35:09] iter = 07360, loss = 6.7308
2024-10-29 12:35:10: [2024-10-29 12:35:10] iter = 07370, loss = 3.8597
2024-10-29 12:35:10: [2024-10-29 12:35:10] iter = 07380, loss = 31.6060
2024-10-29 12:35:11: [2024-10-29 12:35:11] iter = 07390, loss = 4.8274
2024-10-29 12:35:11: [2024-10-29 12:35:11] iter = 07400, loss = 11.1474
2024-10-29 12:35:11: [2024-10-29 12:35:11] iter = 07410, loss = 10.3514
2024-10-29 12:35:12: [2024-10-29 12:35:12] iter = 07420, loss = 13.4553
2024-10-29 12:35:12: [2024-10-29 12:35:12] iter = 07430, loss = 5.4040
2024-10-29 12:35:13: [2024-10-29 12:35:13] iter = 07440, loss = 7.7959
2024-10-29 12:35:13: [2024-10-29 12:35:13] iter = 07450, loss = 5.7660
2024-10-29 12:35:14: [2024-10-29 12:35:14] iter = 07460, loss = 6.7370
2024-10-29 12:35:15: [2024-10-29 12:35:15] iter = 07470, loss = 3.4643
2024-10-29 12:35:15: [2024-10-29 12:35:15] iter = 07480, loss = 2.8120
2024-10-29 12:35:16: [2024-10-29 12:35:16] iter = 07490, loss = 33.4521
2024-10-29 12:35:16: [2024-10-29 12:35:16] iter = 07500, loss = 23.6259
2024-10-29 12:35:17: [2024-10-29 12:35:17] iter = 07510, loss = 5.1132
2024-10-29 12:35:17: [2024-10-29 12:35:17] iter = 07520, loss = 5.0842
2024-10-29 12:35:17: [2024-10-29 12:35:17] iter = 07530, loss = 8.7707
2024-10-29 12:35:18: [2024-10-29 12:35:18] iter = 07540, loss = 13.9795
2024-10-29 12:35:18: [2024-10-29 12:35:18] iter = 07550, loss = 6.0475
2024-10-29 12:35:19: [2024-10-29 12:35:19] iter = 07560, loss = 4.1344
2024-10-29 12:35:19: [2024-10-29 12:35:19] iter = 07570, loss = 23.0287
2024-10-29 12:35:20: [2024-10-29 12:35:20] iter = 07580, loss = 3.9986
2024-10-29 12:35:20: [2024-10-29 12:35:20] iter = 07590, loss = 10.7414
2024-10-29 12:35:21: [2024-10-29 12:35:21] iter = 07600, loss = 10.9231
2024-10-29 12:35:21: [2024-10-29 12:35:21] iter = 07610, loss = 2.5556
2024-10-29 12:35:22: [2024-10-29 12:35:22] iter = 07620, loss = 2.7176
2024-10-29 12:35:22: [2024-10-29 12:35:22] iter = 07630, loss = 4.6128
2024-10-29 12:35:23: [2024-10-29 12:35:23] iter = 07640, loss = 5.5489
2024-10-29 12:35:23: [2024-10-29 12:35:23] iter = 07650, loss = 5.9157
2024-10-29 12:35:24: [2024-10-29 12:35:24] iter = 07660, loss = 35.5696
2024-10-29 12:35:24: [2024-10-29 12:35:24] iter = 07670, loss = 3.1214
2024-10-29 12:35:25: [2024-10-29 12:35:25] iter = 07680, loss = 19.1519
2024-10-29 12:35:25: [2024-10-29 12:35:25] iter = 07690, loss = 2.5266
2024-10-29 12:35:26: [2024-10-29 12:35:26] iter = 07700, loss = 2.8884
2024-10-29 12:35:26: [2024-10-29 12:35:26] iter = 07710, loss = 11.4890
2024-10-29 12:35:27: [2024-10-29 12:35:27] iter = 07720, loss = 6.9579
2024-10-29 12:35:27: [2024-10-29 12:35:27] iter = 07730, loss = 6.5533
2024-10-29 12:35:28: [2024-10-29 12:35:28] iter = 07740, loss = 10.9180
2024-10-29 12:35:28: [2024-10-29 12:35:28] iter = 07750, loss = 6.0236
2024-10-29 12:35:29: [2024-10-29 12:35:29] iter = 07760, loss = 5.1257
2024-10-29 12:35:30: [2024-10-29 12:35:30] iter = 07770, loss = 7.8368
2024-10-29 12:35:30: [2024-10-29 12:35:30] iter = 07780, loss = 2.1796
2024-10-29 12:35:31: [2024-10-29 12:35:31] iter = 07790, loss = 5.8414
2024-10-29 12:35:32: [2024-10-29 12:35:32] iter = 07800, loss = 4.9770
2024-10-29 12:35:33: [2024-10-29 12:35:33] iter = 07810, loss = 3.7391
2024-10-29 12:35:33: [2024-10-29 12:35:33] iter = 07820, loss = 4.7615
2024-10-29 12:35:34: [2024-10-29 12:35:34] iter = 07830, loss = 9.8785
2024-10-29 12:35:35: [2024-10-29 12:35:35] iter = 07840, loss = 4.6873
2024-10-29 12:35:35: [2024-10-29 12:35:35] iter = 07850, loss = 6.0997
2024-10-29 12:35:36: [2024-10-29 12:35:36] iter = 07860, loss = 3.9521
2024-10-29 12:35:36: [2024-10-29 12:35:36] iter = 07870, loss = 4.3808
2024-10-29 12:35:37: [2024-10-29 12:35:37] iter = 07880, loss = 4.2352
2024-10-29 12:35:37: [2024-10-29 12:35:37] iter = 07890, loss = 2.5632
2024-10-29 12:35:38: [2024-10-29 12:35:38] iter = 07900, loss = 3.6457
2024-10-29 12:35:38: [2024-10-29 12:35:38] iter = 07910, loss = 2.2312
2024-10-29 12:35:39: [2024-10-29 12:35:39] iter = 07920, loss = 11.7930
2024-10-29 12:35:39: [2024-10-29 12:35:39] iter = 07930, loss = 5.3043
2024-10-29 12:35:40: [2024-10-29 12:35:40] iter = 07940, loss = 4.4472
2024-10-29 12:35:40: [2024-10-29 12:35:40] iter = 07950, loss = 3.0648
2024-10-29 12:35:41: [2024-10-29 12:35:41] iter = 07960, loss = 10.2152
2024-10-29 12:35:41: [2024-10-29 12:35:41] iter = 07970, loss = 6.6986
2024-10-29 12:35:42: [2024-10-29 12:35:42] iter = 07980, loss = 17.1773
2024-10-29 12:35:42: [2024-10-29 12:35:42] iter = 07990, loss = 5.9403
2024-10-29 12:35:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 12:35:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:35:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 43006}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:36:10: Evaluate 5 random ConvNet, ACCmean = 0.4028 ACCstd = 0.0078
-------------------------
2024-10-29 12:36:10: Evaluate 5 random ConvNet, SENmean = 0.4028 SENstd = 0.0078
-------------------------
2024-10-29 12:36:10: Evaluate 5 random ConvNet, SPEmean = 0.8009 SPEstd = 0.0026
-------------------------
2024-10-29 12:36:10: Evaluate 5 random ConvNet, F!mean = 0.3472 F!std = 0.0100
-------------------------
2024-10-29 12:36:10: Evaluate 5 random ConvNet, mean = 0.4028 std = 0.0078
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:36:10: [2024-10-29 12:36:10] iter = 08000, loss = 5.8133
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:36:10: [2024-10-29 12:36:10] iter = 08010, loss = 3.3442
2024-10-29 12:36:11: [2024-10-29 12:36:11] iter = 08020, loss = 16.8986
2024-10-29 12:36:11: [2024-10-29 12:36:11] iter = 08030, loss = 3.5974
2024-10-29 12:36:12: [2024-10-29 12:36:12] iter = 08040, loss = 2.8294
2024-10-29 12:36:13: [2024-10-29 12:36:13] iter = 08050, loss = 2.6438
2024-10-29 12:36:13: [2024-10-29 12:36:13] iter = 08060, loss = 7.4937
2024-10-29 12:36:14: [2024-10-29 12:36:14] iter = 08070, loss = 2.3281
2024-10-29 12:36:14: [2024-10-29 12:36:14] iter = 08080, loss = 8.3788
2024-10-29 12:36:15: [2024-10-29 12:36:15] iter = 08090, loss = 4.0365
2024-10-29 12:36:16: [2024-10-29 12:36:16] iter = 08100, loss = 14.6307
2024-10-29 12:36:16: [2024-10-29 12:36:16] iter = 08110, loss = 4.6011
2024-10-29 12:36:17: [2024-10-29 12:36:17] iter = 08120, loss = 9.1760
2024-10-29 12:36:18: [2024-10-29 12:36:18] iter = 08130, loss = 7.6934
2024-10-29 12:36:18: [2024-10-29 12:36:18] iter = 08140, loss = 3.3345
2024-10-29 12:36:19: [2024-10-29 12:36:19] iter = 08150, loss = 8.6090
2024-10-29 12:36:20: [2024-10-29 12:36:20] iter = 08160, loss = 4.2616
2024-10-29 12:36:20: [2024-10-29 12:36:20] iter = 08170, loss = 4.1160
2024-10-29 12:36:21: [2024-10-29 12:36:21] iter = 08180, loss = 9.4894
2024-10-29 12:36:21: [2024-10-29 12:36:21] iter = 08190, loss = 3.7637
2024-10-29 12:36:22: [2024-10-29 12:36:22] iter = 08200, loss = 4.8913
2024-10-29 12:36:22: [2024-10-29 12:36:22] iter = 08210, loss = 3.7184
2024-10-29 12:36:23: [2024-10-29 12:36:23] iter = 08220, loss = 5.4545
2024-10-29 12:36:24: [2024-10-29 12:36:24] iter = 08230, loss = 6.0910
2024-10-29 12:36:24: [2024-10-29 12:36:24] iter = 08240, loss = 7.9709
2024-10-29 12:36:25: [2024-10-29 12:36:25] iter = 08250, loss = 3.6927
2024-10-29 12:36:25: [2024-10-29 12:36:25] iter = 08260, loss = 10.0914
2024-10-29 12:36:26: [2024-10-29 12:36:26] iter = 08270, loss = 11.7154
2024-10-29 12:36:26: [2024-10-29 12:36:26] iter = 08280, loss = 9.2363
2024-10-29 12:36:27: [2024-10-29 12:36:27] iter = 08290, loss = 45.1804
2024-10-29 12:36:27: [2024-10-29 12:36:27] iter = 08300, loss = 14.9336
2024-10-29 12:36:28: [2024-10-29 12:36:28] iter = 08310, loss = 8.3216
2024-10-29 12:36:28: [2024-10-29 12:36:28] iter = 08320, loss = 48.0681
2024-10-29 12:36:29: [2024-10-29 12:36:29] iter = 08330, loss = 11.1003
2024-10-29 12:36:29: [2024-10-29 12:36:29] iter = 08340, loss = 4.4687
2024-10-29 12:36:30: [2024-10-29 12:36:30] iter = 08350, loss = 4.8958
2024-10-29 12:36:30: [2024-10-29 12:36:30] iter = 08360, loss = 3.2843
2024-10-29 12:36:31: [2024-10-29 12:36:31] iter = 08370, loss = 4.5402
2024-10-29 12:36:31: [2024-10-29 12:36:31] iter = 08380, loss = 9.5760
2024-10-29 12:36:32: [2024-10-29 12:36:32] iter = 08390, loss = 6.8832
2024-10-29 12:36:32: [2024-10-29 12:36:32] iter = 08400, loss = 29.4247
2024-10-29 12:36:33: [2024-10-29 12:36:33] iter = 08410, loss = 4.0255
2024-10-29 12:36:33: [2024-10-29 12:36:33] iter = 08420, loss = 15.8031
2024-10-29 12:36:34: [2024-10-29 12:36:34] iter = 08430, loss = 55.6230
2024-10-29 12:36:34: [2024-10-29 12:36:34] iter = 08440, loss = 6.4230
2024-10-29 12:36:35: [2024-10-29 12:36:35] iter = 08450, loss = 5.8490
2024-10-29 12:36:35: [2024-10-29 12:36:35] iter = 08460, loss = 3.0065
2024-10-29 12:36:36: [2024-10-29 12:36:36] iter = 08470, loss = 3.5879
2024-10-29 12:36:36: [2024-10-29 12:36:36] iter = 08480, loss = 2.9493
2024-10-29 12:36:37: [2024-10-29 12:36:37] iter = 08490, loss = 4.2703
2024-10-29 12:36:37: [2024-10-29 12:36:37] iter = 08500, loss = 10.9190
2024-10-29 12:36:38: [2024-10-29 12:36:38] iter = 08510, loss = 2.7733
2024-10-29 12:36:39: [2024-10-29 12:36:39] iter = 08520, loss = 3.6719
2024-10-29 12:36:39: [2024-10-29 12:36:39] iter = 08530, loss = 6.6241
2024-10-29 12:36:40: [2024-10-29 12:36:40] iter = 08540, loss = 7.4611
2024-10-29 12:36:40: [2024-10-29 12:36:40] iter = 08550, loss = 3.9132
2024-10-29 12:36:41: [2024-10-29 12:36:41] iter = 08560, loss = 8.6298
2024-10-29 12:36:42: [2024-10-29 12:36:42] iter = 08570, loss = 54.2521
2024-10-29 12:36:42: [2024-10-29 12:36:42] iter = 08580, loss = 7.6409
2024-10-29 12:36:43: [2024-10-29 12:36:43] iter = 08590, loss = 2.0548
2024-10-29 12:36:43: [2024-10-29 12:36:43] iter = 08600, loss = 7.0397
2024-10-29 12:36:44: [2024-10-29 12:36:44] iter = 08610, loss = 3.6788
2024-10-29 12:36:44: [2024-10-29 12:36:44] iter = 08620, loss = 7.9353
2024-10-29 12:36:45: [2024-10-29 12:36:45] iter = 08630, loss = 2.1556
2024-10-29 12:36:45: [2024-10-29 12:36:45] iter = 08640, loss = 4.6608
2024-10-29 12:36:46: [2024-10-29 12:36:46] iter = 08650, loss = 16.1159
2024-10-29 12:36:47: [2024-10-29 12:36:47] iter = 08660, loss = 12.4597
2024-10-29 12:36:47: [2024-10-29 12:36:47] iter = 08670, loss = 12.3257
2024-10-29 12:36:48: [2024-10-29 12:36:48] iter = 08680, loss = 4.1509
2024-10-29 12:36:48: [2024-10-29 12:36:48] iter = 08690, loss = 4.7979
2024-10-29 12:36:49: [2024-10-29 12:36:49] iter = 08700, loss = 12.3209
2024-10-29 12:36:49: [2024-10-29 12:36:49] iter = 08710, loss = 3.6838
2024-10-29 12:36:50: [2024-10-29 12:36:50] iter = 08720, loss = 5.8420
2024-10-29 12:36:50: [2024-10-29 12:36:50] iter = 08730, loss = 8.8871
2024-10-29 12:36:51: [2024-10-29 12:36:51] iter = 08740, loss = 8.4212
2024-10-29 12:36:51: [2024-10-29 12:36:51] iter = 08750, loss = 18.3381
2024-10-29 12:36:52: [2024-10-29 12:36:52] iter = 08760, loss = 32.9667
2024-10-29 12:36:52: [2024-10-29 12:36:52] iter = 08770, loss = 3.5378
2024-10-29 12:36:53: [2024-10-29 12:36:53] iter = 08780, loss = 7.6225
2024-10-29 12:36:53: [2024-10-29 12:36:53] iter = 08790, loss = 8.3361
2024-10-29 12:36:54: [2024-10-29 12:36:54] iter = 08800, loss = 2.6830
2024-10-29 12:36:54: [2024-10-29 12:36:54] iter = 08810, loss = 10.0205
2024-10-29 12:36:54: [2024-10-29 12:36:54] iter = 08820, loss = 3.2914
2024-10-29 12:36:55: [2024-10-29 12:36:55] iter = 08830, loss = 4.5546
2024-10-29 12:36:55: [2024-10-29 12:36:55] iter = 08840, loss = 8.3767
2024-10-29 12:36:56: [2024-10-29 12:36:56] iter = 08850, loss = 10.0310
2024-10-29 12:36:57: [2024-10-29 12:36:57] iter = 08860, loss = 4.2060
2024-10-29 12:36:57: [2024-10-29 12:36:57] iter = 08870, loss = 11.9238
2024-10-29 12:36:58: [2024-10-29 12:36:58] iter = 08880, loss = 2.2688
2024-10-29 12:36:58: [2024-10-29 12:36:58] iter = 08890, loss = 15.0375
2024-10-29 12:36:59: [2024-10-29 12:36:59] iter = 08900, loss = 4.1945
2024-10-29 12:36:59: [2024-10-29 12:36:59] iter = 08910, loss = 2.3417
2024-10-29 12:37:00: [2024-10-29 12:37:00] iter = 08920, loss = 2.6021
2024-10-29 12:37:00: [2024-10-29 12:37:00] iter = 08930, loss = 3.0702
2024-10-29 12:37:01: [2024-10-29 12:37:01] iter = 08940, loss = 7.4923
2024-10-29 12:37:01: [2024-10-29 12:37:01] iter = 08950, loss = 2.3645
2024-10-29 12:37:02: [2024-10-29 12:37:02] iter = 08960, loss = 6.4305
2024-10-29 12:37:02: [2024-10-29 12:37:02] iter = 08970, loss = 2.6926
2024-10-29 12:37:03: [2024-10-29 12:37:03] iter = 08980, loss = 22.5876
2024-10-29 12:37:03: [2024-10-29 12:37:03] iter = 08990, loss = 2.9052
2024-10-29 12:37:04: [2024-10-29 12:37:04] iter = 09000, loss = 3.7801
2024-10-29 12:37:04: [2024-10-29 12:37:04] iter = 09010, loss = 4.5634
2024-10-29 12:37:05: [2024-10-29 12:37:05] iter = 09020, loss = 3.0761
2024-10-29 12:37:05: [2024-10-29 12:37:05] iter = 09030, loss = 13.1424
2024-10-29 12:37:06: [2024-10-29 12:37:06] iter = 09040, loss = 6.1376
2024-10-29 12:37:06: [2024-10-29 12:37:06] iter = 09050, loss = 48.2119
2024-10-29 12:37:07: [2024-10-29 12:37:07] iter = 09060, loss = 10.4168
2024-10-29 12:37:07: [2024-10-29 12:37:07] iter = 09070, loss = 7.7827
2024-10-29 12:37:08: [2024-10-29 12:37:08] iter = 09080, loss = 3.9084
2024-10-29 12:37:08: [2024-10-29 12:37:08] iter = 09090, loss = 5.7954
2024-10-29 12:37:09: [2024-10-29 12:37:09] iter = 09100, loss = 15.7027
2024-10-29 12:37:09: [2024-10-29 12:37:09] iter = 09110, loss = 9.6330
2024-10-29 12:37:10: [2024-10-29 12:37:10] iter = 09120, loss = 3.0978
2024-10-29 12:37:10: [2024-10-29 12:37:10] iter = 09130, loss = 3.6278
2024-10-29 12:37:11: [2024-10-29 12:37:11] iter = 09140, loss = 5.4384
2024-10-29 12:37:11: [2024-10-29 12:37:11] iter = 09150, loss = 2.3083
2024-10-29 12:37:12: [2024-10-29 12:37:12] iter = 09160, loss = 15.6044
2024-10-29 12:37:12: [2024-10-29 12:37:12] iter = 09170, loss = 3.1330
2024-10-29 12:37:12: [2024-10-29 12:37:12] iter = 09180, loss = 14.6621
2024-10-29 12:37:13: [2024-10-29 12:37:13] iter = 09190, loss = 4.5672
2024-10-29 12:37:13: [2024-10-29 12:37:13] iter = 09200, loss = 2.9036
2024-10-29 12:37:14: [2024-10-29 12:37:14] iter = 09210, loss = 12.3110
2024-10-29 12:37:14: [2024-10-29 12:37:14] iter = 09220, loss = 7.2723
2024-10-29 12:37:15: [2024-10-29 12:37:15] iter = 09230, loss = 5.0947
2024-10-29 12:37:15: [2024-10-29 12:37:15] iter = 09240, loss = 32.4795
2024-10-29 12:37:16: [2024-10-29 12:37:16] iter = 09250, loss = 3.8050
2024-10-29 12:37:16: [2024-10-29 12:37:16] iter = 09260, loss = 18.4194
2024-10-29 12:37:17: [2024-10-29 12:37:17] iter = 09270, loss = 7.8740
2024-10-29 12:37:18: [2024-10-29 12:37:18] iter = 09280, loss = 7.3588
2024-10-29 12:37:18: [2024-10-29 12:37:18] iter = 09290, loss = 2.6122
2024-10-29 12:37:19: [2024-10-29 12:37:19] iter = 09300, loss = 12.4612
2024-10-29 12:37:19: [2024-10-29 12:37:19] iter = 09310, loss = 4.8489
2024-10-29 12:37:20: [2024-10-29 12:37:20] iter = 09320, loss = 47.3228
2024-10-29 12:37:20: [2024-10-29 12:37:20] iter = 09330, loss = 8.6300
2024-10-29 12:37:21: [2024-10-29 12:37:21] iter = 09340, loss = 7.2661
2024-10-29 12:37:21: [2024-10-29 12:37:21] iter = 09350, loss = 6.2149
2024-10-29 12:37:22: [2024-10-29 12:37:22] iter = 09360, loss = 15.2498
2024-10-29 12:37:22: [2024-10-29 12:37:22] iter = 09370, loss = 25.0777
2024-10-29 12:37:23: [2024-10-29 12:37:23] iter = 09380, loss = 36.6977
2024-10-29 12:37:24: [2024-10-29 12:37:24] iter = 09390, loss = 4.8919
2024-10-29 12:37:24: [2024-10-29 12:37:24] iter = 09400, loss = 7.6100
2024-10-29 12:37:25: [2024-10-29 12:37:25] iter = 09410, loss = 2.2799
2024-10-29 12:37:26: [2024-10-29 12:37:26] iter = 09420, loss = 2.2231
2024-10-29 12:37:27: [2024-10-29 12:37:27] iter = 09430, loss = 2.9748
2024-10-29 12:37:28: [2024-10-29 12:37:28] iter = 09440, loss = 4.2656
2024-10-29 12:37:28: [2024-10-29 12:37:28] iter = 09450, loss = 29.0399
2024-10-29 12:37:29: [2024-10-29 12:37:29] iter = 09460, loss = 10.0827
2024-10-29 12:37:29: [2024-10-29 12:37:29] iter = 09470, loss = 36.6951
2024-10-29 12:37:30: [2024-10-29 12:37:30] iter = 09480, loss = 9.9991
2024-10-29 12:37:30: [2024-10-29 12:37:30] iter = 09490, loss = 8.9489
2024-10-29 12:37:31: [2024-10-29 12:37:31] iter = 09500, loss = 10.3710
2024-10-29 12:37:32: [2024-10-29 12:37:32] iter = 09510, loss = 6.9600
2024-10-29 12:37:32: [2024-10-29 12:37:32] iter = 09520, loss = 6.5661
2024-10-29 12:37:33: [2024-10-29 12:37:33] iter = 09530, loss = 17.7166
2024-10-29 12:37:33: [2024-10-29 12:37:33] iter = 09540, loss = 3.1618
2024-10-29 12:37:34: [2024-10-29 12:37:34] iter = 09550, loss = 4.2907
2024-10-29 12:37:35: [2024-10-29 12:37:35] iter = 09560, loss = 3.3901
2024-10-29 12:37:35: [2024-10-29 12:37:35] iter = 09570, loss = 9.4268
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 09580, loss = 7.3946
2024-10-29 12:37:36: [2024-10-29 12:37:36] iter = 09590, loss = 55.0780
2024-10-29 12:37:37: [2024-10-29 12:37:37] iter = 09600, loss = 7.1481
2024-10-29 12:37:38: [2024-10-29 12:37:38] iter = 09610, loss = 4.2738
2024-10-29 12:37:38: [2024-10-29 12:37:38] iter = 09620, loss = 3.1228
2024-10-29 12:37:39: [2024-10-29 12:37:39] iter = 09630, loss = 49.1614
2024-10-29 12:37:39: [2024-10-29 12:37:39] iter = 09640, loss = 4.1799
2024-10-29 12:37:40: [2024-10-29 12:37:40] iter = 09650, loss = 9.9190
2024-10-29 12:37:40: [2024-10-29 12:37:40] iter = 09660, loss = 7.0170
2024-10-29 12:37:41: [2024-10-29 12:37:41] iter = 09670, loss = 10.5523
2024-10-29 12:37:42: [2024-10-29 12:37:42] iter = 09680, loss = 10.2070
2024-10-29 12:37:42: [2024-10-29 12:37:42] iter = 09690, loss = 7.5595
2024-10-29 12:37:43: [2024-10-29 12:37:43] iter = 09700, loss = 9.9960
2024-10-29 12:37:43: [2024-10-29 12:37:43] iter = 09710, loss = 13.7475
2024-10-29 12:37:44: [2024-10-29 12:37:44] iter = 09720, loss = 11.9096
2024-10-29 12:37:44: [2024-10-29 12:37:44] iter = 09730, loss = 32.0270
2024-10-29 12:37:45: [2024-10-29 12:37:45] iter = 09740, loss = 5.8015
2024-10-29 12:37:45: [2024-10-29 12:37:45] iter = 09750, loss = 4.1685
2024-10-29 12:37:46: [2024-10-29 12:37:46] iter = 09760, loss = 43.5627
2024-10-29 12:37:46: [2024-10-29 12:37:46] iter = 09770, loss = 4.1931
2024-10-29 12:37:47: [2024-10-29 12:37:47] iter = 09780, loss = 3.5965
2024-10-29 12:37:47: [2024-10-29 12:37:47] iter = 09790, loss = 6.8240
2024-10-29 12:37:48: [2024-10-29 12:37:48] iter = 09800, loss = 6.4591
2024-10-29 12:37:48: [2024-10-29 12:37:48] iter = 09810, loss = 3.4517
2024-10-29 12:37:49: [2024-10-29 12:37:49] iter = 09820, loss = 8.4688
2024-10-29 12:37:49: [2024-10-29 12:37:49] iter = 09830, loss = 6.6298
2024-10-29 12:37:50: [2024-10-29 12:37:50] iter = 09840, loss = 11.2148
2024-10-29 12:37:50: [2024-10-29 12:37:50] iter = 09850, loss = 10.0025
2024-10-29 12:37:51: [2024-10-29 12:37:51] iter = 09860, loss = 21.4249
2024-10-29 12:37:51: [2024-10-29 12:37:51] iter = 09870, loss = 9.4152
2024-10-29 12:37:52: [2024-10-29 12:37:52] iter = 09880, loss = 2.7260
2024-10-29 12:37:52: [2024-10-29 12:37:52] iter = 09890, loss = 4.1645
2024-10-29 12:37:53: [2024-10-29 12:37:53] iter = 09900, loss = 5.7151
2024-10-29 12:37:53: [2024-10-29 12:37:53] iter = 09910, loss = 12.7621
2024-10-29 12:37:54: [2024-10-29 12:37:54] iter = 09920, loss = 8.3964
2024-10-29 12:37:54: [2024-10-29 12:37:54] iter = 09930, loss = 2.6500
2024-10-29 12:37:55: [2024-10-29 12:37:55] iter = 09940, loss = 20.9269
2024-10-29 12:37:55: [2024-10-29 12:37:55] iter = 09950, loss = 5.3248
2024-10-29 12:37:56: [2024-10-29 12:37:56] iter = 09960, loss = 5.4916
2024-10-29 12:37:56: [2024-10-29 12:37:56] iter = 09970, loss = 3.1982
2024-10-29 12:37:57: [2024-10-29 12:37:57] iter = 09980, loss = 4.7999
2024-10-29 12:37:57: [2024-10-29 12:37:57] iter = 09990, loss = 9.0470
2024-10-29 12:37:58: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 12:37:58: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:37:58: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 78177}

[2024-10-29 12:21:15] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002428 train acc = 1.0000, test acc = 0.4780, test_sen =0.4780, test_spe =0.8260, test_f1 =0.4247
[2024-10-29 12:21:20] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.041703 train acc = 1.0000, test acc = 0.4480, test_sen =0.4480, test_spe =0.8160, test_f1 =0.3669
[2024-10-29 12:21:24] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.005649 train acc = 1.0000, test acc = 0.4750, test_sen =0.4750, test_spe =0.8250, test_f1 =0.4285
[2024-10-29 12:23:00] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001618 train acc = 1.0000, test acc = 0.4840, test_sen =0.4840, test_spe =0.8280, test_f1 =0.4291
[2024-10-29 12:23:05] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.000532 train acc = 1.0000, test acc = 0.4980, test_sen =0.4980, test_spe =0.8327, test_f1 =0.4372
[2024-10-29 12:23:10] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001650 train acc = 1.0000, test acc = 0.5190, test_sen =0.5190, test_spe =0.8397, test_f1 =0.4665
[2024-10-29 12:23:14] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.000446 train acc = 1.0000, test acc = 0.4990, test_sen =0.4990, test_spe =0.8330, test_f1 =0.4414
[2024-10-29 12:23:19] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.000838 train acc = 1.0000, test acc = 0.4960, test_sen =0.4960, test_spe =0.8320, test_f1 =0.4292
[2024-10-29 12:24:59] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001810 train acc = 1.0000, test acc = 0.4790, test_sen =0.4790, test_spe =0.8263, test_f1 =0.4769
[2024-10-29 12:25:04] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.024271 train acc = 1.0000, test acc = 0.4530, test_sen =0.4530, test_spe =0.8177, test_f1 =0.4485
[2024-10-29 12:25:09] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.002476 train acc = 1.0000, test acc = 0.4830, test_sen =0.4830, test_spe =0.8277, test_f1 =0.4844
[2024-10-29 12:25:14] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001065 train acc = 1.0000, test acc = 0.4790, test_sen =0.4790, test_spe =0.8263, test_f1 =0.4726
[2024-10-29 12:25:18] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001442 train acc = 1.0000, test acc = 0.4940, test_sen =0.4940, test_spe =0.8313, test_f1 =0.4889
[2024-10-29 12:26:55] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.005684 train acc = 1.0000, test acc = 0.5530, test_sen =0.5530, test_spe =0.8510, test_f1 =0.5576
[2024-10-29 12:27:00] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.002551 train acc = 1.0000, test acc = 0.5590, test_sen =0.5590, test_spe =0.8530, test_f1 =0.5678
[2024-10-29 12:27:05] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001134 train acc = 1.0000, test acc = 0.5650, test_sen =0.5650, test_spe =0.8550, test_f1 =0.5675
[2024-10-29 12:27:10] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.005870 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8533, test_f1 =0.5650
[2024-10-29 12:27:15] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.005453 train acc = 1.0000, test acc = 0.5520, test_sen =0.5520, test_spe =0.8507, test_f1 =0.5580
[2024-10-29 12:27:23] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.007127 train acc = 1.0000, test acc = 0.4150, test_sen =0.4150, test_spe =0.8050, test_f1 =0.4123
[2024-10-29 12:27:28] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.004416 train acc = 1.0000, test acc = 0.4160, test_sen =0.4160, test_spe =0.8053, test_f1 =0.4102
[2024-10-29 12:27:33] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.007105 train acc = 1.0000, test acc = 0.4260, test_sen =0.4260, test_spe =0.8087, test_f1 =0.4256
[2024-10-29 12:27:38] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.007148 train acc = 1.0000, test acc = 0.4140, test_sen =0.4140, test_spe =0.8047, test_f1 =0.4077
[2024-10-29 12:27:42] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.007989 train acc = 1.0000, test acc = 0.4240, test_sen =0.4240, test_spe =0.8080, test_f1 =0.4174
[2024-10-29 12:29:25] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.020745 train acc = 1.0000, test acc = 0.4710, test_sen =0.4710, test_spe =0.8237, test_f1 =0.3748
[2024-10-29 12:29:30] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.008005 train acc = 1.0000, test acc = 0.4690, test_sen =0.4690, test_spe =0.8230, test_f1 =0.3838
[2024-10-29 12:29:35] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.000378 train acc = 1.0000, test acc = 0.4740, test_sen =0.4740, test_spe =0.8247, test_f1 =0.3794
[2024-10-29 12:29:40] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002233 train acc = 1.0000, test acc = 0.4620, test_sen =0.4620, test_spe =0.8207, test_f1 =0.3657
[2024-10-29 12:29:45] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.000937 train acc = 1.0000, test acc = 0.4680, test_sen =0.4680, test_spe =0.8227, test_f1 =0.3716
[2024-10-29 12:31:30] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001218 train acc = 1.0000, test acc = 0.5200, test_sen =0.5200, test_spe =0.8400, test_f1 =0.4641
[2024-10-29 12:31:36] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001379 train acc = 1.0000, test acc = 0.5130, test_sen =0.5130, test_spe =0.8377, test_f1 =0.4519
[2024-10-29 12:31:41] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000333 train acc = 1.0000, test acc = 0.5030, test_sen =0.5030, test_spe =0.8343, test_f1 =0.4578
[2024-10-29 12:31:46] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.022552 train acc = 1.0000, test acc = 0.5270, test_sen =0.5270, test_spe =0.8423, test_f1 =0.4697
[2024-10-29 12:31:51] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.002138 train acc = 1.0000, test acc = 0.5060, test_sen =0.5060, test_spe =0.8353, test_f1 =0.4575
[2024-10-29 12:33:39] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001683 train acc = 1.0000, test acc = 0.5680, test_sen =0.5680, test_spe =0.8560, test_f1 =0.5694
[2024-10-29 12:33:44] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002552 train acc = 1.0000, test acc = 0.5610, test_sen =0.5610, test_spe =0.8537, test_f1 =0.5523
[2024-10-29 12:33:50] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.062286 train acc = 1.0000, test acc = 0.5920, test_sen =0.5920, test_spe =0.8640, test_f1 =0.5895
[2024-10-29 12:33:55] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.039123 train acc = 1.0000, test acc = 0.5820, test_sen =0.5820, test_spe =0.8607, test_f1 =0.5818
[2024-10-29 12:34:00] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.052725 train acc = 0.9750, test acc = 0.5760, test_sen =0.5760, test_spe =0.8587, test_f1 =0.5725
[2024-10-29 12:35:48] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002076 train acc = 1.0000, test acc = 0.3990, test_sen =0.3990, test_spe =0.7997, test_f1 =0.3423
[2024-10-29 12:35:54] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001284 train acc = 1.0000, test acc = 0.4070, test_sen =0.4070, test_spe =0.8023, test_f1 =0.3501
[2024-10-29 12:35:59] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.034849 train acc = 1.0000, test acc = 0.3980, test_sen =0.3980, test_spe =0.7993, test_f1 =0.3549
[2024-10-29 12:36:04] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.007662 train acc = 1.0000, test acc = 0.4160, test_sen =0.4160, test_spe =0.8053, test_f1 =0.3585
[2024-10-29 12:36:10] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.033236 train acc = 1.0000, test acc = 0.3940, test_sen =0.3940, test_spe =0.7980, test_f1 =0.3305
[2024-10-29 12:38:03] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.000681 train acc = 1.0000, test acc = 0.4930, test_sen =0.4930, test_spe =0.8310, test_f1 =0.4168
[2024-10-29 12:38:07] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.000406 train acc = 1.0000, test acc = 0.4540, test_sen =0.4540, test_spe =0.8180, test_f1 =0.3700
[2024-10-29 12:38:12] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.001175 train acc = 1.0000, test acc = 0.4840, test_sen =0.4840, test_spe =0.8280, test_f1 =0.3935
[2024-10-29 12:38:18] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.003724 train acc = 1.0000, test acc = 0.4910, test_sen =0.4910, test_spe =0.8303, test_f1 =0.4117/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:38:24: Evaluate 5 random ConvNet, ACCmean = 0.4818 ACCstd = 0.0142
-------------------------
2024-10-29 12:38:24: Evaluate 5 random ConvNet, SENmean = 0.4818 SENstd = 0.0142
-------------------------
2024-10-29 12:38:24: Evaluate 5 random ConvNet, SPEmean = 0.8273 SPEstd = 0.0047
-------------------------
2024-10-29 12:38:24: Evaluate 5 random ConvNet, F!mean = 0.3963 F!std = 0.0168
-------------------------
2024-10-29 12:38:24: Evaluate 5 random ConvNet, mean = 0.4818 std = 0.0142
-------------------------
2024-10-29 12:38:24: [2024-10-29 12:38:24] iter = 10000, loss = 29.6096
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:38:25: [2024-10-29 12:38:25] iter = 10010, loss = 7.4512
2024-10-29 12:38:26: [2024-10-29 12:38:26] iter = 10020, loss = 3.1200
2024-10-29 12:38:26: [2024-10-29 12:38:26] iter = 10030, loss = 2.1870
2024-10-29 12:38:27: [2024-10-29 12:38:27] iter = 10040, loss = 6.6917
2024-10-29 12:38:27: [2024-10-29 12:38:27] iter = 10050, loss = 3.6991
2024-10-29 12:38:28: [2024-10-29 12:38:28] iter = 10060, loss = 3.5103
2024-10-29 12:38:28: [2024-10-29 12:38:28] iter = 10070, loss = 20.9153
2024-10-29 12:38:29: [2024-10-29 12:38:29] iter = 10080, loss = 13.6621
2024-10-29 12:38:30: [2024-10-29 12:38:30] iter = 10090, loss = 4.2451
2024-10-29 12:38:30: [2024-10-29 12:38:30] iter = 10100, loss = 4.4542
2024-10-29 12:38:31: [2024-10-29 12:38:31] iter = 10110, loss = 2.6440
2024-10-29 12:38:31: [2024-10-29 12:38:31] iter = 10120, loss = 2.9619
2024-10-29 12:38:32: [2024-10-29 12:38:32] iter = 10130, loss = 39.0458
2024-10-29 12:38:32: [2024-10-29 12:38:32] iter = 10140, loss = 4.0286
2024-10-29 12:38:33: [2024-10-29 12:38:33] iter = 10150, loss = 6.7352
2024-10-29 12:38:33: [2024-10-29 12:38:33] iter = 10160, loss = 4.5519
2024-10-29 12:38:34: [2024-10-29 12:38:34] iter = 10170, loss = 9.3422
2024-10-29 12:38:34: [2024-10-29 12:38:34] iter = 10180, loss = 3.9459
2024-10-29 12:38:35: [2024-10-29 12:38:35] iter = 10190, loss = 3.8681
2024-10-29 12:38:35: [2024-10-29 12:38:35] iter = 10200, loss = 25.6663
2024-10-29 12:38:36: [2024-10-29 12:38:36] iter = 10210, loss = 7.6309
2024-10-29 12:38:36: [2024-10-29 12:38:36] iter = 10220, loss = 12.7515
2024-10-29 12:38:37: [2024-10-29 12:38:37] iter = 10230, loss = 17.4906
2024-10-29 12:38:38: [2024-10-29 12:38:38] iter = 10240, loss = 5.7568
2024-10-29 12:38:39: [2024-10-29 12:38:39] iter = 10250, loss = 3.7418
2024-10-29 12:38:39: [2024-10-29 12:38:39] iter = 10260, loss = 9.2477
2024-10-29 12:38:40: [2024-10-29 12:38:40] iter = 10270, loss = 4.5675
2024-10-29 12:38:41: [2024-10-29 12:38:41] iter = 10280, loss = 13.9578
2024-10-29 12:38:41: [2024-10-29 12:38:41] iter = 10290, loss = 8.4150
2024-10-29 12:38:42: [2024-10-29 12:38:42] iter = 10300, loss = 5.6768
2024-10-29 12:38:43: [2024-10-29 12:38:43] iter = 10310, loss = 3.1135
2024-10-29 12:38:43: [2024-10-29 12:38:43] iter = 10320, loss = 3.6493
2024-10-29 12:38:44: [2024-10-29 12:38:44] iter = 10330, loss = 3.9437
2024-10-29 12:38:45: [2024-10-29 12:38:45] iter = 10340, loss = 16.4917
2024-10-29 12:38:45: [2024-10-29 12:38:45] iter = 10350, loss = 5.2128
2024-10-29 12:38:46: [2024-10-29 12:38:46] iter = 10360, loss = 3.4405
2024-10-29 12:38:46: [2024-10-29 12:38:46] iter = 10370, loss = 10.3184
2024-10-29 12:38:47: [2024-10-29 12:38:47] iter = 10380, loss = 8.0699
2024-10-29 12:38:47: [2024-10-29 12:38:47] iter = 10390, loss = 5.1496
2024-10-29 12:38:48: [2024-10-29 12:38:48] iter = 10400, loss = 3.1243
2024-10-29 12:38:48: [2024-10-29 12:38:48] iter = 10410, loss = 5.5248
2024-10-29 12:38:49: [2024-10-29 12:38:49] iter = 10420, loss = 11.2997
2024-10-29 12:38:49: [2024-10-29 12:38:49] iter = 10430, loss = 10.5495
2024-10-29 12:38:50: [2024-10-29 12:38:50] iter = 10440, loss = 3.3886
2024-10-29 12:38:50: [2024-10-29 12:38:50] iter = 10450, loss = 3.2043
2024-10-29 12:38:51: [2024-10-29 12:38:51] iter = 10460, loss = 17.2919
2024-10-29 12:38:51: [2024-10-29 12:38:51] iter = 10470, loss = 4.2691
2024-10-29 12:38:52: [2024-10-29 12:38:52] iter = 10480, loss = 2.5246
2024-10-29 12:38:52: [2024-10-29 12:38:52] iter = 10490, loss = 3.3542
2024-10-29 12:38:53: [2024-10-29 12:38:53] iter = 10500, loss = 31.1644
2024-10-29 12:38:54: [2024-10-29 12:38:54] iter = 10510, loss = 8.1407
2024-10-29 12:38:54: [2024-10-29 12:38:54] iter = 10520, loss = 1.8319
2024-10-29 12:38:55: [2024-10-29 12:38:55] iter = 10530, loss = 17.2634
2024-10-29 12:38:55: [2024-10-29 12:38:55] iter = 10540, loss = 5.0225
2024-10-29 12:38:56: [2024-10-29 12:38:56] iter = 10550, loss = 33.2245
2024-10-29 12:38:56: [2024-10-29 12:38:56] iter = 10560, loss = 4.9635
2024-10-29 12:38:57: [2024-10-29 12:38:57] iter = 10570, loss = 6.3698
2024-10-29 12:38:57: [2024-10-29 12:38:57] iter = 10580, loss = 4.2869
2024-10-29 12:38:58: [2024-10-29 12:38:58] iter = 10590, loss = 35.2019
2024-10-29 12:38:58: [2024-10-29 12:38:58] iter = 10600, loss = 2.7599
2024-10-29 12:38:59: [2024-10-29 12:38:59] iter = 10610, loss = 7.4890
2024-10-29 12:38:59: [2024-10-29 12:38:59] iter = 10620, loss = 4.2997
2024-10-29 12:39:00: [2024-10-29 12:39:00] iter = 10630, loss = 5.8902
2024-10-29 12:39:00: [2024-10-29 12:39:00] iter = 10640, loss = 5.8564
2024-10-29 12:39:01: [2024-10-29 12:39:01] iter = 10650, loss = 16.3950
2024-10-29 12:39:01: [2024-10-29 12:39:01] iter = 10660, loss = 14.0729
2024-10-29 12:39:02: [2024-10-29 12:39:02] iter = 10670, loss = 5.1144
2024-10-29 12:39:02: [2024-10-29 12:39:02] iter = 10680, loss = 9.8644
2024-10-29 12:39:03: [2024-10-29 12:39:03] iter = 10690, loss = 23.4778
2024-10-29 12:39:03: [2024-10-29 12:39:03] iter = 10700, loss = 30.5373
2024-10-29 12:39:04: [2024-10-29 12:39:04] iter = 10710, loss = 12.2166
2024-10-29 12:39:04: [2024-10-29 12:39:04] iter = 10720, loss = 9.4470
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 10730, loss = 10.7972
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 10740, loss = 2.3848
2024-10-29 12:39:05: [2024-10-29 12:39:05] iter = 10750, loss = 40.2571
2024-10-29 12:39:06: [2024-10-29 12:39:06] iter = 10760, loss = 7.7710
2024-10-29 12:39:06: [2024-10-29 12:39:06] iter = 10770, loss = 2.4137
2024-10-29 12:39:07: [2024-10-29 12:39:07] iter = 10780, loss = 2.9103
2024-10-29 12:39:07: [2024-10-29 12:39:07] iter = 10790, loss = 16.6415
2024-10-29 12:39:08: [2024-10-29 12:39:08] iter = 10800, loss = 6.9534
2024-10-29 12:39:08: [2024-10-29 12:39:08] iter = 10810, loss = 4.4313
2024-10-29 12:39:09: [2024-10-29 12:39:09] iter = 10820, loss = 2.8308
2024-10-29 12:39:09: [2024-10-29 12:39:09] iter = 10830, loss = 39.7773
2024-10-29 12:39:10: [2024-10-29 12:39:10] iter = 10840, loss = 3.9775
2024-10-29 12:39:10: [2024-10-29 12:39:10] iter = 10850, loss = 10.2095
2024-10-29 12:39:11: [2024-10-29 12:39:11] iter = 10860, loss = 6.9033
2024-10-29 12:39:11: [2024-10-29 12:39:11] iter = 10870, loss = 3.4128
2024-10-29 12:39:12: [2024-10-29 12:39:12] iter = 10880, loss = 2.6956
2024-10-29 12:39:12: [2024-10-29 12:39:12] iter = 10890, loss = 18.9307
2024-10-29 12:39:13: [2024-10-29 12:39:13] iter = 10900, loss = 33.5438
2024-10-29 12:39:13: [2024-10-29 12:39:13] iter = 10910, loss = 7.3685
2024-10-29 12:39:14: [2024-10-29 12:39:14] iter = 10920, loss = 2.8995
2024-10-29 12:39:14: [2024-10-29 12:39:14] iter = 10930, loss = 4.7561
2024-10-29 12:39:15: [2024-10-29 12:39:15] iter = 10940, loss = 5.1392
2024-10-29 12:39:16: [2024-10-29 12:39:16] iter = 10950, loss = 7.7718
2024-10-29 12:39:16: [2024-10-29 12:39:16] iter = 10960, loss = 4.9924
2024-10-29 12:39:17: [2024-10-29 12:39:17] iter = 10970, loss = 13.9060
2024-10-29 12:39:17: [2024-10-29 12:39:17] iter = 10980, loss = 2.5206
2024-10-29 12:39:18: [2024-10-29 12:39:18] iter = 10990, loss = 32.0180
2024-10-29 12:39:18: [2024-10-29 12:39:18] iter = 11000, loss = 10.2559
2024-10-29 12:39:19: [2024-10-29 12:39:19] iter = 11010, loss = 8.6780
2024-10-29 12:39:19: [2024-10-29 12:39:19] iter = 11020, loss = 34.2465
2024-10-29 12:39:20: [2024-10-29 12:39:20] iter = 11030, loss = 25.8851
2024-10-29 12:39:21: [2024-10-29 12:39:21] iter = 11040, loss = 3.1037
2024-10-29 12:39:21: [2024-10-29 12:39:21] iter = 11050, loss = 6.7853
2024-10-29 12:39:22: [2024-10-29 12:39:22] iter = 11060, loss = 3.5643
2024-10-29 12:39:22: [2024-10-29 12:39:22] iter = 11070, loss = 5.6121
2024-10-29 12:39:23: [2024-10-29 12:39:23] iter = 11080, loss = 11.9615
2024-10-29 12:39:23: [2024-10-29 12:39:23] iter = 11090, loss = 4.0839
2024-10-29 12:39:24: [2024-10-29 12:39:24] iter = 11100, loss = 5.6996
2024-10-29 12:39:24: [2024-10-29 12:39:24] iter = 11110, loss = 6.7008
2024-10-29 12:39:25: [2024-10-29 12:39:25] iter = 11120, loss = 4.0315
2024-10-29 12:39:26: [2024-10-29 12:39:26] iter = 11130, loss = 4.4746
2024-10-29 12:39:26: [2024-10-29 12:39:26] iter = 11140, loss = 4.5721
2024-10-29 12:39:27: [2024-10-29 12:39:27] iter = 11150, loss = 7.2112
2024-10-29 12:39:27: [2024-10-29 12:39:27] iter = 11160, loss = 2.9007
2024-10-29 12:39:28: [2024-10-29 12:39:28] iter = 11170, loss = 3.8724
2024-10-29 12:39:28: [2024-10-29 12:39:28] iter = 11180, loss = 19.9027
2024-10-29 12:39:29: [2024-10-29 12:39:29] iter = 11190, loss = 7.1019
2024-10-29 12:39:30: [2024-10-29 12:39:30] iter = 11200, loss = 3.0041
2024-10-29 12:39:30: [2024-10-29 12:39:30] iter = 11210, loss = 5.7014
2024-10-29 12:39:31: [2024-10-29 12:39:31] iter = 11220, loss = 2.8803
2024-10-29 12:39:32: [2024-10-29 12:39:32] iter = 11230, loss = 4.1502
2024-10-29 12:39:32: [2024-10-29 12:39:32] iter = 11240, loss = 18.3599
2024-10-29 12:39:33: [2024-10-29 12:39:33] iter = 11250, loss = 3.0546
2024-10-29 12:39:33: [2024-10-29 12:39:33] iter = 11260, loss = 19.8125
2024-10-29 12:39:34: [2024-10-29 12:39:34] iter = 11270, loss = 4.3785
2024-10-29 12:39:34: [2024-10-29 12:39:34] iter = 11280, loss = 3.4820
2024-10-29 12:39:35: [2024-10-29 12:39:35] iter = 11290, loss = 7.3465
2024-10-29 12:39:35: [2024-10-29 12:39:35] iter = 11300, loss = 3.7722
2024-10-29 12:39:36: [2024-10-29 12:39:36] iter = 11310, loss = 9.9472
2024-10-29 12:39:36: [2024-10-29 12:39:36] iter = 11320, loss = 2.7029
2024-10-29 12:39:37: [2024-10-29 12:39:37] iter = 11330, loss = 5.8095
2024-10-29 12:39:37: [2024-10-29 12:39:37] iter = 11340, loss = 2.5951
2024-10-29 12:39:37: [2024-10-29 12:39:37] iter = 11350, loss = 10.6728
2024-10-29 12:39:38: [2024-10-29 12:39:38] iter = 11360, loss = 14.0403
2024-10-29 12:39:39: [2024-10-29 12:39:39] iter = 11370, loss = 4.8615
2024-10-29 12:39:39: [2024-10-29 12:39:39] iter = 11380, loss = 5.7918
2024-10-29 12:39:40: [2024-10-29 12:39:40] iter = 11390, loss = 2.3187
2024-10-29 12:39:40: [2024-10-29 12:39:40] iter = 11400, loss = 5.2498
2024-10-29 12:39:41: [2024-10-29 12:39:41] iter = 11410, loss = 14.0684
2024-10-29 12:39:41: [2024-10-29 12:39:41] iter = 11420, loss = 2.0847
2024-10-29 12:39:42: [2024-10-29 12:39:42] iter = 11430, loss = 29.4173
2024-10-29 12:39:42: [2024-10-29 12:39:42] iter = 11440, loss = 63.8192
2024-10-29 12:39:43: [2024-10-29 12:39:43] iter = 11450, loss = 3.1639
2024-10-29 12:39:43: [2024-10-29 12:39:43] iter = 11460, loss = 5.5636
2024-10-29 12:39:44: [2024-10-29 12:39:44] iter = 11470, loss = 11.5360
2024-10-29 12:39:44: [2024-10-29 12:39:44] iter = 11480, loss = 2.6704
2024-10-29 12:39:45: [2024-10-29 12:39:45] iter = 11490, loss = 3.0484
2024-10-29 12:39:45: [2024-10-29 12:39:45] iter = 11500, loss = 7.5388
2024-10-29 12:39:46: [2024-10-29 12:39:46] iter = 11510, loss = 26.5674
2024-10-29 12:39:46: [2024-10-29 12:39:46] iter = 11520, loss = 10.1669
2024-10-29 12:39:47: [2024-10-29 12:39:47] iter = 11530, loss = 3.7780
2024-10-29 12:39:47: [2024-10-29 12:39:47] iter = 11540, loss = 2.5970
2024-10-29 12:39:48: [2024-10-29 12:39:48] iter = 11550, loss = 4.1902
2024-10-29 12:39:48: [2024-10-29 12:39:48] iter = 11560, loss = 2.2939
2024-10-29 12:39:49: [2024-10-29 12:39:49] iter = 11570, loss = 19.4528
2024-10-29 12:39:49: [2024-10-29 12:39:49] iter = 11580, loss = 3.4176
2024-10-29 12:39:50: [2024-10-29 12:39:50] iter = 11590, loss = 3.0685
2024-10-29 12:39:51: [2024-10-29 12:39:51] iter = 11600, loss = 3.6469
2024-10-29 12:39:51: [2024-10-29 12:39:51] iter = 11610, loss = 9.6041
2024-10-29 12:39:52: [2024-10-29 12:39:52] iter = 11620, loss = 3.9899
2024-10-29 12:39:53: [2024-10-29 12:39:53] iter = 11630, loss = 3.6294
2024-10-29 12:39:53: [2024-10-29 12:39:53] iter = 11640, loss = 7.0874
2024-10-29 12:39:54: [2024-10-29 12:39:54] iter = 11650, loss = 5.8498
2024-10-29 12:39:55: [2024-10-29 12:39:55] iter = 11660, loss = 27.9386
2024-10-29 12:39:56: [2024-10-29 12:39:56] iter = 11670, loss = 2.1178
2024-10-29 12:39:56: [2024-10-29 12:39:56] iter = 11680, loss = 2.8747
2024-10-29 12:39:57: [2024-10-29 12:39:57] iter = 11690, loss = 7.5275
2024-10-29 12:39:58: [2024-10-29 12:39:58] iter = 11700, loss = 2.1420
2024-10-29 12:39:58: [2024-10-29 12:39:58] iter = 11710, loss = 5.9120
2024-10-29 12:39:59: [2024-10-29 12:39:59] iter = 11720, loss = 6.2623
2024-10-29 12:40:00: [2024-10-29 12:40:00] iter = 11730, loss = 2.3105
2024-10-29 12:40:00: [2024-10-29 12:40:00] iter = 11740, loss = 28.8018
2024-10-29 12:40:01: [2024-10-29 12:40:01] iter = 11750, loss = 3.5678
2024-10-29 12:40:01: [2024-10-29 12:40:01] iter = 11760, loss = 4.8818
2024-10-29 12:40:02: [2024-10-29 12:40:02] iter = 11770, loss = 11.4577
2024-10-29 12:40:02: [2024-10-29 12:40:02] iter = 11780, loss = 8.7637
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 11790, loss = 3.7847
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 11800, loss = 3.4012
2024-10-29 12:40:03: [2024-10-29 12:40:03] iter = 11810, loss = 5.8038
2024-10-29 12:40:04: [2024-10-29 12:40:04] iter = 11820, loss = 2.8981
2024-10-29 12:40:05: [2024-10-29 12:40:05] iter = 11830, loss = 31.3818
2024-10-29 12:40:05: [2024-10-29 12:40:05] iter = 11840, loss = 22.3031
2024-10-29 12:40:06: [2024-10-29 12:40:06] iter = 11850, loss = 2.7788
2024-10-29 12:40:06: [2024-10-29 12:40:06] iter = 11860, loss = 3.6879
2024-10-29 12:40:07: [2024-10-29 12:40:07] iter = 11870, loss = 14.0511
2024-10-29 12:40:07: [2024-10-29 12:40:07] iter = 11880, loss = 2.1357
2024-10-29 12:40:08: [2024-10-29 12:40:08] iter = 11890, loss = 6.7251
2024-10-29 12:40:09: [2024-10-29 12:40:09] iter = 11900, loss = 4.9215
2024-10-29 12:40:09: [2024-10-29 12:40:09] iter = 11910, loss = 6.0259
2024-10-29 12:40:10: [2024-10-29 12:40:10] iter = 11920, loss = 2.7452
2024-10-29 12:40:10: [2024-10-29 12:40:10] iter = 11930, loss = 4.5868
2024-10-29 12:40:10: [2024-10-29 12:40:10] iter = 11940, loss = 5.7825
2024-10-29 12:40:11: [2024-10-29 12:40:11] iter = 11950, loss = 11.1128
2024-10-29 12:40:11: [2024-10-29 12:40:11] iter = 11960, loss = 25.7757
2024-10-29 12:40:12: [2024-10-29 12:40:12] iter = 11970, loss = 5.8292
2024-10-29 12:40:12: [2024-10-29 12:40:12] iter = 11980, loss = 9.1467
2024-10-29 12:40:13: [2024-10-29 12:40:13] iter = 11990, loss = 2.6356
2024-10-29 12:40:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 12:40:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:40:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 13863}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:41: Evaluate 5 random ConvNet, ACCmean = 0.4988 ACCstd = 0.0132
-------------------------
2024-10-29 12:40:41: Evaluate 5 random ConvNet, SENmean = 0.4988 SENstd = 0.0132
-------------------------
2024-10-29 12:40:41: Evaluate 5 random ConvNet, SPEmean = 0.8329 SPEstd = 0.0044
-------------------------
2024-10-29 12:40:41: Evaluate 5 random ConvNet, F!mean = 0.4369 F!std = 0.0201
-------------------------
2024-10-29 12:40:41: Evaluate 5 random ConvNet, mean = 0.4988 std = 0.0132
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:41: [2024-10-29 12:40:41] iter = 12000, loss = 4.0145
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:40:42: [2024-10-29 12:40:42] iter = 12010, loss = 42.1281
2024-10-29 12:40:42: [2024-10-29 12:40:42] iter = 12020, loss = 3.0700
2024-10-29 12:40:43: [2024-10-29 12:40:43] iter = 12030, loss = 5.5216
2024-10-29 12:40:43: [2024-10-29 12:40:43] iter = 12040, loss = 2.6522
2024-10-29 12:40:44: [2024-10-29 12:40:44] iter = 12050, loss = 4.2483
2024-10-29 12:40:44: [2024-10-29 12:40:44] iter = 12060, loss = 8.9082
2024-10-29 12:40:45: [2024-10-29 12:40:45] iter = 12070, loss = 26.8770
2024-10-29 12:40:45: [2024-10-29 12:40:45] iter = 12080, loss = 2.7467
2024-10-29 12:40:46: [2024-10-29 12:40:46] iter = 12090, loss = 3.1184
2024-10-29 12:40:46: [2024-10-29 12:40:46] iter = 12100, loss = 5.8226
2024-10-29 12:40:47: [2024-10-29 12:40:47] iter = 12110, loss = 3.4906
2024-10-29 12:40:47: [2024-10-29 12:40:47] iter = 12120, loss = 10.5674
2024-10-29 12:40:48: [2024-10-29 12:40:48] iter = 12130, loss = 3.7681
2024-10-29 12:40:48: [2024-10-29 12:40:48] iter = 12140, loss = 21.0900
2024-10-29 12:40:49: [2024-10-29 12:40:49] iter = 12150, loss = 5.8474
2024-10-29 12:40:49: [2024-10-29 12:40:49] iter = 12160, loss = 4.1301
2024-10-29 12:40:50: [2024-10-29 12:40:50] iter = 12170, loss = 6.3615
2024-10-29 12:40:50: [2024-10-29 12:40:50] iter = 12180, loss = 3.8131
2024-10-29 12:40:51: [2024-10-29 12:40:51] iter = 12190, loss = 3.5816
2024-10-29 12:40:51: [2024-10-29 12:40:51] iter = 12200, loss = 1.8959
2024-10-29 12:40:52: [2024-10-29 12:40:52] iter = 12210, loss = 4.8608
2024-10-29 12:40:52: [2024-10-29 12:40:52] iter = 12220, loss = 14.7513
2024-10-29 12:40:53: [2024-10-29 12:40:53] iter = 12230, loss = 3.6203
2024-10-29 12:40:53: [2024-10-29 12:40:53] iter = 12240, loss = 38.4256
2024-10-29 12:40:54: [2024-10-29 12:40:54] iter = 12250, loss = 4.6366
2024-10-29 12:40:54: [2024-10-29 12:40:54] iter = 12260, loss = 2.4546
2024-10-29 12:40:55: [2024-10-29 12:40:55] iter = 12270, loss = 3.0243
2024-10-29 12:40:55: [2024-10-29 12:40:55] iter = 12280, loss = 4.0852
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 12290, loss = 2.4139
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 12300, loss = 2.7805
2024-10-29 12:40:56: [2024-10-29 12:40:56] iter = 12310, loss = 9.1589
2024-10-29 12:40:57: [2024-10-29 12:40:57] iter = 12320, loss = 3.5738
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 12330, loss = 11.7639
2024-10-29 12:40:58: [2024-10-29 12:40:58] iter = 12340, loss = 7.9793
2024-10-29 12:40:59: [2024-10-29 12:40:59] iter = 12350, loss = 5.1281
2024-10-29 12:40:59: [2024-10-29 12:40:59] iter = 12360, loss = 3.5007
2024-10-29 12:41:00: [2024-10-29 12:41:00] iter = 12370, loss = 9.5590
2024-10-29 12:41:00: [2024-10-29 12:41:00] iter = 12380, loss = 13.8382
2024-10-29 12:41:01: [2024-10-29 12:41:01] iter = 12390, loss = 46.4241
2024-10-29 12:41:01: [2024-10-29 12:41:01] iter = 12400, loss = 7.6879
2024-10-29 12:41:02: [2024-10-29 12:41:02] iter = 12410, loss = 15.8524
2024-10-29 12:41:02: [2024-10-29 12:41:02] iter = 12420, loss = 6.1885
2024-10-29 12:41:03: [2024-10-29 12:41:03] iter = 12430, loss = 4.5806
2024-10-29 12:41:03: [2024-10-29 12:41:03] iter = 12440, loss = 14.1594
2024-10-29 12:41:04: [2024-10-29 12:41:04] iter = 12450, loss = 8.8481
2024-10-29 12:41:04: [2024-10-29 12:41:04] iter = 12460, loss = 2.8238
2024-10-29 12:41:05: [2024-10-29 12:41:05] iter = 12470, loss = 4.5581
2024-10-29 12:41:05: [2024-10-29 12:41:05] iter = 12480, loss = 2.4852
2024-10-29 12:41:06: [2024-10-29 12:41:06] iter = 12490, loss = 2.3211
2024-10-29 12:41:07: [2024-10-29 12:41:07] iter = 12500, loss = 53.3743
2024-10-29 12:41:07: [2024-10-29 12:41:07] iter = 12510, loss = 4.3601
2024-10-29 12:41:08: [2024-10-29 12:41:08] iter = 12520, loss = 3.2235
2024-10-29 12:41:09: [2024-10-29 12:41:09] iter = 12530, loss = 19.3265
2024-10-29 12:41:10: [2024-10-29 12:41:10] iter = 12540, loss = 6.1697
2024-10-29 12:41:10: [2024-10-29 12:41:10] iter = 12550, loss = 16.0797
2024-10-29 12:41:11: [2024-10-29 12:41:11] iter = 12560, loss = 4.6619
2024-10-29 12:41:12: [2024-10-29 12:41:12] iter = 12570, loss = 10.7614
2024-10-29 12:41:12: [2024-10-29 12:41:12] iter = 12580, loss = 6.2756
2024-10-29 12:41:13: [2024-10-29 12:41:13] iter = 12590, loss = 7.0104
2024-10-29 12:41:14: [2024-10-29 12:41:14] iter = 12600, loss = 4.5326
2024-10-29 12:41:14: [2024-10-29 12:41:14] iter = 12610, loss = 38.6210
2024-10-29 12:41:15: [2024-10-29 12:41:15] iter = 12620, loss = 6.7370
2024-10-29 12:41:15: [2024-10-29 12:41:15] iter = 12630, loss = 7.7473
2024-10-29 12:41:16: [2024-10-29 12:41:16] iter = 12640, loss = 4.8650
2024-10-29 12:41:17: [2024-10-29 12:41:17] iter = 12650, loss = 2.5699
2024-10-29 12:41:17: [2024-10-29 12:41:17] iter = 12660, loss = 4.4857
2024-10-29 12:41:18: [2024-10-29 12:41:18] iter = 12670, loss = 12.3135
2024-10-29 12:41:18: [2024-10-29 12:41:18] iter = 12680, loss = 32.9387
2024-10-29 12:41:19: [2024-10-29 12:41:19] iter = 12690, loss = 3.2160
2024-10-29 12:41:19: [2024-10-29 12:41:19] iter = 12700, loss = 13.3441
2024-10-29 12:41:20: [2024-10-29 12:41:20] iter = 12710, loss = 6.9008
2024-10-29 12:41:20: [2024-10-29 12:41:20] iter = 12720, loss = 5.1317
2024-10-29 12:41:21: [2024-10-29 12:41:21] iter = 12730, loss = 3.8341
2024-10-29 12:41:22: [2024-10-29 12:41:22] iter = 12740, loss = 4.4647
2024-10-29 12:41:22: [2024-10-29 12:41:22] iter = 12750, loss = 12.6895
2024-10-29 12:41:23: [2024-10-29 12:41:23] iter = 12760, loss = 6.0522
2024-10-29 12:41:24: [2024-10-29 12:41:24] iter = 12770, loss = 15.7508
2024-10-29 12:41:24: [2024-10-29 12:41:24] iter = 12780, loss = 4.4684
2024-10-29 12:41:25: [2024-10-29 12:41:25] iter = 12790, loss = 7.4381
2024-10-29 12:41:25: [2024-10-29 12:41:25] iter = 12800, loss = 3.4210
2024-10-29 12:41:26: [2024-10-29 12:41:26] iter = 12810, loss = 29.7712
2024-10-29 12:41:26: [2024-10-29 12:41:26] iter = 12820, loss = 5.2549
2024-10-29 12:41:27: [2024-10-29 12:41:27] iter = 12830, loss = 47.4456
2024-10-29 12:41:27: [2024-10-29 12:41:27] iter = 12840, loss = 7.9670
2024-10-29 12:41:28: [2024-10-29 12:41:28] iter = 12850, loss = 7.7940
2024-10-29 12:41:28: [2024-10-29 12:41:28] iter = 12860, loss = 9.3215
2024-10-29 12:41:29: [2024-10-29 12:41:29] iter = 12870, loss = 8.0553
2024-10-29 12:41:30: [2024-10-29 12:41:30] iter = 12880, loss = 8.0357
2024-10-29 12:41:30: [2024-10-29 12:41:30] iter = 12890, loss = 8.5639
2024-10-29 12:41:31: [2024-10-29 12:41:31] iter = 12900, loss = 2.2949
2024-10-29 12:41:31: [2024-10-29 12:41:31] iter = 12910, loss = 17.7678
2024-10-29 12:41:32: [2024-10-29 12:41:32] iter = 12920, loss = 8.3557
2024-10-29 12:41:32: [2024-10-29 12:41:32] iter = 12930, loss = 5.3530
2024-10-29 12:41:33: [2024-10-29 12:41:33] iter = 12940, loss = 4.6891
2024-10-29 12:41:33: [2024-10-29 12:41:33] iter = 12950, loss = 9.8932
2024-10-29 12:41:34: [2024-10-29 12:41:34] iter = 12960, loss = 23.0650
2024-10-29 12:41:35: [2024-10-29 12:41:35] iter = 12970, loss = 4.1141
2024-10-29 12:41:35: [2024-10-29 12:41:35] iter = 12980, loss = 4.8921
2024-10-29 12:41:36: [2024-10-29 12:41:36] iter = 12990, loss = 4.2515
2024-10-29 12:41:36: [2024-10-29 12:41:36] iter = 13000, loss = 27.1317
2024-10-29 12:41:37: [2024-10-29 12:41:37] iter = 13010, loss = 3.9728
2024-10-29 12:41:38: [2024-10-29 12:41:38] iter = 13020, loss = 10.9047
2024-10-29 12:41:39: [2024-10-29 12:41:39] iter = 13030, loss = 33.8007
2024-10-29 12:41:39: [2024-10-29 12:41:39] iter = 13040, loss = 3.4269
2024-10-29 12:41:40: [2024-10-29 12:41:40] iter = 13050, loss = 2.7242
2024-10-29 12:41:40: [2024-10-29 12:41:40] iter = 13060, loss = 11.5517
2024-10-29 12:41:41: [2024-10-29 12:41:41] iter = 13070, loss = 2.5172
2024-10-29 12:41:41: [2024-10-29 12:41:41] iter = 13080, loss = 4.6585
2024-10-29 12:41:42: [2024-10-29 12:41:42] iter = 13090, loss = 4.7307
2024-10-29 12:41:42: [2024-10-29 12:41:42] iter = 13100, loss = 2.6745
2024-10-29 12:41:43: [2024-10-29 12:41:43] iter = 13110, loss = 12.9724
2024-10-29 12:41:43: [2024-10-29 12:41:43] iter = 13120, loss = 3.6887
2024-10-29 12:41:44: [2024-10-29 12:41:44] iter = 13130, loss = 8.8919
2024-10-29 12:41:45: [2024-10-29 12:41:45] iter = 13140, loss = 19.4439
2024-10-29 12:41:45: [2024-10-29 12:41:45] iter = 13150, loss = 4.3919
2024-10-29 12:41:46: [2024-10-29 12:41:46] iter = 13160, loss = 2.1673
2024-10-29 12:41:46: [2024-10-29 12:41:46] iter = 13170, loss = 2.7746
2024-10-29 12:41:47: [2024-10-29 12:41:47] iter = 13180, loss = 5.2854
2024-10-29 12:41:47: [2024-10-29 12:41:47] iter = 13190, loss = 2.6281
2024-10-29 12:41:48: [2024-10-29 12:41:48] iter = 13200, loss = 9.6528
2024-10-29 12:41:48: [2024-10-29 12:41:48] iter = 13210, loss = 3.6646
2024-10-29 12:41:49: [2024-10-29 12:41:49] iter = 13220, loss = 10.0670
2024-10-29 12:41:49: [2024-10-29 12:41:49] iter = 13230, loss = 2.4689
2024-10-29 12:41:50: [2024-10-29 12:41:50] iter = 13240, loss = 2.7210
2024-10-29 12:41:50: [2024-10-29 12:41:50] iter = 13250, loss = 3.7117
2024-10-29 12:41:51: [2024-10-29 12:41:51] iter = 13260, loss = 2.2453
2024-10-29 12:41:51: [2024-10-29 12:41:51] iter = 13270, loss = 5.0395
2024-10-29 12:41:52: [2024-10-29 12:41:52] iter = 13280, loss = 3.7437
2024-10-29 12:41:52: [2024-10-29 12:41:52] iter = 13290, loss = 19.3600
2024-10-29 12:41:53: [2024-10-29 12:41:53] iter = 13300, loss = 5.9974
2024-10-29 12:41:53: [2024-10-29 12:41:53] iter = 13310, loss = 3.3274
2024-10-29 12:41:54: [2024-10-29 12:41:54] iter = 13320, loss = 47.7074
2024-10-29 12:41:54: [2024-10-29 12:41:54] iter = 13330, loss = 3.0706
2024-10-29 12:41:55: [2024-10-29 12:41:55] iter = 13340, loss = 19.6757
2024-10-29 12:41:55: [2024-10-29 12:41:55] iter = 13350, loss = 2.9714
2024-10-29 12:41:56: [2024-10-29 12:41:56] iter = 13360, loss = 5.0473
2024-10-29 12:41:56: [2024-10-29 12:41:56] iter = 13370, loss = 4.7498
2024-10-29 12:41:57: [2024-10-29 12:41:57] iter = 13380, loss = 3.0954
2024-10-29 12:41:57: [2024-10-29 12:41:57] iter = 13390, loss = 6.5895
2024-10-29 12:41:58: [2024-10-29 12:41:58] iter = 13400, loss = 7.5187
2024-10-29 12:41:58: [2024-10-29 12:41:58] iter = 13410, loss = 8.7757
2024-10-29 12:41:59: [2024-10-29 12:41:59] iter = 13420, loss = 5.5059
2024-10-29 12:41:59: [2024-10-29 12:41:59] iter = 13430, loss = 5.3968
2024-10-29 12:42:00: [2024-10-29 12:42:00] iter = 13440, loss = 4.2123
2024-10-29 12:42:00: [2024-10-29 12:42:00] iter = 13450, loss = 5.8292
2024-10-29 12:42:01: [2024-10-29 12:42:01] iter = 13460, loss = 9.4426
2024-10-29 12:42:01: [2024-10-29 12:42:01] iter = 13470, loss = 11.9647
2024-10-29 12:42:02: [2024-10-29 12:42:02] iter = 13480, loss = 6.2627
2024-10-29 12:42:02: [2024-10-29 12:42:02] iter = 13490, loss = 34.9521
2024-10-29 12:42:03: [2024-10-29 12:42:03] iter = 13500, loss = 5.2024
2024-10-29 12:42:03: [2024-10-29 12:42:03] iter = 13510, loss = 8.5347
2024-10-29 12:42:04: [2024-10-29 12:42:04] iter = 13520, loss = 3.6226
2024-10-29 12:42:04: [2024-10-29 12:42:04] iter = 13530, loss = 5.2109
2024-10-29 12:42:05: [2024-10-29 12:42:05] iter = 13540, loss = 9.8645
2024-10-29 12:42:05: [2024-10-29 12:42:05] iter = 13550, loss = 3.2541
2024-10-29 12:42:06: [2024-10-29 12:42:06] iter = 13560, loss = 1.8141
2024-10-29 12:42:06: [2024-10-29 12:42:06] iter = 13570, loss = 5.4462
2024-10-29 12:42:07: [2024-10-29 12:42:07] iter = 13580, loss = 6.8925
2024-10-29 12:42:07: [2024-10-29 12:42:07] iter = 13590, loss = 8.7007
2024-10-29 12:42:08: [2024-10-29 12:42:08] iter = 13600, loss = 15.4310
2024-10-29 12:42:08: [2024-10-29 12:42:08] iter = 13610, loss = 4.4574
2024-10-29 12:42:09: [2024-10-29 12:42:09] iter = 13620, loss = 3.9178
2024-10-29 12:42:09: [2024-10-29 12:42:09] iter = 13630, loss = 4.0393
2024-10-29 12:42:09: [2024-10-29 12:42:09] iter = 13640, loss = 3.0580
2024-10-29 12:42:10: [2024-10-29 12:42:10] iter = 13650, loss = 4.0571
2024-10-29 12:42:11: [2024-10-29 12:42:11] iter = 13660, loss = 6.4090
2024-10-29 12:42:11: [2024-10-29 12:42:11] iter = 13670, loss = 6.6907
2024-10-29 12:42:12: [2024-10-29 12:42:12] iter = 13680, loss = 3.3438
2024-10-29 12:42:12: [2024-10-29 12:42:12] iter = 13690, loss = 3.1783
2024-10-29 12:42:13: [2024-10-29 12:42:13] iter = 13700, loss = 3.9787
2024-10-29 12:42:13: [2024-10-29 12:42:13] iter = 13710, loss = 36.5601
2024-10-29 12:42:14: [2024-10-29 12:42:14] iter = 13720, loss = 4.0430
2024-10-29 12:42:14: [2024-10-29 12:42:14] iter = 13730, loss = 2.6493
2024-10-29 12:42:15: [2024-10-29 12:42:15] iter = 13740, loss = 4.9460
2024-10-29 12:42:15: [2024-10-29 12:42:15] iter = 13750, loss = 6.8398
2024-10-29 12:42:16: [2024-10-29 12:42:16] iter = 13760, loss = 8.9717
2024-10-29 12:42:17: [2024-10-29 12:42:17] iter = 13770, loss = 2.9696
2024-10-29 12:42:17: [2024-10-29 12:42:17] iter = 13780, loss = 3.0757
2024-10-29 12:42:18: [2024-10-29 12:42:18] iter = 13790, loss = 3.6246
2024-10-29 12:42:18: [2024-10-29 12:42:18] iter = 13800, loss = 47.3710
2024-10-29 12:42:19: [2024-10-29 12:42:19] iter = 13810, loss = 6.7956
2024-10-29 12:42:20: [2024-10-29 12:42:20] iter = 13820, loss = 21.5444
2024-10-29 12:42:20: [2024-10-29 12:42:20] iter = 13830, loss = 32.8836
2024-10-29 12:42:21: [2024-10-29 12:42:21] iter = 13840, loss = 4.3960
2024-10-29 12:42:21: [2024-10-29 12:42:21] iter = 13850, loss = 3.7677
2024-10-29 12:42:22: [2024-10-29 12:42:22] iter = 13860, loss = 2.9562
2024-10-29 12:42:23: [2024-10-29 12:42:23] iter = 13870, loss = 3.9950
2024-10-29 12:42:23: [2024-10-29 12:42:23] iter = 13880, loss = 7.2457
2024-10-29 12:42:24: [2024-10-29 12:42:24] iter = 13890, loss = 6.0565
2024-10-29 12:42:24: [2024-10-29 12:42:24] iter = 13900, loss = 2.6147
2024-10-29 12:42:25: [2024-10-29 12:42:25] iter = 13910, loss = 6.9194
2024-10-29 12:42:26: [2024-10-29 12:42:26] iter = 13920, loss = 6.1704
2024-10-29 12:42:26: [2024-10-29 12:42:26] iter = 13930, loss = 31.5091
2024-10-29 12:42:27: [2024-10-29 12:42:27] iter = 13940, loss = 7.4829
2024-10-29 12:42:28: [2024-10-29 12:42:28] iter = 13950, loss = 4.2210
2024-10-29 12:42:28: [2024-10-29 12:42:28] iter = 13960, loss = 3.2401
2024-10-29 12:42:29: [2024-10-29 12:42:29] iter = 13970, loss = 7.5380
2024-10-29 12:42:29: [2024-10-29 12:42:29] iter = 13980, loss = 26.1227
2024-10-29 12:42:30: [2024-10-29 12:42:30] iter = 13990, loss = 2.0415
2024-10-29 12:42:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 12:42:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:42:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50884}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:42:59: Evaluate 5 random ConvNet, ACCmean = 0.4586 ACCstd = 0.0130
-------------------------
2024-10-29 12:42:59: Evaluate 5 random ConvNet, SENmean = 0.4586 SENstd = 0.0130
-------------------------
2024-10-29 12:42:59: Evaluate 5 random ConvNet, SPEmean = 0.8195 SPEstd = 0.0043
-------------------------
2024-10-29 12:42:59: Evaluate 5 random ConvNet, F!mean = 0.4045 F!std = 0.0170
-------------------------
2024-10-29 12:42:59: Evaluate 5 random ConvNet, mean = 0.4586 std = 0.0130
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:42:59: [2024-10-29 12:42:59] iter = 14000, loss = 2.9971
2024-10-29 12:42:59: [2024-10-29 12:42:59] iter = 14010, loss = 5.0895
2024-10-29 12:43:00: [2024-10-29 12:43:00] iter = 14020, loss = 4.1506
2024-10-29 12:43:00: [2024-10-29 12:43:00] iter = 14030, loss = 8.3485
2024-10-29 12:43:01: [2024-10-29 12:43:01] iter = 14040, loss = 19.6940
2024-10-29 12:43:01: [2024-10-29 12:43:01] iter = 14050, loss = 16.8260
2024-10-29 12:43:02: [2024-10-29 12:43:02] iter = 14060, loss = 6.9915
2024-10-29 12:43:02: [2024-10-29 12:43:02] iter = 14070, loss = 4.8550
2024-10-29 12:43:03: [2024-10-29 12:43:03] iter = 14080, loss = 7.8308
2024-10-29 12:43:03: [2024-10-29 12:43:03] iter = 14090, loss = 2.6746
2024-10-29 12:43:04: [2024-10-29 12:43:04] iter = 14100, loss = 16.5685
2024-10-29 12:43:04: [2024-10-29 12:43:04] iter = 14110, loss = 1.9346
2024-10-29 12:43:05: [2024-10-29 12:43:05] iter = 14120, loss = 8.1780
2024-10-29 12:43:05: [2024-10-29 12:43:05] iter = 14130, loss = 12.6150
2024-10-29 12:43:06: [2024-10-29 12:43:06] iter = 14140, loss = 7.3771
2024-10-29 12:43:06: [2024-10-29 12:43:06] iter = 14150, loss = 34.0447
2024-10-29 12:43:07: [2024-10-29 12:43:07] iter = 14160, loss = 2.8000
2024-10-29 12:43:07: [2024-10-29 12:43:07] iter = 14170, loss = 6.0574
2024-10-29 12:43:08: [2024-10-29 12:43:08] iter = 14180, loss = 7.3226
2024-10-29 12:43:08: [2024-10-29 12:43:08] iter = 14190, loss = 10.1530
2024-10-29 12:43:09: [2024-10-29 12:43:09] iter = 14200, loss = 13.1643
2024-10-29 12:43:09: [2024-10-29 12:43:09] iter = 14210, loss = 3.3070
2024-10-29 12:43:10: [2024-10-29 12:43:10] iter = 14220, loss = 3.6836
2024-10-29 12:43:10: [2024-10-29 12:43:10] iter = 14230, loss = 6.4625
2024-10-29 12:43:11: [2024-10-29 12:43:11] iter = 14240, loss = 9.1800
2024-10-29 12:43:11: [2024-10-29 12:43:11] iter = 14250, loss = 15.5055
2024-10-29 12:43:12: [2024-10-29 12:43:12] iter = 14260, loss = 11.1732
2024-10-29 12:43:12: [2024-10-29 12:43:12] iter = 14270, loss = 28.9798
2024-10-29 12:43:13: [2024-10-29 12:43:13] iter = 14280, loss = 4.7861
2024-10-29 12:43:13: [2024-10-29 12:43:13] iter = 14290, loss = 30.2646
2024-10-29 12:43:14: [2024-10-29 12:43:14] iter = 14300, loss = 2.8088
2024-10-29 12:43:14: [2024-10-29 12:43:14] iter = 14310, loss = 29.1056
2024-10-29 12:43:15: [2024-10-29 12:43:15] iter = 14320, loss = 7.4618
2024-10-29 12:43:15: [2024-10-29 12:43:15] iter = 14330, loss = 2.9148
2024-10-29 12:43:16: [2024-10-29 12:43:16] iter = 14340, loss = 8.5084
2024-10-29 12:43:16: [2024-10-29 12:43:16] iter = 14350, loss = 18.8798
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 14360, loss = 6.7316
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 14370, loss = 30.6309
2024-10-29 12:43:17: [2024-10-29 12:43:17] iter = 14380, loss = 3.6307
2024-10-29 12:43:18: [2024-10-29 12:43:18] iter = 14390, loss = 4.4227
2024-10-29 12:43:18: [2024-10-29 12:43:18] iter = 14400, loss = 3.7056
2024-10-29 12:43:19: [2024-10-29 12:43:19] iter = 14410, loss = 2.9681
2024-10-29 12:43:19: [2024-10-29 12:43:19] iter = 14420, loss = 4.3519
2024-10-29 12:43:20: [2024-10-29 12:43:20] iter = 14430, loss = 3.3734
2024-10-29 12:43:20: [2024-10-29 12:43:20] iter = 14440, loss = 5.9319
2024-10-29 12:43:21: [2024-10-29 12:43:21] iter = 14450, loss = 5.3832
2024-10-29 12:43:21: [2024-10-29 12:43:21] iter = 14460, loss = 2.8271
2024-10-29 12:43:22: [2024-10-29 12:43:22] iter = 14470, loss = 10.3614
2024-10-29 12:43:22: [2024-10-29 12:43:22] iter = 14480, loss = 9.3332
2024-10-29 12:43:23: [2024-10-29 12:43:23] iter = 14490, loss = 4.0256
2024-10-29 12:43:23: [2024-10-29 12:43:23] iter = 14500, loss = 4.7967
2024-10-29 12:43:24: [2024-10-29 12:43:24] iter = 14510, loss = 2.2671
2024-10-29 12:43:24: [2024-10-29 12:43:24] iter = 14520, loss = 18.2161
2024-10-29 12:43:25: [2024-10-29 12:43:25] iter = 14530, loss = 9.4795
2024-10-29 12:43:25: [2024-10-29 12:43:25] iter = 14540, loss = 4.3261
2024-10-29 12:43:26: [2024-10-29 12:43:26] iter = 14550, loss = 2.7042
2024-10-29 12:43:26: [2024-10-29 12:43:26] iter = 14560, loss = 4.9733
2024-10-29 12:43:27: [2024-10-29 12:43:27] iter = 14570, loss = 3.4634
2024-10-29 12:43:27: [2024-10-29 12:43:27] iter = 14580, loss = 6.4384
2024-10-29 12:43:28: [2024-10-29 12:43:28] iter = 14590, loss = 5.6643
2024-10-29 12:43:28: [2024-10-29 12:43:28] iter = 14600, loss = 2.9734
2024-10-29 12:43:29: [2024-10-29 12:43:29] iter = 14610, loss = 3.7890
2024-10-29 12:43:29: [2024-10-29 12:43:29] iter = 14620, loss = 18.9185
2024-10-29 12:43:30: [2024-10-29 12:43:30] iter = 14630, loss = 3.1708
2024-10-29 12:43:30: [2024-10-29 12:43:30] iter = 14640, loss = 23.3628
2024-10-29 12:43:31: [2024-10-29 12:43:31] iter = 14650, loss = 6.8070
2024-10-29 12:43:31: [2024-10-29 12:43:31] iter = 14660, loss = 23.2086
2024-10-29 12:43:32: [2024-10-29 12:43:32] iter = 14670, loss = 20.6304
2024-10-29 12:43:32: [2024-10-29 12:43:32] iter = 14680, loss = 4.3423
2024-10-29 12:43:33: [2024-10-29 12:43:33] iter = 14690, loss = 3.2182
2024-10-29 12:43:33: [2024-10-29 12:43:33] iter = 14700, loss = 3.2660
2024-10-29 12:43:34: [2024-10-29 12:43:34] iter = 14710, loss = 3.7446
2024-10-29 12:43:35: [2024-10-29 12:43:35] iter = 14720, loss = 59.2387
2024-10-29 12:43:35: [2024-10-29 12:43:35] iter = 14730, loss = 4.1070
2024-10-29 12:43:36: [2024-10-29 12:43:36] iter = 14740, loss = 5.0302
2024-10-29 12:43:37: [2024-10-29 12:43:37] iter = 14750, loss = 12.2869
2024-10-29 12:43:38: [2024-10-29 12:43:38] iter = 14760, loss = 31.9799
2024-10-29 12:43:38: [2024-10-29 12:43:38] iter = 14770, loss = 33.2150
2024-10-29 12:43:39: [2024-10-29 12:43:39] iter = 14780, loss = 9.3151
2024-10-29 12:43:40: [2024-10-29 12:43:40] iter = 14790, loss = 8.7636
2024-10-29 12:43:41: [2024-10-29 12:43:41] iter = 14800, loss = 4.0368
2024-10-29 12:43:41: [2024-10-29 12:43:41] iter = 14810, loss = 8.9123
2024-10-29 12:43:42: [2024-10-29 12:43:42] iter = 14820, loss = 4.8429
2024-10-29 12:43:43: [2024-10-29 12:43:43] iter = 14830, loss = 4.1037
2024-10-29 12:43:43: [2024-10-29 12:43:43] iter = 14840, loss = 7.3153
2024-10-29 12:43:44: [2024-10-29 12:43:44] iter = 14850, loss = 8.5853
2024-10-29 12:43:45: [2024-10-29 12:43:45] iter = 14860, loss = 13.9821
2024-10-29 12:43:45: [2024-10-29 12:43:45] iter = 14870, loss = 3.4155
2024-10-29 12:43:46: [2024-10-29 12:43:46] iter = 14880, loss = 3.3814
2024-10-29 12:43:46: [2024-10-29 12:43:46] iter = 14890, loss = 3.0695
2024-10-29 12:43:47: [2024-10-29 12:43:47] iter = 14900, loss = 8.5966
2024-10-29 12:43:48: [2024-10-29 12:43:48] iter = 14910, loss = 4.8422
2024-10-29 12:43:48: [2024-10-29 12:43:48] iter = 14920, loss = 18.7617
2024-10-29 12:43:48: [2024-10-29 12:43:48] iter = 14930, loss = 6.4830
2024-10-29 12:43:49: [2024-10-29 12:43:49] iter = 14940, loss = 3.2436
2024-10-29 12:43:49: [2024-10-29 12:43:49] iter = 14950, loss = 8.5471
2024-10-29 12:43:50: [2024-10-29 12:43:50] iter = 14960, loss = 51.9549
2024-10-29 12:43:50: [2024-10-29 12:43:50] iter = 14970, loss = 7.1645
2024-10-29 12:43:51: [2024-10-29 12:43:51] iter = 14980, loss = 30.2177
2024-10-29 12:43:51: [2024-10-29 12:43:51] iter = 14990, loss = 2.7671
2024-10-29 12:43:52: [2024-10-29 12:43:52] iter = 15000, loss = 21.9336
2024-10-29 12:43:53: [2024-10-29 12:43:53] iter = 15010, loss = 56.2669
2024-10-29 12:43:53: [2024-10-29 12:43:53] iter = 15020, loss = 3.2669
2024-10-29 12:43:54: [2024-10-29 12:43:54] iter = 15030, loss = 13.8142
2024-10-29 12:43:54: [2024-10-29 12:43:54] iter = 15040, loss = 3.0656
2024-10-29 12:43:55: [2024-10-29 12:43:55] iter = 15050, loss = 5.2227
2024-10-29 12:43:55: [2024-10-29 12:43:55] iter = 15060, loss = 4.3245
2024-10-29 12:43:56: [2024-10-29 12:43:56] iter = 15070, loss = 8.1667
2024-10-29 12:43:56: [2024-10-29 12:43:56] iter = 15080, loss = 4.0116
2024-10-29 12:43:57: [2024-10-29 12:43:57] iter = 15090, loss = 54.0891
2024-10-29 12:43:57: [2024-10-29 12:43:57] iter = 15100, loss = 4.8121
2024-10-29 12:43:58: [2024-10-29 12:43:58] iter = 15110, loss = 4.2329
2024-10-29 12:43:58: [2024-10-29 12:43:58] iter = 15120, loss = 3.8407
2024-10-29 12:43:59: [2024-10-29 12:43:59] iter = 15130, loss = 9.8164
2024-10-29 12:43:59: [2024-10-29 12:43:59] iter = 15140, loss = 1.9858
2024-10-29 12:44:00: [2024-10-29 12:44:00] iter = 15150, loss = 10.7254
2024-10-29 12:44:00: [2024-10-29 12:44:00] iter = 15160, loss = 34.5451
2024-10-29 12:44:01: [2024-10-29 12:44:01] iter = 15170, loss = 3.2551
2024-10-29 12:44:01: [2024-10-29 12:44:01] iter = 15180, loss = 2.4156
2024-10-29 12:44:02: [2024-10-29 12:44:02] iter = 15190, loss = 32.2075
2024-10-29 12:44:02: [2024-10-29 12:44:02] iter = 15200, loss = 3.3399
2024-10-29 12:44:03: [2024-10-29 12:44:03] iter = 15210, loss = 20.8966
2024-10-29 12:44:03: [2024-10-29 12:44:03] iter = 15220, loss = 9.4817
2024-10-29 12:44:03: [2024-10-29 12:44:03] iter = 15230, loss = 2.4390
2024-10-29 12:44:04: [2024-10-29 12:44:04] iter = 15240, loss = 2.7298
2024-10-29 12:44:05: [2024-10-29 12:44:05] iter = 15250, loss = 3.5291
2024-10-29 12:44:05: [2024-10-29 12:44:05] iter = 15260, loss = 12.1634
2024-10-29 12:44:05: [2024-10-29 12:44:05] iter = 15270, loss = 5.9549
2024-10-29 12:44:06: [2024-10-29 12:44:06] iter = 15280, loss = 5.3590
2024-10-29 12:44:06: [2024-10-29 12:44:06] iter = 15290, loss = 5.2543
2024-10-29 12:44:07: [2024-10-29 12:44:07] iter = 15300, loss = 2.8333
2024-10-29 12:44:07: [2024-10-29 12:44:07] iter = 15310, loss = 2.3603
2024-10-29 12:44:07: [2024-10-29 12:44:07] iter = 15320, loss = 6.6400
2024-10-29 12:44:08: [2024-10-29 12:44:08] iter = 15330, loss = 10.2445
2024-10-29 12:44:08: [2024-10-29 12:44:08] iter = 15340, loss = 5.6493
2024-10-29 12:44:09: [2024-10-29 12:44:09] iter = 15350, loss = 3.2218
2024-10-29 12:44:09: [2024-10-29 12:44:09] iter = 15360, loss = 7.8725
2024-10-29 12:44:10: [2024-10-29 12:44:10] iter = 15370, loss = 6.3322
2024-10-29 12:44:11: [2024-10-29 12:44:11] iter = 15380, loss = 9.2042
2024-10-29 12:44:11: [2024-10-29 12:44:11] iter = 15390, loss = 7.2757
2024-10-29 12:44:11: [2024-10-29 12:44:11] iter = 15400, loss = 5.0696
2024-10-29 12:44:12: [2024-10-29 12:44:12] iter = 15410, loss = 13.4415
2024-10-29 12:44:12: [2024-10-29 12:44:12] iter = 15420, loss = 6.1560
2024-10-29 12:44:13: [2024-10-29 12:44:13] iter = 15430, loss = 3.4417
2024-10-29 12:44:13: [2024-10-29 12:44:13] iter = 15440, loss = 4.3164
2024-10-29 12:44:14: [2024-10-29 12:44:14] iter = 15450, loss = 10.7787
2024-10-29 12:44:14: [2024-10-29 12:44:14] iter = 15460, loss = 5.5611
2024-10-29 12:44:15: [2024-10-29 12:44:15] iter = 15470, loss = 3.7005
2024-10-29 12:44:15: [2024-10-29 12:44:15] iter = 15480, loss = 41.5751
2024-10-29 12:44:16: [2024-10-29 12:44:16] iter = 15490, loss = 65.3347
2024-10-29 12:44:16: [2024-10-29 12:44:16] iter = 15500, loss = 17.6452
2024-10-29 12:44:17: [2024-10-29 12:44:17] iter = 15510, loss = 2.8870
2024-10-29 12:44:17: [2024-10-29 12:44:17] iter = 15520, loss = 7.2349
2024-10-29 12:44:17: [2024-10-29 12:44:17] iter = 15530, loss = 5.7206
2024-10-29 12:44:18: [2024-10-29 12:44:18] iter = 15540, loss = 33.5038
2024-10-29 12:44:18: [2024-10-29 12:44:18] iter = 15550, loss = 35.7337
2024-10-29 12:44:19: [2024-10-29 12:44:19] iter = 15560, loss = 11.5082
2024-10-29 12:44:19: [2024-10-29 12:44:19] iter = 15570, loss = 6.3560
2024-10-29 12:44:20: [2024-10-29 12:44:20] iter = 15580, loss = 2.9388
2024-10-29 12:44:20: [2024-10-29 12:44:20] iter = 15590, loss = 6.3298
2024-10-29 12:44:21: [2024-10-29 12:44:21] iter = 15600, loss = 5.0250
2024-10-29 12:44:21: [2024-10-29 12:44:21] iter = 15610, loss = 21.2136
2024-10-29 12:44:22: [2024-10-29 12:44:22] iter = 15620, loss = 2.8486
2024-10-29 12:44:22: [2024-10-29 12:44:22] iter = 15630, loss = 8.5109
2024-10-29 12:44:23: [2024-10-29 12:44:23] iter = 15640, loss = 2.9450
2024-10-29 12:44:23: [2024-10-29 12:44:23] iter = 15650, loss = 9.3992
2024-10-29 12:44:24: [2024-10-29 12:44:24] iter = 15660, loss = 2.6706
2024-10-29 12:44:24: [2024-10-29 12:44:24] iter = 15670, loss = 8.9396
2024-10-29 12:44:25: [2024-10-29 12:44:25] iter = 15680, loss = 3.0744
2024-10-29 12:44:25: [2024-10-29 12:44:25] iter = 15690, loss = 4.9875
2024-10-29 12:44:25: [2024-10-29 12:44:25] iter = 15700, loss = 21.7334
2024-10-29 12:44:26: [2024-10-29 12:44:26] iter = 15710, loss = 4.7718
2024-10-29 12:44:26: [2024-10-29 12:44:26] iter = 15720, loss = 3.7635
2024-10-29 12:44:27: [2024-10-29 12:44:27] iter = 15730, loss = 45.6154
2024-10-29 12:44:28: [2024-10-29 12:44:28] iter = 15740, loss = 5.8425
2024-10-29 12:44:28: [2024-10-29 12:44:28] iter = 15750, loss = 3.1788
2024-10-29 12:44:29: [2024-10-29 12:44:29] iter = 15760, loss = 7.3435
2024-10-29 12:44:29: [2024-10-29 12:44:29] iter = 15770, loss = 13.2808
2024-10-29 12:44:30: [2024-10-29 12:44:30] iter = 15780, loss = 4.9225
2024-10-29 12:44:30: [2024-10-29 12:44:30] iter = 15790, loss = 4.2233
2024-10-29 12:44:31: [2024-10-29 12:44:31] iter = 15800, loss = 2.3706
2024-10-29 12:44:31: [2024-10-29 12:44:31] iter = 15810, loss = 15.2092
2024-10-29 12:44:32: [2024-10-29 12:44:32] iter = 15820, loss = 3.9101
2024-10-29 12:44:32: [2024-10-29 12:44:32] iter = 15830, loss = 2.9201
2024-10-29 12:44:33: [2024-10-29 12:44:33] iter = 15840, loss = 4.3913
2024-10-29 12:44:33: [2024-10-29 12:44:33] iter = 15850, loss = 3.2736
2024-10-29 12:44:34: [2024-10-29 12:44:34] iter = 15860, loss = 3.0929
2024-10-29 12:44:34: [2024-10-29 12:44:34] iter = 15870, loss = 2.5736
2024-10-29 12:44:35: [2024-10-29 12:44:35] iter = 15880, loss = 5.7039
2024-10-29 12:44:35: [2024-10-29 12:44:35] iter = 15890, loss = 20.1885
2024-10-29 12:44:36: [2024-10-29 12:44:36] iter = 15900, loss = 5.5082
2024-10-29 12:44:36: [2024-10-29 12:44:36] iter = 15910, loss = 3.2375
2024-10-29 12:44:37: [2024-10-29 12:44:37] iter = 15920, loss = 4.4300
2024-10-29 12:44:37: [2024-10-29 12:44:37] iter = 15930, loss = 8.9142
2024-10-29 12:44:38: [2024-10-29 12:44:38] iter = 15940, loss = 3.9295
2024-10-29 12:44:38: [2024-10-29 12:44:38] iter = 15950, loss = 8.0709
2024-10-29 12:44:39: [2024-10-29 12:44:39] iter = 15960, loss = 5.9841
2024-10-29 12:44:39: [2024-10-29 12:44:39] iter = 15970, loss = 7.3370
2024-10-29 12:44:40: [2024-10-29 12:44:40] iter = 15980, loss = 4.8718
2024-10-29 12:44:40: [2024-10-29 12:44:40] iter = 15990, loss = 4.3564
2024-10-29 12:44:41: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 12:44:41: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:44:41: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 81191}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:45:10: Evaluate 5 random ConvNet, ACCmean = 0.4050 ACCstd = 0.0231
-------------------------
2024-10-29 12:45:10: Evaluate 5 random ConvNet, SENmean = 0.4050 SENstd = 0.0231
-------------------------
2024-10-29 12:45:10: Evaluate 5 random ConvNet, SPEmean = 0.8017 SPEstd = 0.0077
-------------------------
2024-10-29 12:45:10: Evaluate 5 random ConvNet, F!mean = 0.3583 F!std = 0.0318
-------------------------
2024-10-29 12:45:10: Evaluate 5 random ConvNet, mean = 0.4050 std = 0.0231
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:45:10: [2024-10-29 12:45:10] iter = 16000, loss = 7.5388
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:45:10: [2024-10-29 12:45:10] iter = 16010, loss = 24.6691
2024-10-29 12:45:11: [2024-10-29 12:45:11] iter = 16020, loss = 10.3708
2024-10-29 12:45:11: [2024-10-29 12:45:11] iter = 16030, loss = 4.3409
2024-10-29 12:45:12: [2024-10-29 12:45:12] iter = 16040, loss = 4.8740
2024-10-29 12:45:12: [2024-10-29 12:45:12] iter = 16050, loss = 3.2102
2024-10-29 12:45:13: [2024-10-29 12:45:13] iter = 16060, loss = 6.7801
2024-10-29 12:45:14: [2024-10-29 12:45:14] iter = 16070, loss = 6.1550
2024-10-29 12:45:14: [2024-10-29 12:45:14] iter = 16080, loss = 5.9693
2024-10-29 12:45:15: [2024-10-29 12:45:15] iter = 16090, loss = 8.4456
2024-10-29 12:45:15: [2024-10-29 12:45:15] iter = 16100, loss = 4.8330
2024-10-29 12:45:16: [2024-10-29 12:45:16] iter = 16110, loss = 4.7303
2024-10-29 12:45:17: [2024-10-29 12:45:17] iter = 16120, loss = 10.5200
2024-10-29 12:45:17: [2024-10-29 12:45:17] iter = 16130, loss = 6.9976
2024-10-29 12:45:18: [2024-10-29 12:45:18] iter = 16140, loss = 7.1665
2024-10-29 12:45:19: [2024-10-29 12:45:19] iter = 16150, loss = 7.7213
2024-10-29 12:45:19: [2024-10-29 12:45:19] iter = 16160, loss = 2.4273
2024-10-29 12:45:20: [2024-10-29 12:45:19] iter = 16170, loss = 3.6469
2024-10-29 12:45:20: [2024-10-29 12:45:20] iter = 16180, loss = 9.5489
2024-10-29 12:45:20: [2024-10-29 12:45:20] iter = 16190, loss = 2.8481
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 16200, loss = 29.2587
2024-10-29 12:45:21: [2024-10-29 12:45:21] iter = 16210, loss = 4.2573
2024-10-29 12:45:22: [2024-10-29 12:45:22] iter = 16220, loss = 2.7532
2024-10-29 12:45:22: [2024-10-29 12:45:22] iter = 16230, loss = 4.4781
2024-10-29 12:45:23: [2024-10-29 12:45:23] iter = 16240, loss = 36.0236
2024-10-29 12:45:23: [2024-10-29 12:45:23] iter = 16250, loss = 12.9224
2024-10-29 12:45:24: [2024-10-29 12:45:24] iter = 16260, loss = 13.4033
2024-10-29 12:45:24: [2024-10-29 12:45:24] iter = 16270, loss = 17.8621
2024-10-29 12:45:25: [2024-10-29 12:45:25] iter = 16280, loss = 5.1233
2024-10-29 12:45:25: [2024-10-29 12:45:25] iter = 16290, loss = 7.2622
2024-10-29 12:45:26: [2024-10-29 12:45:26] iter = 16300, loss = 5.7771
2024-10-29 12:45:26: [2024-10-29 12:45:26] iter = 16310, loss = 21.0108
2024-10-29 12:45:27: [2024-10-29 12:45:27] iter = 16320, loss = 5.3519
2024-10-29 12:45:27: [2024-10-29 12:45:27] iter = 16330, loss = 23.5988
2024-10-29 12:45:28: [2024-10-29 12:45:28] iter = 16340, loss = 4.6658
2024-10-29 12:45:28: [2024-10-29 12:45:28] iter = 16350, loss = 8.6193
2024-10-29 12:45:29: [2024-10-29 12:45:29] iter = 16360, loss = 18.5896
2024-10-29 12:45:29: [2024-10-29 12:45:29] iter = 16370, loss = 29.1470
2024-10-29 12:45:30: [2024-10-29 12:45:30] iter = 16380, loss = 10.2884
2024-10-29 12:45:30: [2024-10-29 12:45:30] iter = 16390, loss = 5.3790
2024-10-29 12:45:31: [2024-10-29 12:45:31] iter = 16400, loss = 4.4273
2024-10-29 12:45:31: [2024-10-29 12:45:31] iter = 16410, loss = 5.1550
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 16420, loss = 27.5314
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 16430, loss = 7.9896
2024-10-29 12:45:32: [2024-10-29 12:45:32] iter = 16440, loss = 4.4364
2024-10-29 12:45:33: [2024-10-29 12:45:33] iter = 16450, loss = 3.2966
2024-10-29 12:45:33: [2024-10-29 12:45:33] iter = 16460, loss = 4.3849
2024-10-29 12:45:34: [2024-10-29 12:45:34] iter = 16470, loss = 7.1715
2024-10-29 12:45:34: [2024-10-29 12:45:34] iter = 16480, loss = 32.8133
2024-10-29 12:45:35: [2024-10-29 12:45:35] iter = 16490, loss = 5.3897
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 16500, loss = 4.3845
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 16510, loss = 5.1017
2024-10-29 12:45:36: [2024-10-29 12:45:36] iter = 16520, loss = 3.0808
2024-10-29 12:45:37: [2024-10-29 12:45:37] iter = 16530, loss = 4.6488
2024-10-29 12:45:37: [2024-10-29 12:45:37] iter = 16540, loss = 4.3609
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 16550, loss = 2.9067
2024-10-29 12:45:38: [2024-10-29 12:45:38] iter = 16560, loss = 15.1200
2024-10-29 12:45:39: [2024-10-29 12:45:39] iter = 16570, loss = 98.0306
2024-10-29 12:45:39: [2024-10-29 12:45:39] iter = 16580, loss = 8.8431
2024-10-29 12:45:40: [2024-10-29 12:45:40] iter = 16590, loss = 49.6374
2024-10-29 12:45:40: [2024-10-29 12:45:40] iter = 16600, loss = 27.4178
2024-10-29 12:45:41: [2024-10-29 12:45:41] iter = 16610, loss = 35.2772
2024-10-29 12:45:41: [2024-10-29 12:45:41] iter = 16620, loss = 3.8837
2024-10-29 12:45:42: [2024-10-29 12:45:42] iter = 16630, loss = 10.4170
2024-10-29 12:45:42: [2024-10-29 12:45:42] iter = 16640, loss = 2.9301
2024-10-29 12:45:43: [2024-10-29 12:45:43] iter = 16650, loss = 9.9621
2024-10-29 12:45:43: [2024-10-29 12:45:43] iter = 16660, loss = 10.7997
2024-10-29 12:45:44: [2024-10-29 12:45:44] iter = 16670, loss = 5.7363
2024-10-29 12:45:44: [2024-10-29 12:45:44] iter = 16680, loss = 10.3307
2024-10-29 12:45:45: [2024-10-29 12:45:45] iter = 16690, loss = 10.9538
2024-10-29 12:45:45: [2024-10-29 12:45:45] iter = 16700, loss = 5.5192
2024-10-29 12:45:46: [2024-10-29 12:45:46] iter = 16710, loss = 3.5875
2024-10-29 12:45:47: [2024-10-29 12:45:47] iter = 16720, loss = 3.9560
2024-10-29 12:45:47: [2024-10-29 12:45:47] iter = 16730, loss = 4.3024
2024-10-29 12:45:48: [2024-10-29 12:45:48] iter = 16740, loss = 18.2723
2024-10-29 12:45:48: [2024-10-29 12:45:48] iter = 16750, loss = 2.4649
2024-10-29 12:45:49: [2024-10-29 12:45:49] iter = 16760, loss = 16.6365
2024-10-29 12:45:49: [2024-10-29 12:45:49] iter = 16770, loss = 29.8286
2024-10-29 12:45:50: [2024-10-29 12:45:50] iter = 16780, loss = 9.5735
2024-10-29 12:45:50: [2024-10-29 12:45:50] iter = 16790, loss = 17.1715
2024-10-29 12:45:51: [2024-10-29 12:45:51] iter = 16800, loss = 4.2335
2024-10-29 12:45:51: [2024-10-29 12:45:51] iter = 16810, loss = 3.0062
2024-10-29 12:45:51: [2024-10-29 12:45:51] iter = 16820, loss = 4.0062
2024-10-29 12:45:52: [2024-10-29 12:45:52] iter = 16830, loss = 13.2900
2024-10-29 12:45:53: [2024-10-29 12:45:53] iter = 16840, loss = 8.5776
2024-10-29 12:45:53: [2024-10-29 12:45:53] iter = 16850, loss = 10.5624
2024-10-29 12:45:53: [2024-10-29 12:45:53] iter = 16860, loss = 3.0373
2024-10-29 12:45:54: [2024-10-29 12:45:54] iter = 16870, loss = 5.2638
2024-10-29 12:45:54: [2024-10-29 12:45:54] iter = 16880, loss = 3.8536
2024-10-29 12:45:55: [2024-10-29 12:45:55] iter = 16890, loss = 5.8282
2024-10-29 12:45:55: [2024-10-29 12:45:55] iter = 16900, loss = 6.1784
2024-10-29 12:45:56: [2024-10-29 12:45:56] iter = 16910, loss = 3.1995
2024-10-29 12:45:56: [2024-10-29 12:45:56] iter = 16920, loss = 5.4540
2024-10-29 12:45:57: [2024-10-29 12:45:57] iter = 16930, loss = 45.6820
2024-10-29 12:45:58: [2024-10-29 12:45:58] iter = 16940, loss = 38.0074
2024-10-29 12:45:58: [2024-10-29 12:45:58] iter = 16950, loss = 6.6344
2024-10-29 12:45:59: [2024-10-29 12:45:59] iter = 16960, loss = 5.9814
2024-10-29 12:45:59: [2024-10-29 12:45:59] iter = 16970, loss = 7.2098
2024-10-29 12:46:00: [2024-10-29 12:46:00] iter = 16980, loss = 4.0188
2024-10-29 12:46:01: [2024-10-29 12:46:01] iter = 16990, loss = 18.0288
2024-10-29 12:46:01: [2024-10-29 12:46:01] iter = 17000, loss = 2.7336
2024-10-29 12:46:02: [2024-10-29 12:46:02] iter = 17010, loss = 7.9828
2024-10-29 12:46:02: [2024-10-29 12:46:02] iter = 17020, loss = 5.4372
2024-10-29 12:46:03: [2024-10-29 12:46:03] iter = 17030, loss = 14.6614
2024-10-29 12:46:03: [2024-10-29 12:46:03] iter = 17040, loss = 8.0492
2024-10-29 12:46:04: [2024-10-29 12:46:04] iter = 17050, loss = 8.7851
2024-10-29 12:46:04: [2024-10-29 12:46:04] iter = 17060, loss = 24.5513
2024-10-29 12:46:05: [2024-10-29 12:46:05] iter = 17070, loss = 7.9514
2024-10-29 12:46:05: [2024-10-29 12:46:05] iter = 17080, loss = 23.6168
2024-10-29 12:46:06: [2024-10-29 12:46:06] iter = 17090, loss = 4.5940
2024-10-29 12:46:06: [2024-10-29 12:46:06] iter = 17100, loss = 46.7134
2024-10-29 12:46:07: [2024-10-29 12:46:07] iter = 17110, loss = 2.4475
2024-10-29 12:46:08: [2024-10-29 12:46:08] iter = 17120, loss = 4.5764
2024-10-29 12:46:09: [2024-10-29 12:46:09] iter = 17130, loss = 6.9424
2024-10-29 12:46:09: [2024-10-29 12:46:09] iter = 17140, loss = 4.4349
2024-10-29 12:46:10: [2024-10-29 12:46:10] iter = 17150, loss = 4.8714
2024-10-29 12:46:11: [2024-10-29 12:46:11] iter = 17160, loss = 2.2367
2024-10-29 12:46:12: [2024-10-29 12:46:12] iter = 17170, loss = 8.9655
2024-10-29 12:46:12: [2024-10-29 12:46:12] iter = 17180, loss = 9.0305
2024-10-29 12:46:13: [2024-10-29 12:46:13] iter = 17190, loss = 4.0685
2024-10-29 12:46:14: [2024-10-29 12:46:14] iter = 17200, loss = 5.3326
2024-10-29 12:46:15: [2024-10-29 12:46:15] iter = 17210, loss = 2.4381
2024-10-29 12:46:15: [2024-10-29 12:46:15] iter = 17220, loss = 4.1914
2024-10-29 12:46:16: [2024-10-29 12:46:16] iter = 17230, loss = 3.4491
2024-10-29 12:46:16: [2024-10-29 12:46:16] iter = 17240, loss = 5.7756
2024-10-29 12:46:17: [2024-10-29 12:46:17] iter = 17250, loss = 22.0139
2024-10-29 12:46:17: [2024-10-29 12:46:17] iter = 17260, loss = 4.3778
2024-10-29 12:46:18: [2024-10-29 12:46:18] iter = 17270, loss = 6.0968
2024-10-29 12:46:18: [2024-10-29 12:46:18] iter = 17280, loss = 4.4547
2024-10-29 12:46:19: [2024-10-29 12:46:19] iter = 17290, loss = 5.5234
2024-10-29 12:46:19: [2024-10-29 12:46:19] iter = 17300, loss = 4.3766
2024-10-29 12:46:20: [2024-10-29 12:46:20] iter = 17310, loss = 4.5736
2024-10-29 12:46:20: [2024-10-29 12:46:20] iter = 17320, loss = 4.7740
2024-10-29 12:46:21: [2024-10-29 12:46:21] iter = 17330, loss = 9.4670
2024-10-29 12:46:21: [2024-10-29 12:46:21] iter = 17340, loss = 3.6917
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 17350, loss = 2.4554
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 17360, loss = 4.9807
2024-10-29 12:46:22: [2024-10-29 12:46:22] iter = 17370, loss = 17.9494
2024-10-29 12:46:23: [2024-10-29 12:46:23] iter = 17380, loss = 4.3566
2024-10-29 12:46:23: [2024-10-29 12:46:23] iter = 17390, loss = 12.6799
2024-10-29 12:46:24: [2024-10-29 12:46:24] iter = 17400, loss = 6.3730
2024-10-29 12:46:25: [2024-10-29 12:46:25] iter = 17410, loss = 3.1273
2024-10-29 12:46:25: [2024-10-29 12:46:25] iter = 17420, loss = 11.0017
2024-10-29 12:46:26: [2024-10-29 12:46:26] iter = 17430, loss = 9.7991
2024-10-29 12:46:26: [2024-10-29 12:46:26] iter = 17440, loss = 7.7474
2024-10-29 12:46:27: [2024-10-29 12:46:27] iter = 17450, loss = 8.7634
2024-10-29 12:46:27: [2024-10-29 12:46:27] iter = 17460, loss = 6.5174
2024-10-29 12:46:28: [2024-10-29 12:46:28] iter = 17470, loss = 5.2525
2024-10-29 12:46:28: [2024-10-29 12:46:28] iter = 17480, loss = 2.8227
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 17490, loss = 6.1295
2024-10-29 12:46:29: [2024-10-29 12:46:29] iter = 17500, loss = 3.3557
2024-10-29 12:46:30: [2024-10-29 12:46:30] iter = 17510, loss = 8.6623
2024-10-29 12:46:30: [2024-10-29 12:46:30] iter = 17520, loss = 9.6550
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 17530, loss = 7.9358
2024-10-29 12:46:31: [2024-10-29 12:46:31] iter = 17540, loss = 14.9588
2024-10-29 12:46:32: [2024-10-29 12:46:32] iter = 17550, loss = 10.9687
2024-10-29 12:46:32: [2024-10-29 12:46:32] iter = 17560, loss = 3.0664
2024-10-29 12:46:33: [2024-10-29 12:46:33] iter = 17570, loss = 4.0405
2024-10-29 12:46:33: [2024-10-29 12:46:33] iter = 17580, loss = 4.2496
2024-10-29 12:46:34: [2024-10-29 12:46:34] iter = 17590, loss = 6.3255
2024-10-29 12:46:34: [2024-10-29 12:46:34] iter = 17600, loss = 3.1089
2024-10-29 12:46:35: [2024-10-29 12:46:35] iter = 17610, loss = 5.1396
2024-10-29 12:46:35: [2024-10-29 12:46:35] iter = 17620, loss = 8.8298
2024-10-29 12:46:36: [2024-10-29 12:46:36] iter = 17630, loss = 3.4553
2024-10-29 12:46:36: [2024-10-29 12:46:36] iter = 17640, loss = 12.8274
2024-10-29 12:46:37: [2024-10-29 12:46:37] iter = 17650, loss = 2.4469
2024-10-29 12:46:37: [2024-10-29 12:46:37] iter = 17660, loss = 22.1826
2024-10-29 12:46:38: [2024-10-29 12:46:38] iter = 17670, loss = 5.8046
2024-10-29 12:46:38: [2024-10-29 12:46:38] iter = 17680, loss = 2.2203
2024-10-29 12:46:39: [2024-10-29 12:46:39] iter = 17690, loss = 12.2232
2024-10-29 12:46:39: [2024-10-29 12:46:39] iter = 17700, loss = 4.6058
2024-10-29 12:46:40: [2024-10-29 12:46:40] iter = 17710, loss = 7.2879
2024-10-29 12:46:40: [2024-10-29 12:46:40] iter = 17720, loss = 6.8858
2024-10-29 12:46:41: [2024-10-29 12:46:41] iter = 17730, loss = 5.0283
2024-10-29 12:46:41: [2024-10-29 12:46:41] iter = 17740, loss = 4.2455
2024-10-29 12:46:42: [2024-10-29 12:46:42] iter = 17750, loss = 2.5686
2024-10-29 12:46:42: [2024-10-29 12:46:42] iter = 17760, loss = 4.4777
2024-10-29 12:46:43: [2024-10-29 12:46:43] iter = 17770, loss = 3.3183
2024-10-29 12:46:43: [2024-10-29 12:46:43] iter = 17780, loss = 3.4891
2024-10-29 12:46:44: [2024-10-29 12:46:44] iter = 17790, loss = 10.4799
2024-10-29 12:46:44: [2024-10-29 12:46:44] iter = 17800, loss = 1.7970
2024-10-29 12:46:45: [2024-10-29 12:46:45] iter = 17810, loss = 17.3921
2024-10-29 12:46:45: [2024-10-29 12:46:45] iter = 17820, loss = 7.3294
2024-10-29 12:46:45: [2024-10-29 12:46:45] iter = 17830, loss = 3.0199
2024-10-29 12:46:46: [2024-10-29 12:46:46] iter = 17840, loss = 53.6121
2024-10-29 12:46:47: [2024-10-29 12:46:47] iter = 17850, loss = 6.0047
2024-10-29 12:46:47: [2024-10-29 12:46:47] iter = 17860, loss = 3.8678
2024-10-29 12:46:47: [2024-10-29 12:46:47] iter = 17870, loss = 10.6138
2024-10-29 12:46:48: [2024-10-29 12:46:48] iter = 17880, loss = 10.1593
2024-10-29 12:46:48: [2024-10-29 12:46:48] iter = 17890, loss = 70.3815
2024-10-29 12:46:49: [2024-10-29 12:46:49] iter = 17900, loss = 3.8092
2024-10-29 12:46:49: [2024-10-29 12:46:49] iter = 17910, loss = 3.7776
2024-10-29 12:46:50: [2024-10-29 12:46:50] iter = 17920, loss = 6.1221
2024-10-29 12:46:51: [2024-10-29 12:46:51] iter = 17930, loss = 10.7034
2024-10-29 12:46:51: [2024-10-29 12:46:51] iter = 17940, loss = 8.0299
2024-10-29 12:46:52: [2024-10-29 12:46:52] iter = 17950, loss = 3.3819
2024-10-29 12:46:52: [2024-10-29 12:46:52] iter = 17960, loss = 3.0244
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 17970, loss = 5.5500
2024-10-29 12:46:53: [2024-10-29 12:46:53] iter = 17980, loss = 8.4321
2024-10-29 12:46:54: [2024-10-29 12:46:54] iter = 17990, loss = 4.7929
2024-10-29 12:46:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 12:46:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:46:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 14616}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:47:20: Evaluate 5 random ConvNet, ACCmean = 0.4478 ACCstd = 0.0084
-------------------------
2024-10-29 12:47:20: Evaluate 5 random ConvNet, SENmean = 0.4478 SENstd = 0.0084
-------------------------
2024-10-29 12:47:20: Evaluate 5 random ConvNet, SPEmean = 0.8159 SPEstd = 0.0028
-------------------------
2024-10-29 12:47:20: Evaluate 5 random ConvNet, F!mean = 0.4190 F!std = 0.0080
-------------------------
2024-10-29 12:47:20: Evaluate 5 random ConvNet, mean = 0.4478 std = 0.0084
-------------------------
2024-10-29 12:47:20: [2024-10-29 12:47:20] iter = 18000, loss = 3.3830
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:47:20: [2024-10-29 12:47:20] iter = 18010, loss = 3.8531
2024-10-29 12:47:21: [2024-10-29 12:47:21] iter = 18020, loss = 21.5095
2024-10-29 12:47:21: [2024-10-29 12:47:21] iter = 18030, loss = 49.2044
2024-10-29 12:47:22: [2024-10-29 12:47:22] iter = 18040, loss = 5.2442
2024-10-29 12:47:23: [2024-10-29 12:47:22] iter = 18050, loss = 10.3640
2024-10-29 12:47:23: [2024-10-29 12:47:23] iter = 18060, loss = 18.4336
2024-10-29 12:47:24: [2024-10-29 12:47:24] iter = 18070, loss = 5.8631
2024-10-29 12:47:24: [2024-10-29 12:47:24] iter = 18080, loss = 3.3351
2024-10-29 12:47:25: [2024-10-29 12:47:25] iter = 18090, loss = 8.0049
2024-10-29 12:47:26: [2024-10-29 12:47:26] iter = 18100, loss = 3.8003
2024-10-29 12:47:27: [2024-10-29 12:47:27] iter = 18110, loss = 18.1338
2024-10-29 12:47:28: [2024-10-29 12:47:28] iter = 18120, loss = 3.2134
2024-10-29 12:47:28: [2024-10-29 12:47:28] iter = 18130, loss = 10.7940
2024-10-29 12:47:29: [2024-10-29 12:47:29] iter = 18140, loss = 2.8131
2024-10-29 12:47:30: [2024-10-29 12:47:30] iter = 18150, loss = 3.8834
2024-10-29 12:47:31: [2024-10-29 12:47:31] iter = 18160, loss = 7.3408
2024-10-29 12:47:32: [2024-10-29 12:47:32] iter = 18170, loss = 13.5822
2024-10-29 12:47:32: [2024-10-29 12:47:32] iter = 18180, loss = 4.9273
2024-10-29 12:47:33: [2024-10-29 12:47:33] iter = 18190, loss = 2.9092
2024-10-29 12:47:33: [2024-10-29 12:47:33] iter = 18200, loss = 8.0238
2024-10-29 12:47:34: [2024-10-29 12:47:34] iter = 18210, loss = 4.3482
2024-10-29 12:47:35: [2024-10-29 12:47:34] iter = 18220, loss = 3.5501
2024-10-29 12:47:35: [2024-10-29 12:47:35] iter = 18230, loss = 4.0267
2024-10-29 12:47:36: [2024-10-29 12:47:36] iter = 18240, loss = 4.4793
2024-10-29 12:47:36: [2024-10-29 12:47:36] iter = 18250, loss = 4.7887
2024-10-29 12:47:37: [2024-10-29 12:47:37] iter = 18260, loss = 23.4767
2024-10-29 12:47:37: [2024-10-29 12:47:37] iter = 18270, loss = 2.9360
2024-10-29 12:47:38: [2024-10-29 12:47:38] iter = 18280, loss = 14.9195
2024-10-29 12:47:38: [2024-10-29 12:47:38] iter = 18290, loss = 4.4068
2024-10-29 12:47:39: [2024-10-29 12:47:39] iter = 18300, loss = 17.6750
2024-10-29 12:47:39: [2024-10-29 12:47:39] iter = 18310, loss = 2.6707
2024-10-29 12:47:40: [2024-10-29 12:47:40] iter = 18320, loss = 12.5074
2024-10-29 12:47:40: [2024-10-29 12:47:40] iter = 18330, loss = 2.3950
2024-10-29 12:47:41: [2024-10-29 12:47:41] iter = 18340, loss = 11.4844
2024-10-29 12:47:41: [2024-10-29 12:47:41] iter = 18350, loss = 15.3382
2024-10-29 12:47:42: [2024-10-29 12:47:42] iter = 18360, loss = 8.1996
2024-10-29 12:47:43: [2024-10-29 12:47:43] iter = 18370, loss = 4.0222
2024-10-29 12:47:44: [2024-10-29 12:47:44] iter = 18380, loss = 9.8046
2024-10-29 12:47:44: [2024-10-29 12:47:44] iter = 18390, loss = 33.0818
2024-10-29 12:47:45: [2024-10-29 12:47:45] iter = 18400, loss = 17.2241
2024-10-29 12:47:45: [2024-10-29 12:47:45] iter = 18410, loss = 10.7192
2024-10-29 12:47:46: [2024-10-29 12:47:46] iter = 18420, loss = 3.7452
2024-10-29 12:47:47: [2024-10-29 12:47:47] iter = 18430, loss = 5.7628
2024-10-29 12:47:47: [2024-10-29 12:47:47] iter = 18440, loss = 4.7050
2024-10-29 12:47:48: [2024-10-29 12:47:48] iter = 18450, loss = 6.4580
2024-10-29 12:47:48: [2024-10-29 12:47:48] iter = 18460, loss = 4.7847
2024-10-29 12:47:49: [2024-10-29 12:47:49] iter = 18470, loss = 2.7483
2024-10-29 12:47:49: [2024-10-29 12:47:49] iter = 18480, loss = 4.6181
2024-10-29 12:47:50: [2024-10-29 12:47:50] iter = 18490, loss = 4.5470
2024-10-29 12:47:51: [2024-10-29 12:47:51] iter = 18500, loss = 3.4890
2024-10-29 12:47:51: [2024-10-29 12:47:51] iter = 18510, loss = 4.6342
2024-10-29 12:47:52: [2024-10-29 12:47:52] iter = 18520, loss = 6.8414
2024-10-29 12:47:52: [2024-10-29 12:47:52] iter = 18530, loss = 5.0985
2024-10-29 12:47:53: [2024-10-29 12:47:53] iter = 18540, loss = 38.5224
2024-10-29 12:47:53: [2024-10-29 12:47:53] iter = 18550, loss = 3.3046
2024-10-29 12:47:54: [2024-10-29 12:47:54] iter = 18560, loss = 5.6945
2024-10-29 12:47:54: [2024-10-29 12:47:54] iter = 18570, loss = 27.3532
2024-10-29 12:47:55: [2024-10-29 12:47:55] iter = 18580, loss = 7.7111
2024-10-29 12:47:55: [2024-10-29 12:47:55] iter = 18590, loss = 10.7165
2024-10-29 12:47:56: [2024-10-29 12:47:56] iter = 18600, loss = 15.5347
2024-10-29 12:47:56: [2024-10-29 12:47:56] iter = 18610, loss = 19.1597
2024-10-29 12:47:57: [2024-10-29 12:47:57] iter = 18620, loss = 30.3257
2024-10-29 12:47:57: [2024-10-29 12:47:57] iter = 18630, loss = 7.1031
2024-10-29 12:47:58: [2024-10-29 12:47:58] iter = 18640, loss = 40.2826
2024-10-29 12:47:58: [2024-10-29 12:47:58] iter = 18650, loss = 4.5019
2024-10-29 12:47:59: [2024-10-29 12:47:59] iter = 18660, loss = 6.6258
2024-10-29 12:47:59: [2024-10-29 12:47:59] iter = 18670, loss = 12.6347
2024-10-29 12:48:00: [2024-10-29 12:48:00] iter = 18680, loss = 7.5086
2024-10-29 12:48:00: [2024-10-29 12:48:00] iter = 18690, loss = 4.3013
2024-10-29 12:48:01: [2024-10-29 12:48:01] iter = 18700, loss = 4.4247
2024-10-29 12:48:01: [2024-10-29 12:48:01] iter = 18710, loss = 13.9995
2024-10-29 12:48:02: [2024-10-29 12:48:02] iter = 18720, loss = 2.9047
2024-10-29 12:48:02: [2024-10-29 12:48:02] iter = 18730, loss = 53.1984
2024-10-29 12:48:03: [2024-10-29 12:48:03] iter = 18740, loss = 62.1267
2024-10-29 12:48:03: [2024-10-29 12:48:03] iter = 18750, loss = 7.9595
2024-10-29 12:48:04: [2024-10-29 12:48:04] iter = 18760, loss = 14.3473
2024-10-29 12:48:04: [2024-10-29 12:48:04] iter = 18770, loss = 5.3854
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 18780, loss = 22.8323
2024-10-29 12:48:05: [2024-10-29 12:48:05] iter = 18790, loss = 25.8402
2024-10-29 12:48:06: [2024-10-29 12:48:06] iter = 18800, loss = 11.6996
2024-10-29 12:48:06: [2024-10-29 12:48:06] iter = 18810, loss = 16.4978
2024-10-29 12:48:07: [2024-10-29 12:48:07] iter = 18820, loss = 7.4607
2024-10-29 12:48:08: [2024-10-29 12:48:08] iter = 18830, loss = 5.8398
2024-10-29 12:48:08: [2024-10-29 12:48:08] iter = 18840, loss = 37.4657
2024-10-29 12:48:08: [2024-10-29 12:48:08] iter = 18850, loss = 37.0871
2024-10-29 12:48:09: [2024-10-29 12:48:09] iter = 18860, loss = 29.7306
2024-10-29 12:48:09: [2024-10-29 12:48:09] iter = 18870, loss = 5.1968
2024-10-29 12:48:10: [2024-10-29 12:48:10] iter = 18880, loss = 5.3789
2024-10-29 12:48:10: [2024-10-29 12:48:10] iter = 18890, loss = 7.4108
2024-10-29 12:48:11: [2024-10-29 12:48:11] iter = 18900, loss = 5.1664
2024-10-29 12:48:11: [2024-10-29 12:48:11] iter = 18910, loss = 9.1736
2024-10-29 12:48:12: [2024-10-29 12:48:12] iter = 18920, loss = 19.4790
2024-10-29 12:48:12: [2024-10-29 12:48:12] iter = 18930, loss = 7.8418
2024-10-29 12:48:13: [2024-10-29 12:48:13] iter = 18940, loss = 7.3259
2024-10-29 12:48:13: [2024-10-29 12:48:13] iter = 18950, loss = 6.0411
2024-10-29 12:48:14: [2024-10-29 12:48:14] iter = 18960, loss = 6.0991
2024-10-29 12:48:14: [2024-10-29 12:48:14] iter = 18970, loss = 6.1083
2024-10-29 12:48:15: [2024-10-29 12:48:15] iter = 18980, loss = 3.1503
2024-10-29 12:48:16: [2024-10-29 12:48:16] iter = 18990, loss = 6.5038
2024-10-29 12:48:16: [2024-10-29 12:48:16] iter = 19000, loss = 25.5581
2024-10-29 12:48:17: [2024-10-29 12:48:17] iter = 19010, loss = 27.3461
2024-10-29 12:48:18: [2024-10-29 12:48:18] iter = 19020, loss = 28.6232
2024-10-29 12:48:19: [2024-10-29 12:48:19] iter = 19030, loss = 2.9671
2024-10-29 12:48:19: [2024-10-29 12:48:19] iter = 19040, loss = 4.6639
2024-10-29 12:48:20: [2024-10-29 12:48:20] iter = 19050, loss = 7.5726
2024-10-29 12:48:21: [2024-10-29 12:48:21] iter = 19060, loss = 8.6257
2024-10-29 12:48:21: [2024-10-29 12:48:21] iter = 19070, loss = 18.4724
2024-10-29 12:48:22: [2024-10-29 12:48:22] iter = 19080, loss = 3.4582
2024-10-29 12:48:22: [2024-10-29 12:48:22] iter = 19090, loss = 52.9568
2024-10-29 12:48:23: [2024-10-29 12:48:23] iter = 19100, loss = 10.2945
2024-10-29 12:48:24: [2024-10-29 12:48:24] iter = 19110, loss = 3.5427
2024-10-29 12:48:24: [2024-10-29 12:48:24] iter = 19120, loss = 4.2310
2024-10-29 12:48:25: [2024-10-29 12:48:25] iter = 19130, loss = 9.3102
2024-10-29 12:48:25: [2024-10-29 12:48:25] iter = 19140, loss = 8.5540
2024-10-29 12:48:26: [2024-10-29 12:48:26] iter = 19150, loss = 26.6796
2024-10-29 12:48:26: [2024-10-29 12:48:26] iter = 19160, loss = 10.6283
2024-10-29 12:48:27: [2024-10-29 12:48:27] iter = 19170, loss = 8.2695
2024-10-29 12:48:27: [2024-10-29 12:48:27] iter = 19180, loss = 5.5024
2024-10-29 12:48:28: [2024-10-29 12:48:28] iter = 19190, loss = 3.5359
2024-10-29 12:48:28: [2024-10-29 12:48:28] iter = 19200, loss = 9.7381
2024-10-29 12:48:29: [2024-10-29 12:48:29] iter = 19210, loss = 23.1438
2024-10-29 12:48:29: [2024-10-29 12:48:29] iter = 19220, loss = 4.0527
2024-10-29 12:48:30: [2024-10-29 12:48:30] iter = 19230, loss = 10.3168
2024-10-29 12:48:30: [2024-10-29 12:48:30] iter = 19240, loss = 28.9971
2024-10-29 12:48:31: [2024-10-29 12:48:31] iter = 19250, loss = 4.7648
2024-10-29 12:48:31: [2024-10-29 12:48:31] iter = 19260, loss = 3.3601
2024-10-29 12:48:32: [2024-10-29 12:48:32] iter = 19270, loss = 58.8946
2024-10-29 12:48:32: [2024-10-29 12:48:32] iter = 19280, loss = 14.4473
2024-10-29 12:48:33: [2024-10-29 12:48:33] iter = 19290, loss = 19.8967
2024-10-29 12:48:33: [2024-10-29 12:48:33] iter = 19300, loss = 9.3536
2024-10-29 12:48:34: [2024-10-29 12:48:34] iter = 19310, loss = 12.0216
2024-10-29 12:48:34: [2024-10-29 12:48:34] iter = 19320, loss = 5.1010
2024-10-29 12:48:35: [2024-10-29 12:48:35] iter = 19330, loss = 12.9271
2024-10-29 12:48:35: [2024-10-29 12:48:35] iter = 19340, loss = 7.9101
2024-10-29 12:48:36: [2024-10-29 12:48:36] iter = 19350, loss = 16.2120
2024-10-29 12:48:37: [2024-10-29 12:48:37] iter = 19360, loss = 12.8538
2024-10-29 12:48:37: [2024-10-29 12:48:37] iter = 19370, loss = 3.9765
2024-10-29 12:48:38: [2024-10-29 12:48:38] iter = 19380, loss = 11.0440
2024-10-29 12:48:39: [2024-10-29 12:48:39] iter = 19390, loss = 2.8326
2024-10-29 12:48:39: [2024-10-29 12:48:39] iter = 19400, loss = 3.6702
2024-10-29 12:48:40: [2024-10-29 12:48:40] iter = 19410, loss = 2.4902
2024-10-29 12:48:40: [2024-10-29 12:48:40] iter = 19420, loss = 2.2465
2024-10-29 12:48:41: [2024-10-29 12:48:41] iter = 19430, loss = 3.7693
2024-10-29 12:48:41: [2024-10-29 12:48:41] iter = 19440, loss = 4.1788
2024-10-29 12:48:42: [2024-10-29 12:48:42] iter = 19450, loss = 21.6253
2024-10-29 12:48:43: [2024-10-29 12:48:43] iter = 19460, loss = 2.5982
2024-10-29 12:48:44: [2024-10-29 12:48:44] iter = 19470, loss = 4.6245
2024-10-29 12:48:44: [2024-10-29 12:48:44] iter = 19480, loss = 10.3689
2024-10-29 12:48:45: [2024-10-29 12:48:45] iter = 19490, loss = 12.1796
2024-10-29 12:48:45: [2024-10-29 12:48:45] iter = 19500, loss = 3.8899
2024-10-29 12:48:46: [2024-10-29 12:48:46] iter = 19510, loss = 3.9144
2024-10-29 12:48:47: [2024-10-29 12:48:47] iter = 19520, loss = 2.9445
2024-10-29 12:48:47: [2024-10-29 12:48:47] iter = 19530, loss = 3.4403
2024-10-29 12:48:48: [2024-10-29 12:48:48] iter = 19540, loss = 21.0910
2024-10-29 12:48:48: [2024-10-29 12:48:48] iter = 19550, loss = 13.5630
2024-10-29 12:48:49: [2024-10-29 12:48:49] iter = 19560, loss = 14.6692
2024-10-29 12:48:49: [2024-10-29 12:48:49] iter = 19570, loss = 3.9178
2024-10-29 12:48:50: [2024-10-29 12:48:50] iter = 19580, loss = 3.1064
2024-10-29 12:48:50: [2024-10-29 12:48:50] iter = 19590, loss = 6.1620
2024-10-29 12:48:51: [2024-10-29 12:48:51] iter = 19600, loss = 11.3907
2024-10-29 12:48:51: [2024-10-29 12:48:51] iter = 19610, loss = 5.6835
2024-10-29 12:48:52: [2024-10-29 12:48:52] iter = 19620, loss = 11.3457
2024-10-29 12:48:52: [2024-10-29 12:48:52] iter = 19630, loss = 13.0213
2024-10-29 12:48:53: [2024-10-29 12:48:53] iter = 19640, loss = 4.4060
2024-10-29 12:48:53: [2024-10-29 12:48:53] iter = 19650, loss = 2.4552
2024-10-29 12:48:54: [2024-10-29 12:48:54] iter = 19660, loss = 49.8844
2024-10-29 12:48:54: [2024-10-29 12:48:54] iter = 19670, loss = 13.4240
2024-10-29 12:48:55: [2024-10-29 12:48:55] iter = 19680, loss = 5.4905
2024-10-29 12:48:55: [2024-10-29 12:48:55] iter = 19690, loss = 3.7186
2024-10-29 12:48:56: [2024-10-29 12:48:56] iter = 19700, loss = 3.4497
2024-10-29 12:48:56: [2024-10-29 12:48:56] iter = 19710, loss = 3.7572
2024-10-29 12:48:57: [2024-10-29 12:48:57] iter = 19720, loss = 22.5033
2024-10-29 12:48:58: [2024-10-29 12:48:58] iter = 19730, loss = 3.4988
2024-10-29 12:48:58: [2024-10-29 12:48:58] iter = 19740, loss = 2.5079
2024-10-29 12:48:59: [2024-10-29 12:48:59] iter = 19750, loss = 8.9454
2024-10-29 12:48:59: [2024-10-29 12:48:59] iter = 19760, loss = 9.8587
2024-10-29 12:49:00: [2024-10-29 12:49:00] iter = 19770, loss = 17.2709
2024-10-29 12:49:00: [2024-10-29 12:49:00] iter = 19780, loss = 10.9903
2024-10-29 12:49:01: [2024-10-29 12:49:01] iter = 19790, loss = 15.2465
2024-10-29 12:49:02: [2024-10-29 12:49:02] iter = 19800, loss = 7.7688
2024-10-29 12:49:02: [2024-10-29 12:49:02] iter = 19810, loss = 3.2525
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 19820, loss = 3.9143
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 19830, loss = 12.3177
2024-10-29 12:49:03: [2024-10-29 12:49:03] iter = 19840, loss = 3.5379
2024-10-29 12:49:04: [2024-10-29 12:49:04] iter = 19850, loss = 3.4741
2024-10-29 12:49:05: [2024-10-29 12:49:05] iter = 19860, loss = 8.1001
2024-10-29 12:49:05: [2024-10-29 12:49:05] iter = 19870, loss = 19.2046
2024-10-29 12:49:06: [2024-10-29 12:49:06] iter = 19880, loss = 9.4669
2024-10-29 12:49:06: [2024-10-29 12:49:06] iter = 19890, loss = 48.0060
2024-10-29 12:49:07: [2024-10-29 12:49:07] iter = 19900, loss = 18.2754
2024-10-29 12:49:07: [2024-10-29 12:49:07] iter = 19910, loss = 6.4057
2024-10-29 12:49:08: [2024-10-29 12:49:08] iter = 19920, loss = 8.8579
2024-10-29 12:49:08: [2024-10-29 12:49:08] iter = 19930, loss = 4.4770
2024-10-29 12:49:09: [2024-10-29 12:49:09] iter = 19940, loss = 5.1524
2024-10-29 12:49:09: [2024-10-29 12:49:09] iter = 19950, loss = 3.6720
2024-10-29 12:49:10: [2024-10-29 12:49:10] iter = 19960, loss = 11.3022
2024-10-29 12:49:10: [2024-10-29 12:49:10] iter = 19970, loss = 10.0164
2024-10-29 12:49:11: [2024-10-29 12:49:11] iter = 19980, loss = 9.8552
2024-10-29 12:49:11: [2024-10-29 12:49:11] iter = 19990, loss = 3.6875
2024-10-29 12:49:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 12:49:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:49:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52083}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:49:40: Evaluate 5 random ConvNet, ACCmean = 0.5306 ACCstd = 0.0184
-------------------------
2024-10-29 12:49:40: Evaluate 5 random ConvNet, SENmean = 0.5306 SENstd = 0.0184
-------------------------
2024-10-29 12:49:40: Evaluate 5 random ConvNet, SPEmean = 0.8435 SPEstd = 0.0061
-------------------------
2024-10-29 12:49:40: Evaluate 5 random ConvNet, F!mean = 0.5146 F!std = 0.0203
-------------------------
2024-10-29 12:49:40: Evaluate 5 random ConvNet, mean = 0.5306 std = 0.0184
-------------------------
2024-10-29 12:49:40: [2024-10-29 12:49:40] iter = 20000, loss = 20.3722
2024-10-29 12:49:40: 
================== Exp 3 ==================
 
2024-10-29 12:49:40: Hyper-parameters: 
{'dataset': 'OCTMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faf200e8730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OCTMNIST (INFO)>}
2024-10-29 12:49:40: Evaluation model pool: ['ConvNet']
2024-10-29 12:49:42: class c = 0: 33484 real images
2024-10-29 12:49:42: class c = 1: 10213 real images
2024-10-29 12:49:42: class c = 2: 7754 real images
2024-10-29 12:49:42: class c = 3: 46026 real images
2024-10-29 12:49:42: real images channel 0, mean = 0.1889, std = 0.1963
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 12:49:42: initialize synthetic data from random real images
2024-10-29 12:49:42: [2024-10-29 12:49:42] training begins
2024-10-29 12:49:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 12:49:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:49:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 80062}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:50:11: Evaluate 5 random ConvNet, ACCmean = 0.4470 ACCstd = 0.0144
-------------------------
2024-10-29 12:50:11: Evaluate 5 random ConvNet, SENmean = 0.4470 SENstd = 0.0144
-------------------------
2024-10-29 12:50:11: Evaluate 5 random ConvNet, SPEmean = 0.8157 SPEstd = 0.0048
-------------------------
2024-10-29 12:50:11: Evaluate 5 random ConvNet, F!mean = 0.4385 F!std = 0.0147
-------------------------
2024-10-29 12:50:11: Evaluate 5 random ConvNet, mean = 0.4470 std = 0.0144
-------------------------
2024-10-29 12:50:11: [2024-10-29 12:50:11] iter = 00000, loss = 12.4633
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:50:12: [2024-10-29 12:50:12] iter = 00010, loss = 52.0672
2024-10-29 12:50:12: [2024-10-29 12:50:12] iter = 00020, loss = 11.4010
2024-10-29 12:50:13: [2024-10-29 12:50:13] iter = 00030, loss = 11.2346
2024-10-29 12:50:13: [2024-10-29 12:50:13] iter = 00040, loss = 19.5518
2024-10-29 12:50:14: [2024-10-29 12:50:14] iter = 00050, loss = 12.0307
2024-10-29 12:50:14: [2024-10-29 12:50:14] iter = 00060, loss = 4.8628
2024-10-29 12:50:15: [2024-10-29 12:50:15] iter = 00070, loss = 7.9203
2024-10-29 12:50:15: [2024-10-29 12:50:15] iter = 00080, loss = 30.5653
2024-10-29 12:50:16: [2024-10-29 12:50:16] iter = 00090, loss = 7.6458
2024-10-29 12:50:16: [2024-10-29 12:50:16] iter = 00100, loss = 3.0273
2024-10-29 12:50:17: [2024-10-29 12:50:17] iter = 00110, loss = 5.1636
2024-10-29 12:50:17: [2024-10-29 12:50:17] iter = 00120, loss = 26.1965
2024-10-29 12:50:18: [2024-10-29 12:50:18] iter = 00130, loss = 3.7603
2024-10-29 12:50:18: [2024-10-29 12:50:18] iter = 00140, loss = 16.9506
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 00150, loss = 10.0421
2024-10-29 12:50:19: [2024-10-29 12:50:19] iter = 00160, loss = 5.1328
2024-10-29 12:50:20: [2024-10-29 12:50:20] iter = 00170, loss = 9.1310
2024-10-29 12:50:20: [2024-10-29 12:50:20] iter = 00180, loss = 3.2036
2024-10-29 12:50:21: [2024-10-29 12:50:21] iter = 00190, loss = 10.6414
2024-10-29 12:50:21: [2024-10-29 12:50:21] iter = 00200, loss = 10.1104
2024-10-29 12:50:22: [2024-10-29 12:50:22] iter = 00210, loss = 3.9428
2024-10-29 12:50:22: [2024-10-29 12:50:22] iter = 00220, loss = 3.9222
2024-10-29 12:50:23: [2024-10-29 12:50:23] iter = 00230, loss = 11.2372
2024-10-29 12:50:23: [2024-10-29 12:50:23] iter = 00240, loss = 2.6895
2024-10-29 12:50:24: [2024-10-29 12:50:24] iter = 00250, loss = 17.2331
2024-10-29 12:50:24: [2024-10-29 12:50:24] iter = 00260, loss = 7.0246
2024-10-29 12:50:25: [2024-10-29 12:50:25] iter = 00270, loss = 3.1288
2024-10-29 12:50:25: [2024-10-29 12:50:25] iter = 00280, loss = 3.4325
2024-10-29 12:50:26: [2024-10-29 12:50:26] iter = 00290, loss = 6.5542
2024-10-29 12:50:26: [2024-10-29 12:50:26] iter = 00300, loss = 10.9928
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 00310, loss = 27.0643
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 00320, loss = 10.7614
2024-10-29 12:50:27: [2024-10-29 12:50:27] iter = 00330, loss = 6.0886
2024-10-29 12:50:28: [2024-10-29 12:50:28] iter = 00340, loss = 11.3567
2024-10-29 12:50:28: [2024-10-29 12:50:28] iter = 00350, loss = 4.0730
2024-10-29 12:50:29: [2024-10-29 12:50:29] iter = 00360, loss = 4.8350
2024-10-29 12:50:29: [2024-10-29 12:50:29] iter = 00370, loss = 14.9273
2024-10-29 12:50:30: [2024-10-29 12:50:30] iter = 00380, loss = 47.5334
2024-10-29 12:50:30: [2024-10-29 12:50:30] iter = 00390, loss = 43.0831
2024-10-29 12:50:31: [2024-10-29 12:50:31] iter = 00400, loss = 4.5510
2024-10-29 12:50:31: [2024-10-29 12:50:31] iter = 00410, loss = 64.2164
2024-10-29 12:50:32: [2024-10-29 12:50:32] iter = 00420, loss = 8.4365
2024-10-29 12:50:33: [2024-10-29 12:50:33] iter = 00430, loss = 5.4615
2024-10-29 12:50:33: [2024-10-29 12:50:33] iter = 00440, loss = 10.3173
2024-10-29 12:50:34: [2024-10-29 12:50:34] iter = 00450, loss = 8.7934
2024-10-29 12:50:34: [2024-10-29 12:50:34] iter = 00460, loss = 5.3454
2024-10-29 12:50:35: [2024-10-29 12:50:35] iter = 00470, loss = 4.1950
2024-10-29 12:50:35: [2024-10-29 12:50:35] iter = 00480, loss = 11.6739
2024-10-29 12:50:36: [2024-10-29 12:50:36] iter = 00490, loss = 30.6030
2024-10-29 12:50:36: [2024-10-29 12:50:36] iter = 00500, loss = 4.2034
2024-10-29 12:50:37: [2024-10-29 12:50:37] iter = 00510, loss = 11.0281
2024-10-29 12:50:37: [2024-10-29 12:50:37] iter = 00520, loss = 19.4662
2024-10-29 12:50:38: [2024-10-29 12:50:38] iter = 00530, loss = 5.7990
2024-10-29 12:50:38: [2024-10-29 12:50:38] iter = 00540, loss = 8.5999
2024-10-29 12:50:39: [2024-10-29 12:50:39] iter = 00550, loss = 5.9478
2024-10-29 12:50:40: [2024-10-29 12:50:40] iter = 00560, loss = 2.8045
2024-10-29 12:50:40: [2024-10-29 12:50:40] iter = 00570, loss = 4.0462
2024-10-29 12:50:41: [2024-10-29 12:50:41] iter = 00580, loss = 12.2292
2024-10-29 12:50:41: [2024-10-29 12:50:41] iter = 00590, loss = 3.4886
2024-10-29 12:50:42: [2024-10-29 12:50:42] iter = 00600, loss = 16.6841
2024-10-29 12:50:42: [2024-10-29 12:50:42] iter = 00610, loss = 7.9692
2024-10-29 12:50:43: [2024-10-29 12:50:43] iter = 00620, loss = 9.5873
2024-10-29 12:50:43: [2024-10-29 12:50:43] iter = 00630, loss = 3.6877
2024-10-29 12:50:44: [2024-10-29 12:50:44] iter = 00640, loss = 3.2310
2024-10-29 12:50:44: [2024-10-29 12:50:44] iter = 00650, loss = 8.6498
2024-10-29 12:50:45: [2024-10-29 12:50:45] iter = 00660, loss = 4.1722
2024-10-29 12:50:45: [2024-10-29 12:50:45] iter = 00670, loss = 61.1636
2024-10-29 12:50:46: [2024-10-29 12:50:46] iter = 00680, loss = 7.0508
2024-10-29 12:50:46: [2024-10-29 12:50:46] iter = 00690, loss = 4.6321
2024-10-29 12:50:47: [2024-10-29 12:50:47] iter = 00700, loss = 3.7718
2024-10-29 12:50:47: [2024-10-29 12:50:47] iter = 00710, loss = 13.9585
2024-10-29 12:50:48: [2024-10-29 12:50:48] iter = 00720, loss = 49.3363
2024-10-29 12:50:48: [2024-10-29 12:50:48] iter = 00730, loss = 40.0540
2024-10-29 12:50:49: [2024-10-29 12:50:49] iter = 00740, loss = 4.7072
2024-10-29 12:50:49: [2024-10-29 12:50:49] iter = 00750, loss = 9.3617
2024-10-29 12:50:50: [2024-10-29 12:50:50] iter = 00760, loss = 13.0932
2024-10-29 12:50:50: [2024-10-29 12:50:50] iter = 00770, loss = 18.0527
2024-10-29 12:50:51: [2024-10-29 12:50:51] iter = 00780, loss = 6.6293
2024-10-29 12:50:51: [2024-10-29 12:50:51] iter = 00790, loss = 3.7904
2024-10-29 12:50:52: [2024-10-29 12:50:52] iter = 00800, loss = 11.4712
2024-10-29 12:50:52: [2024-10-29 12:50:52] iter = 00810, loss = 40.4425
2024-10-29 12:50:53: [2024-10-29 12:50:53] iter = 00820, loss = 3.0809
2024-10-29 12:50:53: [2024-10-29 12:50:53] iter = 00830, loss = 6.9438
2024-10-29 12:50:54: [2024-10-29 12:50:54] iter = 00840, loss = 5.7368
2024-10-29 12:50:54: [2024-10-29 12:50:54] iter = 00850, loss = 10.5553
2024-10-29 12:50:55: [2024-10-29 12:50:55] iter = 00860, loss = 4.0458
2024-10-29 12:50:55: [2024-10-29 12:50:55] iter = 00870, loss = 3.2919
2024-10-29 12:50:56: [2024-10-29 12:50:56] iter = 00880, loss = 33.6770
2024-10-29 12:50:56: [2024-10-29 12:50:56] iter = 00890, loss = 3.8079
2024-10-29 12:50:57: [2024-10-29 12:50:57] iter = 00900, loss = 4.4898
2024-10-29 12:50:57: [2024-10-29 12:50:57] iter = 00910, loss = 5.6444
2024-10-29 12:50:58: [2024-10-29 12:50:58] iter = 00920, loss = 47.6799
2024-10-29 12:50:58: [2024-10-29 12:50:58] iter = 00930, loss = 8.1864
2024-10-29 12:50:59: [2024-10-29 12:50:59] iter = 00940, loss = 7.3188
2024-10-29 12:50:59: [2024-10-29 12:50:59] iter = 00950, loss = 14.8514
2024-10-29 12:51:00: [2024-10-29 12:51:00] iter = 00960, loss = 8.8631
2024-10-29 12:51:00: [2024-10-29 12:51:00] iter = 00970, loss = 6.8378
2024-10-29 12:51:01: [2024-10-29 12:51:01] iter = 00980, loss = 12.7792
2024-10-29 12:51:01: [2024-10-29 12:51:01] iter = 00990, loss = 22.9769
2024-10-29 12:51:02: [2024-10-29 12:51:02] iter = 01000, loss = 14.9081
2024-10-29 12:51:02: [2024-10-29 12:51:02] iter = 01010, loss = 3.4845
2024-10-29 12:51:03: [2024-10-29 12:51:03] iter = 01020, loss = 3.2304
2024-10-29 12:51:03: [2024-10-29 12:51:03] iter = 01030, loss = 31.6000
2024-10-29 12:51:04: [2024-10-29 12:51:04] iter = 01040, loss = 11.1273
2024-10-29 12:51:04: [2024-10-29 12:51:04] iter = 01050, loss = 5.4095
2024-10-29 12:51:04: [2024-10-29 12:51:04] iter = 01060, loss = 6.3063
2024-10-29 12:51:05: [2024-10-29 12:51:05] iter = 01070, loss = 20.0252
2024-10-29 12:51:06: [2024-10-29 12:51:06] iter = 01080, loss = 15.1653
2024-10-29 12:51:06: [2024-10-29 12:51:06] iter = 01090, loss = 2.6532
2024-10-29 12:51:07: [2024-10-29 12:51:07] iter = 01100, loss = 13.4836
2024-10-29 12:51:07: [2024-10-29 12:51:07] iter = 01110, loss = 3.8340
2024-10-29 12:51:08: [2024-10-29 12:51:08] iter = 01120, loss = 28.4168
2024-10-29 12:51:08: [2024-10-29 12:51:08] iter = 01130, loss = 5.5875
2024-10-29 12:51:09: [2024-10-29 12:51:09] iter = 01140, loss = 7.9164
2024-10-29 12:51:09: [2024-10-29 12:51:09] iter = 01150, loss = 3.0784
2024-10-29 12:51:10: [2024-10-29 12:51:10] iter = 01160, loss = 4.3539
2024-10-29 12:51:11: [2024-10-29 12:51:11] iter = 01170, loss = 9.1374
2024-10-29 12:51:12: [2024-10-29 12:51:12] iter = 01180, loss = 6.0679
2024-10-29 12:51:13: [2024-10-29 12:51:12] iter = 01190, loss = 6.4850
2024-10-29 12:51:13: [2024-10-29 12:51:13] iter = 01200, loss = 9.2845
2024-10-29 12:51:14: [2024-10-29 12:51:14] iter = 01210, loss = 9.1017
2024-10-29 12:51:14: [2024-10-29 12:51:14] iter = 01220, loss = 30.4966
2024-10-29 12:51:15: [2024-10-29 12:51:15] iter = 01230, loss = 6.0200
2024-10-29 12:51:16: [2024-10-29 12:51:16] iter = 01240, loss = 6.3724
2024-10-29 12:51:17: [2024-10-29 12:51:17] iter = 01250, loss = 6.2653
2024-10-29 12:51:17: [2024-10-29 12:51:17] iter = 01260, loss = 23.1574
2024-10-29 12:51:18: [2024-10-29 12:51:18] iter = 01270, loss = 10.4133
2024-10-29 12:51:18: [2024-10-29 12:51:18] iter = 01280, loss = 5.4280
2024-10-29 12:51:19: [2024-10-29 12:51:19] iter = 01290, loss = 13.1845
2024-10-29 12:51:19: [2024-10-29 12:51:19] iter = 01300, loss = 32.7924
2024-10-29 12:51:20: [2024-10-29 12:51:20] iter = 01310, loss = 12.7836
2024-10-29 12:51:20: [2024-10-29 12:51:20] iter = 01320, loss = 6.7423
2024-10-29 12:51:21: [2024-10-29 12:51:21] iter = 01330, loss = 2.8537
2024-10-29 12:51:21: [2024-10-29 12:51:21] iter = 01340, loss = 5.5049
2024-10-29 12:51:22: [2024-10-29 12:51:22] iter = 01350, loss = 3.6641
2024-10-29 12:51:22: [2024-10-29 12:51:22] iter = 01360, loss = 14.4412
2024-10-29 12:51:23: [2024-10-29 12:51:23] iter = 01370, loss = 2.4067
2024-10-29 12:51:23: [2024-10-29 12:51:23] iter = 01380, loss = 3.2571
2024-10-29 12:51:24: [2024-10-29 12:51:24] iter = 01390, loss = 15.4910
2024-10-29 12:51:24: [2024-10-29 12:51:24] iter = 01400, loss = 12.4607
2024-10-29 12:51:25: [2024-10-29 12:51:25] iter = 01410, loss = 3.2463
2024-10-29 12:51:25: [2024-10-29 12:51:25] iter = 01420, loss = 17.7773
2024-10-29 12:51:26: [2024-10-29 12:51:26] iter = 01430, loss = 5.5498
2024-10-29 12:51:26: [2024-10-29 12:51:26] iter = 01440, loss = 4.5295
2024-10-29 12:51:27: [2024-10-29 12:51:27] iter = 01450, loss = 5.4646
2024-10-29 12:51:27: [2024-10-29 12:51:27] iter = 01460, loss = 20.7304
2024-10-29 12:51:28: [2024-10-29 12:51:28] iter = 01470, loss = 10.0857
2024-10-29 12:51:29: [2024-10-29 12:51:29] iter = 01480, loss = 5.6440
2024-10-29 12:51:29: [2024-10-29 12:51:29] iter = 01490, loss = 6.8200
2024-10-29 12:51:30: [2024-10-29 12:51:30] iter = 01500, loss = 3.5431
2024-10-29 12:51:30: [2024-10-29 12:51:30] iter = 01510, loss = 33.0697
2024-10-29 12:51:31: [2024-10-29 12:51:31] iter = 01520, loss = 11.9730
2024-10-29 12:51:31: [2024-10-29 12:51:31] iter = 01530, loss = 3.2147
2024-10-29 12:51:32: [2024-10-29 12:51:32] iter = 01540, loss = 4.3697
2024-10-29 12:51:32: [2024-10-29 12:51:32] iter = 01550, loss = 11.2294
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 01560, loss = 18.3049
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 01570, loss = 5.5610
2024-10-29 12:51:33: [2024-10-29 12:51:33] iter = 01580, loss = 42.3407
2024-10-29 12:51:34: [2024-10-29 12:51:34] iter = 01590, loss = 101.2480
2024-10-29 12:51:34: [2024-10-29 12:51:34] iter = 01600, loss = 4.8890
2024-10-29 12:51:35: [2024-10-29 12:51:35] iter = 01610, loss = 2.8438
2024-10-29 12:51:35: [2024-10-29 12:51:35] iter = 01620, loss = 11.0682
2024-10-29 12:51:36: [2024-10-29 12:51:36] iter = 01630, loss = 6.7777
2024-10-29 12:51:36: [2024-10-29 12:51:36] iter = 01640, loss = 16.2526
2024-10-29 12:51:37: [2024-10-29 12:51:37] iter = 01650, loss = 4.7774
2024-10-29 12:51:37: [2024-10-29 12:51:37] iter = 01660, loss = 7.2070
2024-10-29 12:51:38: [2024-10-29 12:51:38] iter = 01670, loss = 4.7336
2024-10-29 12:51:38: [2024-10-29 12:51:38] iter = 01680, loss = 49.6639
2024-10-29 12:51:39: [2024-10-29 12:51:39] iter = 01690, loss = 10.0682
2024-10-29 12:51:39: [2024-10-29 12:51:39] iter = 01700, loss = 29.4387
2024-10-29 12:51:40: [2024-10-29 12:51:40] iter = 01710, loss = 4.9442
2024-10-29 12:51:40: [2024-10-29 12:51:40] iter = 01720, loss = 8.4566
2024-10-29 12:51:41: [2024-10-29 12:51:41] iter = 01730, loss = 47.7819
2024-10-29 12:51:41: [2024-10-29 12:51:41] iter = 01740, loss = 12.9322
2024-10-29 12:51:42: [2024-10-29 12:51:42] iter = 01750, loss = 4.8352
2024-10-29 12:51:42: [2024-10-29 12:51:42] iter = 01760, loss = 4.7569
2024-10-29 12:51:43: [2024-10-29 12:51:43] iter = 01770, loss = 2.7187
2024-10-29 12:51:43: [2024-10-29 12:51:43] iter = 01780, loss = 7.1773
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 01790, loss = 11.7508
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 01800, loss = 35.3106
2024-10-29 12:51:44: [2024-10-29 12:51:44] iter = 01810, loss = 27.8035
2024-10-29 12:51:45: [2024-10-29 12:51:45] iter = 01820, loss = 4.6354
2024-10-29 12:51:45: [2024-10-29 12:51:45] iter = 01830, loss = 5.6436
2024-10-29 12:51:46: [2024-10-29 12:51:46] iter = 01840, loss = 4.4322
2024-10-29 12:51:46: [2024-10-29 12:51:46] iter = 01850, loss = 8.3251
2024-10-29 12:51:47: [2024-10-29 12:51:47] iter = 01860, loss = 6.8552
2024-10-29 12:51:47: [2024-10-29 12:51:47] iter = 01870, loss = 14.7258
2024-10-29 12:51:48: [2024-10-29 12:51:48] iter = 01880, loss = 37.9387
2024-10-29 12:51:48: [2024-10-29 12:51:48] iter = 01890, loss = 2.7663
2024-10-29 12:51:49: [2024-10-29 12:51:49] iter = 01900, loss = 18.1555
2024-10-29 12:51:49: [2024-10-29 12:51:49] iter = 01910, loss = 6.4237
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 01920, loss = 2.8450
2024-10-29 12:51:50: [2024-10-29 12:51:50] iter = 01930, loss = 29.6623
2024-10-29 12:51:51: [2024-10-29 12:51:51] iter = 01940, loss = 7.2532
2024-10-29 12:51:51: [2024-10-29 12:51:51] iter = 01950, loss = 14.8346
2024-10-29 12:51:52: [2024-10-29 12:51:52] iter = 01960, loss = 5.1154
2024-10-29 12:51:52: [2024-10-29 12:51:52] iter = 01970, loss = 11.0896
2024-10-29 12:51:53: [2024-10-29 12:51:53] iter = 01980, loss = 4.2228
2024-10-29 12:51:53: [2024-10-29 12:51:53] iter = 01990, loss = 2.9654
2024-10-29 12:51:54: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 12:51:54: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:51:54: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 14310}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:52:20: Evaluate 5 random ConvNet, ACCmean = 0.5408 ACCstd = 0.0080
-------------------------
2024-10-29 12:52:20: Evaluate 5 random ConvNet, SENmean = 0.5408 SENstd = 0.0080
-------------------------
2024-10-29 12:52:20: Evaluate 5 random ConvNet, SPEmean = 0.8469 SPEstd = 0.0027
-------------------------
2024-10-29 12:52:20: Evaluate 5 random ConvNet, F!mean = 0.5018 F!std = 0.0082
-------------------------
2024-10-29 12:52:20: Evaluate 5 random ConvNet, mean = 0.5408 std = 0.0080
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:52:20: [2024-10-29 12:52:20] iter = 02000, loss = 4.3582
2024-10-29 12:52:20: [2024-10-29 12:52:20] iter = 02010, loss = 42.6660
2024-10-29 12:52:21: [2024-10-29 12:52:21] iter = 02020, loss = 32.1034
2024-10-29 12:52:21: [2024-10-29 12:52:21] iter = 02030, loss = 8.0162
2024-10-29 12:52:22: [2024-10-29 12:52:22] iter = 02040, loss = 6.2984
2024-10-29 12:52:22: [2024-10-29 12:52:22] iter = 02050, loss = 3.8859
2024-10-29 12:52:23: [2024-10-29 12:52:23] iter = 02060, loss = 3.5949
2024-10-29 12:52:23: [2024-10-29 12:52:23] iter = 02070, loss = 18.4630
2024-10-29 12:52:24: [2024-10-29 12:52:24] iter = 02080, loss = 3.2919
2024-10-29 12:52:25: [2024-10-29 12:52:25] iter = 02090, loss = 4.6133
2024-10-29 12:52:25: [2024-10-29 12:52:25] iter = 02100, loss = 7.2471
2024-10-29 12:52:26: [2024-10-29 12:52:26] iter = 02110, loss = 12.7166
2024-10-29 12:52:27: [2024-10-29 12:52:27] iter = 02120, loss = 3.4809
2024-10-29 12:52:27: [2024-10-29 12:52:27] iter = 02130, loss = 3.5252
2024-10-29 12:52:28: [2024-10-29 12:52:28] iter = 02140, loss = 3.5559
2024-10-29 12:52:29: [2024-10-29 12:52:29] iter = 02150, loss = 4.7348
2024-10-29 12:52:30: [2024-10-29 12:52:30] iter = 02160, loss = 5.2253
2024-10-29 12:52:30: [2024-10-29 12:52:30] iter = 02170, loss = 13.1470
2024-10-29 12:52:31: [2024-10-29 12:52:31] iter = 02180, loss = 4.2137
2024-10-29 12:52:31: [2024-10-29 12:52:31] iter = 02190, loss = 6.7576
2024-10-29 12:52:32: [2024-10-29 12:52:32] iter = 02200, loss = 5.3810
2024-10-29 12:52:33: [2024-10-29 12:52:33] iter = 02210, loss = 3.5438
2024-10-29 12:52:34: [2024-10-29 12:52:34] iter = 02220, loss = 11.9957
2024-10-29 12:52:34: [2024-10-29 12:52:34] iter = 02230, loss = 9.9054
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 02240, loss = 4.2899
2024-10-29 12:52:35: [2024-10-29 12:52:35] iter = 02250, loss = 2.4209
2024-10-29 12:52:36: [2024-10-29 12:52:36] iter = 02260, loss = 4.5246
2024-10-29 12:52:36: [2024-10-29 12:52:36] iter = 02270, loss = 2.6381
2024-10-29 12:52:37: [2024-10-29 12:52:37] iter = 02280, loss = 15.3406
2024-10-29 12:52:37: [2024-10-29 12:52:37] iter = 02290, loss = 3.7815
2024-10-29 12:52:38: [2024-10-29 12:52:38] iter = 02300, loss = 7.8090
2024-10-29 12:52:38: [2024-10-29 12:52:38] iter = 02310, loss = 5.5088
2024-10-29 12:52:39: [2024-10-29 12:52:39] iter = 02320, loss = 3.1814
2024-10-29 12:52:39: [2024-10-29 12:52:39] iter = 02330, loss = 8.6178
2024-10-29 12:52:40: [2024-10-29 12:52:40] iter = 02340, loss = 5.6847
2024-10-29 12:52:41: [2024-10-29 12:52:41] iter = 02350, loss = 3.0200
2024-10-29 12:52:41: [2024-10-29 12:52:41] iter = 02360, loss = 6.1821
2024-10-29 12:52:42: [2024-10-29 12:52:42] iter = 02370, loss = 15.9053
2024-10-29 12:52:42: [2024-10-29 12:52:42] iter = 02380, loss = 4.7373
2024-10-29 12:52:43: [2024-10-29 12:52:43] iter = 02390, loss = 2.6788
2024-10-29 12:52:43: [2024-10-29 12:52:43] iter = 02400, loss = 4.1075
2024-10-29 12:52:44: [2024-10-29 12:52:44] iter = 02410, loss = 59.2238
2024-10-29 12:52:44: [2024-10-29 12:52:44] iter = 02420, loss = 8.4885
2024-10-29 12:52:45: [2024-10-29 12:52:45] iter = 02430, loss = 11.7278
2024-10-29 12:52:45: [2024-10-29 12:52:45] iter = 02440, loss = 7.3475
2024-10-29 12:52:46: [2024-10-29 12:52:46] iter = 02450, loss = 5.1305
2024-10-29 12:52:46: [2024-10-29 12:52:46] iter = 02460, loss = 8.1418
2024-10-29 12:52:47: [2024-10-29 12:52:47] iter = 02470, loss = 3.0652
2024-10-29 12:52:48: [2024-10-29 12:52:48] iter = 02480, loss = 7.6680
2024-10-29 12:52:48: [2024-10-29 12:52:48] iter = 02490, loss = 2.2825
2024-10-29 12:52:49: [2024-10-29 12:52:49] iter = 02500, loss = 4.3514
2024-10-29 12:52:49: [2024-10-29 12:52:49] iter = 02510, loss = 9.8374
2024-10-29 12:52:50: [2024-10-29 12:52:50] iter = 02520, loss = 3.0637
2024-10-29 12:52:50: [2024-10-29 12:52:50] iter = 02530, loss = 3.6547
2024-10-29 12:52:51: [2024-10-29 12:52:51] iter = 02540, loss = 5.3662
2024-10-29 12:52:51: [2024-10-29 12:52:51] iter = 02550, loss = 26.6856
2024-10-29 12:52:51: [2024-10-29 12:52:51] iter = 02560, loss = 7.7819
2024-10-29 12:52:52: [2024-10-29 12:52:52] iter = 02570, loss = 6.1678
2024-10-29 12:52:53: [2024-10-29 12:52:53] iter = 02580, loss = 5.2140
2024-10-29 12:52:53: [2024-10-29 12:52:53] iter = 02590, loss = 6.9088
2024-10-29 12:52:54: [2024-10-29 12:52:54] iter = 02600, loss = 13.1020
2024-10-29 12:52:54: [2024-10-29 12:52:54] iter = 02610, loss = 10.8668
2024-10-29 12:52:55: [2024-10-29 12:52:55] iter = 02620, loss = 3.3034
2024-10-29 12:52:56: [2024-10-29 12:52:56] iter = 02630, loss = 5.6459
2024-10-29 12:52:56: [2024-10-29 12:52:56] iter = 02640, loss = 11.8006
2024-10-29 12:52:57: [2024-10-29 12:52:57] iter = 02650, loss = 3.3987
2024-10-29 12:52:57: [2024-10-29 12:52:57] iter = 02660, loss = 4.9903
2024-10-29 12:52:58: [2024-10-29 12:52:58] iter = 02670, loss = 3.2099
2024-10-29 12:52:58: [2024-10-29 12:52:58] iter = 02680, loss = 2.9684
2024-10-29 12:52:59: [2024-10-29 12:52:59] iter = 02690, loss = 21.4420
2024-10-29 12:52:59: [2024-10-29 12:52:59] iter = 02700, loss = 51.4005
2024-10-29 12:53:00: [2024-10-29 12:53:00] iter = 02710, loss = 31.7779
2024-10-29 12:53:00: [2024-10-29 12:53:00] iter = 02720, loss = 6.3230
2024-10-29 12:53:01: [2024-10-29 12:53:01] iter = 02730, loss = 2.7487
2024-10-29 12:53:02: [2024-10-29 12:53:02] iter = 02740, loss = 12.1796
2024-10-29 12:53:02: [2024-10-29 12:53:02] iter = 02750, loss = 3.9937
2024-10-29 12:53:03: [2024-10-29 12:53:03] iter = 02760, loss = 4.3000
2024-10-29 12:53:03: [2024-10-29 12:53:03] iter = 02770, loss = 14.4290
2024-10-29 12:53:04: [2024-10-29 12:53:04] iter = 02780, loss = 4.3920
2024-10-29 12:53:04: [2024-10-29 12:53:04] iter = 02790, loss = 13.8471
2024-10-29 12:53:05: [2024-10-29 12:53:05] iter = 02800, loss = 18.1919
2024-10-29 12:53:05: [2024-10-29 12:53:05] iter = 02810, loss = 5.4122
2024-10-29 12:53:06: [2024-10-29 12:53:06] iter = 02820, loss = 12.6243
2024-10-29 12:53:06: [2024-10-29 12:53:06] iter = 02830, loss = 5.1249
2024-10-29 12:53:07: [2024-10-29 12:53:07] iter = 02840, loss = 4.3642
2024-10-29 12:53:07: [2024-10-29 12:53:07] iter = 02850, loss = 8.0708
2024-10-29 12:53:08: [2024-10-29 12:53:08] iter = 02860, loss = 4.0503
2024-10-29 12:53:09: [2024-10-29 12:53:09] iter = 02870, loss = 4.3236
2024-10-29 12:53:09: [2024-10-29 12:53:09] iter = 02880, loss = 6.2874
2024-10-29 12:53:10: [2024-10-29 12:53:10] iter = 02890, loss = 10.0774
2024-10-29 12:53:10: [2024-10-29 12:53:10] iter = 02900, loss = 3.8321
2024-10-29 12:53:11: [2024-10-29 12:53:11] iter = 02910, loss = 4.5456
2024-10-29 12:53:11: [2024-10-29 12:53:11] iter = 02920, loss = 9.2213
2024-10-29 12:53:12: [2024-10-29 12:53:12] iter = 02930, loss = 4.7843
2024-10-29 12:53:12: [2024-10-29 12:53:12] iter = 02940, loss = 5.3361
2024-10-29 12:53:13: [2024-10-29 12:53:13] iter = 02950, loss = 5.5302
2024-10-29 12:53:13: [2024-10-29 12:53:13] iter = 02960, loss = 36.9858
2024-10-29 12:53:14: [2024-10-29 12:53:14] iter = 02970, loss = 10.7384
2024-10-29 12:53:15: [2024-10-29 12:53:15] iter = 02980, loss = 11.2309
2024-10-29 12:53:15: [2024-10-29 12:53:15] iter = 02990, loss = 3.0251
2024-10-29 12:53:16: [2024-10-29 12:53:16] iter = 03000, loss = 5.0046
2024-10-29 12:53:16: [2024-10-29 12:53:16] iter = 03010, loss = 5.8596
2024-10-29 12:53:17: [2024-10-29 12:53:17] iter = 03020, loss = 4.0195
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 03030, loss = 11.5805
2024-10-29 12:53:18: [2024-10-29 12:53:18] iter = 03040, loss = 3.5287
2024-10-29 12:53:19: [2024-10-29 12:53:19] iter = 03050, loss = 2.9380
2024-10-29 12:53:19: [2024-10-29 12:53:19] iter = 03060, loss = 5.0652
2024-10-29 12:53:20: [2024-10-29 12:53:20] iter = 03070, loss = 6.2063
2024-10-29 12:53:20: [2024-10-29 12:53:20] iter = 03080, loss = 3.4465
2024-10-29 12:53:21: [2024-10-29 12:53:21] iter = 03090, loss = 2.4347
2024-10-29 12:53:21: [2024-10-29 12:53:21] iter = 03100, loss = 3.4233
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 03110, loss = 11.8695
2024-10-29 12:53:22: [2024-10-29 12:53:22] iter = 03120, loss = 9.6444
2024-10-29 12:53:23: [2024-10-29 12:53:23] iter = 03130, loss = 4.2128
2024-10-29 12:53:23: [2024-10-29 12:53:23] iter = 03140, loss = 10.8658
2024-10-29 12:53:24: [2024-10-29 12:53:24] iter = 03150, loss = 2.1451
2024-10-29 12:53:24: [2024-10-29 12:53:24] iter = 03160, loss = 16.9625
2024-10-29 12:53:25: [2024-10-29 12:53:25] iter = 03170, loss = 6.3165
2024-10-29 12:53:26: [2024-10-29 12:53:26] iter = 03180, loss = 5.3212
2024-10-29 12:53:26: [2024-10-29 12:53:26] iter = 03190, loss = 7.6147
2024-10-29 12:53:27: [2024-10-29 12:53:27] iter = 03200, loss = 4.1465
2024-10-29 12:53:27: [2024-10-29 12:53:27] iter = 03210, loss = 5.4563
2024-10-29 12:53:28: [2024-10-29 12:53:28] iter = 03220, loss = 4.1541
2024-10-29 12:53:28: [2024-10-29 12:53:28] iter = 03230, loss = 5.6785
2024-10-29 12:53:29: [2024-10-29 12:53:29] iter = 03240, loss = 54.6206
2024-10-29 12:53:29: [2024-10-29 12:53:29] iter = 03250, loss = 2.9630
2024-10-29 12:53:30: [2024-10-29 12:53:30] iter = 03260, loss = 3.4959
2024-10-29 12:53:30: [2024-10-29 12:53:30] iter = 03270, loss = 3.0621
2024-10-29 12:53:31: [2024-10-29 12:53:31] iter = 03280, loss = 3.5754
2024-10-29 12:53:31: [2024-10-29 12:53:31] iter = 03290, loss = 8.6052
2024-10-29 12:53:32: [2024-10-29 12:53:32] iter = 03300, loss = 15.2063
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 03310, loss = 2.9497
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 03320, loss = 2.8571
2024-10-29 12:53:33: [2024-10-29 12:53:33] iter = 03330, loss = 23.3752
2024-10-29 12:53:34: [2024-10-29 12:53:34] iter = 03340, loss = 4.0344
2024-10-29 12:53:34: [2024-10-29 12:53:34] iter = 03350, loss = 2.7426
2024-10-29 12:53:35: [2024-10-29 12:53:35] iter = 03360, loss = 19.8981
2024-10-29 12:53:35: [2024-10-29 12:53:35] iter = 03370, loss = 5.5188
2024-10-29 12:53:36: [2024-10-29 12:53:36] iter = 03380, loss = 6.6761
2024-10-29 12:53:36: [2024-10-29 12:53:36] iter = 03390, loss = 9.4105
2024-10-29 12:53:37: [2024-10-29 12:53:37] iter = 03400, loss = 3.8340
2024-10-29 12:53:38: [2024-10-29 12:53:38] iter = 03410, loss = 3.8606
2024-10-29 12:53:38: [2024-10-29 12:53:38] iter = 03420, loss = 20.6030
2024-10-29 12:53:39: [2024-10-29 12:53:39] iter = 03430, loss = 2.5366
2024-10-29 12:53:40: [2024-10-29 12:53:40] iter = 03440, loss = 5.8807
2024-10-29 12:53:41: [2024-10-29 12:53:41] iter = 03450, loss = 8.7765
2024-10-29 12:53:42: [2024-10-29 12:53:42] iter = 03460, loss = 5.1021
2024-10-29 12:53:43: [2024-10-29 12:53:43] iter = 03470, loss = 15.4614
2024-10-29 12:53:43: [2024-10-29 12:53:43] iter = 03480, loss = 5.4436
2024-10-29 12:53:44: [2024-10-29 12:53:44] iter = 03490, loss = 13.0560
2024-10-29 12:53:44: [2024-10-29 12:53:44] iter = 03500, loss = 7.2639
2024-10-29 12:53:45: [2024-10-29 12:53:45] iter = 03510, loss = 3.9962
2024-10-29 12:53:46: [2024-10-29 12:53:46] iter = 03520, loss = 7.6059
2024-10-29 12:53:46: [2024-10-29 12:53:46] iter = 03530, loss = 5.2170
2024-10-29 12:53:47: [2024-10-29 12:53:47] iter = 03540, loss = 5.0010
2024-10-29 12:53:48: [2024-10-29 12:53:48] iter = 03550, loss = 30.2475
2024-10-29 12:53:48: [2024-10-29 12:53:48] iter = 03560, loss = 18.9110
2024-10-29 12:53:49: [2024-10-29 12:53:49] iter = 03570, loss = 4.9377
2024-10-29 12:53:49: [2024-10-29 12:53:49] iter = 03580, loss = 5.3641
2024-10-29 12:53:50: [2024-10-29 12:53:50] iter = 03590, loss = 8.4719
2024-10-29 12:53:50: [2024-10-29 12:53:50] iter = 03600, loss = 2.5852
2024-10-29 12:53:51: [2024-10-29 12:53:51] iter = 03610, loss = 5.8349
2024-10-29 12:53:51: [2024-10-29 12:53:51] iter = 03620, loss = 9.3727
2024-10-29 12:53:52: [2024-10-29 12:53:52] iter = 03630, loss = 6.1743
2024-10-29 12:53:53: [2024-10-29 12:53:53] iter = 03640, loss = 7.8925
2024-10-29 12:53:53: [2024-10-29 12:53:53] iter = 03650, loss = 3.7743
2024-10-29 12:53:54: [2024-10-29 12:53:54] iter = 03660, loss = 5.4815
2024-10-29 12:53:54: [2024-10-29 12:53:54] iter = 03670, loss = 22.4321
2024-10-29 12:53:55: [2024-10-29 12:53:55] iter = 03680, loss = 4.1539
2024-10-29 12:53:56: [2024-10-29 12:53:56] iter = 03690, loss = 2.7122
2024-10-29 12:53:56: [2024-10-29 12:53:56] iter = 03700, loss = 4.2801
2024-10-29 12:53:57: [2024-10-29 12:53:57] iter = 03710, loss = 3.5860
2024-10-29 12:53:57: [2024-10-29 12:53:57] iter = 03720, loss = 4.9657
2024-10-29 12:53:58: [2024-10-29 12:53:58] iter = 03730, loss = 12.8326
2024-10-29 12:53:59: [2024-10-29 12:53:59] iter = 03740, loss = 3.0690
2024-10-29 12:53:59: [2024-10-29 12:53:59] iter = 03750, loss = 9.3094
2024-10-29 12:54:00: [2024-10-29 12:54:00] iter = 03760, loss = 9.8105
2024-10-29 12:54:00: [2024-10-29 12:54:00] iter = 03770, loss = 6.8061
2024-10-29 12:54:01: [2024-10-29 12:54:01] iter = 03780, loss = 29.8050
2024-10-29 12:54:01: [2024-10-29 12:54:01] iter = 03790, loss = 8.5617
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 03800, loss = 6.8026
2024-10-29 12:54:02: [2024-10-29 12:54:02] iter = 03810, loss = 2.5846
2024-10-29 12:54:03: [2024-10-29 12:54:03] iter = 03820, loss = 2.4275
2024-10-29 12:54:03: [2024-10-29 12:54:03] iter = 03830, loss = 6.9566
2024-10-29 12:54:04: [2024-10-29 12:54:04] iter = 03840, loss = 3.5049
2024-10-29 12:54:04: [2024-10-29 12:54:04] iter = 03850, loss = 10.5483
2024-10-29 12:54:05: [2024-10-29 12:54:05] iter = 03860, loss = 3.9239
2024-10-29 12:54:05: [2024-10-29 12:54:05] iter = 03870, loss = 7.6956
2024-10-29 12:54:06: [2024-10-29 12:54:06] iter = 03880, loss = 3.7625
2024-10-29 12:54:07: [2024-10-29 12:54:07] iter = 03890, loss = 2.8375
2024-10-29 12:54:07: [2024-10-29 12:54:07] iter = 03900, loss = 3.4064
2024-10-29 12:54:08: [2024-10-29 12:54:08] iter = 03910, loss = 18.3143
2024-10-29 12:54:08: [2024-10-29 12:54:08] iter = 03920, loss = 5.5151
2024-10-29 12:54:09: [2024-10-29 12:54:09] iter = 03930, loss = 4.9307
2024-10-29 12:54:09: [2024-10-29 12:54:09] iter = 03940, loss = 3.7370
2024-10-29 12:54:10: [2024-10-29 12:54:10] iter = 03950, loss = 43.3934
2024-10-29 12:54:10: [2024-10-29 12:54:10] iter = 03960, loss = 4.2282
2024-10-29 12:54:11: [2024-10-29 12:54:11] iter = 03970, loss = 3.7037
2024-10-29 12:54:11: [2024-10-29 12:54:11] iter = 03980, loss = 32.2048
2024-10-29 12:54:12: [2024-10-29 12:54:12] iter = 03990, loss = 5.2968
2024-10-29 12:54:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 12:54:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:54:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52724}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:54:38: Evaluate 5 random ConvNet, ACCmean = 0.4632 ACCstd = 0.0100
-------------------------
2024-10-29 12:54:38: Evaluate 5 random ConvNet, SENmean = 0.4632 SENstd = 0.0100
-------------------------
2024-10-29 12:54:38: Evaluate 5 random ConvNet, SPEmean = 0.8211 SPEstd = 0.0033
-------------------------
2024-10-29 12:54:38: Evaluate 5 random ConvNet, F!mean = 0.3733 F!std = 0.0122
-------------------------
2024-10-29 12:54:38: Evaluate 5 random ConvNet, mean = 0.4632 std = 0.0100
-------------------------
2024-10-29 12:54:38: [2024-10-29 12:54:38] iter = 04000, loss = 3.8492
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:54:39: [2024-10-29 12:54:39] iter = 04010, loss = 3.6858
2024-10-29 12:54:39: [2024-10-29 12:54:39] iter = 04020, loss = 15.4986
2024-10-29 12:54:40: [2024-10-29 12:54:40] iter = 04030, loss = 4.1787
2024-10-29 12:54:40: [2024-10-29 12:54:40] iter = 04040, loss = 4.9365
2024-10-29 12:54:41: [2024-10-29 12:54:41] iter = 04050, loss = 59.7714
2024-10-29 12:54:41: [2024-10-29 12:54:41] iter = 04060, loss = 4.3404
2024-10-29 12:54:42: [2024-10-29 12:54:42] iter = 04070, loss = 3.8618
2024-10-29 12:54:42: [2024-10-29 12:54:42] iter = 04080, loss = 23.9701
2024-10-29 12:54:43: [2024-10-29 12:54:43] iter = 04090, loss = 74.6597
2024-10-29 12:54:43: [2024-10-29 12:54:43] iter = 04100, loss = 4.6767
2024-10-29 12:54:44: [2024-10-29 12:54:44] iter = 04110, loss = 4.6207
2024-10-29 12:54:44: [2024-10-29 12:54:44] iter = 04120, loss = 21.9140
2024-10-29 12:54:45: [2024-10-29 12:54:45] iter = 04130, loss = 29.0119
2024-10-29 12:54:45: [2024-10-29 12:54:45] iter = 04140, loss = 3.6006
2024-10-29 12:54:46: [2024-10-29 12:54:46] iter = 04150, loss = 18.5223
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 04160, loss = 4.7431
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 04170, loss = 41.6306
2024-10-29 12:54:47: [2024-10-29 12:54:47] iter = 04180, loss = 4.0956
2024-10-29 12:54:48: [2024-10-29 12:54:48] iter = 04190, loss = 10.2566
2024-10-29 12:54:48: [2024-10-29 12:54:48] iter = 04200, loss = 4.1340
2024-10-29 12:54:49: [2024-10-29 12:54:49] iter = 04210, loss = 4.6960
2024-10-29 12:54:49: [2024-10-29 12:54:49] iter = 04220, loss = 16.4041
2024-10-29 12:54:50: [2024-10-29 12:54:50] iter = 04230, loss = 3.2117
2024-10-29 12:54:51: [2024-10-29 12:54:51] iter = 04240, loss = 22.8644
2024-10-29 12:54:51: [2024-10-29 12:54:51] iter = 04250, loss = 7.6793
2024-10-29 12:54:52: [2024-10-29 12:54:52] iter = 04260, loss = 10.2073
2024-10-29 12:54:52: [2024-10-29 12:54:52] iter = 04270, loss = 4.7244
2024-10-29 12:54:53: [2024-10-29 12:54:53] iter = 04280, loss = 5.1749
2024-10-29 12:54:53: [2024-10-29 12:54:53] iter = 04290, loss = 5.1284
2024-10-29 12:54:54: [2024-10-29 12:54:54] iter = 04300, loss = 30.7199
2024-10-29 12:54:54: [2024-10-29 12:54:54] iter = 04310, loss = 4.5573
2024-10-29 12:54:55: [2024-10-29 12:54:55] iter = 04320, loss = 4.6367
2024-10-29 12:54:55: [2024-10-29 12:54:55] iter = 04330, loss = 14.6967
2024-10-29 12:54:56: [2024-10-29 12:54:56] iter = 04340, loss = 4.6164
2024-10-29 12:54:56: [2024-10-29 12:54:56] iter = 04350, loss = 7.2887
2024-10-29 12:54:57: [2024-10-29 12:54:57] iter = 04360, loss = 8.8480
2024-10-29 12:54:57: [2024-10-29 12:54:57] iter = 04370, loss = 5.0412
2024-10-29 12:54:58: [2024-10-29 12:54:58] iter = 04380, loss = 3.3798
2024-10-29 12:54:58: [2024-10-29 12:54:58] iter = 04390, loss = 6.0543
2024-10-29 12:54:59: [2024-10-29 12:54:59] iter = 04400, loss = 7.1114
2024-10-29 12:54:59: [2024-10-29 12:54:59] iter = 04410, loss = 6.4788
2024-10-29 12:55:00: [2024-10-29 12:55:00] iter = 04420, loss = 8.7997
2024-10-29 12:55:01: [2024-10-29 12:55:01] iter = 04430, loss = 7.9624
2024-10-29 12:55:01: [2024-10-29 12:55:01] iter = 04440, loss = 2.0818
2024-10-29 12:55:02: [2024-10-29 12:55:02] iter = 04450, loss = 23.9695
2024-10-29 12:55:02: [2024-10-29 12:55:02] iter = 04460, loss = 7.0916
2024-10-29 12:55:03: [2024-10-29 12:55:03] iter = 04470, loss = 54.7608
2024-10-29 12:55:03: [2024-10-29 12:55:03] iter = 04480, loss = 7.1027
2024-10-29 12:55:04: [2024-10-29 12:55:04] iter = 04490, loss = 7.9355
2024-10-29 12:55:04: [2024-10-29 12:55:04] iter = 04500, loss = 15.9285
2024-10-29 12:55:05: [2024-10-29 12:55:05] iter = 04510, loss = 2.9406
2024-10-29 12:55:05: [2024-10-29 12:55:05] iter = 04520, loss = 33.4717
2024-10-29 12:55:06: [2024-10-29 12:55:06] iter = 04530, loss = 3.2464
2024-10-29 12:55:06: [2024-10-29 12:55:06] iter = 04540, loss = 7.8648
2024-10-29 12:55:07: [2024-10-29 12:55:07] iter = 04550, loss = 5.7751
2024-10-29 12:55:07: [2024-10-29 12:55:07] iter = 04560, loss = 3.2687
2024-10-29 12:55:08: [2024-10-29 12:55:08] iter = 04570, loss = 3.1297
2024-10-29 12:55:09: [2024-10-29 12:55:09] iter = 04580, loss = 4.6240
2024-10-29 12:55:09: [2024-10-29 12:55:09] iter = 04590, loss = 5.6130
2024-10-29 12:55:10: [2024-10-29 12:55:10] iter = 04600, loss = 4.9645
2024-10-29 12:55:10: [2024-10-29 12:55:10] iter = 04610, loss = 2.8168
2024-10-29 12:55:11: [2024-10-29 12:55:11] iter = 04620, loss = 3.5970
2024-10-29 12:55:11: [2024-10-29 12:55:11] iter = 04630, loss = 20.6942
2024-10-29 12:55:12: [2024-10-29 12:55:12] iter = 04640, loss = 4.6982
2024-10-29 12:55:12: [2024-10-29 12:55:12] iter = 04650, loss = 2.9909
2024-10-29 12:55:13: [2024-10-29 12:55:13] iter = 04660, loss = 5.5002
2024-10-29 12:55:14: [2024-10-29 12:55:14] iter = 04670, loss = 8.3621
2024-10-29 12:55:14: [2024-10-29 12:55:14] iter = 04680, loss = 39.6173
2024-10-29 12:55:15: [2024-10-29 12:55:15] iter = 04690, loss = 3.6302
2024-10-29 12:55:15: [2024-10-29 12:55:15] iter = 04700, loss = 2.8252
2024-10-29 12:55:16: [2024-10-29 12:55:16] iter = 04710, loss = 3.3402
2024-10-29 12:55:17: [2024-10-29 12:55:17] iter = 04720, loss = 15.5456
2024-10-29 12:55:17: [2024-10-29 12:55:17] iter = 04730, loss = 10.8642
2024-10-29 12:55:18: [2024-10-29 12:55:18] iter = 04740, loss = 4.1789
2024-10-29 12:55:18: [2024-10-29 12:55:18] iter = 04750, loss = 4.7492
2024-10-29 12:55:19: [2024-10-29 12:55:19] iter = 04760, loss = 9.1712
2024-10-29 12:55:19: [2024-10-29 12:55:19] iter = 04770, loss = 12.4652
2024-10-29 12:55:20: [2024-10-29 12:55:20] iter = 04780, loss = 3.4741
2024-10-29 12:55:20: [2024-10-29 12:55:20] iter = 04790, loss = 8.3080
2024-10-29 12:55:21: [2024-10-29 12:55:21] iter = 04800, loss = 30.5024
2024-10-29 12:55:21: [2024-10-29 12:55:21] iter = 04810, loss = 3.8300
2024-10-29 12:55:22: [2024-10-29 12:55:22] iter = 04820, loss = 2.7172
2024-10-29 12:55:22: [2024-10-29 12:55:22] iter = 04830, loss = 4.3563
2024-10-29 12:55:23: [2024-10-29 12:55:23] iter = 04840, loss = 2.6181
2024-10-29 12:55:23: [2024-10-29 12:55:23] iter = 04850, loss = 42.2271
2024-10-29 12:55:24: [2024-10-29 12:55:24] iter = 04860, loss = 3.7939
2024-10-29 12:55:24: [2024-10-29 12:55:24] iter = 04870, loss = 10.7339
2024-10-29 12:55:25: [2024-10-29 12:55:25] iter = 04880, loss = 10.4927
2024-10-29 12:55:25: [2024-10-29 12:55:25] iter = 04890, loss = 2.6053
2024-10-29 12:55:26: [2024-10-29 12:55:26] iter = 04900, loss = 22.4854
2024-10-29 12:55:26: [2024-10-29 12:55:26] iter = 04910, loss = 10.7908
2024-10-29 12:55:27: [2024-10-29 12:55:27] iter = 04920, loss = 7.7794
2024-10-29 12:55:27: [2024-10-29 12:55:27] iter = 04930, loss = 5.0677
2024-10-29 12:55:28: [2024-10-29 12:55:28] iter = 04940, loss = 4.2579
2024-10-29 12:55:28: [2024-10-29 12:55:28] iter = 04950, loss = 4.9554
2024-10-29 12:55:29: [2024-10-29 12:55:29] iter = 04960, loss = 52.6693
2024-10-29 12:55:30: [2024-10-29 12:55:30] iter = 04970, loss = 56.4858
2024-10-29 12:55:30: [2024-10-29 12:55:30] iter = 04980, loss = 4.3920
2024-10-29 12:55:31: [2024-10-29 12:55:31] iter = 04990, loss = 8.7294
2024-10-29 12:55:31: [2024-10-29 12:55:31] iter = 05000, loss = 8.4109
2024-10-29 12:55:32: [2024-10-29 12:55:32] iter = 05010, loss = 18.1835
2024-10-29 12:55:32: [2024-10-29 12:55:32] iter = 05020, loss = 10.1838
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 05030, loss = 3.2647
2024-10-29 12:55:33: [2024-10-29 12:55:33] iter = 05040, loss = 10.1943
2024-10-29 12:55:34: [2024-10-29 12:55:34] iter = 05050, loss = 18.7892
2024-10-29 12:55:34: [2024-10-29 12:55:34] iter = 05060, loss = 6.0936
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 05070, loss = 13.3415
2024-10-29 12:55:35: [2024-10-29 12:55:35] iter = 05080, loss = 7.5635
2024-10-29 12:55:36: [2024-10-29 12:55:36] iter = 05090, loss = 2.9177
2024-10-29 12:55:36: [2024-10-29 12:55:36] iter = 05100, loss = 3.0777
2024-10-29 12:55:37: [2024-10-29 12:55:37] iter = 05110, loss = 2.3306
2024-10-29 12:55:37: [2024-10-29 12:55:37] iter = 05120, loss = 5.5276
2024-10-29 12:55:38: [2024-10-29 12:55:38] iter = 05130, loss = 13.5755
2024-10-29 12:55:38: [2024-10-29 12:55:38] iter = 05140, loss = 3.4576
2024-10-29 12:55:39: [2024-10-29 12:55:39] iter = 05150, loss = 4.8266
2024-10-29 12:55:39: [2024-10-29 12:55:39] iter = 05160, loss = 2.7579
2024-10-29 12:55:40: [2024-10-29 12:55:40] iter = 05170, loss = 8.7519
2024-10-29 12:55:40: [2024-10-29 12:55:40] iter = 05180, loss = 40.8914
2024-10-29 12:55:41: [2024-10-29 12:55:41] iter = 05190, loss = 23.2901
2024-10-29 12:55:41: [2024-10-29 12:55:41] iter = 05200, loss = 13.9828
2024-10-29 12:55:42: [2024-10-29 12:55:42] iter = 05210, loss = 3.4242
2024-10-29 12:55:43: [2024-10-29 12:55:43] iter = 05220, loss = 13.6628
2024-10-29 12:55:43: [2024-10-29 12:55:43] iter = 05230, loss = 8.6276
2024-10-29 12:55:44: [2024-10-29 12:55:44] iter = 05240, loss = 12.4233
2024-10-29 12:55:44: [2024-10-29 12:55:44] iter = 05250, loss = 17.0678
2024-10-29 12:55:45: [2024-10-29 12:55:45] iter = 05260, loss = 2.8366
2024-10-29 12:55:45: [2024-10-29 12:55:45] iter = 05270, loss = 5.9315
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 05280, loss = 3.8932
2024-10-29 12:55:46: [2024-10-29 12:55:46] iter = 05290, loss = 4.0244
2024-10-29 12:55:47: [2024-10-29 12:55:47] iter = 05300, loss = 11.4012
2024-10-29 12:55:47: [2024-10-29 12:55:47] iter = 05310, loss = 14.5945
2024-10-29 12:55:48: [2024-10-29 12:55:48] iter = 05320, loss = 3.1225
2024-10-29 12:55:48: [2024-10-29 12:55:48] iter = 05330, loss = 3.4775
2024-10-29 12:55:49: [2024-10-29 12:55:49] iter = 05340, loss = 8.7502
2024-10-29 12:55:50: [2024-10-29 12:55:50] iter = 05350, loss = 17.0986
2024-10-29 12:55:50: [2024-10-29 12:55:50] iter = 05360, loss = 4.0306
2024-10-29 12:55:50: [2024-10-29 12:55:50] iter = 05370, loss = 9.8848
2024-10-29 12:55:51: [2024-10-29 12:55:51] iter = 05380, loss = 10.2642
2024-10-29 12:55:51: [2024-10-29 12:55:51] iter = 05390, loss = 3.7150
2024-10-29 12:55:52: [2024-10-29 12:55:52] iter = 05400, loss = 5.3864
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 05410, loss = 3.0167
2024-10-29 12:55:53: [2024-10-29 12:55:53] iter = 05420, loss = 5.7019
2024-10-29 12:55:54: [2024-10-29 12:55:54] iter = 05430, loss = 8.3347
2024-10-29 12:55:54: [2024-10-29 12:55:54] iter = 05440, loss = 3.6612
2024-10-29 12:55:55: [2024-10-29 12:55:55] iter = 05450, loss = 4.2938
2024-10-29 12:55:56: [2024-10-29 12:55:56] iter = 05460, loss = 4.3030
2024-10-29 12:55:56: [2024-10-29 12:55:56] iter = 05470, loss = 15.0209
2024-10-29 12:55:57: [2024-10-29 12:55:57] iter = 05480, loss = 22.8036
2024-10-29 12:55:57: [2024-10-29 12:55:57] iter = 05490, loss = 2.9330
2024-10-29 12:55:58: [2024-10-29 12:55:58] iter = 05500, loss = 11.2232
2024-10-29 12:55:58: [2024-10-29 12:55:58] iter = 05510, loss = 9.8292
2024-10-29 12:55:59: [2024-10-29 12:55:59] iter = 05520, loss = 3.6339
2024-10-29 12:55:59: [2024-10-29 12:55:59] iter = 05530, loss = 5.2631
2024-10-29 12:56:00: [2024-10-29 12:56:00] iter = 05540, loss = 5.5281
2024-10-29 12:56:01: [2024-10-29 12:56:01] iter = 05550, loss = 4.4822
2024-10-29 12:56:01: [2024-10-29 12:56:01] iter = 05560, loss = 16.0997
2024-10-29 12:56:02: [2024-10-29 12:56:02] iter = 05570, loss = 5.8144
2024-10-29 12:56:02: [2024-10-29 12:56:02] iter = 05580, loss = 3.7022
2024-10-29 12:56:03: [2024-10-29 12:56:03] iter = 05590, loss = 4.9075
2024-10-29 12:56:03: [2024-10-29 12:56:03] iter = 05600, loss = 5.5075
2024-10-29 12:56:04: [2024-10-29 12:56:04] iter = 05610, loss = 8.1805
2024-10-29 12:56:05: [2024-10-29 12:56:05] iter = 05620, loss = 6.5222
2024-10-29 12:56:05: [2024-10-29 12:56:05] iter = 05630, loss = 25.7187
2024-10-29 12:56:06: [2024-10-29 12:56:06] iter = 05640, loss = 2.7587
2024-10-29 12:56:06: [2024-10-29 12:56:06] iter = 05650, loss = 4.3763
2024-10-29 12:56:07: [2024-10-29 12:56:07] iter = 05660, loss = 4.2582
2024-10-29 12:56:07: [2024-10-29 12:56:07] iter = 05670, loss = 3.5888
2024-10-29 12:56:08: [2024-10-29 12:56:08] iter = 05680, loss = 3.6163
2024-10-29 12:56:08: [2024-10-29 12:56:08] iter = 05690, loss = 10.3312
2024-10-29 12:56:09: [2024-10-29 12:56:09] iter = 05700, loss = 7.5639
2024-10-29 12:56:09: [2024-10-29 12:56:09] iter = 05710, loss = 3.5131
2024-10-29 12:56:10: [2024-10-29 12:56:10] iter = 05720, loss = 10.4618
2024-10-29 12:56:10: [2024-10-29 12:56:10] iter = 05730, loss = 3.3995
2024-10-29 12:56:11: [2024-10-29 12:56:11] iter = 05740, loss = 35.9490
2024-10-29 12:56:11: [2024-10-29 12:56:11] iter = 05750, loss = 14.7451
2024-10-29 12:56:12: [2024-10-29 12:56:12] iter = 05760, loss = 3.9853
2024-10-29 12:56:13: [2024-10-29 12:56:13] iter = 05770, loss = 42.4277
2024-10-29 12:56:13: [2024-10-29 12:56:13] iter = 05780, loss = 12.5425
2024-10-29 12:56:14: [2024-10-29 12:56:14] iter = 05790, loss = 3.4183
2024-10-29 12:56:15: [2024-10-29 12:56:15] iter = 05800, loss = 6.6556
2024-10-29 12:56:15: [2024-10-29 12:56:15] iter = 05810, loss = 6.9887
2024-10-29 12:56:16: [2024-10-29 12:56:16] iter = 05820, loss = 3.9095
2024-10-29 12:56:16: [2024-10-29 12:56:16] iter = 05830, loss = 7.5134
2024-10-29 12:56:17: [2024-10-29 12:56:17] iter = 05840, loss = 5.0552
2024-10-29 12:56:17: [2024-10-29 12:56:17] iter = 05850, loss = 19.2288
2024-10-29 12:56:18: [2024-10-29 12:56:18] iter = 05860, loss = 7.6191
2024-10-29 12:56:19: [2024-10-29 12:56:19] iter = 05870, loss = 8.4994
2024-10-29 12:56:19: [2024-10-29 12:56:19] iter = 05880, loss = 3.6644
2024-10-29 12:56:20: [2024-10-29 12:56:20] iter = 05890, loss = 7.6258
2024-10-29 12:56:20: [2024-10-29 12:56:20] iter = 05900, loss = 16.1663
2024-10-29 12:56:21: [2024-10-29 12:56:21] iter = 05910, loss = 4.7774
2024-10-29 12:56:21: [2024-10-29 12:56:21] iter = 05920, loss = 27.5853
2024-10-29 12:56:22: [2024-10-29 12:56:22] iter = 05930, loss = 7.3082
2024-10-29 12:56:22: [2024-10-29 12:56:22] iter = 05940, loss = 3.0417
2024-10-29 12:56:23: [2024-10-29 12:56:23] iter = 05950, loss = 6.5109
2024-10-29 12:56:23: [2024-10-29 12:56:23] iter = 05960, loss = 5.0464
2024-10-29 12:56:24: [2024-10-29 12:56:24] iter = 05970, loss = 4.2466
2024-10-29 12:56:24: [2024-10-29 12:56:24] iter = 05980, loss = 4.1334
2024-10-29 12:56:25: [2024-10-29 12:56:25] iter = 05990, loss = 2.5574
2024-10-29 12:56:25: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 12:56:25: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:56:25: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 85783}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:56:52: Evaluate 5 random ConvNet, ACCmean = 0.3886 ACCstd = 0.0148
-------------------------
2024-10-29 12:56:52: Evaluate 5 random ConvNet, SENmean = 0.3886 SENstd = 0.0148
-------------------------
2024-10-29 12:56:52: Evaluate 5 random ConvNet, SPEmean = 0.7962 SPEstd = 0.0049
-------------------------
2024-10-29 12:56:52: Evaluate 5 random ConvNet, F!mean = 0.3136 F!std = 0.0159
-------------------------
2024-10-29 12:56:52: Evaluate 5 random ConvNet, mean = 0.3886 std = 0.0148
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:56:52: [2024-10-29 12:56:52] iter = 06000, loss = 5.9313
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:56:53: [2024-10-29 12:56:53] iter = 06010, loss = 3.6469
2024-10-29 12:56:53: [2024-10-29 12:56:53] iter = 06020, loss = 27.0968
2024-10-29 12:56:54: [2024-10-29 12:56:54] iter = 06030, loss = 7.2485
2024-10-29 12:56:54: [2024-10-29 12:56:54] iter = 06040, loss = 6.8467
2024-10-29 12:56:55: [2024-10-29 12:56:55] iter = 06050, loss = 5.9210
2024-10-29 12:56:55: [2024-10-29 12:56:55] iter = 06060, loss = 6.6469
2024-10-29 12:56:56: [2024-10-29 12:56:56] iter = 06070, loss = 6.5355
2024-10-29 12:56:56: [2024-10-29 12:56:56] iter = 06080, loss = 8.7313
2024-10-29 12:56:57: [2024-10-29 12:56:57] iter = 06090, loss = 28.1919
2024-10-29 12:56:57: [2024-10-29 12:56:57] iter = 06100, loss = 3.6152
2024-10-29 12:56:58: [2024-10-29 12:56:58] iter = 06110, loss = 5.8579
2024-10-29 12:56:58: [2024-10-29 12:56:58] iter = 06120, loss = 4.3343
2024-10-29 12:56:59: [2024-10-29 12:56:59] iter = 06130, loss = 3.6920
2024-10-29 12:56:59: [2024-10-29 12:56:59] iter = 06140, loss = 2.9726
2024-10-29 12:57:00: [2024-10-29 12:57:00] iter = 06150, loss = 5.4643
2024-10-29 12:57:00: [2024-10-29 12:57:00] iter = 06160, loss = 26.3331
2024-10-29 12:57:01: [2024-10-29 12:57:01] iter = 06170, loss = 3.2847
2024-10-29 12:57:01: [2024-10-29 12:57:01] iter = 06180, loss = 9.7895
2024-10-29 12:57:02: [2024-10-29 12:57:02] iter = 06190, loss = 5.1779
2024-10-29 12:57:02: [2024-10-29 12:57:02] iter = 06200, loss = 8.5745
2024-10-29 12:57:03: [2024-10-29 12:57:03] iter = 06210, loss = 9.2445
2024-10-29 12:57:03: [2024-10-29 12:57:03] iter = 06220, loss = 19.1462
2024-10-29 12:57:04: [2024-10-29 12:57:04] iter = 06230, loss = 10.5625
2024-10-29 12:57:04: [2024-10-29 12:57:04] iter = 06240, loss = 3.6523
2024-10-29 12:57:05: [2024-10-29 12:57:05] iter = 06250, loss = 6.8948
2024-10-29 12:57:05: [2024-10-29 12:57:05] iter = 06260, loss = 3.8674
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 06270, loss = 8.2439
2024-10-29 12:57:06: [2024-10-29 12:57:06] iter = 06280, loss = 11.2190
2024-10-29 12:57:07: [2024-10-29 12:57:07] iter = 06290, loss = 7.6833
2024-10-29 12:57:07: [2024-10-29 12:57:07] iter = 06300, loss = 3.6238
2024-10-29 12:57:08: [2024-10-29 12:57:08] iter = 06310, loss = 7.7862
2024-10-29 12:57:09: [2024-10-29 12:57:09] iter = 06320, loss = 5.3887
2024-10-29 12:57:09: [2024-10-29 12:57:09] iter = 06330, loss = 7.9586
2024-10-29 12:57:10: [2024-10-29 12:57:10] iter = 06340, loss = 4.4477
2024-10-29 12:57:10: [2024-10-29 12:57:10] iter = 06350, loss = 2.6088
2024-10-29 12:57:11: [2024-10-29 12:57:11] iter = 06360, loss = 25.3164
2024-10-29 12:57:11: [2024-10-29 12:57:11] iter = 06370, loss = 6.7422
2024-10-29 12:57:12: [2024-10-29 12:57:12] iter = 06380, loss = 3.5081
2024-10-29 12:57:12: [2024-10-29 12:57:12] iter = 06390, loss = 6.4486
2024-10-29 12:57:13: [2024-10-29 12:57:13] iter = 06400, loss = 19.7949
2024-10-29 12:57:14: [2024-10-29 12:57:14] iter = 06410, loss = 40.2206
2024-10-29 12:57:14: [2024-10-29 12:57:14] iter = 06420, loss = 4.2338
2024-10-29 12:57:15: [2024-10-29 12:57:15] iter = 06430, loss = 3.5114
2024-10-29 12:57:16: [2024-10-29 12:57:16] iter = 06440, loss = 3.1446
2024-10-29 12:57:16: [2024-10-29 12:57:16] iter = 06450, loss = 6.7568
2024-10-29 12:57:17: [2024-10-29 12:57:17] iter = 06460, loss = 16.4288
2024-10-29 12:57:17: [2024-10-29 12:57:17] iter = 06470, loss = 4.3502
2024-10-29 12:57:18: [2024-10-29 12:57:18] iter = 06480, loss = 3.9448
2024-10-29 12:57:18: [2024-10-29 12:57:18] iter = 06490, loss = 4.9034
2024-10-29 12:57:19: [2024-10-29 12:57:19] iter = 06500, loss = 7.2921
2024-10-29 12:57:19: [2024-10-29 12:57:19] iter = 06510, loss = 5.3403
2024-10-29 12:57:20: [2024-10-29 12:57:20] iter = 06520, loss = 9.4425
2024-10-29 12:57:21: [2024-10-29 12:57:21] iter = 06530, loss = 28.8512
2024-10-29 12:57:21: [2024-10-29 12:57:21] iter = 06540, loss = 5.8652
2024-10-29 12:57:22: [2024-10-29 12:57:22] iter = 06550, loss = 14.6485
2024-10-29 12:57:22: [2024-10-29 12:57:22] iter = 06560, loss = 29.8264
2024-10-29 12:57:23: [2024-10-29 12:57:23] iter = 06570, loss = 5.3192
2024-10-29 12:57:23: [2024-10-29 12:57:23] iter = 06580, loss = 8.9577
2024-10-29 12:57:24: [2024-10-29 12:57:24] iter = 06590, loss = 4.7284
2024-10-29 12:57:24: [2024-10-29 12:57:24] iter = 06600, loss = 3.9995
2024-10-29 12:57:25: [2024-10-29 12:57:25] iter = 06610, loss = 5.9989
2024-10-29 12:57:25: [2024-10-29 12:57:25] iter = 06620, loss = 47.7466
2024-10-29 12:57:26: [2024-10-29 12:57:26] iter = 06630, loss = 3.1471
2024-10-29 12:57:26: [2024-10-29 12:57:26] iter = 06640, loss = 6.8818
2024-10-29 12:57:27: [2024-10-29 12:57:27] iter = 06650, loss = 26.7640
2024-10-29 12:57:27: [2024-10-29 12:57:27] iter = 06660, loss = 26.2641
2024-10-29 12:57:28: [2024-10-29 12:57:28] iter = 06670, loss = 3.2702
2024-10-29 12:57:29: [2024-10-29 12:57:29] iter = 06680, loss = 14.0743
2024-10-29 12:57:29: [2024-10-29 12:57:29] iter = 06690, loss = 11.7774
2024-10-29 12:57:30: [2024-10-29 12:57:30] iter = 06700, loss = 11.3117
2024-10-29 12:57:31: [2024-10-29 12:57:31] iter = 06710, loss = 19.2200
2024-10-29 12:57:31: [2024-10-29 12:57:31] iter = 06720, loss = 3.9699
2024-10-29 12:57:32: [2024-10-29 12:57:32] iter = 06730, loss = 19.8151
2024-10-29 12:57:32: [2024-10-29 12:57:32] iter = 06740, loss = 4.0113
2024-10-29 12:57:33: [2024-10-29 12:57:33] iter = 06750, loss = 2.3825
2024-10-29 12:57:33: [2024-10-29 12:57:33] iter = 06760, loss = 6.5830
2024-10-29 12:57:34: [2024-10-29 12:57:34] iter = 06770, loss = 3.8722
2024-10-29 12:57:34: [2024-10-29 12:57:34] iter = 06780, loss = 11.8996
2024-10-29 12:57:35: [2024-10-29 12:57:35] iter = 06790, loss = 10.8832
2024-10-29 12:57:35: [2024-10-29 12:57:35] iter = 06800, loss = 4.6352
2024-10-29 12:57:36: [2024-10-29 12:57:36] iter = 06810, loss = 3.2150
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 06820, loss = 8.4381
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 06830, loss = 6.1963
2024-10-29 12:57:37: [2024-10-29 12:57:37] iter = 06840, loss = 7.4921
2024-10-29 12:57:38: [2024-10-29 12:57:38] iter = 06850, loss = 14.4301
2024-10-29 12:57:39: [2024-10-29 12:57:39] iter = 06860, loss = 37.6967
2024-10-29 12:57:39: [2024-10-29 12:57:39] iter = 06870, loss = 4.3688
2024-10-29 12:57:40: [2024-10-29 12:57:40] iter = 06880, loss = 2.8670
2024-10-29 12:57:40: [2024-10-29 12:57:40] iter = 06890, loss = 4.5557
2024-10-29 12:57:41: [2024-10-29 12:57:41] iter = 06900, loss = 7.7137
2024-10-29 12:57:42: [2024-10-29 12:57:41] iter = 06910, loss = 45.0612
2024-10-29 12:57:42: [2024-10-29 12:57:42] iter = 06920, loss = 5.9860
2024-10-29 12:57:43: [2024-10-29 12:57:43] iter = 06930, loss = 3.8033
2024-10-29 12:57:43: [2024-10-29 12:57:43] iter = 06940, loss = 21.0283
2024-10-29 12:57:44: [2024-10-29 12:57:44] iter = 06950, loss = 10.6966
2024-10-29 12:57:44: [2024-10-29 12:57:44] iter = 06960, loss = 3.5096
2024-10-29 12:57:45: [2024-10-29 12:57:45] iter = 06970, loss = 15.7633
2024-10-29 12:57:45: [2024-10-29 12:57:45] iter = 06980, loss = 2.6975
2024-10-29 12:57:46: [2024-10-29 12:57:46] iter = 06990, loss = 22.0840
2024-10-29 12:57:46: [2024-10-29 12:57:46] iter = 07000, loss = 6.1830
2024-10-29 12:57:47: [2024-10-29 12:57:47] iter = 07010, loss = 9.4142
2024-10-29 12:57:47: [2024-10-29 12:57:47] iter = 07020, loss = 4.2938
2024-10-29 12:57:48: [2024-10-29 12:57:48] iter = 07030, loss = 4.8592
2024-10-29 12:57:48: [2024-10-29 12:57:48] iter = 07040, loss = 6.5135
2024-10-29 12:57:49: [2024-10-29 12:57:49] iter = 07050, loss = 3.8132
2024-10-29 12:57:49: [2024-10-29 12:57:49] iter = 07060, loss = 15.5053
2024-10-29 12:57:50: [2024-10-29 12:57:50] iter = 07070, loss = 11.7571
2024-10-29 12:57:50: [2024-10-29 12:57:50] iter = 07080, loss = 3.0700
2024-10-29 12:57:51: [2024-10-29 12:57:51] iter = 07090, loss = 7.8562
2024-10-29 12:57:51: [2024-10-29 12:57:51] iter = 07100, loss = 3.6894
2024-10-29 12:57:52: [2024-10-29 12:57:52] iter = 07110, loss = 36.1936
2024-10-29 12:57:52: [2024-10-29 12:57:52] iter = 07120, loss = 23.1852
2024-10-29 12:57:53: [2024-10-29 12:57:53] iter = 07130, loss = 11.4948
2024-10-29 12:57:53: [2024-10-29 12:57:53] iter = 07140, loss = 8.5203
2024-10-29 12:57:54: [2024-10-29 12:57:54] iter = 07150, loss = 6.8190
2024-10-29 12:57:55: [2024-10-29 12:57:55] iter = 07160, loss = 3.2589
2024-10-29 12:57:55: [2024-10-29 12:57:55] iter = 07170, loss = 4.6501
2024-10-29 12:57:56: [2024-10-29 12:57:56] iter = 07180, loss = 7.5521
2024-10-29 12:57:56: [2024-10-29 12:57:56] iter = 07190, loss = 8.3698
2024-10-29 12:57:57: [2024-10-29 12:57:57] iter = 07200, loss = 9.2373
2024-10-29 12:57:57: [2024-10-29 12:57:57] iter = 07210, loss = 5.0827
2024-10-29 12:57:58: [2024-10-29 12:57:58] iter = 07220, loss = 3.2653
2024-10-29 12:57:58: [2024-10-29 12:57:58] iter = 07230, loss = 4.0435
2024-10-29 12:57:59: [2024-10-29 12:57:59] iter = 07240, loss = 4.2469
2024-10-29 12:57:59: [2024-10-29 12:57:59] iter = 07250, loss = 3.8594
2024-10-29 12:58:00: [2024-10-29 12:58:00] iter = 07260, loss = 4.7118
2024-10-29 12:58:01: [2024-10-29 12:58:01] iter = 07270, loss = 4.9549
2024-10-29 12:58:01: [2024-10-29 12:58:01] iter = 07280, loss = 5.4074
2024-10-29 12:58:02: [2024-10-29 12:58:02] iter = 07290, loss = 37.6995
2024-10-29 12:58:02: [2024-10-29 12:58:02] iter = 07300, loss = 25.1715
2024-10-29 12:58:03: [2024-10-29 12:58:03] iter = 07310, loss = 3.0095
2024-10-29 12:58:04: [2024-10-29 12:58:04] iter = 07320, loss = 3.1915
2024-10-29 12:58:04: [2024-10-29 12:58:04] iter = 07330, loss = 5.0190
2024-10-29 12:58:05: [2024-10-29 12:58:05] iter = 07340, loss = 12.4893
2024-10-29 12:58:06: [2024-10-29 12:58:06] iter = 07350, loss = 10.1517
2024-10-29 12:58:06: [2024-10-29 12:58:06] iter = 07360, loss = 3.4084
2024-10-29 12:58:07: [2024-10-29 12:58:07] iter = 07370, loss = 3.3936
2024-10-29 12:58:07: [2024-10-29 12:58:07] iter = 07380, loss = 2.6963
2024-10-29 12:58:08: [2024-10-29 12:58:08] iter = 07390, loss = 13.8709
2024-10-29 12:58:08: [2024-10-29 12:58:08] iter = 07400, loss = 5.0177
2024-10-29 12:58:09: [2024-10-29 12:58:09] iter = 07410, loss = 3.1607
2024-10-29 12:58:10: [2024-10-29 12:58:10] iter = 07420, loss = 6.0103
2024-10-29 12:58:10: [2024-10-29 12:58:10] iter = 07430, loss = 24.5843
2024-10-29 12:58:11: [2024-10-29 12:58:11] iter = 07440, loss = 21.9399
2024-10-29 12:58:11: [2024-10-29 12:58:11] iter = 07450, loss = 19.9192
2024-10-29 12:58:12: [2024-10-29 12:58:12] iter = 07460, loss = 5.6316
2024-10-29 12:58:12: [2024-10-29 12:58:12] iter = 07470, loss = 7.7369
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 07480, loss = 7.9097
2024-10-29 12:58:13: [2024-10-29 12:58:13] iter = 07490, loss = 7.7011
2024-10-29 12:58:14: [2024-10-29 12:58:14] iter = 07500, loss = 9.5165
2024-10-29 12:58:14: [2024-10-29 12:58:14] iter = 07510, loss = 2.8466
2024-10-29 12:58:15: [2024-10-29 12:58:15] iter = 07520, loss = 3.6624
2024-10-29 12:58:15: [2024-10-29 12:58:15] iter = 07530, loss = 3.4197
2024-10-29 12:58:16: [2024-10-29 12:58:16] iter = 07540, loss = 59.0712
2024-10-29 12:58:17: [2024-10-29 12:58:17] iter = 07550, loss = 9.0911
2024-10-29 12:58:17: [2024-10-29 12:58:17] iter = 07560, loss = 13.7412
2024-10-29 12:58:18: [2024-10-29 12:58:18] iter = 07570, loss = 4.5122
2024-10-29 12:58:18: [2024-10-29 12:58:18] iter = 07580, loss = 12.5033
2024-10-29 12:58:19: [2024-10-29 12:58:18] iter = 07590, loss = 7.1024
2024-10-29 12:58:19: [2024-10-29 12:58:19] iter = 07600, loss = 13.7203
2024-10-29 12:58:19: [2024-10-29 12:58:19] iter = 07610, loss = 5.7020
2024-10-29 12:58:20: [2024-10-29 12:58:20] iter = 07620, loss = 3.2419
2024-10-29 12:58:21: [2024-10-29 12:58:21] iter = 07630, loss = 6.2590
2024-10-29 12:58:21: [2024-10-29 12:58:21] iter = 07640, loss = 3.8815
2024-10-29 12:58:21: [2024-10-29 12:58:21] iter = 07650, loss = 5.4590
2024-10-29 12:58:22: [2024-10-29 12:58:22] iter = 07660, loss = 9.1225
2024-10-29 12:58:23: [2024-10-29 12:58:23] iter = 07670, loss = 2.9146
2024-10-29 12:58:23: [2024-10-29 12:58:23] iter = 07680, loss = 5.0796
2024-10-29 12:58:24: [2024-10-29 12:58:24] iter = 07690, loss = 8.9655
2024-10-29 12:58:24: [2024-10-29 12:58:24] iter = 07700, loss = 2.6358
2024-10-29 12:58:24: [2024-10-29 12:58:24] iter = 07710, loss = 14.8271
2024-10-29 12:58:25: [2024-10-29 12:58:25] iter = 07720, loss = 3.7548
2024-10-29 12:58:26: [2024-10-29 12:58:26] iter = 07730, loss = 2.6919
2024-10-29 12:58:26: [2024-10-29 12:58:26] iter = 07740, loss = 9.9242
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 07750, loss = 57.4366
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 07760, loss = 4.0467
2024-10-29 12:58:27: [2024-10-29 12:58:27] iter = 07770, loss = 3.7597
2024-10-29 12:58:28: [2024-10-29 12:58:28] iter = 07780, loss = 25.1083
2024-10-29 12:58:28: [2024-10-29 12:58:28] iter = 07790, loss = 21.4516
2024-10-29 12:58:29: [2024-10-29 12:58:29] iter = 07800, loss = 3.3025
2024-10-29 12:58:29: [2024-10-29 12:58:29] iter = 07810, loss = 3.4348
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 07820, loss = 4.3561
2024-10-29 12:58:30: [2024-10-29 12:58:30] iter = 07830, loss = 34.0759
2024-10-29 12:58:31: [2024-10-29 12:58:31] iter = 07840, loss = 4.1872
2024-10-29 12:58:31: [2024-10-29 12:58:31] iter = 07850, loss = 6.8787
2024-10-29 12:58:32: [2024-10-29 12:58:32] iter = 07860, loss = 12.7083
2024-10-29 12:58:32: [2024-10-29 12:58:32] iter = 07870, loss = 5.1253
2024-10-29 12:58:33: [2024-10-29 12:58:33] iter = 07880, loss = 4.2663
2024-10-29 12:58:33: [2024-10-29 12:58:33] iter = 07890, loss = 28.2451
2024-10-29 12:58:34: [2024-10-29 12:58:34] iter = 07900, loss = 37.4864
2024-10-29 12:58:35: [2024-10-29 12:58:35] iter = 07910, loss = 5.4982
2024-10-29 12:58:35: [2024-10-29 12:58:35] iter = 07920, loss = 9.2214
2024-10-29 12:58:36: [2024-10-29 12:58:36] iter = 07930, loss = 12.8490
2024-10-29 12:58:36: [2024-10-29 12:58:36] iter = 07940, loss = 4.9802
2024-10-29 12:58:37: [2024-10-29 12:58:37] iter = 07950, loss = 12.5799
2024-10-29 12:58:37: [2024-10-29 12:58:37] iter = 07960, loss = 4.4341
2024-10-29 12:58:38: [2024-10-29 12:58:38] iter = 07970, loss = 2.6035
2024-10-29 12:58:38: [2024-10-29 12:58:38] iter = 07980, loss = 9.7948
2024-10-29 12:58:39: [2024-10-29 12:58:39] iter = 07990, loss = 6.4060
2024-10-29 12:58:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 12:58:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 12:58:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 19487}

[2024-10-29 12:38:24] Evaluate_04: epoch = 1000 train time = 6 s train loss = 0.007242 train acc = 1.0000, test acc = 0.4870, test_sen =0.4870, test_spe =0.8290, test_f1 =0.3894
[2024-10-29 12:40:19] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001991 train acc = 1.0000, test acc = 0.4840, test_sen =0.4840, test_spe =0.8280, test_f1 =0.4140
[2024-10-29 12:40:25] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.017627 train acc = 1.0000, test acc = 0.4830, test_sen =0.4830, test_spe =0.8277, test_f1 =0.4110
[2024-10-29 12:40:30] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.024487 train acc = 1.0000, test acc = 0.5130, test_sen =0.5130, test_spe =0.8377, test_f1 =0.4551
[2024-10-29 12:40:36] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.063894 train acc = 0.9750, test acc = 0.5130, test_sen =0.5130, test_spe =0.8377, test_f1 =0.4556
[2024-10-29 12:40:41] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.003289 train acc = 1.0000, test acc = 0.5010, test_sen =0.5010, test_spe =0.8337, test_f1 =0.4488
[2024-10-29 12:42:35] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.030796 train acc = 1.0000, test acc = 0.4490, test_sen =0.4490, test_spe =0.8163, test_f1 =0.3893
[2024-10-29 12:42:42] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.007357 train acc = 1.0000, test acc = 0.4570, test_sen =0.4570, test_spe =0.8190, test_f1 =0.4099
[2024-10-29 12:42:48] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.015327 train acc = 1.0000, test acc = 0.4830, test_sen =0.4830, test_spe =0.8277, test_f1 =0.4352
[2024-10-29 12:42:54] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.000695 train acc = 1.0000, test acc = 0.4580, test_sen =0.4580, test_spe =0.8193, test_f1 =0.3984
[2024-10-29 12:42:59] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.002068 train acc = 1.0000, test acc = 0.4460, test_sen =0.4460, test_spe =0.8153, test_f1 =0.3899
[2024-10-29 12:44:47] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.004372 train acc = 1.0000, test acc = 0.4150, test_sen =0.4150, test_spe =0.8050, test_f1 =0.3689
[2024-10-29 12:44:52] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002140 train acc = 1.0000, test acc = 0.4170, test_sen =0.4170, test_spe =0.8057, test_f1 =0.3772
[2024-10-29 12:44:59] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.001881 train acc = 1.0000, test acc = 0.4350, test_sen =0.4350, test_spe =0.8117, test_f1 =0.4001
[2024-10-29 12:45:04] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.037748 train acc = 1.0000, test acc = 0.3880, test_sen =0.3880, test_spe =0.7960, test_f1 =0.3349
[2024-10-29 12:45:10] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.017319 train acc = 1.0000, test acc = 0.3700, test_sen =0.3700, test_spe =0.7900, test_f1 =0.3104
[2024-10-29 12:46:59] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.019405 train acc = 1.0000, test acc = 0.4440, test_sen =0.4440, test_spe =0.8147, test_f1 =0.4186
[2024-10-29 12:47:04] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.027643 train acc = 1.0000, test acc = 0.4550, test_sen =0.4550, test_spe =0.8183, test_f1 =0.4222
[2024-10-29 12:47:10] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.001204 train acc = 1.0000, test acc = 0.4550, test_sen =0.4550, test_spe =0.8183, test_f1 =0.4278
[2024-10-29 12:47:15] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.016526 train acc = 1.0000, test acc = 0.4330, test_sen =0.4330, test_spe =0.8110, test_f1 =0.4041
[2024-10-29 12:47:20] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.003119 train acc = 1.0000, test acc = 0.4520, test_sen =0.4520, test_spe =0.8173, test_f1 =0.4225
[2024-10-29 12:49:17] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002267 train acc = 1.0000, test acc = 0.5340, test_sen =0.5340, test_spe =0.8447, test_f1 =0.5188
[2024-10-29 12:49:22] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.035404 train acc = 1.0000, test acc = 0.5010, test_sen =0.5010, test_spe =0.8337, test_f1 =0.4804
[2024-10-29 12:49:27] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.001353 train acc = 1.0000, test acc = 0.5350, test_sen =0.5350, test_spe =0.8450, test_f1 =0.5184
[2024-10-29 12:49:34] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.000700 train acc = 1.0000, test acc = 0.5580, test_sen =0.5580, test_spe =0.8527, test_f1 =0.5437
[2024-10-29 12:49:40] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.012627 train acc = 1.0000, test acc = 0.5250, test_sen =0.5250, test_spe =0.8417, test_f1 =0.5116
[2024-10-29 12:49:48] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.004896 train acc = 1.0000, test acc = 0.4480, test_sen =0.4480, test_spe =0.8160, test_f1 =0.4403
[2024-10-29 12:49:53] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.009941 train acc = 1.0000, test acc = 0.4380, test_sen =0.4380, test_spe =0.8127, test_f1 =0.4275
[2024-10-29 12:50:00] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.039509 train acc = 1.0000, test acc = 0.4250, test_sen =0.4250, test_spe =0.8083, test_f1 =0.4169
[2024-10-29 12:50:05] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.014456 train acc = 1.0000, test acc = 0.4590, test_sen =0.4590, test_spe =0.8197, test_f1 =0.4517
[2024-10-29 12:50:11] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.005422 train acc = 1.0000, test acc = 0.4650, test_sen =0.4650, test_spe =0.8217, test_f1 =0.4561
[2024-10-29 12:51:59] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001567 train acc = 1.0000, test acc = 0.5270, test_sen =0.5270, test_spe =0.8423, test_f1 =0.4869
[2024-10-29 12:52:05] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001732 train acc = 1.0000, test acc = 0.5440, test_sen =0.5440, test_spe =0.8480, test_f1 =0.5078
[2024-10-29 12:52:09] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.012235 train acc = 1.0000, test acc = 0.5470, test_sen =0.5470, test_spe =0.8490, test_f1 =0.5043
[2024-10-29 12:52:15] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.019775 train acc = 1.0000, test acc = 0.5370, test_sen =0.5370, test_spe =0.8457, test_f1 =0.4999
[2024-10-29 12:52:20] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.003676 train acc = 1.0000, test acc = 0.5490, test_sen =0.5490, test_spe =0.8497, test_f1 =0.5101
[2024-10-29 12:54:17] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001249 train acc = 1.0000, test acc = 0.4640, test_sen =0.4640, test_spe =0.8213, test_f1 =0.3800
[2024-10-29 12:54:23] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.017162 train acc = 1.0000, test acc = 0.4690, test_sen =0.4690, test_spe =0.8230, test_f1 =0.3790
[2024-10-29 12:54:28] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.017941 train acc = 1.0000, test acc = 0.4610, test_sen =0.4610, test_spe =0.8203, test_f1 =0.3682
[2024-10-29 12:54:33] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.011193 train acc = 1.0000, test acc = 0.4760, test_sen =0.4760, test_spe =0.8253, test_f1 =0.3872
[2024-10-29 12:54:38] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001687 train acc = 1.0000, test acc = 0.4460, test_sen =0.4460, test_spe =0.8153, test_f1 =0.3521
[2024-10-29 12:56:31] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.023044 train acc = 1.0000, test acc = 0.3700, test_sen =0.3700, test_spe =0.7900, test_f1 =0.2852
[2024-10-29 12:56:36] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.004047 train acc = 1.0000, test acc = 0.4050, test_sen =0.4050, test_spe =0.8017, test_f1 =0.3259
[2024-10-29 12:56:41] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.002035 train acc = 1.0000, test acc = 0.4020, test_sen =0.4020, test_spe =0.8007, test_f1 =0.3227
[2024-10-29 12:56:47] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.002099 train acc = 1.0000, test acc = 0.3940, test_sen =0.3940, test_spe =0.7980, test_f1 =0.3273
[2024-10-29 12:56:52] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.005675 train acc = 1.0000, test acc = 0.3720, test_sen =0.3720, test_spe =0.7907, test_f1 =0.3069
[2024-10-29 12:58:44] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.023351 train acc = 1.0000, test acc = 0.4420, test_sen =0.4420, test_spe =0.8140, test_f1 =0.3928/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:59:05: Evaluate 5 random ConvNet, ACCmean = 0.4354 ACCstd = 0.0119
-------------------------
2024-10-29 12:59:05: Evaluate 5 random ConvNet, SENmean = 0.4354 SENstd = 0.0119
-------------------------
2024-10-29 12:59:05: Evaluate 5 random ConvNet, SPEmean = 0.8118 SPEstd = 0.0040
-------------------------
2024-10-29 12:59:05: Evaluate 5 random ConvNet, F!mean = 0.3867 F!std = 0.0110
-------------------------
2024-10-29 12:59:05: Evaluate 5 random ConvNet, mean = 0.4354 std = 0.0119
-------------------------
2024-10-29 12:59:05: [2024-10-29 12:59:05] iter = 08000, loss = 51.7385
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 12:59:06: [2024-10-29 12:59:06] iter = 08010, loss = 4.9412
2024-10-29 12:59:06: [2024-10-29 12:59:06] iter = 08020, loss = 2.6585
2024-10-29 12:59:07: [2024-10-29 12:59:07] iter = 08030, loss = 14.4730
2024-10-29 12:59:08: [2024-10-29 12:59:08] iter = 08040, loss = 11.2558
2024-10-29 12:59:08: [2024-10-29 12:59:08] iter = 08050, loss = 5.3209
2024-10-29 12:59:09: [2024-10-29 12:59:09] iter = 08060, loss = 21.7427
2024-10-29 12:59:09: [2024-10-29 12:59:09] iter = 08070, loss = 2.5497
2024-10-29 12:59:10: [2024-10-29 12:59:10] iter = 08080, loss = 6.3360
2024-10-29 12:59:10: [2024-10-29 12:59:10] iter = 08090, loss = 2.8564
2024-10-29 12:59:11: [2024-10-29 12:59:11] iter = 08100, loss = 5.9259
2024-10-29 12:59:11: [2024-10-29 12:59:11] iter = 08110, loss = 2.5549
2024-10-29 12:59:12: [2024-10-29 12:59:12] iter = 08120, loss = 6.6373
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 08130, loss = 72.1666
2024-10-29 12:59:13: [2024-10-29 12:59:13] iter = 08140, loss = 7.9308
2024-10-29 12:59:14: [2024-10-29 12:59:14] iter = 08150, loss = 27.6480
2024-10-29 12:59:14: [2024-10-29 12:59:14] iter = 08160, loss = 5.8828
2024-10-29 12:59:15: [2024-10-29 12:59:15] iter = 08170, loss = 3.4451
2024-10-29 12:59:16: [2024-10-29 12:59:16] iter = 08180, loss = 8.1339
2024-10-29 12:59:16: [2024-10-29 12:59:16] iter = 08190, loss = 3.5454
2024-10-29 12:59:17: [2024-10-29 12:59:17] iter = 08200, loss = 2.3986
2024-10-29 12:59:17: [2024-10-29 12:59:17] iter = 08210, loss = 38.0576
2024-10-29 12:59:18: [2024-10-29 12:59:18] iter = 08220, loss = 42.2223
2024-10-29 12:59:19: [2024-10-29 12:59:19] iter = 08230, loss = 14.4645
2024-10-29 12:59:19: [2024-10-29 12:59:19] iter = 08240, loss = 17.1174
2024-10-29 12:59:20: [2024-10-29 12:59:20] iter = 08250, loss = 6.6059
2024-10-29 12:59:20: [2024-10-29 12:59:20] iter = 08260, loss = 3.5984
2024-10-29 12:59:21: [2024-10-29 12:59:21] iter = 08270, loss = 3.8885
2024-10-29 12:59:21: [2024-10-29 12:59:21] iter = 08280, loss = 7.2236
2024-10-29 12:59:22: [2024-10-29 12:59:22] iter = 08290, loss = 4.3226
2024-10-29 12:59:23: [2024-10-29 12:59:23] iter = 08300, loss = 3.2026
2024-10-29 12:59:23: [2024-10-29 12:59:23] iter = 08310, loss = 4.5427
2024-10-29 12:59:24: [2024-10-29 12:59:24] iter = 08320, loss = 4.0945
2024-10-29 12:59:24: [2024-10-29 12:59:24] iter = 08330, loss = 13.8315
2024-10-29 12:59:25: [2024-10-29 12:59:25] iter = 08340, loss = 22.5564
2024-10-29 12:59:25: [2024-10-29 12:59:25] iter = 08350, loss = 4.9228
2024-10-29 12:59:26: [2024-10-29 12:59:26] iter = 08360, loss = 10.7151
2024-10-29 12:59:26: [2024-10-29 12:59:26] iter = 08370, loss = 7.8449
2024-10-29 12:59:27: [2024-10-29 12:59:27] iter = 08380, loss = 7.0972
2024-10-29 12:59:27: [2024-10-29 12:59:27] iter = 08390, loss = 25.9345
2024-10-29 12:59:28: [2024-10-29 12:59:28] iter = 08400, loss = 3.6265
2024-10-29 12:59:29: [2024-10-29 12:59:29] iter = 08410, loss = 5.4897
2024-10-29 12:59:29: [2024-10-29 12:59:29] iter = 08420, loss = 5.5371
2024-10-29 12:59:30: [2024-10-29 12:59:30] iter = 08430, loss = 5.4329
2024-10-29 12:59:30: [2024-10-29 12:59:30] iter = 08440, loss = 4.6297
2024-10-29 12:59:31: [2024-10-29 12:59:31] iter = 08450, loss = 3.6185
2024-10-29 12:59:31: [2024-10-29 12:59:31] iter = 08460, loss = 5.0288
2024-10-29 12:59:32: [2024-10-29 12:59:32] iter = 08470, loss = 24.8438
2024-10-29 12:59:32: [2024-10-29 12:59:32] iter = 08480, loss = 19.2959
2024-10-29 12:59:33: [2024-10-29 12:59:33] iter = 08490, loss = 4.2314
2024-10-29 12:59:33: [2024-10-29 12:59:33] iter = 08500, loss = 34.1325
2024-10-29 12:59:34: [2024-10-29 12:59:34] iter = 08510, loss = 9.9537
2024-10-29 12:59:34: [2024-10-29 12:59:34] iter = 08520, loss = 20.8815
2024-10-29 12:59:35: [2024-10-29 12:59:35] iter = 08530, loss = 4.6703
2024-10-29 12:59:35: [2024-10-29 12:59:35] iter = 08540, loss = 3.0680
2024-10-29 12:59:36: [2024-10-29 12:59:36] iter = 08550, loss = 4.3244
2024-10-29 12:59:36: [2024-10-29 12:59:36] iter = 08560, loss = 18.3550
2024-10-29 12:59:37: [2024-10-29 12:59:37] iter = 08570, loss = 5.6503
2024-10-29 12:59:37: [2024-10-29 12:59:37] iter = 08580, loss = 7.1092
2024-10-29 12:59:38: [2024-10-29 12:59:38] iter = 08590, loss = 10.9705
2024-10-29 12:59:38: [2024-10-29 12:59:38] iter = 08600, loss = 3.8545
2024-10-29 12:59:39: [2024-10-29 12:59:39] iter = 08610, loss = 6.2738
2024-10-29 12:59:40: [2024-10-29 12:59:40] iter = 08620, loss = 3.9009
2024-10-29 12:59:40: [2024-10-29 12:59:40] iter = 08630, loss = 34.2397
2024-10-29 12:59:41: [2024-10-29 12:59:41] iter = 08640, loss = 4.5324
2024-10-29 12:59:41: [2024-10-29 12:59:41] iter = 08650, loss = 14.9908
2024-10-29 12:59:42: [2024-10-29 12:59:42] iter = 08660, loss = 3.7764
2024-10-29 12:59:42: [2024-10-29 12:59:42] iter = 08670, loss = 10.8748
2024-10-29 12:59:43: [2024-10-29 12:59:43] iter = 08680, loss = 3.1454
2024-10-29 12:59:43: [2024-10-29 12:59:43] iter = 08690, loss = 7.2798
2024-10-29 12:59:43: [2024-10-29 12:59:43] iter = 08700, loss = 11.8496
2024-10-29 12:59:44: [2024-10-29 12:59:44] iter = 08710, loss = 6.3207
2024-10-29 12:59:45: [2024-10-29 12:59:45] iter = 08720, loss = 30.4341
2024-10-29 12:59:46: [2024-10-29 12:59:46] iter = 08730, loss = 7.5625
2024-10-29 12:59:46: [2024-10-29 12:59:46] iter = 08740, loss = 8.6572
2024-10-29 12:59:47: [2024-10-29 12:59:47] iter = 08750, loss = 4.3879
2024-10-29 12:59:47: [2024-10-29 12:59:47] iter = 08760, loss = 22.2368
2024-10-29 12:59:48: [2024-10-29 12:59:48] iter = 08770, loss = 4.6979
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 08780, loss = 4.1183
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 08790, loss = 9.7602
2024-10-29 12:59:49: [2024-10-29 12:59:49] iter = 08800, loss = 10.1721
2024-10-29 12:59:50: [2024-10-29 12:59:50] iter = 08810, loss = 5.3943
2024-10-29 12:59:51: [2024-10-29 12:59:51] iter = 08820, loss = 5.1574
2024-10-29 12:59:51: [2024-10-29 12:59:51] iter = 08830, loss = 24.3524
2024-10-29 12:59:52: [2024-10-29 12:59:52] iter = 08840, loss = 11.1584
2024-10-29 12:59:52: [2024-10-29 12:59:52] iter = 08850, loss = 8.5733
2024-10-29 12:59:53: [2024-10-29 12:59:53] iter = 08860, loss = 2.4831
2024-10-29 12:59:53: [2024-10-29 12:59:53] iter = 08870, loss = 8.0045
2024-10-29 12:59:54: [2024-10-29 12:59:54] iter = 08880, loss = 4.0470
2024-10-29 12:59:54: [2024-10-29 12:59:54] iter = 08890, loss = 9.7304
2024-10-29 12:59:55: [2024-10-29 12:59:55] iter = 08900, loss = 6.5396
2024-10-29 12:59:55: [2024-10-29 12:59:55] iter = 08910, loss = 66.2879
2024-10-29 12:59:56: [2024-10-29 12:59:56] iter = 08920, loss = 5.5952
2024-10-29 12:59:56: [2024-10-29 12:59:56] iter = 08930, loss = 4.4109
2024-10-29 12:59:57: [2024-10-29 12:59:57] iter = 08940, loss = 19.4635
2024-10-29 12:59:58: [2024-10-29 12:59:58] iter = 08950, loss = 2.9424
2024-10-29 12:59:58: [2024-10-29 12:59:58] iter = 08960, loss = 2.5501
2024-10-29 12:59:59: [2024-10-29 12:59:59] iter = 08970, loss = 15.0611
2024-10-29 13:00:00: [2024-10-29 13:00:00] iter = 08980, loss = 15.8361
2024-10-29 13:00:00: [2024-10-29 13:00:00] iter = 08990, loss = 2.9347
2024-10-29 13:00:01: [2024-10-29 13:00:01] iter = 09000, loss = 2.5496
2024-10-29 13:00:01: [2024-10-29 13:00:01] iter = 09010, loss = 2.5256
2024-10-29 13:00:02: [2024-10-29 13:00:02] iter = 09020, loss = 9.3677
2024-10-29 13:00:02: [2024-10-29 13:00:02] iter = 09030, loss = 6.1108
2024-10-29 13:00:02: [2024-10-29 13:00:02] iter = 09040, loss = 3.2454
2024-10-29 13:00:03: [2024-10-29 13:00:03] iter = 09050, loss = 9.9842
2024-10-29 13:00:04: [2024-10-29 13:00:04] iter = 09060, loss = 9.0137
2024-10-29 13:00:04: [2024-10-29 13:00:04] iter = 09070, loss = 34.0962
2024-10-29 13:00:05: [2024-10-29 13:00:05] iter = 09080, loss = 37.0512
2024-10-29 13:00:05: [2024-10-29 13:00:05] iter = 09090, loss = 6.2612
2024-10-29 13:00:06: [2024-10-29 13:00:06] iter = 09100, loss = 3.8633
2024-10-29 13:00:06: [2024-10-29 13:00:06] iter = 09110, loss = 3.7104
2024-10-29 13:00:07: [2024-10-29 13:00:07] iter = 09120, loss = 3.6130
2024-10-29 13:00:08: [2024-10-29 13:00:08] iter = 09130, loss = 3.7066
2024-10-29 13:00:08: [2024-10-29 13:00:08] iter = 09140, loss = 12.7072
2024-10-29 13:00:09: [2024-10-29 13:00:09] iter = 09150, loss = 10.7780
2024-10-29 13:00:09: [2024-10-29 13:00:09] iter = 09160, loss = 5.0545
2024-10-29 13:00:10: [2024-10-29 13:00:10] iter = 09170, loss = 3.9229
2024-10-29 13:00:10: [2024-10-29 13:00:10] iter = 09180, loss = 5.3702
2024-10-29 13:00:11: [2024-10-29 13:00:11] iter = 09190, loss = 4.7246
2024-10-29 13:00:11: [2024-10-29 13:00:11] iter = 09200, loss = 2.8474
2024-10-29 13:00:12: [2024-10-29 13:00:12] iter = 09210, loss = 3.5768
2024-10-29 13:00:12: [2024-10-29 13:00:12] iter = 09220, loss = 3.5742
2024-10-29 13:00:13: [2024-10-29 13:00:13] iter = 09230, loss = 40.0546
2024-10-29 13:00:13: [2024-10-29 13:00:13] iter = 09240, loss = 4.8573
2024-10-29 13:00:14: [2024-10-29 13:00:14] iter = 09250, loss = 2.9672
2024-10-29 13:00:14: [2024-10-29 13:00:14] iter = 09260, loss = 2.1928
2024-10-29 13:00:15: [2024-10-29 13:00:15] iter = 09270, loss = 4.0004
2024-10-29 13:00:15: [2024-10-29 13:00:15] iter = 09280, loss = 20.7678
2024-10-29 13:00:16: [2024-10-29 13:00:16] iter = 09290, loss = 3.5798
2024-10-29 13:00:16: [2024-10-29 13:00:16] iter = 09300, loss = 4.6143
2024-10-29 13:00:17: [2024-10-29 13:00:17] iter = 09310, loss = 7.4157
2024-10-29 13:00:17: [2024-10-29 13:00:17] iter = 09320, loss = 13.2430
2024-10-29 13:00:18: [2024-10-29 13:00:18] iter = 09330, loss = 7.0733
2024-10-29 13:00:18: [2024-10-29 13:00:18] iter = 09340, loss = 8.0177
2024-10-29 13:00:19: [2024-10-29 13:00:19] iter = 09350, loss = 5.3815
2024-10-29 13:00:19: [2024-10-29 13:00:19] iter = 09360, loss = 21.6482
2024-10-29 13:00:20: [2024-10-29 13:00:20] iter = 09370, loss = 2.6429
2024-10-29 13:00:20: [2024-10-29 13:00:20] iter = 09380, loss = 10.2111
2024-10-29 13:00:21: [2024-10-29 13:00:21] iter = 09390, loss = 14.6557
2024-10-29 13:00:21: [2024-10-29 13:00:21] iter = 09400, loss = 8.5310
2024-10-29 13:00:22: [2024-10-29 13:00:22] iter = 09410, loss = 8.4763
2024-10-29 13:00:22: [2024-10-29 13:00:22] iter = 09420, loss = 31.9732
2024-10-29 13:00:23: [2024-10-29 13:00:23] iter = 09430, loss = 31.6000
2024-10-29 13:00:23: [2024-10-29 13:00:23] iter = 09440, loss = 3.2604
2024-10-29 13:00:24: [2024-10-29 13:00:24] iter = 09450, loss = 15.9318
2024-10-29 13:00:24: [2024-10-29 13:00:24] iter = 09460, loss = 24.2751
2024-10-29 13:00:25: [2024-10-29 13:00:25] iter = 09470, loss = 9.9298
2024-10-29 13:00:25: [2024-10-29 13:00:25] iter = 09480, loss = 4.0845
2024-10-29 13:00:26: [2024-10-29 13:00:26] iter = 09490, loss = 2.5424
2024-10-29 13:00:26: [2024-10-29 13:00:26] iter = 09500, loss = 16.4155
2024-10-29 13:00:27: [2024-10-29 13:00:27] iter = 09510, loss = 2.6629
2024-10-29 13:00:27: [2024-10-29 13:00:27] iter = 09520, loss = 3.4226
2024-10-29 13:00:28: [2024-10-29 13:00:28] iter = 09530, loss = 4.9945
2024-10-29 13:00:28: [2024-10-29 13:00:28] iter = 09540, loss = 5.4425
2024-10-29 13:00:29: [2024-10-29 13:00:29] iter = 09550, loss = 3.1238
2024-10-29 13:00:29: [2024-10-29 13:00:29] iter = 09560, loss = 11.6869
2024-10-29 13:00:30: [2024-10-29 13:00:30] iter = 09570, loss = 2.3873
2024-10-29 13:00:30: [2024-10-29 13:00:30] iter = 09580, loss = 3.6696
2024-10-29 13:00:31: [2024-10-29 13:00:31] iter = 09590, loss = 3.7475
2024-10-29 13:00:31: [2024-10-29 13:00:31] iter = 09600, loss = 3.1338
2024-10-29 13:00:32: [2024-10-29 13:00:32] iter = 09610, loss = 4.5799
2024-10-29 13:00:32: [2024-10-29 13:00:32] iter = 09620, loss = 3.0235
2024-10-29 13:00:33: [2024-10-29 13:00:33] iter = 09630, loss = 7.5204
2024-10-29 13:00:33: [2024-10-29 13:00:33] iter = 09640, loss = 5.1045
2024-10-29 13:00:34: [2024-10-29 13:00:34] iter = 09650, loss = 2.0258
2024-10-29 13:00:34: [2024-10-29 13:00:34] iter = 09660, loss = 4.9035
2024-10-29 13:00:35: [2024-10-29 13:00:35] iter = 09670, loss = 58.2846
2024-10-29 13:00:36: [2024-10-29 13:00:36] iter = 09680, loss = 6.0457
2024-10-29 13:00:36: [2024-10-29 13:00:36] iter = 09690, loss = 7.3588
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 09700, loss = 7.0046
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 09710, loss = 2.2025
2024-10-29 13:00:37: [2024-10-29 13:00:37] iter = 09720, loss = 12.6774
2024-10-29 13:00:38: [2024-10-29 13:00:38] iter = 09730, loss = 3.3463
2024-10-29 13:00:38: [2024-10-29 13:00:38] iter = 09740, loss = 3.2054
2024-10-29 13:00:39: [2024-10-29 13:00:39] iter = 09750, loss = 5.5030
2024-10-29 13:00:39: [2024-10-29 13:00:39] iter = 09760, loss = 4.7404
2024-10-29 13:00:40: [2024-10-29 13:00:40] iter = 09770, loss = 13.0514
2024-10-29 13:00:40: [2024-10-29 13:00:40] iter = 09780, loss = 8.0512
2024-10-29 13:00:41: [2024-10-29 13:00:41] iter = 09790, loss = 4.4746
2024-10-29 13:00:41: [2024-10-29 13:00:41] iter = 09800, loss = 5.7710
2024-10-29 13:00:42: [2024-10-29 13:00:42] iter = 09810, loss = 4.7002
2024-10-29 13:00:42: [2024-10-29 13:00:42] iter = 09820, loss = 13.4051
2024-10-29 13:00:43: [2024-10-29 13:00:43] iter = 09830, loss = 3.9805
2024-10-29 13:00:43: [2024-10-29 13:00:43] iter = 09840, loss = 16.6206
2024-10-29 13:00:44: [2024-10-29 13:00:44] iter = 09850, loss = 2.2385
2024-10-29 13:00:44: [2024-10-29 13:00:44] iter = 09860, loss = 5.3704
2024-10-29 13:00:45: [2024-10-29 13:00:45] iter = 09870, loss = 5.4808
2024-10-29 13:00:45: [2024-10-29 13:00:45] iter = 09880, loss = 3.9504
2024-10-29 13:00:46: [2024-10-29 13:00:46] iter = 09890, loss = 2.8992
2024-10-29 13:00:47: [2024-10-29 13:00:47] iter = 09900, loss = 8.6989
2024-10-29 13:00:47: [2024-10-29 13:00:47] iter = 09910, loss = 2.9796
2024-10-29 13:00:48: [2024-10-29 13:00:48] iter = 09920, loss = 2.6061
2024-10-29 13:00:49: [2024-10-29 13:00:49] iter = 09930, loss = 2.4195
2024-10-29 13:00:49: [2024-10-29 13:00:49] iter = 09940, loss = 2.6234
2024-10-29 13:00:50: [2024-10-29 13:00:50] iter = 09950, loss = 5.2526
2024-10-29 13:00:50: [2024-10-29 13:00:50] iter = 09960, loss = 3.3448
2024-10-29 13:00:51: [2024-10-29 13:00:51] iter = 09970, loss = 24.9261
2024-10-29 13:00:51: [2024-10-29 13:00:51] iter = 09980, loss = 3.4559
2024-10-29 13:00:52: [2024-10-29 13:00:52] iter = 09990, loss = 18.8052
2024-10-29 13:00:52: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 13:00:52: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:00:52: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52628}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:01:20: Evaluate 5 random ConvNet, ACCmean = 0.4298 ACCstd = 0.0035
-------------------------
2024-10-29 13:01:20: Evaluate 5 random ConvNet, SENmean = 0.4298 SENstd = 0.0035
-------------------------
2024-10-29 13:01:20: Evaluate 5 random ConvNet, SPEmean = 0.8099 SPEstd = 0.0012
-------------------------
2024-10-29 13:01:20: Evaluate 5 random ConvNet, F!mean = 0.3690 F!std = 0.0026
-------------------------
2024-10-29 13:01:20: Evaluate 5 random ConvNet, mean = 0.4298 std = 0.0035
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:01:20: [2024-10-29 13:01:20] iter = 10000, loss = 48.7994
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:01:21: [2024-10-29 13:01:21] iter = 10010, loss = 4.0131
2024-10-29 13:01:21: [2024-10-29 13:01:21] iter = 10020, loss = 4.4470
2024-10-29 13:01:22: [2024-10-29 13:01:22] iter = 10030, loss = 10.9245
2024-10-29 13:01:22: [2024-10-29 13:01:22] iter = 10040, loss = 9.9597
2024-10-29 13:01:23: [2024-10-29 13:01:23] iter = 10050, loss = 45.3213
2024-10-29 13:01:23: [2024-10-29 13:01:23] iter = 10060, loss = 3.5472
2024-10-29 13:01:24: [2024-10-29 13:01:24] iter = 10070, loss = 7.6235
2024-10-29 13:01:24: [2024-10-29 13:01:24] iter = 10080, loss = 10.5095
2024-10-29 13:01:25: [2024-10-29 13:01:25] iter = 10090, loss = 7.6924
2024-10-29 13:01:26: [2024-10-29 13:01:26] iter = 10100, loss = 15.0192
2024-10-29 13:01:26: [2024-10-29 13:01:26] iter = 10110, loss = 4.6520
2024-10-29 13:01:27: [2024-10-29 13:01:27] iter = 10120, loss = 11.0661
2024-10-29 13:01:27: [2024-10-29 13:01:27] iter = 10130, loss = 18.9348
2024-10-29 13:01:28: [2024-10-29 13:01:28] iter = 10140, loss = 6.1878
2024-10-29 13:01:28: [2024-10-29 13:01:28] iter = 10150, loss = 89.0171
2024-10-29 13:01:29: [2024-10-29 13:01:29] iter = 10160, loss = 4.7632
2024-10-29 13:01:29: [2024-10-29 13:01:29] iter = 10170, loss = 3.5143
2024-10-29 13:01:30: [2024-10-29 13:01:30] iter = 10180, loss = 11.9162
2024-10-29 13:01:30: [2024-10-29 13:01:30] iter = 10190, loss = 10.7252
2024-10-29 13:01:31: [2024-10-29 13:01:31] iter = 10200, loss = 3.0189
2024-10-29 13:01:31: [2024-10-29 13:01:31] iter = 10210, loss = 7.1424
2024-10-29 13:01:32: [2024-10-29 13:01:32] iter = 10220, loss = 27.8399
2024-10-29 13:01:33: [2024-10-29 13:01:33] iter = 10230, loss = 3.2846
2024-10-29 13:01:33: [2024-10-29 13:01:33] iter = 10240, loss = 6.0731
2024-10-29 13:01:34: [2024-10-29 13:01:34] iter = 10250, loss = 3.7268
2024-10-29 13:01:34: [2024-10-29 13:01:34] iter = 10260, loss = 6.9665
2024-10-29 13:01:35: [2024-10-29 13:01:35] iter = 10270, loss = 3.7202
2024-10-29 13:01:35: [2024-10-29 13:01:35] iter = 10280, loss = 3.6542
2024-10-29 13:01:36: [2024-10-29 13:01:36] iter = 10290, loss = 15.0545
2024-10-29 13:01:36: [2024-10-29 13:01:36] iter = 10300, loss = 4.2088
2024-10-29 13:01:37: [2024-10-29 13:01:37] iter = 10310, loss = 3.0912
2024-10-29 13:01:37: [2024-10-29 13:01:37] iter = 10320, loss = 4.9783
2024-10-29 13:01:38: [2024-10-29 13:01:38] iter = 10330, loss = 7.3200
2024-10-29 13:01:38: [2024-10-29 13:01:38] iter = 10340, loss = 10.2349
2024-10-29 13:01:39: [2024-10-29 13:01:39] iter = 10350, loss = 3.5909
2024-10-29 13:01:39: [2024-10-29 13:01:39] iter = 10360, loss = 13.2842
2024-10-29 13:01:40: [2024-10-29 13:01:40] iter = 10370, loss = 2.5829
2024-10-29 13:01:41: [2024-10-29 13:01:41] iter = 10380, loss = 7.9235
2024-10-29 13:01:41: [2024-10-29 13:01:41] iter = 10390, loss = 11.4136
2024-10-29 13:01:42: [2024-10-29 13:01:42] iter = 10400, loss = 4.1809
2024-10-29 13:01:42: [2024-10-29 13:01:42] iter = 10410, loss = 10.7880
2024-10-29 13:01:43: [2024-10-29 13:01:43] iter = 10420, loss = 4.3880
2024-10-29 13:01:44: [2024-10-29 13:01:44] iter = 10430, loss = 2.9812
2024-10-29 13:01:44: [2024-10-29 13:01:44] iter = 10440, loss = 3.6505
2024-10-29 13:01:45: [2024-10-29 13:01:45] iter = 10450, loss = 7.7671
2024-10-29 13:01:45: [2024-10-29 13:01:45] iter = 10460, loss = 4.0748
2024-10-29 13:01:46: [2024-10-29 13:01:46] iter = 10470, loss = 28.6669
2024-10-29 13:01:46: [2024-10-29 13:01:46] iter = 10480, loss = 2.8206
2024-10-29 13:01:47: [2024-10-29 13:01:47] iter = 10490, loss = 3.3993
2024-10-29 13:01:47: [2024-10-29 13:01:47] iter = 10500, loss = 6.3334
2024-10-29 13:01:48: [2024-10-29 13:01:48] iter = 10510, loss = 7.6627
2024-10-29 13:01:48: [2024-10-29 13:01:48] iter = 10520, loss = 4.3538
2024-10-29 13:01:49: [2024-10-29 13:01:49] iter = 10530, loss = 3.0848
2024-10-29 13:01:49: [2024-10-29 13:01:49] iter = 10540, loss = 11.3488
2024-10-29 13:01:50: [2024-10-29 13:01:50] iter = 10550, loss = 41.5695
2024-10-29 13:01:50: [2024-10-29 13:01:50] iter = 10560, loss = 26.8741
2024-10-29 13:01:51: [2024-10-29 13:01:51] iter = 10570, loss = 4.4043
2024-10-29 13:01:52: [2024-10-29 13:01:52] iter = 10580, loss = 6.3019
2024-10-29 13:01:52: [2024-10-29 13:01:52] iter = 10590, loss = 3.6842
2024-10-29 13:01:53: [2024-10-29 13:01:53] iter = 10600, loss = 24.4538
2024-10-29 13:01:53: [2024-10-29 13:01:53] iter = 10610, loss = 3.9714
2024-10-29 13:01:54: [2024-10-29 13:01:54] iter = 10620, loss = 2.4924
2024-10-29 13:01:54: [2024-10-29 13:01:54] iter = 10630, loss = 2.8337
2024-10-29 13:01:55: [2024-10-29 13:01:55] iter = 10640, loss = 5.3171
2024-10-29 13:01:55: [2024-10-29 13:01:55] iter = 10650, loss = 5.6965
2024-10-29 13:01:56: [2024-10-29 13:01:56] iter = 10660, loss = 4.1732
2024-10-29 13:01:56: [2024-10-29 13:01:56] iter = 10670, loss = 32.6315
2024-10-29 13:01:57: [2024-10-29 13:01:57] iter = 10680, loss = 3.7707
2024-10-29 13:01:57: [2024-10-29 13:01:57] iter = 10690, loss = 56.0403
2024-10-29 13:01:58: [2024-10-29 13:01:58] iter = 10700, loss = 3.9062
2024-10-29 13:01:58: [2024-10-29 13:01:58] iter = 10710, loss = 20.9037
2024-10-29 13:01:59: [2024-10-29 13:01:59] iter = 10720, loss = 18.1501
2024-10-29 13:01:59: [2024-10-29 13:01:59] iter = 10730, loss = 12.9382
2024-10-29 13:02:00: [2024-10-29 13:02:00] iter = 10740, loss = 2.2206
2024-10-29 13:02:00: [2024-10-29 13:02:00] iter = 10750, loss = 6.7160
2024-10-29 13:02:01: [2024-10-29 13:02:01] iter = 10760, loss = 3.2107
2024-10-29 13:02:02: [2024-10-29 13:02:02] iter = 10770, loss = 6.1119
2024-10-29 13:02:02: [2024-10-29 13:02:02] iter = 10780, loss = 5.5358
2024-10-29 13:02:03: [2024-10-29 13:02:03] iter = 10790, loss = 23.1747
2024-10-29 13:02:03: [2024-10-29 13:02:03] iter = 10800, loss = 4.5537
2024-10-29 13:02:04: [2024-10-29 13:02:04] iter = 10810, loss = 10.5520
2024-10-29 13:02:04: [2024-10-29 13:02:04] iter = 10820, loss = 12.8397
2024-10-29 13:02:05: [2024-10-29 13:02:05] iter = 10830, loss = 5.5715
2024-10-29 13:02:05: [2024-10-29 13:02:05] iter = 10840, loss = 2.4989
2024-10-29 13:02:06: [2024-10-29 13:02:06] iter = 10850, loss = 4.8363
2024-10-29 13:02:06: [2024-10-29 13:02:06] iter = 10860, loss = 5.2743
2024-10-29 13:02:07: [2024-10-29 13:02:07] iter = 10870, loss = 8.2479
2024-10-29 13:02:07: [2024-10-29 13:02:07] iter = 10880, loss = 5.1278
2024-10-29 13:02:08: [2024-10-29 13:02:08] iter = 10890, loss = 6.5727
2024-10-29 13:02:09: [2024-10-29 13:02:09] iter = 10900, loss = 10.7338
2024-10-29 13:02:09: [2024-10-29 13:02:09] iter = 10910, loss = 14.1129
2024-10-29 13:02:10: [2024-10-29 13:02:10] iter = 10920, loss = 5.3995
2024-10-29 13:02:10: [2024-10-29 13:02:10] iter = 10930, loss = 6.8838
2024-10-29 13:02:11: [2024-10-29 13:02:11] iter = 10940, loss = 6.6871
2024-10-29 13:02:12: [2024-10-29 13:02:12] iter = 10950, loss = 3.9506
2024-10-29 13:02:12: [2024-10-29 13:02:12] iter = 10960, loss = 3.5735
2024-10-29 13:02:13: [2024-10-29 13:02:13] iter = 10970, loss = 4.4179
2024-10-29 13:02:13: [2024-10-29 13:02:13] iter = 10980, loss = 5.2699
2024-10-29 13:02:14: [2024-10-29 13:02:14] iter = 10990, loss = 26.9504
2024-10-29 13:02:14: [2024-10-29 13:02:14] iter = 11000, loss = 5.8427
2024-10-29 13:02:15: [2024-10-29 13:02:15] iter = 11010, loss = 15.0390
2024-10-29 13:02:15: [2024-10-29 13:02:15] iter = 11020, loss = 39.9359
2024-10-29 13:02:16: [2024-10-29 13:02:16] iter = 11030, loss = 24.2448
2024-10-29 13:02:16: [2024-10-29 13:02:16] iter = 11040, loss = 16.6409
2024-10-29 13:02:17: [2024-10-29 13:02:17] iter = 11050, loss = 4.1319
2024-10-29 13:02:17: [2024-10-29 13:02:17] iter = 11060, loss = 24.4798
2024-10-29 13:02:17: [2024-10-29 13:02:17] iter = 11070, loss = 7.2072
2024-10-29 13:02:18: [2024-10-29 13:02:18] iter = 11080, loss = 2.9327
2024-10-29 13:02:18: [2024-10-29 13:02:18] iter = 11090, loss = 8.7109
2024-10-29 13:02:19: [2024-10-29 13:02:19] iter = 11100, loss = 3.7753
2024-10-29 13:02:20: [2024-10-29 13:02:20] iter = 11110, loss = 3.8585
2024-10-29 13:02:20: [2024-10-29 13:02:20] iter = 11120, loss = 4.7087
2024-10-29 13:02:21: [2024-10-29 13:02:21] iter = 11130, loss = 8.1242
2024-10-29 13:02:21: [2024-10-29 13:02:21] iter = 11140, loss = 10.4653
2024-10-29 13:02:22: [2024-10-29 13:02:22] iter = 11150, loss = 20.6110
2024-10-29 13:02:22: [2024-10-29 13:02:22] iter = 11160, loss = 7.2276
2024-10-29 13:02:23: [2024-10-29 13:02:23] iter = 11170, loss = 13.7972
2024-10-29 13:02:23: [2024-10-29 13:02:23] iter = 11180, loss = 8.6323
2024-10-29 13:02:24: [2024-10-29 13:02:24] iter = 11190, loss = 26.8965
2024-10-29 13:02:24: [2024-10-29 13:02:24] iter = 11200, loss = 5.3196
2024-10-29 13:02:25: [2024-10-29 13:02:25] iter = 11210, loss = 5.0392
2024-10-29 13:02:26: [2024-10-29 13:02:26] iter = 11220, loss = 5.5402
2024-10-29 13:02:26: [2024-10-29 13:02:26] iter = 11230, loss = 2.5802
2024-10-29 13:02:27: [2024-10-29 13:02:27] iter = 11240, loss = 2.7433
2024-10-29 13:02:27: [2024-10-29 13:02:27] iter = 11250, loss = 2.5661
2024-10-29 13:02:28: [2024-10-29 13:02:28] iter = 11260, loss = 3.4140
2024-10-29 13:02:29: [2024-10-29 13:02:29] iter = 11270, loss = 5.4064
2024-10-29 13:02:29: [2024-10-29 13:02:29] iter = 11280, loss = 6.9664
2024-10-29 13:02:30: [2024-10-29 13:02:30] iter = 11290, loss = 4.8507
2024-10-29 13:02:30: [2024-10-29 13:02:30] iter = 11300, loss = 3.1558
2024-10-29 13:02:31: [2024-10-29 13:02:31] iter = 11310, loss = 16.4406
2024-10-29 13:02:31: [2024-10-29 13:02:31] iter = 11320, loss = 2.9222
2024-10-29 13:02:32: [2024-10-29 13:02:32] iter = 11330, loss = 4.5074
2024-10-29 13:02:32: [2024-10-29 13:02:32] iter = 11340, loss = 6.0125
2024-10-29 13:02:33: [2024-10-29 13:02:33] iter = 11350, loss = 8.3012
2024-10-29 13:02:33: [2024-10-29 13:02:33] iter = 11360, loss = 7.1128
2024-10-29 13:02:34: [2024-10-29 13:02:34] iter = 11370, loss = 20.8525
2024-10-29 13:02:34: [2024-10-29 13:02:34] iter = 11380, loss = 7.2530
2024-10-29 13:02:35: [2024-10-29 13:02:35] iter = 11390, loss = 62.1259
2024-10-29 13:02:35: [2024-10-29 13:02:35] iter = 11400, loss = 25.0153
2024-10-29 13:02:36: [2024-10-29 13:02:36] iter = 11410, loss = 3.8339
2024-10-29 13:02:36: [2024-10-29 13:02:36] iter = 11420, loss = 3.2344
2024-10-29 13:02:37: [2024-10-29 13:02:37] iter = 11430, loss = 20.8917
2024-10-29 13:02:37: [2024-10-29 13:02:37] iter = 11440, loss = 2.7465
2024-10-29 13:02:38: [2024-10-29 13:02:38] iter = 11450, loss = 5.3464
2024-10-29 13:02:38: [2024-10-29 13:02:38] iter = 11460, loss = 6.3095
2024-10-29 13:02:39: [2024-10-29 13:02:39] iter = 11470, loss = 11.2957
2024-10-29 13:02:39: [2024-10-29 13:02:39] iter = 11480, loss = 6.7436
2024-10-29 13:02:40: [2024-10-29 13:02:40] iter = 11490, loss = 7.6524
2024-10-29 13:02:40: [2024-10-29 13:02:40] iter = 11500, loss = 14.4139
2024-10-29 13:02:41: [2024-10-29 13:02:41] iter = 11510, loss = 4.9242
2024-10-29 13:02:41: [2024-10-29 13:02:41] iter = 11520, loss = 8.3314
2024-10-29 13:02:42: [2024-10-29 13:02:42] iter = 11530, loss = 8.2955
2024-10-29 13:02:42: [2024-10-29 13:02:42] iter = 11540, loss = 3.3779
2024-10-29 13:02:43: [2024-10-29 13:02:43] iter = 11550, loss = 30.1711
2024-10-29 13:02:44: [2024-10-29 13:02:44] iter = 11560, loss = 12.7199
2024-10-29 13:02:44: [2024-10-29 13:02:44] iter = 11570, loss = 5.2954
2024-10-29 13:02:45: [2024-10-29 13:02:45] iter = 11580, loss = 7.9526
2024-10-29 13:02:45: [2024-10-29 13:02:45] iter = 11590, loss = 3.5278
2024-10-29 13:02:46: [2024-10-29 13:02:46] iter = 11600, loss = 5.9324
2024-10-29 13:02:46: [2024-10-29 13:02:46] iter = 11610, loss = 3.6887
2024-10-29 13:02:47: [2024-10-29 13:02:47] iter = 11620, loss = 10.4091
2024-10-29 13:02:47: [2024-10-29 13:02:47] iter = 11630, loss = 29.6545
2024-10-29 13:02:48: [2024-10-29 13:02:48] iter = 11640, loss = 7.6149
2024-10-29 13:02:48: [2024-10-29 13:02:48] iter = 11650, loss = 3.4618
2024-10-29 13:02:49: [2024-10-29 13:02:49] iter = 11660, loss = 19.4188
2024-10-29 13:02:50: [2024-10-29 13:02:50] iter = 11670, loss = 4.3116
2024-10-29 13:02:50: [2024-10-29 13:02:50] iter = 11680, loss = 7.1896
2024-10-29 13:02:51: [2024-10-29 13:02:51] iter = 11690, loss = 6.8154
2024-10-29 13:02:51: [2024-10-29 13:02:51] iter = 11700, loss = 8.8721
2024-10-29 13:02:52: [2024-10-29 13:02:52] iter = 11710, loss = 6.3522
2024-10-29 13:02:52: [2024-10-29 13:02:52] iter = 11720, loss = 3.6402
2024-10-29 13:02:53: [2024-10-29 13:02:53] iter = 11730, loss = 4.1284
2024-10-29 13:02:53: [2024-10-29 13:02:53] iter = 11740, loss = 2.7753
2024-10-29 13:02:54: [2024-10-29 13:02:54] iter = 11750, loss = 5.5836
2024-10-29 13:02:54: [2024-10-29 13:02:54] iter = 11760, loss = 4.4285
2024-10-29 13:02:55: [2024-10-29 13:02:55] iter = 11770, loss = 7.7917
2024-10-29 13:02:55: [2024-10-29 13:02:55] iter = 11780, loss = 2.6798
2024-10-29 13:02:56: [2024-10-29 13:02:56] iter = 11790, loss = 3.6111
2024-10-29 13:02:56: [2024-10-29 13:02:56] iter = 11800, loss = 3.2743
2024-10-29 13:02:57: [2024-10-29 13:02:57] iter = 11810, loss = 6.7842
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 11820, loss = 6.3436
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 11830, loss = 34.6169
2024-10-29 13:02:58: [2024-10-29 13:02:58] iter = 11840, loss = 3.9794
2024-10-29 13:02:59: [2024-10-29 13:02:59] iter = 11850, loss = 6.7018
2024-10-29 13:03:00: [2024-10-29 13:03:00] iter = 11860, loss = 4.9263
2024-10-29 13:03:00: [2024-10-29 13:03:00] iter = 11870, loss = 6.4515
2024-10-29 13:03:01: [2024-10-29 13:03:01] iter = 11880, loss = 2.9771
2024-10-29 13:03:01: [2024-10-29 13:03:01] iter = 11890, loss = 65.2701
2024-10-29 13:03:02: [2024-10-29 13:03:02] iter = 11900, loss = 7.0446
2024-10-29 13:03:02: [2024-10-29 13:03:02] iter = 11910, loss = 21.0699
2024-10-29 13:03:03: [2024-10-29 13:03:03] iter = 11920, loss = 18.7486
2024-10-29 13:03:03: [2024-10-29 13:03:03] iter = 11930, loss = 4.9521
2024-10-29 13:03:04: [2024-10-29 13:03:04] iter = 11940, loss = 6.6665
2024-10-29 13:03:04: [2024-10-29 13:03:04] iter = 11950, loss = 8.7620
2024-10-29 13:03:05: [2024-10-29 13:03:05] iter = 11960, loss = 6.2218
2024-10-29 13:03:05: [2024-10-29 13:03:05] iter = 11970, loss = 3.5916
2024-10-29 13:03:06: [2024-10-29 13:03:06] iter = 11980, loss = 9.8293
2024-10-29 13:03:06: [2024-10-29 13:03:06] iter = 11990, loss = 7.6574
2024-10-29 13:03:07: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 13:03:07: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:03:07: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87064}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:03:33: Evaluate 5 random ConvNet, ACCmean = 0.5594 ACCstd = 0.0074
-------------------------
2024-10-29 13:03:33: Evaluate 5 random ConvNet, SENmean = 0.5594 SENstd = 0.0074
-------------------------
2024-10-29 13:03:33: Evaluate 5 random ConvNet, SPEmean = 0.8531 SPEstd = 0.0025
-------------------------
2024-10-29 13:03:33: Evaluate 5 random ConvNet, F!mean = 0.5594 F!std = 0.0075
-------------------------
2024-10-29 13:03:33: Evaluate 5 random ConvNet, mean = 0.5594 std = 0.0074
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:03:33: [2024-10-29 13:03:33] iter = 12000, loss = 2.8003
2024-10-29 13:03:34: [2024-10-29 13:03:34] iter = 12010, loss = 6.4827
2024-10-29 13:03:34: [2024-10-29 13:03:34] iter = 12020, loss = 2.7121
2024-10-29 13:03:35: [2024-10-29 13:03:35] iter = 12030, loss = 7.9076
2024-10-29 13:03:35: [2024-10-29 13:03:35] iter = 12040, loss = 10.3852
2024-10-29 13:03:36: [2024-10-29 13:03:36] iter = 12050, loss = 61.1561
2024-10-29 13:03:36: [2024-10-29 13:03:36] iter = 12060, loss = 18.9731
2024-10-29 13:03:37: [2024-10-29 13:03:37] iter = 12070, loss = 1.8919
2024-10-29 13:03:37: [2024-10-29 13:03:37] iter = 12080, loss = 5.5752
2024-10-29 13:03:38: [2024-10-29 13:03:38] iter = 12090, loss = 2.4944
2024-10-29 13:03:38: [2024-10-29 13:03:38] iter = 12100, loss = 4.9705
2024-10-29 13:03:39: [2024-10-29 13:03:39] iter = 12110, loss = 5.2469
2024-10-29 13:03:39: [2024-10-29 13:03:39] iter = 12120, loss = 8.6278
2024-10-29 13:03:40: [2024-10-29 13:03:40] iter = 12130, loss = 13.3174
2024-10-29 13:03:40: [2024-10-29 13:03:40] iter = 12140, loss = 2.9617
2024-10-29 13:03:41: [2024-10-29 13:03:41] iter = 12150, loss = 8.7242
2024-10-29 13:03:41: [2024-10-29 13:03:41] iter = 12160, loss = 6.5132
2024-10-29 13:03:42: [2024-10-29 13:03:42] iter = 12170, loss = 3.1996
2024-10-29 13:03:42: [2024-10-29 13:03:42] iter = 12180, loss = 7.0901
2024-10-29 13:03:43: [2024-10-29 13:03:43] iter = 12190, loss = 9.1943
2024-10-29 13:03:43: [2024-10-29 13:03:43] iter = 12200, loss = 2.7555
2024-10-29 13:03:44: [2024-10-29 13:03:44] iter = 12210, loss = 5.1548
2024-10-29 13:03:44: [2024-10-29 13:03:44] iter = 12220, loss = 3.3647
2024-10-29 13:03:45: [2024-10-29 13:03:45] iter = 12230, loss = 8.1819
2024-10-29 13:03:45: [2024-10-29 13:03:45] iter = 12240, loss = 3.8914
2024-10-29 13:03:46: [2024-10-29 13:03:46] iter = 12250, loss = 40.0176
2024-10-29 13:03:46: [2024-10-29 13:03:46] iter = 12260, loss = 7.2319
2024-10-29 13:03:47: [2024-10-29 13:03:47] iter = 12270, loss = 3.6859
2024-10-29 13:03:47: [2024-10-29 13:03:47] iter = 12280, loss = 35.4977
2024-10-29 13:03:48: [2024-10-29 13:03:48] iter = 12290, loss = 4.7837
2024-10-29 13:03:48: [2024-10-29 13:03:48] iter = 12300, loss = 13.2191
2024-10-29 13:03:49: [2024-10-29 13:03:49] iter = 12310, loss = 5.0073
2024-10-29 13:03:49: [2024-10-29 13:03:49] iter = 12320, loss = 8.9555
2024-10-29 13:03:50: [2024-10-29 13:03:50] iter = 12330, loss = 4.4500
2024-10-29 13:03:50: [2024-10-29 13:03:50] iter = 12340, loss = 3.3084
2024-10-29 13:03:51: [2024-10-29 13:03:51] iter = 12350, loss = 2.6837
2024-10-29 13:03:52: [2024-10-29 13:03:52] iter = 12360, loss = 8.5033
2024-10-29 13:03:52: [2024-10-29 13:03:52] iter = 12370, loss = 4.9309
2024-10-29 13:03:53: [2024-10-29 13:03:53] iter = 12380, loss = 10.4444
2024-10-29 13:03:53: [2024-10-29 13:03:53] iter = 12390, loss = 8.7663
2024-10-29 13:03:54: [2024-10-29 13:03:54] iter = 12400, loss = 12.8505
2024-10-29 13:03:54: [2024-10-29 13:03:54] iter = 12410, loss = 4.6798
2024-10-29 13:03:55: [2024-10-29 13:03:55] iter = 12420, loss = 3.9994
2024-10-29 13:03:55: [2024-10-29 13:03:55] iter = 12430, loss = 3.0701
2024-10-29 13:03:56: [2024-10-29 13:03:56] iter = 12440, loss = 11.0531
2024-10-29 13:03:56: [2024-10-29 13:03:56] iter = 12450, loss = 4.9278
2024-10-29 13:03:57: [2024-10-29 13:03:57] iter = 12460, loss = 12.5383
2024-10-29 13:03:57: [2024-10-29 13:03:57] iter = 12470, loss = 4.2220
2024-10-29 13:03:58: [2024-10-29 13:03:58] iter = 12480, loss = 3.4820
2024-10-29 13:03:59: [2024-10-29 13:03:59] iter = 12490, loss = 4.2982
2024-10-29 13:03:59: [2024-10-29 13:03:59] iter = 12500, loss = 7.6250
2024-10-29 13:04:00: [2024-10-29 13:04:00] iter = 12510, loss = 12.7634
2024-10-29 13:04:00: [2024-10-29 13:04:00] iter = 12520, loss = 33.4267
2024-10-29 13:04:01: [2024-10-29 13:04:01] iter = 12530, loss = 21.4022
2024-10-29 13:04:01: [2024-10-29 13:04:01] iter = 12540, loss = 7.1529
2024-10-29 13:04:02: [2024-10-29 13:04:02] iter = 12550, loss = 4.2839
2024-10-29 13:04:02: [2024-10-29 13:04:02] iter = 12560, loss = 2.1789
2024-10-29 13:04:03: [2024-10-29 13:04:03] iter = 12570, loss = 6.1200
2024-10-29 13:04:03: [2024-10-29 13:04:03] iter = 12580, loss = 3.0637
2024-10-29 13:04:04: [2024-10-29 13:04:04] iter = 12590, loss = 13.5680
2024-10-29 13:04:04: [2024-10-29 13:04:04] iter = 12600, loss = 8.2592
2024-10-29 13:04:05: [2024-10-29 13:04:05] iter = 12610, loss = 5.0731
2024-10-29 13:04:05: [2024-10-29 13:04:05] iter = 12620, loss = 33.0681
2024-10-29 13:04:06: [2024-10-29 13:04:06] iter = 12630, loss = 6.2731
2024-10-29 13:04:06: [2024-10-29 13:04:06] iter = 12640, loss = 2.4410
2024-10-29 13:04:07: [2024-10-29 13:04:07] iter = 12650, loss = 4.7757
2024-10-29 13:04:07: [2024-10-29 13:04:07] iter = 12660, loss = 12.0743
2024-10-29 13:04:08: [2024-10-29 13:04:08] iter = 12670, loss = 15.0521
2024-10-29 13:04:08: [2024-10-29 13:04:08] iter = 12680, loss = 11.4241
2024-10-29 13:04:09: [2024-10-29 13:04:09] iter = 12690, loss = 39.1239
2024-10-29 13:04:09: [2024-10-29 13:04:09] iter = 12700, loss = 10.7667
2024-10-29 13:04:10: [2024-10-29 13:04:10] iter = 12710, loss = 8.6528
2024-10-29 13:04:10: [2024-10-29 13:04:10] iter = 12720, loss = 12.8597
2024-10-29 13:04:11: [2024-10-29 13:04:11] iter = 12730, loss = 17.2224
2024-10-29 13:04:11: [2024-10-29 13:04:11] iter = 12740, loss = 16.6032
2024-10-29 13:04:12: [2024-10-29 13:04:12] iter = 12750, loss = 3.0358
2024-10-29 13:04:13: [2024-10-29 13:04:13] iter = 12760, loss = 3.6508
2024-10-29 13:04:13: [2024-10-29 13:04:13] iter = 12770, loss = 4.0874
2024-10-29 13:04:14: [2024-10-29 13:04:14] iter = 12780, loss = 3.2980
2024-10-29 13:04:14: [2024-10-29 13:04:14] iter = 12790, loss = 3.5216
2024-10-29 13:04:15: [2024-10-29 13:04:15] iter = 12800, loss = 6.0270
2024-10-29 13:04:15: [2024-10-29 13:04:15] iter = 12810, loss = 6.1249
2024-10-29 13:04:16: [2024-10-29 13:04:16] iter = 12820, loss = 3.7819
2024-10-29 13:04:16: [2024-10-29 13:04:16] iter = 12830, loss = 5.9355
2024-10-29 13:04:17: [2024-10-29 13:04:17] iter = 12840, loss = 3.7377
2024-10-29 13:04:17: [2024-10-29 13:04:17] iter = 12850, loss = 13.3948
2024-10-29 13:04:18: [2024-10-29 13:04:18] iter = 12860, loss = 15.1958
2024-10-29 13:04:18: [2024-10-29 13:04:18] iter = 12870, loss = 3.4192
2024-10-29 13:04:19: [2024-10-29 13:04:19] iter = 12880, loss = 3.7851
2024-10-29 13:04:20: [2024-10-29 13:04:20] iter = 12890, loss = 8.0327
2024-10-29 13:04:20: [2024-10-29 13:04:20] iter = 12900, loss = 23.1725
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 12910, loss = 6.2372
2024-10-29 13:04:21: [2024-10-29 13:04:21] iter = 12920, loss = 6.0837
2024-10-29 13:04:22: [2024-10-29 13:04:22] iter = 12930, loss = 4.3809
2024-10-29 13:04:22: [2024-10-29 13:04:22] iter = 12940, loss = 11.5481
2024-10-29 13:04:23: [2024-10-29 13:04:23] iter = 12950, loss = 2.1149
2024-10-29 13:04:23: [2024-10-29 13:04:23] iter = 12960, loss = 6.5214
2024-10-29 13:04:24: [2024-10-29 13:04:24] iter = 12970, loss = 9.1712
2024-10-29 13:04:24: [2024-10-29 13:04:24] iter = 12980, loss = 4.3145
2024-10-29 13:04:25: [2024-10-29 13:04:25] iter = 12990, loss = 5.0578
2024-10-29 13:04:25: [2024-10-29 13:04:25] iter = 13000, loss = 2.8352
2024-10-29 13:04:26: [2024-10-29 13:04:26] iter = 13010, loss = 14.3667
2024-10-29 13:04:26: [2024-10-29 13:04:26] iter = 13020, loss = 2.4717
2024-10-29 13:04:27: [2024-10-29 13:04:27] iter = 13030, loss = 16.6718
2024-10-29 13:04:27: [2024-10-29 13:04:27] iter = 13040, loss = 4.8543
2024-10-29 13:04:28: [2024-10-29 13:04:28] iter = 13050, loss = 4.5725
2024-10-29 13:04:29: [2024-10-29 13:04:29] iter = 13060, loss = 3.5299
2024-10-29 13:04:29: [2024-10-29 13:04:29] iter = 13070, loss = 4.6685
2024-10-29 13:04:30: [2024-10-29 13:04:30] iter = 13080, loss = 4.1867
2024-10-29 13:04:30: [2024-10-29 13:04:30] iter = 13090, loss = 3.8471
2024-10-29 13:04:31: [2024-10-29 13:04:31] iter = 13100, loss = 15.9702
2024-10-29 13:04:31: [2024-10-29 13:04:31] iter = 13110, loss = 6.4231
2024-10-29 13:04:32: [2024-10-29 13:04:32] iter = 13120, loss = 46.5156
2024-10-29 13:04:32: [2024-10-29 13:04:32] iter = 13130, loss = 3.0277
2024-10-29 13:04:33: [2024-10-29 13:04:33] iter = 13140, loss = 11.5895
2024-10-29 13:04:33: [2024-10-29 13:04:33] iter = 13150, loss = 15.6704
2024-10-29 13:04:34: [2024-10-29 13:04:34] iter = 13160, loss = 4.5663
2024-10-29 13:04:34: [2024-10-29 13:04:34] iter = 13170, loss = 5.5297
2024-10-29 13:04:35: [2024-10-29 13:04:35] iter = 13180, loss = 2.6818
2024-10-29 13:04:35: [2024-10-29 13:04:35] iter = 13190, loss = 2.6223
2024-10-29 13:04:36: [2024-10-29 13:04:36] iter = 13200, loss = 2.3271
2024-10-29 13:04:36: [2024-10-29 13:04:36] iter = 13210, loss = 2.3706
2024-10-29 13:04:37: [2024-10-29 13:04:37] iter = 13220, loss = 31.7725
2024-10-29 13:04:37: [2024-10-29 13:04:37] iter = 13230, loss = 4.4046
2024-10-29 13:04:38: [2024-10-29 13:04:38] iter = 13240, loss = 5.4439
2024-10-29 13:04:38: [2024-10-29 13:04:38] iter = 13250, loss = 3.3195
2024-10-29 13:04:39: [2024-10-29 13:04:39] iter = 13260, loss = 7.1825
2024-10-29 13:04:39: [2024-10-29 13:04:39] iter = 13270, loss = 5.1554
2024-10-29 13:04:40: [2024-10-29 13:04:40] iter = 13280, loss = 6.0398
2024-10-29 13:04:40: [2024-10-29 13:04:40] iter = 13290, loss = 4.2238
2024-10-29 13:04:41: [2024-10-29 13:04:41] iter = 13300, loss = 3.2269
2024-10-29 13:04:41: [2024-10-29 13:04:41] iter = 13310, loss = 2.7925
2024-10-29 13:04:42: [2024-10-29 13:04:42] iter = 13320, loss = 35.8367
2024-10-29 13:04:42: [2024-10-29 13:04:42] iter = 13330, loss = 23.0446
2024-10-29 13:04:43: [2024-10-29 13:04:43] iter = 13340, loss = 8.7836
2024-10-29 13:04:43: [2024-10-29 13:04:43] iter = 13350, loss = 7.4564
2024-10-29 13:04:44: [2024-10-29 13:04:44] iter = 13360, loss = 29.1218
2024-10-29 13:04:44: [2024-10-29 13:04:44] iter = 13370, loss = 4.7429
2024-10-29 13:04:45: [2024-10-29 13:04:45] iter = 13380, loss = 10.9533
2024-10-29 13:04:45: [2024-10-29 13:04:45] iter = 13390, loss = 5.8744
2024-10-29 13:04:46: [2024-10-29 13:04:46] iter = 13400, loss = 5.2447
2024-10-29 13:04:46: [2024-10-29 13:04:46] iter = 13410, loss = 39.1904
2024-10-29 13:04:47: [2024-10-29 13:04:47] iter = 13420, loss = 15.5802
2024-10-29 13:04:48: [2024-10-29 13:04:48] iter = 13430, loss = 10.1481
2024-10-29 13:04:48: [2024-10-29 13:04:48] iter = 13440, loss = 2.6787
2024-10-29 13:04:49: [2024-10-29 13:04:49] iter = 13450, loss = 2.2987
2024-10-29 13:04:49: [2024-10-29 13:04:49] iter = 13460, loss = 9.7756
2024-10-29 13:04:50: [2024-10-29 13:04:50] iter = 13470, loss = 8.1976
2024-10-29 13:04:51: [2024-10-29 13:04:51] iter = 13480, loss = 2.6553
2024-10-29 13:04:51: [2024-10-29 13:04:51] iter = 13490, loss = 4.8056
2024-10-29 13:04:52: [2024-10-29 13:04:52] iter = 13500, loss = 4.9460
2024-10-29 13:04:52: [2024-10-29 13:04:52] iter = 13510, loss = 4.6675
2024-10-29 13:04:53: [2024-10-29 13:04:53] iter = 13520, loss = 42.7792
2024-10-29 13:04:53: [2024-10-29 13:04:53] iter = 13530, loss = 7.9429
2024-10-29 13:04:54: [2024-10-29 13:04:54] iter = 13540, loss = 9.7951
2024-10-29 13:04:54: [2024-10-29 13:04:54] iter = 13550, loss = 50.8120
2024-10-29 13:04:55: [2024-10-29 13:04:55] iter = 13560, loss = 3.9718
2024-10-29 13:04:55: [2024-10-29 13:04:55] iter = 13570, loss = 15.8618
2024-10-29 13:04:56: [2024-10-29 13:04:56] iter = 13580, loss = 6.9768
2024-10-29 13:04:56: [2024-10-29 13:04:56] iter = 13590, loss = 2.5590
2024-10-29 13:04:57: [2024-10-29 13:04:57] iter = 13600, loss = 4.3536
2024-10-29 13:04:57: [2024-10-29 13:04:57] iter = 13610, loss = 7.3007
2024-10-29 13:04:58: [2024-10-29 13:04:58] iter = 13620, loss = 5.6039
2024-10-29 13:04:58: [2024-10-29 13:04:58] iter = 13630, loss = 2.7753
2024-10-29 13:04:59: [2024-10-29 13:04:59] iter = 13640, loss = 6.9454
2024-10-29 13:04:59: [2024-10-29 13:04:59] iter = 13650, loss = 4.3101
2024-10-29 13:05:00: [2024-10-29 13:05:00] iter = 13660, loss = 5.5541
2024-10-29 13:05:01: [2024-10-29 13:05:01] iter = 13670, loss = 27.3053
2024-10-29 13:05:01: [2024-10-29 13:05:01] iter = 13680, loss = 7.3047
2024-10-29 13:05:02: [2024-10-29 13:05:02] iter = 13690, loss = 17.5252
2024-10-29 13:05:03: [2024-10-29 13:05:03] iter = 13700, loss = 3.0426
2024-10-29 13:05:03: [2024-10-29 13:05:03] iter = 13710, loss = 4.0617
2024-10-29 13:05:04: [2024-10-29 13:05:04] iter = 13720, loss = 2.3235
2024-10-29 13:05:04: [2024-10-29 13:05:04] iter = 13730, loss = 52.0327
2024-10-29 13:05:05: [2024-10-29 13:05:05] iter = 13740, loss = 6.4329
2024-10-29 13:05:06: [2024-10-29 13:05:06] iter = 13750, loss = 2.7508
2024-10-29 13:05:06: [2024-10-29 13:05:06] iter = 13760, loss = 3.2102
2024-10-29 13:05:07: [2024-10-29 13:05:07] iter = 13770, loss = 16.5956
2024-10-29 13:05:07: [2024-10-29 13:05:07] iter = 13780, loss = 6.3449
2024-10-29 13:05:08: [2024-10-29 13:05:08] iter = 13790, loss = 10.0918
2024-10-29 13:05:08: [2024-10-29 13:05:08] iter = 13800, loss = 3.8041
2024-10-29 13:05:09: [2024-10-29 13:05:09] iter = 13810, loss = 2.9321
2024-10-29 13:05:10: [2024-10-29 13:05:10] iter = 13820, loss = 6.4811
2024-10-29 13:05:10: [2024-10-29 13:05:10] iter = 13830, loss = 7.5665
2024-10-29 13:05:10: [2024-10-29 13:05:10] iter = 13840, loss = 5.1297
2024-10-29 13:05:11: [2024-10-29 13:05:11] iter = 13850, loss = 3.7881
2024-10-29 13:05:12: [2024-10-29 13:05:12] iter = 13860, loss = 67.4558
2024-10-29 13:05:12: [2024-10-29 13:05:12] iter = 13870, loss = 6.1453
2024-10-29 13:05:13: [2024-10-29 13:05:13] iter = 13880, loss = 4.6155
2024-10-29 13:05:13: [2024-10-29 13:05:13] iter = 13890, loss = 7.2749
2024-10-29 13:05:14: [2024-10-29 13:05:14] iter = 13900, loss = 8.8877
2024-10-29 13:05:14: [2024-10-29 13:05:14] iter = 13910, loss = 3.6846
2024-10-29 13:05:15: [2024-10-29 13:05:15] iter = 13920, loss = 14.2414
2024-10-29 13:05:15: [2024-10-29 13:05:15] iter = 13930, loss = 5.3819
2024-10-29 13:05:16: [2024-10-29 13:05:16] iter = 13940, loss = 2.1033
2024-10-29 13:05:16: [2024-10-29 13:05:16] iter = 13950, loss = 11.6639
2024-10-29 13:05:17: [2024-10-29 13:05:17] iter = 13960, loss = 3.1169
2024-10-29 13:05:18: [2024-10-29 13:05:18] iter = 13970, loss = 4.0836
2024-10-29 13:05:18: [2024-10-29 13:05:18] iter = 13980, loss = 4.8790
2024-10-29 13:05:19: [2024-10-29 13:05:19] iter = 13990, loss = 6.0937
2024-10-29 13:05:19: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 13:05:19: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:05:19: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 19571}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:05:46: Evaluate 5 random ConvNet, ACCmean = 0.5158 ACCstd = 0.0068
-------------------------
2024-10-29 13:05:46: Evaluate 5 random ConvNet, SENmean = 0.5158 SENstd = 0.0068
-------------------------
2024-10-29 13:05:46: Evaluate 5 random ConvNet, SPEmean = 0.8386 SPEstd = 0.0023
-------------------------
2024-10-29 13:05:46: Evaluate 5 random ConvNet, F!mean = 0.5088 F!std = 0.0083
-------------------------
2024-10-29 13:05:46: Evaluate 5 random ConvNet, mean = 0.5158 std = 0.0068
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:05:46: [2024-10-29 13:05:46] iter = 14000, loss = 3.2271
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:05:46: [2024-10-29 13:05:46] iter = 14010, loss = 3.8572
2024-10-29 13:05:47: [2024-10-29 13:05:47] iter = 14020, loss = 3.9870
2024-10-29 13:05:47: [2024-10-29 13:05:47] iter = 14030, loss = 5.7837
2024-10-29 13:05:48: [2024-10-29 13:05:48] iter = 14040, loss = 5.6553
2024-10-29 13:05:48: [2024-10-29 13:05:48] iter = 14050, loss = 2.4063
2024-10-29 13:05:49: [2024-10-29 13:05:49] iter = 14060, loss = 4.3772
2024-10-29 13:05:49: [2024-10-29 13:05:49] iter = 14070, loss = 8.9793
2024-10-29 13:05:50: [2024-10-29 13:05:50] iter = 14080, loss = 9.8938
2024-10-29 13:05:51: [2024-10-29 13:05:51] iter = 14090, loss = 5.0952
2024-10-29 13:05:51: [2024-10-29 13:05:51] iter = 14100, loss = 3.5255
2024-10-29 13:05:52: [2024-10-29 13:05:52] iter = 14110, loss = 10.1277
2024-10-29 13:05:52: [2024-10-29 13:05:52] iter = 14120, loss = 5.2938
2024-10-29 13:05:53: [2024-10-29 13:05:53] iter = 14130, loss = 8.0419
2024-10-29 13:05:53: [2024-10-29 13:05:53] iter = 14140, loss = 5.7097
2024-10-29 13:05:54: [2024-10-29 13:05:54] iter = 14150, loss = 8.9457
2024-10-29 13:05:54: [2024-10-29 13:05:54] iter = 14160, loss = 3.8534
2024-10-29 13:05:55: [2024-10-29 13:05:55] iter = 14170, loss = 10.2249
2024-10-29 13:05:55: [2024-10-29 13:05:55] iter = 14180, loss = 12.4123
2024-10-29 13:05:56: [2024-10-29 13:05:56] iter = 14190, loss = 12.0635
2024-10-29 13:05:56: [2024-10-29 13:05:56] iter = 14200, loss = 9.2699
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 14210, loss = 15.8140
2024-10-29 13:05:57: [2024-10-29 13:05:57] iter = 14220, loss = 4.4417
2024-10-29 13:05:58: [2024-10-29 13:05:58] iter = 14230, loss = 4.0186
2024-10-29 13:05:59: [2024-10-29 13:05:59] iter = 14240, loss = 10.9513
2024-10-29 13:05:59: [2024-10-29 13:05:59] iter = 14250, loss = 3.6198
2024-10-29 13:06:00: [2024-10-29 13:06:00] iter = 14260, loss = 8.7776
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 14270, loss = 7.9966
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 14280, loss = 3.8357
2024-10-29 13:06:01: [2024-10-29 13:06:01] iter = 14290, loss = 3.0213
2024-10-29 13:06:02: [2024-10-29 13:06:02] iter = 14300, loss = 3.6465
2024-10-29 13:06:02: [2024-10-29 13:06:02] iter = 14310, loss = 11.4036
2024-10-29 13:06:03: [2024-10-29 13:06:03] iter = 14320, loss = 9.7490
2024-10-29 13:06:03: [2024-10-29 13:06:03] iter = 14330, loss = 2.7095
2024-10-29 13:06:04: [2024-10-29 13:06:04] iter = 14340, loss = 6.5612
2024-10-29 13:06:04: [2024-10-29 13:06:04] iter = 14350, loss = 9.7724
2024-10-29 13:06:05: [2024-10-29 13:06:05] iter = 14360, loss = 11.1747
2024-10-29 13:06:05: [2024-10-29 13:06:05] iter = 14370, loss = 3.9219
2024-10-29 13:06:06: [2024-10-29 13:06:06] iter = 14380, loss = 2.5786
2024-10-29 13:06:07: [2024-10-29 13:06:07] iter = 14390, loss = 10.3071
2024-10-29 13:06:07: [2024-10-29 13:06:07] iter = 14400, loss = 14.5523
2024-10-29 13:06:08: [2024-10-29 13:06:08] iter = 14410, loss = 4.5603
2024-10-29 13:06:09: [2024-10-29 13:06:09] iter = 14420, loss = 29.9151
2024-10-29 13:06:09: [2024-10-29 13:06:09] iter = 14430, loss = 12.9216
2024-10-29 13:06:10: [2024-10-29 13:06:10] iter = 14440, loss = 3.6617
2024-10-29 13:06:10: [2024-10-29 13:06:10] iter = 14450, loss = 2.5571
2024-10-29 13:06:11: [2024-10-29 13:06:11] iter = 14460, loss = 5.2301
2024-10-29 13:06:11: [2024-10-29 13:06:11] iter = 14470, loss = 4.3752
2024-10-29 13:06:12: [2024-10-29 13:06:12] iter = 14480, loss = 29.4022
2024-10-29 13:06:12: [2024-10-29 13:06:12] iter = 14490, loss = 15.5251
2024-10-29 13:06:13: [2024-10-29 13:06:13] iter = 14500, loss = 4.4724
2024-10-29 13:06:13: [2024-10-29 13:06:13] iter = 14510, loss = 2.3529
2024-10-29 13:06:14: [2024-10-29 13:06:14] iter = 14520, loss = 26.5592
2024-10-29 13:06:14: [2024-10-29 13:06:14] iter = 14530, loss = 3.4695
2024-10-29 13:06:15: [2024-10-29 13:06:15] iter = 14540, loss = 9.4928
2024-10-29 13:06:15: [2024-10-29 13:06:15] iter = 14550, loss = 14.2352
2024-10-29 13:06:16: [2024-10-29 13:06:16] iter = 14560, loss = 11.7408
2024-10-29 13:06:16: [2024-10-29 13:06:16] iter = 14570, loss = 3.2237
2024-10-29 13:06:17: [2024-10-29 13:06:17] iter = 14580, loss = 2.2457
2024-10-29 13:06:17: [2024-10-29 13:06:17] iter = 14590, loss = 8.8242
2024-10-29 13:06:18: [2024-10-29 13:06:18] iter = 14600, loss = 4.1662
2024-10-29 13:06:18: [2024-10-29 13:06:18] iter = 14610, loss = 7.8046
2024-10-29 13:06:19: [2024-10-29 13:06:19] iter = 14620, loss = 8.7051
2024-10-29 13:06:20: [2024-10-29 13:06:20] iter = 14630, loss = 8.5196
2024-10-29 13:06:20: [2024-10-29 13:06:20] iter = 14640, loss = 2.9768
2024-10-29 13:06:21: [2024-10-29 13:06:21] iter = 14650, loss = 2.6838
2024-10-29 13:06:22: [2024-10-29 13:06:22] iter = 14660, loss = 3.4217
2024-10-29 13:06:22: [2024-10-29 13:06:22] iter = 14670, loss = 68.9945
2024-10-29 13:06:23: [2024-10-29 13:06:23] iter = 14680, loss = 5.2849
2024-10-29 13:06:23: [2024-10-29 13:06:23] iter = 14690, loss = 6.8877
2024-10-29 13:06:24: [2024-10-29 13:06:24] iter = 14700, loss = 12.6171
2024-10-29 13:06:24: [2024-10-29 13:06:24] iter = 14710, loss = 6.9728
2024-10-29 13:06:25: [2024-10-29 13:06:25] iter = 14720, loss = 27.8380
2024-10-29 13:06:25: [2024-10-29 13:06:25] iter = 14730, loss = 4.0151
2024-10-29 13:06:26: [2024-10-29 13:06:26] iter = 14740, loss = 7.3116
2024-10-29 13:06:26: [2024-10-29 13:06:26] iter = 14750, loss = 12.4076
2024-10-29 13:06:27: [2024-10-29 13:06:27] iter = 14760, loss = 3.7447
2024-10-29 13:06:27: [2024-10-29 13:06:27] iter = 14770, loss = 4.7148
2024-10-29 13:06:28: [2024-10-29 13:06:28] iter = 14780, loss = 2.7113
2024-10-29 13:06:28: [2024-10-29 13:06:28] iter = 14790, loss = 2.2735
2024-10-29 13:06:29: [2024-10-29 13:06:29] iter = 14800, loss = 3.0271
2024-10-29 13:06:29: [2024-10-29 13:06:29] iter = 14810, loss = 8.2238
2024-10-29 13:06:30: [2024-10-29 13:06:30] iter = 14820, loss = 7.3312
2024-10-29 13:06:30: [2024-10-29 13:06:30] iter = 14830, loss = 3.2590
2024-10-29 13:06:31: [2024-10-29 13:06:31] iter = 14840, loss = 2.6818
2024-10-29 13:06:32: [2024-10-29 13:06:32] iter = 14850, loss = 9.8300
2024-10-29 13:06:32: [2024-10-29 13:06:32] iter = 14860, loss = 3.5165
2024-10-29 13:06:33: [2024-10-29 13:06:33] iter = 14870, loss = 2.7687
2024-10-29 13:06:33: [2024-10-29 13:06:33] iter = 14880, loss = 8.9579
2024-10-29 13:06:34: [2024-10-29 13:06:34] iter = 14890, loss = 3.9404
2024-10-29 13:06:34: [2024-10-29 13:06:34] iter = 14900, loss = 3.5344
2024-10-29 13:06:35: [2024-10-29 13:06:35] iter = 14910, loss = 3.4227
2024-10-29 13:06:36: [2024-10-29 13:06:36] iter = 14920, loss = 6.7184
2024-10-29 13:06:36: [2024-10-29 13:06:36] iter = 14930, loss = 29.2782
2024-10-29 13:06:37: [2024-10-29 13:06:37] iter = 14940, loss = 19.0922
2024-10-29 13:06:37: [2024-10-29 13:06:37] iter = 14950, loss = 12.2165
2024-10-29 13:06:38: [2024-10-29 13:06:38] iter = 14960, loss = 7.5279
2024-10-29 13:06:38: [2024-10-29 13:06:38] iter = 14970, loss = 42.6398
2024-10-29 13:06:39: [2024-10-29 13:06:39] iter = 14980, loss = 20.1070
2024-10-29 13:06:40: [2024-10-29 13:06:40] iter = 14990, loss = 2.8323
2024-10-29 13:06:40: [2024-10-29 13:06:40] iter = 15000, loss = 12.3025
2024-10-29 13:06:41: [2024-10-29 13:06:41] iter = 15010, loss = 3.2043
2024-10-29 13:06:41: [2024-10-29 13:06:41] iter = 15020, loss = 6.2334
2024-10-29 13:06:42: [2024-10-29 13:06:42] iter = 15030, loss = 5.9535
2024-10-29 13:06:42: [2024-10-29 13:06:42] iter = 15040, loss = 9.9420
2024-10-29 13:06:43: [2024-10-29 13:06:43] iter = 15050, loss = 4.3594
2024-10-29 13:06:43: [2024-10-29 13:06:43] iter = 15060, loss = 6.2995
2024-10-29 13:06:44: [2024-10-29 13:06:44] iter = 15070, loss = 3.2739
2024-10-29 13:06:44: [2024-10-29 13:06:44] iter = 15080, loss = 12.1031
2024-10-29 13:06:45: [2024-10-29 13:06:45] iter = 15090, loss = 11.0391
2024-10-29 13:06:45: [2024-10-29 13:06:45] iter = 15100, loss = 6.1703
2024-10-29 13:06:46: [2024-10-29 13:06:46] iter = 15110, loss = 3.8181
2024-10-29 13:06:46: [2024-10-29 13:06:46] iter = 15120, loss = 4.5165
2024-10-29 13:06:47: [2024-10-29 13:06:47] iter = 15130, loss = 7.7025
2024-10-29 13:06:47: [2024-10-29 13:06:47] iter = 15140, loss = 4.0729
2024-10-29 13:06:48: [2024-10-29 13:06:48] iter = 15150, loss = 4.5999
2024-10-29 13:06:48: [2024-10-29 13:06:48] iter = 15160, loss = 9.9503
2024-10-29 13:06:49: [2024-10-29 13:06:49] iter = 15170, loss = 10.3005
2024-10-29 13:06:49: [2024-10-29 13:06:49] iter = 15180, loss = 3.1950
2024-10-29 13:06:50: [2024-10-29 13:06:50] iter = 15190, loss = 5.9284
2024-10-29 13:06:50: [2024-10-29 13:06:50] iter = 15200, loss = 16.4564
2024-10-29 13:06:51: [2024-10-29 13:06:51] iter = 15210, loss = 22.4613
2024-10-29 13:06:51: [2024-10-29 13:06:51] iter = 15220, loss = 13.3500
2024-10-29 13:06:52: [2024-10-29 13:06:52] iter = 15230, loss = 4.3674
2024-10-29 13:06:52: [2024-10-29 13:06:52] iter = 15240, loss = 11.0313
2024-10-29 13:06:53: [2024-10-29 13:06:53] iter = 15250, loss = 7.6536
2024-10-29 13:06:53: [2024-10-29 13:06:53] iter = 15260, loss = 5.5719
2024-10-29 13:06:54: [2024-10-29 13:06:54] iter = 15270, loss = 6.1179
2024-10-29 13:06:55: [2024-10-29 13:06:55] iter = 15280, loss = 4.2577
2024-10-29 13:06:55: [2024-10-29 13:06:55] iter = 15290, loss = 6.8166
2024-10-29 13:06:56: [2024-10-29 13:06:56] iter = 15300, loss = 8.8648
2024-10-29 13:06:56: [2024-10-29 13:06:56] iter = 15310, loss = 16.3377
2024-10-29 13:06:57: [2024-10-29 13:06:57] iter = 15320, loss = 11.2535
2024-10-29 13:06:57: [2024-10-29 13:06:57] iter = 15330, loss = 11.1133
2024-10-29 13:06:58: [2024-10-29 13:06:58] iter = 15340, loss = 2.8144
2024-10-29 13:06:58: [2024-10-29 13:06:58] iter = 15350, loss = 10.4530
2024-10-29 13:06:59: [2024-10-29 13:06:59] iter = 15360, loss = 5.3781
2024-10-29 13:06:59: [2024-10-29 13:06:59] iter = 15370, loss = 38.3232
2024-10-29 13:07:00: [2024-10-29 13:07:00] iter = 15380, loss = 10.8622
2024-10-29 13:07:01: [2024-10-29 13:07:01] iter = 15390, loss = 32.4807
2024-10-29 13:07:01: [2024-10-29 13:07:01] iter = 15400, loss = 7.5470
2024-10-29 13:07:02: [2024-10-29 13:07:02] iter = 15410, loss = 14.0375
2024-10-29 13:07:02: [2024-10-29 13:07:02] iter = 15420, loss = 22.1281
2024-10-29 13:07:03: [2024-10-29 13:07:03] iter = 15430, loss = 8.0764
2024-10-29 13:07:04: [2024-10-29 13:07:04] iter = 15440, loss = 5.1456
2024-10-29 13:07:04: [2024-10-29 13:07:04] iter = 15450, loss = 3.2642
2024-10-29 13:07:05: [2024-10-29 13:07:05] iter = 15460, loss = 4.8262
2024-10-29 13:07:05: [2024-10-29 13:07:05] iter = 15470, loss = 4.4953
2024-10-29 13:07:06: [2024-10-29 13:07:06] iter = 15480, loss = 7.3869
2024-10-29 13:07:06: [2024-10-29 13:07:06] iter = 15490, loss = 14.3469
2024-10-29 13:07:07: [2024-10-29 13:07:07] iter = 15500, loss = 28.5677
2024-10-29 13:07:08: [2024-10-29 13:07:08] iter = 15510, loss = 20.0172
2024-10-29 13:07:08: [2024-10-29 13:07:08] iter = 15520, loss = 6.9624
2024-10-29 13:07:09: [2024-10-29 13:07:09] iter = 15530, loss = 4.1950
2024-10-29 13:07:10: [2024-10-29 13:07:10] iter = 15540, loss = 10.3660
2024-10-29 13:07:10: [2024-10-29 13:07:10] iter = 15550, loss = 8.4540
2024-10-29 13:07:11: [2024-10-29 13:07:11] iter = 15560, loss = 14.0725
2024-10-29 13:07:12: [2024-10-29 13:07:12] iter = 15570, loss = 9.2848
2024-10-29 13:07:12: [2024-10-29 13:07:12] iter = 15580, loss = 5.0263
2024-10-29 13:07:13: [2024-10-29 13:07:13] iter = 15590, loss = 8.7484
2024-10-29 13:07:13: [2024-10-29 13:07:13] iter = 15600, loss = 7.4435
2024-10-29 13:07:14: [2024-10-29 13:07:14] iter = 15610, loss = 3.7683
2024-10-29 13:07:14: [2024-10-29 13:07:14] iter = 15620, loss = 2.5640
2024-10-29 13:07:15: [2024-10-29 13:07:15] iter = 15630, loss = 2.8167
2024-10-29 13:07:15: [2024-10-29 13:07:15] iter = 15640, loss = 7.9905
2024-10-29 13:07:16: [2024-10-29 13:07:16] iter = 15650, loss = 3.7209
2024-10-29 13:07:17: [2024-10-29 13:07:17] iter = 15660, loss = 17.4021
2024-10-29 13:07:17: [2024-10-29 13:07:17] iter = 15670, loss = 24.9938
2024-10-29 13:07:18: [2024-10-29 13:07:18] iter = 15680, loss = 7.1951
2024-10-29 13:07:18: [2024-10-29 13:07:18] iter = 15690, loss = 4.9686
2024-10-29 13:07:19: [2024-10-29 13:07:19] iter = 15700, loss = 13.5658
2024-10-29 13:07:20: [2024-10-29 13:07:19] iter = 15710, loss = 4.6326
2024-10-29 13:07:20: [2024-10-29 13:07:20] iter = 15720, loss = 8.1278
2024-10-29 13:07:21: [2024-10-29 13:07:21] iter = 15730, loss = 35.0321
2024-10-29 13:07:21: [2024-10-29 13:07:21] iter = 15740, loss = 10.3898
2024-10-29 13:07:22: [2024-10-29 13:07:22] iter = 15750, loss = 20.8848
2024-10-29 13:07:22: [2024-10-29 13:07:22] iter = 15760, loss = 21.1024
2024-10-29 13:07:23: [2024-10-29 13:07:23] iter = 15770, loss = 3.4601
2024-10-29 13:07:23: [2024-10-29 13:07:23] iter = 15780, loss = 8.0238
2024-10-29 13:07:24: [2024-10-29 13:07:24] iter = 15790, loss = 5.5166
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 15800, loss = 3.5242
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 15810, loss = 14.8650
2024-10-29 13:07:25: [2024-10-29 13:07:25] iter = 15820, loss = 12.9911
2024-10-29 13:07:26: [2024-10-29 13:07:26] iter = 15830, loss = 54.6526
2024-10-29 13:07:27: [2024-10-29 13:07:27] iter = 15840, loss = 5.3864
2024-10-29 13:07:27: [2024-10-29 13:07:27] iter = 15850, loss = 5.4549
2024-10-29 13:07:28: [2024-10-29 13:07:28] iter = 15860, loss = 22.9951
2024-10-29 13:07:28: [2024-10-29 13:07:28] iter = 15870, loss = 2.3915
2024-10-29 13:07:29: [2024-10-29 13:07:29] iter = 15880, loss = 3.3749
2024-10-29 13:07:29: [2024-10-29 13:07:29] iter = 15890, loss = 3.7707
2024-10-29 13:07:30: [2024-10-29 13:07:30] iter = 15900, loss = 4.2879
2024-10-29 13:07:30: [2024-10-29 13:07:30] iter = 15910, loss = 4.5259
2024-10-29 13:07:31: [2024-10-29 13:07:31] iter = 15920, loss = 4.2408
2024-10-29 13:07:31: [2024-10-29 13:07:31] iter = 15930, loss = 6.4842
2024-10-29 13:07:32: [2024-10-29 13:07:32] iter = 15940, loss = 8.7034
2024-10-29 13:07:32: [2024-10-29 13:07:32] iter = 15950, loss = 12.1071
2024-10-29 13:07:33: [2024-10-29 13:07:33] iter = 15960, loss = 5.4423
2024-10-29 13:07:33: [2024-10-29 13:07:33] iter = 15970, loss = 5.3571
2024-10-29 13:07:34: [2024-10-29 13:07:34] iter = 15980, loss = 15.3676
2024-10-29 13:07:34: [2024-10-29 13:07:34] iter = 15990, loss = 2.6910
2024-10-29 13:07:35: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 13:07:35: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:07:35: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 55355}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:08:01: Evaluate 5 random ConvNet, ACCmean = 0.3764 ACCstd = 0.0152
-------------------------
2024-10-29 13:08:01: Evaluate 5 random ConvNet, SENmean = 0.3764 SENstd = 0.0152
-------------------------
2024-10-29 13:08:01: Evaluate 5 random ConvNet, SPEmean = 0.7921 SPEstd = 0.0051
-------------------------
2024-10-29 13:08:01: Evaluate 5 random ConvNet, F!mean = 0.3313 F!std = 0.0152
-------------------------
2024-10-29 13:08:01: Evaluate 5 random ConvNet, mean = 0.3764 std = 0.0152
-------------------------
2024-10-29 13:08:01: [2024-10-29 13:08:01] iter = 16000, loss = 36.4485
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 16010, loss = 3.5488
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 16020, loss = 20.8342
2024-10-29 13:08:02: [2024-10-29 13:08:02] iter = 16030, loss = 4.0806
2024-10-29 13:08:03: [2024-10-29 13:08:03] iter = 16040, loss = 14.4022
2024-10-29 13:08:04: [2024-10-29 13:08:04] iter = 16050, loss = 6.4061
2024-10-29 13:08:04: [2024-10-29 13:08:04] iter = 16060, loss = 11.7163
2024-10-29 13:08:05: [2024-10-29 13:08:05] iter = 16070, loss = 7.2241
2024-10-29 13:08:05: [2024-10-29 13:08:05] iter = 16080, loss = 14.3262
2024-10-29 13:08:06: [2024-10-29 13:08:06] iter = 16090, loss = 4.8830
2024-10-29 13:08:06: [2024-10-29 13:08:06] iter = 16100, loss = 12.9258
2024-10-29 13:08:07: [2024-10-29 13:08:07] iter = 16110, loss = 4.3849
2024-10-29 13:08:08: [2024-10-29 13:08:08] iter = 16120, loss = 3.0666
2024-10-29 13:08:08: [2024-10-29 13:08:08] iter = 16130, loss = 5.5496
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 16140, loss = 32.1822
2024-10-29 13:08:09: [2024-10-29 13:08:09] iter = 16150, loss = 15.5000
2024-10-29 13:08:10: [2024-10-29 13:08:10] iter = 16160, loss = 4.8132
2024-10-29 13:08:10: [2024-10-29 13:08:10] iter = 16170, loss = 16.0986
2024-10-29 13:08:11: [2024-10-29 13:08:11] iter = 16180, loss = 6.9310
2024-10-29 13:08:11: [2024-10-29 13:08:11] iter = 16190, loss = 4.9326
2024-10-29 13:08:12: [2024-10-29 13:08:12] iter = 16200, loss = 48.2085
2024-10-29 13:08:12: [2024-10-29 13:08:12] iter = 16210, loss = 3.6711
2024-10-29 13:08:13: [2024-10-29 13:08:13] iter = 16220, loss = 5.0221
2024-10-29 13:08:13: [2024-10-29 13:08:13] iter = 16230, loss = 3.8088
2024-10-29 13:08:14: [2024-10-29 13:08:14] iter = 16240, loss = 7.2090
2024-10-29 13:08:14: [2024-10-29 13:08:14] iter = 16250, loss = 5.0143
2024-10-29 13:08:15: [2024-10-29 13:08:15] iter = 16260, loss = 11.1473
2024-10-29 13:08:15: [2024-10-29 13:08:15] iter = 16270, loss = 20.8704
2024-10-29 13:08:16: [2024-10-29 13:08:16] iter = 16280, loss = 7.0938
2024-10-29 13:08:16: [2024-10-29 13:08:16] iter = 16290, loss = 3.7540
2024-10-29 13:08:17: [2024-10-29 13:08:17] iter = 16300, loss = 2.9501
2024-10-29 13:08:17: [2024-10-29 13:08:17] iter = 16310, loss = 2.6496
2024-10-29 13:08:18: [2024-10-29 13:08:18] iter = 16320, loss = 11.8942
2024-10-29 13:08:18: [2024-10-29 13:08:18] iter = 16330, loss = 3.7856
2024-10-29 13:08:19: [2024-10-29 13:08:19] iter = 16340, loss = 3.0076
2024-10-29 13:08:19: [2024-10-29 13:08:19] iter = 16350, loss = 4.5970
2024-10-29 13:08:20: [2024-10-29 13:08:20] iter = 16360, loss = 13.8719
2024-10-29 13:08:20: [2024-10-29 13:08:20] iter = 16370, loss = 3.2335
2024-10-29 13:08:21: [2024-10-29 13:08:21] iter = 16380, loss = 6.7437
2024-10-29 13:08:21: [2024-10-29 13:08:21] iter = 16390, loss = 6.9688
2024-10-29 13:08:22: [2024-10-29 13:08:22] iter = 16400, loss = 3.1282
2024-10-29 13:08:22: [2024-10-29 13:08:22] iter = 16410, loss = 4.6758
2024-10-29 13:08:23: [2024-10-29 13:08:23] iter = 16420, loss = 4.2247
2024-10-29 13:08:23: [2024-10-29 13:08:23] iter = 16430, loss = 11.7009
2024-10-29 13:08:24: [2024-10-29 13:08:24] iter = 16440, loss = 6.7404
2024-10-29 13:08:24: [2024-10-29 13:08:24] iter = 16450, loss = 15.0432
2024-10-29 13:08:25: [2024-10-29 13:08:25] iter = 16460, loss = 3.4974
2024-10-29 13:08:25: [2024-10-29 13:08:25] iter = 16470, loss = 5.1384
2024-10-29 13:08:26: [2024-10-29 13:08:26] iter = 16480, loss = 2.4762
2024-10-29 13:08:26: [2024-10-29 13:08:26] iter = 16490, loss = 8.7754
2024-10-29 13:08:27: [2024-10-29 13:08:27] iter = 16500, loss = 2.4958
2024-10-29 13:08:27: [2024-10-29 13:08:27] iter = 16510, loss = 25.8661
2024-10-29 13:08:28: [2024-10-29 13:08:28] iter = 16520, loss = 4.3959
2024-10-29 13:08:28: [2024-10-29 13:08:28] iter = 16530, loss = 9.1391
2024-10-29 13:08:29: [2024-10-29 13:08:29] iter = 16540, loss = 3.3185
2024-10-29 13:08:29: [2024-10-29 13:08:29] iter = 16550, loss = 4.6869
2024-10-29 13:08:30: [2024-10-29 13:08:30] iter = 16560, loss = 3.4977
2024-10-29 13:08:30: [2024-10-29 13:08:30] iter = 16570, loss = 22.4238
2024-10-29 13:08:31: [2024-10-29 13:08:31] iter = 16580, loss = 4.7453
2024-10-29 13:08:31: [2024-10-29 13:08:31] iter = 16590, loss = 33.7370
2024-10-29 13:08:32: [2024-10-29 13:08:32] iter = 16600, loss = 7.0658
2024-10-29 13:08:32: [2024-10-29 13:08:32] iter = 16610, loss = 3.2779
2024-10-29 13:08:33: [2024-10-29 13:08:33] iter = 16620, loss = 3.0672
2024-10-29 13:08:33: [2024-10-29 13:08:33] iter = 16630, loss = 6.5229
2024-10-29 13:08:34: [2024-10-29 13:08:34] iter = 16640, loss = 5.8569
2024-10-29 13:08:35: [2024-10-29 13:08:35] iter = 16650, loss = 40.7567
2024-10-29 13:08:35: [2024-10-29 13:08:35] iter = 16660, loss = 34.2403
2024-10-29 13:08:36: [2024-10-29 13:08:36] iter = 16670, loss = 7.7939
2024-10-29 13:08:36: [2024-10-29 13:08:36] iter = 16680, loss = 11.2888
2024-10-29 13:08:37: [2024-10-29 13:08:37] iter = 16690, loss = 9.5021
2024-10-29 13:08:37: [2024-10-29 13:08:37] iter = 16700, loss = 23.5586
2024-10-29 13:08:38: [2024-10-29 13:08:38] iter = 16710, loss = 6.9102
2024-10-29 13:08:39: [2024-10-29 13:08:39] iter = 16720, loss = 4.7990
2024-10-29 13:08:39: [2024-10-29 13:08:39] iter = 16730, loss = 6.5555
2024-10-29 13:08:40: [2024-10-29 13:08:40] iter = 16740, loss = 2.4881
2024-10-29 13:08:40: [2024-10-29 13:08:40] iter = 16750, loss = 4.3899
2024-10-29 13:08:41: [2024-10-29 13:08:41] iter = 16760, loss = 4.6035
2024-10-29 13:08:41: [2024-10-29 13:08:41] iter = 16770, loss = 17.3514
2024-10-29 13:08:42: [2024-10-29 13:08:42] iter = 16780, loss = 4.3497
2024-10-29 13:08:42: [2024-10-29 13:08:42] iter = 16790, loss = 3.8549
2024-10-29 13:08:43: [2024-10-29 13:08:43] iter = 16800, loss = 8.5240
2024-10-29 13:08:43: [2024-10-29 13:08:43] iter = 16810, loss = 4.5928
2024-10-29 13:08:44: [2024-10-29 13:08:44] iter = 16820, loss = 7.7844
2024-10-29 13:08:44: [2024-10-29 13:08:44] iter = 16830, loss = 2.3541
2024-10-29 13:08:45: [2024-10-29 13:08:45] iter = 16840, loss = 3.2125
2024-10-29 13:08:45: [2024-10-29 13:08:45] iter = 16850, loss = 6.0565
2024-10-29 13:08:46: [2024-10-29 13:08:46] iter = 16860, loss = 3.2587
2024-10-29 13:08:46: [2024-10-29 13:08:46] iter = 16870, loss = 42.4428
2024-10-29 13:08:47: [2024-10-29 13:08:47] iter = 16880, loss = 20.6242
2024-10-29 13:08:47: [2024-10-29 13:08:47] iter = 16890, loss = 7.7312
2024-10-29 13:08:48: [2024-10-29 13:08:48] iter = 16900, loss = 4.4535
2024-10-29 13:08:48: [2024-10-29 13:08:48] iter = 16910, loss = 49.4311
2024-10-29 13:08:49: [2024-10-29 13:08:49] iter = 16920, loss = 7.2953
2024-10-29 13:08:49: [2024-10-29 13:08:49] iter = 16930, loss = 6.4756
2024-10-29 13:08:50: [2024-10-29 13:08:50] iter = 16940, loss = 3.9772
2024-10-29 13:08:50: [2024-10-29 13:08:50] iter = 16950, loss = 3.4785
2024-10-29 13:08:51: [2024-10-29 13:08:51] iter = 16960, loss = 20.2042
2024-10-29 13:08:52: [2024-10-29 13:08:52] iter = 16970, loss = 9.5164
2024-10-29 13:08:53: [2024-10-29 13:08:53] iter = 16980, loss = 2.5947
2024-10-29 13:08:53: [2024-10-29 13:08:53] iter = 16990, loss = 6.4691
2024-10-29 13:08:54: [2024-10-29 13:08:54] iter = 17000, loss = 20.9346
2024-10-29 13:08:54: [2024-10-29 13:08:54] iter = 17010, loss = 8.1610
2024-10-29 13:08:55: [2024-10-29 13:08:55] iter = 17020, loss = 3.3971
2024-10-29 13:08:55: [2024-10-29 13:08:55] iter = 17030, loss = 5.3112
2024-10-29 13:08:56: [2024-10-29 13:08:56] iter = 17040, loss = 8.1985
2024-10-29 13:08:56: [2024-10-29 13:08:56] iter = 17050, loss = 4.8013
2024-10-29 13:08:57: [2024-10-29 13:08:57] iter = 17060, loss = 43.0320
2024-10-29 13:08:57: [2024-10-29 13:08:57] iter = 17070, loss = 8.6927
2024-10-29 13:08:58: [2024-10-29 13:08:58] iter = 17080, loss = 2.6725
2024-10-29 13:08:58: [2024-10-29 13:08:58] iter = 17090, loss = 30.8093
2024-10-29 13:08:59: [2024-10-29 13:08:59] iter = 17100, loss = 4.7353
2024-10-29 13:08:59: [2024-10-29 13:08:59] iter = 17110, loss = 5.6294
2024-10-29 13:09:00: [2024-10-29 13:09:00] iter = 17120, loss = 11.9007
2024-10-29 13:09:00: [2024-10-29 13:09:00] iter = 17130, loss = 7.8693
2024-10-29 13:09:01: [2024-10-29 13:09:01] iter = 17140, loss = 2.4482
2024-10-29 13:09:01: [2024-10-29 13:09:01] iter = 17150, loss = 17.2154
2024-10-29 13:09:02: [2024-10-29 13:09:02] iter = 17160, loss = 23.6982
2024-10-29 13:09:02: [2024-10-29 13:09:02] iter = 17170, loss = 6.0434
2024-10-29 13:09:03: [2024-10-29 13:09:03] iter = 17180, loss = 6.5434
2024-10-29 13:09:03: [2024-10-29 13:09:03] iter = 17190, loss = 3.3653
2024-10-29 13:09:04: [2024-10-29 13:09:04] iter = 17200, loss = 2.6546
2024-10-29 13:09:04: [2024-10-29 13:09:04] iter = 17210, loss = 3.8468
2024-10-29 13:09:05: [2024-10-29 13:09:05] iter = 17220, loss = 5.4506
2024-10-29 13:09:05: [2024-10-29 13:09:05] iter = 17230, loss = 2.9429
2024-10-29 13:09:06: [2024-10-29 13:09:06] iter = 17240, loss = 44.2808
2024-10-29 13:09:07: [2024-10-29 13:09:07] iter = 17250, loss = 9.4713
2024-10-29 13:09:07: [2024-10-29 13:09:07] iter = 17260, loss = 13.2014
2024-10-29 13:09:08: [2024-10-29 13:09:08] iter = 17270, loss = 2.8898
2024-10-29 13:09:08: [2024-10-29 13:09:08] iter = 17280, loss = 3.2726
2024-10-29 13:09:09: [2024-10-29 13:09:09] iter = 17290, loss = 9.3261
2024-10-29 13:09:09: [2024-10-29 13:09:09] iter = 17300, loss = 56.5003
2024-10-29 13:09:10: [2024-10-29 13:09:10] iter = 17310, loss = 7.3910
2024-10-29 13:09:11: [2024-10-29 13:09:11] iter = 17320, loss = 3.7489
2024-10-29 13:09:11: [2024-10-29 13:09:11] iter = 17330, loss = 37.8045
2024-10-29 13:09:12: [2024-10-29 13:09:12] iter = 17340, loss = 27.3092
2024-10-29 13:09:12: [2024-10-29 13:09:12] iter = 17350, loss = 3.5337
2024-10-29 13:09:13: [2024-10-29 13:09:13] iter = 17360, loss = 3.3816
2024-10-29 13:09:13: [2024-10-29 13:09:13] iter = 17370, loss = 3.3316
2024-10-29 13:09:14: [2024-10-29 13:09:14] iter = 17380, loss = 6.7933
2024-10-29 13:09:14: [2024-10-29 13:09:14] iter = 17390, loss = 3.0342
2024-10-29 13:09:15: [2024-10-29 13:09:15] iter = 17400, loss = 14.6350
2024-10-29 13:09:15: [2024-10-29 13:09:15] iter = 17410, loss = 25.7337
2024-10-29 13:09:16: [2024-10-29 13:09:16] iter = 17420, loss = 5.7567
2024-10-29 13:09:17: [2024-10-29 13:09:17] iter = 17430, loss = 10.3221
2024-10-29 13:09:17: [2024-10-29 13:09:17] iter = 17440, loss = 4.0571
2024-10-29 13:09:18: [2024-10-29 13:09:18] iter = 17450, loss = 7.1971
2024-10-29 13:09:18: [2024-10-29 13:09:18] iter = 17460, loss = 5.0287
2024-10-29 13:09:19: [2024-10-29 13:09:19] iter = 17470, loss = 20.3171
2024-10-29 13:09:19: [2024-10-29 13:09:19] iter = 17480, loss = 4.2974
2024-10-29 13:09:20: [2024-10-29 13:09:20] iter = 17490, loss = 4.1220
2024-10-29 13:09:20: [2024-10-29 13:09:20] iter = 17500, loss = 13.8272
2024-10-29 13:09:21: [2024-10-29 13:09:21] iter = 17510, loss = 3.2427
2024-10-29 13:09:21: [2024-10-29 13:09:21] iter = 17520, loss = 14.8181
2024-10-29 13:09:22: [2024-10-29 13:09:22] iter = 17530, loss = 2.9213
2024-10-29 13:09:22: [2024-10-29 13:09:22] iter = 17540, loss = 4.5649
2024-10-29 13:09:23: [2024-10-29 13:09:23] iter = 17550, loss = 6.9310
2024-10-29 13:09:24: [2024-10-29 13:09:24] iter = 17560, loss = 49.0845
2024-10-29 13:09:24: [2024-10-29 13:09:24] iter = 17570, loss = 9.1979
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 17580, loss = 5.6422
2024-10-29 13:09:25: [2024-10-29 13:09:25] iter = 17590, loss = 7.0987
2024-10-29 13:09:26: [2024-10-29 13:09:26] iter = 17600, loss = 4.4047
2024-10-29 13:09:26: [2024-10-29 13:09:26] iter = 17610, loss = 3.0005
2024-10-29 13:09:27: [2024-10-29 13:09:27] iter = 17620, loss = 2.7219
2024-10-29 13:09:27: [2024-10-29 13:09:27] iter = 17630, loss = 2.1837
2024-10-29 13:09:28: [2024-10-29 13:09:28] iter = 17640, loss = 42.5843
2024-10-29 13:09:28: [2024-10-29 13:09:28] iter = 17650, loss = 4.1162
2024-10-29 13:09:29: [2024-10-29 13:09:29] iter = 17660, loss = 26.7539
2024-10-29 13:09:29: [2024-10-29 13:09:29] iter = 17670, loss = 4.0053
2024-10-29 13:09:30: [2024-10-29 13:09:30] iter = 17680, loss = 26.3649
2024-10-29 13:09:30: [2024-10-29 13:09:30] iter = 17690, loss = 15.7207
2024-10-29 13:09:31: [2024-10-29 13:09:31] iter = 17700, loss = 5.7327
2024-10-29 13:09:31: [2024-10-29 13:09:31] iter = 17710, loss = 7.3094
2024-10-29 13:09:32: [2024-10-29 13:09:32] iter = 17720, loss = 3.7379
2024-10-29 13:09:32: [2024-10-29 13:09:32] iter = 17730, loss = 24.0704
2024-10-29 13:09:33: [2024-10-29 13:09:33] iter = 17740, loss = 3.8688
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 17750, loss = 27.1534
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 17760, loss = 6.2559
2024-10-29 13:09:34: [2024-10-29 13:09:34] iter = 17770, loss = 6.8774
2024-10-29 13:09:35: [2024-10-29 13:09:35] iter = 17780, loss = 6.9162
2024-10-29 13:09:35: [2024-10-29 13:09:35] iter = 17790, loss = 5.6408
2024-10-29 13:09:36: [2024-10-29 13:09:36] iter = 17800, loss = 3.2253
2024-10-29 13:09:36: [2024-10-29 13:09:36] iter = 17810, loss = 3.3532
2024-10-29 13:09:37: [2024-10-29 13:09:37] iter = 17820, loss = 3.4078
2024-10-29 13:09:37: [2024-10-29 13:09:37] iter = 17830, loss = 10.1987
2024-10-29 13:09:38: [2024-10-29 13:09:38] iter = 17840, loss = 9.1682
2024-10-29 13:09:38: [2024-10-29 13:09:38] iter = 17850, loss = 10.4253
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 17860, loss = 3.9801
2024-10-29 13:09:39: [2024-10-29 13:09:39] iter = 17870, loss = 12.6501
2024-10-29 13:09:40: [2024-10-29 13:09:40] iter = 17880, loss = 16.0505
2024-10-29 13:09:40: [2024-10-29 13:09:40] iter = 17890, loss = 26.0382
2024-10-29 13:09:41: [2024-10-29 13:09:41] iter = 17900, loss = 29.9269
2024-10-29 13:09:41: [2024-10-29 13:09:41] iter = 17910, loss = 2.9667
2024-10-29 13:09:42: [2024-10-29 13:09:42] iter = 17920, loss = 3.5570
2024-10-29 13:09:42: [2024-10-29 13:09:42] iter = 17930, loss = 49.1942
2024-10-29 13:09:43: [2024-10-29 13:09:43] iter = 17940, loss = 2.8050
2024-10-29 13:09:43: [2024-10-29 13:09:43] iter = 17950, loss = 4.2123
2024-10-29 13:09:44: [2024-10-29 13:09:44] iter = 17960, loss = 2.8368
2024-10-29 13:09:44: [2024-10-29 13:09:44] iter = 17970, loss = 3.3157
2024-10-29 13:09:45: [2024-10-29 13:09:45] iter = 17980, loss = 2.4062
2024-10-29 13:09:45: [2024-10-29 13:09:45] iter = 17990, loss = 11.8260
2024-10-29 13:09:46: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 13:09:46: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:09:46: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 86249}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:10:14: Evaluate 5 random ConvNet, ACCmean = 0.3774 ACCstd = 0.0042
-------------------------
2024-10-29 13:10:14: Evaluate 5 random ConvNet, SENmean = 0.3774 SENstd = 0.0042
-------------------------
2024-10-29 13:10:14: Evaluate 5 random ConvNet, SPEmean = 0.7925 SPEstd = 0.0014
-------------------------
2024-10-29 13:10:14: Evaluate 5 random ConvNet, F!mean = 0.3173 F!std = 0.0080
-------------------------
2024-10-29 13:10:14: Evaluate 5 random ConvNet, mean = 0.3774 std = 0.0042
-------------------------
2024-10-29 13:10:14: [2024-10-29 13:10:14] iter = 18000, loss = 47.2273
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:10:14: [2024-10-29 13:10:14] iter = 18010, loss = 3.4392
2024-10-29 13:10:15: [2024-10-29 13:10:15] iter = 18020, loss = 4.1534
2024-10-29 13:10:15: [2024-10-29 13:10:15] iter = 18030, loss = 4.2013
2024-10-29 13:10:16: [2024-10-29 13:10:16] iter = 18040, loss = 24.7637
2024-10-29 13:10:17: [2024-10-29 13:10:17] iter = 18050, loss = 4.2310
2024-10-29 13:10:17: [2024-10-29 13:10:17] iter = 18060, loss = 10.4662
2024-10-29 13:10:18: [2024-10-29 13:10:18] iter = 18070, loss = 36.9035
2024-10-29 13:10:18: [2024-10-29 13:10:18] iter = 18080, loss = 10.9379
2024-10-29 13:10:19: [2024-10-29 13:10:19] iter = 18090, loss = 10.1117
2024-10-29 13:10:19: [2024-10-29 13:10:19] iter = 18100, loss = 6.5357
2024-10-29 13:10:20: [2024-10-29 13:10:20] iter = 18110, loss = 6.5853
2024-10-29 13:10:20: [2024-10-29 13:10:20] iter = 18120, loss = 2.5621
2024-10-29 13:10:21: [2024-10-29 13:10:21] iter = 18130, loss = 5.7628
2024-10-29 13:10:21: [2024-10-29 13:10:21] iter = 18140, loss = 3.1998
2024-10-29 13:10:22: [2024-10-29 13:10:22] iter = 18150, loss = 2.8128
2024-10-29 13:10:23: [2024-10-29 13:10:23] iter = 18160, loss = 11.7515
2024-10-29 13:10:23: [2024-10-29 13:10:23] iter = 18170, loss = 4.9882
2024-10-29 13:10:24: [2024-10-29 13:10:24] iter = 18180, loss = 3.4557
2024-10-29 13:10:24: [2024-10-29 13:10:24] iter = 18190, loss = 2.8005
2024-10-29 13:10:25: [2024-10-29 13:10:25] iter = 18200, loss = 18.5710
2024-10-29 13:10:25: [2024-10-29 13:10:25] iter = 18210, loss = 18.5487
2024-10-29 13:10:26: [2024-10-29 13:10:26] iter = 18220, loss = 4.0753
2024-10-29 13:10:26: [2024-10-29 13:10:26] iter = 18230, loss = 3.8598
2024-10-29 13:10:27: [2024-10-29 13:10:27] iter = 18240, loss = 4.4039
2024-10-29 13:10:27: [2024-10-29 13:10:27] iter = 18250, loss = 32.5996
2024-10-29 13:10:28: [2024-10-29 13:10:28] iter = 18260, loss = 5.9221
2024-10-29 13:10:28: [2024-10-29 13:10:28] iter = 18270, loss = 6.8508
2024-10-29 13:10:29: [2024-10-29 13:10:29] iter = 18280, loss = 9.5255
2024-10-29 13:10:29: [2024-10-29 13:10:29] iter = 18290, loss = 8.2792
2024-10-29 13:10:30: [2024-10-29 13:10:30] iter = 18300, loss = 7.6554
2024-10-29 13:10:30: [2024-10-29 13:10:30] iter = 18310, loss = 3.5234
2024-10-29 13:10:31: [2024-10-29 13:10:31] iter = 18320, loss = 14.2714
2024-10-29 13:10:31: [2024-10-29 13:10:31] iter = 18330, loss = 3.8431
2024-10-29 13:10:32: [2024-10-29 13:10:32] iter = 18340, loss = 11.9241
2024-10-29 13:10:32: [2024-10-29 13:10:32] iter = 18350, loss = 8.8107
2024-10-29 13:10:33: [2024-10-29 13:10:33] iter = 18360, loss = 77.5026
2024-10-29 13:10:33: [2024-10-29 13:10:33] iter = 18370, loss = 4.1139
2024-10-29 13:10:34: [2024-10-29 13:10:34] iter = 18380, loss = 6.7302
2024-10-29 13:10:34: [2024-10-29 13:10:34] iter = 18390, loss = 7.8419
2024-10-29 13:10:35: [2024-10-29 13:10:35] iter = 18400, loss = 4.3290
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 18410, loss = 3.3783
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 18420, loss = 3.3968
2024-10-29 13:10:36: [2024-10-29 13:10:36] iter = 18430, loss = 6.2849
2024-10-29 13:10:37: [2024-10-29 13:10:37] iter = 18440, loss = 3.9669
2024-10-29 13:10:38: [2024-10-29 13:10:38] iter = 18450, loss = 3.4760
2024-10-29 13:10:38: [2024-10-29 13:10:38] iter = 18460, loss = 2.1825
2024-10-29 13:10:39: [2024-10-29 13:10:39] iter = 18470, loss = 1.7881
2024-10-29 13:10:39: [2024-10-29 13:10:39] iter = 18480, loss = 2.5802
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 18490, loss = 9.2991
2024-10-29 13:10:40: [2024-10-29 13:10:40] iter = 18500, loss = 9.7616
2024-10-29 13:10:41: [2024-10-29 13:10:41] iter = 18510, loss = 12.9109
2024-10-29 13:10:41: [2024-10-29 13:10:41] iter = 18520, loss = 13.9237
2024-10-29 13:10:42: [2024-10-29 13:10:42] iter = 18530, loss = 6.7506
2024-10-29 13:10:42: [2024-10-29 13:10:42] iter = 18540, loss = 4.1697
2024-10-29 13:10:43: [2024-10-29 13:10:43] iter = 18550, loss = 46.9469
2024-10-29 13:10:43: [2024-10-29 13:10:43] iter = 18560, loss = 6.9658
2024-10-29 13:10:44: [2024-10-29 13:10:44] iter = 18570, loss = 8.2497
2024-10-29 13:10:44: [2024-10-29 13:10:44] iter = 18580, loss = 4.2410
2024-10-29 13:10:45: [2024-10-29 13:10:45] iter = 18590, loss = 7.7204
2024-10-29 13:10:45: [2024-10-29 13:10:45] iter = 18600, loss = 15.0589
2024-10-29 13:10:46: [2024-10-29 13:10:46] iter = 18610, loss = 14.0141
2024-10-29 13:10:47: [2024-10-29 13:10:47] iter = 18620, loss = 16.2582
2024-10-29 13:10:47: [2024-10-29 13:10:47] iter = 18630, loss = 21.3823
2024-10-29 13:10:48: [2024-10-29 13:10:48] iter = 18640, loss = 11.5685
2024-10-29 13:10:48: [2024-10-29 13:10:48] iter = 18650, loss = 4.3163
2024-10-29 13:10:49: [2024-10-29 13:10:49] iter = 18660, loss = 8.2338
2024-10-29 13:10:49: [2024-10-29 13:10:49] iter = 18670, loss = 3.0470
2024-10-29 13:10:50: [2024-10-29 13:10:50] iter = 18680, loss = 3.6976
2024-10-29 13:10:50: [2024-10-29 13:10:50] iter = 18690, loss = 8.9243
2024-10-29 13:10:51: [2024-10-29 13:10:51] iter = 18700, loss = 13.1683
2024-10-29 13:10:52: [2024-10-29 13:10:51] iter = 18710, loss = 9.5321
2024-10-29 13:10:52: [2024-10-29 13:10:52] iter = 18720, loss = 3.4091
2024-10-29 13:10:53: [2024-10-29 13:10:53] iter = 18730, loss = 3.5823
2024-10-29 13:10:53: [2024-10-29 13:10:53] iter = 18740, loss = 5.4266
2024-10-29 13:10:54: [2024-10-29 13:10:54] iter = 18750, loss = 5.4308
2024-10-29 13:10:55: [2024-10-29 13:10:55] iter = 18760, loss = 6.2346
2024-10-29 13:10:56: [2024-10-29 13:10:56] iter = 18770, loss = 5.9264
2024-10-29 13:10:56: [2024-10-29 13:10:56] iter = 18780, loss = 4.4649
2024-10-29 13:10:57: [2024-10-29 13:10:57] iter = 18790, loss = 53.8556
2024-10-29 13:10:58: [2024-10-29 13:10:58] iter = 18800, loss = 2.8169
2024-10-29 13:10:58: [2024-10-29 13:10:58] iter = 18810, loss = 8.4085
2024-10-29 13:10:59: [2024-10-29 13:10:59] iter = 18820, loss = 38.7075
2024-10-29 13:10:59: [2024-10-29 13:10:59] iter = 18830, loss = 3.6211
2024-10-29 13:11:00: [2024-10-29 13:11:00] iter = 18840, loss = 11.7819
2024-10-29 13:11:00: [2024-10-29 13:11:00] iter = 18850, loss = 3.6798
2024-10-29 13:11:01: [2024-10-29 13:11:01] iter = 18860, loss = 4.7912
2024-10-29 13:11:02: [2024-10-29 13:11:01] iter = 18870, loss = 5.0305
2024-10-29 13:11:02: [2024-10-29 13:11:02] iter = 18880, loss = 6.8046
2024-10-29 13:11:03: [2024-10-29 13:11:03] iter = 18890, loss = 50.3812
2024-10-29 13:11:03: [2024-10-29 13:11:03] iter = 18900, loss = 3.0805
2024-10-29 13:11:04: [2024-10-29 13:11:04] iter = 18910, loss = 4.0585
2024-10-29 13:11:05: [2024-10-29 13:11:05] iter = 18920, loss = 5.6163
2024-10-29 13:11:05: [2024-10-29 13:11:05] iter = 18930, loss = 13.0096
2024-10-29 13:11:06: [2024-10-29 13:11:06] iter = 18940, loss = 14.8807
2024-10-29 13:11:07: [2024-10-29 13:11:07] iter = 18950, loss = 4.7316
2024-10-29 13:11:07: [2024-10-29 13:11:07] iter = 18960, loss = 3.0106
2024-10-29 13:11:08: [2024-10-29 13:11:08] iter = 18970, loss = 10.4120
2024-10-29 13:11:08: [2024-10-29 13:11:08] iter = 18980, loss = 2.5738
2024-10-29 13:11:09: [2024-10-29 13:11:09] iter = 18990, loss = 5.1976
2024-10-29 13:11:09: [2024-10-29 13:11:09] iter = 19000, loss = 68.7116
2024-10-29 13:11:10: [2024-10-29 13:11:10] iter = 19010, loss = 3.7355
2024-10-29 13:11:11: [2024-10-29 13:11:11] iter = 19020, loss = 4.2974
2024-10-29 13:11:11: [2024-10-29 13:11:11] iter = 19030, loss = 6.3473
2024-10-29 13:11:12: [2024-10-29 13:11:12] iter = 19040, loss = 6.7221
2024-10-29 13:11:12: [2024-10-29 13:11:12] iter = 19050, loss = 11.1011
2024-10-29 13:11:13: [2024-10-29 13:11:13] iter = 19060, loss = 9.3573
2024-10-29 13:11:14: [2024-10-29 13:11:14] iter = 19070, loss = 4.5057
2024-10-29 13:11:14: [2024-10-29 13:11:14] iter = 19080, loss = 6.6701
2024-10-29 13:11:15: [2024-10-29 13:11:15] iter = 19090, loss = 12.0578
2024-10-29 13:11:15: [2024-10-29 13:11:15] iter = 19100, loss = 5.2106
2024-10-29 13:11:16: [2024-10-29 13:11:16] iter = 19110, loss = 7.3920
2024-10-29 13:11:17: [2024-10-29 13:11:17] iter = 19120, loss = 23.2543
2024-10-29 13:11:17: [2024-10-29 13:11:17] iter = 19130, loss = 7.6322
2024-10-29 13:11:18: [2024-10-29 13:11:18] iter = 19140, loss = 3.0490
2024-10-29 13:11:19: [2024-10-29 13:11:19] iter = 19150, loss = 10.6215
2024-10-29 13:11:19: [2024-10-29 13:11:19] iter = 19160, loss = 4.9469
2024-10-29 13:11:20: [2024-10-29 13:11:20] iter = 19170, loss = 4.3560
2024-10-29 13:11:20: [2024-10-29 13:11:20] iter = 19180, loss = 11.0403
2024-10-29 13:11:21: [2024-10-29 13:11:21] iter = 19190, loss = 19.3035
2024-10-29 13:11:21: [2024-10-29 13:11:21] iter = 19200, loss = 8.8258
2024-10-29 13:11:21: [2024-10-29 13:11:21] iter = 19210, loss = 3.2881
2024-10-29 13:11:22: [2024-10-29 13:11:22] iter = 19220, loss = 7.8910
2024-10-29 13:11:22: [2024-10-29 13:11:22] iter = 19230, loss = 2.6833
2024-10-29 13:11:23: [2024-10-29 13:11:23] iter = 19240, loss = 9.6011
2024-10-29 13:11:23: [2024-10-29 13:11:23] iter = 19250, loss = 8.2104
2024-10-29 13:11:24: [2024-10-29 13:11:24] iter = 19260, loss = 29.3750
2024-10-29 13:11:24: [2024-10-29 13:11:24] iter = 19270, loss = 4.4826
2024-10-29 13:11:25: [2024-10-29 13:11:25] iter = 19280, loss = 35.7312
2024-10-29 13:11:25: [2024-10-29 13:11:25] iter = 19290, loss = 21.0910
2024-10-29 13:11:26: [2024-10-29 13:11:26] iter = 19300, loss = 3.6612
2024-10-29 13:11:26: [2024-10-29 13:11:26] iter = 19310, loss = 3.0356
2024-10-29 13:11:27: [2024-10-29 13:11:27] iter = 19320, loss = 2.6651
2024-10-29 13:11:28: [2024-10-29 13:11:28] iter = 19330, loss = 3.2211
2024-10-29 13:11:28: [2024-10-29 13:11:28] iter = 19340, loss = 23.3762
2024-10-29 13:11:29: [2024-10-29 13:11:29] iter = 19350, loss = 8.6340
2024-10-29 13:11:29: [2024-10-29 13:11:29] iter = 19360, loss = 3.3105
2024-10-29 13:11:30: [2024-10-29 13:11:30] iter = 19370, loss = 21.3136
2024-10-29 13:11:30: [2024-10-29 13:11:30] iter = 19380, loss = 16.1049
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 19390, loss = 5.0065
2024-10-29 13:11:31: [2024-10-29 13:11:31] iter = 19400, loss = 8.9036
2024-10-29 13:11:32: [2024-10-29 13:11:32] iter = 19410, loss = 7.7521
2024-10-29 13:11:32: [2024-10-29 13:11:32] iter = 19420, loss = 28.1267
2024-10-29 13:11:33: [2024-10-29 13:11:33] iter = 19430, loss = 6.8185
2024-10-29 13:11:33: [2024-10-29 13:11:33] iter = 19440, loss = 49.1794
2024-10-29 13:11:34: [2024-10-29 13:11:34] iter = 19450, loss = 15.6614
2024-10-29 13:11:34: [2024-10-29 13:11:34] iter = 19460, loss = 2.7230
2024-10-29 13:11:35: [2024-10-29 13:11:35] iter = 19470, loss = 8.0081
2024-10-29 13:11:35: [2024-10-29 13:11:35] iter = 19480, loss = 5.4491
2024-10-29 13:11:36: [2024-10-29 13:11:36] iter = 19490, loss = 5.6097
2024-10-29 13:11:36: [2024-10-29 13:11:36] iter = 19500, loss = 4.5188
2024-10-29 13:11:37: [2024-10-29 13:11:37] iter = 19510, loss = 5.5008
2024-10-29 13:11:37: [2024-10-29 13:11:37] iter = 19520, loss = 10.2868
2024-10-29 13:11:38: [2024-10-29 13:11:38] iter = 19530, loss = 15.3236
2024-10-29 13:11:38: [2024-10-29 13:11:38] iter = 19540, loss = 6.8598
2024-10-29 13:11:39: [2024-10-29 13:11:39] iter = 19550, loss = 15.4909
2024-10-29 13:11:39: [2024-10-29 13:11:39] iter = 19560, loss = 3.6334
2024-10-29 13:11:40: [2024-10-29 13:11:40] iter = 19570, loss = 4.9521
2024-10-29 13:11:40: [2024-10-29 13:11:40] iter = 19580, loss = 4.0809
2024-10-29 13:11:41: [2024-10-29 13:11:41] iter = 19590, loss = 3.3680
2024-10-29 13:11:41: [2024-10-29 13:11:41] iter = 19600, loss = 8.9818
2024-10-29 13:11:42: [2024-10-29 13:11:42] iter = 19610, loss = 11.9981
2024-10-29 13:11:42: [2024-10-29 13:11:42] iter = 19620, loss = 3.5533
2024-10-29 13:11:43: [2024-10-29 13:11:43] iter = 19630, loss = 4.3951
2024-10-29 13:11:43: [2024-10-29 13:11:43] iter = 19640, loss = 5.9862
2024-10-29 13:11:44: [2024-10-29 13:11:44] iter = 19650, loss = 7.2690
2024-10-29 13:11:44: [2024-10-29 13:11:44] iter = 19660, loss = 10.8418
2024-10-29 13:11:45: [2024-10-29 13:11:45] iter = 19670, loss = 5.1026
2024-10-29 13:11:45: [2024-10-29 13:11:45] iter = 19680, loss = 3.5920
2024-10-29 13:11:46: [2024-10-29 13:11:46] iter = 19690, loss = 13.1903
2024-10-29 13:11:47: [2024-10-29 13:11:47] iter = 19700, loss = 2.5496
2024-10-29 13:11:48: [2024-10-29 13:11:48] iter = 19710, loss = 32.6564
2024-10-29 13:11:48: [2024-10-29 13:11:48] iter = 19720, loss = 4.9189
2024-10-29 13:11:49: [2024-10-29 13:11:49] iter = 19730, loss = 4.3944
2024-10-29 13:11:49: [2024-10-29 13:11:49] iter = 19740, loss = 15.5009
2024-10-29 13:11:50: [2024-10-29 13:11:50] iter = 19750, loss = 43.3599
2024-10-29 13:11:51: [2024-10-29 13:11:51] iter = 19760, loss = 4.1549
2024-10-29 13:11:51: [2024-10-29 13:11:51] iter = 19770, loss = 9.8409
2024-10-29 13:11:52: [2024-10-29 13:11:52] iter = 19780, loss = 2.3711
2024-10-29 13:11:53: [2024-10-29 13:11:53] iter = 19790, loss = 5.5761
2024-10-29 13:11:53: [2024-10-29 13:11:53] iter = 19800, loss = 6.2419
2024-10-29 13:11:54: [2024-10-29 13:11:54] iter = 19810, loss = 11.1970
2024-10-29 13:11:54: [2024-10-29 13:11:54] iter = 19820, loss = 5.0211
2024-10-29 13:11:55: [2024-10-29 13:11:55] iter = 19830, loss = 3.7668
2024-10-29 13:11:55: [2024-10-29 13:11:55] iter = 19840, loss = 4.8959
2024-10-29 13:11:56: [2024-10-29 13:11:56] iter = 19850, loss = 14.3736
2024-10-29 13:11:57: [2024-10-29 13:11:57] iter = 19860, loss = 5.8898
2024-10-29 13:11:57: [2024-10-29 13:11:57] iter = 19870, loss = 10.2875
2024-10-29 13:11:57: [2024-10-29 13:11:57] iter = 19880, loss = 10.0648
2024-10-29 13:11:58: [2024-10-29 13:11:58] iter = 19890, loss = 8.7618
2024-10-29 13:11:58: [2024-10-29 13:11:58] iter = 19900, loss = 5.4329
2024-10-29 13:11:59: [2024-10-29 13:11:59] iter = 19910, loss = 3.3068
2024-10-29 13:12:00: [2024-10-29 13:12:00] iter = 19920, loss = 4.2107
2024-10-29 13:12:00: [2024-10-29 13:12:00] iter = 19930, loss = 4.0649
2024-10-29 13:12:01: [2024-10-29 13:12:01] iter = 19940, loss = 4.7585
2024-10-29 13:12:01: [2024-10-29 13:12:01] iter = 19950, loss = 12.6904
2024-10-29 13:12:02: [2024-10-29 13:12:02] iter = 19960, loss = 3.2041
2024-10-29 13:12:02: [2024-10-29 13:12:02] iter = 19970, loss = 5.0107
2024-10-29 13:12:03: [2024-10-29 13:12:03] iter = 19980, loss = 3.2423
2024-10-29 13:12:03: [2024-10-29 13:12:03] iter = 19990, loss = 7.4385
2024-10-29 13:12:04: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:12:04: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:12:04: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 24244}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:12:33: Evaluate 5 random ConvNet, ACCmean = 0.4624 ACCstd = 0.0078
-------------------------
2024-10-29 13:12:33: Evaluate 5 random ConvNet, SENmean = 0.4624 SENstd = 0.0078
-------------------------
2024-10-29 13:12:33: Evaluate 5 random ConvNet, SPEmean = 0.8208 SPEstd = 0.0026
-------------------------
2024-10-29 13:12:33: Evaluate 5 random ConvNet, F!mean = 0.3997 F!std = 0.0065
-------------------------
2024-10-29 13:12:33: Evaluate 5 random ConvNet, mean = 0.4624 std = 0.0078
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:12:33: [2024-10-29 13:12:33] iter = 20000, loss = 50.0245
2024-10-29 13:12:33: 
================== Exp 4 ==================
 
2024-10-29 13:12:33: Hyper-parameters: 
{'dataset': 'OCTMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7faf200e8730>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_OCTMNIST (INFO)>}
2024-10-29 13:12:33: Evaluation model pool: ['ConvNet']
2024-10-29 13:12:35: class c = 0: 33484 real images
2024-10-29 13:12:35: class c = 1: 10213 real images
2024-10-29 13:12:35: class c = 2: 7754 real images
2024-10-29 13:12:35: class c = 3: 46026 real images
2024-10-29 13:12:36: real images channel 0, mean = 0.1889, std = 0.1963
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-29 13:12:36: initialize synthetic data from random real images
2024-10-29 13:12:36: [2024-10-29 13:12:36] training begins
2024-10-29 13:12:36: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-29 13:12:36: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:12:36: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53211}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:03: Evaluate 5 random ConvNet, ACCmean = 0.4574 ACCstd = 0.0067
-------------------------
2024-10-29 13:13:03: Evaluate 5 random ConvNet, SENmean = 0.4574 SENstd = 0.0067
-------------------------
2024-10-29 13:13:03: Evaluate 5 random ConvNet, SPEmean = 0.8191 SPEstd = 0.0022
-------------------------
2024-10-29 13:13:03: Evaluate 5 random ConvNet, F!mean = 0.4530 F!std = 0.0074
-------------------------
2024-10-29 13:13:03: Evaluate 5 random ConvNet, mean = 0.4574 std = 0.0067
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:03: [2024-10-29 13:13:03] iter = 00000, loss = 30.5062
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:13:03: [2024-10-29 13:13:03] iter = 00010, loss = 13.6409
2024-10-29 13:13:04: [2024-10-29 13:13:04] iter = 00020, loss = 7.9450
2024-10-29 13:13:04: [2024-10-29 13:13:04] iter = 00030, loss = 47.6308
2024-10-29 13:13:05: [2024-10-29 13:13:05] iter = 00040, loss = 8.6112
2024-10-29 13:13:05: [2024-10-29 13:13:05] iter = 00050, loss = 10.6741
2024-10-29 13:13:06: [2024-10-29 13:13:06] iter = 00060, loss = 5.3347
2024-10-29 13:13:06: [2024-10-29 13:13:06] iter = 00070, loss = 3.8331
2024-10-29 13:13:07: [2024-10-29 13:13:07] iter = 00080, loss = 4.6601
2024-10-29 13:13:08: [2024-10-29 13:13:08] iter = 00090, loss = 4.7988
2024-10-29 13:13:08: [2024-10-29 13:13:08] iter = 00100, loss = 6.1280
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 00110, loss = 3.2171
2024-10-29 13:13:09: [2024-10-29 13:13:09] iter = 00120, loss = 3.9555
2024-10-29 13:13:10: [2024-10-29 13:13:10] iter = 00130, loss = 9.1241
2024-10-29 13:13:10: [2024-10-29 13:13:10] iter = 00140, loss = 3.1261
2024-10-29 13:13:11: [2024-10-29 13:13:11] iter = 00150, loss = 21.3171
2024-10-29 13:13:12: [2024-10-29 13:13:12] iter = 00160, loss = 4.8199
2024-10-29 13:13:12: [2024-10-29 13:13:12] iter = 00170, loss = 3.8805
2024-10-29 13:13:13: [2024-10-29 13:13:13] iter = 00180, loss = 5.9030
2024-10-29 13:13:13: [2024-10-29 13:13:13] iter = 00190, loss = 3.1025
2024-10-29 13:13:14: [2024-10-29 13:13:14] iter = 00200, loss = 7.0553
2024-10-29 13:13:14: [2024-10-29 13:13:14] iter = 00210, loss = 10.0868
2024-10-29 13:13:15: [2024-10-29 13:13:15] iter = 00220, loss = 6.8250
2024-10-29 13:13:15: [2024-10-29 13:13:15] iter = 00230, loss = 27.9454
2024-10-29 13:13:16: [2024-10-29 13:13:16] iter = 00240, loss = 8.6558
2024-10-29 13:13:16: [2024-10-29 13:13:16] iter = 00250, loss = 8.3821
2024-10-29 13:13:17: [2024-10-29 13:13:17] iter = 00260, loss = 7.5966
2024-10-29 13:13:17: [2024-10-29 13:13:17] iter = 00270, loss = 3.0843
2024-10-29 13:13:18: [2024-10-29 13:13:18] iter = 00280, loss = 8.3917
2024-10-29 13:13:18: [2024-10-29 13:13:18] iter = 00290, loss = 6.3235
2024-10-29 13:13:19: [2024-10-29 13:13:19] iter = 00300, loss = 4.9083
2024-10-29 13:13:19: [2024-10-29 13:13:19] iter = 00310, loss = 25.6478
2024-10-29 13:13:20: [2024-10-29 13:13:20] iter = 00320, loss = 4.4439
2024-10-29 13:13:20: [2024-10-29 13:13:20] iter = 00330, loss = 8.3316
2024-10-29 13:13:21: [2024-10-29 13:13:21] iter = 00340, loss = 3.9304
2024-10-29 13:13:22: [2024-10-29 13:13:22] iter = 00350, loss = 6.9454
2024-10-29 13:13:22: [2024-10-29 13:13:22] iter = 00360, loss = 2.5190
2024-10-29 13:13:23: [2024-10-29 13:13:23] iter = 00370, loss = 5.7000
2024-10-29 13:13:23: [2024-10-29 13:13:23] iter = 00380, loss = 4.5788
2024-10-29 13:13:24: [2024-10-29 13:13:24] iter = 00390, loss = 2.6017
2024-10-29 13:13:24: [2024-10-29 13:13:24] iter = 00400, loss = 17.4414
2024-10-29 13:13:25: [2024-10-29 13:13:25] iter = 00410, loss = 6.2626
2024-10-29 13:13:25: [2024-10-29 13:13:25] iter = 00420, loss = 3.3275
2024-10-29 13:13:26: [2024-10-29 13:13:26] iter = 00430, loss = 10.6042
2024-10-29 13:13:27: [2024-10-29 13:13:27] iter = 00440, loss = 5.5401
2024-10-29 13:13:28: [2024-10-29 13:13:28] iter = 00450, loss = 3.4484
2024-10-29 13:13:28: [2024-10-29 13:13:28] iter = 00460, loss = 7.4355
2024-10-29 13:13:29: [2024-10-29 13:13:29] iter = 00470, loss = 4.3621
2024-10-29 13:13:29: [2024-10-29 13:13:29] iter = 00480, loss = 5.6347
2024-10-29 13:13:30: [2024-10-29 13:13:30] iter = 00490, loss = 11.6477
2024-10-29 13:13:30: [2024-10-29 13:13:30] iter = 00500, loss = 24.4409
2024-10-29 13:13:31: [2024-10-29 13:13:31] iter = 00510, loss = 3.5897
2024-10-29 13:13:31: [2024-10-29 13:13:31] iter = 00520, loss = 5.4469
2024-10-29 13:13:32: [2024-10-29 13:13:32] iter = 00530, loss = 5.3342
2024-10-29 13:13:32: [2024-10-29 13:13:32] iter = 00540, loss = 5.9563
2024-10-29 13:13:33: [2024-10-29 13:13:33] iter = 00550, loss = 24.1069
2024-10-29 13:13:33: [2024-10-29 13:13:33] iter = 00560, loss = 2.8156
2024-10-29 13:13:34: [2024-10-29 13:13:34] iter = 00570, loss = 4.0504
2024-10-29 13:13:34: [2024-10-29 13:13:34] iter = 00580, loss = 6.4760
2024-10-29 13:13:35: [2024-10-29 13:13:35] iter = 00590, loss = 10.0898
2024-10-29 13:13:35: [2024-10-29 13:13:35] iter = 00600, loss = 4.9505
2024-10-29 13:13:36: [2024-10-29 13:13:36] iter = 00610, loss = 5.3649
2024-10-29 13:13:37: [2024-10-29 13:13:37] iter = 00620, loss = 5.7643
2024-10-29 13:13:37: [2024-10-29 13:13:37] iter = 00630, loss = 4.5233
2024-10-29 13:13:38: [2024-10-29 13:13:38] iter = 00640, loss = 7.1701
2024-10-29 13:13:38: [2024-10-29 13:13:38] iter = 00650, loss = 4.8423
2024-10-29 13:13:39: [2024-10-29 13:13:39] iter = 00660, loss = 14.0356
2024-10-29 13:13:39: [2024-10-29 13:13:39] iter = 00670, loss = 6.2375
2024-10-29 13:13:40: [2024-10-29 13:13:40] iter = 00680, loss = 2.6446
2024-10-29 13:13:40: [2024-10-29 13:13:40] iter = 00690, loss = 7.1709
2024-10-29 13:13:41: [2024-10-29 13:13:41] iter = 00700, loss = 8.0997
2024-10-29 13:13:42: [2024-10-29 13:13:42] iter = 00710, loss = 5.4166
2024-10-29 13:13:42: [2024-10-29 13:13:42] iter = 00720, loss = 17.5840
2024-10-29 13:13:43: [2024-10-29 13:13:43] iter = 00730, loss = 5.0460
2024-10-29 13:13:44: [2024-10-29 13:13:44] iter = 00740, loss = 5.9284
2024-10-29 13:13:44: [2024-10-29 13:13:44] iter = 00750, loss = 16.4147
2024-10-29 13:13:45: [2024-10-29 13:13:45] iter = 00760, loss = 25.3636
2024-10-29 13:13:45: [2024-10-29 13:13:45] iter = 00770, loss = 10.3494
2024-10-29 13:13:46: [2024-10-29 13:13:46] iter = 00780, loss = 10.9258
2024-10-29 13:13:46: [2024-10-29 13:13:46] iter = 00790, loss = 9.6248
2024-10-29 13:13:47: [2024-10-29 13:13:47] iter = 00800, loss = 3.3543
2024-10-29 13:13:47: [2024-10-29 13:13:47] iter = 00810, loss = 8.0221
2024-10-29 13:13:48: [2024-10-29 13:13:48] iter = 00820, loss = 2.9220
2024-10-29 13:13:49: [2024-10-29 13:13:49] iter = 00830, loss = 3.4239
2024-10-29 13:13:49: [2024-10-29 13:13:49] iter = 00840, loss = 5.2562
2024-10-29 13:13:50: [2024-10-29 13:13:50] iter = 00850, loss = 12.7449
2024-10-29 13:13:50: [2024-10-29 13:13:50] iter = 00860, loss = 8.1047
2024-10-29 13:13:51: [2024-10-29 13:13:51] iter = 00870, loss = 3.5066
2024-10-29 13:13:51: [2024-10-29 13:13:51] iter = 00880, loss = 3.7787
2024-10-29 13:13:52: [2024-10-29 13:13:52] iter = 00890, loss = 15.5458
2024-10-29 13:13:52: [2024-10-29 13:13:52] iter = 00900, loss = 9.5744
2024-10-29 13:13:53: [2024-10-29 13:13:53] iter = 00910, loss = 47.0245
2024-10-29 13:13:53: [2024-10-29 13:13:53] iter = 00920, loss = 27.7960
2024-10-29 13:13:54: [2024-10-29 13:13:54] iter = 00930, loss = 6.9715
2024-10-29 13:13:54: [2024-10-29 13:13:54] iter = 00940, loss = 3.0844
2024-10-29 13:13:55: [2024-10-29 13:13:55] iter = 00950, loss = 5.6143
2024-10-29 13:13:55: [2024-10-29 13:13:55] iter = 00960, loss = 2.5830
2024-10-29 13:13:56: [2024-10-29 13:13:56] iter = 00970, loss = 9.4112
2024-10-29 13:13:56: [2024-10-29 13:13:56] iter = 00980, loss = 9.7056
2024-10-29 13:13:57: [2024-10-29 13:13:57] iter = 00990, loss = 45.2594
2024-10-29 13:13:57: [2024-10-29 13:13:57] iter = 01000, loss = 3.8767
2024-10-29 13:13:58: [2024-10-29 13:13:58] iter = 01010, loss = 3.0645
2024-10-29 13:13:58: [2024-10-29 13:13:58] iter = 01020, loss = 6.4403
2024-10-29 13:13:59: [2024-10-29 13:13:59] iter = 01030, loss = 10.4786
2024-10-29 13:13:59: [2024-10-29 13:13:59] iter = 01040, loss = 6.3874
2024-10-29 13:14:00: [2024-10-29 13:14:00] iter = 01050, loss = 11.0294
2024-10-29 13:14:00: [2024-10-29 13:14:00] iter = 01060, loss = 10.2587
2024-10-29 13:14:01: [2024-10-29 13:14:01] iter = 01070, loss = 23.3599
2024-10-29 13:14:01: [2024-10-29 13:14:01] iter = 01080, loss = 8.9217
2024-10-29 13:14:02: [2024-10-29 13:14:02] iter = 01090, loss = 4.6726
2024-10-29 13:14:03: [2024-10-29 13:14:03] iter = 01100, loss = 3.9871
2024-10-29 13:14:03: [2024-10-29 13:14:03] iter = 01110, loss = 4.7078
2024-10-29 13:14:04: [2024-10-29 13:14:04] iter = 01120, loss = 2.4803
2024-10-29 13:14:05: [2024-10-29 13:14:05] iter = 01130, loss = 2.6388
2024-10-29 13:14:05: [2024-10-29 13:14:05] iter = 01140, loss = 2.9686
2024-10-29 13:14:06: [2024-10-29 13:14:06] iter = 01150, loss = 30.4073
2024-10-29 13:14:06: [2024-10-29 13:14:06] iter = 01160, loss = 41.8715
2024-10-29 13:14:07: [2024-10-29 13:14:07] iter = 01170, loss = 7.7563
2024-10-29 13:14:07: [2024-10-29 13:14:07] iter = 01180, loss = 30.1067
2024-10-29 13:14:08: [2024-10-29 13:14:08] iter = 01190, loss = 7.8659
2024-10-29 13:14:08: [2024-10-29 13:14:08] iter = 01200, loss = 2.7265
2024-10-29 13:14:09: [2024-10-29 13:14:09] iter = 01210, loss = 5.1834
2024-10-29 13:14:09: [2024-10-29 13:14:09] iter = 01220, loss = 22.9780
2024-10-29 13:14:10: [2024-10-29 13:14:10] iter = 01230, loss = 3.6113
2024-10-29 13:14:10: [2024-10-29 13:14:10] iter = 01240, loss = 6.0779
2024-10-29 13:14:11: [2024-10-29 13:14:11] iter = 01250, loss = 14.2535
2024-10-29 13:14:12: [2024-10-29 13:14:12] iter = 01260, loss = 3.5939
2024-10-29 13:14:12: [2024-10-29 13:14:12] iter = 01270, loss = 7.7102
2024-10-29 13:14:13: [2024-10-29 13:14:13] iter = 01280, loss = 3.6772
2024-10-29 13:14:13: [2024-10-29 13:14:13] iter = 01290, loss = 4.6171
2024-10-29 13:14:14: [2024-10-29 13:14:14] iter = 01300, loss = 3.2935
2024-10-29 13:14:14: [2024-10-29 13:14:14] iter = 01310, loss = 2.9594
2024-10-29 13:14:15: [2024-10-29 13:14:15] iter = 01320, loss = 2.9644
2024-10-29 13:14:15: [2024-10-29 13:14:15] iter = 01330, loss = 29.8845
2024-10-29 13:14:16: [2024-10-29 13:14:16] iter = 01340, loss = 4.3119
2024-10-29 13:14:16: [2024-10-29 13:14:16] iter = 01350, loss = 20.9367
2024-10-29 13:14:17: [2024-10-29 13:14:17] iter = 01360, loss = 5.3277
2024-10-29 13:14:17: [2024-10-29 13:14:17] iter = 01370, loss = 3.2915
2024-10-29 13:14:18: [2024-10-29 13:14:18] iter = 01380, loss = 4.7512
2024-10-29 13:14:18: [2024-10-29 13:14:18] iter = 01390, loss = 13.2305
2024-10-29 13:14:19: [2024-10-29 13:14:19] iter = 01400, loss = 3.6886
2024-10-29 13:14:19: [2024-10-29 13:14:19] iter = 01410, loss = 55.3730
2024-10-29 13:14:20: [2024-10-29 13:14:20] iter = 01420, loss = 6.5434
2024-10-29 13:14:20: [2024-10-29 13:14:20] iter = 01430, loss = 6.4797
2024-10-29 13:14:21: [2024-10-29 13:14:21] iter = 01440, loss = 4.3962
2024-10-29 13:14:21: [2024-10-29 13:14:21] iter = 01450, loss = 4.6539
2024-10-29 13:14:22: [2024-10-29 13:14:22] iter = 01460, loss = 4.0144
2024-10-29 13:14:22: [2024-10-29 13:14:22] iter = 01470, loss = 9.0947
2024-10-29 13:14:23: [2024-10-29 13:14:23] iter = 01480, loss = 31.9037
2024-10-29 13:14:23: [2024-10-29 13:14:23] iter = 01490, loss = 9.8076
2024-10-29 13:14:24: [2024-10-29 13:14:24] iter = 01500, loss = 4.7672
2024-10-29 13:14:24: [2024-10-29 13:14:24] iter = 01510, loss = 8.4331
2024-10-29 13:14:25: [2024-10-29 13:14:25] iter = 01520, loss = 4.9931
2024-10-29 13:14:25: [2024-10-29 13:14:25] iter = 01530, loss = 4.2658
2024-10-29 13:14:26: [2024-10-29 13:14:26] iter = 01540, loss = 2.5933
2024-10-29 13:14:26: [2024-10-29 13:14:26] iter = 01550, loss = 5.6002
2024-10-29 13:14:27: [2024-10-29 13:14:27] iter = 01560, loss = 6.4895
2024-10-29 13:14:27: [2024-10-29 13:14:27] iter = 01570, loss = 6.2719
2024-10-29 13:14:28: [2024-10-29 13:14:28] iter = 01580, loss = 4.0113
2024-10-29 13:14:29: [2024-10-29 13:14:28] iter = 01590, loss = 3.6938
2024-10-29 13:14:29: [2024-10-29 13:14:29] iter = 01600, loss = 5.6044
2024-10-29 13:14:29: [2024-10-29 13:14:29] iter = 01610, loss = 3.2970
2024-10-29 13:14:30: [2024-10-29 13:14:30] iter = 01620, loss = 4.0313
2024-10-29 13:14:31: [2024-10-29 13:14:31] iter = 01630, loss = 2.8383
2024-10-29 13:14:31: [2024-10-29 13:14:31] iter = 01640, loss = 4.5996
2024-10-29 13:14:32: [2024-10-29 13:14:32] iter = 01650, loss = 5.2986
2024-10-29 13:14:32: [2024-10-29 13:14:32] iter = 01660, loss = 3.6189
2024-10-29 13:14:33: [2024-10-29 13:14:33] iter = 01670, loss = 4.7911
2024-10-29 13:14:33: [2024-10-29 13:14:33] iter = 01680, loss = 2.9959
2024-10-29 13:14:34: [2024-10-29 13:14:34] iter = 01690, loss = 4.4588
2024-10-29 13:14:34: [2024-10-29 13:14:34] iter = 01700, loss = 4.5598
2024-10-29 13:14:35: [2024-10-29 13:14:35] iter = 01710, loss = 3.8879
2024-10-29 13:14:35: [2024-10-29 13:14:35] iter = 01720, loss = 6.0460
2024-10-29 13:14:36: [2024-10-29 13:14:36] iter = 01730, loss = 7.8389
2024-10-29 13:14:36: [2024-10-29 13:14:36] iter = 01740, loss = 23.7696
2024-10-29 13:14:37: [2024-10-29 13:14:37] iter = 01750, loss = 15.8818
2024-10-29 13:14:37: [2024-10-29 13:14:37] iter = 01760, loss = 7.7050
2024-10-29 13:14:38: [2024-10-29 13:14:38] iter = 01770, loss = 3.7509
2024-10-29 13:14:38: [2024-10-29 13:14:38] iter = 01780, loss = 5.5604
2024-10-29 13:14:39: [2024-10-29 13:14:39] iter = 01790, loss = 3.2980
2024-10-29 13:14:39: [2024-10-29 13:14:39] iter = 01800, loss = 8.3036
2024-10-29 13:14:40: [2024-10-29 13:14:40] iter = 01810, loss = 6.3139
2024-10-29 13:14:41: [2024-10-29 13:14:41] iter = 01820, loss = 7.0534
2024-10-29 13:14:41: [2024-10-29 13:14:41] iter = 01830, loss = 2.6165
2024-10-29 13:14:42: [2024-10-29 13:14:42] iter = 01840, loss = 3.5717
2024-10-29 13:14:42: [2024-10-29 13:14:42] iter = 01850, loss = 10.7944
2024-10-29 13:14:43: [2024-10-29 13:14:43] iter = 01860, loss = 9.9403
2024-10-29 13:14:43: [2024-10-29 13:14:43] iter = 01870, loss = 5.9643
2024-10-29 13:14:44: [2024-10-29 13:14:44] iter = 01880, loss = 3.5420
2024-10-29 13:14:44: [2024-10-29 13:14:44] iter = 01890, loss = 2.6786
2024-10-29 13:14:45: [2024-10-29 13:14:45] iter = 01900, loss = 2.4397
2024-10-29 13:14:45: [2024-10-29 13:14:45] iter = 01910, loss = 13.7780
2024-10-29 13:14:46: [2024-10-29 13:14:46] iter = 01920, loss = 7.9297
2024-10-29 13:14:46: [2024-10-29 13:14:46] iter = 01930, loss = 5.2515
2024-10-29 13:14:47: [2024-10-29 13:14:47] iter = 01940, loss = 2.3163
2024-10-29 13:14:47: [2024-10-29 13:14:47] iter = 01950, loss = 6.2272
2024-10-29 13:14:48: [2024-10-29 13:14:48] iter = 01960, loss = 2.3368
2024-10-29 13:14:49: [2024-10-29 13:14:49] iter = 01970, loss = 6.0061
2024-10-29 13:14:49: [2024-10-29 13:14:49] iter = 01980, loss = 7.9198
2024-10-29 13:14:50: [2024-10-29 13:14:50] iter = 01990, loss = 4.4056
2024-10-29 13:14:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-29 13:14:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:14:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 90614}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:15:16: Evaluate 5 random ConvNet, ACCmean = 0.3846 ACCstd = 0.0190
-------------------------
2024-10-29 13:15:16: Evaluate 5 random ConvNet, SENmean = 0.3846 SENstd = 0.0190
-------------------------
2024-10-29 13:15:16: Evaluate 5 random ConvNet, SPEmean = 0.7949 SPEstd = 0.0063
-------------------------
2024-10-29 13:15:16: Evaluate 5 random ConvNet, F!mean = 0.3210 F!std = 0.0213
-------------------------
2024-10-29 13:15:16: Evaluate 5 random ConvNet, mean = 0.3846 std = 0.0190
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:15:17: [2024-10-29 13:15:17] iter = 02000, loss = 6.1768
2024-10-29 13:15:17: [2024-10-29 13:15:17] iter = 02010, loss = 5.5091
2024-10-29 13:15:18: [2024-10-29 13:15:18] iter = 02020, loss = 6.1966
2024-10-29 13:15:18: [2024-10-29 13:15:18] iter = 02030, loss = 6.7446
2024-10-29 13:15:19: [2024-10-29 13:15:19] iter = 02040, loss = 1.8859
2024-10-29 13:15:19: [2024-10-29 13:15:19] iter = 02050, loss = 8.9211
2024-10-29 13:15:20: [2024-10-29 13:15:20] iter = 02060, loss = 2.9624
2024-10-29 13:15:20: [2024-10-29 13:15:20] iter = 02070, loss = 4.5299
2024-10-29 13:15:21: [2024-10-29 13:15:21] iter = 02080, loss = 26.2731
2024-10-29 13:15:21: [2024-10-29 13:15:21] iter = 02090, loss = 6.7076
2024-10-29 13:15:22: [2024-10-29 13:15:22] iter = 02100, loss = 6.5185
2024-10-29 13:15:22: [2024-10-29 13:15:22] iter = 02110, loss = 2.7529
2024-10-29 13:15:23: [2024-10-29 13:15:23] iter = 02120, loss = 17.5727
2024-10-29 13:15:23: [2024-10-29 13:15:23] iter = 02130, loss = 7.4285
2024-10-29 13:15:24: [2024-10-29 13:15:24] iter = 02140, loss = 12.3843
2024-10-29 13:15:24: [2024-10-29 13:15:24] iter = 02150, loss = 30.1201
2024-10-29 13:15:25: [2024-10-29 13:15:25] iter = 02160, loss = 3.5794
2024-10-29 13:15:25: [2024-10-29 13:15:25] iter = 02170, loss = 8.4703
2024-10-29 13:15:26: [2024-10-29 13:15:26] iter = 02180, loss = 3.3031
2024-10-29 13:15:26: [2024-10-29 13:15:26] iter = 02190, loss = 16.1997
2024-10-29 13:15:27: [2024-10-29 13:15:27] iter = 02200, loss = 4.4173
2024-10-29 13:15:27: [2024-10-29 13:15:27] iter = 02210, loss = 16.3668
2024-10-29 13:15:28: [2024-10-29 13:15:28] iter = 02220, loss = 8.2637
2024-10-29 13:15:28: [2024-10-29 13:15:28] iter = 02230, loss = 9.1360
2024-10-29 13:15:29: [2024-10-29 13:15:29] iter = 02240, loss = 13.5485
2024-10-29 13:15:29: [2024-10-29 13:15:29] iter = 02250, loss = 5.4270
2024-10-29 13:15:30: [2024-10-29 13:15:30] iter = 02260, loss = 6.5770
2024-10-29 13:15:30: [2024-10-29 13:15:30] iter = 02270, loss = 6.3492
2024-10-29 13:15:31: [2024-10-29 13:15:31] iter = 02280, loss = 5.6250
2024-10-29 13:15:32: [2024-10-29 13:15:31] iter = 02290, loss = 4.9015
2024-10-29 13:15:32: [2024-10-29 13:15:32] iter = 02300, loss = 4.1381
2024-10-29 13:15:32: [2024-10-29 13:15:32] iter = 02310, loss = 4.8086
2024-10-29 13:15:33: [2024-10-29 13:15:33] iter = 02320, loss = 3.8874
2024-10-29 13:15:33: [2024-10-29 13:15:33] iter = 02330, loss = 6.7299
2024-10-29 13:15:34: [2024-10-29 13:15:34] iter = 02340, loss = 6.6173
2024-10-29 13:15:34: [2024-10-29 13:15:34] iter = 02350, loss = 33.4143
2024-10-29 13:15:35: [2024-10-29 13:15:35] iter = 02360, loss = 16.3313
2024-10-29 13:15:35: [2024-10-29 13:15:35] iter = 02370, loss = 4.8551
2024-10-29 13:15:36: [2024-10-29 13:15:36] iter = 02380, loss = 28.2491
2024-10-29 13:15:36: [2024-10-29 13:15:36] iter = 02390, loss = 5.3065
2024-10-29 13:15:37: [2024-10-29 13:15:37] iter = 02400, loss = 17.2413
2024-10-29 13:15:37: [2024-10-29 13:15:37] iter = 02410, loss = 15.8763
2024-10-29 13:15:38: [2024-10-29 13:15:38] iter = 02420, loss = 43.5313
2024-10-29 13:15:38: [2024-10-29 13:15:38] iter = 02430, loss = 2.5590
2024-10-29 13:15:39: [2024-10-29 13:15:39] iter = 02440, loss = 8.8577
2024-10-29 13:15:39: [2024-10-29 13:15:39] iter = 02450, loss = 3.3025
2024-10-29 13:15:40: [2024-10-29 13:15:40] iter = 02460, loss = 4.3666
2024-10-29 13:15:40: [2024-10-29 13:15:40] iter = 02470, loss = 7.1745
2024-10-29 13:15:41: [2024-10-29 13:15:41] iter = 02480, loss = 4.7634
2024-10-29 13:15:42: [2024-10-29 13:15:42] iter = 02490, loss = 4.7971
2024-10-29 13:15:42: [2024-10-29 13:15:42] iter = 02500, loss = 3.3616
2024-10-29 13:15:43: [2024-10-29 13:15:43] iter = 02510, loss = 4.5028
2024-10-29 13:15:43: [2024-10-29 13:15:43] iter = 02520, loss = 5.0542
2024-10-29 13:15:44: [2024-10-29 13:15:44] iter = 02530, loss = 5.1356
2024-10-29 13:15:44: [2024-10-29 13:15:44] iter = 02540, loss = 3.6104
2024-10-29 13:15:45: [2024-10-29 13:15:45] iter = 02550, loss = 3.1416
2024-10-29 13:15:46: [2024-10-29 13:15:46] iter = 02560, loss = 27.1665
2024-10-29 13:15:46: [2024-10-29 13:15:46] iter = 02570, loss = 3.3429
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 02580, loss = 10.7009
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 02590, loss = 6.5399
2024-10-29 13:15:47: [2024-10-29 13:15:47] iter = 02600, loss = 9.1673
2024-10-29 13:15:48: [2024-10-29 13:15:48] iter = 02610, loss = 10.5753
2024-10-29 13:15:48: [2024-10-29 13:15:48] iter = 02620, loss = 19.5589
2024-10-29 13:15:49: [2024-10-29 13:15:49] iter = 02630, loss = 3.0952
2024-10-29 13:15:49: [2024-10-29 13:15:49] iter = 02640, loss = 4.9418
2024-10-29 13:15:50: [2024-10-29 13:15:50] iter = 02650, loss = 9.3063
2024-10-29 13:15:50: [2024-10-29 13:15:50] iter = 02660, loss = 2.3641
2024-10-29 13:15:51: [2024-10-29 13:15:51] iter = 02670, loss = 13.6765
2024-10-29 13:15:51: [2024-10-29 13:15:51] iter = 02680, loss = 20.3179
2024-10-29 13:15:52: [2024-10-29 13:15:52] iter = 02690, loss = 3.4764
2024-10-29 13:15:52: [2024-10-29 13:15:52] iter = 02700, loss = 11.4301
2024-10-29 13:15:53: [2024-10-29 13:15:53] iter = 02710, loss = 13.1087
2024-10-29 13:15:53: [2024-10-29 13:15:53] iter = 02720, loss = 5.3267
2024-10-29 13:15:54: [2024-10-29 13:15:54] iter = 02730, loss = 3.5843
2024-10-29 13:15:55: [2024-10-29 13:15:55] iter = 02740, loss = 3.0519
2024-10-29 13:15:55: [2024-10-29 13:15:55] iter = 02750, loss = 3.0581
2024-10-29 13:15:56: [2024-10-29 13:15:56] iter = 02760, loss = 15.3897
2024-10-29 13:15:56: [2024-10-29 13:15:56] iter = 02770, loss = 2.6688
2024-10-29 13:15:57: [2024-10-29 13:15:57] iter = 02780, loss = 14.1290
2024-10-29 13:15:57: [2024-10-29 13:15:57] iter = 02790, loss = 2.7629
2024-10-29 13:15:58: [2024-10-29 13:15:58] iter = 02800, loss = 15.0306
2024-10-29 13:15:58: [2024-10-29 13:15:58] iter = 02810, loss = 4.4330
2024-10-29 13:15:59: [2024-10-29 13:15:59] iter = 02820, loss = 5.2252
2024-10-29 13:15:59: [2024-10-29 13:15:59] iter = 02830, loss = 4.5091
2024-10-29 13:16:00: [2024-10-29 13:16:00] iter = 02840, loss = 2.7552
2024-10-29 13:16:00: [2024-10-29 13:16:00] iter = 02850, loss = 20.4418
2024-10-29 13:16:01: [2024-10-29 13:16:01] iter = 02860, loss = 18.6234
2024-10-29 13:16:01: [2024-10-29 13:16:01] iter = 02870, loss = 20.8629
2024-10-29 13:16:02: [2024-10-29 13:16:02] iter = 02880, loss = 11.3445
2024-10-29 13:16:02: [2024-10-29 13:16:02] iter = 02890, loss = 8.9876
2024-10-29 13:16:03: [2024-10-29 13:16:03] iter = 02900, loss = 15.8198
2024-10-29 13:16:03: [2024-10-29 13:16:03] iter = 02910, loss = 4.3969
2024-10-29 13:16:04: [2024-10-29 13:16:04] iter = 02920, loss = 41.4495
2024-10-29 13:16:04: [2024-10-29 13:16:04] iter = 02930, loss = 41.3331
2024-10-29 13:16:05: [2024-10-29 13:16:05] iter = 02940, loss = 45.4398
2024-10-29 13:16:05: [2024-10-29 13:16:05] iter = 02950, loss = 6.3043
2024-10-29 13:16:06: [2024-10-29 13:16:06] iter = 02960, loss = 4.8183
2024-10-29 13:16:06: [2024-10-29 13:16:06] iter = 02970, loss = 88.5654
2024-10-29 13:16:07: [2024-10-29 13:16:07] iter = 02980, loss = 5.1954
2024-10-29 13:16:07: [2024-10-29 13:16:07] iter = 02990, loss = 3.8866
2024-10-29 13:16:08: [2024-10-29 13:16:08] iter = 03000, loss = 14.5687
2024-10-29 13:16:08: [2024-10-29 13:16:08] iter = 03010, loss = 3.5499
2024-10-29 13:16:09: [2024-10-29 13:16:09] iter = 03020, loss = 2.3794
2024-10-29 13:16:09: [2024-10-29 13:16:09] iter = 03030, loss = 8.3903
2024-10-29 13:16:10: [2024-10-29 13:16:10] iter = 03040, loss = 8.3761
2024-10-29 13:16:11: [2024-10-29 13:16:10] iter = 03050, loss = 8.2964
2024-10-29 13:16:11: [2024-10-29 13:16:11] iter = 03060, loss = 2.8919
2024-10-29 13:16:11: [2024-10-29 13:16:11] iter = 03070, loss = 3.2007
2024-10-29 13:16:12: [2024-10-29 13:16:12] iter = 03080, loss = 8.4681
2024-10-29 13:16:13: [2024-10-29 13:16:13] iter = 03090, loss = 9.4631
2024-10-29 13:16:13: [2024-10-29 13:16:13] iter = 03100, loss = 6.5478
2024-10-29 13:16:14: [2024-10-29 13:16:14] iter = 03110, loss = 4.4113
2024-10-29 13:16:14: [2024-10-29 13:16:14] iter = 03120, loss = 3.3986
2024-10-29 13:16:15: [2024-10-29 13:16:15] iter = 03130, loss = 18.0925
2024-10-29 13:16:15: [2024-10-29 13:16:15] iter = 03140, loss = 3.2581
2024-10-29 13:16:16: [2024-10-29 13:16:16] iter = 03150, loss = 32.3884
2024-10-29 13:16:16: [2024-10-29 13:16:16] iter = 03160, loss = 3.5018
2024-10-29 13:16:17: [2024-10-29 13:16:17] iter = 03170, loss = 46.0769
2024-10-29 13:16:17: [2024-10-29 13:16:17] iter = 03180, loss = 32.2324
2024-10-29 13:16:18: [2024-10-29 13:16:18] iter = 03190, loss = 7.8237
2024-10-29 13:16:18: [2024-10-29 13:16:18] iter = 03200, loss = 4.1975
2024-10-29 13:16:19: [2024-10-29 13:16:19] iter = 03210, loss = 28.5482
2024-10-29 13:16:19: [2024-10-29 13:16:19] iter = 03220, loss = 4.1775
2024-10-29 13:16:20: [2024-10-29 13:16:20] iter = 03230, loss = 8.8316
2024-10-29 13:16:20: [2024-10-29 13:16:20] iter = 03240, loss = 10.7732
2024-10-29 13:16:21: [2024-10-29 13:16:21] iter = 03250, loss = 4.3654
2024-10-29 13:16:22: [2024-10-29 13:16:22] iter = 03260, loss = 3.0347
2024-10-29 13:16:22: [2024-10-29 13:16:22] iter = 03270, loss = 6.0849
2024-10-29 13:16:23: [2024-10-29 13:16:23] iter = 03280, loss = 5.2238
2024-10-29 13:16:23: [2024-10-29 13:16:23] iter = 03290, loss = 15.6689
2024-10-29 13:16:24: [2024-10-29 13:16:24] iter = 03300, loss = 14.5135
2024-10-29 13:16:24: [2024-10-29 13:16:24] iter = 03310, loss = 5.1197
2024-10-29 13:16:25: [2024-10-29 13:16:25] iter = 03320, loss = 13.4912
2024-10-29 13:16:25: [2024-10-29 13:16:25] iter = 03330, loss = 3.3726
2024-10-29 13:16:26: [2024-10-29 13:16:26] iter = 03340, loss = 7.8545
2024-10-29 13:16:27: [2024-10-29 13:16:27] iter = 03350, loss = 11.0978
2024-10-29 13:16:27: [2024-10-29 13:16:27] iter = 03360, loss = 17.6588
2024-10-29 13:16:28: [2024-10-29 13:16:28] iter = 03370, loss = 3.5199
2024-10-29 13:16:28: [2024-10-29 13:16:28] iter = 03380, loss = 4.8769
2024-10-29 13:16:29: [2024-10-29 13:16:29] iter = 03390, loss = 5.4143
2024-10-29 13:16:29: [2024-10-29 13:16:29] iter = 03400, loss = 9.2000
2024-10-29 13:16:30: [2024-10-29 13:16:30] iter = 03410, loss = 3.1587
2024-10-29 13:16:30: [2024-10-29 13:16:30] iter = 03420, loss = 3.4503
2024-10-29 13:16:31: [2024-10-29 13:16:31] iter = 03430, loss = 5.0770
2024-10-29 13:16:31: [2024-10-29 13:16:31] iter = 03440, loss = 3.6885
2024-10-29 13:16:32: [2024-10-29 13:16:32] iter = 03450, loss = 4.1032
2024-10-29 13:16:33: [2024-10-29 13:16:33] iter = 03460, loss = 13.5754
2024-10-29 13:16:33: [2024-10-29 13:16:33] iter = 03470, loss = 3.6223
2024-10-29 13:16:34: [2024-10-29 13:16:34] iter = 03480, loss = 15.8059
2024-10-29 13:16:34: [2024-10-29 13:16:34] iter = 03490, loss = 6.0922
2024-10-29 13:16:35: [2024-10-29 13:16:35] iter = 03500, loss = 6.5178
2024-10-29 13:16:35: [2024-10-29 13:16:35] iter = 03510, loss = 4.3464
2024-10-29 13:16:36: [2024-10-29 13:16:36] iter = 03520, loss = 12.1929
2024-10-29 13:16:37: [2024-10-29 13:16:37] iter = 03530, loss = 10.1305
2024-10-29 13:16:37: [2024-10-29 13:16:37] iter = 03540, loss = 12.6190
2024-10-29 13:16:38: [2024-10-29 13:16:38] iter = 03550, loss = 5.8741
2024-10-29 13:16:38: [2024-10-29 13:16:38] iter = 03560, loss = 46.9167
2024-10-29 13:16:39: [2024-10-29 13:16:39] iter = 03570, loss = 3.7192
2024-10-29 13:16:39: [2024-10-29 13:16:39] iter = 03580, loss = 25.3902
2024-10-29 13:16:40: [2024-10-29 13:16:40] iter = 03590, loss = 4.7784
2024-10-29 13:16:40: [2024-10-29 13:16:40] iter = 03600, loss = 3.2020
2024-10-29 13:16:41: [2024-10-29 13:16:41] iter = 03610, loss = 4.3261
2024-10-29 13:16:41: [2024-10-29 13:16:41] iter = 03620, loss = 7.6584
2024-10-29 13:16:42: [2024-10-29 13:16:42] iter = 03630, loss = 4.1201
2024-10-29 13:16:42: [2024-10-29 13:16:42] iter = 03640, loss = 7.9625
2024-10-29 13:16:43: [2024-10-29 13:16:43] iter = 03650, loss = 2.7072
2024-10-29 13:16:43: [2024-10-29 13:16:43] iter = 03660, loss = 2.9468
2024-10-29 13:16:44: [2024-10-29 13:16:44] iter = 03670, loss = 4.3469
2024-10-29 13:16:45: [2024-10-29 13:16:45] iter = 03680, loss = 4.8042
2024-10-29 13:16:46: [2024-10-29 13:16:46] iter = 03690, loss = 6.1785
2024-10-29 13:16:46: [2024-10-29 13:16:46] iter = 03700, loss = 3.4940
2024-10-29 13:16:47: [2024-10-29 13:16:47] iter = 03710, loss = 9.4893
2024-10-29 13:16:47: [2024-10-29 13:16:47] iter = 03720, loss = 4.1035
2024-10-29 13:16:48: [2024-10-29 13:16:48] iter = 03730, loss = 3.4618
2024-10-29 13:16:48: [2024-10-29 13:16:48] iter = 03740, loss = 25.5941
2024-10-29 13:16:49: [2024-10-29 13:16:49] iter = 03750, loss = 2.7066
2024-10-29 13:16:49: [2024-10-29 13:16:49] iter = 03760, loss = 3.6508
2024-10-29 13:16:50: [2024-10-29 13:16:50] iter = 03770, loss = 5.3380
2024-10-29 13:16:50: [2024-10-29 13:16:50] iter = 03780, loss = 9.4158
2024-10-29 13:16:51: [2024-10-29 13:16:51] iter = 03790, loss = 6.0126
2024-10-29 13:16:51: [2024-10-29 13:16:51] iter = 03800, loss = 7.2959
2024-10-29 13:16:52: [2024-10-29 13:16:52] iter = 03810, loss = 3.7887
2024-10-29 13:16:52: [2024-10-29 13:16:52] iter = 03820, loss = 26.4476
2024-10-29 13:16:53: [2024-10-29 13:16:53] iter = 03830, loss = 2.6127
2024-10-29 13:16:53: [2024-10-29 13:16:53] iter = 03840, loss = 10.6250
2024-10-29 13:16:54: [2024-10-29 13:16:54] iter = 03850, loss = 2.3953
2024-10-29 13:16:54: [2024-10-29 13:16:54] iter = 03860, loss = 6.8302
2024-10-29 13:16:55: [2024-10-29 13:16:55] iter = 03870, loss = 53.3564
2024-10-29 13:16:55: [2024-10-29 13:16:55] iter = 03880, loss = 27.2021
2024-10-29 13:16:56: [2024-10-29 13:16:56] iter = 03890, loss = 8.1908
2024-10-29 13:16:56: [2024-10-29 13:16:56] iter = 03900, loss = 3.4360
2024-10-29 13:16:57: [2024-10-29 13:16:57] iter = 03910, loss = 11.5237
2024-10-29 13:16:58: [2024-10-29 13:16:58] iter = 03920, loss = 10.0842
2024-10-29 13:16:58: [2024-10-29 13:16:58] iter = 03930, loss = 6.2653
2024-10-29 13:16:59: [2024-10-29 13:16:59] iter = 03940, loss = 3.3092
2024-10-29 13:16:59: [2024-10-29 13:16:59] iter = 03950, loss = 8.0909
2024-10-29 13:17:00: [2024-10-29 13:17:00] iter = 03960, loss = 3.4043
2024-10-29 13:17:00: [2024-10-29 13:17:00] iter = 03970, loss = 2.9497
2024-10-29 13:17:01: [2024-10-29 13:17:01] iter = 03980, loss = 7.2313
2024-10-29 13:17:01: [2024-10-29 13:17:01] iter = 03990, loss = 4.4831
2024-10-29 13:17:02: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-29 13:17:02: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:17:02: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 22344}

[2024-10-29 12:58:49] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002182 train acc = 1.0000, test acc = 0.4130, test_sen =0.4130, test_spe =0.8043, test_f1 =0.3657
[2024-10-29 12:58:55] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.001910 train acc = 1.0000, test acc = 0.4480, test_sen =0.4480, test_spe =0.8160, test_f1 =0.3978
[2024-10-29 12:59:00] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.029274 train acc = 1.0000, test acc = 0.4380, test_sen =0.4380, test_spe =0.8127, test_f1 =0.3889
[2024-10-29 12:59:05] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.004624 train acc = 1.0000, test acc = 0.4360, test_sen =0.4360, test_spe =0.8120, test_f1 =0.3883
[2024-10-29 13:00:57] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.001384 train acc = 1.0000, test acc = 0.4360, test_sen =0.4360, test_spe =0.8120, test_f1 =0.3724
[2024-10-29 13:01:02] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001701 train acc = 1.0000, test acc = 0.4260, test_sen =0.4260, test_spe =0.8087, test_f1 =0.3646
[2024-10-29 13:01:09] Evaluate_02: epoch = 1000 train time = 6 s train loss = 0.021358 train acc = 1.0000, test acc = 0.4310, test_sen =0.4310, test_spe =0.8103, test_f1 =0.3681
[2024-10-29 13:01:14] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001948 train acc = 1.0000, test acc = 0.4290, test_sen =0.4290, test_spe =0.8097, test_f1 =0.3697
[2024-10-29 13:01:20] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.000685 train acc = 1.0000, test acc = 0.4270, test_sen =0.4270, test_spe =0.8090, test_f1 =0.3704
[2024-10-29 13:03:12] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.004353 train acc = 1.0000, test acc = 0.5680, test_sen =0.5680, test_spe =0.8560, test_f1 =0.5694
[2024-10-29 13:03:17] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.043178 train acc = 1.0000, test acc = 0.5530, test_sen =0.5530, test_spe =0.8510, test_f1 =0.5500
[2024-10-29 13:03:22] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.034113 train acc = 1.0000, test acc = 0.5540, test_sen =0.5540, test_spe =0.8513, test_f1 =0.5546
[2024-10-29 13:03:27] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001562 train acc = 1.0000, test acc = 0.5530, test_sen =0.5530, test_spe =0.8510, test_f1 =0.5560
[2024-10-29 13:03:33] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.052058 train acc = 1.0000, test acc = 0.5690, test_sen =0.5690, test_spe =0.8563, test_f1 =0.5669
[2024-10-29 13:05:24] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001157 train acc = 1.0000, test acc = 0.5110, test_sen =0.5110, test_spe =0.8370, test_f1 =0.5026
[2024-10-29 13:05:29] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.001163 train acc = 1.0000, test acc = 0.5210, test_sen =0.5210, test_spe =0.8403, test_f1 =0.5126
[2024-10-29 13:05:35] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.006966 train acc = 1.0000, test acc = 0.5160, test_sen =0.5160, test_spe =0.8387, test_f1 =0.5075
[2024-10-29 13:05:40] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.000753 train acc = 1.0000, test acc = 0.5250, test_sen =0.5250, test_spe =0.8417, test_f1 =0.5226
[2024-10-29 13:05:46] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.002238 train acc = 1.0000, test acc = 0.5060, test_sen =0.5060, test_spe =0.8353, test_f1 =0.4987
[2024-10-29 13:07:40] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002424 train acc = 1.0000, test acc = 0.3530, test_sen =0.3530, test_spe =0.7843, test_f1 =0.3060
[2024-10-29 13:07:46] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.000510 train acc = 1.0000, test acc = 0.3660, test_sen =0.3660, test_spe =0.7887, test_f1 =0.3213
[2024-10-29 13:07:51] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.002308 train acc = 1.0000, test acc = 0.3920, test_sen =0.3920, test_spe =0.7973, test_f1 =0.3434
[2024-10-29 13:07:56] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.001200 train acc = 1.0000, test acc = 0.3790, test_sen =0.3790, test_spe =0.7930, test_f1 =0.3430
[2024-10-29 13:08:01] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.044383 train acc = 1.0000, test acc = 0.3920, test_sen =0.3920, test_spe =0.7973, test_f1 =0.3425
[2024-10-29 13:09:51] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002712 train acc = 1.0000, test acc = 0.3740, test_sen =0.3740, test_spe =0.7913, test_f1 =0.3110
[2024-10-29 13:09:56] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.002231 train acc = 1.0000, test acc = 0.3820, test_sen =0.3820, test_spe =0.7940, test_f1 =0.3239
[2024-10-29 13:10:02] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.002713 train acc = 1.0000, test acc = 0.3740, test_sen =0.3740, test_spe =0.7913, test_f1 =0.3096
[2024-10-29 13:10:08] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001379 train acc = 1.0000, test acc = 0.3830, test_sen =0.3830, test_spe =0.7943, test_f1 =0.3298
[2024-10-29 13:10:14] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001588 train acc = 1.0000, test acc = 0.3740, test_sen =0.3740, test_spe =0.7913, test_f1 =0.3122
[2024-10-29 13:12:10] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.002366 train acc = 1.0000, test acc = 0.4720, test_sen =0.4720, test_spe =0.8240, test_f1 =0.4080
[2024-10-29 13:12:16] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.000853 train acc = 1.0000, test acc = 0.4490, test_sen =0.4490, test_spe =0.8163, test_f1 =0.3907
[2024-10-29 13:12:21] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.015574 train acc = 1.0000, test acc = 0.4600, test_sen =0.4600, test_spe =0.8200, test_f1 =0.3966
[2024-10-29 13:12:28] Evaluate_03: epoch = 1000 train time = 6 s train loss = 0.018137 train acc = 1.0000, test acc = 0.4670, test_sen =0.4670, test_spe =0.8223, test_f1 =0.4062
[2024-10-29 13:12:33] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.020185 train acc = 1.0000, test acc = 0.4640, test_sen =0.4640, test_spe =0.8213, test_f1 =0.3969
[2024-10-29 13:12:42] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.011736 train acc = 1.0000, test acc = 0.4630, test_sen =0.4630, test_spe =0.8210, test_f1 =0.4567
[2024-10-29 13:12:47] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.008374 train acc = 1.0000, test acc = 0.4610, test_sen =0.4610, test_spe =0.8203, test_f1 =0.4588
[2024-10-29 13:12:53] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.016802 train acc = 1.0000, test acc = 0.4520, test_sen =0.4520, test_spe =0.8173, test_f1 =0.4481
[2024-10-29 13:12:58] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.006460 train acc = 1.0000, test acc = 0.4640, test_sen =0.4640, test_spe =0.8213, test_f1 =0.4604
[2024-10-29 13:13:03] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.004969 train acc = 1.0000, test acc = 0.4470, test_sen =0.4470, test_spe =0.8157, test_f1 =0.4410
[2024-10-29 13:14:56] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000810 train acc = 1.0000, test acc = 0.3890, test_sen =0.3890, test_spe =0.7963, test_f1 =0.3273
[2024-10-29 13:15:01] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.000921 train acc = 1.0000, test acc = 0.4100, test_sen =0.4100, test_spe =0.8033, test_f1 =0.3492
[2024-10-29 13:15:06] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.022115 train acc = 1.0000, test acc = 0.3860, test_sen =0.3860, test_spe =0.7953, test_f1 =0.3241
[2024-10-29 13:15:11] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.017042 train acc = 1.0000, test acc = 0.3870, test_sen =0.3870, test_spe =0.7957, test_f1 =0.3211
[2024-10-29 13:15:16] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001411 train acc = 1.0000, test acc = 0.3510, test_sen =0.3510, test_spe =0.7837, test_f1 =0.2833
[2024-10-29 13:17:07] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.037329 train acc = 1.0000, test acc = 0.5410, test_sen =0.5410, test_spe =0.8470, test_f1 =0.4812
[2024-10-29 13:17:13] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.003926 train acc = 1.0000, test acc = 0.5290, test_sen =0.5290, test_spe =0.8430, test_f1 =0.4679
[2024-10-29 13:17:18] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.012173 train acc = 1.0000, test acc = 0.5190, test_sen =0.5190, test_spe =0.8397, test_f1 =0.4637/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:17:29: Evaluate 5 random ConvNet, ACCmean = 0.5374 ACCstd = 0.0131
-------------------------
2024-10-29 13:17:29: Evaluate 5 random ConvNet, SENmean = 0.5374 SENstd = 0.0131
-------------------------
2024-10-29 13:17:29: Evaluate 5 random ConvNet, SPEmean = 0.8458 SPEstd = 0.0044
-------------------------
2024-10-29 13:17:29: Evaluate 5 random ConvNet, F!mean = 0.4798 F!std = 0.0172
-------------------------
2024-10-29 13:17:29: Evaluate 5 random ConvNet, mean = 0.5374 std = 0.0131
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:17:29: [2024-10-29 13:17:29] iter = 04000, loss = 13.5713
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:17:29: [2024-10-29 13:17:29] iter = 04010, loss = 17.7923
2024-10-29 13:17:30: [2024-10-29 13:17:30] iter = 04020, loss = 3.2115
2024-10-29 13:17:30: [2024-10-29 13:17:30] iter = 04030, loss = 50.3271
2024-10-29 13:17:31: [2024-10-29 13:17:31] iter = 04040, loss = 13.4594
2024-10-29 13:17:32: [2024-10-29 13:17:32] iter = 04050, loss = 3.9276
2024-10-29 13:17:32: [2024-10-29 13:17:32] iter = 04060, loss = 2.8436
2024-10-29 13:17:33: [2024-10-29 13:17:33] iter = 04070, loss = 10.0434
2024-10-29 13:17:33: [2024-10-29 13:17:33] iter = 04080, loss = 10.7086
2024-10-29 13:17:34: [2024-10-29 13:17:34] iter = 04090, loss = 3.4257
2024-10-29 13:17:35: [2024-10-29 13:17:35] iter = 04100, loss = 4.5273
2024-10-29 13:17:35: [2024-10-29 13:17:35] iter = 04110, loss = 7.6568
2024-10-29 13:17:36: [2024-10-29 13:17:36] iter = 04120, loss = 5.8889
2024-10-29 13:17:36: [2024-10-29 13:17:36] iter = 04130, loss = 3.9722
2024-10-29 13:17:37: [2024-10-29 13:17:37] iter = 04140, loss = 6.0842
2024-10-29 13:17:37: [2024-10-29 13:17:37] iter = 04150, loss = 7.8509
2024-10-29 13:17:38: [2024-10-29 13:17:38] iter = 04160, loss = 4.5365
2024-10-29 13:17:38: [2024-10-29 13:17:38] iter = 04170, loss = 5.4133
2024-10-29 13:17:39: [2024-10-29 13:17:39] iter = 04180, loss = 3.1738
2024-10-29 13:17:39: [2024-10-29 13:17:39] iter = 04190, loss = 4.2062
2024-10-29 13:17:40: [2024-10-29 13:17:40] iter = 04200, loss = 11.4546
2024-10-29 13:17:40: [2024-10-29 13:17:40] iter = 04210, loss = 4.4532
2024-10-29 13:17:41: [2024-10-29 13:17:41] iter = 04220, loss = 4.4313
2024-10-29 13:17:41: [2024-10-29 13:17:41] iter = 04230, loss = 9.6786
2024-10-29 13:17:42: [2024-10-29 13:17:42] iter = 04240, loss = 5.1600
2024-10-29 13:17:42: [2024-10-29 13:17:42] iter = 04250, loss = 33.8117
2024-10-29 13:17:43: [2024-10-29 13:17:43] iter = 04260, loss = 3.2974
2024-10-29 13:17:44: [2024-10-29 13:17:44] iter = 04270, loss = 11.0813
2024-10-29 13:17:44: [2024-10-29 13:17:44] iter = 04280, loss = 10.7555
2024-10-29 13:17:45: [2024-10-29 13:17:45] iter = 04290, loss = 5.6720
2024-10-29 13:17:45: [2024-10-29 13:17:45] iter = 04300, loss = 3.7445
2024-10-29 13:17:46: [2024-10-29 13:17:46] iter = 04310, loss = 4.0528
2024-10-29 13:17:46: [2024-10-29 13:17:46] iter = 04320, loss = 3.1219
2024-10-29 13:17:47: [2024-10-29 13:17:47] iter = 04330, loss = 21.6667
2024-10-29 13:17:47: [2024-10-29 13:17:47] iter = 04340, loss = 23.1233
2024-10-29 13:17:48: [2024-10-29 13:17:48] iter = 04350, loss = 7.0178
2024-10-29 13:17:48: [2024-10-29 13:17:48] iter = 04360, loss = 5.7767
2024-10-29 13:17:49: [2024-10-29 13:17:49] iter = 04370, loss = 24.4810
2024-10-29 13:17:49: [2024-10-29 13:17:49] iter = 04380, loss = 4.7692
2024-10-29 13:17:50: [2024-10-29 13:17:50] iter = 04390, loss = 3.8183
2024-10-29 13:17:50: [2024-10-29 13:17:50] iter = 04400, loss = 4.9589
2024-10-29 13:17:51: [2024-10-29 13:17:51] iter = 04410, loss = 42.5971
2024-10-29 13:17:51: [2024-10-29 13:17:51] iter = 04420, loss = 41.4225
2024-10-29 13:17:52: [2024-10-29 13:17:52] iter = 04430, loss = 6.9439
2024-10-29 13:17:52: [2024-10-29 13:17:52] iter = 04440, loss = 5.3073
2024-10-29 13:17:53: [2024-10-29 13:17:52] iter = 04450, loss = 5.8182
2024-10-29 13:17:53: [2024-10-29 13:17:53] iter = 04460, loss = 9.0466
2024-10-29 13:17:54: [2024-10-29 13:17:54] iter = 04470, loss = 8.4186
2024-10-29 13:17:54: [2024-10-29 13:17:54] iter = 04480, loss = 6.2066
2024-10-29 13:17:55: [2024-10-29 13:17:55] iter = 04490, loss = 7.5216
2024-10-29 13:17:55: [2024-10-29 13:17:55] iter = 04500, loss = 4.6824
2024-10-29 13:17:56: [2024-10-29 13:17:56] iter = 04510, loss = 14.2093
2024-10-29 13:17:56: [2024-10-29 13:17:56] iter = 04520, loss = 3.0058
2024-10-29 13:17:57: [2024-10-29 13:17:57] iter = 04530, loss = 10.7343
2024-10-29 13:17:58: [2024-10-29 13:17:58] iter = 04540, loss = 2.8414
2024-10-29 13:17:58: [2024-10-29 13:17:58] iter = 04550, loss = 16.3143
2024-10-29 13:17:59: [2024-10-29 13:17:59] iter = 04560, loss = 13.2306
2024-10-29 13:18:00: [2024-10-29 13:18:00] iter = 04570, loss = 10.4977
2024-10-29 13:18:00: [2024-10-29 13:18:00] iter = 04580, loss = 8.0435
2024-10-29 13:18:01: [2024-10-29 13:18:01] iter = 04590, loss = 3.5435
2024-10-29 13:18:01: [2024-10-29 13:18:01] iter = 04600, loss = 4.9123
2024-10-29 13:18:02: [2024-10-29 13:18:02] iter = 04610, loss = 2.7673
2024-10-29 13:18:03: [2024-10-29 13:18:03] iter = 04620, loss = 11.4648
2024-10-29 13:18:03: [2024-10-29 13:18:03] iter = 04630, loss = 2.7777
2024-10-29 13:18:04: [2024-10-29 13:18:04] iter = 04640, loss = 5.4614
2024-10-29 13:18:04: [2024-10-29 13:18:04] iter = 04650, loss = 4.7922
2024-10-29 13:18:05: [2024-10-29 13:18:05] iter = 04660, loss = 8.1379
2024-10-29 13:18:05: [2024-10-29 13:18:05] iter = 04670, loss = 11.3716
2024-10-29 13:18:06: [2024-10-29 13:18:06] iter = 04680, loss = 3.0624
2024-10-29 13:18:06: [2024-10-29 13:18:06] iter = 04690, loss = 8.0412
2024-10-29 13:18:07: [2024-10-29 13:18:07] iter = 04700, loss = 10.4195
2024-10-29 13:18:07: [2024-10-29 13:18:07] iter = 04710, loss = 8.1547
2024-10-29 13:18:08: [2024-10-29 13:18:08] iter = 04720, loss = 15.6661
2024-10-29 13:18:08: [2024-10-29 13:18:08] iter = 04730, loss = 27.9998
2024-10-29 13:18:09: [2024-10-29 13:18:09] iter = 04740, loss = 3.8839
2024-10-29 13:18:09: [2024-10-29 13:18:09] iter = 04750, loss = 4.5212
2024-10-29 13:18:10: [2024-10-29 13:18:10] iter = 04760, loss = 32.5434
2024-10-29 13:18:10: [2024-10-29 13:18:10] iter = 04770, loss = 10.7167
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 04780, loss = 2.9680
2024-10-29 13:18:11: [2024-10-29 13:18:11] iter = 04790, loss = 7.1220
2024-10-29 13:18:12: [2024-10-29 13:18:12] iter = 04800, loss = 2.7322
2024-10-29 13:18:12: [2024-10-29 13:18:12] iter = 04810, loss = 3.2051
2024-10-29 13:18:13: [2024-10-29 13:18:13] iter = 04820, loss = 10.8132
2024-10-29 13:18:13: [2024-10-29 13:18:13] iter = 04830, loss = 4.1108
2024-10-29 13:18:14: [2024-10-29 13:18:14] iter = 04840, loss = 7.5622
2024-10-29 13:18:14: [2024-10-29 13:18:14] iter = 04850, loss = 28.4815
2024-10-29 13:18:15: [2024-10-29 13:18:15] iter = 04860, loss = 5.0761
2024-10-29 13:18:15: [2024-10-29 13:18:15] iter = 04870, loss = 4.9045
2024-10-29 13:18:16: [2024-10-29 13:18:16] iter = 04880, loss = 3.4078
2024-10-29 13:18:16: [2024-10-29 13:18:16] iter = 04890, loss = 2.3678
2024-10-29 13:18:17: [2024-10-29 13:18:17] iter = 04900, loss = 3.7779
2024-10-29 13:18:18: [2024-10-29 13:18:17] iter = 04910, loss = 25.1313
2024-10-29 13:18:18: [2024-10-29 13:18:18] iter = 04920, loss = 14.0363
2024-10-29 13:18:18: [2024-10-29 13:18:18] iter = 04930, loss = 4.1139
2024-10-29 13:18:19: [2024-10-29 13:18:19] iter = 04940, loss = 12.9291
2024-10-29 13:18:20: [2024-10-29 13:18:20] iter = 04950, loss = 29.0220
2024-10-29 13:18:20: [2024-10-29 13:18:20] iter = 04960, loss = 3.4777
2024-10-29 13:18:21: [2024-10-29 13:18:21] iter = 04970, loss = 18.8280
2024-10-29 13:18:21: [2024-10-29 13:18:21] iter = 04980, loss = 3.8984
2024-10-29 13:18:22: [2024-10-29 13:18:22] iter = 04990, loss = 8.5316
2024-10-29 13:18:22: [2024-10-29 13:18:22] iter = 05000, loss = 7.6965
2024-10-29 13:18:23: [2024-10-29 13:18:23] iter = 05010, loss = 3.5021
2024-10-29 13:18:23: [2024-10-29 13:18:23] iter = 05020, loss = 17.3973
2024-10-29 13:18:24: [2024-10-29 13:18:24] iter = 05030, loss = 12.1592
2024-10-29 13:18:24: [2024-10-29 13:18:24] iter = 05040, loss = 3.1300
2024-10-29 13:18:25: [2024-10-29 13:18:25] iter = 05050, loss = 32.5268
2024-10-29 13:18:26: [2024-10-29 13:18:26] iter = 05060, loss = 7.7231
2024-10-29 13:18:26: [2024-10-29 13:18:26] iter = 05070, loss = 5.0016
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 05080, loss = 13.2324
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 05090, loss = 3.4455
2024-10-29 13:18:27: [2024-10-29 13:18:27] iter = 05100, loss = 10.6982
2024-10-29 13:18:28: [2024-10-29 13:18:28] iter = 05110, loss = 6.1309
2024-10-29 13:18:29: [2024-10-29 13:18:29] iter = 05120, loss = 4.3222
2024-10-29 13:18:29: [2024-10-29 13:18:29] iter = 05130, loss = 3.9651
2024-10-29 13:18:30: [2024-10-29 13:18:30] iter = 05140, loss = 21.4404
2024-10-29 13:18:30: [2024-10-29 13:18:30] iter = 05150, loss = 4.0412
2024-10-29 13:18:31: [2024-10-29 13:18:31] iter = 05160, loss = 5.3072
2024-10-29 13:18:31: [2024-10-29 13:18:31] iter = 05170, loss = 5.0838
2024-10-29 13:18:32: [2024-10-29 13:18:32] iter = 05180, loss = 10.2040
2024-10-29 13:18:32: [2024-10-29 13:18:32] iter = 05190, loss = 2.3809
2024-10-29 13:18:33: [2024-10-29 13:18:33] iter = 05200, loss = 5.0535
2024-10-29 13:18:33: [2024-10-29 13:18:33] iter = 05210, loss = 3.7521
2024-10-29 13:18:34: [2024-10-29 13:18:34] iter = 05220, loss = 2.8717
2024-10-29 13:18:34: [2024-10-29 13:18:34] iter = 05230, loss = 9.6106
2024-10-29 13:18:35: [2024-10-29 13:18:35] iter = 05240, loss = 6.6711
2024-10-29 13:18:35: [2024-10-29 13:18:35] iter = 05250, loss = 3.7158
2024-10-29 13:18:36: [2024-10-29 13:18:36] iter = 05260, loss = 6.2047
2024-10-29 13:18:36: [2024-10-29 13:18:36] iter = 05270, loss = 5.4666
2024-10-29 13:18:37: [2024-10-29 13:18:37] iter = 05280, loss = 2.6067
2024-10-29 13:18:37: [2024-10-29 13:18:37] iter = 05290, loss = 16.4249
2024-10-29 13:18:38: [2024-10-29 13:18:38] iter = 05300, loss = 9.5806
2024-10-29 13:18:38: [2024-10-29 13:18:38] iter = 05310, loss = 33.0394
2024-10-29 13:18:39: [2024-10-29 13:18:39] iter = 05320, loss = 5.1577
2024-10-29 13:18:39: [2024-10-29 13:18:39] iter = 05330, loss = 5.5062
2024-10-29 13:18:40: [2024-10-29 13:18:40] iter = 05340, loss = 3.9699
2024-10-29 13:18:40: [2024-10-29 13:18:40] iter = 05350, loss = 13.8993
2024-10-29 13:18:41: [2024-10-29 13:18:41] iter = 05360, loss = 4.4026
2024-10-29 13:18:41: [2024-10-29 13:18:41] iter = 05370, loss = 3.4735
2024-10-29 13:18:42: [2024-10-29 13:18:42] iter = 05380, loss = 2.4359
2024-10-29 13:18:42: [2024-10-29 13:18:42] iter = 05390, loss = 3.9742
2024-10-29 13:18:43: [2024-10-29 13:18:43] iter = 05400, loss = 4.9896
2024-10-29 13:18:43: [2024-10-29 13:18:43] iter = 05410, loss = 4.1420
2024-10-29 13:18:44: [2024-10-29 13:18:44] iter = 05420, loss = 6.2170
2024-10-29 13:18:45: [2024-10-29 13:18:45] iter = 05430, loss = 18.0346
2024-10-29 13:18:45: [2024-10-29 13:18:45] iter = 05440, loss = 30.3481
2024-10-29 13:18:46: [2024-10-29 13:18:46] iter = 05450, loss = 24.6969
2024-10-29 13:18:46: [2024-10-29 13:18:46] iter = 05460, loss = 7.7987
2024-10-29 13:18:47: [2024-10-29 13:18:47] iter = 05470, loss = 5.5022
2024-10-29 13:18:47: [2024-10-29 13:18:47] iter = 05480, loss = 1.9352
2024-10-29 13:18:48: [2024-10-29 13:18:48] iter = 05490, loss = 2.3541
2024-10-29 13:18:48: [2024-10-29 13:18:48] iter = 05500, loss = 24.4156
2024-10-29 13:18:49: [2024-10-29 13:18:49] iter = 05510, loss = 9.1500
2024-10-29 13:18:49: [2024-10-29 13:18:49] iter = 05520, loss = 3.3523
2024-10-29 13:18:50: [2024-10-29 13:18:50] iter = 05530, loss = 4.0007
2024-10-29 13:18:50: [2024-10-29 13:18:50] iter = 05540, loss = 6.1617
2024-10-29 13:18:51: [2024-10-29 13:18:51] iter = 05550, loss = 2.7232
2024-10-29 13:18:52: [2024-10-29 13:18:52] iter = 05560, loss = 4.0421
2024-10-29 13:18:52: [2024-10-29 13:18:52] iter = 05570, loss = 6.2423
2024-10-29 13:18:52: [2024-10-29 13:18:52] iter = 05580, loss = 14.8843
2024-10-29 13:18:53: [2024-10-29 13:18:53] iter = 05590, loss = 2.6778
2024-10-29 13:18:53: [2024-10-29 13:18:53] iter = 05600, loss = 7.0582
2024-10-29 13:18:54: [2024-10-29 13:18:54] iter = 05610, loss = 5.3490
2024-10-29 13:18:54: [2024-10-29 13:18:54] iter = 05620, loss = 5.5410
2024-10-29 13:18:55: [2024-10-29 13:18:55] iter = 05630, loss = 5.1889
2024-10-29 13:18:56: [2024-10-29 13:18:56] iter = 05640, loss = 13.4025
2024-10-29 13:18:56: [2024-10-29 13:18:56] iter = 05650, loss = 9.9646
2024-10-29 13:18:57: [2024-10-29 13:18:57] iter = 05660, loss = 9.6892
2024-10-29 13:18:57: [2024-10-29 13:18:57] iter = 05670, loss = 8.0947
2024-10-29 13:18:58: [2024-10-29 13:18:58] iter = 05680, loss = 13.2868
2024-10-29 13:18:58: [2024-10-29 13:18:58] iter = 05690, loss = 2.6180
2024-10-29 13:18:59: [2024-10-29 13:18:59] iter = 05700, loss = 16.2170
2024-10-29 13:18:59: [2024-10-29 13:18:59] iter = 05710, loss = 2.4420
2024-10-29 13:19:00: [2024-10-29 13:19:00] iter = 05720, loss = 3.9488
2024-10-29 13:19:00: [2024-10-29 13:19:00] iter = 05730, loss = 8.6021
2024-10-29 13:19:01: [2024-10-29 13:19:01] iter = 05740, loss = 20.8601
2024-10-29 13:19:01: [2024-10-29 13:19:01] iter = 05750, loss = 4.5409
2024-10-29 13:19:01: [2024-10-29 13:19:01] iter = 05760, loss = 3.9672
2024-10-29 13:19:02: [2024-10-29 13:19:02] iter = 05770, loss = 10.8593
2024-10-29 13:19:02: [2024-10-29 13:19:02] iter = 05780, loss = 2.6256
2024-10-29 13:19:03: [2024-10-29 13:19:03] iter = 05790, loss = 2.4043
2024-10-29 13:19:04: [2024-10-29 13:19:04] iter = 05800, loss = 11.8660
2024-10-29 13:19:04: [2024-10-29 13:19:04] iter = 05810, loss = 3.7749
2024-10-29 13:19:04: [2024-10-29 13:19:04] iter = 05820, loss = 3.3601
2024-10-29 13:19:05: [2024-10-29 13:19:05] iter = 05830, loss = 13.3272
2024-10-29 13:19:06: [2024-10-29 13:19:06] iter = 05840, loss = 10.0080
2024-10-29 13:19:06: [2024-10-29 13:19:06] iter = 05850, loss = 39.0949
2024-10-29 13:19:07: [2024-10-29 13:19:07] iter = 05860, loss = 4.0313
2024-10-29 13:19:07: [2024-10-29 13:19:07] iter = 05870, loss = 2.5595
2024-10-29 13:19:08: [2024-10-29 13:19:08] iter = 05880, loss = 7.8875
2024-10-29 13:19:08: [2024-10-29 13:19:08] iter = 05890, loss = 3.1435
2024-10-29 13:19:09: [2024-10-29 13:19:09] iter = 05900, loss = 3.1692
2024-10-29 13:19:09: [2024-10-29 13:19:09] iter = 05910, loss = 4.3953
2024-10-29 13:19:10: [2024-10-29 13:19:10] iter = 05920, loss = 5.0942
2024-10-29 13:19:10: [2024-10-29 13:19:10] iter = 05930, loss = 2.8934
2024-10-29 13:19:11: [2024-10-29 13:19:11] iter = 05940, loss = 2.4390
2024-10-29 13:19:11: [2024-10-29 13:19:11] iter = 05950, loss = 12.1277
2024-10-29 13:19:12: [2024-10-29 13:19:12] iter = 05960, loss = 4.6761
2024-10-29 13:19:12: [2024-10-29 13:19:12] iter = 05970, loss = 7.4182
2024-10-29 13:19:13: [2024-10-29 13:19:13] iter = 05980, loss = 5.3400
2024-10-29 13:19:13: [2024-10-29 13:19:13] iter = 05990, loss = 4.9011
2024-10-29 13:19:13: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-29 13:19:13: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:19:13: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53943}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:39: Evaluate 5 random ConvNet, ACCmean = 0.4428 ACCstd = 0.0138
-------------------------
2024-10-29 13:19:39: Evaluate 5 random ConvNet, SENmean = 0.4428 SENstd = 0.0138
-------------------------
2024-10-29 13:19:39: Evaluate 5 random ConvNet, SPEmean = 0.8143 SPEstd = 0.0046
-------------------------
2024-10-29 13:19:39: Evaluate 5 random ConvNet, F!mean = 0.4305 F!std = 0.0214
-------------------------
2024-10-29 13:19:39: Evaluate 5 random ConvNet, mean = 0.4428 std = 0.0138
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:39: [2024-10-29 13:19:39] iter = 06000, loss = 8.4047
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:19:40: [2024-10-29 13:19:40] iter = 06010, loss = 3.9776
2024-10-29 13:19:40: [2024-10-29 13:19:40] iter = 06020, loss = 6.9900
2024-10-29 13:19:41: [2024-10-29 13:19:41] iter = 06030, loss = 4.3330
2024-10-29 13:19:41: [2024-10-29 13:19:41] iter = 06040, loss = 5.7732
2024-10-29 13:19:42: [2024-10-29 13:19:42] iter = 06050, loss = 3.9553
2024-10-29 13:19:42: [2024-10-29 13:19:42] iter = 06060, loss = 4.5156
2024-10-29 13:19:43: [2024-10-29 13:19:43] iter = 06070, loss = 5.5775
2024-10-29 13:19:43: [2024-10-29 13:19:43] iter = 06080, loss = 3.5099
2024-10-29 13:19:44: [2024-10-29 13:19:44] iter = 06090, loss = 5.0384
2024-10-29 13:19:44: [2024-10-29 13:19:44] iter = 06100, loss = 3.4435
2024-10-29 13:19:45: [2024-10-29 13:19:45] iter = 06110, loss = 38.7479
2024-10-29 13:19:45: [2024-10-29 13:19:45] iter = 06120, loss = 24.1167
2024-10-29 13:19:46: [2024-10-29 13:19:46] iter = 06130, loss = 4.8808
2024-10-29 13:19:46: [2024-10-29 13:19:46] iter = 06140, loss = 5.5888
2024-10-29 13:19:47: [2024-10-29 13:19:47] iter = 06150, loss = 32.3060
2024-10-29 13:19:47: [2024-10-29 13:19:47] iter = 06160, loss = 5.8141
2024-10-29 13:19:48: [2024-10-29 13:19:48] iter = 06170, loss = 6.8219
2024-10-29 13:19:49: [2024-10-29 13:19:49] iter = 06180, loss = 4.1612
2024-10-29 13:19:49: [2024-10-29 13:19:49] iter = 06190, loss = 3.0277
2024-10-29 13:19:50: [2024-10-29 13:19:50] iter = 06200, loss = 15.7922
2024-10-29 13:19:50: [2024-10-29 13:19:50] iter = 06210, loss = 4.8723
2024-10-29 13:19:51: [2024-10-29 13:19:51] iter = 06220, loss = 2.9829
2024-10-29 13:19:51: [2024-10-29 13:19:51] iter = 06230, loss = 6.7990
2024-10-29 13:19:52: [2024-10-29 13:19:52] iter = 06240, loss = 17.8895
2024-10-29 13:19:52: [2024-10-29 13:19:52] iter = 06250, loss = 23.9811
2024-10-29 13:19:53: [2024-10-29 13:19:53] iter = 06260, loss = 15.1773
2024-10-29 13:19:54: [2024-10-29 13:19:54] iter = 06270, loss = 4.4066
2024-10-29 13:19:54: [2024-10-29 13:19:54] iter = 06280, loss = 8.1709
2024-10-29 13:19:55: [2024-10-29 13:19:55] iter = 06290, loss = 10.2421
2024-10-29 13:19:55: [2024-10-29 13:19:55] iter = 06300, loss = 14.1633
2024-10-29 13:19:56: [2024-10-29 13:19:56] iter = 06310, loss = 5.9223
2024-10-29 13:19:56: [2024-10-29 13:19:56] iter = 06320, loss = 15.7349
2024-10-29 13:19:57: [2024-10-29 13:19:57] iter = 06330, loss = 2.2212
2024-10-29 13:19:57: [2024-10-29 13:19:57] iter = 06340, loss = 5.3066
2024-10-29 13:19:58: [2024-10-29 13:19:58] iter = 06350, loss = 48.4112
2024-10-29 13:19:58: [2024-10-29 13:19:58] iter = 06360, loss = 4.6117
2024-10-29 13:19:59: [2024-10-29 13:19:59] iter = 06370, loss = 3.7998
2024-10-29 13:19:59: [2024-10-29 13:19:59] iter = 06380, loss = 5.3543
2024-10-29 13:20:00: [2024-10-29 13:20:00] iter = 06390, loss = 10.8466
2024-10-29 13:20:00: [2024-10-29 13:20:00] iter = 06400, loss = 28.5385
2024-10-29 13:20:01: [2024-10-29 13:20:01] iter = 06410, loss = 9.3685
2024-10-29 13:20:01: [2024-10-29 13:20:01] iter = 06420, loss = 16.4508
2024-10-29 13:20:02: [2024-10-29 13:20:02] iter = 06430, loss = 5.5364
2024-10-29 13:20:02: [2024-10-29 13:20:02] iter = 06440, loss = 2.7464
2024-10-29 13:20:03: [2024-10-29 13:20:03] iter = 06450, loss = 5.2622
2024-10-29 13:20:03: [2024-10-29 13:20:03] iter = 06460, loss = 41.7204
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 06470, loss = 43.9628
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 06480, loss = 10.5471
2024-10-29 13:20:04: [2024-10-29 13:20:04] iter = 06490, loss = 5.5219
2024-10-29 13:20:05: [2024-10-29 13:20:05] iter = 06500, loss = 10.0070
2024-10-29 13:20:05: [2024-10-29 13:20:05] iter = 06510, loss = 6.4551
2024-10-29 13:20:06: [2024-10-29 13:20:06] iter = 06520, loss = 5.1380
2024-10-29 13:20:07: [2024-10-29 13:20:07] iter = 06530, loss = 5.1349
2024-10-29 13:20:07: [2024-10-29 13:20:07] iter = 06540, loss = 4.3801
2024-10-29 13:20:08: [2024-10-29 13:20:07] iter = 06550, loss = 2.5602
2024-10-29 13:20:08: [2024-10-29 13:20:08] iter = 06560, loss = 4.7643
2024-10-29 13:20:09: [2024-10-29 13:20:09] iter = 06570, loss = 44.2881
2024-10-29 13:20:09: [2024-10-29 13:20:09] iter = 06580, loss = 8.4244
2024-10-29 13:20:10: [2024-10-29 13:20:10] iter = 06590, loss = 5.3991
2024-10-29 13:20:10: [2024-10-29 13:20:10] iter = 06600, loss = 32.1491
2024-10-29 13:20:11: [2024-10-29 13:20:11] iter = 06610, loss = 5.0322
2024-10-29 13:20:11: [2024-10-29 13:20:11] iter = 06620, loss = 18.2890
2024-10-29 13:20:12: [2024-10-29 13:20:12] iter = 06630, loss = 12.8215
2024-10-29 13:20:12: [2024-10-29 13:20:12] iter = 06640, loss = 30.0865
2024-10-29 13:20:13: [2024-10-29 13:20:13] iter = 06650, loss = 4.7710
2024-10-29 13:20:13: [2024-10-29 13:20:13] iter = 06660, loss = 25.9538
2024-10-29 13:20:14: [2024-10-29 13:20:14] iter = 06670, loss = 15.2636
2024-10-29 13:20:14: [2024-10-29 13:20:14] iter = 06680, loss = 6.9568
2024-10-29 13:20:15: [2024-10-29 13:20:15] iter = 06690, loss = 4.2304
2024-10-29 13:20:15: [2024-10-29 13:20:15] iter = 06700, loss = 7.1368
2024-10-29 13:20:16: [2024-10-29 13:20:16] iter = 06710, loss = 9.0341
2024-10-29 13:20:17: [2024-10-29 13:20:17] iter = 06720, loss = 9.7523
2024-10-29 13:20:18: [2024-10-29 13:20:18] iter = 06730, loss = 2.9222
2024-10-29 13:20:18: [2024-10-29 13:20:18] iter = 06740, loss = 6.4092
2024-10-29 13:20:19: [2024-10-29 13:20:19] iter = 06750, loss = 5.2569
2024-10-29 13:20:19: [2024-10-29 13:20:19] iter = 06760, loss = 3.4784
2024-10-29 13:20:20: [2024-10-29 13:20:20] iter = 06770, loss = 2.6224
2024-10-29 13:20:20: [2024-10-29 13:20:20] iter = 06780, loss = 3.2319
2024-10-29 13:20:21: [2024-10-29 13:20:21] iter = 06790, loss = 19.3833
2024-10-29 13:20:21: [2024-10-29 13:20:21] iter = 06800, loss = 5.0411
2024-10-29 13:20:22: [2024-10-29 13:20:22] iter = 06810, loss = 3.3930
2024-10-29 13:20:23: [2024-10-29 13:20:23] iter = 06820, loss = 3.2705
2024-10-29 13:20:23: [2024-10-29 13:20:23] iter = 06830, loss = 12.4586
2024-10-29 13:20:24: [2024-10-29 13:20:24] iter = 06840, loss = 11.8905
2024-10-29 13:20:24: [2024-10-29 13:20:24] iter = 06850, loss = 2.6507
2024-10-29 13:20:25: [2024-10-29 13:20:25] iter = 06860, loss = 27.5423
2024-10-29 13:20:26: [2024-10-29 13:20:26] iter = 06870, loss = 3.2324
2024-10-29 13:20:26: [2024-10-29 13:20:26] iter = 06880, loss = 10.1850
2024-10-29 13:20:27: [2024-10-29 13:20:27] iter = 06890, loss = 9.6108
2024-10-29 13:20:27: [2024-10-29 13:20:27] iter = 06900, loss = 41.5474
2024-10-29 13:20:28: [2024-10-29 13:20:28] iter = 06910, loss = 3.7317
2024-10-29 13:20:28: [2024-10-29 13:20:28] iter = 06920, loss = 14.0437
2024-10-29 13:20:29: [2024-10-29 13:20:29] iter = 06930, loss = 4.8187
2024-10-29 13:20:29: [2024-10-29 13:20:29] iter = 06940, loss = 36.1054
2024-10-29 13:20:30: [2024-10-29 13:20:30] iter = 06950, loss = 4.2710
2024-10-29 13:20:30: [2024-10-29 13:20:30] iter = 06960, loss = 4.1845
2024-10-29 13:20:31: [2024-10-29 13:20:31] iter = 06970, loss = 6.8227
2024-10-29 13:20:31: [2024-10-29 13:20:31] iter = 06980, loss = 2.4489
2024-10-29 13:20:32: [2024-10-29 13:20:32] iter = 06990, loss = 7.8299
2024-10-29 13:20:32: [2024-10-29 13:20:32] iter = 07000, loss = 8.7462
2024-10-29 13:20:33: [2024-10-29 13:20:33] iter = 07010, loss = 3.2791
2024-10-29 13:20:33: [2024-10-29 13:20:33] iter = 07020, loss = 12.6502
2024-10-29 13:20:34: [2024-10-29 13:20:34] iter = 07030, loss = 12.4455
2024-10-29 13:20:34: [2024-10-29 13:20:34] iter = 07040, loss = 3.7100
2024-10-29 13:20:35: [2024-10-29 13:20:35] iter = 07050, loss = 3.0037
2024-10-29 13:20:36: [2024-10-29 13:20:36] iter = 07060, loss = 10.5962
2024-10-29 13:20:36: [2024-10-29 13:20:36] iter = 07070, loss = 13.4469
2024-10-29 13:20:37: [2024-10-29 13:20:37] iter = 07080, loss = 25.3146
2024-10-29 13:20:38: [2024-10-29 13:20:38] iter = 07090, loss = 7.0170
2024-10-29 13:20:38: [2024-10-29 13:20:38] iter = 07100, loss = 2.7554
2024-10-29 13:20:39: [2024-10-29 13:20:39] iter = 07110, loss = 4.3250
2024-10-29 13:20:40: [2024-10-29 13:20:40] iter = 07120, loss = 10.2768
2024-10-29 13:20:40: [2024-10-29 13:20:40] iter = 07130, loss = 2.6519
2024-10-29 13:20:41: [2024-10-29 13:20:41] iter = 07140, loss = 7.8389
2024-10-29 13:20:42: [2024-10-29 13:20:42] iter = 07150, loss = 4.8766
2024-10-29 13:20:42: [2024-10-29 13:20:42] iter = 07160, loss = 25.8319
2024-10-29 13:20:43: [2024-10-29 13:20:43] iter = 07170, loss = 4.5446
2024-10-29 13:20:43: [2024-10-29 13:20:43] iter = 07180, loss = 9.4905
2024-10-29 13:20:44: [2024-10-29 13:20:44] iter = 07190, loss = 2.6286
2024-10-29 13:20:44: [2024-10-29 13:20:44] iter = 07200, loss = 4.2086
2024-10-29 13:20:45: [2024-10-29 13:20:45] iter = 07210, loss = 9.1220
2024-10-29 13:20:46: [2024-10-29 13:20:46] iter = 07220, loss = 38.6050
2024-10-29 13:20:46: [2024-10-29 13:20:46] iter = 07230, loss = 4.4824
2024-10-29 13:20:47: [2024-10-29 13:20:47] iter = 07240, loss = 11.1045
2024-10-29 13:20:47: [2024-10-29 13:20:47] iter = 07250, loss = 12.0749
2024-10-29 13:20:48: [2024-10-29 13:20:48] iter = 07260, loss = 11.3142
2024-10-29 13:20:48: [2024-10-29 13:20:48] iter = 07270, loss = 3.2124
2024-10-29 13:20:49: [2024-10-29 13:20:49] iter = 07280, loss = 15.8673
2024-10-29 13:20:49: [2024-10-29 13:20:49] iter = 07290, loss = 3.2758
2024-10-29 13:20:50: [2024-10-29 13:20:50] iter = 07300, loss = 3.9536
2024-10-29 13:20:50: [2024-10-29 13:20:50] iter = 07310, loss = 29.9360
2024-10-29 13:20:51: [2024-10-29 13:20:51] iter = 07320, loss = 8.4329
2024-10-29 13:20:51: [2024-10-29 13:20:51] iter = 07330, loss = 3.7529
2024-10-29 13:20:52: [2024-10-29 13:20:52] iter = 07340, loss = 2.9539
2024-10-29 13:20:53: [2024-10-29 13:20:53] iter = 07350, loss = 4.5283
2024-10-29 13:20:53: [2024-10-29 13:20:53] iter = 07360, loss = 9.7587
2024-10-29 13:20:54: [2024-10-29 13:20:54] iter = 07370, loss = 6.3152
2024-10-29 13:20:54: [2024-10-29 13:20:54] iter = 07380, loss = 12.3853
2024-10-29 13:20:55: [2024-10-29 13:20:55] iter = 07390, loss = 33.8671
2024-10-29 13:20:55: [2024-10-29 13:20:55] iter = 07400, loss = 17.6336
2024-10-29 13:20:56: [2024-10-29 13:20:56] iter = 07410, loss = 8.8207
2024-10-29 13:20:56: [2024-10-29 13:20:56] iter = 07420, loss = 11.7862
2024-10-29 13:20:57: [2024-10-29 13:20:57] iter = 07430, loss = 46.0887
2024-10-29 13:20:57: [2024-10-29 13:20:57] iter = 07440, loss = 21.5679
2024-10-29 13:20:58: [2024-10-29 13:20:58] iter = 07450, loss = 22.1191
2024-10-29 13:20:59: [2024-10-29 13:20:59] iter = 07460, loss = 13.8374
2024-10-29 13:20:59: [2024-10-29 13:20:59] iter = 07470, loss = 7.8112
2024-10-29 13:20:59: [2024-10-29 13:20:59] iter = 07480, loss = 11.1193
2024-10-29 13:21:00: [2024-10-29 13:21:00] iter = 07490, loss = 9.4775
2024-10-29 13:21:01: [2024-10-29 13:21:01] iter = 07500, loss = 5.9977
2024-10-29 13:21:01: [2024-10-29 13:21:01] iter = 07510, loss = 10.2984
2024-10-29 13:21:01: [2024-10-29 13:21:01] iter = 07520, loss = 28.9589
2024-10-29 13:21:02: [2024-10-29 13:21:02] iter = 07530, loss = 3.9241
2024-10-29 13:21:02: [2024-10-29 13:21:02] iter = 07540, loss = 8.1389
2024-10-29 13:21:03: [2024-10-29 13:21:03] iter = 07550, loss = 11.3844
2024-10-29 13:21:04: [2024-10-29 13:21:04] iter = 07560, loss = 3.7831
2024-10-29 13:21:04: [2024-10-29 13:21:04] iter = 07570, loss = 5.8914
2024-10-29 13:21:05: [2024-10-29 13:21:05] iter = 07580, loss = 20.6524
2024-10-29 13:21:05: [2024-10-29 13:21:05] iter = 07590, loss = 3.8351
2024-10-29 13:21:06: [2024-10-29 13:21:06] iter = 07600, loss = 8.7621
2024-10-29 13:21:06: [2024-10-29 13:21:06] iter = 07610, loss = 7.5452
2024-10-29 13:21:07: [2024-10-29 13:21:07] iter = 07620, loss = 6.3060
2024-10-29 13:21:08: [2024-10-29 13:21:08] iter = 07630, loss = 50.3821
2024-10-29 13:21:08: [2024-10-29 13:21:08] iter = 07640, loss = 5.8542
2024-10-29 13:21:09: [2024-10-29 13:21:09] iter = 07650, loss = 4.6409
2024-10-29 13:21:10: [2024-10-29 13:21:10] iter = 07660, loss = 4.3731
2024-10-29 13:21:10: [2024-10-29 13:21:10] iter = 07670, loss = 12.3282
2024-10-29 13:21:11: [2024-10-29 13:21:11] iter = 07680, loss = 2.3103
2024-10-29 13:21:11: [2024-10-29 13:21:11] iter = 07690, loss = 15.3080
2024-10-29 13:21:12: [2024-10-29 13:21:12] iter = 07700, loss = 17.0316
2024-10-29 13:21:12: [2024-10-29 13:21:12] iter = 07710, loss = 7.2588
2024-10-29 13:21:13: [2024-10-29 13:21:13] iter = 07720, loss = 3.2221
2024-10-29 13:21:13: [2024-10-29 13:21:13] iter = 07730, loss = 16.5724
2024-10-29 13:21:14: [2024-10-29 13:21:14] iter = 07740, loss = 7.4036
2024-10-29 13:21:14: [2024-10-29 13:21:14] iter = 07750, loss = 10.9130
2024-10-29 13:21:15: [2024-10-29 13:21:15] iter = 07760, loss = 8.3648
2024-10-29 13:21:16: [2024-10-29 13:21:16] iter = 07770, loss = 4.5252
2024-10-29 13:21:16: [2024-10-29 13:21:16] iter = 07780, loss = 5.3257
2024-10-29 13:21:17: [2024-10-29 13:21:17] iter = 07790, loss = 16.6463
2024-10-29 13:21:18: [2024-10-29 13:21:18] iter = 07800, loss = 11.8759
2024-10-29 13:21:18: [2024-10-29 13:21:18] iter = 07810, loss = 6.0157
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 07820, loss = 6.0865
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 07830, loss = 15.2563
2024-10-29 13:21:19: [2024-10-29 13:21:19] iter = 07840, loss = 3.6892
2024-10-29 13:21:20: [2024-10-29 13:21:20] iter = 07850, loss = 5.3133
2024-10-29 13:21:20: [2024-10-29 13:21:20] iter = 07860, loss = 6.7300
2024-10-29 13:21:21: [2024-10-29 13:21:21] iter = 07870, loss = 3.4519
2024-10-29 13:21:21: [2024-10-29 13:21:21] iter = 07880, loss = 27.8444
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 07890, loss = 6.6754
2024-10-29 13:21:22: [2024-10-29 13:21:22] iter = 07900, loss = 18.8812
2024-10-29 13:21:23: [2024-10-29 13:21:23] iter = 07910, loss = 8.4364
2024-10-29 13:21:23: [2024-10-29 13:21:23] iter = 07920, loss = 4.1950
2024-10-29 13:21:24: [2024-10-29 13:21:24] iter = 07930, loss = 6.6039
2024-10-29 13:21:24: [2024-10-29 13:21:24] iter = 07940, loss = 22.1789
2024-10-29 13:21:25: [2024-10-29 13:21:25] iter = 07950, loss = 9.1762
2024-10-29 13:21:25: [2024-10-29 13:21:25] iter = 07960, loss = 40.3233
2024-10-29 13:21:26: [2024-10-29 13:21:26] iter = 07970, loss = 3.5732
2024-10-29 13:21:26: [2024-10-29 13:21:26] iter = 07980, loss = 5.7178
2024-10-29 13:21:27: [2024-10-29 13:21:27] iter = 07990, loss = 33.4527
2024-10-29 13:21:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-29 13:21:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:21:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 87851}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:21:56: Evaluate 5 random ConvNet, ACCmean = 0.4542 ACCstd = 0.0044
-------------------------
2024-10-29 13:21:56: Evaluate 5 random ConvNet, SENmean = 0.4542 SENstd = 0.0044
-------------------------
2024-10-29 13:21:56: Evaluate 5 random ConvNet, SPEmean = 0.8181 SPEstd = 0.0015
-------------------------
2024-10-29 13:21:56: Evaluate 5 random ConvNet, F!mean = 0.3934 F!std = 0.0031
-------------------------
2024-10-29 13:21:56: Evaluate 5 random ConvNet, mean = 0.4542 std = 0.0044
-------------------------
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 08000, loss = 6.0930
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 08010, loss = 3.1836
2024-10-29 13:21:56: [2024-10-29 13:21:56] iter = 08020, loss = 2.2427
2024-10-29 13:21:57: [2024-10-29 13:21:57] iter = 08030, loss = 2.2461
2024-10-29 13:21:58: [2024-10-29 13:21:58] iter = 08040, loss = 3.6948
2024-10-29 13:21:58: [2024-10-29 13:21:58] iter = 08050, loss = 7.9871
2024-10-29 13:21:59: [2024-10-29 13:21:59] iter = 08060, loss = 1.9074
2024-10-29 13:21:59: [2024-10-29 13:21:59] iter = 08070, loss = 6.8747
2024-10-29 13:22:00: [2024-10-29 13:22:00] iter = 08080, loss = 3.7370
2024-10-29 13:22:00: [2024-10-29 13:22:00] iter = 08090, loss = 3.0297
2024-10-29 13:22:01: [2024-10-29 13:22:01] iter = 08100, loss = 4.0318
2024-10-29 13:22:02: [2024-10-29 13:22:02] iter = 08110, loss = 4.7183
2024-10-29 13:22:02: [2024-10-29 13:22:02] iter = 08120, loss = 2.3050
2024-10-29 13:22:03: [2024-10-29 13:22:03] iter = 08130, loss = 14.6277
2024-10-29 13:22:03: [2024-10-29 13:22:03] iter = 08140, loss = 4.7816
2024-10-29 13:22:04: [2024-10-29 13:22:04] iter = 08150, loss = 4.7619
2024-10-29 13:22:04: [2024-10-29 13:22:04] iter = 08160, loss = 4.5994
2024-10-29 13:22:05: [2024-10-29 13:22:05] iter = 08170, loss = 14.8546
2024-10-29 13:22:05: [2024-10-29 13:22:05] iter = 08180, loss = 4.5372
2024-10-29 13:22:06: [2024-10-29 13:22:06] iter = 08190, loss = 6.5229
2024-10-29 13:22:06: [2024-10-29 13:22:06] iter = 08200, loss = 4.0942
2024-10-29 13:22:07: [2024-10-29 13:22:07] iter = 08210, loss = 2.6864
2024-10-29 13:22:07: [2024-10-29 13:22:07] iter = 08220, loss = 3.3782
2024-10-29 13:22:08: [2024-10-29 13:22:08] iter = 08230, loss = 20.4130
2024-10-29 13:22:08: [2024-10-29 13:22:08] iter = 08240, loss = 7.9113
2024-10-29 13:22:09: [2024-10-29 13:22:09] iter = 08250, loss = 4.2047
2024-10-29 13:22:09: [2024-10-29 13:22:09] iter = 08260, loss = 6.0233
2024-10-29 13:22:10: [2024-10-29 13:22:10] iter = 08270, loss = 3.3915
2024-10-29 13:22:10: [2024-10-29 13:22:10] iter = 08280, loss = 23.9316
2024-10-29 13:22:11: [2024-10-29 13:22:11] iter = 08290, loss = 5.9385
2024-10-29 13:22:12: [2024-10-29 13:22:12] iter = 08300, loss = 27.7222
2024-10-29 13:22:12: [2024-10-29 13:22:12] iter = 08310, loss = 5.0146
2024-10-29 13:22:13: [2024-10-29 13:22:13] iter = 08320, loss = 13.2843
2024-10-29 13:22:13: [2024-10-29 13:22:13] iter = 08330, loss = 5.0526
2024-10-29 13:22:14: [2024-10-29 13:22:14] iter = 08340, loss = 27.4481
2024-10-29 13:22:14: [2024-10-29 13:22:14] iter = 08350, loss = 20.7706
2024-10-29 13:22:15: [2024-10-29 13:22:15] iter = 08360, loss = 8.2209
2024-10-29 13:22:15: [2024-10-29 13:22:15] iter = 08370, loss = 3.2959
2024-10-29 13:22:16: [2024-10-29 13:22:16] iter = 08380, loss = 4.5774
2024-10-29 13:22:16: [2024-10-29 13:22:16] iter = 08390, loss = 4.3704
2024-10-29 13:22:17: [2024-10-29 13:22:17] iter = 08400, loss = 5.6428
2024-10-29 13:22:17: [2024-10-29 13:22:17] iter = 08410, loss = 5.5864
2024-10-29 13:22:18: [2024-10-29 13:22:18] iter = 08420, loss = 4.3541
2024-10-29 13:22:19: [2024-10-29 13:22:19] iter = 08430, loss = 2.4869
2024-10-29 13:22:19: [2024-10-29 13:22:19] iter = 08440, loss = 10.8151
2024-10-29 13:22:20: [2024-10-29 13:22:20] iter = 08450, loss = 5.4897
2024-10-29 13:22:20: [2024-10-29 13:22:20] iter = 08460, loss = 2.4072
2024-10-29 13:22:21: [2024-10-29 13:22:21] iter = 08470, loss = 17.3915
2024-10-29 13:22:21: [2024-10-29 13:22:21] iter = 08480, loss = 5.9662
2024-10-29 13:22:22: [2024-10-29 13:22:22] iter = 08490, loss = 4.4639
2024-10-29 13:22:22: [2024-10-29 13:22:22] iter = 08500, loss = 6.2960
2024-10-29 13:22:23: [2024-10-29 13:22:23] iter = 08510, loss = 3.0915
2024-10-29 13:22:23: [2024-10-29 13:22:23] iter = 08520, loss = 4.4484
2024-10-29 13:22:24: [2024-10-29 13:22:24] iter = 08530, loss = 2.7896
2024-10-29 13:22:25: [2024-10-29 13:22:25] iter = 08540, loss = 3.4859
2024-10-29 13:22:25: [2024-10-29 13:22:25] iter = 08550, loss = 20.4092
2024-10-29 13:22:26: [2024-10-29 13:22:26] iter = 08560, loss = 2.5432
2024-10-29 13:22:26: [2024-10-29 13:22:26] iter = 08570, loss = 9.9283
2024-10-29 13:22:27: [2024-10-29 13:22:27] iter = 08580, loss = 3.2814
2024-10-29 13:22:27: [2024-10-29 13:22:27] iter = 08590, loss = 3.3783
2024-10-29 13:22:28: [2024-10-29 13:22:28] iter = 08600, loss = 12.2465
2024-10-29 13:22:28: [2024-10-29 13:22:28] iter = 08610, loss = 8.1680
2024-10-29 13:22:29: [2024-10-29 13:22:29] iter = 08620, loss = 3.9075
2024-10-29 13:22:29: [2024-10-29 13:22:29] iter = 08630, loss = 4.9278
2024-10-29 13:22:30: [2024-10-29 13:22:30] iter = 08640, loss = 21.9502
2024-10-29 13:22:30: [2024-10-29 13:22:30] iter = 08650, loss = 20.0404
2024-10-29 13:22:31: [2024-10-29 13:22:31] iter = 08660, loss = 3.6490
2024-10-29 13:22:31: [2024-10-29 13:22:31] iter = 08670, loss = 4.7889
2024-10-29 13:22:32: [2024-10-29 13:22:32] iter = 08680, loss = 4.5401
2024-10-29 13:22:32: [2024-10-29 13:22:32] iter = 08690, loss = 6.8896
2024-10-29 13:22:33: [2024-10-29 13:22:33] iter = 08700, loss = 4.1068
2024-10-29 13:22:34: [2024-10-29 13:22:34] iter = 08710, loss = 3.3344
2024-10-29 13:22:34: [2024-10-29 13:22:34] iter = 08720, loss = 3.7451
2024-10-29 13:22:35: [2024-10-29 13:22:35] iter = 08730, loss = 5.0723
2024-10-29 13:22:36: [2024-10-29 13:22:36] iter = 08740, loss = 2.6890
2024-10-29 13:22:36: [2024-10-29 13:22:36] iter = 08750, loss = 4.7741
2024-10-29 13:22:36: [2024-10-29 13:22:36] iter = 08760, loss = 3.5074
2024-10-29 13:22:37: [2024-10-29 13:22:37] iter = 08770, loss = 7.5502
2024-10-29 13:22:38: [2024-10-29 13:22:38] iter = 08780, loss = 3.5277
2024-10-29 13:22:38: [2024-10-29 13:22:38] iter = 08790, loss = 5.2645
2024-10-29 13:22:39: [2024-10-29 13:22:39] iter = 08800, loss = 5.6192
2024-10-29 13:22:39: [2024-10-29 13:22:39] iter = 08810, loss = 4.6782
2024-10-29 13:22:40: [2024-10-29 13:22:40] iter = 08820, loss = 21.3736
2024-10-29 13:22:40: [2024-10-29 13:22:40] iter = 08830, loss = 62.6987
2024-10-29 13:22:41: [2024-10-29 13:22:41] iter = 08840, loss = 4.7002
2024-10-29 13:22:41: [2024-10-29 13:22:41] iter = 08850, loss = 4.7493
2024-10-29 13:22:42: [2024-10-29 13:22:42] iter = 08860, loss = 12.6451
2024-10-29 13:22:42: [2024-10-29 13:22:42] iter = 08870, loss = 7.2919
2024-10-29 13:22:43: [2024-10-29 13:22:43] iter = 08880, loss = 10.4667
2024-10-29 13:22:43: [2024-10-29 13:22:43] iter = 08890, loss = 2.5441
2024-10-29 13:22:44: [2024-10-29 13:22:44] iter = 08900, loss = 11.2326
2024-10-29 13:22:44: [2024-10-29 13:22:44] iter = 08910, loss = 3.1796
2024-10-29 13:22:45: [2024-10-29 13:22:45] iter = 08920, loss = 4.5336
2024-10-29 13:22:45: [2024-10-29 13:22:45] iter = 08930, loss = 38.4295
2024-10-29 13:22:46: [2024-10-29 13:22:46] iter = 08940, loss = 17.5826
2024-10-29 13:22:47: [2024-10-29 13:22:47] iter = 08950, loss = 8.8058
2024-10-29 13:22:47: [2024-10-29 13:22:47] iter = 08960, loss = 10.7869
2024-10-29 13:22:48: [2024-10-29 13:22:48] iter = 08970, loss = 8.1588
2024-10-29 13:22:48: [2024-10-29 13:22:48] iter = 08980, loss = 4.6678
2024-10-29 13:22:49: [2024-10-29 13:22:49] iter = 08990, loss = 4.1796
2024-10-29 13:22:50: [2024-10-29 13:22:50] iter = 09000, loss = 2.8146
2024-10-29 13:22:50: [2024-10-29 13:22:50] iter = 09010, loss = 2.9541
2024-10-29 13:22:51: [2024-10-29 13:22:51] iter = 09020, loss = 7.8220
2024-10-29 13:22:51: [2024-10-29 13:22:51] iter = 09030, loss = 6.9607
2024-10-29 13:22:51: [2024-10-29 13:22:51] iter = 09040, loss = 6.0072
2024-10-29 13:22:52: [2024-10-29 13:22:52] iter = 09050, loss = 4.2044
2024-10-29 13:22:52: [2024-10-29 13:22:52] iter = 09060, loss = 10.8278
2024-10-29 13:22:53: [2024-10-29 13:22:53] iter = 09070, loss = 3.7030
2024-10-29 13:22:54: [2024-10-29 13:22:54] iter = 09080, loss = 5.2022
2024-10-29 13:22:54: [2024-10-29 13:22:54] iter = 09090, loss = 2.8950
2024-10-29 13:22:55: [2024-10-29 13:22:55] iter = 09100, loss = 17.8641
2024-10-29 13:22:55: [2024-10-29 13:22:55] iter = 09110, loss = 4.2541
2024-10-29 13:22:56: [2024-10-29 13:22:56] iter = 09120, loss = 18.3531
2024-10-29 13:22:57: [2024-10-29 13:22:57] iter = 09130, loss = 7.0404
2024-10-29 13:22:57: [2024-10-29 13:22:57] iter = 09140, loss = 4.0736
2024-10-29 13:22:58: [2024-10-29 13:22:58] iter = 09150, loss = 3.4115
2024-10-29 13:22:58: [2024-10-29 13:22:58] iter = 09160, loss = 5.1546
2024-10-29 13:22:59: [2024-10-29 13:22:59] iter = 09170, loss = 3.6161
2024-10-29 13:23:00: [2024-10-29 13:23:00] iter = 09180, loss = 16.2066
2024-10-29 13:23:00: [2024-10-29 13:23:00] iter = 09190, loss = 5.9720
2024-10-29 13:23:01: [2024-10-29 13:23:01] iter = 09200, loss = 5.6576
2024-10-29 13:23:01: [2024-10-29 13:23:01] iter = 09210, loss = 11.9879
2024-10-29 13:23:02: [2024-10-29 13:23:02] iter = 09220, loss = 6.8595
2024-10-29 13:23:02: [2024-10-29 13:23:02] iter = 09230, loss = 9.0158
2024-10-29 13:23:03: [2024-10-29 13:23:03] iter = 09240, loss = 2.9162
2024-10-29 13:23:03: [2024-10-29 13:23:03] iter = 09250, loss = 8.5505
2024-10-29 13:23:04: [2024-10-29 13:23:04] iter = 09260, loss = 4.9214
2024-10-29 13:23:04: [2024-10-29 13:23:04] iter = 09270, loss = 5.6687
2024-10-29 13:23:05: [2024-10-29 13:23:05] iter = 09280, loss = 49.5941
2024-10-29 13:23:05: [2024-10-29 13:23:05] iter = 09290, loss = 49.0754
2024-10-29 13:23:06: [2024-10-29 13:23:06] iter = 09300, loss = 3.3591
2024-10-29 13:23:06: [2024-10-29 13:23:06] iter = 09310, loss = 20.4600
2024-10-29 13:23:07: [2024-10-29 13:23:07] iter = 09320, loss = 4.0321
2024-10-29 13:23:07: [2024-10-29 13:23:07] iter = 09330, loss = 4.8131
2024-10-29 13:23:08: [2024-10-29 13:23:08] iter = 09340, loss = 7.2956
2024-10-29 13:23:08: [2024-10-29 13:23:08] iter = 09350, loss = 11.7843
2024-10-29 13:23:09: [2024-10-29 13:23:09] iter = 09360, loss = 4.1274
2024-10-29 13:23:10: [2024-10-29 13:23:10] iter = 09370, loss = 5.0125
2024-10-29 13:23:10: [2024-10-29 13:23:10] iter = 09380, loss = 4.1142
2024-10-29 13:23:11: [2024-10-29 13:23:11] iter = 09390, loss = 5.6620
2024-10-29 13:23:11: [2024-10-29 13:23:11] iter = 09400, loss = 10.0300
2024-10-29 13:23:12: [2024-10-29 13:23:12] iter = 09410, loss = 10.0387
2024-10-29 13:23:12: [2024-10-29 13:23:12] iter = 09420, loss = 3.1905
2024-10-29 13:23:13: [2024-10-29 13:23:13] iter = 09430, loss = 3.0985
2024-10-29 13:23:13: [2024-10-29 13:23:13] iter = 09440, loss = 9.5430
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 09450, loss = 16.7551
2024-10-29 13:23:14: [2024-10-29 13:23:14] iter = 09460, loss = 50.3768
2024-10-29 13:23:15: [2024-10-29 13:23:15] iter = 09470, loss = 50.2137
2024-10-29 13:23:15: [2024-10-29 13:23:15] iter = 09480, loss = 7.4572
2024-10-29 13:23:16: [2024-10-29 13:23:16] iter = 09490, loss = 8.9794
2024-10-29 13:23:17: [2024-10-29 13:23:17] iter = 09500, loss = 6.8452
2024-10-29 13:23:17: [2024-10-29 13:23:17] iter = 09510, loss = 3.8940
2024-10-29 13:23:18: [2024-10-29 13:23:18] iter = 09520, loss = 12.6980
2024-10-29 13:23:18: [2024-10-29 13:23:18] iter = 09530, loss = 53.0417
2024-10-29 13:23:19: [2024-10-29 13:23:19] iter = 09540, loss = 4.3184
2024-10-29 13:23:19: [2024-10-29 13:23:19] iter = 09550, loss = 6.5806
2024-10-29 13:23:20: [2024-10-29 13:23:20] iter = 09560, loss = 4.6810
2024-10-29 13:23:20: [2024-10-29 13:23:20] iter = 09570, loss = 5.6848
2024-10-29 13:23:21: [2024-10-29 13:23:21] iter = 09580, loss = 5.2494
2024-10-29 13:23:21: [2024-10-29 13:23:21] iter = 09590, loss = 4.2995
2024-10-29 13:23:22: [2024-10-29 13:23:22] iter = 09600, loss = 8.3758
2024-10-29 13:23:23: [2024-10-29 13:23:23] iter = 09610, loss = 3.7936
2024-10-29 13:23:23: [2024-10-29 13:23:23] iter = 09620, loss = 5.8566
2024-10-29 13:23:24: [2024-10-29 13:23:24] iter = 09630, loss = 4.3701
2024-10-29 13:23:24: [2024-10-29 13:23:24] iter = 09640, loss = 30.9486
2024-10-29 13:23:25: [2024-10-29 13:23:25] iter = 09650, loss = 24.8748
2024-10-29 13:23:25: [2024-10-29 13:23:25] iter = 09660, loss = 23.1105
2024-10-29 13:23:26: [2024-10-29 13:23:26] iter = 09670, loss = 19.0614
2024-10-29 13:23:27: [2024-10-29 13:23:27] iter = 09680, loss = 14.8137
2024-10-29 13:23:27: [2024-10-29 13:23:27] iter = 09690, loss = 4.2458
2024-10-29 13:23:28: [2024-10-29 13:23:28] iter = 09700, loss = 9.1340
2024-10-29 13:23:28: [2024-10-29 13:23:28] iter = 09710, loss = 33.2709
2024-10-29 13:23:29: [2024-10-29 13:23:29] iter = 09720, loss = 4.3617
2024-10-29 13:23:29: [2024-10-29 13:23:29] iter = 09730, loss = 3.9445
2024-10-29 13:23:30: [2024-10-29 13:23:30] iter = 09740, loss = 56.1844
2024-10-29 13:23:30: [2024-10-29 13:23:30] iter = 09750, loss = 34.8726
2024-10-29 13:23:31: [2024-10-29 13:23:31] iter = 09760, loss = 8.9522
2024-10-29 13:23:31: [2024-10-29 13:23:31] iter = 09770, loss = 3.5500
2024-10-29 13:23:32: [2024-10-29 13:23:32] iter = 09780, loss = 4.8760
2024-10-29 13:23:32: [2024-10-29 13:23:32] iter = 09790, loss = 6.1456
2024-10-29 13:23:33: [2024-10-29 13:23:33] iter = 09800, loss = 4.4023
2024-10-29 13:23:33: [2024-10-29 13:23:33] iter = 09810, loss = 3.3488
2024-10-29 13:23:34: [2024-10-29 13:23:34] iter = 09820, loss = 2.9020
2024-10-29 13:23:35: [2024-10-29 13:23:35] iter = 09830, loss = 9.7164
2024-10-29 13:23:35: [2024-10-29 13:23:35] iter = 09840, loss = 2.3856
2024-10-29 13:23:36: [2024-10-29 13:23:36] iter = 09850, loss = 5.5370
2024-10-29 13:23:37: [2024-10-29 13:23:37] iter = 09860, loss = 3.2017
2024-10-29 13:23:37: [2024-10-29 13:23:37] iter = 09870, loss = 7.1340
2024-10-29 13:23:38: [2024-10-29 13:23:38] iter = 09880, loss = 9.0826
2024-10-29 13:23:39: [2024-10-29 13:23:39] iter = 09890, loss = 6.2586
2024-10-29 13:23:39: [2024-10-29 13:23:39] iter = 09900, loss = 3.7788
2024-10-29 13:23:40: [2024-10-29 13:23:40] iter = 09910, loss = 13.2107
2024-10-29 13:23:40: [2024-10-29 13:23:40] iter = 09920, loss = 5.6699
2024-10-29 13:23:41: [2024-10-29 13:23:41] iter = 09930, loss = 7.6469
2024-10-29 13:23:41: [2024-10-29 13:23:41] iter = 09940, loss = 4.3798
2024-10-29 13:23:42: [2024-10-29 13:23:42] iter = 09950, loss = 9.3882
2024-10-29 13:23:42: [2024-10-29 13:23:42] iter = 09960, loss = 2.7630
2024-10-29 13:23:43: [2024-10-29 13:23:43] iter = 09970, loss = 20.3252
2024-10-29 13:23:43: [2024-10-29 13:23:43] iter = 09980, loss = 2.8569
2024-10-29 13:23:44: [2024-10-29 13:23:44] iter = 09990, loss = 3.0636
2024-10-29 13:23:44: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-29 13:23:44: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:23:44: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 24584}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:24:10: Evaluate 5 random ConvNet, ACCmean = 0.5152 ACCstd = 0.0084
-------------------------
2024-10-29 13:24:10: Evaluate 5 random ConvNet, SENmean = 0.5152 SENstd = 0.0084
-------------------------
2024-10-29 13:24:10: Evaluate 5 random ConvNet, SPEmean = 0.8384 SPEstd = 0.0028
-------------------------
2024-10-29 13:24:10: Evaluate 5 random ConvNet, F!mean = 0.5059 F!std = 0.0115
-------------------------
2024-10-29 13:24:10: Evaluate 5 random ConvNet, mean = 0.5152 std = 0.0084
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:24:10: [2024-10-29 13:24:10] iter = 10000, loss = 2.7774
2024-10-29 13:24:11: [2024-10-29 13:24:11] iter = 10010, loss = 3.4945
2024-10-29 13:24:12: [2024-10-29 13:24:12] iter = 10020, loss = 13.5561
2024-10-29 13:24:12: [2024-10-29 13:24:12] iter = 10030, loss = 9.5934
2024-10-29 13:24:13: [2024-10-29 13:24:13] iter = 10040, loss = 10.0620
2024-10-29 13:24:13: [2024-10-29 13:24:13] iter = 10050, loss = 11.9776
2024-10-29 13:24:14: [2024-10-29 13:24:14] iter = 10060, loss = 3.3574
2024-10-29 13:24:14: [2024-10-29 13:24:14] iter = 10070, loss = 3.1712
2024-10-29 13:24:15: [2024-10-29 13:24:15] iter = 10080, loss = 3.7772
2024-10-29 13:24:15: [2024-10-29 13:24:15] iter = 10090, loss = 48.2457
2024-10-29 13:24:16: [2024-10-29 13:24:16] iter = 10100, loss = 3.7577
2024-10-29 13:24:17: [2024-10-29 13:24:17] iter = 10110, loss = 5.9339
2024-10-29 13:24:17: [2024-10-29 13:24:17] iter = 10120, loss = 29.9784
2024-10-29 13:24:18: [2024-10-29 13:24:18] iter = 10130, loss = 3.6672
2024-10-29 13:24:19: [2024-10-29 13:24:19] iter = 10140, loss = 29.2906
2024-10-29 13:24:19: [2024-10-29 13:24:19] iter = 10150, loss = 7.4212
2024-10-29 13:24:20: [2024-10-29 13:24:20] iter = 10160, loss = 5.8882
2024-10-29 13:24:20: [2024-10-29 13:24:20] iter = 10170, loss = 2.7669
2024-10-29 13:24:21: [2024-10-29 13:24:21] iter = 10180, loss = 4.0794
2024-10-29 13:24:22: [2024-10-29 13:24:22] iter = 10190, loss = 7.7357
2024-10-29 13:24:22: [2024-10-29 13:24:22] iter = 10200, loss = 9.8917
2024-10-29 13:24:23: [2024-10-29 13:24:23] iter = 10210, loss = 27.9211
2024-10-29 13:24:24: [2024-10-29 13:24:24] iter = 10220, loss = 31.5672
2024-10-29 13:24:24: [2024-10-29 13:24:24] iter = 10230, loss = 52.5393
2024-10-29 13:24:25: [2024-10-29 13:24:25] iter = 10240, loss = 4.5047
2024-10-29 13:24:25: [2024-10-29 13:24:25] iter = 10250, loss = 4.2135
2024-10-29 13:24:26: [2024-10-29 13:24:26] iter = 10260, loss = 1.8293
2024-10-29 13:24:27: [2024-10-29 13:24:27] iter = 10270, loss = 9.5065
2024-10-29 13:24:27: [2024-10-29 13:24:27] iter = 10280, loss = 6.6110
2024-10-29 13:24:28: [2024-10-29 13:24:28] iter = 10290, loss = 6.4683
2024-10-29 13:24:28: [2024-10-29 13:24:28] iter = 10300, loss = 10.6804
2024-10-29 13:24:29: [2024-10-29 13:24:29] iter = 10310, loss = 9.3269
2024-10-29 13:24:29: [2024-10-29 13:24:29] iter = 10320, loss = 3.2426
2024-10-29 13:24:30: [2024-10-29 13:24:30] iter = 10330, loss = 7.2277
2024-10-29 13:24:31: [2024-10-29 13:24:31] iter = 10340, loss = 8.6464
2024-10-29 13:24:31: [2024-10-29 13:24:31] iter = 10350, loss = 6.6680
2024-10-29 13:24:32: [2024-10-29 13:24:32] iter = 10360, loss = 10.6726
2024-10-29 13:24:32: [2024-10-29 13:24:32] iter = 10370, loss = 3.4538
2024-10-29 13:24:33: [2024-10-29 13:24:33] iter = 10380, loss = 8.6917
2024-10-29 13:24:33: [2024-10-29 13:24:33] iter = 10390, loss = 4.8096
2024-10-29 13:24:34: [2024-10-29 13:24:34] iter = 10400, loss = 11.4219
2024-10-29 13:24:34: [2024-10-29 13:24:34] iter = 10410, loss = 7.9833
2024-10-29 13:24:35: [2024-10-29 13:24:35] iter = 10420, loss = 3.4042
2024-10-29 13:24:36: [2024-10-29 13:24:36] iter = 10430, loss = 3.1210
2024-10-29 13:24:36: [2024-10-29 13:24:36] iter = 10440, loss = 9.6717
2024-10-29 13:24:37: [2024-10-29 13:24:37] iter = 10450, loss = 2.9357
2024-10-29 13:24:37: [2024-10-29 13:24:37] iter = 10460, loss = 57.3947
2024-10-29 13:24:38: [2024-10-29 13:24:38] iter = 10470, loss = 9.2207
2024-10-29 13:24:38: [2024-10-29 13:24:38] iter = 10480, loss = 12.7300
2024-10-29 13:24:39: [2024-10-29 13:24:39] iter = 10490, loss = 3.4303
2024-10-29 13:24:39: [2024-10-29 13:24:39] iter = 10500, loss = 18.9839
2024-10-29 13:24:40: [2024-10-29 13:24:40] iter = 10510, loss = 3.3505
2024-10-29 13:24:40: [2024-10-29 13:24:40] iter = 10520, loss = 4.1025
2024-10-29 13:24:41: [2024-10-29 13:24:41] iter = 10530, loss = 2.8107
2024-10-29 13:24:42: [2024-10-29 13:24:42] iter = 10540, loss = 3.0292
2024-10-29 13:24:42: [2024-10-29 13:24:42] iter = 10550, loss = 3.1956
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 10560, loss = 9.5379
2024-10-29 13:24:43: [2024-10-29 13:24:43] iter = 10570, loss = 10.0942
2024-10-29 13:24:44: [2024-10-29 13:24:44] iter = 10580, loss = 3.0438
2024-10-29 13:24:44: [2024-10-29 13:24:44] iter = 10590, loss = 5.3975
2024-10-29 13:24:45: [2024-10-29 13:24:45] iter = 10600, loss = 10.5790
2024-10-29 13:24:45: [2024-10-29 13:24:45] iter = 10610, loss = 5.7673
2024-10-29 13:24:46: [2024-10-29 13:24:46] iter = 10620, loss = 7.2660
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 10630, loss = 7.3907
2024-10-29 13:24:47: [2024-10-29 13:24:47] iter = 10640, loss = 21.5171
2024-10-29 13:24:48: [2024-10-29 13:24:48] iter = 10650, loss = 5.8928
2024-10-29 13:24:48: [2024-10-29 13:24:48] iter = 10660, loss = 2.5058
2024-10-29 13:24:49: [2024-10-29 13:24:49] iter = 10670, loss = 6.9982
2024-10-29 13:24:50: [2024-10-29 13:24:50] iter = 10680, loss = 25.2552
2024-10-29 13:24:50: [2024-10-29 13:24:50] iter = 10690, loss = 17.6566
2024-10-29 13:24:51: [2024-10-29 13:24:51] iter = 10700, loss = 35.5098
2024-10-29 13:24:51: [2024-10-29 13:24:51] iter = 10710, loss = 3.9134
2024-10-29 13:24:52: [2024-10-29 13:24:52] iter = 10720, loss = 5.4514
2024-10-29 13:24:53: [2024-10-29 13:24:53] iter = 10730, loss = 4.5307
2024-10-29 13:24:53: [2024-10-29 13:24:53] iter = 10740, loss = 3.1835
2024-10-29 13:24:54: [2024-10-29 13:24:54] iter = 10750, loss = 25.7105
2024-10-29 13:24:55: [2024-10-29 13:24:55] iter = 10760, loss = 68.2540
2024-10-29 13:24:55: [2024-10-29 13:24:55] iter = 10770, loss = 9.6077
2024-10-29 13:24:56: [2024-10-29 13:24:56] iter = 10780, loss = 10.8591
2024-10-29 13:24:57: [2024-10-29 13:24:57] iter = 10790, loss = 2.8256
2024-10-29 13:24:57: [2024-10-29 13:24:57] iter = 10800, loss = 5.7298
2024-10-29 13:24:58: [2024-10-29 13:24:58] iter = 10810, loss = 20.5692
2024-10-29 13:24:59: [2024-10-29 13:24:59] iter = 10820, loss = 5.6452
2024-10-29 13:24:59: [2024-10-29 13:24:59] iter = 10830, loss = 4.7701
2024-10-29 13:25:00: [2024-10-29 13:25:00] iter = 10840, loss = 3.7389
2024-10-29 13:25:00: [2024-10-29 13:25:00] iter = 10850, loss = 38.9620
2024-10-29 13:25:01: [2024-10-29 13:25:01] iter = 10860, loss = 4.6425
2024-10-29 13:25:01: [2024-10-29 13:25:01] iter = 10870, loss = 8.8652
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 10880, loss = 3.1124
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 10890, loss = 10.1706
2024-10-29 13:25:02: [2024-10-29 13:25:02] iter = 10900, loss = 6.1722
2024-10-29 13:25:03: [2024-10-29 13:25:03] iter = 10910, loss = 7.1697
2024-10-29 13:25:03: [2024-10-29 13:25:03] iter = 10920, loss = 2.9454
2024-10-29 13:25:04: [2024-10-29 13:25:04] iter = 10930, loss = 15.5865
2024-10-29 13:25:04: [2024-10-29 13:25:04] iter = 10940, loss = 20.5907
2024-10-29 13:25:05: [2024-10-29 13:25:05] iter = 10950, loss = 2.6585
2024-10-29 13:25:05: [2024-10-29 13:25:05] iter = 10960, loss = 3.4907
2024-10-29 13:25:06: [2024-10-29 13:25:06] iter = 10970, loss = 15.9936
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 10980, loss = 7.1282
2024-10-29 13:25:07: [2024-10-29 13:25:07] iter = 10990, loss = 7.1215
2024-10-29 13:25:08: [2024-10-29 13:25:08] iter = 11000, loss = 9.6693
2024-10-29 13:25:08: [2024-10-29 13:25:08] iter = 11010, loss = 6.7141
2024-10-29 13:25:09: [2024-10-29 13:25:09] iter = 11020, loss = 3.3170
2024-10-29 13:25:09: [2024-10-29 13:25:09] iter = 11030, loss = 6.9966
2024-10-29 13:25:10: [2024-10-29 13:25:10] iter = 11040, loss = 38.0018
2024-10-29 13:25:10: [2024-10-29 13:25:10] iter = 11050, loss = 7.2852
2024-10-29 13:25:11: [2024-10-29 13:25:11] iter = 11060, loss = 6.3437
2024-10-29 13:25:11: [2024-10-29 13:25:11] iter = 11070, loss = 4.2020
2024-10-29 13:25:12: [2024-10-29 13:25:12] iter = 11080, loss = 8.8102
2024-10-29 13:25:12: [2024-10-29 13:25:12] iter = 11090, loss = 4.1552
2024-10-29 13:25:13: [2024-10-29 13:25:13] iter = 11100, loss = 12.9816
2024-10-29 13:25:13: [2024-10-29 13:25:13] iter = 11110, loss = 3.9843
2024-10-29 13:25:14: [2024-10-29 13:25:14] iter = 11120, loss = 5.4967
2024-10-29 13:25:14: [2024-10-29 13:25:14] iter = 11130, loss = 45.4138
2024-10-29 13:25:15: [2024-10-29 13:25:15] iter = 11140, loss = 5.9011
2024-10-29 13:25:15: [2024-10-29 13:25:15] iter = 11150, loss = 13.7132
2024-10-29 13:25:16: [2024-10-29 13:25:16] iter = 11160, loss = 9.5097
2024-10-29 13:25:16: [2024-10-29 13:25:16] iter = 11170, loss = 4.4900
2024-10-29 13:25:17: [2024-10-29 13:25:17] iter = 11180, loss = 9.5346
2024-10-29 13:25:18: [2024-10-29 13:25:18] iter = 11190, loss = 3.9682
2024-10-29 13:25:18: [2024-10-29 13:25:18] iter = 11200, loss = 8.6530
2024-10-29 13:25:19: [2024-10-29 13:25:19] iter = 11210, loss = 12.9303
2024-10-29 13:25:19: [2024-10-29 13:25:19] iter = 11220, loss = 3.2805
2024-10-29 13:25:20: [2024-10-29 13:25:20] iter = 11230, loss = 6.9430
2024-10-29 13:25:20: [2024-10-29 13:25:20] iter = 11240, loss = 3.5954
2024-10-29 13:25:21: [2024-10-29 13:25:21] iter = 11250, loss = 11.0059
2024-10-29 13:25:21: [2024-10-29 13:25:21] iter = 11260, loss = 10.0230
2024-10-29 13:25:22: [2024-10-29 13:25:22] iter = 11270, loss = 4.3830
2024-10-29 13:25:22: [2024-10-29 13:25:22] iter = 11280, loss = 16.7496
2024-10-29 13:25:23: [2024-10-29 13:25:23] iter = 11290, loss = 7.9347
2024-10-29 13:25:23: [2024-10-29 13:25:23] iter = 11300, loss = 3.2261
2024-10-29 13:25:24: [2024-10-29 13:25:24] iter = 11310, loss = 5.1099
2024-10-29 13:25:24: [2024-10-29 13:25:24] iter = 11320, loss = 15.6381
2024-10-29 13:25:25: [2024-10-29 13:25:25] iter = 11330, loss = 4.5832
2024-10-29 13:25:25: [2024-10-29 13:25:25] iter = 11340, loss = 7.3545
2024-10-29 13:25:26: [2024-10-29 13:25:26] iter = 11350, loss = 3.0127
2024-10-29 13:25:26: [2024-10-29 13:25:26] iter = 11360, loss = 12.5413
2024-10-29 13:25:27: [2024-10-29 13:25:27] iter = 11370, loss = 10.1538
2024-10-29 13:25:28: [2024-10-29 13:25:28] iter = 11380, loss = 7.1855
2024-10-29 13:25:28: [2024-10-29 13:25:28] iter = 11390, loss = 7.0549
2024-10-29 13:25:29: [2024-10-29 13:25:29] iter = 11400, loss = 3.1776
2024-10-29 13:25:29: [2024-10-29 13:25:29] iter = 11410, loss = 43.5991
2024-10-29 13:25:30: [2024-10-29 13:25:30] iter = 11420, loss = 16.7230
2024-10-29 13:25:30: [2024-10-29 13:25:30] iter = 11430, loss = 4.1206
2024-10-29 13:25:31: [2024-10-29 13:25:31] iter = 11440, loss = 9.1767
2024-10-29 13:25:31: [2024-10-29 13:25:31] iter = 11450, loss = 3.8174
2024-10-29 13:25:32: [2024-10-29 13:25:32] iter = 11460, loss = 11.2335
2024-10-29 13:25:32: [2024-10-29 13:25:32] iter = 11470, loss = 8.3953
2024-10-29 13:25:33: [2024-10-29 13:25:33] iter = 11480, loss = 5.9492
2024-10-29 13:25:33: [2024-10-29 13:25:33] iter = 11490, loss = 3.4419
2024-10-29 13:25:34: [2024-10-29 13:25:34] iter = 11500, loss = 4.1373
2024-10-29 13:25:35: [2024-10-29 13:25:35] iter = 11510, loss = 6.1743
2024-10-29 13:25:35: [2024-10-29 13:25:35] iter = 11520, loss = 3.4084
2024-10-29 13:25:36: [2024-10-29 13:25:36] iter = 11530, loss = 3.1907
2024-10-29 13:25:36: [2024-10-29 13:25:36] iter = 11540, loss = 2.7258
2024-10-29 13:25:37: [2024-10-29 13:25:37] iter = 11550, loss = 3.5147
2024-10-29 13:25:37: [2024-10-29 13:25:37] iter = 11560, loss = 23.7550
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 11570, loss = 3.0343
2024-10-29 13:25:38: [2024-10-29 13:25:38] iter = 11580, loss = 3.4827
2024-10-29 13:25:39: [2024-10-29 13:25:39] iter = 11590, loss = 14.8720
2024-10-29 13:25:39: [2024-10-29 13:25:39] iter = 11600, loss = 13.6891
2024-10-29 13:25:40: [2024-10-29 13:25:40] iter = 11610, loss = 8.9138
2024-10-29 13:25:40: [2024-10-29 13:25:40] iter = 11620, loss = 3.1717
2024-10-29 13:25:41: [2024-10-29 13:25:41] iter = 11630, loss = 3.9711
2024-10-29 13:25:41: [2024-10-29 13:25:41] iter = 11640, loss = 3.6449
2024-10-29 13:25:42: [2024-10-29 13:25:42] iter = 11650, loss = 4.9507
2024-10-29 13:25:43: [2024-10-29 13:25:43] iter = 11660, loss = 6.3957
2024-10-29 13:25:43: [2024-10-29 13:25:43] iter = 11670, loss = 16.0133
2024-10-29 13:25:44: [2024-10-29 13:25:44] iter = 11680, loss = 45.0895
2024-10-29 13:25:45: [2024-10-29 13:25:45] iter = 11690, loss = 3.2305
2024-10-29 13:25:45: [2024-10-29 13:25:45] iter = 11700, loss = 3.1396
2024-10-29 13:25:46: [2024-10-29 13:25:46] iter = 11710, loss = 6.1213
2024-10-29 13:25:46: [2024-10-29 13:25:46] iter = 11720, loss = 3.9678
2024-10-29 13:25:47: [2024-10-29 13:25:47] iter = 11730, loss = 5.7731
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 11740, loss = 11.2032
2024-10-29 13:25:48: [2024-10-29 13:25:48] iter = 11750, loss = 8.1116
2024-10-29 13:25:49: [2024-10-29 13:25:49] iter = 11760, loss = 3.2143
2024-10-29 13:25:49: [2024-10-29 13:25:49] iter = 11770, loss = 35.2756
2024-10-29 13:25:50: [2024-10-29 13:25:50] iter = 11780, loss = 13.3636
2024-10-29 13:25:50: [2024-10-29 13:25:50] iter = 11790, loss = 25.4765
2024-10-29 13:25:51: [2024-10-29 13:25:51] iter = 11800, loss = 9.9370
2024-10-29 13:25:52: [2024-10-29 13:25:52] iter = 11810, loss = 57.6586
2024-10-29 13:25:52: [2024-10-29 13:25:52] iter = 11820, loss = 3.5396
2024-10-29 13:25:53: [2024-10-29 13:25:53] iter = 11830, loss = 3.3089
2024-10-29 13:25:53: [2024-10-29 13:25:53] iter = 11840, loss = 2.8861
2024-10-29 13:25:54: [2024-10-29 13:25:54] iter = 11850, loss = 3.4051
2024-10-29 13:25:54: [2024-10-29 13:25:54] iter = 11860, loss = 3.7419
2024-10-29 13:25:55: [2024-10-29 13:25:55] iter = 11870, loss = 10.3241
2024-10-29 13:25:55: [2024-10-29 13:25:55] iter = 11880, loss = 2.6018
2024-10-29 13:25:56: [2024-10-29 13:25:56] iter = 11890, loss = 9.4095
2024-10-29 13:25:56: [2024-10-29 13:25:56] iter = 11900, loss = 14.9448
2024-10-29 13:25:57: [2024-10-29 13:25:57] iter = 11910, loss = 5.6402
2024-10-29 13:25:57: [2024-10-29 13:25:57] iter = 11920, loss = 5.2764
2024-10-29 13:25:58: [2024-10-29 13:25:58] iter = 11930, loss = 4.3284
2024-10-29 13:25:58: [2024-10-29 13:25:58] iter = 11940, loss = 9.9682
2024-10-29 13:25:59: [2024-10-29 13:25:59] iter = 11950, loss = 5.6904
2024-10-29 13:25:59: [2024-10-29 13:25:59] iter = 11960, loss = 35.0892
2024-10-29 13:26:00: [2024-10-29 13:26:00] iter = 11970, loss = 14.5988
2024-10-29 13:26:00: [2024-10-29 13:26:00] iter = 11980, loss = 4.0895
2024-10-29 13:26:01: [2024-10-29 13:26:01] iter = 11990, loss = 14.4116
2024-10-29 13:26:02: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-29 13:26:02: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:26:02: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 62013}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:30: Evaluate 5 random ConvNet, ACCmean = 0.5306 ACCstd = 0.0116
-------------------------
2024-10-29 13:26:30: Evaluate 5 random ConvNet, SENmean = 0.5306 SENstd = 0.0116
-------------------------
2024-10-29 13:26:30: Evaluate 5 random ConvNet, SPEmean = 0.8435 SPEstd = 0.0039
-------------------------
2024-10-29 13:26:30: Evaluate 5 random ConvNet, F!mean = 0.5136 F!std = 0.0147
-------------------------
2024-10-29 13:26:30: Evaluate 5 random ConvNet, mean = 0.5306 std = 0.0116
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:30: [2024-10-29 13:26:30] iter = 12000, loss = 2.1880
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:26:30: [2024-10-29 13:26:30] iter = 12010, loss = 3.5130
2024-10-29 13:26:31: [2024-10-29 13:26:31] iter = 12020, loss = 32.3035
2024-10-29 13:26:31: [2024-10-29 13:26:31] iter = 12030, loss = 4.3488
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 12040, loss = 10.4758
2024-10-29 13:26:32: [2024-10-29 13:26:32] iter = 12050, loss = 14.6084
2024-10-29 13:26:33: [2024-10-29 13:26:33] iter = 12060, loss = 3.2099
2024-10-29 13:26:33: [2024-10-29 13:26:33] iter = 12070, loss = 9.4307
2024-10-29 13:26:34: [2024-10-29 13:26:34] iter = 12080, loss = 7.6624
2024-10-29 13:26:34: [2024-10-29 13:26:34] iter = 12090, loss = 10.3231
2024-10-29 13:26:35: [2024-10-29 13:26:35] iter = 12100, loss = 9.4298
2024-10-29 13:26:35: [2024-10-29 13:26:35] iter = 12110, loss = 7.5848
2024-10-29 13:26:36: [2024-10-29 13:26:36] iter = 12120, loss = 17.1172
2024-10-29 13:26:36: [2024-10-29 13:26:36] iter = 12130, loss = 14.4751
2024-10-29 13:26:37: [2024-10-29 13:26:37] iter = 12140, loss = 4.4451
2024-10-29 13:26:37: [2024-10-29 13:26:37] iter = 12150, loss = 8.7577
2024-10-29 13:26:38: [2024-10-29 13:26:38] iter = 12160, loss = 3.4068
2024-10-29 13:26:38: [2024-10-29 13:26:38] iter = 12170, loss = 2.4948
2024-10-29 13:26:39: [2024-10-29 13:26:39] iter = 12180, loss = 4.1412
2024-10-29 13:26:39: [2024-10-29 13:26:39] iter = 12190, loss = 4.0845
2024-10-29 13:26:40: [2024-10-29 13:26:40] iter = 12200, loss = 6.6742
2024-10-29 13:26:40: [2024-10-29 13:26:40] iter = 12210, loss = 8.8201
2024-10-29 13:26:41: [2024-10-29 13:26:41] iter = 12220, loss = 6.6429
2024-10-29 13:26:42: [2024-10-29 13:26:42] iter = 12230, loss = 3.3185
2024-10-29 13:26:42: [2024-10-29 13:26:42] iter = 12240, loss = 7.2353
2024-10-29 13:26:43: [2024-10-29 13:26:43] iter = 12250, loss = 3.6014
2024-10-29 13:26:43: [2024-10-29 13:26:43] iter = 12260, loss = 3.6389
2024-10-29 13:26:44: [2024-10-29 13:26:44] iter = 12270, loss = 5.4213
2024-10-29 13:26:44: [2024-10-29 13:26:44] iter = 12280, loss = 11.6573
2024-10-29 13:26:45: [2024-10-29 13:26:45] iter = 12290, loss = 9.6569
2024-10-29 13:26:45: [2024-10-29 13:26:45] iter = 12300, loss = 6.6134
2024-10-29 13:26:46: [2024-10-29 13:26:46] iter = 12310, loss = 3.4587
2024-10-29 13:26:47: [2024-10-29 13:26:47] iter = 12320, loss = 9.9866
2024-10-29 13:26:47: [2024-10-29 13:26:47] iter = 12330, loss = 8.6741
2024-10-29 13:26:48: [2024-10-29 13:26:48] iter = 12340, loss = 5.3880
2024-10-29 13:26:49: [2024-10-29 13:26:49] iter = 12350, loss = 6.8660
2024-10-29 13:26:49: [2024-10-29 13:26:49] iter = 12360, loss = 7.9919
2024-10-29 13:26:50: [2024-10-29 13:26:50] iter = 12370, loss = 5.1823
2024-10-29 13:26:51: [2024-10-29 13:26:51] iter = 12380, loss = 8.8062
2024-10-29 13:26:51: [2024-10-29 13:26:51] iter = 12390, loss = 3.7233
2024-10-29 13:26:52: [2024-10-29 13:26:52] iter = 12400, loss = 8.4837
2024-10-29 13:26:52: [2024-10-29 13:26:52] iter = 12410, loss = 2.5806
2024-10-29 13:26:53: [2024-10-29 13:26:53] iter = 12420, loss = 39.7707
2024-10-29 13:26:53: [2024-10-29 13:26:53] iter = 12430, loss = 3.6393
2024-10-29 13:26:54: [2024-10-29 13:26:54] iter = 12440, loss = 3.5645
2024-10-29 13:26:54: [2024-10-29 13:26:54] iter = 12450, loss = 5.2964
2024-10-29 13:26:55: [2024-10-29 13:26:55] iter = 12460, loss = 8.6857
2024-10-29 13:26:56: [2024-10-29 13:26:56] iter = 12470, loss = 5.6173
2024-10-29 13:26:56: [2024-10-29 13:26:56] iter = 12480, loss = 12.5874
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 12490, loss = 2.8702
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 12500, loss = 4.0624
2024-10-29 13:26:57: [2024-10-29 13:26:57] iter = 12510, loss = 12.9982
2024-10-29 13:26:58: [2024-10-29 13:26:58] iter = 12520, loss = 4.8674
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 12530, loss = 49.3820
2024-10-29 13:26:59: [2024-10-29 13:26:59] iter = 12540, loss = 3.7271
2024-10-29 13:27:00: [2024-10-29 13:27:00] iter = 12550, loss = 3.3108
2024-10-29 13:27:00: [2024-10-29 13:27:00] iter = 12560, loss = 3.2879
2024-10-29 13:27:01: [2024-10-29 13:27:01] iter = 12570, loss = 9.2743
2024-10-29 13:27:01: [2024-10-29 13:27:01] iter = 12580, loss = 5.1635
2024-10-29 13:27:02: [2024-10-29 13:27:02] iter = 12590, loss = 3.9144
2024-10-29 13:27:02: [2024-10-29 13:27:02] iter = 12600, loss = 3.3863
2024-10-29 13:27:03: [2024-10-29 13:27:03] iter = 12610, loss = 3.7385
2024-10-29 13:27:03: [2024-10-29 13:27:03] iter = 12620, loss = 7.5179
2024-10-29 13:27:04: [2024-10-29 13:27:04] iter = 12630, loss = 11.1187
2024-10-29 13:27:04: [2024-10-29 13:27:04] iter = 12640, loss = 8.2575
2024-10-29 13:27:05: [2024-10-29 13:27:05] iter = 12650, loss = 23.7522
2024-10-29 13:27:05: [2024-10-29 13:27:05] iter = 12660, loss = 5.6731
2024-10-29 13:27:06: [2024-10-29 13:27:06] iter = 12670, loss = 4.4000
2024-10-29 13:27:06: [2024-10-29 13:27:06] iter = 12680, loss = 8.0610
2024-10-29 13:27:07: [2024-10-29 13:27:07] iter = 12690, loss = 3.4602
2024-10-29 13:27:07: [2024-10-29 13:27:07] iter = 12700, loss = 14.8139
2024-10-29 13:27:08: [2024-10-29 13:27:08] iter = 12710, loss = 4.9309
2024-10-29 13:27:08: [2024-10-29 13:27:08] iter = 12720, loss = 36.1696
2024-10-29 13:27:09: [2024-10-29 13:27:09] iter = 12730, loss = 5.5569
2024-10-29 13:27:09: [2024-10-29 13:27:09] iter = 12740, loss = 14.9224
2024-10-29 13:27:10: [2024-10-29 13:27:10] iter = 12750, loss = 7.4388
2024-10-29 13:27:10: [2024-10-29 13:27:10] iter = 12760, loss = 10.7303
2024-10-29 13:27:11: [2024-10-29 13:27:11] iter = 12770, loss = 38.7871
2024-10-29 13:27:11: [2024-10-29 13:27:11] iter = 12780, loss = 3.1610
2024-10-29 13:27:12: [2024-10-29 13:27:12] iter = 12790, loss = 6.7800
2024-10-29 13:27:12: [2024-10-29 13:27:12] iter = 12800, loss = 16.5342
2024-10-29 13:27:13: [2024-10-29 13:27:13] iter = 12810, loss = 3.0239
2024-10-29 13:27:13: [2024-10-29 13:27:13] iter = 12820, loss = 8.3435
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 12830, loss = 2.9699
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 12840, loss = 9.1041
2024-10-29 13:27:14: [2024-10-29 13:27:14] iter = 12850, loss = 5.5734
2024-10-29 13:27:15: [2024-10-29 13:27:15] iter = 12860, loss = 3.1204
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 12870, loss = 3.8994
2024-10-29 13:27:16: [2024-10-29 13:27:16] iter = 12880, loss = 4.9983
2024-10-29 13:27:17: [2024-10-29 13:27:17] iter = 12890, loss = 47.5254
2024-10-29 13:27:17: [2024-10-29 13:27:17] iter = 12900, loss = 9.4920
2024-10-29 13:27:18: [2024-10-29 13:27:18] iter = 12910, loss = 29.6354
2024-10-29 13:27:18: [2024-10-29 13:27:18] iter = 12920, loss = 3.3122
2024-10-29 13:27:19: [2024-10-29 13:27:19] iter = 12930, loss = 14.1542
2024-10-29 13:27:19: [2024-10-29 13:27:19] iter = 12940, loss = 2.9898
2024-10-29 13:27:20: [2024-10-29 13:27:20] iter = 12950, loss = 3.5236
2024-10-29 13:27:20: [2024-10-29 13:27:20] iter = 12960, loss = 3.6639
2024-10-29 13:27:21: [2024-10-29 13:27:21] iter = 12970, loss = 6.5002
2024-10-29 13:27:21: [2024-10-29 13:27:21] iter = 12980, loss = 8.3480
2024-10-29 13:27:22: [2024-10-29 13:27:22] iter = 12990, loss = 4.4053
2024-10-29 13:27:22: [2024-10-29 13:27:22] iter = 13000, loss = 3.0647
2024-10-29 13:27:23: [2024-10-29 13:27:23] iter = 13010, loss = 6.2248
2024-10-29 13:27:23: [2024-10-29 13:27:23] iter = 13020, loss = 3.3833
2024-10-29 13:27:24: [2024-10-29 13:27:24] iter = 13030, loss = 6.6234
2024-10-29 13:27:24: [2024-10-29 13:27:24] iter = 13040, loss = 4.1879
2024-10-29 13:27:25: [2024-10-29 13:27:25] iter = 13050, loss = 6.0445
2024-10-29 13:27:25: [2024-10-29 13:27:25] iter = 13060, loss = 18.0411
2024-10-29 13:27:26: [2024-10-29 13:27:26] iter = 13070, loss = 8.6628
2024-10-29 13:27:26: [2024-10-29 13:27:26] iter = 13080, loss = 2.1857
2024-10-29 13:27:27: [2024-10-29 13:27:27] iter = 13090, loss = 9.2427
2024-10-29 13:27:27: [2024-10-29 13:27:27] iter = 13100, loss = 10.0040
2024-10-29 13:27:28: [2024-10-29 13:27:28] iter = 13110, loss = 4.1261
2024-10-29 13:27:28: [2024-10-29 13:27:28] iter = 13120, loss = 7.7971
2024-10-29 13:27:29: [2024-10-29 13:27:29] iter = 13130, loss = 10.9749
2024-10-29 13:27:29: [2024-10-29 13:27:29] iter = 13140, loss = 3.4611
2024-10-29 13:27:30: [2024-10-29 13:27:30] iter = 13150, loss = 5.9880
2024-10-29 13:27:31: [2024-10-29 13:27:31] iter = 13160, loss = 8.3711
2024-10-29 13:27:31: [2024-10-29 13:27:31] iter = 13170, loss = 11.3944
2024-10-29 13:27:32: [2024-10-29 13:27:32] iter = 13180, loss = 3.3490
2024-10-29 13:27:32: [2024-10-29 13:27:32] iter = 13190, loss = 6.3450
2024-10-29 13:27:33: [2024-10-29 13:27:33] iter = 13200, loss = 4.1363
2024-10-29 13:27:33: [2024-10-29 13:27:33] iter = 13210, loss = 4.4412
2024-10-29 13:27:34: [2024-10-29 13:27:34] iter = 13220, loss = 2.6920
2024-10-29 13:27:34: [2024-10-29 13:27:34] iter = 13230, loss = 5.7906
2024-10-29 13:27:35: [2024-10-29 13:27:35] iter = 13240, loss = 10.4270
2024-10-29 13:27:35: [2024-10-29 13:27:35] iter = 13250, loss = 4.7201
2024-10-29 13:27:36: [2024-10-29 13:27:36] iter = 13260, loss = 10.4141
2024-10-29 13:27:36: [2024-10-29 13:27:36] iter = 13270, loss = 4.6798
2024-10-29 13:27:37: [2024-10-29 13:27:37] iter = 13280, loss = 4.8305
2024-10-29 13:27:38: [2024-10-29 13:27:38] iter = 13290, loss = 3.3834
2024-10-29 13:27:38: [2024-10-29 13:27:38] iter = 13300, loss = 13.7336
2024-10-29 13:27:39: [2024-10-29 13:27:39] iter = 13310, loss = 3.3020
2024-10-29 13:27:39: [2024-10-29 13:27:39] iter = 13320, loss = 8.8082
2024-10-29 13:27:40: [2024-10-29 13:27:40] iter = 13330, loss = 12.7740
2024-10-29 13:27:40: [2024-10-29 13:27:40] iter = 13340, loss = 9.3076
2024-10-29 13:27:41: [2024-10-29 13:27:41] iter = 13350, loss = 2.8860
2024-10-29 13:27:41: [2024-10-29 13:27:41] iter = 13360, loss = 4.8429
2024-10-29 13:27:42: [2024-10-29 13:27:42] iter = 13370, loss = 25.5537
2024-10-29 13:27:43: [2024-10-29 13:27:43] iter = 13380, loss = 10.4126
2024-10-29 13:27:43: [2024-10-29 13:27:43] iter = 13390, loss = 7.2993
2024-10-29 13:27:44: [2024-10-29 13:27:44] iter = 13400, loss = 18.6338
2024-10-29 13:27:44: [2024-10-29 13:27:44] iter = 13410, loss = 2.7550
2024-10-29 13:27:45: [2024-10-29 13:27:45] iter = 13420, loss = 55.6854
2024-10-29 13:27:45: [2024-10-29 13:27:45] iter = 13430, loss = 12.0605
2024-10-29 13:27:46: [2024-10-29 13:27:46] iter = 13440, loss = 14.5307
2024-10-29 13:27:46: [2024-10-29 13:27:46] iter = 13450, loss = 21.8965
2024-10-29 13:27:47: [2024-10-29 13:27:47] iter = 13460, loss = 8.0644
2024-10-29 13:27:47: [2024-10-29 13:27:47] iter = 13470, loss = 27.0459
2024-10-29 13:27:48: [2024-10-29 13:27:48] iter = 13480, loss = 10.0170
2024-10-29 13:27:48: [2024-10-29 13:27:48] iter = 13490, loss = 4.8602
2024-10-29 13:27:49: [2024-10-29 13:27:49] iter = 13500, loss = 25.3941
2024-10-29 13:27:50: [2024-10-29 13:27:50] iter = 13510, loss = 4.0161
2024-10-29 13:27:50: [2024-10-29 13:27:50] iter = 13520, loss = 2.4634
2024-10-29 13:27:51: [2024-10-29 13:27:51] iter = 13530, loss = 18.6352
2024-10-29 13:27:51: [2024-10-29 13:27:51] iter = 13540, loss = 3.3519
2024-10-29 13:27:52: [2024-10-29 13:27:52] iter = 13550, loss = 6.1744
2024-10-29 13:27:53: [2024-10-29 13:27:53] iter = 13560, loss = 3.6505
2024-10-29 13:27:53: [2024-10-29 13:27:53] iter = 13570, loss = 5.5259
2024-10-29 13:27:54: [2024-10-29 13:27:54] iter = 13580, loss = 13.2597
2024-10-29 13:27:54: [2024-10-29 13:27:54] iter = 13590, loss = 3.6240
2024-10-29 13:27:55: [2024-10-29 13:27:55] iter = 13600, loss = 4.1904
2024-10-29 13:27:56: [2024-10-29 13:27:56] iter = 13610, loss = 8.5742
2024-10-29 13:27:56: [2024-10-29 13:27:56] iter = 13620, loss = 2.6045
2024-10-29 13:27:57: [2024-10-29 13:27:57] iter = 13630, loss = 12.2269
2024-10-29 13:27:57: [2024-10-29 13:27:57] iter = 13640, loss = 6.5198
2024-10-29 13:27:58: [2024-10-29 13:27:58] iter = 13650, loss = 5.3992
2024-10-29 13:27:58: [2024-10-29 13:27:58] iter = 13660, loss = 11.6090
2024-10-29 13:27:59: [2024-10-29 13:27:59] iter = 13670, loss = 8.2145
2024-10-29 13:27:59: [2024-10-29 13:27:59] iter = 13680, loss = 3.6345
2024-10-29 13:28:00: [2024-10-29 13:28:00] iter = 13690, loss = 55.4081
2024-10-29 13:28:00: [2024-10-29 13:28:00] iter = 13700, loss = 4.2351
2024-10-29 13:28:01: [2024-10-29 13:28:01] iter = 13710, loss = 2.6794
2024-10-29 13:28:02: [2024-10-29 13:28:02] iter = 13720, loss = 2.8807
2024-10-29 13:28:02: [2024-10-29 13:28:02] iter = 13730, loss = 7.0880
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 13740, loss = 2.8952
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 13750, loss = 25.6602
2024-10-29 13:28:03: [2024-10-29 13:28:03] iter = 13760, loss = 10.3310
2024-10-29 13:28:04: [2024-10-29 13:28:04] iter = 13770, loss = 14.2555
2024-10-29 13:28:05: [2024-10-29 13:28:05] iter = 13780, loss = 2.5133
2024-10-29 13:28:05: [2024-10-29 13:28:05] iter = 13790, loss = 3.0592
2024-10-29 13:28:06: [2024-10-29 13:28:06] iter = 13800, loss = 6.2585
2024-10-29 13:28:06: [2024-10-29 13:28:06] iter = 13810, loss = 2.9741
2024-10-29 13:28:07: [2024-10-29 13:28:07] iter = 13820, loss = 3.5492
2024-10-29 13:28:07: [2024-10-29 13:28:07] iter = 13830, loss = 29.8758
2024-10-29 13:28:08: [2024-10-29 13:28:08] iter = 13840, loss = 23.1703
2024-10-29 13:28:08: [2024-10-29 13:28:08] iter = 13850, loss = 2.0612
2024-10-29 13:28:09: [2024-10-29 13:28:09] iter = 13860, loss = 3.3615
2024-10-29 13:28:09: [2024-10-29 13:28:09] iter = 13870, loss = 26.4080
2024-10-29 13:28:10: [2024-10-29 13:28:10] iter = 13880, loss = 29.0381
2024-10-29 13:28:11: [2024-10-29 13:28:11] iter = 13890, loss = 12.1380
2024-10-29 13:28:11: [2024-10-29 13:28:11] iter = 13900, loss = 5.9073
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 13910, loss = 2.9944
2024-10-29 13:28:12: [2024-10-29 13:28:12] iter = 13920, loss = 9.8639
2024-10-29 13:28:13: [2024-10-29 13:28:13] iter = 13930, loss = 17.7847
2024-10-29 13:28:13: [2024-10-29 13:28:13] iter = 13940, loss = 4.4634
2024-10-29 13:28:14: [2024-10-29 13:28:14] iter = 13950, loss = 3.2893
2024-10-29 13:28:15: [2024-10-29 13:28:15] iter = 13960, loss = 6.0474
2024-10-29 13:28:15: [2024-10-29 13:28:15] iter = 13970, loss = 5.6716
2024-10-29 13:28:16: [2024-10-29 13:28:16] iter = 13980, loss = 3.5518
2024-10-29 13:28:17: [2024-10-29 13:28:17] iter = 13990, loss = 3.4278
2024-10-29 13:28:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-29 13:28:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:28:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97649}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:28:44: Evaluate 5 random ConvNet, ACCmean = 0.5176 ACCstd = 0.0120
-------------------------
2024-10-29 13:28:44: Evaluate 5 random ConvNet, SENmean = 0.5176 SENstd = 0.0120
-------------------------
2024-10-29 13:28:44: Evaluate 5 random ConvNet, SPEmean = 0.8392 SPEstd = 0.0040
-------------------------
2024-10-29 13:28:44: Evaluate 5 random ConvNet, F!mean = 0.4710 F!std = 0.0182
-------------------------
2024-10-29 13:28:44: Evaluate 5 random ConvNet, mean = 0.5176 std = 0.0120
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:28:44: [2024-10-29 13:28:44] iter = 14000, loss = 5.2602
2024-10-29 13:28:45: [2024-10-29 13:28:45] iter = 14010, loss = 3.0426
2024-10-29 13:28:45: [2024-10-29 13:28:45] iter = 14020, loss = 9.8081
2024-10-29 13:28:46: [2024-10-29 13:28:46] iter = 14030, loss = 15.5863
2024-10-29 13:28:46: [2024-10-29 13:28:46] iter = 14040, loss = 6.9417
2024-10-29 13:28:47: [2024-10-29 13:28:47] iter = 14050, loss = 7.4100
2024-10-29 13:28:47: [2024-10-29 13:28:47] iter = 14060, loss = 12.3365
2024-10-29 13:28:48: [2024-10-29 13:28:48] iter = 14070, loss = 4.3135
2024-10-29 13:28:49: [2024-10-29 13:28:49] iter = 14080, loss = 10.1262
2024-10-29 13:28:49: [2024-10-29 13:28:49] iter = 14090, loss = 12.1334
2024-10-29 13:28:50: [2024-10-29 13:28:50] iter = 14100, loss = 5.0617
2024-10-29 13:28:50: [2024-10-29 13:28:50] iter = 14110, loss = 10.8469
2024-10-29 13:28:51: [2024-10-29 13:28:51] iter = 14120, loss = 20.4522
2024-10-29 13:28:51: [2024-10-29 13:28:51] iter = 14130, loss = 7.3302
2024-10-29 13:28:52: [2024-10-29 13:28:52] iter = 14140, loss = 29.3266
2024-10-29 13:28:52: [2024-10-29 13:28:52] iter = 14150, loss = 5.8136
2024-10-29 13:28:53: [2024-10-29 13:28:53] iter = 14160, loss = 3.6591
2024-10-29 13:28:53: [2024-10-29 13:28:53] iter = 14170, loss = 19.7132
2024-10-29 13:28:54: [2024-10-29 13:28:54] iter = 14180, loss = 6.0708
2024-10-29 13:28:54: [2024-10-29 13:28:54] iter = 14190, loss = 6.0845
2024-10-29 13:28:55: [2024-10-29 13:28:55] iter = 14200, loss = 2.0673
2024-10-29 13:28:56: [2024-10-29 13:28:56] iter = 14210, loss = 3.2579
2024-10-29 13:28:56: [2024-10-29 13:28:56] iter = 14220, loss = 6.0058
2024-10-29 13:28:57: [2024-10-29 13:28:57] iter = 14230, loss = 108.8879
2024-10-29 13:28:57: [2024-10-29 13:28:57] iter = 14240, loss = 3.2704
2024-10-29 13:28:58: [2024-10-29 13:28:58] iter = 14250, loss = 14.7819
2024-10-29 13:28:58: [2024-10-29 13:28:58] iter = 14260, loss = 2.9514
2024-10-29 13:28:59: [2024-10-29 13:28:59] iter = 14270, loss = 3.5803
2024-10-29 13:28:59: [2024-10-29 13:28:59] iter = 14280, loss = 4.0507
2024-10-29 13:29:00: [2024-10-29 13:29:00] iter = 14290, loss = 6.6637
2024-10-29 13:29:00: [2024-10-29 13:29:00] iter = 14300, loss = 7.8675
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 14310, loss = 50.0251
2024-10-29 13:29:01: [2024-10-29 13:29:01] iter = 14320, loss = 3.9441
2024-10-29 13:29:02: [2024-10-29 13:29:02] iter = 14330, loss = 5.3226
2024-10-29 13:29:02: [2024-10-29 13:29:02] iter = 14340, loss = 2.5828
2024-10-29 13:29:03: [2024-10-29 13:29:03] iter = 14350, loss = 3.5302
2024-10-29 13:29:03: [2024-10-29 13:29:03] iter = 14360, loss = 3.4433
2024-10-29 13:29:04: [2024-10-29 13:29:04] iter = 14370, loss = 6.8216
2024-10-29 13:29:04: [2024-10-29 13:29:04] iter = 14380, loss = 2.8369
2024-10-29 13:29:05: [2024-10-29 13:29:05] iter = 14390, loss = 4.5629
2024-10-29 13:29:06: [2024-10-29 13:29:06] iter = 14400, loss = 7.4608
2024-10-29 13:29:06: [2024-10-29 13:29:06] iter = 14410, loss = 6.6007
2024-10-29 13:29:07: [2024-10-29 13:29:07] iter = 14420, loss = 10.1071
2024-10-29 13:29:07: [2024-10-29 13:29:07] iter = 14430, loss = 32.4115
2024-10-29 13:29:08: [2024-10-29 13:29:08] iter = 14440, loss = 12.6015
2024-10-29 13:29:08: [2024-10-29 13:29:08] iter = 14450, loss = 6.9863
2024-10-29 13:29:09: [2024-10-29 13:29:09] iter = 14460, loss = 4.1506
2024-10-29 13:29:10: [2024-10-29 13:29:10] iter = 14470, loss = 8.9415
2024-10-29 13:29:10: [2024-10-29 13:29:10] iter = 14480, loss = 8.4705
2024-10-29 13:29:11: [2024-10-29 13:29:11] iter = 14490, loss = 4.6450
2024-10-29 13:29:11: [2024-10-29 13:29:11] iter = 14500, loss = 5.9504
2024-10-29 13:29:12: [2024-10-29 13:29:12] iter = 14510, loss = 10.4858
2024-10-29 13:29:12: [2024-10-29 13:29:12] iter = 14520, loss = 7.8649
2024-10-29 13:29:13: [2024-10-29 13:29:13] iter = 14530, loss = 19.8077
2024-10-29 13:29:13: [2024-10-29 13:29:13] iter = 14540, loss = 9.5007
2024-10-29 13:29:14: [2024-10-29 13:29:14] iter = 14550, loss = 4.7220
2024-10-29 13:29:14: [2024-10-29 13:29:14] iter = 14560, loss = 12.9256
2024-10-29 13:29:15: [2024-10-29 13:29:15] iter = 14570, loss = 2.3874
2024-10-29 13:29:16: [2024-10-29 13:29:16] iter = 14580, loss = 4.3576
2024-10-29 13:29:16: [2024-10-29 13:29:16] iter = 14590, loss = 7.7547
2024-10-29 13:29:17: [2024-10-29 13:29:17] iter = 14600, loss = 14.6109
2024-10-29 13:29:17: [2024-10-29 13:29:17] iter = 14610, loss = 10.9879
2024-10-29 13:29:18: [2024-10-29 13:29:18] iter = 14620, loss = 3.4328
2024-10-29 13:29:18: [2024-10-29 13:29:18] iter = 14630, loss = 35.5475
2024-10-29 13:29:19: [2024-10-29 13:29:19] iter = 14640, loss = 10.1925
2024-10-29 13:29:19: [2024-10-29 13:29:19] iter = 14650, loss = 3.1701
2024-10-29 13:29:20: [2024-10-29 13:29:20] iter = 14660, loss = 4.5811
2024-10-29 13:29:20: [2024-10-29 13:29:20] iter = 14670, loss = 2.3138
2024-10-29 13:29:21: [2024-10-29 13:29:21] iter = 14680, loss = 6.3531
2024-10-29 13:29:21: [2024-10-29 13:29:21] iter = 14690, loss = 9.7270
2024-10-29 13:29:22: [2024-10-29 13:29:22] iter = 14700, loss = 3.6247
2024-10-29 13:29:22: [2024-10-29 13:29:22] iter = 14710, loss = 5.1270
2024-10-29 13:29:23: [2024-10-29 13:29:23] iter = 14720, loss = 18.1786
2024-10-29 13:29:23: [2024-10-29 13:29:23] iter = 14730, loss = 12.3686
2024-10-29 13:29:24: [2024-10-29 13:29:24] iter = 14740, loss = 11.4271
2024-10-29 13:29:24: [2024-10-29 13:29:24] iter = 14750, loss = 38.9125
2024-10-29 13:29:25: [2024-10-29 13:29:25] iter = 14760, loss = 4.3341
2024-10-29 13:29:26: [2024-10-29 13:29:26] iter = 14770, loss = 6.3037
2024-10-29 13:29:26: [2024-10-29 13:29:26] iter = 14780, loss = 13.5526
2024-10-29 13:29:27: [2024-10-29 13:29:27] iter = 14790, loss = 4.1271
2024-10-29 13:29:27: [2024-10-29 13:29:27] iter = 14800, loss = 4.5084
2024-10-29 13:29:28: [2024-10-29 13:29:28] iter = 14810, loss = 13.3748
2024-10-29 13:29:28: [2024-10-29 13:29:28] iter = 14820, loss = 4.4804
2024-10-29 13:29:29: [2024-10-29 13:29:29] iter = 14830, loss = 7.9890
2024-10-29 13:29:29: [2024-10-29 13:29:29] iter = 14840, loss = 8.2573
2024-10-29 13:29:30: [2024-10-29 13:29:30] iter = 14850, loss = 29.9138
2024-10-29 13:29:30: [2024-10-29 13:29:30] iter = 14860, loss = 3.5326
2024-10-29 13:29:31: [2024-10-29 13:29:31] iter = 14870, loss = 4.0853
2024-10-29 13:29:31: [2024-10-29 13:29:31] iter = 14880, loss = 3.6659
2024-10-29 13:29:32: [2024-10-29 13:29:32] iter = 14890, loss = 5.3497
2024-10-29 13:29:32: [2024-10-29 13:29:32] iter = 14900, loss = 3.4435
2024-10-29 13:29:33: [2024-10-29 13:29:33] iter = 14910, loss = 6.2403
2024-10-29 13:29:33: [2024-10-29 13:29:33] iter = 14920, loss = 14.1244
2024-10-29 13:29:33: [2024-10-29 13:29:33] iter = 14930, loss = 5.3667
2024-10-29 13:29:34: [2024-10-29 13:29:34] iter = 14940, loss = 3.6682
2024-10-29 13:29:35: [2024-10-29 13:29:35] iter = 14950, loss = 15.2866
2024-10-29 13:29:35: [2024-10-29 13:29:35] iter = 14960, loss = 9.9102
2024-10-29 13:29:36: [2024-10-29 13:29:36] iter = 14970, loss = 2.8596
2024-10-29 13:29:36: [2024-10-29 13:29:36] iter = 14980, loss = 7.6934
2024-10-29 13:29:36: [2024-10-29 13:29:36] iter = 14990, loss = 5.4726
2024-10-29 13:29:37: [2024-10-29 13:29:37] iter = 15000, loss = 9.3062
2024-10-29 13:29:37: [2024-10-29 13:29:37] iter = 15010, loss = 4.2926
2024-10-29 13:29:38: [2024-10-29 13:29:38] iter = 15020, loss = 6.6768
2024-10-29 13:29:38: [2024-10-29 13:29:38] iter = 15030, loss = 2.6188
2024-10-29 13:29:39: [2024-10-29 13:29:39] iter = 15040, loss = 24.5036
2024-10-29 13:29:39: [2024-10-29 13:29:39] iter = 15050, loss = 7.5597
2024-10-29 13:29:40: [2024-10-29 13:29:40] iter = 15060, loss = 54.1242
2024-10-29 13:29:40: [2024-10-29 13:29:40] iter = 15070, loss = 4.2797
2024-10-29 13:29:41: [2024-10-29 13:29:41] iter = 15080, loss = 2.1683
2024-10-29 13:29:41: [2024-10-29 13:29:41] iter = 15090, loss = 2.5422
2024-10-29 13:29:42: [2024-10-29 13:29:42] iter = 15100, loss = 2.8210
2024-10-29 13:29:43: [2024-10-29 13:29:43] iter = 15110, loss = 5.6010
2024-10-29 13:29:43: [2024-10-29 13:29:43] iter = 15120, loss = 3.6691
2024-10-29 13:29:44: [2024-10-29 13:29:44] iter = 15130, loss = 4.6250
2024-10-29 13:29:44: [2024-10-29 13:29:44] iter = 15140, loss = 4.2008
2024-10-29 13:29:45: [2024-10-29 13:29:45] iter = 15150, loss = 6.2721
2024-10-29 13:29:46: [2024-10-29 13:29:46] iter = 15160, loss = 7.9904
2024-10-29 13:29:46: [2024-10-29 13:29:46] iter = 15170, loss = 5.5325
2024-10-29 13:29:47: [2024-10-29 13:29:47] iter = 15180, loss = 4.7680
2024-10-29 13:29:47: [2024-10-29 13:29:47] iter = 15190, loss = 14.5289
2024-10-29 13:29:48: [2024-10-29 13:29:48] iter = 15200, loss = 9.5994
2024-10-29 13:29:48: [2024-10-29 13:29:48] iter = 15210, loss = 7.2968
2024-10-29 13:29:49: [2024-10-29 13:29:49] iter = 15220, loss = 6.1991
2024-10-29 13:29:50: [2024-10-29 13:29:50] iter = 15230, loss = 5.0731
2024-10-29 13:29:50: [2024-10-29 13:29:50] iter = 15240, loss = 3.3606
2024-10-29 13:29:51: [2024-10-29 13:29:51] iter = 15250, loss = 3.2890
2024-10-29 13:29:51: [2024-10-29 13:29:51] iter = 15260, loss = 4.9227
2024-10-29 13:29:52: [2024-10-29 13:29:52] iter = 15270, loss = 4.4296
2024-10-29 13:29:52: [2024-10-29 13:29:52] iter = 15280, loss = 7.7246
2024-10-29 13:29:53: [2024-10-29 13:29:53] iter = 15290, loss = 6.2619
2024-10-29 13:29:53: [2024-10-29 13:29:53] iter = 15300, loss = 5.2905
2024-10-29 13:29:54: [2024-10-29 13:29:54] iter = 15310, loss = 6.2587
2024-10-29 13:29:54: [2024-10-29 13:29:54] iter = 15320, loss = 3.2813
2024-10-29 13:29:55: [2024-10-29 13:29:55] iter = 15330, loss = 3.2716
2024-10-29 13:29:55: [2024-10-29 13:29:55] iter = 15340, loss = 9.4945
2024-10-29 13:29:56: [2024-10-29 13:29:56] iter = 15350, loss = 3.9838
2024-10-29 13:29:57: [2024-10-29 13:29:57] iter = 15360, loss = 8.2880
2024-10-29 13:29:57: [2024-10-29 13:29:57] iter = 15370, loss = 2.5340
2024-10-29 13:29:58: [2024-10-29 13:29:58] iter = 15380, loss = 2.6479
2024-10-29 13:29:59: [2024-10-29 13:29:59] iter = 15390, loss = 10.9081
2024-10-29 13:29:59: [2024-10-29 13:29:59] iter = 15400, loss = 6.6010
2024-10-29 13:30:00: [2024-10-29 13:30:00] iter = 15410, loss = 13.5055
2024-10-29 13:30:00: [2024-10-29 13:30:00] iter = 15420, loss = 6.4356
2024-10-29 13:30:01: [2024-10-29 13:30:01] iter = 15430, loss = 40.0919
2024-10-29 13:30:01: [2024-10-29 13:30:01] iter = 15440, loss = 3.5792
2024-10-29 13:30:02: [2024-10-29 13:30:02] iter = 15450, loss = 20.4196
2024-10-29 13:30:02: [2024-10-29 13:30:02] iter = 15460, loss = 7.0950
2024-10-29 13:30:03: [2024-10-29 13:30:03] iter = 15470, loss = 4.1243
2024-10-29 13:30:03: [2024-10-29 13:30:03] iter = 15480, loss = 2.6147
2024-10-29 13:30:04: [2024-10-29 13:30:04] iter = 15490, loss = 3.4235
2024-10-29 13:30:04: [2024-10-29 13:30:04] iter = 15500, loss = 24.0376
2024-10-29 13:30:05: [2024-10-29 13:30:05] iter = 15510, loss = 3.2620
2024-10-29 13:30:05: [2024-10-29 13:30:05] iter = 15520, loss = 3.9129
2024-10-29 13:30:06: [2024-10-29 13:30:06] iter = 15530, loss = 9.3675
2024-10-29 13:30:06: [2024-10-29 13:30:06] iter = 15540, loss = 10.8897
2024-10-29 13:30:07: [2024-10-29 13:30:07] iter = 15550, loss = 4.2669
2024-10-29 13:30:07: [2024-10-29 13:30:07] iter = 15560, loss = 5.5310
2024-10-29 13:30:08: [2024-10-29 13:30:08] iter = 15570, loss = 4.5167
2024-10-29 13:30:08: [2024-10-29 13:30:08] iter = 15580, loss = 3.5210
2024-10-29 13:30:09: [2024-10-29 13:30:09] iter = 15590, loss = 5.5607
2024-10-29 13:30:09: [2024-10-29 13:30:09] iter = 15600, loss = 5.3040
2024-10-29 13:30:10: [2024-10-29 13:30:10] iter = 15610, loss = 26.5248
2024-10-29 13:30:10: [2024-10-29 13:30:10] iter = 15620, loss = 41.9905
2024-10-29 13:30:11: [2024-10-29 13:30:11] iter = 15630, loss = 21.6095
2024-10-29 13:30:11: [2024-10-29 13:30:11] iter = 15640, loss = 12.6721
2024-10-29 13:30:12: [2024-10-29 13:30:12] iter = 15650, loss = 5.2918
2024-10-29 13:30:12: [2024-10-29 13:30:12] iter = 15660, loss = 3.4974
2024-10-29 13:30:13: [2024-10-29 13:30:13] iter = 15670, loss = 3.6150
2024-10-29 13:30:13: [2024-10-29 13:30:13] iter = 15680, loss = 8.1741
2024-10-29 13:30:14: [2024-10-29 13:30:14] iter = 15690, loss = 9.0542
2024-10-29 13:30:14: [2024-10-29 13:30:14] iter = 15700, loss = 9.4554
2024-10-29 13:30:15: [2024-10-29 13:30:15] iter = 15710, loss = 2.9282
2024-10-29 13:30:15: [2024-10-29 13:30:15] iter = 15720, loss = 3.7890
2024-10-29 13:30:16: [2024-10-29 13:30:16] iter = 15730, loss = 13.2423
2024-10-29 13:30:16: [2024-10-29 13:30:16] iter = 15740, loss = 3.2859
2024-10-29 13:30:17: [2024-10-29 13:30:17] iter = 15750, loss = 26.4625
2024-10-29 13:30:17: [2024-10-29 13:30:17] iter = 15760, loss = 13.0122
2024-10-29 13:30:18: [2024-10-29 13:30:18] iter = 15770, loss = 9.9505
2024-10-29 13:30:18: [2024-10-29 13:30:18] iter = 15780, loss = 8.3166
2024-10-29 13:30:19: [2024-10-29 13:30:19] iter = 15790, loss = 3.6278
2024-10-29 13:30:19: [2024-10-29 13:30:19] iter = 15800, loss = 5.4905
2024-10-29 13:30:20: [2024-10-29 13:30:20] iter = 15810, loss = 3.3435
2024-10-29 13:30:20: [2024-10-29 13:30:20] iter = 15820, loss = 3.0569
2024-10-29 13:30:21: [2024-10-29 13:30:21] iter = 15830, loss = 4.2030
2024-10-29 13:30:22: [2024-10-29 13:30:22] iter = 15840, loss = 6.5282
2024-10-29 13:30:22: [2024-10-29 13:30:22] iter = 15850, loss = 4.6601
2024-10-29 13:30:23: [2024-10-29 13:30:23] iter = 15860, loss = 18.3507
2024-10-29 13:30:23: [2024-10-29 13:30:23] iter = 15870, loss = 7.9402
2024-10-29 13:30:24: [2024-10-29 13:30:24] iter = 15880, loss = 4.0940
2024-10-29 13:30:24: [2024-10-29 13:30:24] iter = 15890, loss = 20.5277
2024-10-29 13:30:25: [2024-10-29 13:30:25] iter = 15900, loss = 11.7552
2024-10-29 13:30:25: [2024-10-29 13:30:25] iter = 15910, loss = 3.1891
2024-10-29 13:30:26: [2024-10-29 13:30:26] iter = 15920, loss = 14.5370
2024-10-29 13:30:26: [2024-10-29 13:30:26] iter = 15930, loss = 4.3921
2024-10-29 13:30:27: [2024-10-29 13:30:27] iter = 15940, loss = 5.5260
2024-10-29 13:30:27: [2024-10-29 13:30:27] iter = 15950, loss = 33.0196
2024-10-29 13:30:28: [2024-10-29 13:30:28] iter = 15960, loss = 4.3890
2024-10-29 13:30:28: [2024-10-29 13:30:28] iter = 15970, loss = 5.4391
2024-10-29 13:30:29: [2024-10-29 13:30:29] iter = 15980, loss = 17.2575
2024-10-29 13:30:29: [2024-10-29 13:30:29] iter = 15990, loss = 14.7862
2024-10-29 13:30:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-29 13:30:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:30:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30150}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:30:56: Evaluate 5 random ConvNet, ACCmean = 0.5192 ACCstd = 0.0113
-------------------------
2024-10-29 13:30:56: Evaluate 5 random ConvNet, SENmean = 0.5192 SENstd = 0.0113
-------------------------
2024-10-29 13:30:56: Evaluate 5 random ConvNet, SPEmean = 0.8397 SPEstd = 0.0038
-------------------------
2024-10-29 13:30:56: Evaluate 5 random ConvNet, F!mean = 0.4751 F!std = 0.0116
-------------------------
2024-10-29 13:30:56: Evaluate 5 random ConvNet, mean = 0.5192 std = 0.0113
-------------------------
2024-10-29 13:30:56: [2024-10-29 13:30:56] iter = 16000, loss = 15.3796
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:30:57: [2024-10-29 13:30:57] iter = 16010, loss = 7.3395
2024-10-29 13:30:57: [2024-10-29 13:30:57] iter = 16020, loss = 37.9884
2024-10-29 13:30:58: [2024-10-29 13:30:58] iter = 16030, loss = 3.8188
2024-10-29 13:30:58: [2024-10-29 13:30:58] iter = 16040, loss = 7.7723
2024-10-29 13:30:59: [2024-10-29 13:30:59] iter = 16050, loss = 5.4095
2024-10-29 13:30:59: [2024-10-29 13:30:59] iter = 16060, loss = 4.3260
2024-10-29 13:31:00: [2024-10-29 13:31:00] iter = 16070, loss = 2.7630
2024-10-29 13:31:01: [2024-10-29 13:31:01] iter = 16080, loss = 12.1214
2024-10-29 13:31:01: [2024-10-29 13:31:01] iter = 16090, loss = 3.6126
2024-10-29 13:31:02: [2024-10-29 13:31:02] iter = 16100, loss = 7.6447
2024-10-29 13:31:02: [2024-10-29 13:31:02] iter = 16110, loss = 11.0260
2024-10-29 13:31:03: [2024-10-29 13:31:03] iter = 16120, loss = 32.1177
2024-10-29 13:31:03: [2024-10-29 13:31:03] iter = 16130, loss = 4.0030
2024-10-29 13:31:04: [2024-10-29 13:31:04] iter = 16140, loss = 21.4045
2024-10-29 13:31:04: [2024-10-29 13:31:04] iter = 16150, loss = 8.5460
2024-10-29 13:31:05: [2024-10-29 13:31:05] iter = 16160, loss = 6.1517
2024-10-29 13:31:05: [2024-10-29 13:31:05] iter = 16170, loss = 38.4409
2024-10-29 13:31:06: [2024-10-29 13:31:06] iter = 16180, loss = 8.2789
2024-10-29 13:31:07: [2024-10-29 13:31:07] iter = 16190, loss = 5.8720
2024-10-29 13:31:07: [2024-10-29 13:31:07] iter = 16200, loss = 6.6552
2024-10-29 13:31:08: [2024-10-29 13:31:08] iter = 16210, loss = 4.4928
2024-10-29 13:31:08: [2024-10-29 13:31:08] iter = 16220, loss = 3.9091
2024-10-29 13:31:09: [2024-10-29 13:31:09] iter = 16230, loss = 2.8132
2024-10-29 13:31:09: [2024-10-29 13:31:09] iter = 16240, loss = 3.4482
2024-10-29 13:31:10: [2024-10-29 13:31:10] iter = 16250, loss = 15.2394
2024-10-29 13:31:10: [2024-10-29 13:31:10] iter = 16260, loss = 3.8742
2024-10-29 13:31:11: [2024-10-29 13:31:11] iter = 16270, loss = 4.1342
2024-10-29 13:31:11: [2024-10-29 13:31:11] iter = 16280, loss = 3.5344
2024-10-29 13:31:12: [2024-10-29 13:31:12] iter = 16290, loss = 3.8617
2024-10-29 13:31:13: [2024-10-29 13:31:13] iter = 16300, loss = 6.1830
2024-10-29 13:31:13: [2024-10-29 13:31:13] iter = 16310, loss = 3.5356
2024-10-29 13:31:14: [2024-10-29 13:31:14] iter = 16320, loss = 7.8821
2024-10-29 13:31:14: [2024-10-29 13:31:14] iter = 16330, loss = 9.1396
2024-10-29 13:31:15: [2024-10-29 13:31:15] iter = 16340, loss = 10.3488
2024-10-29 13:31:15: [2024-10-29 13:31:15] iter = 16350, loss = 5.1996
2024-10-29 13:31:16: [2024-10-29 13:31:16] iter = 16360, loss = 8.7838
2024-10-29 13:31:16: [2024-10-29 13:31:16] iter = 16370, loss = 3.5717
2024-10-29 13:31:17: [2024-10-29 13:31:17] iter = 16380, loss = 23.7382
2024-10-29 13:31:17: [2024-10-29 13:31:17] iter = 16390, loss = 3.8693
2024-10-29 13:31:18: [2024-10-29 13:31:18] iter = 16400, loss = 3.8806
2024-10-29 13:31:18: [2024-10-29 13:31:18] iter = 16410, loss = 4.5029
2024-10-29 13:31:19: [2024-10-29 13:31:19] iter = 16420, loss = 11.4322
2024-10-29 13:31:19: [2024-10-29 13:31:19] iter = 16430, loss = 3.1355
2024-10-29 13:31:20: [2024-10-29 13:31:20] iter = 16440, loss = 2.8708
2024-10-29 13:31:20: [2024-10-29 13:31:20] iter = 16450, loss = 70.0281
2024-10-29 13:31:21: [2024-10-29 13:31:21] iter = 16460, loss = 6.3433
2024-10-29 13:31:21: [2024-10-29 13:31:21] iter = 16470, loss = 4.1115
2024-10-29 13:31:22: [2024-10-29 13:31:22] iter = 16480, loss = 28.2646
2024-10-29 13:31:22: [2024-10-29 13:31:22] iter = 16490, loss = 10.6031
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 16500, loss = 30.8492
2024-10-29 13:31:23: [2024-10-29 13:31:23] iter = 16510, loss = 34.5501
2024-10-29 13:31:24: [2024-10-29 13:31:24] iter = 16520, loss = 7.7703
2024-10-29 13:31:25: [2024-10-29 13:31:25] iter = 16530, loss = 6.6857
2024-10-29 13:31:25: [2024-10-29 13:31:25] iter = 16540, loss = 2.7475
2024-10-29 13:31:26: [2024-10-29 13:31:26] iter = 16550, loss = 3.4347
2024-10-29 13:31:26: [2024-10-29 13:31:26] iter = 16560, loss = 6.0072
2024-10-29 13:31:27: [2024-10-29 13:31:26] iter = 16570, loss = 24.5836
2024-10-29 13:31:27: [2024-10-29 13:31:27] iter = 16580, loss = 3.3445
2024-10-29 13:31:28: [2024-10-29 13:31:28] iter = 16590, loss = 3.8500
2024-10-29 13:31:28: [2024-10-29 13:31:28] iter = 16600, loss = 3.4908
2024-10-29 13:31:29: [2024-10-29 13:31:29] iter = 16610, loss = 4.3207
2024-10-29 13:31:29: [2024-10-29 13:31:29] iter = 16620, loss = 9.9044
2024-10-29 13:31:30: [2024-10-29 13:31:30] iter = 16630, loss = 5.1729
2024-10-29 13:31:30: [2024-10-29 13:31:30] iter = 16640, loss = 3.4458
2024-10-29 13:31:31: [2024-10-29 13:31:31] iter = 16650, loss = 11.3519
2024-10-29 13:31:31: [2024-10-29 13:31:31] iter = 16660, loss = 11.6612
2024-10-29 13:31:32: [2024-10-29 13:31:32] iter = 16670, loss = 6.7946
2024-10-29 13:31:32: [2024-10-29 13:31:32] iter = 16680, loss = 10.5088
2024-10-29 13:31:33: [2024-10-29 13:31:33] iter = 16690, loss = 2.7615
2024-10-29 13:31:33: [2024-10-29 13:31:33] iter = 16700, loss = 3.9294
2024-10-29 13:31:34: [2024-10-29 13:31:34] iter = 16710, loss = 4.4090
2024-10-29 13:31:35: [2024-10-29 13:31:35] iter = 16720, loss = 10.2508
2024-10-29 13:31:35: [2024-10-29 13:31:35] iter = 16730, loss = 3.9910
2024-10-29 13:31:36: [2024-10-29 13:31:36] iter = 16740, loss = 3.8260
2024-10-29 13:31:36: [2024-10-29 13:31:36] iter = 16750, loss = 4.2648
2024-10-29 13:31:37: [2024-10-29 13:31:37] iter = 16760, loss = 14.4709
2024-10-29 13:31:37: [2024-10-29 13:31:37] iter = 16770, loss = 6.6606
2024-10-29 13:31:38: [2024-10-29 13:31:38] iter = 16780, loss = 9.7980
2024-10-29 13:31:38: [2024-10-29 13:31:38] iter = 16790, loss = 7.6578
2024-10-29 13:31:39: [2024-10-29 13:31:39] iter = 16800, loss = 6.6498
2024-10-29 13:31:39: [2024-10-29 13:31:39] iter = 16810, loss = 4.9559
2024-10-29 13:31:40: [2024-10-29 13:31:40] iter = 16820, loss = 27.6476
2024-10-29 13:31:41: [2024-10-29 13:31:41] iter = 16830, loss = 5.4386
2024-10-29 13:31:41: [2024-10-29 13:31:41] iter = 16840, loss = 7.5601
2024-10-29 13:31:42: [2024-10-29 13:31:42] iter = 16850, loss = 3.9705
2024-10-29 13:31:42: [2024-10-29 13:31:42] iter = 16860, loss = 4.4019
2024-10-29 13:31:43: [2024-10-29 13:31:43] iter = 16870, loss = 3.0797
2024-10-29 13:31:43: [2024-10-29 13:31:43] iter = 16880, loss = 4.1025
2024-10-29 13:31:44: [2024-10-29 13:31:44] iter = 16890, loss = 5.8167
2024-10-29 13:31:44: [2024-10-29 13:31:44] iter = 16900, loss = 57.7707
2024-10-29 13:31:45: [2024-10-29 13:31:45] iter = 16910, loss = 9.7290
2024-10-29 13:31:46: [2024-10-29 13:31:46] iter = 16920, loss = 5.1375
2024-10-29 13:31:46: [2024-10-29 13:31:46] iter = 16930, loss = 9.0763
2024-10-29 13:31:47: [2024-10-29 13:31:47] iter = 16940, loss = 6.4954
2024-10-29 13:31:47: [2024-10-29 13:31:47] iter = 16950, loss = 5.9785
2024-10-29 13:31:48: [2024-10-29 13:31:48] iter = 16960, loss = 7.8331
2024-10-29 13:31:49: [2024-10-29 13:31:49] iter = 16970, loss = 2.5118
2024-10-29 13:31:49: [2024-10-29 13:31:49] iter = 16980, loss = 5.5208
2024-10-29 13:31:50: [2024-10-29 13:31:50] iter = 16990, loss = 10.8903
2024-10-29 13:31:50: [2024-10-29 13:31:50] iter = 17000, loss = 27.2693
2024-10-29 13:31:51: [2024-10-29 13:31:51] iter = 17010, loss = 4.7914
2024-10-29 13:31:51: [2024-10-29 13:31:51] iter = 17020, loss = 6.5015
2024-10-29 13:31:52: [2024-10-29 13:31:52] iter = 17030, loss = 8.0791
2024-10-29 13:31:52: [2024-10-29 13:31:52] iter = 17040, loss = 2.4634
2024-10-29 13:31:53: [2024-10-29 13:31:53] iter = 17050, loss = 3.4089
2024-10-29 13:31:53: [2024-10-29 13:31:53] iter = 17060, loss = 2.6613
2024-10-29 13:31:54: [2024-10-29 13:31:54] iter = 17070, loss = 9.8867
2024-10-29 13:31:54: [2024-10-29 13:31:54] iter = 17080, loss = 5.8934
2024-10-29 13:31:55: [2024-10-29 13:31:55] iter = 17090, loss = 7.8055
2024-10-29 13:31:55: [2024-10-29 13:31:55] iter = 17100, loss = 2.4446
2024-10-29 13:31:56: [2024-10-29 13:31:56] iter = 17110, loss = 18.9637
2024-10-29 13:31:56: [2024-10-29 13:31:56] iter = 17120, loss = 11.2137
2024-10-29 13:31:57: [2024-10-29 13:31:57] iter = 17130, loss = 17.7730
2024-10-29 13:31:57: [2024-10-29 13:31:57] iter = 17140, loss = 5.2904
2024-10-29 13:31:58: [2024-10-29 13:31:58] iter = 17150, loss = 9.4329
2024-10-29 13:31:58: [2024-10-29 13:31:58] iter = 17160, loss = 4.6677
2024-10-29 13:31:59: [2024-10-29 13:31:59] iter = 17170, loss = 11.5891
2024-10-29 13:31:59: [2024-10-29 13:31:59] iter = 17180, loss = 3.5951
2024-10-29 13:32:00: [2024-10-29 13:32:00] iter = 17190, loss = 5.9738
2024-10-29 13:32:00: [2024-10-29 13:32:00] iter = 17200, loss = 9.0799
2024-10-29 13:32:01: [2024-10-29 13:32:01] iter = 17210, loss = 6.0984
2024-10-29 13:32:01: [2024-10-29 13:32:01] iter = 17220, loss = 11.7115
2024-10-29 13:32:02: [2024-10-29 13:32:02] iter = 17230, loss = 2.8543
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 17240, loss = 4.2457
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 17250, loss = 6.5843
2024-10-29 13:32:03: [2024-10-29 13:32:03] iter = 17260, loss = 5.8704
2024-10-29 13:32:04: [2024-10-29 13:32:04] iter = 17270, loss = 18.2939
2024-10-29 13:32:05: [2024-10-29 13:32:05] iter = 17280, loss = 2.9631
2024-10-29 13:32:05: [2024-10-29 13:32:05] iter = 17290, loss = 30.4970
2024-10-29 13:32:06: [2024-10-29 13:32:06] iter = 17300, loss = 3.2339
2024-10-29 13:32:06: [2024-10-29 13:32:06] iter = 17310, loss = 12.2073
2024-10-29 13:32:07: [2024-10-29 13:32:07] iter = 17320, loss = 40.3592
2024-10-29 13:32:07: [2024-10-29 13:32:07] iter = 17330, loss = 19.0674
2024-10-29 13:32:08: [2024-10-29 13:32:08] iter = 17340, loss = 3.6234
2024-10-29 13:32:09: [2024-10-29 13:32:09] iter = 17350, loss = 4.8598
2024-10-29 13:32:09: [2024-10-29 13:32:09] iter = 17360, loss = 11.7824
2024-10-29 13:32:10: [2024-10-29 13:32:10] iter = 17370, loss = 12.1127
2024-10-29 13:32:10: [2024-10-29 13:32:10] iter = 17380, loss = 3.3245
2024-10-29 13:32:11: [2024-10-29 13:32:11] iter = 17390, loss = 37.2878
2024-10-29 13:32:11: [2024-10-29 13:32:11] iter = 17400, loss = 33.9605
2024-10-29 13:32:12: [2024-10-29 13:32:12] iter = 17410, loss = 3.6881
2024-10-29 13:32:12: [2024-10-29 13:32:12] iter = 17420, loss = 3.9207
2024-10-29 13:32:13: [2024-10-29 13:32:13] iter = 17430, loss = 17.5617
2024-10-29 13:32:14: [2024-10-29 13:32:14] iter = 17440, loss = 14.5988
2024-10-29 13:32:14: [2024-10-29 13:32:14] iter = 17450, loss = 5.1490
2024-10-29 13:32:15: [2024-10-29 13:32:15] iter = 17460, loss = 4.7905
2024-10-29 13:32:16: [2024-10-29 13:32:16] iter = 17470, loss = 15.8078
2024-10-29 13:32:16: [2024-10-29 13:32:16] iter = 17480, loss = 3.1515
2024-10-29 13:32:17: [2024-10-29 13:32:17] iter = 17490, loss = 6.8821
2024-10-29 13:32:17: [2024-10-29 13:32:17] iter = 17500, loss = 3.1197
2024-10-29 13:32:18: [2024-10-29 13:32:18] iter = 17510, loss = 17.3930
2024-10-29 13:32:18: [2024-10-29 13:32:18] iter = 17520, loss = 16.7023
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 17530, loss = 3.4017
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 17540, loss = 3.9357
2024-10-29 13:32:19: [2024-10-29 13:32:19] iter = 17550, loss = 12.2023
2024-10-29 13:32:20: [2024-10-29 13:32:20] iter = 17560, loss = 3.3160
2024-10-29 13:32:20: [2024-10-29 13:32:20] iter = 17570, loss = 7.8184
2024-10-29 13:32:21: [2024-10-29 13:32:21] iter = 17580, loss = 4.7854
2024-10-29 13:32:21: [2024-10-29 13:32:21] iter = 17590, loss = 3.7327
2024-10-29 13:32:22: [2024-10-29 13:32:22] iter = 17600, loss = 5.0930
2024-10-29 13:32:22: [2024-10-29 13:32:22] iter = 17610, loss = 6.2549
2024-10-29 13:32:23: [2024-10-29 13:32:23] iter = 17620, loss = 3.2298
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 17630, loss = 7.4561
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 17640, loss = 2.9490
2024-10-29 13:32:24: [2024-10-29 13:32:24] iter = 17650, loss = 8.5176
2024-10-29 13:32:25: [2024-10-29 13:32:25] iter = 17660, loss = 8.8064
2024-10-29 13:32:26: [2024-10-29 13:32:26] iter = 17670, loss = 3.3513
2024-10-29 13:32:26: [2024-10-29 13:32:26] iter = 17680, loss = 8.8694
2024-10-29 13:32:27: [2024-10-29 13:32:27] iter = 17690, loss = 6.8436
2024-10-29 13:32:27: [2024-10-29 13:32:27] iter = 17700, loss = 38.0694
2024-10-29 13:32:28: [2024-10-29 13:32:28] iter = 17710, loss = 7.3342
2024-10-29 13:32:28: [2024-10-29 13:32:28] iter = 17720, loss = 3.3856
2024-10-29 13:32:29: [2024-10-29 13:32:29] iter = 17730, loss = 8.7692
2024-10-29 13:32:29: [2024-10-29 13:32:29] iter = 17740, loss = 9.9871
2024-10-29 13:32:30: [2024-10-29 13:32:30] iter = 17750, loss = 2.5744
2024-10-29 13:32:30: [2024-10-29 13:32:30] iter = 17760, loss = 9.5713
2024-10-29 13:32:31: [2024-10-29 13:32:31] iter = 17770, loss = 9.4895
2024-10-29 13:32:32: [2024-10-29 13:32:32] iter = 17780, loss = 5.3062
2024-10-29 13:32:32: [2024-10-29 13:32:32] iter = 17790, loss = 3.9965
2024-10-29 13:32:33: [2024-10-29 13:32:33] iter = 17800, loss = 2.7323
2024-10-29 13:32:33: [2024-10-29 13:32:33] iter = 17810, loss = 5.1269
2024-10-29 13:32:34: [2024-10-29 13:32:34] iter = 17820, loss = 7.3783
2024-10-29 13:32:34: [2024-10-29 13:32:34] iter = 17830, loss = 4.2832
2024-10-29 13:32:35: [2024-10-29 13:32:35] iter = 17840, loss = 4.3192
2024-10-29 13:32:35: [2024-10-29 13:32:35] iter = 17850, loss = 3.0797
2024-10-29 13:32:36: [2024-10-29 13:32:36] iter = 17860, loss = 8.3066
2024-10-29 13:32:36: [2024-10-29 13:32:36] iter = 17870, loss = 3.8576
2024-10-29 13:32:37: [2024-10-29 13:32:37] iter = 17880, loss = 4.5179
2024-10-29 13:32:37: [2024-10-29 13:32:37] iter = 17890, loss = 2.2188
2024-10-29 13:32:38: [2024-10-29 13:32:38] iter = 17900, loss = 4.3365
2024-10-29 13:32:38: [2024-10-29 13:32:38] iter = 17910, loss = 9.5917
2024-10-29 13:32:39: [2024-10-29 13:32:39] iter = 17920, loss = 20.5173
2024-10-29 13:32:39: [2024-10-29 13:32:39] iter = 17930, loss = 3.4259
2024-10-29 13:32:40: [2024-10-29 13:32:40] iter = 17940, loss = 4.3102
2024-10-29 13:32:40: [2024-10-29 13:32:40] iter = 17950, loss = 5.4076
2024-10-29 13:32:41: [2024-10-29 13:32:41] iter = 17960, loss = 2.5502
2024-10-29 13:32:41: [2024-10-29 13:32:41] iter = 17970, loss = 5.8277
2024-10-29 13:32:42: [2024-10-29 13:32:42] iter = 17980, loss = 4.0607
2024-10-29 13:32:42: [2024-10-29 13:32:42] iter = 17990, loss = 7.4239
2024-10-29 13:32:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-29 13:32:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:32:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63272}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:33:10: Evaluate 5 random ConvNet, ACCmean = 0.5262 ACCstd = 0.0117
-------------------------
2024-10-29 13:33:10: Evaluate 5 random ConvNet, SENmean = 0.5262 SENstd = 0.0117
-------------------------
2024-10-29 13:33:10: Evaluate 5 random ConvNet, SPEmean = 0.8421 SPEstd = 0.0039
-------------------------
2024-10-29 13:33:10: Evaluate 5 random ConvNet, F!mean = 0.4749 F!std = 0.0129
-------------------------
2024-10-29 13:33:10: Evaluate 5 random ConvNet, mean = 0.5262 std = 0.0117
-------------------------
2024-10-29 13:33:10: [2024-10-29 13:33:10] iter = 18000, loss = 10.6666
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:33:10: [2024-10-29 13:33:10] iter = 18010, loss = 16.9832
2024-10-29 13:33:11: [2024-10-29 13:33:11] iter = 18020, loss = 3.3287
2024-10-29 13:33:11: [2024-10-29 13:33:11] iter = 18030, loss = 13.5972
2024-10-29 13:33:12: [2024-10-29 13:33:12] iter = 18040, loss = 34.6418
2024-10-29 13:33:13: [2024-10-29 13:33:13] iter = 18050, loss = 10.2077
2024-10-29 13:33:13: [2024-10-29 13:33:13] iter = 18060, loss = 8.3178
2024-10-29 13:33:14: [2024-10-29 13:33:14] iter = 18070, loss = 5.8864
2024-10-29 13:33:14: [2024-10-29 13:33:14] iter = 18080, loss = 11.4154
2024-10-29 13:33:15: [2024-10-29 13:33:15] iter = 18090, loss = 5.6832
2024-10-29 13:33:15: [2024-10-29 13:33:15] iter = 18100, loss = 6.5034
2024-10-29 13:33:16: [2024-10-29 13:33:16] iter = 18110, loss = 4.1280
2024-10-29 13:33:17: [2024-10-29 13:33:17] iter = 18120, loss = 7.4307
2024-10-29 13:33:17: [2024-10-29 13:33:17] iter = 18130, loss = 3.3386
2024-10-29 13:33:17: [2024-10-29 13:33:17] iter = 18140, loss = 10.0125
2024-10-29 13:33:18: [2024-10-29 13:33:18] iter = 18150, loss = 9.5004
2024-10-29 13:33:18: [2024-10-29 13:33:18] iter = 18160, loss = 28.6077
2024-10-29 13:33:19: [2024-10-29 13:33:19] iter = 18170, loss = 3.3750
2024-10-29 13:33:20: [2024-10-29 13:33:20] iter = 18180, loss = 2.8713
2024-10-29 13:33:20: [2024-10-29 13:33:20] iter = 18190, loss = 4.9246
2024-10-29 13:33:21: [2024-10-29 13:33:21] iter = 18200, loss = 2.6057
2024-10-29 13:33:21: [2024-10-29 13:33:21] iter = 18210, loss = 8.0308
2024-10-29 13:33:22: [2024-10-29 13:33:22] iter = 18220, loss = 7.2795
2024-10-29 13:33:22: [2024-10-29 13:33:22] iter = 18230, loss = 7.9911
2024-10-29 13:33:23: [2024-10-29 13:33:23] iter = 18240, loss = 4.9216
2024-10-29 13:33:23: [2024-10-29 13:33:23] iter = 18250, loss = 3.6453
2024-10-29 13:33:24: [2024-10-29 13:33:24] iter = 18260, loss = 4.5029
2024-10-29 13:33:24: [2024-10-29 13:33:24] iter = 18270, loss = 38.3251
2024-10-29 13:33:25: [2024-10-29 13:33:25] iter = 18280, loss = 30.1534
2024-10-29 13:33:25: [2024-10-29 13:33:25] iter = 18290, loss = 4.2338
2024-10-29 13:33:26: [2024-10-29 13:33:26] iter = 18300, loss = 2.3101
2024-10-29 13:33:26: [2024-10-29 13:33:26] iter = 18310, loss = 4.5855
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 18320, loss = 5.0087
2024-10-29 13:33:27: [2024-10-29 13:33:27] iter = 18330, loss = 10.5185
2024-10-29 13:33:28: [2024-10-29 13:33:28] iter = 18340, loss = 2.1703
2024-10-29 13:33:28: [2024-10-29 13:33:28] iter = 18350, loss = 7.9031
2024-10-29 13:33:29: [2024-10-29 13:33:29] iter = 18360, loss = 3.1065
2024-10-29 13:33:29: [2024-10-29 13:33:29] iter = 18370, loss = 3.9322
2024-10-29 13:33:30: [2024-10-29 13:33:30] iter = 18380, loss = 8.8765
2024-10-29 13:33:31: [2024-10-29 13:33:31] iter = 18390, loss = 28.9750
2024-10-29 13:33:31: [2024-10-29 13:33:31] iter = 18400, loss = 7.5503
2024-10-29 13:33:32: [2024-10-29 13:33:32] iter = 18410, loss = 4.0669
2024-10-29 13:33:32: [2024-10-29 13:33:32] iter = 18420, loss = 28.7262
2024-10-29 13:33:33: [2024-10-29 13:33:33] iter = 18430, loss = 6.5936
2024-10-29 13:33:33: [2024-10-29 13:33:33] iter = 18440, loss = 29.4779
2024-10-29 13:33:34: [2024-10-29 13:33:34] iter = 18450, loss = 2.8862
2024-10-29 13:33:34: [2024-10-29 13:33:34] iter = 18460, loss = 8.7931
2024-10-29 13:33:35: [2024-10-29 13:33:35] iter = 18470, loss = 13.7890
2024-10-29 13:33:36: [2024-10-29 13:33:36] iter = 18480, loss = 8.6349
2024-10-29 13:33:36: [2024-10-29 13:33:36] iter = 18490, loss = 33.3847
2024-10-29 13:33:37: [2024-10-29 13:33:37] iter = 18500, loss = 14.3249
2024-10-29 13:33:37: [2024-10-29 13:33:37] iter = 18510, loss = 5.7073
2024-10-29 13:33:38: [2024-10-29 13:33:38] iter = 18520, loss = 4.5452
2024-10-29 13:33:39: [2024-10-29 13:33:39] iter = 18530, loss = 7.4656
2024-10-29 13:33:39: [2024-10-29 13:33:39] iter = 18540, loss = 3.9172
2024-10-29 13:33:40: [2024-10-29 13:33:40] iter = 18550, loss = 5.0324
2024-10-29 13:33:41: [2024-10-29 13:33:41] iter = 18560, loss = 3.1316
2024-10-29 13:33:41: [2024-10-29 13:33:41] iter = 18570, loss = 3.1824
2024-10-29 13:33:42: [2024-10-29 13:33:42] iter = 18580, loss = 9.7684
2024-10-29 13:33:42: [2024-10-29 13:33:42] iter = 18590, loss = 5.2448
2024-10-29 13:33:43: [2024-10-29 13:33:43] iter = 18600, loss = 2.6824
2024-10-29 13:33:43: [2024-10-29 13:33:43] iter = 18610, loss = 3.4069
2024-10-29 13:33:44: [2024-10-29 13:33:44] iter = 18620, loss = 5.9413
2024-10-29 13:33:44: [2024-10-29 13:33:44] iter = 18630, loss = 3.7502
2024-10-29 13:33:45: [2024-10-29 13:33:45] iter = 18640, loss = 4.0937
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 18650, loss = 8.8042
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 18660, loss = 5.8890
2024-10-29 13:33:46: [2024-10-29 13:33:46] iter = 18670, loss = 10.3639
2024-10-29 13:33:47: [2024-10-29 13:33:47] iter = 18680, loss = 7.7385
2024-10-29 13:33:47: [2024-10-29 13:33:47] iter = 18690, loss = 17.6639
2024-10-29 13:33:48: [2024-10-29 13:33:48] iter = 18700, loss = 3.9630
2024-10-29 13:33:49: [2024-10-29 13:33:49] iter = 18710, loss = 6.3999
2024-10-29 13:33:49: [2024-10-29 13:33:49] iter = 18720, loss = 51.3358
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 18730, loss = 5.9281
2024-10-29 13:33:50: [2024-10-29 13:33:50] iter = 18740, loss = 13.1481
2024-10-29 13:33:51: [2024-10-29 13:33:51] iter = 18750, loss = 4.4135
2024-10-29 13:33:51: [2024-10-29 13:33:51] iter = 18760, loss = 4.7330
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 18770, loss = 2.8412
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 18780, loss = 6.3017
2024-10-29 13:33:52: [2024-10-29 13:33:52] iter = 18790, loss = 3.9024
2024-10-29 13:33:53: [2024-10-29 13:33:53] iter = 18800, loss = 7.7821
2024-10-29 13:33:54: [2024-10-29 13:33:54] iter = 18810, loss = 17.0094
2024-10-29 13:33:54: [2024-10-29 13:33:54] iter = 18820, loss = 6.1988
2024-10-29 13:33:55: [2024-10-29 13:33:55] iter = 18830, loss = 2.9270
2024-10-29 13:33:55: [2024-10-29 13:33:55] iter = 18840, loss = 19.5846
2024-10-29 13:33:56: [2024-10-29 13:33:56] iter = 18850, loss = 17.7197
2024-10-29 13:33:56: [2024-10-29 13:33:56] iter = 18860, loss = 6.5330
2024-10-29 13:33:57: [2024-10-29 13:33:57] iter = 18870, loss = 6.4494
2024-10-29 13:33:58: [2024-10-29 13:33:58] iter = 18880, loss = 4.4871
2024-10-29 13:33:58: [2024-10-29 13:33:58] iter = 18890, loss = 2.9741
2024-10-29 13:33:59: [2024-10-29 13:33:59] iter = 18900, loss = 5.2192
2024-10-29 13:34:00: [2024-10-29 13:34:00] iter = 18910, loss = 4.4857
2024-10-29 13:34:00: [2024-10-29 13:34:00] iter = 18920, loss = 5.0234
2024-10-29 13:34:01: [2024-10-29 13:34:01] iter = 18930, loss = 4.5532
2024-10-29 13:34:01: [2024-10-29 13:34:01] iter = 18940, loss = 7.3555
2024-10-29 13:34:02: [2024-10-29 13:34:02] iter = 18950, loss = 11.0367
2024-10-29 13:34:02: [2024-10-29 13:34:02] iter = 18960, loss = 4.1154
2024-10-29 13:34:03: [2024-10-29 13:34:03] iter = 18970, loss = 10.8240
2024-10-29 13:34:03: [2024-10-29 13:34:03] iter = 18980, loss = 3.6741
2024-10-29 13:34:04: [2024-10-29 13:34:04] iter = 18990, loss = 5.1691
2024-10-29 13:34:04: [2024-10-29 13:34:04] iter = 19000, loss = 5.6186
2024-10-29 13:34:05: [2024-10-29 13:34:05] iter = 19010, loss = 3.5536
2024-10-29 13:34:05: [2024-10-29 13:34:05] iter = 19020, loss = 7.7809
2024-10-29 13:34:06: [2024-10-29 13:34:06] iter = 19030, loss = 4.2662
2024-10-29 13:34:07: [2024-10-29 13:34:07] iter = 19040, loss = 4.4800
2024-10-29 13:34:07: [2024-10-29 13:34:07] iter = 19050, loss = 3.1950
2024-10-29 13:34:08: [2024-10-29 13:34:08] iter = 19060, loss = 6.4288
2024-10-29 13:34:08: [2024-10-29 13:34:08] iter = 19070, loss = 3.4309
2024-10-29 13:34:09: [2024-10-29 13:34:09] iter = 19080, loss = 4.3577
2024-10-29 13:34:09: [2024-10-29 13:34:09] iter = 19090, loss = 3.6581
2024-10-29 13:34:10: [2024-10-29 13:34:10] iter = 19100, loss = 16.2912
2024-10-29 13:34:10: [2024-10-29 13:34:10] iter = 19110, loss = 10.5066
2024-10-29 13:34:11: [2024-10-29 13:34:11] iter = 19120, loss = 4.1403
2024-10-29 13:34:11: [2024-10-29 13:34:11] iter = 19130, loss = 6.4071
2024-10-29 13:34:12: [2024-10-29 13:34:12] iter = 19140, loss = 4.7285
2024-10-29 13:34:13: [2024-10-29 13:34:13] iter = 19150, loss = 3.0775
2024-10-29 13:34:13: [2024-10-29 13:34:13] iter = 19160, loss = 3.9599
2024-10-29 13:34:14: [2024-10-29 13:34:14] iter = 19170, loss = 3.0821
2024-10-29 13:34:14: [2024-10-29 13:34:14] iter = 19180, loss = 2.5471
2024-10-29 13:34:15: [2024-10-29 13:34:15] iter = 19190, loss = 4.9078
2024-10-29 13:34:15: [2024-10-29 13:34:15] iter = 19200, loss = 2.7921
2024-10-29 13:34:16: [2024-10-29 13:34:16] iter = 19210, loss = 41.7630
2024-10-29 13:34:16: [2024-10-29 13:34:16] iter = 19220, loss = 23.0800
2024-10-29 13:34:17: [2024-10-29 13:34:17] iter = 19230, loss = 8.7633
2024-10-29 13:34:17: [2024-10-29 13:34:17] iter = 19240, loss = 30.3662
2024-10-29 13:34:18: [2024-10-29 13:34:18] iter = 19250, loss = 11.9877
2024-10-29 13:34:18: [2024-10-29 13:34:18] iter = 19260, loss = 4.9626
2024-10-29 13:34:19: [2024-10-29 13:34:19] iter = 19270, loss = 2.5339
2024-10-29 13:34:19: [2024-10-29 13:34:19] iter = 19280, loss = 7.3115
2024-10-29 13:34:20: [2024-10-29 13:34:20] iter = 19290, loss = 3.8585
2024-10-29 13:34:20: [2024-10-29 13:34:20] iter = 19300, loss = 5.0562
2024-10-29 13:34:21: [2024-10-29 13:34:21] iter = 19310, loss = 5.0732
2024-10-29 13:34:22: [2024-10-29 13:34:22] iter = 19320, loss = 12.2171
2024-10-29 13:34:22: [2024-10-29 13:34:22] iter = 19330, loss = 11.3934
2024-10-29 13:34:22: [2024-10-29 13:34:22] iter = 19340, loss = 10.9392
2024-10-29 13:34:23: [2024-10-29 13:34:23] iter = 19350, loss = 3.6071
2024-10-29 13:34:23: [2024-10-29 13:34:23] iter = 19360, loss = 3.1313
2024-10-29 13:34:24: [2024-10-29 13:34:24] iter = 19370, loss = 4.5382
2024-10-29 13:34:24: [2024-10-29 13:34:24] iter = 19380, loss = 3.9077
2024-10-29 13:34:25: [2024-10-29 13:34:25] iter = 19390, loss = 3.5166
2024-10-29 13:34:25: [2024-10-29 13:34:25] iter = 19400, loss = 2.9286
2024-10-29 13:34:26: [2024-10-29 13:34:26] iter = 19410, loss = 3.7233
2024-10-29 13:34:26: [2024-10-29 13:34:26] iter = 19420, loss = 54.5977
2024-10-29 13:34:27: [2024-10-29 13:34:27] iter = 19430, loss = 3.3032
2024-10-29 13:34:27: [2024-10-29 13:34:27] iter = 19440, loss = 3.9079
2024-10-29 13:34:28: [2024-10-29 13:34:28] iter = 19450, loss = 28.3086
2024-10-29 13:34:28: [2024-10-29 13:34:28] iter = 19460, loss = 3.4242
2024-10-29 13:34:29: [2024-10-29 13:34:29] iter = 19470, loss = 5.8581
2024-10-29 13:34:29: [2024-10-29 13:34:29] iter = 19480, loss = 5.7967
2024-10-29 13:34:30: [2024-10-29 13:34:30] iter = 19490, loss = 3.5225
2024-10-29 13:34:31: [2024-10-29 13:34:31] iter = 19500, loss = 4.8833
2024-10-29 13:34:31: [2024-10-29 13:34:31] iter = 19510, loss = 9.5464
2024-10-29 13:34:32: [2024-10-29 13:34:32] iter = 19520, loss = 27.9211
2024-10-29 13:34:32: [2024-10-29 13:34:32] iter = 19530, loss = 44.1663
2024-10-29 13:34:33: [2024-10-29 13:34:33] iter = 19540, loss = 4.8404
2024-10-29 13:34:33: [2024-10-29 13:34:33] iter = 19550, loss = 3.9166
2024-10-29 13:34:34: [2024-10-29 13:34:34] iter = 19560, loss = 2.7319
2024-10-29 13:34:34: [2024-10-29 13:34:34] iter = 19570, loss = 49.3534
2024-10-29 13:34:35: [2024-10-29 13:34:35] iter = 19580, loss = 7.3193
2024-10-29 13:34:35: [2024-10-29 13:34:35] iter = 19590, loss = 4.7104
2024-10-29 13:34:36: [2024-10-29 13:34:36] iter = 19600, loss = 12.9385
2024-10-29 13:34:36: [2024-10-29 13:34:36] iter = 19610, loss = 3.7201
2024-10-29 13:34:37: [2024-10-29 13:34:37] iter = 19620, loss = 6.1261
2024-10-29 13:34:37: [2024-10-29 13:34:37] iter = 19630, loss = 9.4352
2024-10-29 13:34:38: [2024-10-29 13:34:38] iter = 19640, loss = 2.9152
2024-10-29 13:34:38: [2024-10-29 13:34:38] iter = 19650, loss = 3.8822
2024-10-29 13:34:39: [2024-10-29 13:34:39] iter = 19660, loss = 7.2956
2024-10-29 13:34:39: [2024-10-29 13:34:39] iter = 19670, loss = 4.7736
2024-10-29 13:34:40: [2024-10-29 13:34:40] iter = 19680, loss = 4.9409
2024-10-29 13:34:40: [2024-10-29 13:34:40] iter = 19690, loss = 3.5181
2024-10-29 13:34:41: [2024-10-29 13:34:41] iter = 19700, loss = 3.4236
2024-10-29 13:34:41: [2024-10-29 13:34:41] iter = 19710, loss = 5.7260
2024-10-29 13:34:42: [2024-10-29 13:34:42] iter = 19720, loss = 3.8194
2024-10-29 13:34:42: [2024-10-29 13:34:42] iter = 19730, loss = 9.0581
2024-10-29 13:34:43: [2024-10-29 13:34:43] iter = 19740, loss = 4.8956
2024-10-29 13:34:44: [2024-10-29 13:34:44] iter = 19750, loss = 3.2387
2024-10-29 13:34:44: [2024-10-29 13:34:44] iter = 19760, loss = 2.8468
2024-10-29 13:34:45: [2024-10-29 13:34:45] iter = 19770, loss = 8.8019
2024-10-29 13:34:45: [2024-10-29 13:34:45] iter = 19780, loss = 7.7928
2024-10-29 13:34:46: [2024-10-29 13:34:46] iter = 19790, loss = 2.9228
2024-10-29 13:34:46: [2024-10-29 13:34:46] iter = 19800, loss = 3.5424
2024-10-29 13:34:47: [2024-10-29 13:34:47] iter = 19810, loss = 19.6526
2024-10-29 13:34:47: [2024-10-29 13:34:47] iter = 19820, loss = 7.0848
2024-10-29 13:34:48: [2024-10-29 13:34:48] iter = 19830, loss = 3.8066
2024-10-29 13:34:48: [2024-10-29 13:34:48] iter = 19840, loss = 7.0994
2024-10-29 13:34:49: [2024-10-29 13:34:49] iter = 19850, loss = 18.8186
2024-10-29 13:34:50: [2024-10-29 13:34:50] iter = 19860, loss = 8.3611
2024-10-29 13:34:50: [2024-10-29 13:34:50] iter = 19870, loss = 7.1269
2024-10-29 13:34:51: [2024-10-29 13:34:51] iter = 19880, loss = 4.3791
2024-10-29 13:34:51: [2024-10-29 13:34:51] iter = 19890, loss = 6.0539
2024-10-29 13:34:52: [2024-10-29 13:34:52] iter = 19900, loss = 19.1643
2024-10-29 13:34:53: [2024-10-29 13:34:53] iter = 19910, loss = 5.2248
2024-10-29 13:34:53: [2024-10-29 13:34:53] iter = 19920, loss = 6.7861
2024-10-29 13:34:54: [2024-10-29 13:34:54] iter = 19930, loss = 8.1763
2024-10-29 13:34:54: [2024-10-29 13:34:54] iter = 19940, loss = 51.8367
2024-10-29 13:34:55: [2024-10-29 13:34:55] iter = 19950, loss = 4.9561
2024-10-29 13:34:55: [2024-10-29 13:34:55] iter = 19960, loss = 58.2860
2024-10-29 13:34:56: [2024-10-29 13:34:56] iter = 19970, loss = 3.5136
2024-10-29 13:34:56: [2024-10-29 13:34:56] iter = 19980, loss = 28.0347
2024-10-29 13:34:57: [2024-10-29 13:34:57] iter = 19990, loss = 25.2117
2024-10-29 13:34:57: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-29 13:34:57: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-29 13:34:57: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 97914}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-29 13:35:25: Evaluate 5 random ConvNet, ACCmean = 0.5636 ACCstd = 0.0087
-------------------------
2024-10-29 13:35:25: Evaluate 5 random ConvNet, SENmean = 0.5636 SENstd = 0.0087
-------------------------
2024-10-29 13:35:25: Evaluate 5 random ConvNet, SPEmean = 0.8545 SPEstd = 0.0029
-------------------------
2024-10-29 13:35:25: Evaluate 5 random ConvNet, F!mean = 0.5550 F!std = 0.0080
-------------------------
2024-10-29 13:35:25: Evaluate 5 random ConvNet, mean = 0.5636 std = 0.0087
-------------------------
2024-10-29 13:35:25: [2024-10-29 13:35:25] iter = 20000, loss = 3.0098
2024-10-29 13:35:25: 
==================== Final Results ====================

2024-10-29 13:35:25: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 53.10%  std = 3.82%

[2024-10-29 13:17:24] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.006799 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8467, test_f1 =0.4742
[2024-10-29 13:17:29] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.002217 train acc = 1.0000, test acc = 0.5580, test_sen =0.5580, test_spe =0.8527, test_f1 =0.5121
[2024-10-29 13:19:18] Evaluate_00: epoch = 1000 train time = 4 s train loss = 0.002344 train acc = 1.0000, test acc = 0.4480, test_sen =0.4480, test_spe =0.8160, test_f1 =0.4314
[2024-10-29 13:19:23] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.005289 train acc = 1.0000, test acc = 0.4300, test_sen =0.4300, test_spe =0.8100, test_f1 =0.4230
[2024-10-29 13:19:29] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.001377 train acc = 1.0000, test acc = 0.4300, test_sen =0.4300, test_spe =0.8100, test_f1 =0.4015
[2024-10-29 13:19:34] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.006525 train acc = 1.0000, test acc = 0.4390, test_sen =0.4390, test_spe =0.8130, test_f1 =0.4290
[2024-10-29 13:19:39] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001149 train acc = 1.0000, test acc = 0.4670, test_sen =0.4670, test_spe =0.8223, test_f1 =0.4677
[2024-10-29 13:21:33] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.003734 train acc = 1.0000, test acc = 0.4600, test_sen =0.4600, test_spe =0.8200, test_f1 =0.3879
[2024-10-29 13:21:39] Evaluate_01: epoch = 1000 train time = 6 s train loss = 0.000415 train acc = 1.0000, test acc = 0.4470, test_sen =0.4470, test_spe =0.8157, test_f1 =0.3965
[2024-10-29 13:21:45] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.020342 train acc = 1.0000, test acc = 0.4570, test_sen =0.4570, test_spe =0.8190, test_f1 =0.3926
[2024-10-29 13:21:50] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.003240 train acc = 1.0000, test acc = 0.4540, test_sen =0.4540, test_spe =0.8180, test_f1 =0.3965
[2024-10-29 13:21:56] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.001726 train acc = 1.0000, test acc = 0.4530, test_sen =0.4530, test_spe =0.8177, test_f1 =0.3934
[2024-10-29 13:23:49] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.001187 train acc = 1.0000, test acc = 0.5200, test_sen =0.5200, test_spe =0.8400, test_f1 =0.5152
[2024-10-29 13:23:55] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.004730 train acc = 1.0000, test acc = 0.5260, test_sen =0.5260, test_spe =0.8420, test_f1 =0.5175
[2024-10-29 13:24:00] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.007829 train acc = 1.0000, test acc = 0.5020, test_sen =0.5020, test_spe =0.8340, test_f1 =0.4913
[2024-10-29 13:24:05] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.003229 train acc = 1.0000, test acc = 0.5100, test_sen =0.5100, test_spe =0.8367, test_f1 =0.4925
[2024-10-29 13:24:10] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.018145 train acc = 1.0000, test acc = 0.5180, test_sen =0.5180, test_spe =0.8393, test_f1 =0.5131
[2024-10-29 13:26:08] Evaluate_00: epoch = 1000 train time = 6 s train loss = 0.004127 train acc = 1.0000, test acc = 0.5490, test_sen =0.5490, test_spe =0.8497, test_f1 =0.5363
[2024-10-29 13:26:14] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.059298 train acc = 0.9750, test acc = 0.5190, test_sen =0.5190, test_spe =0.8397, test_f1 =0.5006
[2024-10-29 13:26:19] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.027818 train acc = 1.0000, test acc = 0.5390, test_sen =0.5390, test_spe =0.8463, test_f1 =0.5258
[2024-10-29 13:26:24] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.038180 train acc = 1.0000, test acc = 0.5250, test_sen =0.5250, test_spe =0.8417, test_f1 =0.5026
[2024-10-29 13:26:30] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.019727 train acc = 1.0000, test acc = 0.5210, test_sen =0.5210, test_spe =0.8403, test_f1 =0.5027
[2024-10-29 13:28:23] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000923 train acc = 1.0000, test acc = 0.5130, test_sen =0.5130, test_spe =0.8377, test_f1 =0.4644
[2024-10-29 13:28:29] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.017827 train acc = 1.0000, test acc = 0.5280, test_sen =0.5280, test_spe =0.8427, test_f1 =0.4877
[2024-10-29 13:28:34] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.002630 train acc = 1.0000, test acc = 0.4960, test_sen =0.4960, test_spe =0.8320, test_f1 =0.4382
[2024-10-29 13:28:39] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.001559 train acc = 1.0000, test acc = 0.5260, test_sen =0.5260, test_spe =0.8420, test_f1 =0.4805
[2024-10-29 13:28:44] Evaluate_04: epoch = 1000 train time = 4 s train loss = 0.001407 train acc = 1.0000, test acc = 0.5250, test_sen =0.5250, test_spe =0.8417, test_f1 =0.4840
[2024-10-29 13:30:35] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.002553 train acc = 1.0000, test acc = 0.5030, test_sen =0.5030, test_spe =0.8343, test_f1 =0.4603
[2024-10-29 13:30:40] Evaluate_01: epoch = 1000 train time = 4 s train loss = 0.006420 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8413, test_f1 =0.4861
[2024-10-29 13:30:45] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.000749 train acc = 1.0000, test acc = 0.5330, test_sen =0.5330, test_spe =0.8443, test_f1 =0.4910
[2024-10-29 13:30:51] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.026253 train acc = 1.0000, test acc = 0.5270, test_sen =0.5270, test_spe =0.8423, test_f1 =0.4721
[2024-10-29 13:30:56] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.005493 train acc = 1.0000, test acc = 0.5090, test_sen =0.5090, test_spe =0.8363, test_f1 =0.4662
[2024-10-29 13:32:48] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.000759 train acc = 1.0000, test acc = 0.5450, test_sen =0.5450, test_spe =0.8483, test_f1 =0.4991
[2024-10-29 13:32:54] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.027673 train acc = 1.0000, test acc = 0.5140, test_sen =0.5140, test_spe =0.8380, test_f1 =0.4630
[2024-10-29 13:32:59] Evaluate_02: epoch = 1000 train time = 4 s train loss = 0.000991 train acc = 1.0000, test acc = 0.5330, test_sen =0.5330, test_spe =0.8443, test_f1 =0.4766
[2024-10-29 13:33:04] Evaluate_03: epoch = 1000 train time = 4 s train loss = 0.002501 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8413, test_f1 =0.4699
[2024-10-29 13:33:10] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.000979 train acc = 1.0000, test acc = 0.5150, test_sen =0.5150, test_spe =0.8383, test_f1 =0.4659
[2024-10-29 13:35:03] Evaluate_00: epoch = 1000 train time = 5 s train loss = 0.046153 train acc = 1.0000, test acc = 0.5650, test_sen =0.5650, test_spe =0.8550, test_f1 =0.5569
[2024-10-29 13:35:08] Evaluate_01: epoch = 1000 train time = 5 s train loss = 0.011959 train acc = 1.0000, test acc = 0.5720, test_sen =0.5720, test_spe =0.8573, test_f1 =0.5602
[2024-10-29 13:35:14] Evaluate_02: epoch = 1000 train time = 5 s train loss = 0.037680 train acc = 1.0000, test acc = 0.5500, test_sen =0.5500, test_spe =0.8500, test_f1 =0.5458
[2024-10-29 13:35:20] Evaluate_03: epoch = 1000 train time = 5 s train loss = 0.092254 train acc = 0.9750, test acc = 0.5730, test_sen =0.5730, test_spe =0.8577, test_f1 =0.5661
[2024-10-29 13:35:25] Evaluate_04: epoch = 1000 train time = 5 s train loss = 0.011261 train acc = 1.0000, test acc = 0.5580, test_sen =0.5580, test_spe =0.8527, test_f1 =0.5461
