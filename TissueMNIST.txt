nohup: ignoring input
2024-10-30 14:18:48: eval_it_pool: [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]
2024-10-30 14:18:51: 
================== Exp 0 ==================
 
2024-10-30 14:18:51: Hyper-parameters: 
{'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ffaf9964b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_TissueMNIST (INFO)>}
2024-10-30 14:18:51: Evaluation model pool: ['ConvNet']
2024-10-30 14:18:57: class c = 0: 53075 real images
2024-10-30 14:18:57: class c = 1: 7814 real images
2024-10-30 14:18:57: class c = 2: 5866 real images
2024-10-30 14:18:57: class c = 3: 15406 real images
2024-10-30 14:18:57: class c = 4: 11789 real images
2024-10-30 14:18:57: class c = 5: 7705 real images
2024-10-30 14:18:57: class c = 6: 39203 real images
2024-10-30 14:18:57: class c = 7: 24608 real images
2024-10-30 14:18:57: real images channel 0, mean = 0.1020, std = 0.1000
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
main_DM.py:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 14:18:57: initialize synthetic data from random real images
2024-10-30 14:18:57: [2024-10-30 14:18:57] training begins
2024-10-30 14:18:57: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 14:18:57: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:18:57: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:19:59: Evaluate 5 random ConvNet, ACCmean = 0.2692 ACCstd = 0.0063
-------------------------
2024-10-30 14:19:59: Evaluate 5 random ConvNet, SENmean = 0.2462 SENstd = 0.0030
-------------------------
2024-10-30 14:19:59: Evaluate 5 random ConvNet, SPEmean = 0.8951 SPEstd = 0.0007
-------------------------
2024-10-30 14:19:59: Evaluate 5 random ConvNet, F!mean = 0.2262 F!std = 0.0033
-------------------------
2024-10-30 14:19:59: Evaluate 5 random ConvNet, mean = 0.2692 std = 0.0063
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:19:59: [2024-10-30 14:19:59] iter = 00000, loss = 19.6809
2024-10-30 14:20:01: [2024-10-30 14:20:01] iter = 00010, loss = 96.2154
2024-10-30 14:20:02: [2024-10-30 14:20:02] iter = 00020, loss = 83.2043
2024-10-30 14:20:03: [2024-10-30 14:20:03] iter = 00030, loss = 36.9962
2024-10-30 14:20:05: [2024-10-30 14:20:05] iter = 00040, loss = 43.0893
2024-10-30 14:20:06: [2024-10-30 14:20:06] iter = 00050, loss = 32.6143
2024-10-30 14:20:08: [2024-10-30 14:20:08] iter = 00060, loss = 11.2964
2024-10-30 14:20:09: [2024-10-30 14:20:09] iter = 00070, loss = 22.0095
2024-10-30 14:20:11: [2024-10-30 14:20:11] iter = 00080, loss = 18.7736
2024-10-30 14:20:12: [2024-10-30 14:20:12] iter = 00090, loss = 11.4918
2024-10-30 14:20:14: [2024-10-30 14:20:14] iter = 00100, loss = 50.2385
2024-10-30 14:20:15: [2024-10-30 14:20:15] iter = 00110, loss = 10.7609
2024-10-30 14:20:17: [2024-10-30 14:20:17] iter = 00120, loss = 50.4171
2024-10-30 14:20:18: [2024-10-30 14:20:18] iter = 00130, loss = 72.0320
2024-10-30 14:20:20: [2024-10-30 14:20:20] iter = 00140, loss = 8.7710
2024-10-30 14:20:22: [2024-10-30 14:20:22] iter = 00150, loss = 27.4057
2024-10-30 14:20:24: [2024-10-30 14:20:24] iter = 00160, loss = 31.5325
2024-10-30 14:20:25: [2024-10-30 14:20:25] iter = 00170, loss = 39.4531
2024-10-30 14:20:26: [2024-10-30 14:20:26] iter = 00180, loss = 20.2507
2024-10-30 14:20:28: [2024-10-30 14:20:28] iter = 00190, loss = 29.0557
2024-10-30 14:20:29: [2024-10-30 14:20:29] iter = 00200, loss = 6.3370
2024-10-30 14:20:31: [2024-10-30 14:20:31] iter = 00210, loss = 19.9337
2024-10-30 14:20:32: [2024-10-30 14:20:32] iter = 00220, loss = 9.3730
2024-10-30 14:20:34: [2024-10-30 14:20:34] iter = 00230, loss = 6.3791
2024-10-30 14:20:36: [2024-10-30 14:20:36] iter = 00240, loss = 4.8079
2024-10-30 14:20:37: [2024-10-30 14:20:37] iter = 00250, loss = 23.6456
2024-10-30 14:20:40: [2024-10-30 14:20:40] iter = 00260, loss = 7.1795
2024-10-30 14:20:42: [2024-10-30 14:20:42] iter = 00270, loss = 5.9647
2024-10-30 14:20:44: [2024-10-30 14:20:44] iter = 00280, loss = 5.6386
2024-10-30 14:20:46: [2024-10-30 14:20:46] iter = 00290, loss = 8.6583
2024-10-30 14:20:48: [2024-10-30 14:20:48] iter = 00300, loss = 19.4924
2024-10-30 14:20:50: [2024-10-30 14:20:50] iter = 00310, loss = 4.2675
2024-10-30 14:20:53: [2024-10-30 14:20:53] iter = 00320, loss = 4.7988
2024-10-30 14:20:55: [2024-10-30 14:20:55] iter = 00330, loss = 23.8507
2024-10-30 14:20:57: [2024-10-30 14:20:57] iter = 00340, loss = 48.4237
2024-10-30 14:21:00: [2024-10-30 14:21:00] iter = 00350, loss = 9.7756
2024-10-30 14:21:02: [2024-10-30 14:21:02] iter = 00360, loss = 51.1807
2024-10-30 14:21:05: [2024-10-30 14:21:05] iter = 00370, loss = 24.0693
2024-10-30 14:21:07: [2024-10-30 14:21:07] iter = 00380, loss = 9.8546
2024-10-30 14:21:10: [2024-10-30 14:21:09] iter = 00390, loss = 18.2058
2024-10-30 14:21:12: [2024-10-30 14:21:12] iter = 00400, loss = 4.7902
2024-10-30 14:21:14: [2024-10-30 14:21:14] iter = 00410, loss = 12.3656
2024-10-30 14:21:16: [2024-10-30 14:21:16] iter = 00420, loss = 5.9731
2024-10-30 14:21:18: [2024-10-30 14:21:18] iter = 00430, loss = 11.8058
2024-10-30 14:21:20: [2024-10-30 14:21:20] iter = 00440, loss = 14.0377
2024-10-30 14:21:22: [2024-10-30 14:21:22] iter = 00450, loss = 49.6994
2024-10-30 14:21:24: [2024-10-30 14:21:24] iter = 00460, loss = 4.8227
2024-10-30 14:21:26: [2024-10-30 14:21:26] iter = 00470, loss = 6.6061
2024-10-30 14:21:28: [2024-10-30 14:21:28] iter = 00480, loss = 16.3598
2024-10-30 14:21:30: [2024-10-30 14:21:30] iter = 00490, loss = 22.3585
2024-10-30 14:21:32: [2024-10-30 14:21:32] iter = 00500, loss = 20.1729
2024-10-30 14:21:34: [2024-10-30 14:21:34] iter = 00510, loss = 8.5957
2024-10-30 14:21:36: [2024-10-30 14:21:36] iter = 00520, loss = 4.5852
2024-10-30 14:21:39: [2024-10-30 14:21:38] iter = 00530, loss = 44.5836
2024-10-30 14:21:40: [2024-10-30 14:21:40] iter = 00540, loss = 6.4482
2024-10-30 14:21:42: [2024-10-30 14:21:42] iter = 00550, loss = 22.3340
2024-10-30 14:21:43: [2024-10-30 14:21:43] iter = 00560, loss = 4.1096
2024-10-30 14:21:45: [2024-10-30 14:21:45] iter = 00570, loss = 34.8874
2024-10-30 14:21:47: [2024-10-30 14:21:47] iter = 00580, loss = 13.4281
2024-10-30 14:21:49: [2024-10-30 14:21:49] iter = 00590, loss = 9.6706
2024-10-30 14:21:51: [2024-10-30 14:21:51] iter = 00600, loss = 15.9100
2024-10-30 14:21:53: [2024-10-30 14:21:53] iter = 00610, loss = 18.0583
2024-10-30 14:21:55: [2024-10-30 14:21:55] iter = 00620, loss = 30.3621
2024-10-30 14:21:56: [2024-10-30 14:21:56] iter = 00630, loss = 19.6484
2024-10-30 14:21:58: [2024-10-30 14:21:58] iter = 00640, loss = 5.8097
2024-10-30 14:22:00: [2024-10-30 14:22:00] iter = 00650, loss = 17.9196
2024-10-30 14:22:02: [2024-10-30 14:22:02] iter = 00660, loss = 8.5959
2024-10-30 14:22:04: [2024-10-30 14:22:04] iter = 00670, loss = 52.3121
2024-10-30 14:22:06: [2024-10-30 14:22:06] iter = 00680, loss = 8.6715
2024-10-30 14:22:08: [2024-10-30 14:22:08] iter = 00690, loss = 13.6600
2024-10-30 14:22:09: [2024-10-30 14:22:09] iter = 00700, loss = 7.8627
2024-10-30 14:22:11: [2024-10-30 14:22:11] iter = 00710, loss = 38.6149
2024-10-30 14:22:14: [2024-10-30 14:22:14] iter = 00720, loss = 27.0369
2024-10-30 14:22:15: [2024-10-30 14:22:15] iter = 00730, loss = 10.4384
2024-10-30 14:22:17: [2024-10-30 14:22:17] iter = 00740, loss = 43.0539
2024-10-30 14:22:20: [2024-10-30 14:22:20] iter = 00750, loss = 6.5441
2024-10-30 14:22:22: [2024-10-30 14:22:22] iter = 00760, loss = 9.3751
2024-10-30 14:22:24: [2024-10-30 14:22:24] iter = 00770, loss = 15.1433
2024-10-30 14:22:26: [2024-10-30 14:22:26] iter = 00780, loss = 5.9909
2024-10-30 14:22:27: [2024-10-30 14:22:27] iter = 00790, loss = 4.1052
2024-10-30 14:22:29: [2024-10-30 14:22:29] iter = 00800, loss = 25.3749
2024-10-30 14:22:31: [2024-10-30 14:22:31] iter = 00810, loss = 27.9520
2024-10-30 14:22:32: [2024-10-30 14:22:32] iter = 00820, loss = 8.8964
2024-10-30 14:22:34: [2024-10-30 14:22:34] iter = 00830, loss = 13.2076
2024-10-30 14:22:35: [2024-10-30 14:22:35] iter = 00840, loss = 13.7386
2024-10-30 14:22:37: [2024-10-30 14:22:37] iter = 00850, loss = 13.4183
2024-10-30 14:22:39: [2024-10-30 14:22:39] iter = 00860, loss = 7.9248
2024-10-30 14:22:41: [2024-10-30 14:22:41] iter = 00870, loss = 21.7388
2024-10-30 14:22:42: [2024-10-30 14:22:42] iter = 00880, loss = 4.7712
2024-10-30 14:22:44: [2024-10-30 14:22:44] iter = 00890, loss = 8.4346
2024-10-30 14:22:46: [2024-10-30 14:22:46] iter = 00900, loss = 7.6735
2024-10-30 14:22:48: [2024-10-30 14:22:48] iter = 00910, loss = 5.3286
2024-10-30 14:22:50: [2024-10-30 14:22:50] iter = 00920, loss = 6.6476
2024-10-30 14:22:51: [2024-10-30 14:22:51] iter = 00930, loss = 9.3355
2024-10-30 14:22:53: [2024-10-30 14:22:53] iter = 00940, loss = 8.1890
2024-10-30 14:22:55: [2024-10-30 14:22:55] iter = 00950, loss = 8.4064
2024-10-30 14:22:56: [2024-10-30 14:22:56] iter = 00960, loss = 41.8495
2024-10-30 14:22:59: [2024-10-30 14:22:59] iter = 00970, loss = 19.8350
2024-10-30 14:23:01: [2024-10-30 14:23:01] iter = 00980, loss = 7.2177
2024-10-30 14:23:03: [2024-10-30 14:23:03] iter = 00990, loss = 10.4532
2024-10-30 14:23:05: [2024-10-30 14:23:05] iter = 01000, loss = 57.9774
2024-10-30 14:23:07: [2024-10-30 14:23:07] iter = 01010, loss = 4.3218
2024-10-30 14:23:09: [2024-10-30 14:23:09] iter = 01020, loss = 42.8798
2024-10-30 14:23:10: [2024-10-30 14:23:10] iter = 01030, loss = 44.7704
2024-10-30 14:23:12: [2024-10-30 14:23:12] iter = 01040, loss = 6.5478
2024-10-30 14:23:14: [2024-10-30 14:23:14] iter = 01050, loss = 18.6237
2024-10-30 14:23:17: [2024-10-30 14:23:17] iter = 01060, loss = 5.2150
2024-10-30 14:23:18: [2024-10-30 14:23:18] iter = 01070, loss = 19.3838
2024-10-30 14:23:20: [2024-10-30 14:23:20] iter = 01080, loss = 32.9002
2024-10-30 14:23:22: [2024-10-30 14:23:22] iter = 01090, loss = 51.5382
2024-10-30 14:23:24: [2024-10-30 14:23:24] iter = 01100, loss = 19.2560
2024-10-30 14:23:25: [2024-10-30 14:23:25] iter = 01110, loss = 7.2976
2024-10-30 14:23:27: [2024-10-30 14:23:27] iter = 01120, loss = 47.4379
2024-10-30 14:23:29: [2024-10-30 14:23:29] iter = 01130, loss = 10.7522
2024-10-30 14:23:30: [2024-10-30 14:23:30] iter = 01140, loss = 59.2623
2024-10-30 14:23:32: [2024-10-30 14:23:32] iter = 01150, loss = 60.7236
2024-10-30 14:23:34: [2024-10-30 14:23:34] iter = 01160, loss = 83.6497
2024-10-30 14:23:36: [2024-10-30 14:23:36] iter = 01170, loss = 21.1965
2024-10-30 14:23:38: [2024-10-30 14:23:38] iter = 01180, loss = 13.6679
2024-10-30 14:23:39: [2024-10-30 14:23:39] iter = 01190, loss = 15.8116
2024-10-30 14:23:41: [2024-10-30 14:23:41] iter = 01200, loss = 47.5691
2024-10-30 14:23:43: [2024-10-30 14:23:43] iter = 01210, loss = 4.4179
2024-10-30 14:23:45: [2024-10-30 14:23:45] iter = 01220, loss = 3.9619
2024-10-30 14:23:46: [2024-10-30 14:23:46] iter = 01230, loss = 10.3242
2024-10-30 14:23:47: [2024-10-30 14:23:47] iter = 01240, loss = 15.5287
2024-10-30 14:23:49: [2024-10-30 14:23:49] iter = 01250, loss = 10.4180
2024-10-30 14:23:50: [2024-10-30 14:23:50] iter = 01260, loss = 7.0432
2024-10-30 14:23:52: [2024-10-30 14:23:52] iter = 01270, loss = 5.8246
2024-10-30 14:23:54: [2024-10-30 14:23:54] iter = 01280, loss = 9.2976
2024-10-30 14:23:56: [2024-10-30 14:23:56] iter = 01290, loss = 10.8187
2024-10-30 14:23:58: [2024-10-30 14:23:58] iter = 01300, loss = 14.7535
2024-10-30 14:24:00: [2024-10-30 14:24:00] iter = 01310, loss = 14.8255
2024-10-30 14:24:02: [2024-10-30 14:24:02] iter = 01320, loss = 7.5994
2024-10-30 14:24:04: [2024-10-30 14:24:04] iter = 01330, loss = 6.5805
2024-10-30 14:24:06: [2024-10-30 14:24:06] iter = 01340, loss = 13.0254
2024-10-30 14:24:08: [2024-10-30 14:24:08] iter = 01350, loss = 25.2718
2024-10-30 14:24:09: [2024-10-30 14:24:09] iter = 01360, loss = 4.1816
2024-10-30 14:24:11: [2024-10-30 14:24:11] iter = 01370, loss = 12.2287
2024-10-30 14:24:13: [2024-10-30 14:24:13] iter = 01380, loss = 33.0551
2024-10-30 14:24:15: [2024-10-30 14:24:15] iter = 01390, loss = 23.9635
2024-10-30 14:24:17: [2024-10-30 14:24:17] iter = 01400, loss = 18.6531
2024-10-30 14:24:18: [2024-10-30 14:24:18] iter = 01410, loss = 9.7082
2024-10-30 14:24:20: [2024-10-30 14:24:20] iter = 01420, loss = 7.5870
2024-10-30 14:24:22: [2024-10-30 14:24:22] iter = 01430, loss = 12.4762
2024-10-30 14:24:24: [2024-10-30 14:24:24] iter = 01440, loss = 49.0595
2024-10-30 14:24:26: [2024-10-30 14:24:26] iter = 01450, loss = 3.6032
2024-10-30 14:24:28: [2024-10-30 14:24:28] iter = 01460, loss = 3.9443
2024-10-30 14:24:30: [2024-10-30 14:24:30] iter = 01470, loss = 2.9354
2024-10-30 14:24:32: [2024-10-30 14:24:32] iter = 01480, loss = 13.4262
2024-10-30 14:24:34: [2024-10-30 14:24:34] iter = 01490, loss = 19.6091
2024-10-30 14:24:36: [2024-10-30 14:24:36] iter = 01500, loss = 3.2568
2024-10-30 14:24:37: [2024-10-30 14:24:37] iter = 01510, loss = 21.4180
2024-10-30 14:24:39: [2024-10-30 14:24:39] iter = 01520, loss = 41.1600
2024-10-30 14:24:40: [2024-10-30 14:24:40] iter = 01530, loss = 20.2924
2024-10-30 14:24:42: [2024-10-30 14:24:42] iter = 01540, loss = 64.9354
2024-10-30 14:24:43: [2024-10-30 14:24:43] iter = 01550, loss = 4.6708
2024-10-30 14:24:45: [2024-10-30 14:24:45] iter = 01560, loss = 13.9755
2024-10-30 14:24:46: [2024-10-30 14:24:46] iter = 01570, loss = 4.7094
2024-10-30 14:24:48: [2024-10-30 14:24:48] iter = 01580, loss = 9.7832
2024-10-30 14:24:49: [2024-10-30 14:24:49] iter = 01590, loss = 4.5550
2024-10-30 14:24:51: [2024-10-30 14:24:51] iter = 01600, loss = 41.0149
2024-10-30 14:24:53: [2024-10-30 14:24:53] iter = 01610, loss = 19.3103
2024-10-30 14:24:55: [2024-10-30 14:24:55] iter = 01620, loss = 16.9837
2024-10-30 14:24:58: [2024-10-30 14:24:58] iter = 01630, loss = 22.7437
2024-10-30 14:24:59: [2024-10-30 14:24:59] iter = 01640, loss = 10.5057
2024-10-30 14:25:00: [2024-10-30 14:25:00] iter = 01650, loss = 4.9713
2024-10-30 14:25:02: [2024-10-30 14:25:02] iter = 01660, loss = 8.8456
2024-10-30 14:25:04: [2024-10-30 14:25:04] iter = 01670, loss = 12.3955
2024-10-30 14:25:06: [2024-10-30 14:25:06] iter = 01680, loss = 5.5705
2024-10-30 14:25:08: [2024-10-30 14:25:08] iter = 01690, loss = 4.7238
2024-10-30 14:25:09: [2024-10-30 14:25:09] iter = 01700, loss = 9.4407
2024-10-30 14:25:12: [2024-10-30 14:25:12] iter = 01710, loss = 3.0885
2024-10-30 14:25:13: [2024-10-30 14:25:13] iter = 01720, loss = 4.3273
2024-10-30 14:25:15: [2024-10-30 14:25:15] iter = 01730, loss = 44.4659
2024-10-30 14:25:17: [2024-10-30 14:25:17] iter = 01740, loss = 4.2167
2024-10-30 14:25:19: [2024-10-30 14:25:19] iter = 01750, loss = 77.2920
2024-10-30 14:25:21: [2024-10-30 14:25:21] iter = 01760, loss = 4.2682
2024-10-30 14:25:23: [2024-10-30 14:25:23] iter = 01770, loss = 48.2720
2024-10-30 14:25:25: [2024-10-30 14:25:25] iter = 01780, loss = 5.3578
2024-10-30 14:25:26: [2024-10-30 14:25:26] iter = 01790, loss = 38.7227
2024-10-30 14:25:28: [2024-10-30 14:25:28] iter = 01800, loss = 13.0394
2024-10-30 14:25:31: [2024-10-30 14:25:31] iter = 01810, loss = 7.6844
2024-10-30 14:25:32: [2024-10-30 14:25:32] iter = 01820, loss = 4.0655
2024-10-30 14:25:34: [2024-10-30 14:25:34] iter = 01830, loss = 15.9056
2024-10-30 14:25:36: [2024-10-30 14:25:36] iter = 01840, loss = 49.2439
2024-10-30 14:25:39: [2024-10-30 14:25:39] iter = 01850, loss = 5.1627
2024-10-30 14:25:40: [2024-10-30 14:25:40] iter = 01860, loss = 23.6563
2024-10-30 14:25:42: [2024-10-30 14:25:42] iter = 01870, loss = 20.7876
2024-10-30 14:25:43: [2024-10-30 14:25:43] iter = 01880, loss = 11.0223
2024-10-30 14:25:45: [2024-10-30 14:25:45] iter = 01890, loss = 8.6633
2024-10-30 14:25:47: [2024-10-30 14:25:47] iter = 01900, loss = 8.9458
2024-10-30 14:25:49: [2024-10-30 14:25:49] iter = 01910, loss = 3.4370
2024-10-30 14:25:51: [2024-10-30 14:25:51] iter = 01920, loss = 10.9102
2024-10-30 14:25:53: [2024-10-30 14:25:53] iter = 01930, loss = 5.6842
2024-10-30 14:25:55: [2024-10-30 14:25:55] iter = 01940, loss = 14.7903
2024-10-30 14:25:57: [2024-10-30 14:25:57] iter = 01950, loss = 51.1909
2024-10-30 14:25:59: [2024-10-30 14:25:59] iter = 01960, loss = 11.2351
2024-10-30 14:26:01: [2024-10-30 14:26:01] iter = 01970, loss = 9.4890
2024-10-30 14:26:02: [2024-10-30 14:26:02] iter = 01980, loss = 78.2371
2024-10-30 14:26:04: [2024-10-30 14:26:04] iter = 01990, loss = 32.5685
2024-10-30 14:26:06: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 14:26:06: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:26:06: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 66409}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:27:23: Evaluate 5 random ConvNet, ACCmean = 0.3291 ACCstd = 0.0078
-------------------------
2024-10-30 14:27:23: Evaluate 5 random ConvNet, SENmean = 0.2949 SENstd = 0.0034
-------------------------
2024-10-30 14:27:23: Evaluate 5 random ConvNet, SPEmean = 0.9039 SPEstd = 0.0008
-------------------------
2024-10-30 14:27:23: Evaluate 5 random ConvNet, F!mean = 0.2682 F!std = 0.0056
-------------------------
2024-10-30 14:27:23: Evaluate 5 random ConvNet, mean = 0.3291 std = 0.0078
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:27:23: [2024-10-30 14:27:23] iter = 02000, loss = 4.4094
2024-10-30 14:27:25: [2024-10-30 14:27:25] iter = 02010, loss = 6.2256
2024-10-30 14:27:27: [2024-10-30 14:27:27] iter = 02020, loss = 36.2950
2024-10-30 14:27:29: [2024-10-30 14:27:29] iter = 02030, loss = 51.7170
2024-10-30 14:27:31: [2024-10-30 14:27:31] iter = 02040, loss = 3.4225
2024-10-30 14:27:32: [2024-10-30 14:27:32] iter = 02050, loss = 8.6319
2024-10-30 14:27:34: [2024-10-30 14:27:34] iter = 02060, loss = 6.7786
2024-10-30 14:27:36: [2024-10-30 14:27:36] iter = 02070, loss = 56.5376
2024-10-30 14:27:38: [2024-10-30 14:27:38] iter = 02080, loss = 39.8316
2024-10-30 14:27:40: [2024-10-30 14:27:40] iter = 02090, loss = 37.3117
2024-10-30 14:27:41: [2024-10-30 14:27:41] iter = 02100, loss = 21.9497
2024-10-30 14:27:43: [2024-10-30 14:27:43] iter = 02110, loss = 8.5753
2024-10-30 14:27:45: [2024-10-30 14:27:45] iter = 02120, loss = 20.4926
2024-10-30 14:27:47: [2024-10-30 14:27:47] iter = 02130, loss = 3.7343
2024-10-30 14:27:49: [2024-10-30 14:27:49] iter = 02140, loss = 33.8403
2024-10-30 14:27:51: [2024-10-30 14:27:51] iter = 02150, loss = 7.5935
2024-10-30 14:27:53: [2024-10-30 14:27:53] iter = 02160, loss = 12.7121
2024-10-30 14:27:54: [2024-10-30 14:27:54] iter = 02170, loss = 6.4962
2024-10-30 14:27:55: [2024-10-30 14:27:55] iter = 02180, loss = 43.3829
2024-10-30 14:27:57: [2024-10-30 14:27:57] iter = 02190, loss = 59.5790
2024-10-30 14:27:59: [2024-10-30 14:27:59] iter = 02200, loss = 41.6959
2024-10-30 14:28:01: [2024-10-30 14:28:01] iter = 02210, loss = 65.8177
2024-10-30 14:28:03: [2024-10-30 14:28:03] iter = 02220, loss = 34.7435
2024-10-30 14:28:04: [2024-10-30 14:28:04] iter = 02230, loss = 43.8105
2024-10-30 14:28:07: [2024-10-30 14:28:07] iter = 02240, loss = 5.0238
2024-10-30 14:28:09: [2024-10-30 14:28:09] iter = 02250, loss = 17.7451
2024-10-30 14:28:11: [2024-10-30 14:28:11] iter = 02260, loss = 14.4759
2024-10-30 14:28:12: [2024-10-30 14:28:12] iter = 02270, loss = 33.9980
2024-10-30 14:28:14: [2024-10-30 14:28:14] iter = 02280, loss = 5.2795
2024-10-30 14:28:16: [2024-10-30 14:28:16] iter = 02290, loss = 23.1184
2024-10-30 14:28:17: [2024-10-30 14:28:17] iter = 02300, loss = 44.0720
2024-10-30 14:28:19: [2024-10-30 14:28:19] iter = 02310, loss = 52.9256
2024-10-30 14:28:21: [2024-10-30 14:28:21] iter = 02320, loss = 22.0314
2024-10-30 14:28:23: [2024-10-30 14:28:23] iter = 02330, loss = 7.9207
2024-10-30 14:28:25: [2024-10-30 14:28:25] iter = 02340, loss = 25.2724
2024-10-30 14:28:27: [2024-10-30 14:28:27] iter = 02350, loss = 6.3757
2024-10-30 14:28:29: [2024-10-30 14:28:29] iter = 02360, loss = 8.3157
2024-10-30 14:28:32: [2024-10-30 14:28:32] iter = 02370, loss = 13.4821
2024-10-30 14:28:34: [2024-10-30 14:28:34] iter = 02380, loss = 10.5155
2024-10-30 14:28:35: [2024-10-30 14:28:35] iter = 02390, loss = 9.3460
2024-10-30 14:28:37: [2024-10-30 14:28:37] iter = 02400, loss = 65.9431
2024-10-30 14:28:39: [2024-10-30 14:28:39] iter = 02410, loss = 44.2896
2024-10-30 14:28:41: [2024-10-30 14:28:41] iter = 02420, loss = 21.4906
2024-10-30 14:28:43: [2024-10-30 14:28:43] iter = 02430, loss = 9.7115
2024-10-30 14:28:45: [2024-10-30 14:28:45] iter = 02440, loss = 5.6544
2024-10-30 14:28:47: [2024-10-30 14:28:47] iter = 02450, loss = 26.7787
2024-10-30 14:28:49: [2024-10-30 14:28:49] iter = 02460, loss = 44.4209
2024-10-30 14:28:51: [2024-10-30 14:28:51] iter = 02470, loss = 12.5774
2024-10-30 14:28:53: [2024-10-30 14:28:53] iter = 02480, loss = 28.9055
2024-10-30 14:28:55: [2024-10-30 14:28:55] iter = 02490, loss = 13.7333
2024-10-30 14:28:56: [2024-10-30 14:28:56] iter = 02500, loss = 10.0620
2024-10-30 14:28:58: [2024-10-30 14:28:58] iter = 02510, loss = 34.8003
2024-10-30 14:29:00: [2024-10-30 14:29:00] iter = 02520, loss = 6.8139
2024-10-30 14:29:02: [2024-10-30 14:29:02] iter = 02530, loss = 8.9380
2024-10-30 14:29:03: [2024-10-30 14:29:03] iter = 02540, loss = 33.0866
2024-10-30 14:29:05: [2024-10-30 14:29:05] iter = 02550, loss = 34.9535
2024-10-30 14:29:07: [2024-10-30 14:29:07] iter = 02560, loss = 13.8156
2024-10-30 14:29:08: [2024-10-30 14:29:08] iter = 02570, loss = 59.3752
2024-10-30 14:29:10: [2024-10-30 14:29:10] iter = 02580, loss = 43.4771
2024-10-30 14:29:12: [2024-10-30 14:29:12] iter = 02590, loss = 54.1970
2024-10-30 14:29:14: [2024-10-30 14:29:14] iter = 02600, loss = 17.4916
2024-10-30 14:29:16: [2024-10-30 14:29:16] iter = 02610, loss = 76.3213
2024-10-30 14:29:17: [2024-10-30 14:29:17] iter = 02620, loss = 9.0260
2024-10-30 14:29:19: [2024-10-30 14:29:19] iter = 02630, loss = 5.0943
2024-10-30 14:29:21: [2024-10-30 14:29:21] iter = 02640, loss = 42.2270
2024-10-30 14:29:22: [2024-10-30 14:29:22] iter = 02650, loss = 14.1139
2024-10-30 14:29:24: [2024-10-30 14:29:24] iter = 02660, loss = 6.0895
2024-10-30 14:29:26: [2024-10-30 14:29:26] iter = 02670, loss = 8.0108
2024-10-30 14:29:28: [2024-10-30 14:29:28] iter = 02680, loss = 35.4637
2024-10-30 14:29:30: [2024-10-30 14:29:30] iter = 02690, loss = 104.1668
2024-10-30 14:29:32: [2024-10-30 14:29:32] iter = 02700, loss = 34.5843
2024-10-30 14:29:34: [2024-10-30 14:29:34] iter = 02710, loss = 8.5666
2024-10-30 14:29:36: [2024-10-30 14:29:36] iter = 02720, loss = 11.1561
2024-10-30 14:29:38: [2024-10-30 14:29:38] iter = 02730, loss = 7.8399
2024-10-30 14:29:40: [2024-10-30 14:29:40] iter = 02740, loss = 4.5696
2024-10-30 14:29:42: [2024-10-30 14:29:42] iter = 02750, loss = 33.7605
2024-10-30 14:29:44: [2024-10-30 14:29:44] iter = 02760, loss = 11.5914
2024-10-30 14:29:46: [2024-10-30 14:29:46] iter = 02770, loss = 8.0761
2024-10-30 14:29:48: [2024-10-30 14:29:48] iter = 02780, loss = 16.1408
2024-10-30 14:29:50: [2024-10-30 14:29:50] iter = 02790, loss = 8.5015
2024-10-30 14:29:51: [2024-10-30 14:29:51] iter = 02800, loss = 93.7244
2024-10-30 14:29:53: [2024-10-30 14:29:53] iter = 02810, loss = 12.9798
2024-10-30 14:29:55: [2024-10-30 14:29:55] iter = 02820, loss = 7.7403
2024-10-30 14:29:57: [2024-10-30 14:29:57] iter = 02830, loss = 40.8688
2024-10-30 14:29:58: [2024-10-30 14:29:58] iter = 02840, loss = 22.5737
2024-10-30 14:30:00: [2024-10-30 14:30:00] iter = 02850, loss = 23.3510
2024-10-30 14:30:02: [2024-10-30 14:30:02] iter = 02860, loss = 17.8534
2024-10-30 14:30:04: [2024-10-30 14:30:04] iter = 02870, loss = 70.3353
2024-10-30 14:30:05: [2024-10-30 14:30:05] iter = 02880, loss = 4.1423
2024-10-30 14:30:07: [2024-10-30 14:30:07] iter = 02890, loss = 3.6298
2024-10-30 14:30:08: [2024-10-30 14:30:08] iter = 02900, loss = 5.3702
2024-10-30 14:30:09: [2024-10-30 14:30:09] iter = 02910, loss = 23.9053
2024-10-30 14:30:11: [2024-10-30 14:30:11] iter = 02920, loss = 10.0013
2024-10-30 14:30:13: [2024-10-30 14:30:13] iter = 02930, loss = 8.3449
2024-10-30 14:30:14: [2024-10-30 14:30:14] iter = 02940, loss = 50.5858
2024-10-30 14:30:16: [2024-10-30 14:30:16] iter = 02950, loss = 43.3865
2024-10-30 14:30:18: [2024-10-30 14:30:18] iter = 02960, loss = 13.2227
2024-10-30 14:30:20: [2024-10-30 14:30:20] iter = 02970, loss = 4.1560
2024-10-30 14:30:22: [2024-10-30 14:30:22] iter = 02980, loss = 12.6896
2024-10-30 14:30:24: [2024-10-30 14:30:24] iter = 02990, loss = 3.2954
2024-10-30 14:30:26: [2024-10-30 14:30:26] iter = 03000, loss = 22.1881
2024-10-30 14:30:28: [2024-10-30 14:30:28] iter = 03010, loss = 12.2760
2024-10-30 14:30:30: [2024-10-30 14:30:30] iter = 03020, loss = 7.2083
2024-10-30 14:30:32: [2024-10-30 14:30:32] iter = 03030, loss = 5.6576
2024-10-30 14:30:33: [2024-10-30 14:30:33] iter = 03040, loss = 11.4000
2024-10-30 14:30:35: [2024-10-30 14:30:35] iter = 03050, loss = 8.3585
2024-10-30 14:30:36: [2024-10-30 14:30:36] iter = 03060, loss = 14.2615
2024-10-30 14:30:38: [2024-10-30 14:30:38] iter = 03070, loss = 6.6703
2024-10-30 14:30:40: [2024-10-30 14:30:40] iter = 03080, loss = 15.3312
2024-10-30 14:30:41: [2024-10-30 14:30:41] iter = 03090, loss = 17.3639
2024-10-30 14:30:44: [2024-10-30 14:30:44] iter = 03100, loss = 9.2706
2024-10-30 14:30:46: [2024-10-30 14:30:46] iter = 03110, loss = 7.6278
2024-10-30 14:30:48: [2024-10-30 14:30:48] iter = 03120, loss = 3.2028
2024-10-30 14:30:50: [2024-10-30 14:30:50] iter = 03130, loss = 11.9567
2024-10-30 14:30:52: [2024-10-30 14:30:52] iter = 03140, loss = 9.8090
2024-10-30 14:30:53: [2024-10-30 14:30:53] iter = 03150, loss = 3.4508
2024-10-30 14:30:55: [2024-10-30 14:30:55] iter = 03160, loss = 13.9354
2024-10-30 14:30:56: [2024-10-30 14:30:56] iter = 03170, loss = 18.9374
2024-10-30 14:30:58: [2024-10-30 14:30:58] iter = 03180, loss = 28.9698
2024-10-30 14:31:00: [2024-10-30 14:31:00] iter = 03190, loss = 13.2512
2024-10-30 14:31:01: [2024-10-30 14:31:01] iter = 03200, loss = 10.1267
2024-10-30 14:31:03: [2024-10-30 14:31:03] iter = 03210, loss = 58.8405
2024-10-30 14:31:05: [2024-10-30 14:31:05] iter = 03220, loss = 16.8164
2024-10-30 14:31:07: [2024-10-30 14:31:07] iter = 03230, loss = 5.2362
2024-10-30 14:31:08: [2024-10-30 14:31:08] iter = 03240, loss = 9.0411
2024-10-30 14:31:10: [2024-10-30 14:31:10] iter = 03250, loss = 8.6539
2024-10-30 14:31:12: [2024-10-30 14:31:12] iter = 03260, loss = 36.2579
2024-10-30 14:31:13: [2024-10-30 14:31:13] iter = 03270, loss = 5.7651
2024-10-30 14:31:14: [2024-10-30 14:31:14] iter = 03280, loss = 14.4912
2024-10-30 14:31:16: [2024-10-30 14:31:16] iter = 03290, loss = 4.0325
2024-10-30 14:31:18: [2024-10-30 14:31:18] iter = 03300, loss = 16.1162
2024-10-30 14:31:20: [2024-10-30 14:31:20] iter = 03310, loss = 41.1775
2024-10-30 14:31:22: [2024-10-30 14:31:22] iter = 03320, loss = 3.5369
2024-10-30 14:31:23: [2024-10-30 14:31:23] iter = 03330, loss = 4.8217
2024-10-30 14:31:25: [2024-10-30 14:31:25] iter = 03340, loss = 13.3112
2024-10-30 14:31:27: [2024-10-30 14:31:27] iter = 03350, loss = 17.8803
2024-10-30 14:31:29: [2024-10-30 14:31:29] iter = 03360, loss = 17.3392
2024-10-30 14:31:31: [2024-10-30 14:31:31] iter = 03370, loss = 60.9948
2024-10-30 14:31:33: [2024-10-30 14:31:33] iter = 03380, loss = 22.8134
2024-10-30 14:31:34: [2024-10-30 14:31:34] iter = 03390, loss = 21.3989
2024-10-30 14:31:37: [2024-10-30 14:31:37] iter = 03400, loss = 36.7590
2024-10-30 14:31:39: [2024-10-30 14:31:39] iter = 03410, loss = 34.5221
2024-10-30 14:31:41: [2024-10-30 14:31:41] iter = 03420, loss = 7.1436
2024-10-30 14:31:43: [2024-10-30 14:31:43] iter = 03430, loss = 3.9594
2024-10-30 14:31:45: [2024-10-30 14:31:45] iter = 03440, loss = 5.4736
2024-10-30 14:31:47: [2024-10-30 14:31:47] iter = 03450, loss = 12.2187
2024-10-30 14:31:49: [2024-10-30 14:31:49] iter = 03460, loss = 11.9678
2024-10-30 14:31:51: [2024-10-30 14:31:51] iter = 03470, loss = 6.6478
2024-10-30 14:31:53: [2024-10-30 14:31:53] iter = 03480, loss = 5.1406
2024-10-30 14:31:55: [2024-10-30 14:31:55] iter = 03490, loss = 5.0553
2024-10-30 14:31:57: [2024-10-30 14:31:57] iter = 03500, loss = 5.0558
2024-10-30 14:31:59: [2024-10-30 14:31:59] iter = 03510, loss = 13.3407
2024-10-30 14:32:00: [2024-10-30 14:32:00] iter = 03520, loss = 43.5120
2024-10-30 14:32:02: [2024-10-30 14:32:02] iter = 03530, loss = 8.6391
2024-10-30 14:32:04: [2024-10-30 14:32:04] iter = 03540, loss = 34.3878
2024-10-30 14:32:06: [2024-10-30 14:32:06] iter = 03550, loss = 12.8864
2024-10-30 14:32:08: [2024-10-30 14:32:08] iter = 03560, loss = 5.1844
2024-10-30 14:32:10: [2024-10-30 14:32:10] iter = 03570, loss = 10.6903
2024-10-30 14:32:12: [2024-10-30 14:32:12] iter = 03580, loss = 7.2578
2024-10-30 14:32:14: [2024-10-30 14:32:14] iter = 03590, loss = 47.5787
2024-10-30 14:32:16: [2024-10-30 14:32:16] iter = 03600, loss = 6.1989
2024-10-30 14:32:18: [2024-10-30 14:32:18] iter = 03610, loss = 3.8979
2024-10-30 14:32:19: [2024-10-30 14:32:19] iter = 03620, loss = 28.0541
2024-10-30 14:32:21: [2024-10-30 14:32:21] iter = 03630, loss = 5.4892
2024-10-30 14:32:23: [2024-10-30 14:32:23] iter = 03640, loss = 4.7095
2024-10-30 14:32:24: [2024-10-30 14:32:24] iter = 03650, loss = 5.2254
2024-10-30 14:32:26: [2024-10-30 14:32:26] iter = 03660, loss = 7.7845
2024-10-30 14:32:28: [2024-10-30 14:32:28] iter = 03670, loss = 17.2133
2024-10-30 14:32:29: [2024-10-30 14:32:29] iter = 03680, loss = 31.0104
2024-10-30 14:32:31: [2024-10-30 14:32:31] iter = 03690, loss = 24.8526
2024-10-30 14:32:32: [2024-10-30 14:32:32] iter = 03700, loss = 5.0550
2024-10-30 14:32:34: [2024-10-30 14:32:34] iter = 03710, loss = 46.3023
2024-10-30 14:32:36: [2024-10-30 14:32:36] iter = 03720, loss = 3.7465
2024-10-30 14:32:38: [2024-10-30 14:32:38] iter = 03730, loss = 4.6446
2024-10-30 14:32:40: [2024-10-30 14:32:40] iter = 03740, loss = 14.8939
2024-10-30 14:32:42: [2024-10-30 14:32:42] iter = 03750, loss = 14.4508
2024-10-30 14:32:44: [2024-10-30 14:32:44] iter = 03760, loss = 4.9888
2024-10-30 14:32:45: [2024-10-30 14:32:45] iter = 03770, loss = 30.4429
2024-10-30 14:32:47: [2024-10-30 14:32:47] iter = 03780, loss = 13.4685
2024-10-30 14:32:49: [2024-10-30 14:32:49] iter = 03790, loss = 33.0903
2024-10-30 14:32:50: [2024-10-30 14:32:50] iter = 03800, loss = 13.6104
2024-10-30 14:32:52: [2024-10-30 14:32:52] iter = 03810, loss = 5.3824
2024-10-30 14:32:54: [2024-10-30 14:32:54] iter = 03820, loss = 7.4315
2024-10-30 14:32:56: [2024-10-30 14:32:56] iter = 03830, loss = 20.7910
2024-10-30 14:32:57: [2024-10-30 14:32:57] iter = 03840, loss = 8.3851
2024-10-30 14:33:00: [2024-10-30 14:33:00] iter = 03850, loss = 3.4346
2024-10-30 14:33:02: [2024-10-30 14:33:02] iter = 03860, loss = 27.8829
2024-10-30 14:33:04: [2024-10-30 14:33:04] iter = 03870, loss = 13.4104
2024-10-30 14:33:05: [2024-10-30 14:33:05] iter = 03880, loss = 13.7088
2024-10-30 14:33:07: [2024-10-30 14:33:07] iter = 03890, loss = 5.0694
2024-10-30 14:33:09: [2024-10-30 14:33:09] iter = 03900, loss = 12.8480
2024-10-30 14:33:11: [2024-10-30 14:33:11] iter = 03910, loss = 7.0639
2024-10-30 14:33:13: [2024-10-30 14:33:13] iter = 03920, loss = 16.1639
2024-10-30 14:33:15: [2024-10-30 14:33:15] iter = 03930, loss = 8.3022
2024-10-30 14:33:17: [2024-10-30 14:33:17] iter = 03940, loss = 25.8849
2024-10-30 14:33:18: [2024-10-30 14:33:18] iter = 03950, loss = 18.4926
2024-10-30 14:33:19: [2024-10-30 14:33:19] iter = 03960, loss = 12.2031
2024-10-30 14:33:21: [2024-10-30 14:33:21] iter = 03970, loss = 26.9544
2024-10-30 14:33:23: [2024-10-30 14:33:23] iter = 03980, loss = 7.6847
2024-10-30 14:33:24: [2024-10-30 14:33:24] iter = 03990, loss = 65.4218
2024-10-30 14:33:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 14:33:26: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:33:26: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 6195}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:34:36: Evaluate 5 random ConvNet, ACCmean = 0.3829 ACCstd = 0.0072
-------------------------
2024-10-30 14:34:36: Evaluate 5 random ConvNet, SENmean = 0.2781 SENstd = 0.0045
-------------------------
2024-10-30 14:34:36: Evaluate 5 random ConvNet, SPEmean = 0.9064 SPEstd = 0.0012
-------------------------
2024-10-30 14:34:36: Evaluate 5 random ConvNet, F!mean = 0.2387 F!std = 0.0057
-------------------------
2024-10-30 14:34:36: Evaluate 5 random ConvNet, mean = 0.3829 std = 0.0072
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:34:36: [2024-10-30 14:34:36] iter = 04000, loss = 25.9919
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:34:38: [2024-10-30 14:34:38] iter = 04010, loss = 11.8013
2024-10-30 14:34:39: [2024-10-30 14:34:39] iter = 04020, loss = 44.5457
2024-10-30 14:34:41: [2024-10-30 14:34:41] iter = 04030, loss = 4.0439
2024-10-30 14:34:43: [2024-10-30 14:34:43] iter = 04040, loss = 12.8946
2024-10-30 14:34:45: [2024-10-30 14:34:45] iter = 04050, loss = 18.4302
2024-10-30 14:34:46: [2024-10-30 14:34:46] iter = 04060, loss = 19.3230
2024-10-30 14:34:48: [2024-10-30 14:34:48] iter = 04070, loss = 5.5380
2024-10-30 14:34:49: [2024-10-30 14:34:49] iter = 04080, loss = 42.7355
2024-10-30 14:34:51: [2024-10-30 14:34:51] iter = 04090, loss = 22.6195
2024-10-30 14:34:53: [2024-10-30 14:34:53] iter = 04100, loss = 31.1249
2024-10-30 14:34:55: [2024-10-30 14:34:55] iter = 04110, loss = 7.2842
2024-10-30 14:34:56: [2024-10-30 14:34:56] iter = 04120, loss = 6.1753
2024-10-30 14:34:58: [2024-10-30 14:34:58] iter = 04130, loss = 41.5660
2024-10-30 14:35:00: [2024-10-30 14:35:00] iter = 04140, loss = 22.3131
2024-10-30 14:35:01: [2024-10-30 14:35:01] iter = 04150, loss = 15.0821
2024-10-30 14:35:03: [2024-10-30 14:35:03] iter = 04160, loss = 7.2939
2024-10-30 14:35:05: [2024-10-30 14:35:05] iter = 04170, loss = 6.6422
2024-10-30 14:35:06: [2024-10-30 14:35:06] iter = 04180, loss = 5.6586
2024-10-30 14:35:08: [2024-10-30 14:35:08] iter = 04190, loss = 19.3415
2024-10-30 14:35:10: [2024-10-30 14:35:10] iter = 04200, loss = 14.3821
2024-10-30 14:35:11: [2024-10-30 14:35:11] iter = 04210, loss = 40.4069
2024-10-30 14:35:13: [2024-10-30 14:35:13] iter = 04220, loss = 34.9544
2024-10-30 14:35:14: [2024-10-30 14:35:14] iter = 04230, loss = 4.3937
2024-10-30 14:35:16: [2024-10-30 14:35:16] iter = 04240, loss = 20.4673
2024-10-30 14:35:17: [2024-10-30 14:35:17] iter = 04250, loss = 50.0172
2024-10-30 14:35:19: [2024-10-30 14:35:19] iter = 04260, loss = 9.0740
2024-10-30 14:35:21: [2024-10-30 14:35:21] iter = 04270, loss = 15.4191
2024-10-30 14:35:24: [2024-10-30 14:35:24] iter = 04280, loss = 8.8345
2024-10-30 14:35:25: [2024-10-30 14:35:25] iter = 04290, loss = 20.7840
2024-10-30 14:35:27: [2024-10-30 14:35:27] iter = 04300, loss = 11.7895
2024-10-30 14:35:29: [2024-10-30 14:35:29] iter = 04310, loss = 23.1182
2024-10-30 14:35:32: [2024-10-30 14:35:32] iter = 04320, loss = 10.6298
2024-10-30 14:35:34: [2024-10-30 14:35:34] iter = 04330, loss = 42.1840
2024-10-30 14:35:36: [2024-10-30 14:35:36] iter = 04340, loss = 5.4130
2024-10-30 14:35:37: [2024-10-30 14:35:37] iter = 04350, loss = 11.6676
2024-10-30 14:35:38: [2024-10-30 14:35:38] iter = 04360, loss = 5.9675
2024-10-30 14:35:40: [2024-10-30 14:35:40] iter = 04370, loss = 21.1955
2024-10-30 14:35:42: [2024-10-30 14:35:42] iter = 04380, loss = 10.9364
2024-10-30 14:35:44: [2024-10-30 14:35:44] iter = 04390, loss = 8.7349
2024-10-30 14:35:45: [2024-10-30 14:35:45] iter = 04400, loss = 42.1784
2024-10-30 14:35:47: [2024-10-30 14:35:47] iter = 04410, loss = 42.3547
2024-10-30 14:35:49: [2024-10-30 14:35:49] iter = 04420, loss = 4.1809
2024-10-30 14:35:51: [2024-10-30 14:35:51] iter = 04430, loss = 30.3155
2024-10-30 14:35:52: [2024-10-30 14:35:52] iter = 04440, loss = 18.8642
2024-10-30 14:35:54: [2024-10-30 14:35:54] iter = 04450, loss = 10.5161
2024-10-30 14:35:55: [2024-10-30 14:35:55] iter = 04460, loss = 5.2924
2024-10-30 14:35:58: [2024-10-30 14:35:58] iter = 04470, loss = 4.1842
2024-10-30 14:35:59: [2024-10-30 14:35:59] iter = 04480, loss = 16.9857
2024-10-30 14:36:01: [2024-10-30 14:36:01] iter = 04490, loss = 9.7533
2024-10-30 14:36:03: [2024-10-30 14:36:03] iter = 04500, loss = 17.5849
2024-10-30 14:36:05: [2024-10-30 14:36:05] iter = 04510, loss = 7.1668
2024-10-30 14:36:07: [2024-10-30 14:36:07] iter = 04520, loss = 7.5680
2024-10-30 14:36:09: [2024-10-30 14:36:09] iter = 04530, loss = 3.3704
2024-10-30 14:36:10: [2024-10-30 14:36:10] iter = 04540, loss = 30.4448
2024-10-30 14:36:12: [2024-10-30 14:36:12] iter = 04550, loss = 31.4305
2024-10-30 14:36:14: [2024-10-30 14:36:14] iter = 04560, loss = 24.2640
2024-10-30 14:36:16: [2024-10-30 14:36:16] iter = 04570, loss = 4.2954
2024-10-30 14:36:18: [2024-10-30 14:36:18] iter = 04580, loss = 15.9856
2024-10-30 14:36:20: [2024-10-30 14:36:20] iter = 04590, loss = 9.6248
2024-10-30 14:36:22: [2024-10-30 14:36:22] iter = 04600, loss = 22.4801
2024-10-30 14:36:23: [2024-10-30 14:36:23] iter = 04610, loss = 4.6588
2024-10-30 14:36:25: [2024-10-30 14:36:25] iter = 04620, loss = 97.3276
2024-10-30 14:36:27: [2024-10-30 14:36:27] iter = 04630, loss = 5.6345
2024-10-30 14:36:29: [2024-10-30 14:36:29] iter = 04640, loss = 4.0085
2024-10-30 14:36:31: [2024-10-30 14:36:31] iter = 04650, loss = 66.4309
2024-10-30 14:36:33: [2024-10-30 14:36:33] iter = 04660, loss = 8.2182
2024-10-30 14:36:35: [2024-10-30 14:36:35] iter = 04670, loss = 4.7285
2024-10-30 14:36:36: [2024-10-30 14:36:36] iter = 04680, loss = 36.1478
2024-10-30 14:36:38: [2024-10-30 14:36:38] iter = 04690, loss = 21.8580
2024-10-30 14:36:40: [2024-10-30 14:36:40] iter = 04700, loss = 12.1625
2024-10-30 14:36:41: [2024-10-30 14:36:41] iter = 04710, loss = 7.0227
2024-10-30 14:36:44: [2024-10-30 14:36:44] iter = 04720, loss = 6.4028
2024-10-30 14:36:45: [2024-10-30 14:36:45] iter = 04730, loss = 23.0296
2024-10-30 14:36:47: [2024-10-30 14:36:47] iter = 04740, loss = 3.5825
2024-10-30 14:36:49: [2024-10-30 14:36:49] iter = 04750, loss = 6.6829
2024-10-30 14:36:50: [2024-10-30 14:36:50] iter = 04760, loss = 5.6376
2024-10-30 14:36:53: [2024-10-30 14:36:53] iter = 04770, loss = 58.5435
2024-10-30 14:36:55: [2024-10-30 14:36:55] iter = 04780, loss = 20.9135
2024-10-30 14:36:56: [2024-10-30 14:36:56] iter = 04790, loss = 42.3381
2024-10-30 14:36:58: [2024-10-30 14:36:58] iter = 04800, loss = 48.2028
2024-10-30 14:37:00: [2024-10-30 14:37:00] iter = 04810, loss = 3.9308
2024-10-30 14:37:02: [2024-10-30 14:37:02] iter = 04820, loss = 47.3850
2024-10-30 14:37:04: [2024-10-30 14:37:04] iter = 04830, loss = 22.2175
2024-10-30 14:37:05: [2024-10-30 14:37:05] iter = 04840, loss = 44.2424
2024-10-30 14:37:07: [2024-10-30 14:37:07] iter = 04850, loss = 13.7847
2024-10-30 14:37:09: [2024-10-30 14:37:09] iter = 04860, loss = 8.9043
2024-10-30 14:37:11: [2024-10-30 14:37:11] iter = 04870, loss = 12.5580
2024-10-30 14:37:13: [2024-10-30 14:37:13] iter = 04880, loss = 4.5125
2024-10-30 14:37:14: [2024-10-30 14:37:14] iter = 04890, loss = 42.5663
2024-10-30 14:37:16: [2024-10-30 14:37:16] iter = 04900, loss = 10.0442
2024-10-30 14:37:18: [2024-10-30 14:37:18] iter = 04910, loss = 4.1233
2024-10-30 14:37:20: [2024-10-30 14:37:20] iter = 04920, loss = 64.7484
2024-10-30 14:37:23: [2024-10-30 14:37:23] iter = 04930, loss = 12.0560
2024-10-30 14:37:25: [2024-10-30 14:37:25] iter = 04940, loss = 4.6380
2024-10-30 14:37:28: [2024-10-30 14:37:28] iter = 04950, loss = 19.0377
2024-10-30 14:37:30: [2024-10-30 14:37:30] iter = 04960, loss = 44.9540
2024-10-30 14:37:31: [2024-10-30 14:37:31] iter = 04970, loss = 21.5185
2024-10-30 14:37:34: [2024-10-30 14:37:34] iter = 04980, loss = 5.5066
2024-10-30 14:37:36: [2024-10-30 14:37:36] iter = 04990, loss = 4.7743
2024-10-30 14:37:38: [2024-10-30 14:37:38] iter = 05000, loss = 55.5599
2024-10-30 14:37:40: [2024-10-30 14:37:40] iter = 05010, loss = 37.2079
2024-10-30 14:37:42: [2024-10-30 14:37:42] iter = 05020, loss = 5.0136
2024-10-30 14:37:44: [2024-10-30 14:37:44] iter = 05030, loss = 51.1789
2024-10-30 14:37:45: [2024-10-30 14:37:45] iter = 05040, loss = 23.1952
2024-10-30 14:37:47: [2024-10-30 14:37:47] iter = 05050, loss = 18.7650
2024-10-30 14:37:49: [2024-10-30 14:37:49] iter = 05060, loss = 55.8357
2024-10-30 14:37:50: [2024-10-30 14:37:50] iter = 05070, loss = 5.7934
2024-10-30 14:37:52: [2024-10-30 14:37:52] iter = 05080, loss = 5.1253
2024-10-30 14:37:55: [2024-10-30 14:37:55] iter = 05090, loss = 4.7085
2024-10-30 14:37:57: [2024-10-30 14:37:57] iter = 05100, loss = 37.6557
2024-10-30 14:37:59: [2024-10-30 14:37:59] iter = 05110, loss = 24.9012
2024-10-30 14:38:00: [2024-10-30 14:38:00] iter = 05120, loss = 14.9455
2024-10-30 14:38:03: [2024-10-30 14:38:03] iter = 05130, loss = 4.5057
2024-10-30 14:38:04: [2024-10-30 14:38:04] iter = 05140, loss = 61.2570
2024-10-30 14:38:06: [2024-10-30 14:38:06] iter = 05150, loss = 7.7345
2024-10-30 14:38:08: [2024-10-30 14:38:08] iter = 05160, loss = 14.6766
2024-10-30 14:38:10: [2024-10-30 14:38:10] iter = 05170, loss = 61.8052
2024-10-30 14:38:12: [2024-10-30 14:38:12] iter = 05180, loss = 23.2780
2024-10-30 14:38:14: [2024-10-30 14:38:14] iter = 05190, loss = 25.1314
2024-10-30 14:38:15: [2024-10-30 14:38:15] iter = 05200, loss = 40.3173
2024-10-30 14:38:18: [2024-10-30 14:38:18] iter = 05210, loss = 4.9314
2024-10-30 14:38:21: [2024-10-30 14:38:21] iter = 05220, loss = 9.7561
2024-10-30 14:38:23: [2024-10-30 14:38:23] iter = 05230, loss = 4.8005
2024-10-30 14:38:25: [2024-10-30 14:38:25] iter = 05240, loss = 66.4308
2024-10-30 14:38:26: [2024-10-30 14:38:26] iter = 05250, loss = 18.1260
2024-10-30 14:38:28: [2024-10-30 14:38:28] iter = 05260, loss = 18.6937
2024-10-30 14:38:29: [2024-10-30 14:38:29] iter = 05270, loss = 8.3568
2024-10-30 14:38:30: [2024-10-30 14:38:30] iter = 05280, loss = 5.8346
2024-10-30 14:38:32: [2024-10-30 14:38:32] iter = 05290, loss = 40.3086
2024-10-30 14:38:33: [2024-10-30 14:38:33] iter = 05300, loss = 38.0437
2024-10-30 14:38:36: [2024-10-30 14:38:36] iter = 05310, loss = 4.8582
2024-10-30 14:38:38: [2024-10-30 14:38:38] iter = 05320, loss = 20.0369
2024-10-30 14:38:40: [2024-10-30 14:38:40] iter = 05330, loss = 22.3448
2024-10-30 14:38:42: [2024-10-30 14:38:42] iter = 05340, loss = 4.1240
2024-10-30 14:38:44: [2024-10-30 14:38:44] iter = 05350, loss = 33.3616
2024-10-30 14:38:46: [2024-10-30 14:38:46] iter = 05360, loss = 3.4455
2024-10-30 14:38:48: [2024-10-30 14:38:48] iter = 05370, loss = 32.1557
2024-10-30 14:38:50: [2024-10-30 14:38:49] iter = 05380, loss = 23.7858
2024-10-30 14:38:51: [2024-10-30 14:38:51] iter = 05390, loss = 3.8835
2024-10-30 14:38:53: [2024-10-30 14:38:53] iter = 05400, loss = 4.8570
2024-10-30 14:38:55: [2024-10-30 14:38:55] iter = 05410, loss = 28.6742
2024-10-30 14:38:56: [2024-10-30 14:38:56] iter = 05420, loss = 8.6395
2024-10-30 14:38:58: [2024-10-30 14:38:58] iter = 05430, loss = 17.0493
2024-10-30 14:39:00: [2024-10-30 14:39:00] iter = 05440, loss = 15.1989
2024-10-30 14:39:02: [2024-10-30 14:39:02] iter = 05450, loss = 11.2758
2024-10-30 14:39:04: [2024-10-30 14:39:04] iter = 05460, loss = 8.1630
2024-10-30 14:39:05: [2024-10-30 14:39:05] iter = 05470, loss = 10.5503
2024-10-30 14:39:07: [2024-10-30 14:39:07] iter = 05480, loss = 32.0766
2024-10-30 14:39:09: [2024-10-30 14:39:09] iter = 05490, loss = 9.7144
2024-10-30 14:39:12: [2024-10-30 14:39:12] iter = 05500, loss = 79.4505
2024-10-30 14:39:14: [2024-10-30 14:39:14] iter = 05510, loss = 42.5389
2024-10-30 14:39:16: [2024-10-30 14:39:16] iter = 05520, loss = 18.7597
2024-10-30 14:39:17: [2024-10-30 14:39:17] iter = 05530, loss = 4.1422
2024-10-30 14:39:20: [2024-10-30 14:39:20] iter = 05540, loss = 8.9158
2024-10-30 14:39:22: [2024-10-30 14:39:22] iter = 05550, loss = 4.8549
2024-10-30 14:39:24: [2024-10-30 14:39:24] iter = 05560, loss = 3.1452
2024-10-30 14:39:26: [2024-10-30 14:39:26] iter = 05570, loss = 57.4503
2024-10-30 14:39:27: [2024-10-30 14:39:27] iter = 05580, loss = 7.2145
2024-10-30 14:39:29: [2024-10-30 14:39:29] iter = 05590, loss = 39.3900
2024-10-30 14:39:31: [2024-10-30 14:39:31] iter = 05600, loss = 60.5756
2024-10-30 14:39:33: [2024-10-30 14:39:33] iter = 05610, loss = 3.3306
2024-10-30 14:39:35: [2024-10-30 14:39:35] iter = 05620, loss = 78.1438
2024-10-30 14:39:37: [2024-10-30 14:39:37] iter = 05630, loss = 72.9882
2024-10-30 14:39:39: [2024-10-30 14:39:39] iter = 05640, loss = 100.4966
2024-10-30 14:39:40: [2024-10-30 14:39:40] iter = 05650, loss = 36.7638
2024-10-30 14:39:42: [2024-10-30 14:39:42] iter = 05660, loss = 10.6361
2024-10-30 14:39:44: [2024-10-30 14:39:44] iter = 05670, loss = 6.1708
2024-10-30 14:39:46: [2024-10-30 14:39:46] iter = 05680, loss = 7.2199
2024-10-30 14:39:48: [2024-10-30 14:39:48] iter = 05690, loss = 9.2724
2024-10-30 14:39:49: [2024-10-30 14:39:49] iter = 05700, loss = 22.1540
2024-10-30 14:39:51: [2024-10-30 14:39:51] iter = 05710, loss = 16.5829
2024-10-30 14:39:53: [2024-10-30 14:39:53] iter = 05720, loss = 24.4513
2024-10-30 14:39:55: [2024-10-30 14:39:55] iter = 05730, loss = 33.2523
2024-10-30 14:39:57: [2024-10-30 14:39:57] iter = 05740, loss = 7.0822
2024-10-30 14:39:59: [2024-10-30 14:39:59] iter = 05750, loss = 53.7629
2024-10-30 14:40:01: [2024-10-30 14:40:01] iter = 05760, loss = 15.0200
2024-10-30 14:40:02: [2024-10-30 14:40:02] iter = 05770, loss = 21.6221
2024-10-30 14:40:05: [2024-10-30 14:40:05] iter = 05780, loss = 5.4225
2024-10-30 14:40:07: [2024-10-30 14:40:07] iter = 05790, loss = 18.4713
2024-10-30 14:40:09: [2024-10-30 14:40:09] iter = 05800, loss = 29.6978
2024-10-30 14:40:11: [2024-10-30 14:40:11] iter = 05810, loss = 8.7888
2024-10-30 14:40:14: [2024-10-30 14:40:14] iter = 05820, loss = 5.7966
2024-10-30 14:40:16: [2024-10-30 14:40:16] iter = 05830, loss = 15.5315
2024-10-30 14:40:18: [2024-10-30 14:40:18] iter = 05840, loss = 15.1377
2024-10-30 14:40:21: [2024-10-30 14:40:21] iter = 05850, loss = 3.8830
2024-10-30 14:40:23: [2024-10-30 14:40:23] iter = 05860, loss = 10.2897
2024-10-30 14:40:25: [2024-10-30 14:40:25] iter = 05870, loss = 13.4897
2024-10-30 14:40:27: [2024-10-30 14:40:27] iter = 05880, loss = 20.9920
2024-10-30 14:40:28: [2024-10-30 14:40:28] iter = 05890, loss = 25.4742
2024-10-30 14:40:30: [2024-10-30 14:40:30] iter = 05900, loss = 24.5421
2024-10-30 14:40:32: [2024-10-30 14:40:32] iter = 05910, loss = 5.9554
2024-10-30 14:40:34: [2024-10-30 14:40:34] iter = 05920, loss = 3.7384
2024-10-30 14:40:36: [2024-10-30 14:40:35] iter = 05930, loss = 33.4190
2024-10-30 14:40:37: [2024-10-30 14:40:37] iter = 05940, loss = 4.1442
2024-10-30 14:40:39: [2024-10-30 14:40:39] iter = 05950, loss = 4.5386
2024-10-30 14:40:42: [2024-10-30 14:40:42] iter = 05960, loss = 3.6407
2024-10-30 14:40:44: [2024-10-30 14:40:44] iter = 05970, loss = 9.2156
2024-10-30 14:40:46: [2024-10-30 14:40:46] iter = 05980, loss = 56.0644
2024-10-30 14:40:48: [2024-10-30 14:40:48] iter = 05990, loss = 26.3604
2024-10-30 14:40:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 14:40:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:40:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50984}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:42:07: Evaluate 5 random ConvNet, ACCmean = 0.3792 ACCstd = 0.0084
-------------------------
2024-10-30 14:42:07: Evaluate 5 random ConvNet, SENmean = 0.3029 SENstd = 0.0021
-------------------------
2024-10-30 14:42:07: Evaluate 5 random ConvNet, SPEmean = 0.9097 SPEstd = 0.0007
-------------------------
2024-10-30 14:42:07: Evaluate 5 random ConvNet, F!mean = 0.2744 F!std = 0.0039
-------------------------
2024-10-30 14:42:07: Evaluate 5 random ConvNet, mean = 0.3792 std = 0.0084
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:42:07: [2024-10-30 14:42:07] iter = 06000, loss = 29.7838
2024-10-30 14:42:09: [2024-10-30 14:42:09] iter = 06010, loss = 129.8000
2024-10-30 14:42:11: [2024-10-30 14:42:11] iter = 06020, loss = 6.6175
2024-10-30 14:42:13: [2024-10-30 14:42:13] iter = 06030, loss = 5.0750
2024-10-30 14:42:15: [2024-10-30 14:42:15] iter = 06040, loss = 13.0119
2024-10-30 14:42:17: [2024-10-30 14:42:17] iter = 06050, loss = 46.9462
2024-10-30 14:42:20: [2024-10-30 14:42:20] iter = 06060, loss = 56.2888
2024-10-30 14:42:23: [2024-10-30 14:42:23] iter = 06070, loss = 10.4622
2024-10-30 14:42:26: [2024-10-30 14:42:26] iter = 06080, loss = 9.5455
2024-10-30 14:42:28: [2024-10-30 14:42:28] iter = 06090, loss = 4.8357
2024-10-30 14:42:30: [2024-10-30 14:42:30] iter = 06100, loss = 15.6966
2024-10-30 14:42:33: [2024-10-30 14:42:33] iter = 06110, loss = 5.6164
2024-10-30 14:42:35: [2024-10-30 14:42:35] iter = 06120, loss = 35.7257
2024-10-30 14:42:37: [2024-10-30 14:42:37] iter = 06130, loss = 4.0874
2024-10-30 14:42:40: [2024-10-30 14:42:40] iter = 06140, loss = 3.6328
2024-10-30 14:42:42: [2024-10-30 14:42:42] iter = 06150, loss = 20.7587
2024-10-30 14:42:45: [2024-10-30 14:42:45] iter = 06160, loss = 4.5845
2024-10-30 14:42:47: [2024-10-30 14:42:47] iter = 06170, loss = 51.6160
2024-10-30 14:42:49: [2024-10-30 14:42:49] iter = 06180, loss = 61.3646
2024-10-30 14:42:51: [2024-10-30 14:42:51] iter = 06190, loss = 5.8883
2024-10-30 14:42:53: [2024-10-30 14:42:53] iter = 06200, loss = 16.5293
2024-10-30 14:42:55: [2024-10-30 14:42:55] iter = 06210, loss = 40.9236
2024-10-30 14:42:57: [2024-10-30 14:42:57] iter = 06220, loss = 39.4899
2024-10-30 14:42:59: [2024-10-30 14:42:59] iter = 06230, loss = 3.9033
2024-10-30 14:43:00: [2024-10-30 14:43:00] iter = 06240, loss = 7.6881
2024-10-30 14:43:02: [2024-10-30 14:43:02] iter = 06250, loss = 35.4702
2024-10-30 14:43:04: [2024-10-30 14:43:04] iter = 06260, loss = 25.5980
2024-10-30 14:43:06: [2024-10-30 14:43:06] iter = 06270, loss = 19.6362
2024-10-30 14:43:07: [2024-10-30 14:43:07] iter = 06280, loss = 14.5332
2024-10-30 14:43:09: [2024-10-30 14:43:09] iter = 06290, loss = 22.6322
2024-10-30 14:43:11: [2024-10-30 14:43:11] iter = 06300, loss = 11.6170
2024-10-30 14:43:13: [2024-10-30 14:43:13] iter = 06310, loss = 4.4795
2024-10-30 14:43:15: [2024-10-30 14:43:15] iter = 06320, loss = 7.5742
2024-10-30 14:43:17: [2024-10-30 14:43:17] iter = 06330, loss = 5.7004
2024-10-30 14:43:18: [2024-10-30 14:43:18] iter = 06340, loss = 15.7525
2024-10-30 14:43:20: [2024-10-30 14:43:20] iter = 06350, loss = 115.6153
2024-10-30 14:43:22: [2024-10-30 14:43:22] iter = 06360, loss = 8.8953
2024-10-30 14:43:24: [2024-10-30 14:43:24] iter = 06370, loss = 5.8540
2024-10-30 14:43:25: [2024-10-30 14:43:25] iter = 06380, loss = 17.6937
2024-10-30 14:43:27: [2024-10-30 14:43:27] iter = 06390, loss = 40.9133
2024-10-30 14:43:28: [2024-10-30 14:43:28] iter = 06400, loss = 8.7592
2024-10-30 14:43:30: [2024-10-30 14:43:30] iter = 06410, loss = 11.4312
2024-10-30 14:43:31: [2024-10-30 14:43:31] iter = 06420, loss = 6.6123
2024-10-30 14:43:33: [2024-10-30 14:43:33] iter = 06430, loss = 8.8137
2024-10-30 14:43:34: [2024-10-30 14:43:34] iter = 06440, loss = 6.6518
2024-10-30 14:43:36: [2024-10-30 14:43:36] iter = 06450, loss = 5.2819
2024-10-30 14:43:38: [2024-10-30 14:43:38] iter = 06460, loss = 13.3141
2024-10-30 14:43:40: [2024-10-30 14:43:40] iter = 06470, loss = 4.8782
2024-10-30 14:43:42: [2024-10-30 14:43:42] iter = 06480, loss = 57.4993
2024-10-30 14:43:44: [2024-10-30 14:43:44] iter = 06490, loss = 26.8633
2024-10-30 14:43:46: [2024-10-30 14:43:46] iter = 06500, loss = 6.8832
2024-10-30 14:43:48: [2024-10-30 14:43:48] iter = 06510, loss = 6.0799
2024-10-30 14:43:50: [2024-10-30 14:43:50] iter = 06520, loss = 14.9710
2024-10-30 14:43:52: [2024-10-30 14:43:52] iter = 06530, loss = 45.2923
2024-10-30 14:43:54: [2024-10-30 14:43:54] iter = 06540, loss = 22.0994
2024-10-30 14:43:56: [2024-10-30 14:43:56] iter = 06550, loss = 4.7490
2024-10-30 14:43:58: [2024-10-30 14:43:58] iter = 06560, loss = 21.3843
2024-10-30 14:44:00: [2024-10-30 14:44:00] iter = 06570, loss = 5.4772
2024-10-30 14:44:02: [2024-10-30 14:44:02] iter = 06580, loss = 27.4579
2024-10-30 14:44:04: [2024-10-30 14:44:04] iter = 06590, loss = 8.1588
2024-10-30 14:44:06: [2024-10-30 14:44:06] iter = 06600, loss = 11.5854
2024-10-30 14:44:08: [2024-10-30 14:44:08] iter = 06610, loss = 22.0737
2024-10-30 14:44:10: [2024-10-30 14:44:10] iter = 06620, loss = 3.8733
2024-10-30 14:44:11: [2024-10-30 14:44:11] iter = 06630, loss = 9.8002
2024-10-30 14:44:13: [2024-10-30 14:44:13] iter = 06640, loss = 20.8887
2024-10-30 14:44:15: [2024-10-30 14:44:15] iter = 06650, loss = 66.5671
2024-10-30 14:44:16: [2024-10-30 14:44:16] iter = 06660, loss = 49.9955
2024-10-30 14:44:19: [2024-10-30 14:44:19] iter = 06670, loss = 52.2979
2024-10-30 14:44:21: [2024-10-30 14:44:21] iter = 06680, loss = 94.0947
2024-10-30 14:44:24: [2024-10-30 14:44:24] iter = 06690, loss = 4.6351
2024-10-30 14:44:26: [2024-10-30 14:44:26] iter = 06700, loss = 40.9739
2024-10-30 14:44:28: [2024-10-30 14:44:28] iter = 06710, loss = 5.3066
2024-10-30 14:44:30: [2024-10-30 14:44:30] iter = 06720, loss = 10.1718
2024-10-30 14:44:32: [2024-10-30 14:44:32] iter = 06730, loss = 19.0040
2024-10-30 14:44:34: [2024-10-30 14:44:34] iter = 06740, loss = 20.0550
2024-10-30 14:44:36: [2024-10-30 14:44:36] iter = 06750, loss = 9.3396
2024-10-30 14:44:37: [2024-10-30 14:44:37] iter = 06760, loss = 46.3383
2024-10-30 14:44:39: [2024-10-30 14:44:39] iter = 06770, loss = 4.0663
2024-10-30 14:44:41: [2024-10-30 14:44:41] iter = 06780, loss = 16.4831
2024-10-30 14:44:43: [2024-10-30 14:44:43] iter = 06790, loss = 3.9401
2024-10-30 14:44:44: [2024-10-30 14:44:44] iter = 06800, loss = 27.3778
2024-10-30 14:44:46: [2024-10-30 14:44:46] iter = 06810, loss = 16.7510
2024-10-30 14:44:48: [2024-10-30 14:44:48] iter = 06820, loss = 15.3459
2024-10-30 14:44:50: [2024-10-30 14:44:50] iter = 06830, loss = 12.3583
2024-10-30 14:44:52: [2024-10-30 14:44:52] iter = 06840, loss = 29.4856
2024-10-30 14:44:53: [2024-10-30 14:44:53] iter = 06850, loss = 4.2323
2024-10-30 14:44:55: [2024-10-30 14:44:55] iter = 06860, loss = 4.5289
2024-10-30 14:44:56: [2024-10-30 14:44:56] iter = 06870, loss = 42.7566
2024-10-30 14:44:58: [2024-10-30 14:44:58] iter = 06880, loss = 25.2107
2024-10-30 14:45:00: [2024-10-30 14:45:00] iter = 06890, loss = 3.4845
2024-10-30 14:45:02: [2024-10-30 14:45:02] iter = 06900, loss = 16.2418
2024-10-30 14:45:03: [2024-10-30 14:45:03] iter = 06910, loss = 4.5290
2024-10-30 14:45:05: [2024-10-30 14:45:05] iter = 06920, loss = 8.6597
2024-10-30 14:45:06: [2024-10-30 14:45:06] iter = 06930, loss = 4.9350
2024-10-30 14:45:07: [2024-10-30 14:45:07] iter = 06940, loss = 3.9369
2024-10-30 14:45:09: [2024-10-30 14:45:09] iter = 06950, loss = 5.4702
2024-10-30 14:45:10: [2024-10-30 14:45:10] iter = 06960, loss = 28.4719
2024-10-30 14:45:13: [2024-10-30 14:45:13] iter = 06970, loss = 4.9129
2024-10-30 14:45:15: [2024-10-30 14:45:15] iter = 06980, loss = 4.1027
2024-10-30 14:45:17: [2024-10-30 14:45:17] iter = 06990, loss = 16.9790
2024-10-30 14:45:19: [2024-10-30 14:45:19] iter = 07000, loss = 11.4442
2024-10-30 14:45:21: [2024-10-30 14:45:21] iter = 07010, loss = 5.3924
2024-10-30 14:45:23: [2024-10-30 14:45:23] iter = 07020, loss = 32.9179
2024-10-30 14:45:25: [2024-10-30 14:45:25] iter = 07030, loss = 7.3046
2024-10-30 14:45:27: [2024-10-30 14:45:27] iter = 07040, loss = 6.2065
2024-10-30 14:45:28: [2024-10-30 14:45:28] iter = 07050, loss = 4.6581
2024-10-30 14:45:30: [2024-10-30 14:45:30] iter = 07060, loss = 62.1648
2024-10-30 14:45:32: [2024-10-30 14:45:32] iter = 07070, loss = 21.5589
2024-10-30 14:45:35: [2024-10-30 14:45:35] iter = 07080, loss = 4.3092
2024-10-30 14:45:36: [2024-10-30 14:45:36] iter = 07090, loss = 12.5525
2024-10-30 14:45:38: [2024-10-30 14:45:38] iter = 07100, loss = 5.8085
2024-10-30 14:45:40: [2024-10-30 14:45:40] iter = 07110, loss = 7.6007
2024-10-30 14:45:42: [2024-10-30 14:45:42] iter = 07120, loss = 4.5739
2024-10-30 14:45:45: [2024-10-30 14:45:44] iter = 07130, loss = 83.0358
2024-10-30 14:45:46: [2024-10-30 14:45:46] iter = 07140, loss = 4.8496
2024-10-30 14:45:48: [2024-10-30 14:45:48] iter = 07150, loss = 15.2440
2024-10-30 14:45:50: [2024-10-30 14:45:50] iter = 07160, loss = 6.3512
2024-10-30 14:45:51: [2024-10-30 14:45:51] iter = 07170, loss = 13.0641
2024-10-30 14:45:53: [2024-10-30 14:45:53] iter = 07180, loss = 9.6438
2024-10-30 14:45:56: [2024-10-30 14:45:56] iter = 07190, loss = 56.6426
2024-10-30 14:45:57: [2024-10-30 14:45:57] iter = 07200, loss = 5.5802
2024-10-30 14:45:59: [2024-10-30 14:45:59] iter = 07210, loss = 5.5667
2024-10-30 14:46:00: [2024-10-30 14:46:00] iter = 07220, loss = 8.8968
2024-10-30 14:46:02: [2024-10-30 14:46:02] iter = 07230, loss = 5.6408
2024-10-30 14:46:04: [2024-10-30 14:46:04] iter = 07240, loss = 27.7497
2024-10-30 14:46:06: [2024-10-30 14:46:06] iter = 07250, loss = 13.2012
2024-10-30 14:46:08: [2024-10-30 14:46:08] iter = 07260, loss = 76.4297
2024-10-30 14:46:10: [2024-10-30 14:46:10] iter = 07270, loss = 12.3739
2024-10-30 14:46:12: [2024-10-30 14:46:12] iter = 07280, loss = 9.8256
2024-10-30 14:46:15: [2024-10-30 14:46:15] iter = 07290, loss = 7.1582
2024-10-30 14:46:17: [2024-10-30 14:46:17] iter = 07300, loss = 28.2008
2024-10-30 14:46:20: [2024-10-30 14:46:20] iter = 07310, loss = 5.0224
2024-10-30 14:46:22: [2024-10-30 14:46:22] iter = 07320, loss = 28.9258
2024-10-30 14:46:24: [2024-10-30 14:46:24] iter = 07330, loss = 23.3639
2024-10-30 14:46:26: [2024-10-30 14:46:26] iter = 07340, loss = 5.6246
2024-10-30 14:46:28: [2024-10-30 14:46:28] iter = 07350, loss = 3.5669
2024-10-30 14:46:31: [2024-10-30 14:46:31] iter = 07360, loss = 5.6194
2024-10-30 14:46:34: [2024-10-30 14:46:34] iter = 07370, loss = 20.2816
2024-10-30 14:46:35: [2024-10-30 14:46:35] iter = 07380, loss = 28.8234
2024-10-30 14:46:37: [2024-10-30 14:46:37] iter = 07390, loss = 8.3438
2024-10-30 14:46:39: [2024-10-30 14:46:39] iter = 07400, loss = 87.4099
2024-10-30 14:46:41: [2024-10-30 14:46:41] iter = 07410, loss = 16.8522
2024-10-30 14:46:43: [2024-10-30 14:46:43] iter = 07420, loss = 21.7683
2024-10-30 14:46:44: [2024-10-30 14:46:44] iter = 07430, loss = 11.8979
2024-10-30 14:46:46: [2024-10-30 14:46:46] iter = 07440, loss = 5.1486
2024-10-30 14:46:48: [2024-10-30 14:46:48] iter = 07450, loss = 17.5446
2024-10-30 14:46:49: [2024-10-30 14:46:49] iter = 07460, loss = 5.7204
2024-10-30 14:46:52: [2024-10-30 14:46:52] iter = 07470, loss = 26.4585
2024-10-30 14:46:53: [2024-10-30 14:46:53] iter = 07480, loss = 10.2513
2024-10-30 14:46:55: [2024-10-30 14:46:55] iter = 07490, loss = 61.0375
2024-10-30 14:46:58: [2024-10-30 14:46:58] iter = 07500, loss = 51.1156
2024-10-30 14:47:00: [2024-10-30 14:47:00] iter = 07510, loss = 5.8851
2024-10-30 14:47:01: [2024-10-30 14:47:01] iter = 07520, loss = 43.7853
2024-10-30 14:47:04: [2024-10-30 14:47:04] iter = 07530, loss = 7.6406
2024-10-30 14:47:06: [2024-10-30 14:47:06] iter = 07540, loss = 14.4487
2024-10-30 14:47:08: [2024-10-30 14:47:08] iter = 07550, loss = 13.5774
2024-10-30 14:47:10: [2024-10-30 14:47:10] iter = 07560, loss = 4.3200
2024-10-30 14:47:12: [2024-10-30 14:47:12] iter = 07570, loss = 58.0127
2024-10-30 14:47:14: [2024-10-30 14:47:14] iter = 07580, loss = 15.5940
2024-10-30 14:47:16: [2024-10-30 14:47:16] iter = 07590, loss = 10.5083
2024-10-30 14:47:19: [2024-10-30 14:47:19] iter = 07600, loss = 23.9669
2024-10-30 14:47:21: [2024-10-30 14:47:21] iter = 07610, loss = 51.5262
2024-10-30 14:47:24: [2024-10-30 14:47:24] iter = 07620, loss = 14.1198
2024-10-30 14:47:26: [2024-10-30 14:47:26] iter = 07630, loss = 27.0246
2024-10-30 14:47:28: [2024-10-30 14:47:28] iter = 07640, loss = 45.8573
2024-10-30 14:47:29: [2024-10-30 14:47:29] iter = 07650, loss = 35.7034
2024-10-30 14:47:32: [2024-10-30 14:47:32] iter = 07660, loss = 26.0185
2024-10-30 14:47:34: [2024-10-30 14:47:34] iter = 07670, loss = 13.3281
2024-10-30 14:47:37: [2024-10-30 14:47:37] iter = 07680, loss = 40.7872
2024-10-30 14:47:39: [2024-10-30 14:47:39] iter = 07690, loss = 5.9175
2024-10-30 14:47:41: [2024-10-30 14:47:41] iter = 07700, loss = 19.5438
2024-10-30 14:47:43: [2024-10-30 14:47:43] iter = 07710, loss = 45.7278
2024-10-30 14:47:45: [2024-10-30 14:47:45] iter = 07720, loss = 10.4950
2024-10-30 14:47:47: [2024-10-30 14:47:47] iter = 07730, loss = 10.5874
2024-10-30 14:47:49: [2024-10-30 14:47:49] iter = 07740, loss = 3.1182
2024-10-30 14:47:51: [2024-10-30 14:47:51] iter = 07750, loss = 85.9515
2024-10-30 14:47:53: [2024-10-30 14:47:53] iter = 07760, loss = 4.4556
2024-10-30 14:47:55: [2024-10-30 14:47:55] iter = 07770, loss = 9.1056
2024-10-30 14:47:56: [2024-10-30 14:47:56] iter = 07780, loss = 16.9706
2024-10-30 14:47:57: [2024-10-30 14:47:57] iter = 07790, loss = 6.9131
2024-10-30 14:47:59: [2024-10-30 14:47:59] iter = 07800, loss = 13.5829
2024-10-30 14:48:01: [2024-10-30 14:48:01] iter = 07810, loss = 32.7963
2024-10-30 14:48:03: [2024-10-30 14:48:03] iter = 07820, loss = 4.1722
2024-10-30 14:48:05: [2024-10-30 14:48:05] iter = 07830, loss = 4.1816
2024-10-30 14:48:07: [2024-10-30 14:48:07] iter = 07840, loss = 75.7199
2024-10-30 14:48:09: [2024-10-30 14:48:09] iter = 07850, loss = 27.5406
2024-10-30 14:48:11: [2024-10-30 14:48:11] iter = 07860, loss = 36.0352
2024-10-30 14:48:13: [2024-10-30 14:48:13] iter = 07870, loss = 20.9458
2024-10-30 14:48:16: [2024-10-30 14:48:16] iter = 07880, loss = 8.3111
2024-10-30 14:48:18: [2024-10-30 14:48:18] iter = 07890, loss = 28.7191
2024-10-30 14:48:20: [2024-10-30 14:48:20] iter = 07900, loss = 17.5081
2024-10-30 14:48:22: [2024-10-30 14:48:22] iter = 07910, loss = 4.4649
2024-10-30 14:48:24: [2024-10-30 14:48:24] iter = 07920, loss = 22.9668
2024-10-30 14:48:26: [2024-10-30 14:48:26] iter = 07930, loss = 10.4624
2024-10-30 14:48:28: [2024-10-30 14:48:28] iter = 07940, loss = 17.5089
2024-10-30 14:48:30: [2024-10-30 14:48:30] iter = 07950, loss = 38.2783
2024-10-30 14:48:32: [2024-10-30 14:48:32] iter = 07960, loss = 4.7054
2024-10-30 14:48:34: [2024-10-30 14:48:34] iter = 07970, loss = 13.5744
2024-10-30 14:48:37: [2024-10-30 14:48:37] iter = 07980, loss = 34.2103
2024-10-30 14:48:39: [2024-10-30 14:48:39] iter = 07990, loss = 27.9522
2024-10-30 14:48:41: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 14:48:41: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:48:41: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 21400}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:50:09: Evaluate 5 random ConvNet, ACCmean = 0.3490 ACCstd = 0.0041
-------------------------
2024-10-30 14:50:09: Evaluate 5 random ConvNet, SENmean = 0.3167 SENstd = 0.0030
-------------------------
2024-10-30 14:50:09: Evaluate 5 random ConvNet, SPEmean = 0.9079 SPEstd = 0.0003
-------------------------
2024-10-30 14:50:09: Evaluate 5 random ConvNet, F!mean = 0.2705 F!std = 0.0036
-------------------------
2024-10-30 14:50:09: Evaluate 5 random ConvNet, mean = 0.3490 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 14:50:09: [2024-10-30 14:50:09] iter = 08000, loss = 10.8946
2024-10-30 14:50:12: [2024-10-30 14:50:12] iter = 08010, loss = 7.6320
2024-10-30 14:50:15: [2024-10-30 14:50:15] iter = 08020, loss = 18.1883
2024-10-30 14:50:17: [2024-10-30 14:50:17] iter = 08030, loss = 29.1195
2024-10-30 14:50:20: [2024-10-30 14:50:20] iter = 08040, loss = 16.3589
2024-10-30 14:50:23: [2024-10-30 14:50:23] iter = 08050, loss = 9.0839
2024-10-30 14:50:26: [2024-10-30 14:50:26] iter = 08060, loss = 4.5583
2024-10-30 14:50:29: [2024-10-30 14:50:29] iter = 08070, loss = 10.5146
2024-10-30 14:50:32: [2024-10-30 14:50:32] iter = 08080, loss = 50.1141
2024-10-30 14:50:35: [2024-10-30 14:50:35] iter = 08090, loss = 4.6001
2024-10-30 14:50:38: [2024-10-30 14:50:38] iter = 08100, loss = 11.0171
2024-10-30 14:50:40: [2024-10-30 14:50:40] iter = 08110, loss = 11.2577
2024-10-30 14:50:41: [2024-10-30 14:50:41] iter = 08120, loss = 12.0288
2024-10-30 14:50:43: [2024-10-30 14:50:43] iter = 08130, loss = 6.3200
2024-10-30 14:50:45: [2024-10-30 14:50:45] iter = 08140, loss = 13.9006
2024-10-30 14:50:46: [2024-10-30 14:50:46] iter = 08150, loss = 20.2197
2024-10-30 14:50:48: [2024-10-30 14:50:48] iter = 08160, loss = 12.9010
2024-10-30 14:50:51: [2024-10-30 14:50:51] iter = 08170, loss = 22.9770
2024-10-30 14:50:53: [2024-10-30 14:50:53] iter = 08180, loss = 44.9830
2024-10-30 14:50:55: [2024-10-30 14:50:55] iter = 08190, loss = 6.9098
2024-10-30 14:50:57: [2024-10-30 14:50:57] iter = 08200, loss = 5.4592
2024-10-30 14:51:00: [2024-10-30 14:51:00] iter = 08210, loss = 7.8207
2024-10-30 14:51:02: [2024-10-30 14:51:02] iter = 08220, loss = 14.4817
2024-10-30 14:51:05: [2024-10-30 14:51:05] iter = 08230, loss = 9.3718
2024-10-30 14:51:08: [2024-10-30 14:51:08] iter = 08240, loss = 39.5575
2024-10-30 14:51:10: [2024-10-30 14:51:10] iter = 08250, loss = 35.3885
2024-10-30 14:51:13: [2024-10-30 14:51:13] iter = 08260, loss = 12.7709
2024-10-30 14:51:15: [2024-10-30 14:51:15] iter = 08270, loss = 37.8465
2024-10-30 14:51:17: [2024-10-30 14:51:17] iter = 08280, loss = 28.7139
2024-10-30 14:51:21: [2024-10-30 14:51:21] iter = 08290, loss = 4.5618
2024-10-30 14:51:24: [2024-10-30 14:51:24] iter = 08300, loss = 81.6123
2024-10-30 14:51:25: [2024-10-30 14:51:25] iter = 08310, loss = 27.8060
2024-10-30 14:51:27: [2024-10-30 14:51:27] iter = 08320, loss = 60.6776
2024-10-30 14:51:29: [2024-10-30 14:51:29] iter = 08330, loss = 12.7730
2024-10-30 14:51:30: [2024-10-30 14:51:30] iter = 08340, loss = 4.8835
2024-10-30 14:51:33: [2024-10-30 14:51:33] iter = 08350, loss = 4.3713
2024-10-30 14:51:35: [2024-10-30 14:51:35] iter = 08360, loss = 17.3184
2024-10-30 14:51:37: [2024-10-30 14:51:37] iter = 08370, loss = 71.3330
2024-10-30 14:51:40: [2024-10-30 14:51:40] iter = 08380, loss = 22.6214
2024-10-30 14:51:44: [2024-10-30 14:51:44] iter = 08390, loss = 20.4795
2024-10-30 14:51:46: [2024-10-30 14:51:46] iter = 08400, loss = 34.7166
2024-10-30 14:51:49: [2024-10-30 14:51:49] iter = 08410, loss = 19.8188
2024-10-30 14:51:51: [2024-10-30 14:51:51] iter = 08420, loss = 38.8878
2024-10-30 14:51:54: [2024-10-30 14:51:54] iter = 08430, loss = 10.8338
2024-10-30 14:51:57: [2024-10-30 14:51:57] iter = 08440, loss = 16.1473
2024-10-30 14:52:00: [2024-10-30 14:52:00] iter = 08450, loss = 5.3497
2024-10-30 14:52:03: [2024-10-30 14:52:03] iter = 08460, loss = 7.2207
2024-10-30 14:52:06: [2024-10-30 14:52:06] iter = 08470, loss = 33.3691
2024-10-30 14:52:09: [2024-10-30 14:52:09] iter = 08480, loss = 11.2591
2024-10-30 14:52:13: [2024-10-30 14:52:12] iter = 08490, loss = 3.8832
2024-10-30 14:52:15: [2024-10-30 14:52:15] iter = 08500, loss = 34.9685
2024-10-30 14:52:19: [2024-10-30 14:52:19] iter = 08510, loss = 3.5221
2024-10-30 14:52:22: [2024-10-30 14:52:22] iter = 08520, loss = 6.0246
2024-10-30 14:52:25: [2024-10-30 14:52:25] iter = 08530, loss = 41.1115
2024-10-30 14:52:28: [2024-10-30 14:52:28] iter = 08540, loss = 49.3580
2024-10-30 14:52:31: [2024-10-30 14:52:31] iter = 08550, loss = 49.0948
2024-10-30 14:52:33: [2024-10-30 14:52:33] iter = 08560, loss = 38.4372
2024-10-30 14:52:35: [2024-10-30 14:52:35] iter = 08570, loss = 53.0117
2024-10-30 14:52:37: [2024-10-30 14:52:37] iter = 08580, loss = 3.7898
2024-10-30 14:52:39: [2024-10-30 14:52:39] iter = 08590, loss = 34.8445
2024-10-30 14:52:42: [2024-10-30 14:52:42] iter = 08600, loss = 22.2147
2024-10-30 14:52:45: [2024-10-30 14:52:45] iter = 08610, loss = 3.7115
2024-10-30 14:52:48: [2024-10-30 14:52:48] iter = 08620, loss = 5.4250
2024-10-30 14:52:51: [2024-10-30 14:52:51] iter = 08630, loss = 14.9172
2024-10-30 14:52:54: [2024-10-30 14:52:54] iter = 08640, loss = 16.2274
2024-10-30 14:52:57: [2024-10-30 14:52:57] iter = 08650, loss = 23.2637
2024-10-30 14:52:59: [2024-10-30 14:52:59] iter = 08660, loss = 51.5429
2024-10-30 14:53:01: [2024-10-30 14:53:01] iter = 08670, loss = 45.4196
2024-10-30 14:53:04: [2024-10-30 14:53:04] iter = 08680, loss = 4.9170
2024-10-30 14:53:06: [2024-10-30 14:53:06] iter = 08690, loss = 6.1938
2024-10-30 14:53:09: [2024-10-30 14:53:09] iter = 08700, loss = 5.9517
2024-10-30 14:53:12: [2024-10-30 14:53:12] iter = 08710, loss = 8.0411
2024-10-30 14:53:14: [2024-10-30 14:53:14] iter = 08720, loss = 12.9261
2024-10-30 14:53:16: [2024-10-30 14:53:16] iter = 08730, loss = 23.6768
2024-10-30 14:53:19: [2024-10-30 14:53:19] iter = 08740, loss = 23.9409
2024-10-30 14:53:21: [2024-10-30 14:53:21] iter = 08750, loss = 4.9126
2024-10-30 14:53:24: [2024-10-30 14:53:24] iter = 08760, loss = 31.7656
2024-10-30 14:53:26: [2024-10-30 14:53:26] iter = 08770, loss = 4.5719
2024-10-30 14:53:28: [2024-10-30 14:53:28] iter = 08780, loss = 20.0454
2024-10-30 14:53:31: [2024-10-30 14:53:31] iter = 08790, loss = 14.3892
2024-10-30 14:53:33: [2024-10-30 14:53:33] iter = 08800, loss = 19.2806
2024-10-30 14:53:36: [2024-10-30 14:53:36] iter = 08810, loss = 28.7836
2024-10-30 14:53:39: [2024-10-30 14:53:39] iter = 08820, loss = 12.6541
2024-10-30 14:53:41: [2024-10-30 14:53:41] iter = 08830, loss = 8.1867
2024-10-30 14:53:42: [2024-10-30 14:53:42] iter = 08840, loss = 4.4965
2024-10-30 14:53:45: [2024-10-30 14:53:45] iter = 08850, loss = 6.7795
2024-10-30 14:53:48: [2024-10-30 14:53:48] iter = 08860, loss = 8.8145
2024-10-30 14:53:50: [2024-10-30 14:53:50] iter = 08870, loss = 5.4071
2024-10-30 14:53:53: [2024-10-30 14:53:53] iter = 08880, loss = 4.0969
2024-10-30 14:53:55: [2024-10-30 14:53:55] iter = 08890, loss = 13.0121
2024-10-30 14:53:58: [2024-10-30 14:53:58] iter = 08900, loss = 3.5869
2024-10-30 14:54:00: [2024-10-30 14:54:00] iter = 08910, loss = 5.3066
2024-10-30 14:54:02: [2024-10-30 14:54:02] iter = 08920, loss = 4.6793
2024-10-30 14:54:04: [2024-10-30 14:54:04] iter = 08930, loss = 7.7113
2024-10-30 14:54:06: [2024-10-30 14:54:06] iter = 08940, loss = 19.6311
2024-10-30 14:54:08: [2024-10-30 14:54:08] iter = 08950, loss = 53.3672
2024-10-30 14:54:11: [2024-10-30 14:54:11] iter = 08960, loss = 7.0794
2024-10-30 14:54:13: [2024-10-30 14:54:13] iter = 08970, loss = 4.1570
2024-10-30 14:54:15: [2024-10-30 14:54:15] iter = 08980, loss = 8.2618
2024-10-30 14:54:19: [2024-10-30 14:54:19] iter = 08990, loss = 39.3424
2024-10-30 14:54:21: [2024-10-30 14:54:21] iter = 09000, loss = 21.1419
2024-10-30 14:54:24: [2024-10-30 14:54:24] iter = 09010, loss = 4.6124
2024-10-30 14:54:27: [2024-10-30 14:54:27] iter = 09020, loss = 3.4006
2024-10-30 14:54:30: [2024-10-30 14:54:30] iter = 09030, loss = 6.0455
2024-10-30 14:54:32: [2024-10-30 14:54:32] iter = 09040, loss = 29.9117
2024-10-30 14:54:34: [2024-10-30 14:54:34] iter = 09050, loss = 46.2343
2024-10-30 14:54:36: [2024-10-30 14:54:36] iter = 09060, loss = 10.1676
2024-10-30 14:54:39: [2024-10-30 14:54:39] iter = 09070, loss = 15.6237
2024-10-30 14:54:41: [2024-10-30 14:54:41] iter = 09080, loss = 3.7018
2024-10-30 14:54:44: [2024-10-30 14:54:44] iter = 09090, loss = 6.3946
2024-10-30 14:54:46: [2024-10-30 14:54:46] iter = 09100, loss = 4.1541
2024-10-30 14:54:48: [2024-10-30 14:54:48] iter = 09110, loss = 22.7537
2024-10-30 14:54:49: [2024-10-30 14:54:49] iter = 09120, loss = 7.9390
2024-10-30 14:54:51: [2024-10-30 14:54:51] iter = 09130, loss = 34.2782
2024-10-30 14:54:53: [2024-10-30 14:54:53] iter = 09140, loss = 13.6792
2024-10-30 14:54:56: [2024-10-30 14:54:56] iter = 09150, loss = 9.2500
2024-10-30 14:54:58: [2024-10-30 14:54:58] iter = 09160, loss = 54.2489
2024-10-30 14:55:01: [2024-10-30 14:55:01] iter = 09170, loss = 131.8973
2024-10-30 14:55:03: [2024-10-30 14:55:03] iter = 09180, loss = 6.6068
2024-10-30 14:55:06: [2024-10-30 14:55:06] iter = 09190, loss = 42.7338
2024-10-30 14:55:08: [2024-10-30 14:55:08] iter = 09200, loss = 46.9260
2024-10-30 14:55:11: [2024-10-30 14:55:11] iter = 09210, loss = 5.6453
2024-10-30 14:55:14: [2024-10-30 14:55:14] iter = 09220, loss = 18.5302
2024-10-30 14:55:16: [2024-10-30 14:55:16] iter = 09230, loss = 5.2939
2024-10-30 14:55:19: [2024-10-30 14:55:18] iter = 09240, loss = 6.5613
2024-10-30 14:55:20: [2024-10-30 14:55:20] iter = 09250, loss = 12.9448
2024-10-30 14:55:23: [2024-10-30 14:55:23] iter = 09260, loss = 23.7390
2024-10-30 14:55:25: [2024-10-30 14:55:25] iter = 09270, loss = 5.4349
2024-10-30 14:55:28: [2024-10-30 14:55:28] iter = 09280, loss = 29.3750
2024-10-30 14:55:30: [2024-10-30 14:55:30] iter = 09290, loss = 6.5997
2024-10-30 14:55:33: [2024-10-30 14:55:33] iter = 09300, loss = 4.3370
2024-10-30 14:55:35: [2024-10-30 14:55:35] iter = 09310, loss = 3.3934
2024-10-30 14:55:37: [2024-10-30 14:55:37] iter = 09320, loss = 6.5639
2024-10-30 14:55:39: [2024-10-30 14:55:39] iter = 09330, loss = 19.8547
2024-10-30 14:55:41: [2024-10-30 14:55:41] iter = 09340, loss = 42.1757
2024-10-30 14:55:44: [2024-10-30 14:55:44] iter = 09350, loss = 8.3833
2024-10-30 14:55:46: [2024-10-30 14:55:46] iter = 09360, loss = 5.3914
2024-10-30 14:55:48: [2024-10-30 14:55:48] iter = 09370, loss = 34.0805
2024-10-30 14:55:51: [2024-10-30 14:55:51] iter = 09380, loss = 64.3375
2024-10-30 14:55:54: [2024-10-30 14:55:54] iter = 09390, loss = 17.3842
2024-10-30 14:55:56: [2024-10-30 14:55:56] iter = 09400, loss = 30.0628
2024-10-30 14:55:59: [2024-10-30 14:55:59] iter = 09410, loss = 12.8617
2024-10-30 14:56:01: [2024-10-30 14:56:01] iter = 09420, loss = 46.1310
2024-10-30 14:56:03: [2024-10-30 14:56:03] iter = 09430, loss = 9.4372
2024-10-30 14:56:05: [2024-10-30 14:56:05] iter = 09440, loss = 13.6302
2024-10-30 14:56:07: [2024-10-30 14:56:07] iter = 09450, loss = 3.5988
2024-10-30 14:56:10: [2024-10-30 14:56:10] iter = 09460, loss = 5.2878
2024-10-30 14:56:12: [2024-10-30 14:56:12] iter = 09470, loss = 48.5333
2024-10-30 14:56:14: [2024-10-30 14:56:14] iter = 09480, loss = 5.9347
2024-10-30 14:56:16: [2024-10-30 14:56:16] iter = 09490, loss = 11.6034
2024-10-30 14:56:18: [2024-10-30 14:56:18] iter = 09500, loss = 90.4845
2024-10-30 14:56:21: [2024-10-30 14:56:21] iter = 09510, loss = 6.0797
2024-10-30 14:56:24: [2024-10-30 14:56:24] iter = 09520, loss = 3.8512
2024-10-30 14:56:26: [2024-10-30 14:56:26] iter = 09530, loss = 4.3339
2024-10-30 14:56:29: [2024-10-30 14:56:29] iter = 09540, loss = 21.6827
2024-10-30 14:56:32: [2024-10-30 14:56:32] iter = 09550, loss = 7.3099
2024-10-30 14:56:34: [2024-10-30 14:56:34] iter = 09560, loss = 28.0456
2024-10-30 14:56:36: [2024-10-30 14:56:36] iter = 09570, loss = 6.4315
2024-10-30 14:56:38: [2024-10-30 14:56:38] iter = 09580, loss = 37.2660
2024-10-30 14:56:40: [2024-10-30 14:56:40] iter = 09590, loss = 22.1765
2024-10-30 14:56:42: [2024-10-30 14:56:42] iter = 09600, loss = 19.0590
2024-10-30 14:56:44: [2024-10-30 14:56:44] iter = 09610, loss = 39.7349
2024-10-30 14:56:47: [2024-10-30 14:56:47] iter = 09620, loss = 35.3607
2024-10-30 14:56:50: [2024-10-30 14:56:50] iter = 09630, loss = 47.2480
2024-10-30 14:56:53: [2024-10-30 14:56:53] iter = 09640, loss = 10.3344
2024-10-30 14:56:57: [2024-10-30 14:56:57] iter = 09650, loss = 6.9927
2024-10-30 14:57:00: [2024-10-30 14:57:00] iter = 09660, loss = 5.8671
2024-10-30 14:57:03: [2024-10-30 14:57:03] iter = 09670, loss = 35.5550
2024-10-30 14:57:07: [2024-10-30 14:57:07] iter = 09680, loss = 17.3536
2024-10-30 14:57:10: [2024-10-30 14:57:10] iter = 09690, loss = 11.9735
2024-10-30 14:57:13: [2024-10-30 14:57:13] iter = 09700, loss = 14.4800
2024-10-30 14:57:18: [2024-10-30 14:57:18] iter = 09710, loss = 9.0903
2024-10-30 14:57:21: [2024-10-30 14:57:21] iter = 09720, loss = 16.2474
2024-10-30 14:57:25: [2024-10-30 14:57:25] iter = 09730, loss = 27.3317
2024-10-30 14:57:29: [2024-10-30 14:57:29] iter = 09740, loss = 17.9344
2024-10-30 14:57:33: [2024-10-30 14:57:33] iter = 09750, loss = 30.5483
2024-10-30 14:57:38: [2024-10-30 14:57:38] iter = 09760, loss = 119.6266
2024-10-30 14:57:42: [2024-10-30 14:57:42] iter = 09770, loss = 15.1368
2024-10-30 14:57:46: [2024-10-30 14:57:46] iter = 09780, loss = 40.9474
2024-10-30 14:57:51: [2024-10-30 14:57:51] iter = 09790, loss = 5.5708
2024-10-30 14:57:56: [2024-10-30 14:57:56] iter = 09800, loss = 7.1919
2024-10-30 14:58:01: [2024-10-30 14:58:01] iter = 09810, loss = 35.3087
2024-10-30 14:58:05: [2024-10-30 14:58:05] iter = 09820, loss = 13.0384
2024-10-30 14:58:09: [2024-10-30 14:58:09] iter = 09830, loss = 11.1482
2024-10-30 14:58:14: [2024-10-30 14:58:14] iter = 09840, loss = 5.5794
2024-10-30 14:58:18: [2024-10-30 14:58:18] iter = 09850, loss = 5.3174
2024-10-30 14:58:21: [2024-10-30 14:58:21] iter = 09860, loss = 32.5167
2024-10-30 14:58:26: [2024-10-30 14:58:26] iter = 09870, loss = 29.8292
2024-10-30 14:58:30: [2024-10-30 14:58:30] iter = 09880, loss = 51.7198
2024-10-30 14:58:34: [2024-10-30 14:58:34] iter = 09890, loss = 55.3921
2024-10-30 14:58:38: [2024-10-30 14:58:38] iter = 09900, loss = 19.8465
2024-10-30 14:58:44: [2024-10-30 14:58:44] iter = 09910, loss = 17.6776
2024-10-30 14:58:48: [2024-10-30 14:58:48] iter = 09920, loss = 38.3007
2024-10-30 14:58:52: [2024-10-30 14:58:52] iter = 09930, loss = 36.3703
2024-10-30 14:58:55: [2024-10-30 14:58:55] iter = 09940, loss = 4.4999
2024-10-30 14:58:59: [2024-10-30 14:58:59] iter = 09950, loss = 4.8921
2024-10-30 14:59:04: [2024-10-30 14:59:04] iter = 09960, loss = 7.5993
2024-10-30 14:59:08: [2024-10-30 14:59:08] iter = 09970, loss = 19.1132
2024-10-30 14:59:13: [2024-10-30 14:59:13] iter = 09980, loss = 15.7597
2024-10-30 14:59:17: [2024-10-30 14:59:17] iter = 09990, loss = 16.3573
2024-10-30 14:59:20: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 14:59:20: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 14:59:20: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60703}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:01:59: Evaluate 5 random ConvNet, ACCmean = 0.3790 ACCstd = 0.0051
-------------------------
2024-10-30 15:01:59: Evaluate 5 random ConvNet, SENmean = 0.2975 SENstd = 0.0012
-------------------------
2024-10-30 15:01:59: Evaluate 5 random ConvNet, SPEmean = 0.9093 SPEstd = 0.0004
-------------------------
2024-10-30 15:01:59: Evaluate 5 random ConvNet, F!mean = 0.2682 F!std = 0.0020
-------------------------
2024-10-30 15:01:59: Evaluate 5 random ConvNet, mean = 0.3790 std = 0.0051
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:01:59: [2024-10-30 15:01:59] iter = 10000, loss = 25.6503
2024-10-30 15:02:03: [2024-10-30 15:02:03] iter = 10010, loss = 6.9038
2024-10-30 15:02:08: [2024-10-30 15:02:08] iter = 10020, loss = 16.7364
2024-10-30 15:02:13: [2024-10-30 15:02:13] iter = 10030, loss = 43.8857
2024-10-30 15:02:18: [2024-10-30 15:02:18] iter = 10040, loss = 3.4308
2024-10-30 15:02:21: [2024-10-30 15:02:21] iter = 10050, loss = 11.0973
2024-10-30 15:02:24: [2024-10-30 15:02:24] iter = 10060, loss = 5.0144
2024-10-30 15:02:29: [2024-10-30 15:02:29] iter = 10070, loss = 9.6505
2024-10-30 15:02:33: [2024-10-30 15:02:33] iter = 10080, loss = 41.3686
2024-10-30 15:02:38: [2024-10-30 15:02:38] iter = 10090, loss = 14.0954
2024-10-30 15:02:43: [2024-10-30 15:02:43] iter = 10100, loss = 11.9458
2024-10-30 15:02:47: [2024-10-30 15:02:47] iter = 10110, loss = 5.0765
2024-10-30 15:02:51: [2024-10-30 15:02:51] iter = 10120, loss = 5.2309
2024-10-30 15:02:56: [2024-10-30 15:02:56] iter = 10130, loss = 4.8090
2024-10-30 15:03:01: [2024-10-30 15:03:01] iter = 10140, loss = 4.9996
2024-10-30 15:03:06: [2024-10-30 15:03:06] iter = 10150, loss = 8.5860
2024-10-30 15:03:11: [2024-10-30 15:03:11] iter = 10160, loss = 11.3599
2024-10-30 15:03:16: [2024-10-30 15:03:16] iter = 10170, loss = 4.0872
2024-10-30 15:03:19: [2024-10-30 15:03:19] iter = 10180, loss = 29.6706
2024-10-30 15:03:24: [2024-10-30 15:03:24] iter = 10190, loss = 10.6816
2024-10-30 15:03:29: [2024-10-30 15:03:29] iter = 10200, loss = 5.4188
2024-10-30 15:03:33: [2024-10-30 15:03:33] iter = 10210, loss = 21.5902
2024-10-30 15:03:38: [2024-10-30 15:03:38] iter = 10220, loss = 3.7951
2024-10-30 15:03:41: [2024-10-30 15:03:41] iter = 10230, loss = 4.5286
2024-10-30 15:03:45: [2024-10-30 15:03:45] iter = 10240, loss = 31.8984
2024-10-30 15:03:49: [2024-10-30 15:03:49] iter = 10250, loss = 5.2811
2024-10-30 15:03:53: [2024-10-30 15:03:53] iter = 10260, loss = 33.4994
2024-10-30 15:03:57: [2024-10-30 15:03:57] iter = 10270, loss = 4.2028
2024-10-30 15:04:00: [2024-10-30 15:04:00] iter = 10280, loss = 11.9411
2024-10-30 15:04:04: [2024-10-30 15:04:04] iter = 10290, loss = 3.9799
2024-10-30 15:04:08: [2024-10-30 15:04:08] iter = 10300, loss = 6.8070
2024-10-30 15:04:12: [2024-10-30 15:04:12] iter = 10310, loss = 37.4496
2024-10-30 15:04:15: [2024-10-30 15:04:15] iter = 10320, loss = 17.5820
2024-10-30 15:04:19: [2024-10-30 15:04:19] iter = 10330, loss = 7.3175
2024-10-30 15:04:24: [2024-10-30 15:04:24] iter = 10340, loss = 52.3818
2024-10-30 15:04:28: [2024-10-30 15:04:28] iter = 10350, loss = 12.1267
2024-10-30 15:04:32: [2024-10-30 15:04:32] iter = 10360, loss = 17.9675
2024-10-30 15:04:38: [2024-10-30 15:04:38] iter = 10370, loss = 20.7659
2024-10-30 15:04:42: [2024-10-30 15:04:42] iter = 10380, loss = 7.3378
2024-10-30 15:04:46: [2024-10-30 15:04:46] iter = 10390, loss = 41.2946
2024-10-30 15:04:50: [2024-10-30 15:04:50] iter = 10400, loss = 4.7265
2024-10-30 15:04:55: [2024-10-30 15:04:55] iter = 10410, loss = 3.6811
2024-10-30 15:04:59: [2024-10-30 15:04:59] iter = 10420, loss = 6.2160
2024-10-30 15:05:04: [2024-10-30 15:05:04] iter = 10430, loss = 6.4839
2024-10-30 15:05:08: [2024-10-30 15:05:08] iter = 10440, loss = 13.8178
2024-10-30 15:05:12: [2024-10-30 15:05:12] iter = 10450, loss = 4.5286
2024-10-30 15:05:15: [2024-10-30 15:05:15] iter = 10460, loss = 4.1619
2024-10-30 15:05:19: [2024-10-30 15:05:19] iter = 10470, loss = 3.5803
2024-10-30 15:05:23: [2024-10-30 15:05:23] iter = 10480, loss = 4.3721
2024-10-30 15:05:28: [2024-10-30 15:05:28] iter = 10490, loss = 58.4547
2024-10-30 15:05:32: [2024-10-30 15:05:32] iter = 10500, loss = 4.7361
2024-10-30 15:05:36: [2024-10-30 15:05:36] iter = 10510, loss = 5.6361
2024-10-30 15:05:39: [2024-10-30 15:05:39] iter = 10520, loss = 16.6560
2024-10-30 15:05:43: [2024-10-30 15:05:43] iter = 10530, loss = 4.8239
2024-10-30 15:05:47: [2024-10-30 15:05:47] iter = 10540, loss = 3.9718
2024-10-30 15:05:50: [2024-10-30 15:05:50] iter = 10550, loss = 20.8741
2024-10-30 15:05:53: [2024-10-30 15:05:53] iter = 10560, loss = 8.5752
2024-10-30 15:05:57: [2024-10-30 15:05:57] iter = 10570, loss = 14.1978
2024-10-30 15:06:00: [2024-10-30 15:06:00] iter = 10580, loss = 67.7670
2024-10-30 15:06:03: [2024-10-30 15:06:03] iter = 10590, loss = 7.4679
2024-10-30 15:06:07: [2024-10-30 15:06:07] iter = 10600, loss = 8.0355
2024-10-30 15:06:11: [2024-10-30 15:06:11] iter = 10610, loss = 4.4128
2024-10-30 15:06:16: [2024-10-30 15:06:16] iter = 10620, loss = 18.3777
2024-10-30 15:06:20: [2024-10-30 15:06:20] iter = 10630, loss = 25.1200
2024-10-30 15:06:24: [2024-10-30 15:06:24] iter = 10640, loss = 33.8434
2024-10-30 15:06:28: [2024-10-30 15:06:28] iter = 10650, loss = 31.4711
2024-10-30 15:06:32: [2024-10-30 15:06:32] iter = 10660, loss = 27.2209
2024-10-30 15:06:36: [2024-10-30 15:06:36] iter = 10670, loss = 4.2311
2024-10-30 15:06:40: [2024-10-30 15:06:40] iter = 10680, loss = 56.0133
2024-10-30 15:06:44: [2024-10-30 15:06:44] iter = 10690, loss = 82.2826
2024-10-30 15:06:47: [2024-10-30 15:06:47] iter = 10700, loss = 28.7665
2024-10-30 15:06:51: [2024-10-30 15:06:51] iter = 10710, loss = 12.5041
2024-10-30 15:06:56: [2024-10-30 15:06:56] iter = 10720, loss = 5.9198
2024-10-30 15:06:59: [2024-10-30 15:06:59] iter = 10730, loss = 20.9617
2024-10-30 15:07:02: [2024-10-30 15:07:02] iter = 10740, loss = 14.9482
2024-10-30 15:07:06: [2024-10-30 15:07:06] iter = 10750, loss = 11.7321
2024-10-30 15:07:10: [2024-10-30 15:07:10] iter = 10760, loss = 18.6340
2024-10-30 15:07:14: [2024-10-30 15:07:14] iter = 10770, loss = 32.9474
2024-10-30 15:07:18: [2024-10-30 15:07:18] iter = 10780, loss = 5.8742
2024-10-30 15:07:22: [2024-10-30 15:07:22] iter = 10790, loss = 15.6557
2024-10-30 15:07:26: [2024-10-30 15:07:26] iter = 10800, loss = 93.9364
2024-10-30 15:07:29: [2024-10-30 15:07:29] iter = 10810, loss = 47.2366
2024-10-30 15:07:33: [2024-10-30 15:07:33] iter = 10820, loss = 39.1764
2024-10-30 15:07:37: [2024-10-30 15:07:37] iter = 10830, loss = 14.5334
2024-10-30 15:07:40: [2024-10-30 15:07:40] iter = 10840, loss = 40.6377
2024-10-30 15:07:43: [2024-10-30 15:07:43] iter = 10850, loss = 32.6377
2024-10-30 15:07:47: [2024-10-30 15:07:47] iter = 10860, loss = 11.7002
2024-10-30 15:07:51: [2024-10-30 15:07:51] iter = 10870, loss = 31.5002
2024-10-30 15:07:55: [2024-10-30 15:07:55] iter = 10880, loss = 38.8684
2024-10-30 15:07:58: [2024-10-30 15:07:58] iter = 10890, loss = 5.0436
2024-10-30 15:08:02: [2024-10-30 15:08:02] iter = 10900, loss = 15.7141
2024-10-30 15:08:06: [2024-10-30 15:08:06] iter = 10910, loss = 41.6035
2024-10-30 15:08:09: [2024-10-30 15:08:09] iter = 10920, loss = 10.6889
2024-10-30 15:08:13: [2024-10-30 15:08:13] iter = 10930, loss = 25.7331
2024-10-30 15:08:16: [2024-10-30 15:08:16] iter = 10940, loss = 15.5145
2024-10-30 15:08:20: [2024-10-30 15:08:20] iter = 10950, loss = 14.5797
2024-10-30 15:08:23: [2024-10-30 15:08:23] iter = 10960, loss = 5.2830
2024-10-30 15:08:27: [2024-10-30 15:08:27] iter = 10970, loss = 8.3025
2024-10-30 15:08:31: [2024-10-30 15:08:31] iter = 10980, loss = 5.2233
2024-10-30 15:08:33: [2024-10-30 15:08:33] iter = 10990, loss = 4.4190
2024-10-30 15:08:36: [2024-10-30 15:08:36] iter = 11000, loss = 31.8803
2024-10-30 15:08:39: [2024-10-30 15:08:39] iter = 11010, loss = 21.2212
2024-10-30 15:08:43: [2024-10-30 15:08:43] iter = 11020, loss = 16.7219
2024-10-30 15:08:47: [2024-10-30 15:08:47] iter = 11030, loss = 13.9884
2024-10-30 15:08:51: [2024-10-30 15:08:51] iter = 11040, loss = 28.1542
2024-10-30 15:08:56: [2024-10-30 15:08:56] iter = 11050, loss = 5.3693
2024-10-30 15:08:58: [2024-10-30 15:08:58] iter = 11060, loss = 7.6550
2024-10-30 15:09:01: [2024-10-30 15:09:01] iter = 11070, loss = 8.3967
2024-10-30 15:09:05: [2024-10-30 15:09:05] iter = 11080, loss = 18.9042
2024-10-30 15:09:08: [2024-10-30 15:09:08] iter = 11090, loss = 10.4672
2024-10-30 15:09:12: [2024-10-30 15:09:12] iter = 11100, loss = 43.6547
2024-10-30 15:09:16: [2024-10-30 15:09:16] iter = 11110, loss = 43.5581
2024-10-30 15:09:20: [2024-10-30 15:09:20] iter = 11120, loss = 4.6316
2024-10-30 15:09:25: [2024-10-30 15:09:24] iter = 11130, loss = 100.4744
2024-10-30 15:09:28: [2024-10-30 15:09:28] iter = 11140, loss = 27.4149
2024-10-30 15:09:32: [2024-10-30 15:09:32] iter = 11150, loss = 47.2690
2024-10-30 15:09:36: [2024-10-30 15:09:36] iter = 11160, loss = 13.2113
2024-10-30 15:09:41: [2024-10-30 15:09:41] iter = 11170, loss = 4.7210
2024-10-30 15:09:45: [2024-10-30 15:09:45] iter = 11180, loss = 7.4892
2024-10-30 15:09:49: [2024-10-30 15:09:49] iter = 11190, loss = 4.6873
2024-10-30 15:09:54: [2024-10-30 15:09:54] iter = 11200, loss = 5.6517
2024-10-30 15:09:58: [2024-10-30 15:09:58] iter = 11210, loss = 4.8692
2024-10-30 15:10:01: [2024-10-30 15:10:01] iter = 11220, loss = 8.6583
2024-10-30 15:10:05: [2024-10-30 15:10:05] iter = 11230, loss = 14.6984
2024-10-30 15:10:08: [2024-10-30 15:10:08] iter = 11240, loss = 37.3482
2024-10-30 15:10:11: [2024-10-30 15:10:11] iter = 11250, loss = 10.7111
2024-10-30 15:10:14: [2024-10-30 15:10:14] iter = 11260, loss = 33.0538
2024-10-30 15:10:18: [2024-10-30 15:10:18] iter = 11270, loss = 25.0560
2024-10-30 15:10:23: [2024-10-30 15:10:23] iter = 11280, loss = 9.4568
2024-10-30 15:10:26: [2024-10-30 15:10:26] iter = 11290, loss = 74.0818
2024-10-30 15:10:31: [2024-10-30 15:10:31] iter = 11300, loss = 4.8127
2024-10-30 15:10:35: [2024-10-30 15:10:35] iter = 11310, loss = 30.1962
2024-10-30 15:10:38: [2024-10-30 15:10:38] iter = 11320, loss = 38.0043
2024-10-30 15:10:41: [2024-10-30 15:10:41] iter = 11330, loss = 18.7445
2024-10-30 15:10:44: [2024-10-30 15:10:44] iter = 11340, loss = 3.3720
2024-10-30 15:10:48: [2024-10-30 15:10:48] iter = 11350, loss = 34.9611
2024-10-30 15:10:52: [2024-10-30 15:10:52] iter = 11360, loss = 25.0000
2024-10-30 15:10:57: [2024-10-30 15:10:57] iter = 11370, loss = 23.5702
2024-10-30 15:11:02: [2024-10-30 15:11:02] iter = 11380, loss = 29.3715
2024-10-30 15:11:06: [2024-10-30 15:11:06] iter = 11390, loss = 26.0171
2024-10-30 15:11:10: [2024-10-30 15:11:10] iter = 11400, loss = 9.6748
2024-10-30 15:11:13: [2024-10-30 15:11:13] iter = 11410, loss = 8.4381
2024-10-30 15:11:17: [2024-10-30 15:11:17] iter = 11420, loss = 5.5929
2024-10-30 15:11:22: [2024-10-30 15:11:22] iter = 11430, loss = 10.4492
2024-10-30 15:11:27: [2024-10-30 15:11:27] iter = 11440, loss = 4.6457
2024-10-30 15:11:32: [2024-10-30 15:11:32] iter = 11450, loss = 30.2207
2024-10-30 15:11:35: [2024-10-30 15:11:35] iter = 11460, loss = 50.9539
2024-10-30 15:11:40: [2024-10-30 15:11:40] iter = 11470, loss = 6.2973
2024-10-30 15:11:44: [2024-10-30 15:11:44] iter = 11480, loss = 10.3113
2024-10-30 15:11:49: [2024-10-30 15:11:49] iter = 11490, loss = 69.9081
2024-10-30 15:11:52: [2024-10-30 15:11:52] iter = 11500, loss = 43.2193
2024-10-30 15:11:57: [2024-10-30 15:11:57] iter = 11510, loss = 10.5286
2024-10-30 15:12:01: [2024-10-30 15:12:01] iter = 11520, loss = 27.9745
2024-10-30 15:12:06: [2024-10-30 15:12:06] iter = 11530, loss = 22.8570
2024-10-30 15:12:11: [2024-10-30 15:12:11] iter = 11540, loss = 5.0491
2024-10-30 15:12:16: [2024-10-30 15:12:16] iter = 11550, loss = 19.0544
2024-10-30 15:12:20: [2024-10-30 15:12:20] iter = 11560, loss = 40.2262
2024-10-30 15:12:25: [2024-10-30 15:12:25] iter = 11570, loss = 30.1167
2024-10-30 15:12:30: [2024-10-30 15:12:30] iter = 11580, loss = 34.0556
2024-10-30 15:12:34: [2024-10-30 15:12:34] iter = 11590, loss = 7.1418
2024-10-30 15:12:39: [2024-10-30 15:12:39] iter = 11600, loss = 50.1002
2024-10-30 15:12:43: [2024-10-30 15:12:43] iter = 11610, loss = 20.1986
2024-10-30 15:12:47: [2024-10-30 15:12:47] iter = 11620, loss = 5.2982
2024-10-30 15:12:51: [2024-10-30 15:12:51] iter = 11630, loss = 6.8201
2024-10-30 15:12:56: [2024-10-30 15:12:56] iter = 11640, loss = 14.8593
2024-10-30 15:13:00: [2024-10-30 15:13:00] iter = 11650, loss = 47.1280
2024-10-30 15:13:05: [2024-10-30 15:13:05] iter = 11660, loss = 7.3416
2024-10-30 15:13:08: [2024-10-30 15:13:08] iter = 11670, loss = 10.5477
2024-10-30 15:13:15: [2024-10-30 15:13:15] iter = 11680, loss = 13.9791
2024-10-30 15:13:20: [2024-10-30 15:13:20] iter = 11690, loss = 6.5537
2024-10-30 15:13:24: [2024-10-30 15:13:24] iter = 11700, loss = 3.8200
2024-10-30 15:13:30: [2024-10-30 15:13:30] iter = 11710, loss = 7.0700
2024-10-30 15:13:34: [2024-10-30 15:13:34] iter = 11720, loss = 5.8719
2024-10-30 15:13:39: [2024-10-30 15:13:39] iter = 11730, loss = 7.0512
2024-10-30 15:13:44: [2024-10-30 15:13:44] iter = 11740, loss = 37.5480
2024-10-30 15:13:48: [2024-10-30 15:13:48] iter = 11750, loss = 16.7574
2024-10-30 15:13:52: [2024-10-30 15:13:52] iter = 11760, loss = 8.2828
2024-10-30 15:13:57: [2024-10-30 15:13:57] iter = 11770, loss = 22.2596
2024-10-30 15:14:02: [2024-10-30 15:14:02] iter = 11780, loss = 13.3094
2024-10-30 15:14:06: [2024-10-30 15:14:06] iter = 11790, loss = 20.0492
2024-10-30 15:14:11: [2024-10-30 15:14:11] iter = 11800, loss = 31.5080
2024-10-30 15:14:16: [2024-10-30 15:14:16] iter = 11810, loss = 5.7245
2024-10-30 15:14:20: [2024-10-30 15:14:20] iter = 11820, loss = 18.7527
2024-10-30 15:14:25: [2024-10-30 15:14:25] iter = 11830, loss = 5.0331
2024-10-30 15:14:31: [2024-10-30 15:14:31] iter = 11840, loss = 5.6333
2024-10-30 15:14:36: [2024-10-30 15:14:36] iter = 11850, loss = 11.2991
2024-10-30 15:14:40: [2024-10-30 15:14:40] iter = 11860, loss = 6.1971
2024-10-30 15:14:45: [2024-10-30 15:14:45] iter = 11870, loss = 24.2502
2024-10-30 15:14:49: [2024-10-30 15:14:49] iter = 11880, loss = 15.9201
2024-10-30 15:14:54: [2024-10-30 15:14:54] iter = 11890, loss = 5.8404
2024-10-30 15:14:59: [2024-10-30 15:14:59] iter = 11900, loss = 3.5879
2024-10-30 15:15:04: [2024-10-30 15:15:04] iter = 11910, loss = 10.7464
2024-10-30 15:15:08: [2024-10-30 15:15:08] iter = 11920, loss = 12.0301
2024-10-30 15:15:12: [2024-10-30 15:15:12] iter = 11930, loss = 4.3366
2024-10-30 15:15:16: [2024-10-30 15:15:16] iter = 11940, loss = 40.4536
2024-10-30 15:15:20: [2024-10-30 15:15:20] iter = 11950, loss = 12.9423
2024-10-30 15:15:24: [2024-10-30 15:15:24] iter = 11960, loss = 19.8798
2024-10-30 15:15:28: [2024-10-30 15:15:28] iter = 11970, loss = 53.4948
2024-10-30 15:15:31: [2024-10-30 15:15:31] iter = 11980, loss = 17.0217
2024-10-30 15:15:36: [2024-10-30 15:15:36] iter = 11990, loss = 15.7400
2024-10-30 15:15:40: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 15:15:40: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:15:40: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 40303}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:18:29: Evaluate 5 random ConvNet, ACCmean = 0.3741 ACCstd = 0.0010
-------------------------
2024-10-30 15:18:29: Evaluate 5 random ConvNet, SENmean = 0.3170 SENstd = 0.0029
-------------------------
2024-10-30 15:18:29: Evaluate 5 random ConvNet, SPEmean = 0.9100 SPEstd = 0.0002
-------------------------
2024-10-30 15:18:29: Evaluate 5 random ConvNet, F!mean = 0.2905 F!std = 0.0008
-------------------------
2024-10-30 15:18:29: Evaluate 5 random ConvNet, mean = 0.3741 std = 0.0010
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:18:30: [2024-10-30 15:18:30] iter = 12000, loss = 29.3263
2024-10-30 15:18:35: [2024-10-30 15:18:35] iter = 12010, loss = 10.9172
2024-10-30 15:18:40: [2024-10-30 15:18:40] iter = 12020, loss = 25.7164
2024-10-30 15:18:45: [2024-10-30 15:18:45] iter = 12030, loss = 15.0335
2024-10-30 15:18:49: [2024-10-30 15:18:49] iter = 12040, loss = 10.8471
2024-10-30 15:18:54: [2024-10-30 15:18:54] iter = 12050, loss = 6.6186
2024-10-30 15:19:00: [2024-10-30 15:19:00] iter = 12060, loss = 20.0216
2024-10-30 15:19:05: [2024-10-30 15:19:05] iter = 12070, loss = 4.4648
2024-10-30 15:19:10: [2024-10-30 15:19:10] iter = 12080, loss = 19.2530
2024-10-30 15:19:15: [2024-10-30 15:19:15] iter = 12090, loss = 6.2059
2024-10-30 15:19:19: [2024-10-30 15:19:19] iter = 12100, loss = 4.6103
2024-10-30 15:19:24: [2024-10-30 15:19:24] iter = 12110, loss = 9.6390
2024-10-30 15:19:29: [2024-10-30 15:19:29] iter = 12120, loss = 7.3871
2024-10-30 15:19:33: [2024-10-30 15:19:33] iter = 12130, loss = 41.3168
2024-10-30 15:19:39: [2024-10-30 15:19:39] iter = 12140, loss = 3.9737
2024-10-30 15:19:44: [2024-10-30 15:19:44] iter = 12150, loss = 11.5329
2024-10-30 15:19:47: [2024-10-30 15:19:47] iter = 12160, loss = 49.2102
2024-10-30 15:19:51: [2024-10-30 15:19:51] iter = 12170, loss = 8.0966
2024-10-30 15:19:55: [2024-10-30 15:19:55] iter = 12180, loss = 4.4622
2024-10-30 15:19:59: [2024-10-30 15:19:59] iter = 12190, loss = 43.3857
2024-10-30 15:20:02: [2024-10-30 15:20:02] iter = 12200, loss = 4.1172
2024-10-30 15:20:05: [2024-10-30 15:20:05] iter = 12210, loss = 19.3191
2024-10-30 15:20:09: [2024-10-30 15:20:09] iter = 12220, loss = 6.1633
2024-10-30 15:20:13: [2024-10-30 15:20:13] iter = 12230, loss = 5.3773
2024-10-30 15:20:18: [2024-10-30 15:20:18] iter = 12240, loss = 34.0550
2024-10-30 15:20:22: [2024-10-30 15:20:22] iter = 12250, loss = 7.1560
2024-10-30 15:20:24: [2024-10-30 15:20:24] iter = 12260, loss = 26.7605
2024-10-30 15:20:29: [2024-10-30 15:20:29] iter = 12270, loss = 15.1488
2024-10-30 15:20:33: [2024-10-30 15:20:33] iter = 12280, loss = 9.9083
2024-10-30 15:20:38: [2024-10-30 15:20:38] iter = 12290, loss = 9.8492
2024-10-30 15:20:41: [2024-10-30 15:20:41] iter = 12300, loss = 8.7535
2024-10-30 15:20:46: [2024-10-30 15:20:46] iter = 12310, loss = 12.6721
2024-10-30 15:20:51: [2024-10-30 15:20:51] iter = 12320, loss = 6.7129
2024-10-30 15:20:55: [2024-10-30 15:20:55] iter = 12330, loss = 44.2686
2024-10-30 15:21:00: [2024-10-30 15:21:00] iter = 12340, loss = 5.7447
2024-10-30 15:21:04: [2024-10-30 15:21:04] iter = 12350, loss = 46.5496
2024-10-30 15:21:08: [2024-10-30 15:21:08] iter = 12360, loss = 5.2134
2024-10-30 15:21:13: [2024-10-30 15:21:13] iter = 12370, loss = 34.2395
2024-10-30 15:21:17: [2024-10-30 15:21:17] iter = 12380, loss = 25.5395
2024-10-30 15:21:21: [2024-10-30 15:21:21] iter = 12390, loss = 5.5841
2024-10-30 15:21:25: [2024-10-30 15:21:25] iter = 12400, loss = 23.3893
2024-10-30 15:21:30: [2024-10-30 15:21:30] iter = 12410, loss = 23.2539
2024-10-30 15:21:33: [2024-10-30 15:21:33] iter = 12420, loss = 65.7551
2024-10-30 15:21:38: [2024-10-30 15:21:38] iter = 12430, loss = 12.6532
2024-10-30 15:21:43: [2024-10-30 15:21:43] iter = 12440, loss = 4.4803
2024-10-30 15:21:46: [2024-10-30 15:21:46] iter = 12450, loss = 10.0876
2024-10-30 15:21:50: [2024-10-30 15:21:50] iter = 12460, loss = 40.4681
2024-10-30 15:21:55: [2024-10-30 15:21:55] iter = 12470, loss = 6.9661
2024-10-30 15:21:59: [2024-10-30 15:21:59] iter = 12480, loss = 5.1282
2024-10-30 15:22:04: [2024-10-30 15:22:04] iter = 12490, loss = 16.2999
2024-10-30 15:22:09: [2024-10-30 15:22:09] iter = 12500, loss = 5.1485
2024-10-30 15:22:13: [2024-10-30 15:22:13] iter = 12510, loss = 79.8682
2024-10-30 15:22:17: [2024-10-30 15:22:17] iter = 12520, loss = 20.6941
2024-10-30 15:22:21: [2024-10-30 15:22:21] iter = 12530, loss = 18.4600
2024-10-30 15:22:26: [2024-10-30 15:22:26] iter = 12540, loss = 28.0505
2024-10-30 15:22:30: [2024-10-30 15:22:30] iter = 12550, loss = 5.4857
2024-10-30 15:22:34: [2024-10-30 15:22:34] iter = 12560, loss = 42.6773
2024-10-30 15:22:39: [2024-10-30 15:22:39] iter = 12570, loss = 51.6919
2024-10-30 15:22:43: [2024-10-30 15:22:43] iter = 12580, loss = 8.1128
2024-10-30 15:22:47: [2024-10-30 15:22:47] iter = 12590, loss = 41.5477
2024-10-30 15:22:52: [2024-10-30 15:22:52] iter = 12600, loss = 59.1241
2024-10-30 15:22:56: [2024-10-30 15:22:56] iter = 12610, loss = 4.8387
2024-10-30 15:23:00: [2024-10-30 15:23:00] iter = 12620, loss = 10.7782
2024-10-30 15:23:05: [2024-10-30 15:23:05] iter = 12630, loss = 24.4432
2024-10-30 15:23:09: [2024-10-30 15:23:09] iter = 12640, loss = 9.4855
2024-10-30 15:23:14: [2024-10-30 15:23:14] iter = 12650, loss = 59.6651
2024-10-30 15:23:18: [2024-10-30 15:23:18] iter = 12660, loss = 40.7815
2024-10-30 15:23:23: [2024-10-30 15:23:23] iter = 12670, loss = 27.2323
2024-10-30 15:23:27: [2024-10-30 15:23:27] iter = 12680, loss = 17.9673
2024-10-30 15:23:30: [2024-10-30 15:23:30] iter = 12690, loss = 29.1694
2024-10-30 15:23:33: [2024-10-30 15:23:33] iter = 12700, loss = 5.6312
2024-10-30 15:23:38: [2024-10-30 15:23:38] iter = 12710, loss = 15.5556
2024-10-30 15:23:43: [2024-10-30 15:23:43] iter = 12720, loss = 29.7311
2024-10-30 15:23:48: [2024-10-30 15:23:48] iter = 12730, loss = 29.5134
2024-10-30 15:23:52: [2024-10-30 15:23:52] iter = 12740, loss = 4.6418
2024-10-30 15:23:55: [2024-10-30 15:23:55] iter = 12750, loss = 15.1935
2024-10-30 15:24:00: [2024-10-30 15:24:00] iter = 12760, loss = 29.2246
2024-10-30 15:24:05: [2024-10-30 15:24:05] iter = 12770, loss = 24.2773
2024-10-30 15:24:09: [2024-10-30 15:24:09] iter = 12780, loss = 5.9590
2024-10-30 15:24:14: [2024-10-30 15:24:14] iter = 12790, loss = 7.5515
2024-10-30 15:24:19: [2024-10-30 15:24:19] iter = 12800, loss = 4.6282
2024-10-30 15:24:23: [2024-10-30 15:24:23] iter = 12810, loss = 14.0998
2024-10-30 15:24:29: [2024-10-30 15:24:29] iter = 12820, loss = 10.8244
2024-10-30 15:24:33: [2024-10-30 15:24:33] iter = 12830, loss = 5.2949
2024-10-30 15:24:38: [2024-10-30 15:24:38] iter = 12840, loss = 3.6684
2024-10-30 15:24:43: [2024-10-30 15:24:43] iter = 12850, loss = 8.3504
2024-10-30 15:24:47: [2024-10-30 15:24:47] iter = 12860, loss = 7.3704
2024-10-30 15:24:52: [2024-10-30 15:24:52] iter = 12870, loss = 5.6448
2024-10-30 15:24:57: [2024-10-30 15:24:57] iter = 12880, loss = 3.3099
2024-10-30 15:25:03: [2024-10-30 15:25:03] iter = 12890, loss = 58.7702
2024-10-30 15:25:07: [2024-10-30 15:25:07] iter = 12900, loss = 4.6874
2024-10-30 15:25:12: [2024-10-30 15:25:12] iter = 12910, loss = 4.5858
2024-10-30 15:25:16: [2024-10-30 15:25:16] iter = 12920, loss = 5.3320
2024-10-30 15:25:21: [2024-10-30 15:25:21] iter = 12930, loss = 9.3332
2024-10-30 15:25:25: [2024-10-30 15:25:25] iter = 12940, loss = 67.3904
2024-10-30 15:25:30: [2024-10-30 15:25:30] iter = 12950, loss = 7.2794
2024-10-30 15:25:34: [2024-10-30 15:25:34] iter = 12960, loss = 15.7364
2024-10-30 15:25:39: [2024-10-30 15:25:39] iter = 12970, loss = 11.4658
2024-10-30 15:25:43: [2024-10-30 15:25:43] iter = 12980, loss = 51.8965
2024-10-30 15:25:48: [2024-10-30 15:25:48] iter = 12990, loss = 9.1221
2024-10-30 15:25:52: [2024-10-30 15:25:52] iter = 13000, loss = 5.3051
2024-10-30 15:25:57: [2024-10-30 15:25:57] iter = 13010, loss = 4.4223
2024-10-30 15:26:00: [2024-10-30 15:26:00] iter = 13020, loss = 4.8193
2024-10-30 15:26:03: [2024-10-30 15:26:03] iter = 13030, loss = 7.7935
2024-10-30 15:26:06: [2024-10-30 15:26:06] iter = 13040, loss = 107.2088
2024-10-30 15:26:10: [2024-10-30 15:26:10] iter = 13050, loss = 6.6399
2024-10-30 15:26:14: [2024-10-30 15:26:14] iter = 13060, loss = 23.2859
2024-10-30 15:26:17: [2024-10-30 15:26:17] iter = 13070, loss = 12.0164
2024-10-30 15:26:20: [2024-10-30 15:26:20] iter = 13080, loss = 6.8897
2024-10-30 15:26:25: [2024-10-30 15:26:25] iter = 13090, loss = 44.8505
2024-10-30 15:26:30: [2024-10-30 15:26:30] iter = 13100, loss = 10.1117
2024-10-30 15:26:34: [2024-10-30 15:26:34] iter = 13110, loss = 31.5691
2024-10-30 15:26:38: [2024-10-30 15:26:38] iter = 13120, loss = 7.9750
2024-10-30 15:26:41: [2024-10-30 15:26:41] iter = 13130, loss = 37.1461
2024-10-30 15:26:45: [2024-10-30 15:26:45] iter = 13140, loss = 4.2514
2024-10-30 15:26:49: [2024-10-30 15:26:49] iter = 13150, loss = 5.4249
2024-10-30 15:26:54: [2024-10-30 15:26:54] iter = 13160, loss = 30.8199
2024-10-30 15:26:56: [2024-10-30 15:26:56] iter = 13170, loss = 11.5525
2024-10-30 15:26:59: [2024-10-30 15:26:59] iter = 13180, loss = 6.3308
2024-10-30 15:27:02: [2024-10-30 15:27:02] iter = 13190, loss = 17.0530
2024-10-30 15:27:06: [2024-10-30 15:27:06] iter = 13200, loss = 11.4988
2024-10-30 15:27:11: [2024-10-30 15:27:11] iter = 13210, loss = 13.6183
2024-10-30 15:27:15: [2024-10-30 15:27:15] iter = 13220, loss = 3.8030
2024-10-30 15:27:18: [2024-10-30 15:27:18] iter = 13230, loss = 31.6764
2024-10-30 15:27:21: [2024-10-30 15:27:21] iter = 13240, loss = 31.3120
2024-10-30 15:27:24: [2024-10-30 15:27:24] iter = 13250, loss = 9.5205
2024-10-30 15:27:26: [2024-10-30 15:27:26] iter = 13260, loss = 19.7856
2024-10-30 15:27:31: [2024-10-30 15:27:31] iter = 13270, loss = 21.9102
2024-10-30 15:27:35: [2024-10-30 15:27:35] iter = 13280, loss = 36.9708
2024-10-30 15:27:39: [2024-10-30 15:27:39] iter = 13290, loss = 39.7091
2024-10-30 15:27:43: [2024-10-30 15:27:43] iter = 13300, loss = 23.1552
2024-10-30 15:27:47: [2024-10-30 15:27:47] iter = 13310, loss = 17.0874
2024-10-30 15:27:51: [2024-10-30 15:27:51] iter = 13320, loss = 27.0218
2024-10-30 15:27:56: [2024-10-30 15:27:56] iter = 13330, loss = 8.8954
2024-10-30 15:28:00: [2024-10-30 15:28:00] iter = 13340, loss = 35.4789
2024-10-30 15:28:05: [2024-10-30 15:28:05] iter = 13350, loss = 29.7053
2024-10-30 15:28:10: [2024-10-30 15:28:10] iter = 13360, loss = 5.3189
2024-10-30 15:28:14: [2024-10-30 15:28:14] iter = 13370, loss = 33.5248
2024-10-30 15:28:19: [2024-10-30 15:28:19] iter = 13380, loss = 6.8409
2024-10-30 15:28:24: [2024-10-30 15:28:24] iter = 13390, loss = 43.7193
2024-10-30 15:28:29: [2024-10-30 15:28:29] iter = 13400, loss = 13.5815
2024-10-30 15:28:33: [2024-10-30 15:28:33] iter = 13410, loss = 18.1768
2024-10-30 15:28:37: [2024-10-30 15:28:37] iter = 13420, loss = 58.7686
2024-10-30 15:28:41: [2024-10-30 15:28:41] iter = 13430, loss = 4.1862
2024-10-30 15:28:46: [2024-10-30 15:28:46] iter = 13440, loss = 28.8382
2024-10-30 15:28:50: [2024-10-30 15:28:50] iter = 13450, loss = 39.4842
2024-10-30 15:28:55: [2024-10-30 15:28:55] iter = 13460, loss = 4.1286
2024-10-30 15:28:59: [2024-10-30 15:28:59] iter = 13470, loss = 8.9560
2024-10-30 15:29:03: [2024-10-30 15:29:03] iter = 13480, loss = 35.5320
2024-10-30 15:29:07: [2024-10-30 15:29:07] iter = 13490, loss = 7.2670
2024-10-30 15:29:11: [2024-10-30 15:29:11] iter = 13500, loss = 16.0810
2024-10-30 15:29:15: [2024-10-30 15:29:15] iter = 13510, loss = 5.6959
2024-10-30 15:29:20: [2024-10-30 15:29:20] iter = 13520, loss = 22.7814
2024-10-30 15:29:24: [2024-10-30 15:29:24] iter = 13530, loss = 28.0095
2024-10-30 15:29:28: [2024-10-30 15:29:28] iter = 13540, loss = 37.1005
2024-10-30 15:29:34: [2024-10-30 15:29:34] iter = 13550, loss = 12.6546
2024-10-30 15:29:38: [2024-10-30 15:29:38] iter = 13560, loss = 8.0446
2024-10-30 15:29:43: [2024-10-30 15:29:43] iter = 13570, loss = 4.4184
2024-10-30 15:29:47: [2024-10-30 15:29:47] iter = 13580, loss = 27.7144
2024-10-30 15:29:51: [2024-10-30 15:29:51] iter = 13590, loss = 5.3750
2024-10-30 15:29:54: [2024-10-30 15:29:54] iter = 13600, loss = 27.3673
2024-10-30 15:29:57: [2024-10-30 15:29:57] iter = 13610, loss = 4.0173
2024-10-30 15:30:02: [2024-10-30 15:30:02] iter = 13620, loss = 31.0228
2024-10-30 15:30:05: [2024-10-30 15:30:05] iter = 13630, loss = 12.6518
2024-10-30 15:30:10: [2024-10-30 15:30:10] iter = 13640, loss = 17.1492
2024-10-30 15:30:14: [2024-10-30 15:30:14] iter = 13650, loss = 33.0454
2024-10-30 15:30:17: [2024-10-30 15:30:17] iter = 13660, loss = 5.3451
2024-10-30 15:30:20: [2024-10-30 15:30:20] iter = 13670, loss = 18.1190
2024-10-30 15:30:24: [2024-10-30 15:30:24] iter = 13680, loss = 14.7415
2024-10-30 15:30:27: [2024-10-30 15:30:27] iter = 13690, loss = 3.8747
2024-10-30 15:30:32: [2024-10-30 15:30:32] iter = 13700, loss = 8.9083
2024-10-30 15:30:35: [2024-10-30 15:30:35] iter = 13710, loss = 27.4689
2024-10-30 15:30:39: [2024-10-30 15:30:39] iter = 13720, loss = 111.8507
2024-10-30 15:30:44: [2024-10-30 15:30:44] iter = 13730, loss = 13.4053
2024-10-30 15:30:47: [2024-10-30 15:30:47] iter = 13740, loss = 9.5851
2024-10-30 15:30:51: [2024-10-30 15:30:51] iter = 13750, loss = 44.6419
2024-10-30 15:30:55: [2024-10-30 15:30:55] iter = 13760, loss = 44.8004
2024-10-30 15:30:58: [2024-10-30 15:30:58] iter = 13770, loss = 38.0524
2024-10-30 15:31:02: [2024-10-30 15:31:02] iter = 13780, loss = 22.3712
2024-10-30 15:31:06: [2024-10-30 15:31:05] iter = 13790, loss = 17.2617
2024-10-30 15:31:10: [2024-10-30 15:31:10] iter = 13800, loss = 13.5172
2024-10-30 15:31:14: [2024-10-30 15:31:14] iter = 13810, loss = 14.5826
2024-10-30 15:31:18: [2024-10-30 15:31:18] iter = 13820, loss = 3.8099
2024-10-30 15:31:22: [2024-10-30 15:31:22] iter = 13830, loss = 4.8487
2024-10-30 15:31:27: [2024-10-30 15:31:27] iter = 13840, loss = 47.1452
2024-10-30 15:31:31: [2024-10-30 15:31:31] iter = 13850, loss = 26.2652
2024-10-30 15:31:35: [2024-10-30 15:31:35] iter = 13860, loss = 20.6822
2024-10-30 15:31:39: [2024-10-30 15:31:39] iter = 13870, loss = 15.2788
2024-10-30 15:31:43: [2024-10-30 15:31:43] iter = 13880, loss = 10.7412
2024-10-30 15:31:47: [2024-10-30 15:31:47] iter = 13890, loss = 29.4342
2024-10-30 15:31:51: [2024-10-30 15:31:51] iter = 13900, loss = 56.1881
2024-10-30 15:31:55: [2024-10-30 15:31:55] iter = 13910, loss = 9.3596
2024-10-30 15:31:59: [2024-10-30 15:31:59] iter = 13920, loss = 32.2242
2024-10-30 15:32:03: [2024-10-30 15:32:03] iter = 13930, loss = 34.8554
2024-10-30 15:32:06: [2024-10-30 15:32:06] iter = 13940, loss = 55.4514
2024-10-30 15:32:10: [2024-10-30 15:32:10] iter = 13950, loss = 7.3750
2024-10-30 15:32:14: [2024-10-30 15:32:14] iter = 13960, loss = 4.4142
2024-10-30 15:32:17: [2024-10-30 15:32:17] iter = 13970, loss = 8.3722
2024-10-30 15:32:22: [2024-10-30 15:32:22] iter = 13980, loss = 5.5300
2024-10-30 15:32:26: [2024-10-30 15:32:26] iter = 13990, loss = 14.9676
2024-10-30 15:32:30: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 15:32:30: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:32:30: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50556}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:35:03: Evaluate 5 random ConvNet, ACCmean = 0.3067 ACCstd = 0.0115
-------------------------
2024-10-30 15:35:03: Evaluate 5 random ConvNet, SENmean = 0.3073 SENstd = 0.0036
-------------------------
2024-10-30 15:35:03: Evaluate 5 random ConvNet, SPEmean = 0.9024 SPEstd = 0.0016
-------------------------
2024-10-30 15:35:03: Evaluate 5 random ConvNet, F!mean = 0.2585 F!std = 0.0080
-------------------------
2024-10-30 15:35:03: Evaluate 5 random ConvNet, mean = 0.3067 std = 0.0115
-------------------------
2024-10-30 15:35:04: [2024-10-30 15:35:04] iter = 14000, loss = 19.2733
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:35:08: [2024-10-30 15:35:08] iter = 14010, loss = 18.0895
2024-10-30 15:35:12: [2024-10-30 15:35:12] iter = 14020, loss = 6.3740
2024-10-30 15:35:16: [2024-10-30 15:35:16] iter = 14030, loss = 10.6046
2024-10-30 15:35:19: [2024-10-30 15:35:19] iter = 14040, loss = 9.6020
2024-10-30 15:35:24: [2024-10-30 15:35:24] iter = 14050, loss = 22.7469
2024-10-30 15:35:28: [2024-10-30 15:35:28] iter = 14060, loss = 9.9845
2024-10-30 15:35:32: [2024-10-30 15:35:32] iter = 14070, loss = 13.6332
2024-10-30 15:35:36: [2024-10-30 15:35:36] iter = 14080, loss = 63.0673
2024-10-30 15:35:39: [2024-10-30 15:35:39] iter = 14090, loss = 36.9366
2024-10-30 15:35:44: [2024-10-30 15:35:44] iter = 14100, loss = 5.3215
2024-10-30 15:35:48: [2024-10-30 15:35:48] iter = 14110, loss = 6.6097
2024-10-30 15:35:52: [2024-10-30 15:35:52] iter = 14120, loss = 19.6834
2024-10-30 15:35:56: [2024-10-30 15:35:56] iter = 14130, loss = 4.4969
2024-10-30 15:36:01: [2024-10-30 15:36:01] iter = 14140, loss = 11.7253
2024-10-30 15:36:05: [2024-10-30 15:36:05] iter = 14150, loss = 9.0703
2024-10-30 15:36:09: [2024-10-30 15:36:09] iter = 14160, loss = 5.7537
2024-10-30 15:36:13: [2024-10-30 15:36:13] iter = 14170, loss = 7.6966
2024-10-30 15:36:17: [2024-10-30 15:36:17] iter = 14180, loss = 19.5232
2024-10-30 15:36:22: [2024-10-30 15:36:22] iter = 14190, loss = 3.4900
2024-10-30 15:36:27: [2024-10-30 15:36:27] iter = 14200, loss = 5.1319
2024-10-30 15:36:32: [2024-10-30 15:36:32] iter = 14210, loss = 22.3336
2024-10-30 15:36:37: [2024-10-30 15:36:37] iter = 14220, loss = 34.9869
2024-10-30 15:36:42: [2024-10-30 15:36:42] iter = 14230, loss = 63.0948
2024-10-30 15:36:46: [2024-10-30 15:36:46] iter = 14240, loss = 38.9384
2024-10-30 15:36:50: [2024-10-30 15:36:50] iter = 14250, loss = 16.1656
2024-10-30 15:36:54: [2024-10-30 15:36:54] iter = 14260, loss = 83.8223
2024-10-30 15:36:58: [2024-10-30 15:36:58] iter = 14270, loss = 12.7739
2024-10-30 15:37:03: [2024-10-30 15:37:03] iter = 14280, loss = 13.1032
2024-10-30 15:37:07: [2024-10-30 15:37:07] iter = 14290, loss = 13.2156
2024-10-30 15:37:11: [2024-10-30 15:37:11] iter = 14300, loss = 7.0124
2024-10-30 15:37:16: [2024-10-30 15:37:16] iter = 14310, loss = 7.0521
2024-10-30 15:37:21: [2024-10-30 15:37:21] iter = 14320, loss = 36.7166
2024-10-30 15:37:25: [2024-10-30 15:37:25] iter = 14330, loss = 3.4466
2024-10-30 15:37:28: [2024-10-30 15:37:28] iter = 14340, loss = 35.6478
2024-10-30 15:37:32: [2024-10-30 15:37:32] iter = 14350, loss = 21.1315
2024-10-30 15:37:36: [2024-10-30 15:37:36] iter = 14360, loss = 18.8365
2024-10-30 15:37:41: [2024-10-30 15:37:41] iter = 14370, loss = 32.5863
2024-10-30 15:37:44: [2024-10-30 15:37:44] iter = 14380, loss = 5.4289
2024-10-30 15:37:47: [2024-10-30 15:37:47] iter = 14390, loss = 43.0799
2024-10-30 15:37:50: [2024-10-30 15:37:50] iter = 14400, loss = 3.4799
2024-10-30 15:37:53: [2024-10-30 15:37:53] iter = 14410, loss = 8.4889
2024-10-30 15:37:56: [2024-10-30 15:37:56] iter = 14420, loss = 57.4097
2024-10-30 15:38:00: [2024-10-30 15:38:00] iter = 14430, loss = 10.8029
2024-10-30 15:38:05: [2024-10-30 15:38:05] iter = 14440, loss = 4.7949
2024-10-30 15:38:09: [2024-10-30 15:38:09] iter = 14450, loss = 11.3523
2024-10-30 15:38:13: [2024-10-30 15:38:13] iter = 14460, loss = 13.2746
2024-10-30 15:38:17: [2024-10-30 15:38:17] iter = 14470, loss = 13.3298
2024-10-30 15:38:21: [2024-10-30 15:38:21] iter = 14480, loss = 5.6825
2024-10-30 15:38:25: [2024-10-30 15:38:25] iter = 14490, loss = 3.3092
2024-10-30 15:38:29: [2024-10-30 15:38:29] iter = 14500, loss = 4.0852
2024-10-30 15:38:33: [2024-10-30 15:38:33] iter = 14510, loss = 4.0937
2024-10-30 15:38:36: [2024-10-30 15:38:36] iter = 14520, loss = 8.3617
2024-10-30 15:38:38: [2024-10-30 15:38:38] iter = 14530, loss = 39.9159
2024-10-30 15:38:42: [2024-10-30 15:38:42] iter = 14540, loss = 6.1732
2024-10-30 15:38:46: [2024-10-30 15:38:46] iter = 14550, loss = 8.8463
2024-10-30 15:38:50: [2024-10-30 15:38:50] iter = 14560, loss = 28.1482
2024-10-30 15:38:54: [2024-10-30 15:38:54] iter = 14570, loss = 8.2167
2024-10-30 15:38:57: [2024-10-30 15:38:57] iter = 14580, loss = 51.0993
2024-10-30 15:39:00: [2024-10-30 15:39:00] iter = 14590, loss = 4.9026
2024-10-30 15:39:04: [2024-10-30 15:39:04] iter = 14600, loss = 40.5670
2024-10-30 15:39:07: [2024-10-30 15:39:07] iter = 14610, loss = 105.9248
2024-10-30 15:39:12: [2024-10-30 15:39:12] iter = 14620, loss = 20.0353
2024-10-30 15:39:17: [2024-10-30 15:39:17] iter = 14630, loss = 4.3453
2024-10-30 15:39:22: [2024-10-30 15:39:22] iter = 14640, loss = 4.7360
2024-10-30 15:39:26: [2024-10-30 15:39:26] iter = 14650, loss = 35.4152
2024-10-30 15:39:30: [2024-10-30 15:39:30] iter = 14660, loss = 5.2571
2024-10-30 15:39:33: [2024-10-30 15:39:33] iter = 14670, loss = 22.4136
2024-10-30 15:39:37: [2024-10-30 15:39:37] iter = 14680, loss = 75.4150
2024-10-30 15:39:41: [2024-10-30 15:39:41] iter = 14690, loss = 22.0177
2024-10-30 15:39:45: [2024-10-30 15:39:45] iter = 14700, loss = 8.5516
2024-10-30 15:39:49: [2024-10-30 15:39:49] iter = 14710, loss = 66.2473
2024-10-30 15:39:53: [2024-10-30 15:39:53] iter = 14720, loss = 7.2280
2024-10-30 15:39:58: [2024-10-30 15:39:58] iter = 14730, loss = 13.6732
2024-10-30 15:40:03: [2024-10-30 15:40:03] iter = 14740, loss = 12.2842
2024-10-30 15:40:07: [2024-10-30 15:40:07] iter = 14750, loss = 28.0950
2024-10-30 15:40:10: [2024-10-30 15:40:10] iter = 14760, loss = 19.9166
2024-10-30 15:40:14: [2024-10-30 15:40:14] iter = 14770, loss = 12.8812
2024-10-30 15:40:18: [2024-10-30 15:40:18] iter = 14780, loss = 4.0893
2024-10-30 15:40:22: [2024-10-30 15:40:22] iter = 14790, loss = 18.5972
2024-10-30 15:40:27: [2024-10-30 15:40:27] iter = 14800, loss = 14.9019
2024-10-30 15:40:31: [2024-10-30 15:40:31] iter = 14810, loss = 11.3078
2024-10-30 15:40:36: [2024-10-30 15:40:36] iter = 14820, loss = 7.4680
2024-10-30 15:40:40: [2024-10-30 15:40:40] iter = 14830, loss = 17.5725
2024-10-30 15:40:43: [2024-10-30 15:40:43] iter = 14840, loss = 17.3364
2024-10-30 15:40:47: [2024-10-30 15:40:47] iter = 14850, loss = 12.9094
2024-10-30 15:40:51: [2024-10-30 15:40:51] iter = 14860, loss = 50.9710
2024-10-30 15:40:55: [2024-10-30 15:40:55] iter = 14870, loss = 16.5520
2024-10-30 15:40:58: [2024-10-30 15:40:58] iter = 14880, loss = 10.7665
2024-10-30 15:41:02: [2024-10-30 15:41:02] iter = 14890, loss = 20.8611
2024-10-30 15:41:07: [2024-10-30 15:41:07] iter = 14900, loss = 20.7747
2024-10-30 15:41:11: [2024-10-30 15:41:11] iter = 14910, loss = 3.7659
2024-10-30 15:41:16: [2024-10-30 15:41:16] iter = 14920, loss = 5.3507
2024-10-30 15:41:20: [2024-10-30 15:41:20] iter = 14930, loss = 16.6241
2024-10-30 15:41:24: [2024-10-30 15:41:24] iter = 14940, loss = 7.2045
2024-10-30 15:41:29: [2024-10-30 15:41:29] iter = 14950, loss = 44.5341
2024-10-30 15:41:34: [2024-10-30 15:41:34] iter = 14960, loss = 14.4015
2024-10-30 15:41:37: [2024-10-30 15:41:37] iter = 14970, loss = 8.0747
2024-10-30 15:41:40: [2024-10-30 15:41:40] iter = 14980, loss = 37.8283
2024-10-30 15:41:45: [2024-10-30 15:41:45] iter = 14990, loss = 7.2612
2024-10-30 15:41:48: [2024-10-30 15:41:48] iter = 15000, loss = 23.0359
2024-10-30 15:41:51: [2024-10-30 15:41:51] iter = 15010, loss = 15.0344
2024-10-30 15:41:55: [2024-10-30 15:41:55] iter = 15020, loss = 11.7427
2024-10-30 15:41:59: [2024-10-30 15:41:59] iter = 15030, loss = 24.1977
2024-10-30 15:42:03: [2024-10-30 15:42:03] iter = 15040, loss = 43.9656
2024-10-30 15:42:07: [2024-10-30 15:42:07] iter = 15050, loss = 6.2895
2024-10-30 15:42:11: [2024-10-30 15:42:11] iter = 15060, loss = 64.9032
2024-10-30 15:42:15: [2024-10-30 15:42:15] iter = 15070, loss = 8.8057
2024-10-30 15:42:19: [2024-10-30 15:42:19] iter = 15080, loss = 7.0510
2024-10-30 15:42:22: [2024-10-30 15:42:22] iter = 15090, loss = 19.3635
2024-10-30 15:42:25: [2024-10-30 15:42:25] iter = 15100, loss = 4.5505
2024-10-30 15:42:29: [2024-10-30 15:42:29] iter = 15110, loss = 6.9687
2024-10-30 15:42:32: [2024-10-30 15:42:32] iter = 15120, loss = 10.5754
2024-10-30 15:42:36: [2024-10-30 15:42:36] iter = 15130, loss = 30.9528
2024-10-30 15:42:39: [2024-10-30 15:42:39] iter = 15140, loss = 11.6284
2024-10-30 15:42:42: [2024-10-30 15:42:42] iter = 15150, loss = 32.4510
2024-10-30 15:42:46: [2024-10-30 15:42:46] iter = 15160, loss = 5.9373
2024-10-30 15:42:50: [2024-10-30 15:42:50] iter = 15170, loss = 12.3197
2024-10-30 15:42:53: [2024-10-30 15:42:53] iter = 15180, loss = 8.2282
2024-10-30 15:42:56: [2024-10-30 15:42:56] iter = 15190, loss = 10.3034
2024-10-30 15:43:00: [2024-10-30 15:43:00] iter = 15200, loss = 7.3702
2024-10-30 15:43:05: [2024-10-30 15:43:05] iter = 15210, loss = 3.7491
2024-10-30 15:43:09: [2024-10-30 15:43:09] iter = 15220, loss = 51.2497
2024-10-30 15:43:12: [2024-10-30 15:43:12] iter = 15230, loss = 10.0762
2024-10-30 15:43:17: [2024-10-30 15:43:17] iter = 15240, loss = 21.9189
2024-10-30 15:43:20: [2024-10-30 15:43:20] iter = 15250, loss = 12.5459
2024-10-30 15:43:24: [2024-10-30 15:43:23] iter = 15260, loss = 3.6891
2024-10-30 15:43:27: [2024-10-30 15:43:27] iter = 15270, loss = 3.7854
2024-10-30 15:43:31: [2024-10-30 15:43:31] iter = 15280, loss = 3.6792
2024-10-30 15:43:34: [2024-10-30 15:43:34] iter = 15290, loss = 3.5155
2024-10-30 15:43:36: [2024-10-30 15:43:36] iter = 15300, loss = 55.3420
2024-10-30 15:43:38: [2024-10-30 15:43:38] iter = 15310, loss = 14.2117
2024-10-30 15:43:42: [2024-10-30 15:43:42] iter = 15320, loss = 35.3163
2024-10-30 15:43:46: [2024-10-30 15:43:46] iter = 15330, loss = 11.2988
2024-10-30 15:43:50: [2024-10-30 15:43:50] iter = 15340, loss = 7.9905
2024-10-30 15:43:53: [2024-10-30 15:43:53] iter = 15350, loss = 8.5401
2024-10-30 15:43:57: [2024-10-30 15:43:57] iter = 15360, loss = 7.4490
2024-10-30 15:44:00: [2024-10-30 15:44:00] iter = 15370, loss = 30.6996
2024-10-30 15:44:04: [2024-10-30 15:44:04] iter = 15380, loss = 4.8694
2024-10-30 15:44:08: [2024-10-30 15:44:08] iter = 15390, loss = 47.9472
2024-10-30 15:44:12: [2024-10-30 15:44:12] iter = 15400, loss = 4.3894
2024-10-30 15:44:15: [2024-10-30 15:44:15] iter = 15410, loss = 5.5553
2024-10-30 15:44:20: [2024-10-30 15:44:20] iter = 15420, loss = 25.0505
2024-10-30 15:44:25: [2024-10-30 15:44:25] iter = 15430, loss = 22.6608
2024-10-30 15:44:29: [2024-10-30 15:44:29] iter = 15440, loss = 11.3701
2024-10-30 15:44:33: [2024-10-30 15:44:33] iter = 15450, loss = 4.0929
2024-10-30 15:44:36: [2024-10-30 15:44:36] iter = 15460, loss = 20.1390
2024-10-30 15:44:41: [2024-10-30 15:44:41] iter = 15470, loss = 38.3353
2024-10-30 15:44:44: [2024-10-30 15:44:44] iter = 15480, loss = 10.8109
2024-10-30 15:44:48: [2024-10-30 15:44:48] iter = 15490, loss = 12.8695
2024-10-30 15:44:53: [2024-10-30 15:44:53] iter = 15500, loss = 5.2820
2024-10-30 15:44:56: [2024-10-30 15:44:56] iter = 15510, loss = 5.5937
2024-10-30 15:44:59: [2024-10-30 15:44:59] iter = 15520, loss = 27.9578
2024-10-30 15:45:03: [2024-10-30 15:45:03] iter = 15530, loss = 5.2514
2024-10-30 15:45:06: [2024-10-30 15:45:06] iter = 15540, loss = 26.6949
2024-10-30 15:45:10: [2024-10-30 15:45:10] iter = 15550, loss = 13.1730
2024-10-30 15:45:14: [2024-10-30 15:45:14] iter = 15560, loss = 6.2897
2024-10-30 15:45:17: [2024-10-30 15:45:17] iter = 15570, loss = 36.3473
2024-10-30 15:45:21: [2024-10-30 15:45:21] iter = 15580, loss = 25.9632
2024-10-30 15:45:25: [2024-10-30 15:45:25] iter = 15590, loss = 77.2153
2024-10-30 15:45:29: [2024-10-30 15:45:29] iter = 15600, loss = 27.2459
2024-10-30 15:45:32: [2024-10-30 15:45:32] iter = 15610, loss = 30.8947
2024-10-30 15:45:36: [2024-10-30 15:45:36] iter = 15620, loss = 35.6244
2024-10-30 15:45:41: [2024-10-30 15:45:41] iter = 15630, loss = 5.9804
2024-10-30 15:45:45: [2024-10-30 15:45:45] iter = 15640, loss = 72.5442
2024-10-30 15:45:49: [2024-10-30 15:45:49] iter = 15650, loss = 10.8334
2024-10-30 15:45:53: [2024-10-30 15:45:53] iter = 15660, loss = 18.1887
2024-10-30 15:45:57: [2024-10-30 15:45:57] iter = 15670, loss = 34.0955
2024-10-30 15:46:01: [2024-10-30 15:46:01] iter = 15680, loss = 47.3226
2024-10-30 15:46:05: [2024-10-30 15:46:05] iter = 15690, loss = 9.6163
2024-10-30 15:46:09: [2024-10-30 15:46:09] iter = 15700, loss = 12.5383
2024-10-30 15:46:13: [2024-10-30 15:46:13] iter = 15710, loss = 80.7095
2024-10-30 15:46:18: [2024-10-30 15:46:18] iter = 15720, loss = 11.5967
2024-10-30 15:46:21: [2024-10-30 15:46:21] iter = 15730, loss = 22.5464
2024-10-30 15:46:25: [2024-10-30 15:46:25] iter = 15740, loss = 26.1807
2024-10-30 15:46:29: [2024-10-30 15:46:29] iter = 15750, loss = 9.8899
2024-10-30 15:46:32: [2024-10-30 15:46:32] iter = 15760, loss = 18.2178
2024-10-30 15:46:36: [2024-10-30 15:46:36] iter = 15770, loss = 5.4521
2024-10-30 15:46:40: [2024-10-30 15:46:40] iter = 15780, loss = 9.6015
2024-10-30 15:46:43: [2024-10-30 15:46:43] iter = 15790, loss = 41.8172
2024-10-30 15:46:47: [2024-10-30 15:46:47] iter = 15800, loss = 5.6001
2024-10-30 15:46:51: [2024-10-30 15:46:51] iter = 15810, loss = 12.8000
2024-10-30 15:46:55: [2024-10-30 15:46:55] iter = 15820, loss = 39.7566
2024-10-30 15:47:00: [2024-10-30 15:47:00] iter = 15830, loss = 32.7008
2024-10-30 15:47:04: [2024-10-30 15:47:04] iter = 15840, loss = 13.5019
2024-10-30 15:47:08: [2024-10-30 15:47:08] iter = 15850, loss = 7.6828
2024-10-30 15:47:12: [2024-10-30 15:47:12] iter = 15860, loss = 5.2111
2024-10-30 15:47:15: [2024-10-30 15:47:15] iter = 15870, loss = 6.7652
2024-10-30 15:47:19: [2024-10-30 15:47:19] iter = 15880, loss = 4.6584
2024-10-30 15:47:24: [2024-10-30 15:47:24] iter = 15890, loss = 21.1415
2024-10-30 15:47:28: [2024-10-30 15:47:28] iter = 15900, loss = 59.0214
2024-10-30 15:47:31: [2024-10-30 15:47:31] iter = 15910, loss = 15.4330
2024-10-30 15:47:36: [2024-10-30 15:47:36] iter = 15920, loss = 13.0448
2024-10-30 15:47:40: [2024-10-30 15:47:40] iter = 15930, loss = 9.7367
2024-10-30 15:47:43: [2024-10-30 15:47:43] iter = 15940, loss = 13.9607
2024-10-30 15:47:48: [2024-10-30 15:47:48] iter = 15950, loss = 57.1338
2024-10-30 15:47:52: [2024-10-30 15:47:52] iter = 15960, loss = 4.4158
2024-10-30 15:47:56: [2024-10-30 15:47:56] iter = 15970, loss = 33.8985
2024-10-30 15:47:59: [2024-10-30 15:47:59] iter = 15980, loss = 6.5705
2024-10-30 15:48:04: [2024-10-30 15:48:04] iter = 15990, loss = 33.7630
2024-10-30 15:48:08: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 15:48:08: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 15:48:08: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 88722}
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/tissuemnist.npz
Using downloaded and verified file: /data/users/xiongyuxuan/.medmnist/tissuemnist.npz
Loaded the dataset:TissueMNIST
[2024-10-30 14:19:13] Evaluate_00: epoch = 1000 train time = 13 s train loss = 0.116640 train acc = 0.9875, test acc = 0.2771, test_sen =0.2511, test_spe =0.8959, test_f1 =0.2317
[2024-10-30 14:19:24] Evaluate_01: epoch = 1000 train time = 9 s train loss = 0.014271 train acc = 1.0000, test acc = 0.2751, test_sen =0.2456, test_spe =0.8957, test_f1 =0.2269
[2024-10-30 14:19:35] Evaluate_02: epoch = 1000 train time = 9 s train loss = 0.021281 train acc = 1.0000, test acc = 0.2638, test_sen =0.2447, test_spe =0.8945, test_f1 =0.2234
[2024-10-30 14:19:47] Evaluate_03: epoch = 1000 train time = 9 s train loss = 0.094566 train acc = 0.9875, test acc = 0.2609, test_sen =0.2423, test_spe =0.8942, test_f1 =0.2221
[2024-10-30 14:19:59] Evaluate_04: epoch = 1000 train time = 9 s train loss = 0.024134 train acc = 1.0000, test acc = 0.2692, test_sen =0.2475, test_spe =0.8950, test_f1 =0.2269
[2024-10-30 14:26:23] Evaluate_00: epoch = 1000 train time = 14 s train loss = 0.001757 train acc = 1.0000, test acc = 0.3329, test_sen =0.2981, test_spe =0.9041, test_f1 =0.2717
[2024-10-30 14:26:38] Evaluate_01: epoch = 1000 train time = 11 s train loss = 0.010275 train acc = 1.0000, test acc = 0.3383, test_sen =0.2952, test_spe =0.9048, test_f1 =0.2733
[2024-10-30 14:26:54] Evaluate_02: epoch = 1000 train time = 13 s train loss = 0.009124 train acc = 1.0000, test acc = 0.3220, test_sen =0.2975, test_spe =0.9034, test_f1 =0.2664
[2024-10-30 14:27:08] Evaluate_03: epoch = 1000 train time = 10 s train loss = 0.045883 train acc = 1.0000, test acc = 0.3178, test_sen =0.2885, test_spe =0.9025, test_f1 =0.2580
[2024-10-30 14:27:23] Evaluate_04: epoch = 1000 train time = 11 s train loss = 0.060082 train acc = 0.9875, test acc = 0.3344, test_sen =0.2950, test_spe =0.9045, test_f1 =0.2715
[2024-10-30 14:33:41] Evaluate_00: epoch = 1000 train time = 12 s train loss = 0.011675 train acc = 1.0000, test acc = 0.3932, test_sen =0.2818, test_spe =0.9080, test_f1 =0.2436
[2024-10-30 14:33:55] Evaluate_01: epoch = 1000 train time = 11 s train loss = 0.001751 train acc = 1.0000, test acc = 0.3781, test_sen =0.2709, test_spe =0.9056, test_f1 =0.2301
[2024-10-30 14:34:09] Evaluate_02: epoch = 1000 train time = 11 s train loss = 0.045261 train acc = 1.0000, test acc = 0.3726, test_sen =0.2747, test_spe =0.9046, test_f1 =0.2336
[2024-10-30 14:34:23] Evaluate_03: epoch = 1000 train time = 11 s train loss = 0.002335 train acc = 1.0000, test acc = 0.3877, test_sen =0.2814, test_spe =0.9070, test_f1 =0.2425
[2024-10-30 14:34:36] Evaluate_04: epoch = 1000 train time = 11 s train loss = 0.003858 train acc = 1.0000, test acc = 0.3828, test_sen =0.2819, test_spe =0.9067, test_f1 =0.2438
[2024-10-30 14:41:06] Evaluate_00: epoch = 1000 train time = 12 s train loss = 0.002808 train acc = 1.0000, test acc = 0.3936, test_sen =0.3043, test_spe =0.9109, test_f1 =0.2809
[2024-10-30 14:41:20] Evaluate_01: epoch = 1000 train time = 10 s train loss = 0.003073 train acc = 1.0000, test acc = 0.3716, test_sen =0.3037, test_spe =0.9089, test_f1 =0.2724
[2024-10-30 14:41:36] Evaluate_02: epoch = 1000 train time = 13 s train loss = 0.079999 train acc = 0.9875, test acc = 0.3837, test_sen =0.3032, test_spe =0.9101, test_f1 =0.2751
[2024-10-30 14:41:52] Evaluate_03: epoch = 1000 train time = 12 s train loss = 0.003287 train acc = 1.0000, test acc = 0.3751, test_sen =0.2989, test_spe =0.9091, test_f1 =0.2690
[2024-10-30 14:42:07] Evaluate_04: epoch = 1000 train time = 11 s train loss = 0.003019 train acc = 1.0000, test acc = 0.3722, test_sen =0.3046, test_spe =0.9092, test_f1 =0.2747
[2024-10-30 14:48:58] Evaluate_00: epoch = 1000 train time = 13 s train loss = 0.004970 train acc = 1.0000, test acc = 0.3490, test_sen =0.3153, test_spe =0.9079, test_f1 =0.2688
[2024-10-30 14:49:15] Evaluate_01: epoch = 1000 train time = 13 s train loss = 0.023914 train acc = 1.0000, test acc = 0.3500, test_sen =0.3168, test_spe =0.9080, test_f1 =0.2718
[2024-10-30 14:49:31] Evaluate_02: epoch = 1000 train time = 13 s train loss = 0.093835 train acc = 1.0000, test acc = 0.3544, test_sen =0.3184, test_spe =0.9083, test_f1 =0.2751
[2024-10-30 14:49:50] Evaluate_03: epoch = 1000 train time = 15 s train loss = 0.002772 train acc = 1.0000, test acc = 0.3418, test_sen =0.3119, test_spe =0.9073, test_f1 =0.2646
[2024-10-30 14:50:09] Evaluate_04: epoch = 1000 train time = 16 s train loss = 0.053780 train acc = 1.0000, test acc = 0.3500, test_sen =0.3209, test_spe =0.9082, test_f1 =0.2724
[2024-10-30 14:59:52] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.003087 train acc = 1.0000, test acc = 0.3727, test_sen =0.2972, test_spe =0.9089, test_f1 =0.2667
[2024-10-30 15:00:26] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.001763 train acc = 1.0000, test acc = 0.3745, test_sen =0.2972, test_spe =0.9089, test_f1 =0.2697
[2024-10-30 15:00:56] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.040068 train acc = 1.0000, test acc = 0.3796, test_sen =0.2966, test_spe =0.9093, test_f1 =0.2653
[2024-10-30 15:01:28] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.007979 train acc = 1.0000, test acc = 0.3814, test_sen =0.2968, test_spe =0.9093, test_f1 =0.2685
[2024-10-30 15:01:59] Evaluate_04: epoch = 1000 train time = 25 s train loss = 0.009566 train acc = 1.0000, test acc = 0.3870, test_sen =0.2999, test_spe =0.9100, test_f1 =0.2708
[2024-10-30 15:16:08] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.004524 train acc = 1.0000, test acc = 0.3735, test_sen =0.3139, test_spe =0.9096, test_f1 =0.2900
[2024-10-30 15:16:39] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.049207 train acc = 0.9875, test acc = 0.3729, test_sen =0.3167, test_spe =0.9099, test_f1 =0.2903
[2024-10-30 15:17:15] Evaluate_02: epoch = 1000 train time = 30 s train loss = 0.033132 train acc = 1.0000, test acc = 0.3746, test_sen =0.3149, test_spe =0.9098, test_f1 =0.2905
[2024-10-30 15:17:49] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.043840 train acc = 1.0000, test acc = 0.3757, test_sen =0.3174, test_spe =0.9103, test_f1 =0.2898
[2024-10-30 15:18:29] Evaluate_04: epoch = 1000 train time = 32 s train loss = 0.004216 train acc = 1.0000, test acc = 0.3739, test_sen =0.3221, test_spe =0.9102, test_f1 =0.2920
[2024-10-30 15:32:59] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.015911 train acc = 1.0000, test acc = 0.2969, test_sen =0.3013, test_spe =0.9007, test_f1 =0.2518
[2024-10-30 15:33:25] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.011882 train acc = 1.0000, test acc = 0.3200, test_sen =0.3090, test_spe =0.9040, test_f1 =0.2662
[2024-10-30 15:33:59] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.027876 train acc = 1.0000, test acc = 0.3166, test_sen =0.3099, test_spe =0.9039, test_f1 =0.2668
[2024-10-30 15:34:29] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.035558 train acc = 1.0000, test acc = 0.3100, test_sen =0.3113, test_spe =0.9029, test_f1 =0.2608
[2024-10-30 15:35:03] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.002417 train acc = 1.0000, test acc = 0.2900, test_sen =0.3051, test_spe =0.9004, test_f1 =0.2467
[2024-10-30 15:48:40] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.003158 train acc = 1.0000, test acc = 0.3858, test_sen =0.3083, test_spe =0.9100, test_f1 =0.2743
[2024-10-30 15:49:08] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.064777 train acc = 0.9875, test acc = 0.3782, test_sen =0.3140, test_spe =0.9099, test_f1 =0.2784
[2024-10-30 15:49:37] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.031408 train acc = 1.0000, test acc = 0.3779, test_sen =0.3062, test_spe =0.9092, test_f1 =0.2724
[2024-10-30 15:50:09] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.004927 train acc = 1.0000, test acc = 0.3680, test_sen =0.3098, test_spe =0.9086, test_f1 =0.2735
[2024-10-30 15:50:43] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.011608 train acc = 1.0000, test acc = 0.3936, test_sen =0.3181, test_spe =0.9107, test_f1 =0.2871/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:50:43: Evaluate 5 random ConvNet, ACCmean = 0.3807 ACCstd = 0.0086
-------------------------
2024-10-30 15:50:43: Evaluate 5 random ConvNet, SENmean = 0.3113 SENstd = 0.0042
-------------------------
2024-10-30 15:50:43: Evaluate 5 random ConvNet, SPEmean = 0.9097 SPEstd = 0.0007
-------------------------
2024-10-30 15:50:43: Evaluate 5 random ConvNet, F!mean = 0.2772 F!std = 0.0054
-------------------------
2024-10-30 15:50:43: Evaluate 5 random ConvNet, mean = 0.3807 std = 0.0086
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:50:44: [2024-10-30 15:50:44] iter = 16000, loss = 24.9144
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 15:50:49: [2024-10-30 15:50:49] iter = 16010, loss = 4.3581
2024-10-30 15:50:55: [2024-10-30 15:50:55] iter = 16020, loss = 3.5355
2024-10-30 15:50:59: [2024-10-30 15:50:59] iter = 16030, loss = 21.7994
2024-10-30 15:51:04: [2024-10-30 15:51:04] iter = 16040, loss = 15.3427
2024-10-30 15:51:10: [2024-10-30 15:51:10] iter = 16050, loss = 35.0618
2024-10-30 15:51:15: [2024-10-30 15:51:15] iter = 16060, loss = 12.9285
2024-10-30 15:51:19: [2024-10-30 15:51:19] iter = 16070, loss = 21.8012
2024-10-30 15:51:23: [2024-10-30 15:51:23] iter = 16080, loss = 4.3056
2024-10-30 15:51:26: [2024-10-30 15:51:26] iter = 16090, loss = 4.6834
2024-10-30 15:51:30: [2024-10-30 15:51:30] iter = 16100, loss = 3.8088
2024-10-30 15:51:33: [2024-10-30 15:51:33] iter = 16110, loss = 63.0778
2024-10-30 15:51:38: [2024-10-30 15:51:38] iter = 16120, loss = 30.1558
2024-10-30 15:51:42: [2024-10-30 15:51:42] iter = 16130, loss = 5.0378
2024-10-30 15:51:46: [2024-10-30 15:51:46] iter = 16140, loss = 52.4875
2024-10-30 15:51:51: [2024-10-30 15:51:51] iter = 16150, loss = 16.3185
2024-10-30 15:51:55: [2024-10-30 15:51:55] iter = 16160, loss = 23.0150
2024-10-30 15:52:01: [2024-10-30 15:52:01] iter = 16170, loss = 25.1785
2024-10-30 15:52:05: [2024-10-30 15:52:05] iter = 16180, loss = 4.5356
2024-10-30 15:52:09: [2024-10-30 15:52:09] iter = 16190, loss = 42.7032
2024-10-30 15:52:14: [2024-10-30 15:52:14] iter = 16200, loss = 5.1136
2024-10-30 15:52:19: [2024-10-30 15:52:19] iter = 16210, loss = 5.2505
2024-10-30 15:52:24: [2024-10-30 15:52:24] iter = 16220, loss = 3.0628
2024-10-30 15:52:27: [2024-10-30 15:52:27] iter = 16230, loss = 5.1836
2024-10-30 15:52:32: [2024-10-30 15:52:32] iter = 16240, loss = 25.5063
2024-10-30 15:52:37: [2024-10-30 15:52:37] iter = 16250, loss = 6.2898
2024-10-30 15:52:41: [2024-10-30 15:52:41] iter = 16260, loss = 39.9331
2024-10-30 15:52:47: [2024-10-30 15:52:47] iter = 16270, loss = 4.7061
2024-10-30 15:52:50: [2024-10-30 15:52:50] iter = 16280, loss = 25.4284
2024-10-30 15:52:54: [2024-10-30 15:52:54] iter = 16290, loss = 8.2730
2024-10-30 15:52:59: [2024-10-30 15:52:59] iter = 16300, loss = 6.9547
2024-10-30 15:53:03: [2024-10-30 15:53:03] iter = 16310, loss = 10.8594
2024-10-30 15:53:08: [2024-10-30 15:53:08] iter = 16320, loss = 8.4502
2024-10-30 15:53:13: [2024-10-30 15:53:13] iter = 16330, loss = 12.1077
2024-10-30 15:53:18: [2024-10-30 15:53:18] iter = 16340, loss = 11.9819
2024-10-30 15:53:22: [2024-10-30 15:53:22] iter = 16350, loss = 29.3000
2024-10-30 15:53:26: [2024-10-30 15:53:26] iter = 16360, loss = 3.6374
2024-10-30 15:53:31: [2024-10-30 15:53:31] iter = 16370, loss = 5.2576
2024-10-30 15:53:35: [2024-10-30 15:53:35] iter = 16380, loss = 27.2903
2024-10-30 15:53:40: [2024-10-30 15:53:40] iter = 16390, loss = 10.2212
2024-10-30 15:53:45: [2024-10-30 15:53:45] iter = 16400, loss = 18.1873
2024-10-30 15:53:50: [2024-10-30 15:53:50] iter = 16410, loss = 7.6551
2024-10-30 15:53:55: [2024-10-30 15:53:55] iter = 16420, loss = 39.5807
2024-10-30 15:53:59: [2024-10-30 15:53:59] iter = 16430, loss = 4.9789
2024-10-30 15:54:04: [2024-10-30 15:54:04] iter = 16440, loss = 16.0644
2024-10-30 15:54:09: [2024-10-30 15:54:09] iter = 16450, loss = 4.3463
2024-10-30 15:54:14: [2024-10-30 15:54:14] iter = 16460, loss = 4.7407
2024-10-30 15:54:18: [2024-10-30 15:54:18] iter = 16470, loss = 28.1036
2024-10-30 15:54:22: [2024-10-30 15:54:22] iter = 16480, loss = 11.6498
2024-10-30 15:54:27: [2024-10-30 15:54:27] iter = 16490, loss = 13.0652
2024-10-30 15:54:32: [2024-10-30 15:54:32] iter = 16500, loss = 4.9401
2024-10-30 15:54:37: [2024-10-30 15:54:37] iter = 16510, loss = 8.1113
2024-10-30 15:54:41: [2024-10-30 15:54:41] iter = 16520, loss = 13.0461
2024-10-30 15:54:46: [2024-10-30 15:54:46] iter = 16530, loss = 72.4255
2024-10-30 15:54:52: [2024-10-30 15:54:52] iter = 16540, loss = 6.0833
2024-10-30 15:54:56: [2024-10-30 15:54:56] iter = 16550, loss = 20.8239
2024-10-30 15:55:01: [2024-10-30 15:55:01] iter = 16560, loss = 9.9500
2024-10-30 15:55:06: [2024-10-30 15:55:06] iter = 16570, loss = 9.0565
2024-10-30 15:55:11: [2024-10-30 15:55:11] iter = 16580, loss = 41.2353
2024-10-30 15:55:15: [2024-10-30 15:55:15] iter = 16590, loss = 27.4563
2024-10-30 15:55:21: [2024-10-30 15:55:21] iter = 16600, loss = 9.1091
2024-10-30 15:55:26: [2024-10-30 15:55:26] iter = 16610, loss = 35.2540
2024-10-30 15:55:31: [2024-10-30 15:55:31] iter = 16620, loss = 4.6981
2024-10-30 15:55:36: [2024-10-30 15:55:36] iter = 16630, loss = 10.4570
2024-10-30 15:55:40: [2024-10-30 15:55:40] iter = 16640, loss = 64.0307
2024-10-30 15:55:45: [2024-10-30 15:55:45] iter = 16650, loss = 12.0656
2024-10-30 15:55:50: [2024-10-30 15:55:50] iter = 16660, loss = 4.4678
2024-10-30 15:55:56: [2024-10-30 15:55:56] iter = 16670, loss = 16.0739
2024-10-30 15:56:01: [2024-10-30 15:56:01] iter = 16680, loss = 3.2762
2024-10-30 15:56:06: [2024-10-30 15:56:06] iter = 16690, loss = 10.1051
2024-10-30 15:56:12: [2024-10-30 15:56:12] iter = 16700, loss = 4.1502
2024-10-30 15:56:17: [2024-10-30 15:56:17] iter = 16710, loss = 7.3558
2024-10-30 15:56:23: [2024-10-30 15:56:23] iter = 16720, loss = 13.6762
2024-10-30 15:56:28: [2024-10-30 15:56:28] iter = 16730, loss = 62.9928
2024-10-30 15:56:32: [2024-10-30 15:56:32] iter = 16740, loss = 5.7235
2024-10-30 15:56:37: [2024-10-30 15:56:37] iter = 16750, loss = 8.8805
2024-10-30 15:56:42: [2024-10-30 15:56:42] iter = 16760, loss = 16.5098
2024-10-30 15:56:46: [2024-10-30 15:56:46] iter = 16770, loss = 55.7893
2024-10-30 15:56:52: [2024-10-30 15:56:52] iter = 16780, loss = 9.9223
2024-10-30 15:56:57: [2024-10-30 15:56:57] iter = 16790, loss = 4.6001
2024-10-30 15:57:02: [2024-10-30 15:57:02] iter = 16800, loss = 4.2809
2024-10-30 15:57:07: [2024-10-30 15:57:07] iter = 16810, loss = 4.7372
2024-10-30 15:57:12: [2024-10-30 15:57:12] iter = 16820, loss = 8.5909
2024-10-30 15:57:15: [2024-10-30 15:57:15] iter = 16830, loss = 6.1316
2024-10-30 15:57:19: [2024-10-30 15:57:19] iter = 16840, loss = 32.4732
2024-10-30 15:57:23: [2024-10-30 15:57:23] iter = 16850, loss = 15.9607
2024-10-30 15:57:28: [2024-10-30 15:57:28] iter = 16860, loss = 12.5400
2024-10-30 15:57:32: [2024-10-30 15:57:32] iter = 16870, loss = 13.4837
2024-10-30 15:57:37: [2024-10-30 15:57:37] iter = 16880, loss = 41.3615
2024-10-30 15:57:42: [2024-10-30 15:57:42] iter = 16890, loss = 41.0494
2024-10-30 15:57:46: [2024-10-30 15:57:46] iter = 16900, loss = 4.5902
2024-10-30 15:57:51: [2024-10-30 15:57:51] iter = 16910, loss = 34.3818
2024-10-30 15:57:55: [2024-10-30 15:57:55] iter = 16920, loss = 11.8213
2024-10-30 15:57:59: [2024-10-30 15:57:59] iter = 16930, loss = 55.1466
2024-10-30 15:58:04: [2024-10-30 15:58:04] iter = 16940, loss = 21.5321
2024-10-30 15:58:08: [2024-10-30 15:58:08] iter = 16950, loss = 4.7584
2024-10-30 15:58:12: [2024-10-30 15:58:12] iter = 16960, loss = 7.0601
2024-10-30 15:58:17: [2024-10-30 15:58:17] iter = 16970, loss = 7.1211
2024-10-30 15:58:22: [2024-10-30 15:58:22] iter = 16980, loss = 49.4742
2024-10-30 15:58:27: [2024-10-30 15:58:27] iter = 16990, loss = 4.4894
2024-10-30 15:58:30: [2024-10-30 15:58:30] iter = 17000, loss = 6.3700
2024-10-30 15:58:33: [2024-10-30 15:58:33] iter = 17010, loss = 5.4400
2024-10-30 15:58:38: [2024-10-30 15:58:38] iter = 17020, loss = 25.5541
2024-10-30 15:58:42: [2024-10-30 15:58:42] iter = 17030, loss = 20.7706
2024-10-30 15:58:47: [2024-10-30 15:58:47] iter = 17040, loss = 8.5838
2024-10-30 15:58:51: [2024-10-30 15:58:51] iter = 17050, loss = 12.3593
2024-10-30 15:58:56: [2024-10-30 15:58:56] iter = 17060, loss = 6.0643
2024-10-30 15:59:01: [2024-10-30 15:59:01] iter = 17070, loss = 11.3497
2024-10-30 15:59:06: [2024-10-30 15:59:06] iter = 17080, loss = 95.3676
2024-10-30 15:59:10: [2024-10-30 15:59:10] iter = 17090, loss = 8.7589
2024-10-30 15:59:14: [2024-10-30 15:59:14] iter = 17100, loss = 7.6657
2024-10-30 15:59:19: [2024-10-30 15:59:19] iter = 17110, loss = 27.3491
2024-10-30 15:59:24: [2024-10-30 15:59:24] iter = 17120, loss = 39.5552
2024-10-30 15:59:29: [2024-10-30 15:59:29] iter = 17130, loss = 4.4523
2024-10-30 15:59:34: [2024-10-30 15:59:34] iter = 17140, loss = 12.5329
2024-10-30 15:59:39: [2024-10-30 15:59:39] iter = 17150, loss = 15.0569
2024-10-30 15:59:45: [2024-10-30 15:59:45] iter = 17160, loss = 12.5010
2024-10-30 15:59:49: [2024-10-30 15:59:49] iter = 17170, loss = 4.4185
2024-10-30 15:59:55: [2024-10-30 15:59:55] iter = 17180, loss = 3.5378
2024-10-30 15:59:58: [2024-10-30 15:59:58] iter = 17190, loss = 11.1117
2024-10-30 16:00:01: [2024-10-30 16:00:01] iter = 17200, loss = 7.2428
2024-10-30 16:00:05: [2024-10-30 16:00:05] iter = 17210, loss = 4.5949
2024-10-30 16:00:09: [2024-10-30 16:00:09] iter = 17220, loss = 5.9162
2024-10-30 16:00:14: [2024-10-30 16:00:14] iter = 17230, loss = 6.6319
2024-10-30 16:00:19: [2024-10-30 16:00:19] iter = 17240, loss = 15.4382
2024-10-30 16:00:25: [2024-10-30 16:00:25] iter = 17250, loss = 4.1419
2024-10-30 16:00:29: [2024-10-30 16:00:29] iter = 17260, loss = 58.4663
2024-10-30 16:00:34: [2024-10-30 16:00:34] iter = 17270, loss = 3.9488
2024-10-30 16:00:39: [2024-10-30 16:00:39] iter = 17280, loss = 8.8298
2024-10-30 16:00:43: [2024-10-30 16:00:43] iter = 17290, loss = 7.2550
2024-10-30 16:00:47: [2024-10-30 16:00:47] iter = 17300, loss = 9.2889
2024-10-30 16:00:52: [2024-10-30 16:00:52] iter = 17310, loss = 7.0769
2024-10-30 16:00:57: [2024-10-30 16:00:57] iter = 17320, loss = 3.6955
2024-10-30 16:01:02: [2024-10-30 16:01:02] iter = 17330, loss = 4.9141
2024-10-30 16:01:07: [2024-10-30 16:01:07] iter = 17340, loss = 11.2856
2024-10-30 16:01:11: [2024-10-30 16:01:11] iter = 17350, loss = 7.3396
2024-10-30 16:01:16: [2024-10-30 16:01:16] iter = 17360, loss = 5.0704
2024-10-30 16:01:21: [2024-10-30 16:01:21] iter = 17370, loss = 7.5485
2024-10-30 16:01:25: [2024-10-30 16:01:25] iter = 17380, loss = 18.0596
2024-10-30 16:01:31: [2024-10-30 16:01:31] iter = 17390, loss = 4.8973
2024-10-30 16:01:36: [2024-10-30 16:01:36] iter = 17400, loss = 53.3204
2024-10-30 16:01:41: [2024-10-30 16:01:41] iter = 17410, loss = 4.1265
2024-10-30 16:01:46: [2024-10-30 16:01:46] iter = 17420, loss = 7.9913
2024-10-30 16:01:51: [2024-10-30 16:01:51] iter = 17430, loss = 6.1861
2024-10-30 16:01:56: [2024-10-30 16:01:56] iter = 17440, loss = 18.7312
2024-10-30 16:02:01: [2024-10-30 16:02:01] iter = 17450, loss = 21.8088
2024-10-30 16:02:05: [2024-10-30 16:02:05] iter = 17460, loss = 16.3076
2024-10-30 16:02:08: [2024-10-30 16:02:08] iter = 17470, loss = 15.7870
2024-10-30 16:02:13: [2024-10-30 16:02:13] iter = 17480, loss = 3.4084
2024-10-30 16:02:18: [2024-10-30 16:02:18] iter = 17490, loss = 46.2611
2024-10-30 16:02:23: [2024-10-30 16:02:23] iter = 17500, loss = 5.5744
2024-10-30 16:02:27: [2024-10-30 16:02:27] iter = 17510, loss = 17.5230
2024-10-30 16:02:31: [2024-10-30 16:02:31] iter = 17520, loss = 12.8306
2024-10-30 16:02:36: [2024-10-30 16:02:36] iter = 17530, loss = 16.8977
2024-10-30 16:02:41: [2024-10-30 16:02:41] iter = 17540, loss = 16.7664
2024-10-30 16:02:45: [2024-10-30 16:02:45] iter = 17550, loss = 15.9176
2024-10-30 16:02:50: [2024-10-30 16:02:50] iter = 17560, loss = 5.5512
2024-10-30 16:02:56: [2024-10-30 16:02:56] iter = 17570, loss = 27.3030
2024-10-30 16:03:00: [2024-10-30 16:03:00] iter = 17580, loss = 11.9128
2024-10-30 16:03:03: [2024-10-30 16:03:03] iter = 17590, loss = 16.5532
2024-10-30 16:03:08: [2024-10-30 16:03:08] iter = 17600, loss = 29.1836
2024-10-30 16:03:11: [2024-10-30 16:03:11] iter = 17610, loss = 9.9938
2024-10-30 16:03:16: [2024-10-30 16:03:16] iter = 17620, loss = 33.4253
2024-10-30 16:03:22: [2024-10-30 16:03:22] iter = 17630, loss = 10.8273
2024-10-30 16:03:27: [2024-10-30 16:03:27] iter = 17640, loss = 4.6932
2024-10-30 16:03:31: [2024-10-30 16:03:31] iter = 17650, loss = 23.1500
2024-10-30 16:03:36: [2024-10-30 16:03:36] iter = 17660, loss = 6.0974
2024-10-30 16:03:40: [2024-10-30 16:03:40] iter = 17670, loss = 4.7295
2024-10-30 16:03:44: [2024-10-30 16:03:44] iter = 17680, loss = 9.5943
2024-10-30 16:03:48: [2024-10-30 16:03:48] iter = 17690, loss = 4.1803
2024-10-30 16:03:51: [2024-10-30 16:03:51] iter = 17700, loss = 4.4042
2024-10-30 16:03:55: [2024-10-30 16:03:55] iter = 17710, loss = 26.6822
2024-10-30 16:04:00: [2024-10-30 16:04:00] iter = 17720, loss = 50.1611
2024-10-30 16:04:04: [2024-10-30 16:04:04] iter = 17730, loss = 5.9581
2024-10-30 16:04:08: [2024-10-30 16:04:08] iter = 17740, loss = 4.0256
2024-10-30 16:04:14: [2024-10-30 16:04:14] iter = 17750, loss = 4.3732
2024-10-30 16:04:19: [2024-10-30 16:04:19] iter = 17760, loss = 3.9534
2024-10-30 16:04:23: [2024-10-30 16:04:23] iter = 17770, loss = 26.0240
2024-10-30 16:04:28: [2024-10-30 16:04:28] iter = 17780, loss = 24.9745
2024-10-30 16:04:32: [2024-10-30 16:04:32] iter = 17790, loss = 13.2915
2024-10-30 16:04:36: [2024-10-30 16:04:36] iter = 17800, loss = 6.8497
2024-10-30 16:04:41: [2024-10-30 16:04:41] iter = 17810, loss = 4.9321
2024-10-30 16:04:45: [2024-10-30 16:04:45] iter = 17820, loss = 8.2476
2024-10-30 16:04:49: [2024-10-30 16:04:49] iter = 17830, loss = 21.2299
2024-10-30 16:04:53: [2024-10-30 16:04:53] iter = 17840, loss = 16.3973
2024-10-30 16:04:57: [2024-10-30 16:04:57] iter = 17850, loss = 47.4334
2024-10-30 16:05:01: [2024-10-30 16:05:01] iter = 17860, loss = 4.5937
2024-10-30 16:05:05: [2024-10-30 16:05:05] iter = 17870, loss = 24.6334
2024-10-30 16:05:09: [2024-10-30 16:05:09] iter = 17880, loss = 5.0578
2024-10-30 16:05:14: [2024-10-30 16:05:14] iter = 17890, loss = 66.9798
2024-10-30 16:05:18: [2024-10-30 16:05:18] iter = 17900, loss = 4.5218
2024-10-30 16:05:22: [2024-10-30 16:05:22] iter = 17910, loss = 4.7230
2024-10-30 16:05:26: [2024-10-30 16:05:26] iter = 17920, loss = 25.0489
2024-10-30 16:05:31: [2024-10-30 16:05:31] iter = 17930, loss = 7.1332
2024-10-30 16:05:35: [2024-10-30 16:05:35] iter = 17940, loss = 3.2255
2024-10-30 16:05:40: [2024-10-30 16:05:40] iter = 17950, loss = 7.4823
2024-10-30 16:05:44: [2024-10-30 16:05:44] iter = 17960, loss = 22.5580
2024-10-30 16:05:49: [2024-10-30 16:05:49] iter = 17970, loss = 25.1357
2024-10-30 16:05:52: [2024-10-30 16:05:52] iter = 17980, loss = 44.8122
2024-10-30 16:05:57: [2024-10-30 16:05:57] iter = 17990, loss = 4.3651
2024-10-30 16:06:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 16:06:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:06:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60576}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:08:47: Evaluate 5 random ConvNet, ACCmean = 0.2533 ACCstd = 0.0060
-------------------------
2024-10-30 16:08:47: Evaluate 5 random ConvNet, SENmean = 0.2815 SENstd = 0.0024
-------------------------
2024-10-30 16:08:47: Evaluate 5 random ConvNet, SPEmean = 0.8958 SPEstd = 0.0005
-------------------------
2024-10-30 16:08:47: Evaluate 5 random ConvNet, F!mean = 0.2201 F!std = 0.0036
-------------------------
2024-10-30 16:08:47: Evaluate 5 random ConvNet, mean = 0.2533 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:08:47: [2024-10-30 16:08:47] iter = 18000, loss = 31.0914
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:08:50: [2024-10-30 16:08:50] iter = 18010, loss = 19.6776
2024-10-30 16:08:53: [2024-10-30 16:08:53] iter = 18020, loss = 26.8632
2024-10-30 16:08:57: [2024-10-30 16:08:57] iter = 18030, loss = 7.3831
2024-10-30 16:09:01: [2024-10-30 16:09:01] iter = 18040, loss = 38.3040
2024-10-30 16:09:05: [2024-10-30 16:09:05] iter = 18050, loss = 49.3335
2024-10-30 16:09:09: [2024-10-30 16:09:09] iter = 18060, loss = 13.0269
2024-10-30 16:09:13: [2024-10-30 16:09:13] iter = 18070, loss = 5.8560
2024-10-30 16:09:19: [2024-10-30 16:09:19] iter = 18080, loss = 4.4090
2024-10-30 16:09:23: [2024-10-30 16:09:23] iter = 18090, loss = 5.1143
2024-10-30 16:09:27: [2024-10-30 16:09:27] iter = 18100, loss = 48.5936
2024-10-30 16:09:31: [2024-10-30 16:09:31] iter = 18110, loss = 36.1477
2024-10-30 16:09:36: [2024-10-30 16:09:36] iter = 18120, loss = 3.5270
2024-10-30 16:09:39: [2024-10-30 16:09:39] iter = 18130, loss = 15.5177
2024-10-30 16:09:44: [2024-10-30 16:09:44] iter = 18140, loss = 59.9762
2024-10-30 16:09:50: [2024-10-30 16:09:50] iter = 18150, loss = 45.2941
2024-10-30 16:09:55: [2024-10-30 16:09:55] iter = 18160, loss = 26.4739
2024-10-30 16:09:59: [2024-10-30 16:09:59] iter = 18170, loss = 7.3159
2024-10-30 16:10:03: [2024-10-30 16:10:03] iter = 18180, loss = 17.0712
2024-10-30 16:10:08: [2024-10-30 16:10:08] iter = 18190, loss = 48.0790
2024-10-30 16:10:12: [2024-10-30 16:10:12] iter = 18200, loss = 4.8253
2024-10-30 16:10:17: [2024-10-30 16:10:17] iter = 18210, loss = 7.2513
2024-10-30 16:10:21: [2024-10-30 16:10:21] iter = 18220, loss = 29.1635
2024-10-30 16:10:25: [2024-10-30 16:10:25] iter = 18230, loss = 50.6127
2024-10-30 16:10:31: [2024-10-30 16:10:31] iter = 18240, loss = 5.4266
2024-10-30 16:10:35: [2024-10-30 16:10:35] iter = 18250, loss = 10.0415
2024-10-30 16:10:40: [2024-10-30 16:10:40] iter = 18260, loss = 10.2934
2024-10-30 16:10:44: [2024-10-30 16:10:44] iter = 18270, loss = 4.2751
2024-10-30 16:10:48: [2024-10-30 16:10:48] iter = 18280, loss = 50.2894
2024-10-30 16:10:52: [2024-10-30 16:10:52] iter = 18290, loss = 21.1228
2024-10-30 16:10:57: [2024-10-30 16:10:57] iter = 18300, loss = 12.2140
2024-10-30 16:11:00: [2024-10-30 16:11:00] iter = 18310, loss = 12.0883
2024-10-30 16:11:05: [2024-10-30 16:11:05] iter = 18320, loss = 36.6452
2024-10-30 16:11:09: [2024-10-30 16:11:09] iter = 18330, loss = 82.5835
2024-10-30 16:11:13: [2024-10-30 16:11:13] iter = 18340, loss = 15.8379
2024-10-30 16:11:17: [2024-10-30 16:11:17] iter = 18350, loss = 4.6105
2024-10-30 16:11:21: [2024-10-30 16:11:21] iter = 18360, loss = 3.7239
2024-10-30 16:11:26: [2024-10-30 16:11:26] iter = 18370, loss = 20.6835
2024-10-30 16:11:28: [2024-10-30 16:11:28] iter = 18380, loss = 6.4839
2024-10-30 16:11:33: [2024-10-30 16:11:33] iter = 18390, loss = 5.8730
2024-10-30 16:11:38: [2024-10-30 16:11:38] iter = 18400, loss = 4.2538
2024-10-30 16:11:43: [2024-10-30 16:11:43] iter = 18410, loss = 59.0217
2024-10-30 16:11:48: [2024-10-30 16:11:48] iter = 18420, loss = 11.6860
2024-10-30 16:11:51: [2024-10-30 16:11:51] iter = 18430, loss = 34.7844
2024-10-30 16:11:56: [2024-10-30 16:11:56] iter = 18440, loss = 8.8684
2024-10-30 16:12:00: [2024-10-30 16:12:00] iter = 18450, loss = 18.7509
2024-10-30 16:12:04: [2024-10-30 16:12:04] iter = 18460, loss = 6.4273
2024-10-30 16:12:08: [2024-10-30 16:12:08] iter = 18470, loss = 13.9524
2024-10-30 16:12:13: [2024-10-30 16:12:12] iter = 18480, loss = 45.4142
2024-10-30 16:12:18: [2024-10-30 16:12:18] iter = 18490, loss = 15.4511
2024-10-30 16:12:23: [2024-10-30 16:12:23] iter = 18500, loss = 16.0727
2024-10-30 16:12:28: [2024-10-30 16:12:28] iter = 18510, loss = 17.5087
2024-10-30 16:12:33: [2024-10-30 16:12:33] iter = 18520, loss = 5.0429
2024-10-30 16:12:38: [2024-10-30 16:12:38] iter = 18530, loss = 17.8923
2024-10-30 16:12:42: [2024-10-30 16:12:42] iter = 18540, loss = 49.5440
2024-10-30 16:12:46: [2024-10-30 16:12:46] iter = 18550, loss = 7.4183
2024-10-30 16:12:50: [2024-10-30 16:12:50] iter = 18560, loss = 21.1352
2024-10-30 16:12:55: [2024-10-30 16:12:55] iter = 18570, loss = 11.9705
2024-10-30 16:12:59: [2024-10-30 16:12:59] iter = 18580, loss = 46.6954
2024-10-30 16:13:03: [2024-10-30 16:13:03] iter = 18590, loss = 26.3315
2024-10-30 16:13:08: [2024-10-30 16:13:08] iter = 18600, loss = 45.5267
2024-10-30 16:13:12: [2024-10-30 16:13:12] iter = 18610, loss = 40.2452
2024-10-30 16:13:17: [2024-10-30 16:13:17] iter = 18620, loss = 29.9202
2024-10-30 16:13:21: [2024-10-30 16:13:21] iter = 18630, loss = 6.2969
2024-10-30 16:13:26: [2024-10-30 16:13:26] iter = 18640, loss = 11.5068
2024-10-30 16:13:31: [2024-10-30 16:13:31] iter = 18650, loss = 16.8371
2024-10-30 16:13:36: [2024-10-30 16:13:36] iter = 18660, loss = 5.5036
2024-10-30 16:13:41: [2024-10-30 16:13:41] iter = 18670, loss = 7.9307
2024-10-30 16:13:46: [2024-10-30 16:13:46] iter = 18680, loss = 4.7823
2024-10-30 16:13:51: [2024-10-30 16:13:51] iter = 18690, loss = 32.8616
2024-10-30 16:13:56: [2024-10-30 16:13:56] iter = 18700, loss = 28.8381
2024-10-30 16:14:01: [2024-10-30 16:14:01] iter = 18710, loss = 51.0905
2024-10-30 16:14:05: [2024-10-30 16:14:05] iter = 18720, loss = 30.2520
2024-10-30 16:14:10: [2024-10-30 16:14:10] iter = 18730, loss = 31.7175
2024-10-30 16:14:15: [2024-10-30 16:14:15] iter = 18740, loss = 20.3842
2024-10-30 16:14:19: [2024-10-30 16:14:19] iter = 18750, loss = 4.0171
2024-10-30 16:14:24: [2024-10-30 16:14:24] iter = 18760, loss = 3.5475
2024-10-30 16:14:29: [2024-10-30 16:14:29] iter = 18770, loss = 6.3313
2024-10-30 16:14:34: [2024-10-30 16:14:34] iter = 18780, loss = 7.7712
2024-10-30 16:14:38: [2024-10-30 16:14:38] iter = 18790, loss = 10.1662
2024-10-30 16:14:42: [2024-10-30 16:14:42] iter = 18800, loss = 52.8478
2024-10-30 16:14:47: [2024-10-30 16:14:47] iter = 18810, loss = 11.3096
2024-10-30 16:14:52: [2024-10-30 16:14:52] iter = 18820, loss = 41.7084
2024-10-30 16:14:56: [2024-10-30 16:14:56] iter = 18830, loss = 9.9464
2024-10-30 16:15:01: [2024-10-30 16:15:01] iter = 18840, loss = 12.8674
2024-10-30 16:15:04: [2024-10-30 16:15:04] iter = 18850, loss = 27.4624
2024-10-30 16:15:09: [2024-10-30 16:15:09] iter = 18860, loss = 5.8605
2024-10-30 16:15:14: [2024-10-30 16:15:14] iter = 18870, loss = 23.1437
2024-10-30 16:15:20: [2024-10-30 16:15:20] iter = 18880, loss = 37.4405
2024-10-30 16:15:23: [2024-10-30 16:15:23] iter = 18890, loss = 4.6502
2024-10-30 16:15:29: [2024-10-30 16:15:29] iter = 18900, loss = 5.6909
2024-10-30 16:15:33: [2024-10-30 16:15:33] iter = 18910, loss = 17.8878
2024-10-30 16:15:37: [2024-10-30 16:15:37] iter = 18920, loss = 32.0058
2024-10-30 16:15:41: [2024-10-30 16:15:41] iter = 18930, loss = 4.6183
2024-10-30 16:15:46: [2024-10-30 16:15:46] iter = 18940, loss = 17.5478
2024-10-30 16:15:50: [2024-10-30 16:15:50] iter = 18950, loss = 4.3775
2024-10-30 16:15:55: [2024-10-30 16:15:55] iter = 18960, loss = 11.2941
2024-10-30 16:16:00: [2024-10-30 16:16:00] iter = 18970, loss = 8.6699
2024-10-30 16:16:04: [2024-10-30 16:16:04] iter = 18980, loss = 7.0222
2024-10-30 16:16:09: [2024-10-30 16:16:09] iter = 18990, loss = 11.7583
2024-10-30 16:16:12: [2024-10-30 16:16:12] iter = 19000, loss = 8.8746
2024-10-30 16:16:17: [2024-10-30 16:16:17] iter = 19010, loss = 12.1187
2024-10-30 16:16:22: [2024-10-30 16:16:22] iter = 19020, loss = 22.1019
2024-10-30 16:16:26: [2024-10-30 16:16:26] iter = 19030, loss = 6.8195
2024-10-30 16:16:30: [2024-10-30 16:16:30] iter = 19040, loss = 6.1419
2024-10-30 16:16:36: [2024-10-30 16:16:36] iter = 19050, loss = 7.6817
2024-10-30 16:16:39: [2024-10-30 16:16:39] iter = 19060, loss = 18.3986
2024-10-30 16:16:42: [2024-10-30 16:16:42] iter = 19070, loss = 7.8491
2024-10-30 16:16:47: [2024-10-30 16:16:47] iter = 19080, loss = 46.1546
2024-10-30 16:16:51: [2024-10-30 16:16:51] iter = 19090, loss = 14.6919
2024-10-30 16:16:55: [2024-10-30 16:16:55] iter = 19100, loss = 15.2698
2024-10-30 16:17:00: [2024-10-30 16:17:00] iter = 19110, loss = 15.7261
2024-10-30 16:17:05: [2024-10-30 16:17:05] iter = 19120, loss = 4.5026
2024-10-30 16:17:10: [2024-10-30 16:17:10] iter = 19130, loss = 14.5493
2024-10-30 16:17:15: [2024-10-30 16:17:15] iter = 19140, loss = 77.8451
2024-10-30 16:17:20: [2024-10-30 16:17:20] iter = 19150, loss = 3.4548
2024-10-30 16:17:24: [2024-10-30 16:17:24] iter = 19160, loss = 9.4965
2024-10-30 16:17:28: [2024-10-30 16:17:28] iter = 19170, loss = 9.1979
2024-10-30 16:17:33: [2024-10-30 16:17:33] iter = 19180, loss = 22.6475
2024-10-30 16:17:37: [2024-10-30 16:17:37] iter = 19190, loss = 16.2200
2024-10-30 16:17:42: [2024-10-30 16:17:42] iter = 19200, loss = 50.1785
2024-10-30 16:17:46: [2024-10-30 16:17:46] iter = 19210, loss = 37.2554
2024-10-30 16:17:52: [2024-10-30 16:17:52] iter = 19220, loss = 3.9213
2024-10-30 16:17:57: [2024-10-30 16:17:57] iter = 19230, loss = 4.4129
2024-10-30 16:18:02: [2024-10-30 16:18:02] iter = 19240, loss = 31.5640
2024-10-30 16:18:07: [2024-10-30 16:18:07] iter = 19250, loss = 23.2360
2024-10-30 16:18:12: [2024-10-30 16:18:12] iter = 19260, loss = 5.7733
2024-10-30 16:18:17: [2024-10-30 16:18:17] iter = 19270, loss = 50.3890
2024-10-30 16:18:22: [2024-10-30 16:18:22] iter = 19280, loss = 6.4757
2024-10-30 16:18:27: [2024-10-30 16:18:27] iter = 19290, loss = 10.3943
2024-10-30 16:18:31: [2024-10-30 16:18:31] iter = 19300, loss = 5.5428
2024-10-30 16:18:36: [2024-10-30 16:18:36] iter = 19310, loss = 15.0317
2024-10-30 16:18:41: [2024-10-30 16:18:41] iter = 19320, loss = 4.4445
2024-10-30 16:18:46: [2024-10-30 16:18:46] iter = 19330, loss = 11.3546
2024-10-30 16:18:52: [2024-10-30 16:18:52] iter = 19340, loss = 3.9689
2024-10-30 16:18:56: [2024-10-30 16:18:56] iter = 19350, loss = 12.4227
2024-10-30 16:19:01: [2024-10-30 16:19:01] iter = 19360, loss = 64.7678
2024-10-30 16:19:05: [2024-10-30 16:19:05] iter = 19370, loss = 70.9706
2024-10-30 16:19:09: [2024-10-30 16:19:09] iter = 19380, loss = 20.0681
2024-10-30 16:19:13: [2024-10-30 16:19:13] iter = 19390, loss = 4.2075
2024-10-30 16:19:18: [2024-10-30 16:19:18] iter = 19400, loss = 17.8055
2024-10-30 16:19:22: [2024-10-30 16:19:22] iter = 19410, loss = 5.8552
2024-10-30 16:19:27: [2024-10-30 16:19:27] iter = 19420, loss = 46.3610
2024-10-30 16:19:31: [2024-10-30 16:19:31] iter = 19430, loss = 31.3103
2024-10-30 16:19:35: [2024-10-30 16:19:35] iter = 19440, loss = 41.7107
2024-10-30 16:19:40: [2024-10-30 16:19:40] iter = 19450, loss = 4.7029
2024-10-30 16:19:45: [2024-10-30 16:19:45] iter = 19460, loss = 5.7130
2024-10-30 16:19:50: [2024-10-30 16:19:50] iter = 19470, loss = 26.2644
2024-10-30 16:19:54: [2024-10-30 16:19:54] iter = 19480, loss = 4.3031
2024-10-30 16:19:57: [2024-10-30 16:19:57] iter = 19490, loss = 24.1424
2024-10-30 16:20:01: [2024-10-30 16:20:01] iter = 19500, loss = 4.6038
2024-10-30 16:20:05: [2024-10-30 16:20:05] iter = 19510, loss = 32.2488
2024-10-30 16:20:09: [2024-10-30 16:20:09] iter = 19520, loss = 41.8404
2024-10-30 16:20:14: [2024-10-30 16:20:14] iter = 19530, loss = 22.4165
2024-10-30 16:20:18: [2024-10-30 16:20:18] iter = 19540, loss = 6.0537
2024-10-30 16:20:22: [2024-10-30 16:20:22] iter = 19550, loss = 22.9136
2024-10-30 16:20:25: [2024-10-30 16:20:25] iter = 19560, loss = 26.9696
2024-10-30 16:20:30: [2024-10-30 16:20:30] iter = 19570, loss = 21.2007
2024-10-30 16:20:35: [2024-10-30 16:20:35] iter = 19580, loss = 5.4594
2024-10-30 16:20:39: [2024-10-30 16:20:39] iter = 19590, loss = 72.4059
2024-10-30 16:20:43: [2024-10-30 16:20:43] iter = 19600, loss = 7.0600
2024-10-30 16:20:48: [2024-10-30 16:20:48] iter = 19610, loss = 32.7352
2024-10-30 16:20:53: [2024-10-30 16:20:53] iter = 19620, loss = 9.7828
2024-10-30 16:20:57: [2024-10-30 16:20:57] iter = 19630, loss = 43.4642
2024-10-30 16:21:00: [2024-10-30 16:21:00] iter = 19640, loss = 8.3929
2024-10-30 16:21:05: [2024-10-30 16:21:05] iter = 19650, loss = 6.3514
2024-10-30 16:21:10: [2024-10-30 16:21:10] iter = 19660, loss = 7.8858
2024-10-30 16:21:14: [2024-10-30 16:21:14] iter = 19670, loss = 4.9426
2024-10-30 16:21:18: [2024-10-30 16:21:18] iter = 19680, loss = 5.9958
2024-10-30 16:21:23: [2024-10-30 16:21:23] iter = 19690, loss = 34.5280
2024-10-30 16:21:28: [2024-10-30 16:21:28] iter = 19700, loss = 6.8815
2024-10-30 16:21:32: [2024-10-30 16:21:32] iter = 19710, loss = 4.3826
2024-10-30 16:21:35: [2024-10-30 16:21:35] iter = 19720, loss = 4.2172
2024-10-30 16:21:40: [2024-10-30 16:21:40] iter = 19730, loss = 55.1648
2024-10-30 16:21:44: [2024-10-30 16:21:44] iter = 19740, loss = 20.8363
2024-10-30 16:21:48: [2024-10-30 16:21:48] iter = 19750, loss = 4.6839
2024-10-30 16:21:52: [2024-10-30 16:21:52] iter = 19760, loss = 11.5829
2024-10-30 16:21:55: [2024-10-30 16:21:55] iter = 19770, loss = 13.8617
2024-10-30 16:22:00: [2024-10-30 16:22:00] iter = 19780, loss = 31.4478
2024-10-30 16:22:04: [2024-10-30 16:22:04] iter = 19790, loss = 40.0928
2024-10-30 16:22:07: [2024-10-30 16:22:07] iter = 19800, loss = 16.8282
2024-10-30 16:22:12: [2024-10-30 16:22:12] iter = 19810, loss = 3.8294
2024-10-30 16:22:16: [2024-10-30 16:22:16] iter = 19820, loss = 4.3255
2024-10-30 16:22:19: [2024-10-30 16:22:19] iter = 19830, loss = 23.0318
2024-10-30 16:22:23: [2024-10-30 16:22:23] iter = 19840, loss = 12.4393
2024-10-30 16:22:27: [2024-10-30 16:22:27] iter = 19850, loss = 5.2104
2024-10-30 16:22:31: [2024-10-30 16:22:31] iter = 19860, loss = 31.5763
2024-10-30 16:22:35: [2024-10-30 16:22:35] iter = 19870, loss = 60.5148
2024-10-30 16:22:40: [2024-10-30 16:22:40] iter = 19880, loss = 5.6978
2024-10-30 16:22:44: [2024-10-30 16:22:44] iter = 19890, loss = 14.6240
2024-10-30 16:22:48: [2024-10-30 16:22:48] iter = 19900, loss = 14.5563
2024-10-30 16:22:53: [2024-10-30 16:22:53] iter = 19910, loss = 4.5532
2024-10-30 16:22:58: [2024-10-30 16:22:58] iter = 19920, loss = 36.3729
2024-10-30 16:23:03: [2024-10-30 16:23:03] iter = 19930, loss = 67.2136
2024-10-30 16:23:07: [2024-10-30 16:23:07] iter = 19940, loss = 3.7928
2024-10-30 16:23:12: [2024-10-30 16:23:12] iter = 19950, loss = 13.4725
2024-10-30 16:23:16: [2024-10-30 16:23:16] iter = 19960, loss = 19.3215
2024-10-30 16:23:21: [2024-10-30 16:23:21] iter = 19970, loss = 56.2094
2024-10-30 16:23:25: [2024-10-30 16:23:25] iter = 19980, loss = 7.2781
2024-10-30 16:23:30: [2024-10-30 16:23:30] iter = 19990, loss = 7.0090
2024-10-30 16:23:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 16:23:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:23:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 13712}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:26:03: Evaluate 5 random ConvNet, ACCmean = 0.3694 ACCstd = 0.0043
-------------------------
2024-10-30 16:26:03: Evaluate 5 random ConvNet, SENmean = 0.3004 SENstd = 0.0014
-------------------------
2024-10-30 16:26:03: Evaluate 5 random ConvNet, SPEmean = 0.9084 SPEstd = 0.0004
-------------------------
2024-10-30 16:26:03: Evaluate 5 random ConvNet, F!mean = 0.2639 F!std = 0.0028
-------------------------
2024-10-30 16:26:03: Evaluate 5 random ConvNet, mean = 0.3694 std = 0.0043
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:26:03: [2024-10-30 16:26:03] iter = 20000, loss = 22.1797
2024-10-30 16:26:03: 
================== Exp 1 ==================
 
2024-10-30 16:26:03: Hyper-parameters: 
{'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ffaf9964b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_TissueMNIST (INFO)>}
2024-10-30 16:26:03: Evaluation model pool: ['ConvNet']
2024-10-30 16:26:19: class c = 0: 53075 real images
2024-10-30 16:26:19: class c = 1: 7814 real images
2024-10-30 16:26:19: class c = 2: 5866 real images
2024-10-30 16:26:19: class c = 3: 15406 real images
2024-10-30 16:26:19: class c = 4: 11789 real images
2024-10-30 16:26:19: class c = 5: 7705 real images
2024-10-30 16:26:19: class c = 6: 39203 real images
2024-10-30 16:26:19: class c = 7: 24608 real images
2024-10-30 16:26:19: real images channel 0, mean = 0.1020, std = 0.1000
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 16:26:19: initialize synthetic data from random real images
2024-10-30 16:26:19: [2024-10-30 16:26:19] training begins
2024-10-30 16:26:19: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 16:26:19: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:26:19: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63688}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:28:48: Evaluate 5 random ConvNet, ACCmean = 0.2733 ACCstd = 0.0030
-------------------------
2024-10-30 16:28:48: Evaluate 5 random ConvNet, SENmean = 0.2547 SENstd = 0.0025
-------------------------
2024-10-30 16:28:48: Evaluate 5 random ConvNet, SPEmean = 0.8949 SPEstd = 0.0003
-------------------------
2024-10-30 16:28:48: Evaluate 5 random ConvNet, F!mean = 0.2319 F!std = 0.0027
-------------------------
2024-10-30 16:28:48: Evaluate 5 random ConvNet, mean = 0.2733 std = 0.0030
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:28:49: [2024-10-30 16:28:49] iter = 00000, loss = 19.1063
2024-10-30 16:28:52: [2024-10-30 16:28:52] iter = 00010, loss = 18.6954
2024-10-30 16:28:56: [2024-10-30 16:28:56] iter = 00020, loss = 20.8281
2024-10-30 16:29:01: [2024-10-30 16:29:01] iter = 00030, loss = 23.5394
2024-10-30 16:29:05: [2024-10-30 16:29:05] iter = 00040, loss = 12.1608
2024-10-30 16:29:09: [2024-10-30 16:29:09] iter = 00050, loss = 15.2861
2024-10-30 16:29:13: [2024-10-30 16:29:13] iter = 00060, loss = 5.6267
2024-10-30 16:29:18: [2024-10-30 16:29:18] iter = 00070, loss = 38.4122
2024-10-30 16:29:22: [2024-10-30 16:29:22] iter = 00080, loss = 20.1780
2024-10-30 16:29:27: [2024-10-30 16:29:27] iter = 00090, loss = 5.1654
2024-10-30 16:29:31: [2024-10-30 16:29:31] iter = 00100, loss = 9.6830
2024-10-30 16:29:35: [2024-10-30 16:29:35] iter = 00110, loss = 13.0918
2024-10-30 16:29:39: [2024-10-30 16:29:39] iter = 00120, loss = 28.4692
2024-10-30 16:29:44: [2024-10-30 16:29:44] iter = 00130, loss = 21.6179
2024-10-30 16:29:48: [2024-10-30 16:29:48] iter = 00140, loss = 43.2558
2024-10-30 16:29:52: [2024-10-30 16:29:52] iter = 00150, loss = 8.7518
2024-10-30 16:29:55: [2024-10-30 16:29:55] iter = 00160, loss = 19.4883
2024-10-30 16:29:59: [2024-10-30 16:29:59] iter = 00170, loss = 23.7566
2024-10-30 16:30:02: [2024-10-30 16:30:02] iter = 00180, loss = 7.6736
2024-10-30 16:30:07: [2024-10-30 16:30:07] iter = 00190, loss = 51.1255
2024-10-30 16:30:10: [2024-10-30 16:30:10] iter = 00200, loss = 6.1703
2024-10-30 16:30:15: [2024-10-30 16:30:15] iter = 00210, loss = 6.5709
2024-10-30 16:30:19: [2024-10-30 16:30:19] iter = 00220, loss = 10.0323
2024-10-30 16:30:24: [2024-10-30 16:30:24] iter = 00230, loss = 23.1381
2024-10-30 16:30:28: [2024-10-30 16:30:28] iter = 00240, loss = 5.0697
2024-10-30 16:30:33: [2024-10-30 16:30:33] iter = 00250, loss = 6.1240
2024-10-30 16:30:36: [2024-10-30 16:30:36] iter = 00260, loss = 9.1046
2024-10-30 16:30:40: [2024-10-30 16:30:40] iter = 00270, loss = 52.0469
2024-10-30 16:30:45: [2024-10-30 16:30:45] iter = 00280, loss = 5.5487
2024-10-30 16:30:49: [2024-10-30 16:30:49] iter = 00290, loss = 8.5624
2024-10-30 16:30:52: [2024-10-30 16:30:52] iter = 00300, loss = 10.4669
2024-10-30 16:30:55: [2024-10-30 16:30:55] iter = 00310, loss = 18.0896
2024-10-30 16:31:00: [2024-10-30 16:31:00] iter = 00320, loss = 18.6927
2024-10-30 16:31:02: [2024-10-30 16:31:02] iter = 00330, loss = 19.6372
2024-10-30 16:31:06: [2024-10-30 16:31:06] iter = 00340, loss = 27.3273
2024-10-30 16:31:10: [2024-10-30 16:31:10] iter = 00350, loss = 18.3877
2024-10-30 16:31:15: [2024-10-30 16:31:15] iter = 00360, loss = 4.6437
2024-10-30 16:31:18: [2024-10-30 16:31:18] iter = 00370, loss = 9.0897
2024-10-30 16:31:22: [2024-10-30 16:31:22] iter = 00380, loss = 14.0307
2024-10-30 16:31:26: [2024-10-30 16:31:26] iter = 00390, loss = 13.7252
2024-10-30 16:31:30: [2024-10-30 16:31:30] iter = 00400, loss = 74.7065
2024-10-30 16:31:35: [2024-10-30 16:31:35] iter = 00410, loss = 9.3555
2024-10-30 16:31:39: [2024-10-30 16:31:39] iter = 00420, loss = 41.1834
2024-10-30 16:31:44: [2024-10-30 16:31:44] iter = 00430, loss = 78.5537
2024-10-30 16:31:47: [2024-10-30 16:31:47] iter = 00440, loss = 7.0466
2024-10-30 16:31:51: [2024-10-30 16:31:51] iter = 00450, loss = 45.9285
2024-10-30 16:31:56: [2024-10-30 16:31:56] iter = 00460, loss = 15.1019
2024-10-30 16:32:01: [2024-10-30 16:32:01] iter = 00470, loss = 26.1795
2024-10-30 16:32:05: [2024-10-30 16:32:05] iter = 00480, loss = 21.5277
2024-10-30 16:32:09: [2024-10-30 16:32:09] iter = 00490, loss = 24.1502
2024-10-30 16:32:13: [2024-10-30 16:32:13] iter = 00500, loss = 37.7462
2024-10-30 16:32:18: [2024-10-30 16:32:18] iter = 00510, loss = 16.8038
2024-10-30 16:32:22: [2024-10-30 16:32:22] iter = 00520, loss = 43.8686
2024-10-30 16:32:26: [2024-10-30 16:32:26] iter = 00530, loss = 6.4410
2024-10-30 16:32:30: [2024-10-30 16:32:30] iter = 00540, loss = 5.8446
2024-10-30 16:32:34: [2024-10-30 16:32:34] iter = 00550, loss = 51.5719
2024-10-30 16:32:38: [2024-10-30 16:32:38] iter = 00560, loss = 18.9694
2024-10-30 16:32:43: [2024-10-30 16:32:43] iter = 00570, loss = 5.7874
2024-10-30 16:32:45: [2024-10-30 16:32:45] iter = 00580, loss = 6.9499
2024-10-30 16:32:49: [2024-10-30 16:32:49] iter = 00590, loss = 26.4794
2024-10-30 16:32:55: [2024-10-30 16:32:55] iter = 00600, loss = 44.7649
2024-10-30 16:32:59: [2024-10-30 16:32:59] iter = 00610, loss = 60.4034
2024-10-30 16:33:04: [2024-10-30 16:33:04] iter = 00620, loss = 20.6938
2024-10-30 16:33:08: [2024-10-30 16:33:08] iter = 00630, loss = 19.4577
2024-10-30 16:33:13: [2024-10-30 16:33:13] iter = 00640, loss = 9.5558
2024-10-30 16:33:18: [2024-10-30 16:33:18] iter = 00650, loss = 26.2795
2024-10-30 16:33:21: [2024-10-30 16:33:21] iter = 00660, loss = 6.0020
2024-10-30 16:33:25: [2024-10-30 16:33:25] iter = 00670, loss = 20.9322
2024-10-30 16:33:29: [2024-10-30 16:33:29] iter = 00680, loss = 18.2200
2024-10-30 16:33:35: [2024-10-30 16:33:35] iter = 00690, loss = 36.7723
2024-10-30 16:33:39: [2024-10-30 16:33:39] iter = 00700, loss = 9.2060
2024-10-30 16:33:43: [2024-10-30 16:33:43] iter = 00710, loss = 6.6426
2024-10-30 16:33:48: [2024-10-30 16:33:48] iter = 00720, loss = 25.2475
2024-10-30 16:33:51: [2024-10-30 16:33:51] iter = 00730, loss = 5.9790
2024-10-30 16:33:55: [2024-10-30 16:33:55] iter = 00740, loss = 5.9696
2024-10-30 16:33:59: [2024-10-30 16:33:59] iter = 00750, loss = 10.2667
2024-10-30 16:34:04: [2024-10-30 16:34:04] iter = 00760, loss = 42.8541
2024-10-30 16:34:08: [2024-10-30 16:34:08] iter = 00770, loss = 39.4376
2024-10-30 16:34:13: [2024-10-30 16:34:13] iter = 00780, loss = 23.4410
2024-10-30 16:34:18: [2024-10-30 16:34:18] iter = 00790, loss = 66.3478
2024-10-30 16:34:22: [2024-10-30 16:34:22] iter = 00800, loss = 10.1748
2024-10-30 16:34:26: [2024-10-30 16:34:26] iter = 00810, loss = 33.4794
2024-10-30 16:34:31: [2024-10-30 16:34:31] iter = 00820, loss = 5.6855
2024-10-30 16:34:36: [2024-10-30 16:34:36] iter = 00830, loss = 9.3996
2024-10-30 16:34:41: [2024-10-30 16:34:41] iter = 00840, loss = 6.2201
2024-10-30 16:34:46: [2024-10-30 16:34:46] iter = 00850, loss = 13.3027
2024-10-30 16:34:49: [2024-10-30 16:34:49] iter = 00860, loss = 20.4834
2024-10-30 16:34:54: [2024-10-30 16:34:54] iter = 00870, loss = 16.9459
2024-10-30 16:34:58: [2024-10-30 16:34:58] iter = 00880, loss = 14.3339
2024-10-30 16:35:02: [2024-10-30 16:35:02] iter = 00890, loss = 39.1162
2024-10-30 16:35:07: [2024-10-30 16:35:07] iter = 00900, loss = 5.7519
2024-10-30 16:35:12: [2024-10-30 16:35:12] iter = 00910, loss = 51.1078
2024-10-30 16:35:15: [2024-10-30 16:35:15] iter = 00920, loss = 23.7610
2024-10-30 16:35:20: [2024-10-30 16:35:20] iter = 00930, loss = 7.4172
2024-10-30 16:35:24: [2024-10-30 16:35:24] iter = 00940, loss = 20.4663
2024-10-30 16:35:28: [2024-10-30 16:35:28] iter = 00950, loss = 51.9374
2024-10-30 16:35:30: [2024-10-30 16:35:30] iter = 00960, loss = 6.5125
2024-10-30 16:35:34: [2024-10-30 16:35:34] iter = 00970, loss = 9.5709
2024-10-30 16:35:39: [2024-10-30 16:35:39] iter = 00980, loss = 65.2573
2024-10-30 16:35:43: [2024-10-30 16:35:43] iter = 00990, loss = 54.5278
2024-10-30 16:35:48: [2024-10-30 16:35:48] iter = 01000, loss = 10.0588
2024-10-30 16:35:53: [2024-10-30 16:35:53] iter = 01010, loss = 9.1986
2024-10-30 16:35:57: [2024-10-30 16:35:57] iter = 01020, loss = 17.2688
2024-10-30 16:36:01: [2024-10-30 16:36:01] iter = 01030, loss = 17.9869
2024-10-30 16:36:04: [2024-10-30 16:36:04] iter = 01040, loss = 36.9316
2024-10-30 16:36:08: [2024-10-30 16:36:08] iter = 01050, loss = 17.6416
2024-10-30 16:36:11: [2024-10-30 16:36:11] iter = 01060, loss = 47.1920
2024-10-30 16:36:15: [2024-10-30 16:36:15] iter = 01070, loss = 57.2617
2024-10-30 16:36:20: [2024-10-30 16:36:20] iter = 01080, loss = 5.7778
2024-10-30 16:36:25: [2024-10-30 16:36:25] iter = 01090, loss = 33.6399
2024-10-30 16:36:30: [2024-10-30 16:36:30] iter = 01100, loss = 5.5530
2024-10-30 16:36:34: [2024-10-30 16:36:34] iter = 01110, loss = 25.7774
2024-10-30 16:36:38: [2024-10-30 16:36:38] iter = 01120, loss = 16.1930
2024-10-30 16:36:43: [2024-10-30 16:36:43] iter = 01130, loss = 16.4075
2024-10-30 16:36:47: [2024-10-30 16:36:47] iter = 01140, loss = 74.9255
2024-10-30 16:36:52: [2024-10-30 16:36:52] iter = 01150, loss = 14.6384
2024-10-30 16:36:56: [2024-10-30 16:36:56] iter = 01160, loss = 8.8545
2024-10-30 16:37:02: [2024-10-30 16:37:02] iter = 01170, loss = 5.4062
2024-10-30 16:37:07: [2024-10-30 16:37:07] iter = 01180, loss = 24.3509
2024-10-30 16:37:11: [2024-10-30 16:37:11] iter = 01190, loss = 4.9393
2024-10-30 16:37:16: [2024-10-30 16:37:16] iter = 01200, loss = 27.9315
2024-10-30 16:37:21: [2024-10-30 16:37:21] iter = 01210, loss = 25.0523
2024-10-30 16:37:26: [2024-10-30 16:37:26] iter = 01220, loss = 16.0057
2024-10-30 16:37:30: [2024-10-30 16:37:30] iter = 01230, loss = 3.5352
2024-10-30 16:37:35: [2024-10-30 16:37:35] iter = 01240, loss = 17.5988
2024-10-30 16:37:40: [2024-10-30 16:37:40] iter = 01250, loss = 7.9570
2024-10-30 16:37:44: [2024-10-30 16:37:44] iter = 01260, loss = 30.3086
2024-10-30 16:37:48: [2024-10-30 16:37:48] iter = 01270, loss = 73.8779
2024-10-30 16:37:54: [2024-10-30 16:37:54] iter = 01280, loss = 8.0002
2024-10-30 16:37:58: [2024-10-30 16:37:58] iter = 01290, loss = 66.4209
2024-10-30 16:38:02: [2024-10-30 16:38:02] iter = 01300, loss = 6.4730
2024-10-30 16:38:05: [2024-10-30 16:38:05] iter = 01310, loss = 20.0670
2024-10-30 16:38:08: [2024-10-30 16:38:08] iter = 01320, loss = 19.2714
2024-10-30 16:38:12: [2024-10-30 16:38:12] iter = 01330, loss = 18.6677
2024-10-30 16:38:17: [2024-10-30 16:38:17] iter = 01340, loss = 22.3969
2024-10-30 16:38:22: [2024-10-30 16:38:22] iter = 01350, loss = 9.0344
2024-10-30 16:38:26: [2024-10-30 16:38:26] iter = 01360, loss = 4.2764
2024-10-30 16:38:31: [2024-10-30 16:38:31] iter = 01370, loss = 8.2168
2024-10-30 16:38:33: [2024-10-30 16:38:33] iter = 01380, loss = 26.9760
2024-10-30 16:38:37: [2024-10-30 16:38:37] iter = 01390, loss = 5.5912
2024-10-30 16:38:41: [2024-10-30 16:38:41] iter = 01400, loss = 12.8685
2024-10-30 16:38:45: [2024-10-30 16:38:45] iter = 01410, loss = 61.3371
2024-10-30 16:38:49: [2024-10-30 16:38:49] iter = 01420, loss = 45.9922
2024-10-30 16:38:53: [2024-10-30 16:38:53] iter = 01430, loss = 5.4150
2024-10-30 16:38:57: [2024-10-30 16:38:57] iter = 01440, loss = 39.1780
2024-10-30 16:39:02: [2024-10-30 16:39:02] iter = 01450, loss = 5.1891
2024-10-30 16:39:07: [2024-10-30 16:39:07] iter = 01460, loss = 15.1323
2024-10-30 16:39:11: [2024-10-30 16:39:11] iter = 01470, loss = 3.8079
2024-10-30 16:39:15: [2024-10-30 16:39:15] iter = 01480, loss = 16.6308
2024-10-30 16:39:19: [2024-10-30 16:39:19] iter = 01490, loss = 14.0584
2024-10-30 16:39:24: [2024-10-30 16:39:24] iter = 01500, loss = 16.4529
2024-10-30 16:39:29: [2024-10-30 16:39:29] iter = 01510, loss = 17.1072
2024-10-30 16:39:34: [2024-10-30 16:39:34] iter = 01520, loss = 4.2164
2024-10-30 16:39:37: [2024-10-30 16:39:37] iter = 01530, loss = 31.7992
2024-10-30 16:39:41: [2024-10-30 16:39:41] iter = 01540, loss = 43.4175
2024-10-30 16:39:45: [2024-10-30 16:39:45] iter = 01550, loss = 21.7193
2024-10-30 16:39:49: [2024-10-30 16:39:49] iter = 01560, loss = 61.7157
2024-10-30 16:39:53: [2024-10-30 16:39:53] iter = 01570, loss = 12.2683
2024-10-30 16:39:56: [2024-10-30 16:39:56] iter = 01580, loss = 27.5824
2024-10-30 16:39:59: [2024-10-30 16:39:59] iter = 01590, loss = 4.1478
2024-10-30 16:40:02: [2024-10-30 16:40:02] iter = 01600, loss = 4.3584
2024-10-30 16:40:06: [2024-10-30 16:40:06] iter = 01610, loss = 11.7595
2024-10-30 16:40:12: [2024-10-30 16:40:12] iter = 01620, loss = 14.9602
2024-10-30 16:40:14: [2024-10-30 16:40:14] iter = 01630, loss = 4.7272
2024-10-30 16:40:20: [2024-10-30 16:40:20] iter = 01640, loss = 4.2166
2024-10-30 16:40:24: [2024-10-30 16:40:24] iter = 01650, loss = 49.1562
2024-10-30 16:40:29: [2024-10-30 16:40:29] iter = 01660, loss = 5.2478
2024-10-30 16:40:32: [2024-10-30 16:40:32] iter = 01670, loss = 8.3504
2024-10-30 16:40:35: [2024-10-30 16:40:35] iter = 01680, loss = 4.5501
2024-10-30 16:40:39: [2024-10-30 16:40:39] iter = 01690, loss = 25.8069
2024-10-30 16:40:44: [2024-10-30 16:40:44] iter = 01700, loss = 5.8017
2024-10-30 16:40:48: [2024-10-30 16:40:48] iter = 01710, loss = 64.6284
2024-10-30 16:40:51: [2024-10-30 16:40:51] iter = 01720, loss = 57.5007
2024-10-30 16:40:54: [2024-10-30 16:40:54] iter = 01730, loss = 8.2103
2024-10-30 16:40:57: [2024-10-30 16:40:57] iter = 01740, loss = 4.3616
2024-10-30 16:40:59: [2024-10-30 16:40:59] iter = 01750, loss = 5.8977
2024-10-30 16:41:04: [2024-10-30 16:41:04] iter = 01760, loss = 8.5427
2024-10-30 16:41:08: [2024-10-30 16:41:08] iter = 01770, loss = 3.5845
2024-10-30 16:41:12: [2024-10-30 16:41:12] iter = 01780, loss = 16.8953
2024-10-30 16:41:16: [2024-10-30 16:41:16] iter = 01790, loss = 12.9744
2024-10-30 16:41:20: [2024-10-30 16:41:20] iter = 01800, loss = 5.8694
2024-10-30 16:41:25: [2024-10-30 16:41:25] iter = 01810, loss = 15.4451
2024-10-30 16:41:29: [2024-10-30 16:41:29] iter = 01820, loss = 21.6963
2024-10-30 16:41:33: [2024-10-30 16:41:33] iter = 01830, loss = 6.9013
2024-10-30 16:41:37: [2024-10-30 16:41:37] iter = 01840, loss = 40.6619
2024-10-30 16:41:40: [2024-10-30 16:41:40] iter = 01850, loss = 5.4997
2024-10-30 16:41:45: [2024-10-30 16:41:45] iter = 01860, loss = 64.3747
2024-10-30 16:41:48: [2024-10-30 16:41:48] iter = 01870, loss = 9.1213
2024-10-30 16:41:53: [2024-10-30 16:41:53] iter = 01880, loss = 52.5527
2024-10-30 16:41:58: [2024-10-30 16:41:58] iter = 01890, loss = 37.4098
2024-10-30 16:42:03: [2024-10-30 16:42:03] iter = 01900, loss = 13.9706
2024-10-30 16:42:08: [2024-10-30 16:42:08] iter = 01910, loss = 9.1318
2024-10-30 16:42:12: [2024-10-30 16:42:12] iter = 01920, loss = 13.7619
2024-10-30 16:42:16: [2024-10-30 16:42:16] iter = 01930, loss = 46.3877
2024-10-30 16:42:20: [2024-10-30 16:42:20] iter = 01940, loss = 5.4388
2024-10-30 16:42:24: [2024-10-30 16:42:24] iter = 01950, loss = 10.9055
2024-10-30 16:42:28: [2024-10-30 16:42:28] iter = 01960, loss = 11.9830
2024-10-30 16:42:31: [2024-10-30 16:42:31] iter = 01970, loss = 4.1282
2024-10-30 16:42:36: [2024-10-30 16:42:36] iter = 01980, loss = 4.6159
2024-10-30 16:42:40: [2024-10-30 16:42:40] iter = 01990, loss = 6.0410
2024-10-30 16:42:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 16:42:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:42:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63559}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:15: Evaluate 5 random ConvNet, ACCmean = 0.3063 ACCstd = 0.0052
-------------------------
2024-10-30 16:45:15: Evaluate 5 random ConvNet, SENmean = 0.2886 SENstd = 0.0014
-------------------------
2024-10-30 16:45:15: Evaluate 5 random ConvNet, SPEmean = 0.9019 SPEstd = 0.0004
-------------------------
2024-10-30 16:45:15: Evaluate 5 random ConvNet, F!mean = 0.2385 F!std = 0.0020
-------------------------
2024-10-30 16:45:15: Evaluate 5 random ConvNet, mean = 0.3063 std = 0.0052
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 16:45:16: [2024-10-30 16:45:16] iter = 02000, loss = 5.5567
2024-10-30 16:45:21: [2024-10-30 16:45:21] iter = 02010, loss = 25.5273
2024-10-30 16:45:25: [2024-10-30 16:45:25] iter = 02020, loss = 9.4975
2024-10-30 16:45:28: [2024-10-30 16:45:28] iter = 02030, loss = 8.8913
2024-10-30 16:45:32: [2024-10-30 16:45:32] iter = 02040, loss = 13.1665
2024-10-30 16:45:37: [2024-10-30 16:45:37] iter = 02050, loss = 35.4037
2024-10-30 16:45:42: [2024-10-30 16:45:42] iter = 02060, loss = 32.2772
2024-10-30 16:45:46: [2024-10-30 16:45:46] iter = 02070, loss = 17.0410
2024-10-30 16:45:51: [2024-10-30 16:45:51] iter = 02080, loss = 10.6895
2024-10-30 16:45:56: [2024-10-30 16:45:56] iter = 02090, loss = 16.9624
2024-10-30 16:45:59: [2024-10-30 16:45:59] iter = 02100, loss = 29.2253
2024-10-30 16:46:03: [2024-10-30 16:46:03] iter = 02110, loss = 32.5151
2024-10-30 16:46:08: [2024-10-30 16:46:08] iter = 02120, loss = 18.2909
2024-10-30 16:46:13: [2024-10-30 16:46:13] iter = 02130, loss = 9.1340
2024-10-30 16:46:16: [2024-10-30 16:46:16] iter = 02140, loss = 27.6363
2024-10-30 16:46:18: [2024-10-30 16:46:18] iter = 02150, loss = 4.3283
2024-10-30 16:46:20: [2024-10-30 16:46:20] iter = 02160, loss = 34.4472
2024-10-30 16:46:24: [2024-10-30 16:46:24] iter = 02170, loss = 4.6182
2024-10-30 16:46:29: [2024-10-30 16:46:29] iter = 02180, loss = 12.3978
2024-10-30 16:46:34: [2024-10-30 16:46:34] iter = 02190, loss = 6.3266
2024-10-30 16:46:39: [2024-10-30 16:46:39] iter = 02200, loss = 9.3458
2024-10-30 16:46:42: [2024-10-30 16:46:42] iter = 02210, loss = 4.9773
2024-10-30 16:46:46: [2024-10-30 16:46:46] iter = 02220, loss = 11.0417
2024-10-30 16:46:50: [2024-10-30 16:46:50] iter = 02230, loss = 19.6397
2024-10-30 16:46:54: [2024-10-30 16:46:54] iter = 02240, loss = 11.7753
2024-10-30 16:46:58: [2024-10-30 16:46:58] iter = 02250, loss = 38.1817
2024-10-30 16:47:01: [2024-10-30 16:47:01] iter = 02260, loss = 4.0713
2024-10-30 16:47:05: [2024-10-30 16:47:05] iter = 02270, loss = 7.0497
2024-10-30 16:47:10: [2024-10-30 16:47:10] iter = 02280, loss = 7.0992
2024-10-30 16:47:14: [2024-10-30 16:47:14] iter = 02290, loss = 17.6047
2024-10-30 16:47:18: [2024-10-30 16:47:18] iter = 02300, loss = 21.7339
2024-10-30 16:47:22: [2024-10-30 16:47:22] iter = 02310, loss = 7.0119
2024-10-30 16:47:26: [2024-10-30 16:47:26] iter = 02320, loss = 4.4824
2024-10-30 16:47:30: [2024-10-30 16:47:30] iter = 02330, loss = 8.9545
2024-10-30 16:47:34: [2024-10-30 16:47:34] iter = 02340, loss = 4.0939
2024-10-30 16:47:38: [2024-10-30 16:47:38] iter = 02350, loss = 19.3972
2024-10-30 16:47:43: [2024-10-30 16:47:43] iter = 02360, loss = 29.9525
2024-10-30 16:47:46: [2024-10-30 16:47:46] iter = 02370, loss = 4.5992
2024-10-30 16:47:49: [2024-10-30 16:47:49] iter = 02380, loss = 4.0721
2024-10-30 16:47:53: [2024-10-30 16:47:53] iter = 02390, loss = 22.9266
2024-10-30 16:47:57: [2024-10-30 16:47:57] iter = 02400, loss = 34.3221
2024-10-30 16:48:00: [2024-10-30 16:48:00] iter = 02410, loss = 14.8443
2024-10-30 16:48:03: [2024-10-30 16:48:03] iter = 02420, loss = 103.5534
2024-10-30 16:48:07: [2024-10-30 16:48:07] iter = 02430, loss = 8.0920
2024-10-30 16:48:11: [2024-10-30 16:48:11] iter = 02440, loss = 16.3963
2024-10-30 16:48:16: [2024-10-30 16:48:16] iter = 02450, loss = 18.2902
2024-10-30 16:48:20: [2024-10-30 16:48:20] iter = 02460, loss = 68.0621
2024-10-30 16:48:25: [2024-10-30 16:48:25] iter = 02470, loss = 5.0411
2024-10-30 16:48:29: [2024-10-30 16:48:29] iter = 02480, loss = 20.1639
2024-10-30 16:48:34: [2024-10-30 16:48:34] iter = 02490, loss = 46.1173
2024-10-30 16:48:38: [2024-10-30 16:48:38] iter = 02500, loss = 46.2493
2024-10-30 16:48:42: [2024-10-30 16:48:42] iter = 02510, loss = 7.8802
2024-10-30 16:48:45: [2024-10-30 16:48:45] iter = 02520, loss = 4.6890
2024-10-30 16:48:49: [2024-10-30 16:48:49] iter = 02530, loss = 19.2521
2024-10-30 16:48:53: [2024-10-30 16:48:53] iter = 02540, loss = 4.0965
2024-10-30 16:48:58: [2024-10-30 16:48:58] iter = 02550, loss = 11.6903
2024-10-30 16:49:02: [2024-10-30 16:49:02] iter = 02560, loss = 6.2641
2024-10-30 16:49:07: [2024-10-30 16:49:07] iter = 02570, loss = 3.5030
2024-10-30 16:49:12: [2024-10-30 16:49:12] iter = 02580, loss = 8.1668
2024-10-30 16:49:17: [2024-10-30 16:49:17] iter = 02590, loss = 7.6670
2024-10-30 16:49:21: [2024-10-30 16:49:21] iter = 02600, loss = 14.1656
2024-10-30 16:49:25: [2024-10-30 16:49:25] iter = 02610, loss = 3.7952
2024-10-30 16:49:30: [2024-10-30 16:49:30] iter = 02620, loss = 63.0932
2024-10-30 16:49:33: [2024-10-30 16:49:33] iter = 02630, loss = 4.3293
2024-10-30 16:49:37: [2024-10-30 16:49:37] iter = 02640, loss = 31.5718
2024-10-30 16:49:41: [2024-10-30 16:49:41] iter = 02650, loss = 31.4297
2024-10-30 16:49:44: [2024-10-30 16:49:44] iter = 02660, loss = 27.9192
2024-10-30 16:49:49: [2024-10-30 16:49:49] iter = 02670, loss = 52.4001
2024-10-30 16:49:52: [2024-10-30 16:49:52] iter = 02680, loss = 57.0580
2024-10-30 16:49:56: [2024-10-30 16:49:56] iter = 02690, loss = 9.2595
2024-10-30 16:50:01: [2024-10-30 16:50:01] iter = 02700, loss = 21.4153
2024-10-30 16:50:05: [2024-10-30 16:50:05] iter = 02710, loss = 21.1099
2024-10-30 16:50:09: [2024-10-30 16:50:09] iter = 02720, loss = 36.3850
2024-10-30 16:50:13: [2024-10-30 16:50:13] iter = 02730, loss = 9.7078
2024-10-30 16:50:18: [2024-10-30 16:50:18] iter = 02740, loss = 16.0254
2024-10-30 16:50:22: [2024-10-30 16:50:22] iter = 02750, loss = 12.7345
2024-10-30 16:50:26: [2024-10-30 16:50:26] iter = 02760, loss = 26.6962
2024-10-30 16:50:31: [2024-10-30 16:50:31] iter = 02770, loss = 4.4991
2024-10-30 16:50:35: [2024-10-30 16:50:35] iter = 02780, loss = 8.1993
2024-10-30 16:50:40: [2024-10-30 16:50:40] iter = 02790, loss = 35.0745
2024-10-30 16:50:44: [2024-10-30 16:50:44] iter = 02800, loss = 8.9435
2024-10-30 16:50:48: [2024-10-30 16:50:48] iter = 02810, loss = 21.4714
2024-10-30 16:50:52: [2024-10-30 16:50:52] iter = 02820, loss = 22.9841
2024-10-30 16:50:55: [2024-10-30 16:50:55] iter = 02830, loss = 6.7044
2024-10-30 16:50:59: [2024-10-30 16:50:59] iter = 02840, loss = 12.1462
2024-10-30 16:51:02: [2024-10-30 16:51:02] iter = 02850, loss = 56.4008
2024-10-30 16:51:05: [2024-10-30 16:51:05] iter = 02860, loss = 116.7318
2024-10-30 16:51:09: [2024-10-30 16:51:09] iter = 02870, loss = 4.0773
2024-10-30 16:51:13: [2024-10-30 16:51:13] iter = 02880, loss = 64.7982
2024-10-30 16:51:17: [2024-10-30 16:51:17] iter = 02890, loss = 12.2273
2024-10-30 16:51:21: [2024-10-30 16:51:21] iter = 02900, loss = 5.1449
2024-10-30 16:51:23: [2024-10-30 16:51:23] iter = 02910, loss = 102.2096
2024-10-30 16:51:27: [2024-10-30 16:51:27] iter = 02920, loss = 7.4681
2024-10-30 16:51:32: [2024-10-30 16:51:32] iter = 02930, loss = 5.0385
2024-10-30 16:51:36: [2024-10-30 16:51:36] iter = 02940, loss = 57.4751
2024-10-30 16:51:41: [2024-10-30 16:51:41] iter = 02950, loss = 10.5761
2024-10-30 16:51:45: [2024-10-30 16:51:45] iter = 02960, loss = 52.2396
2024-10-30 16:51:50: [2024-10-30 16:51:50] iter = 02970, loss = 6.0091
2024-10-30 16:51:54: [2024-10-30 16:51:54] iter = 02980, loss = 19.2053
2024-10-30 16:51:58: [2024-10-30 16:51:58] iter = 02990, loss = 12.6268
2024-10-30 16:52:01: [2024-10-30 16:52:01] iter = 03000, loss = 27.0283
2024-10-30 16:52:02: [2024-10-30 16:52:02] iter = 03010, loss = 6.5799
2024-10-30 16:52:07: [2024-10-30 16:52:06] iter = 03020, loss = 11.3953
2024-10-30 16:52:11: [2024-10-30 16:52:11] iter = 03030, loss = 10.3518
2024-10-30 16:52:14: [2024-10-30 16:52:14] iter = 03040, loss = 13.7770
2024-10-30 16:52:19: [2024-10-30 16:52:19] iter = 03050, loss = 5.6139
2024-10-30 16:52:22: [2024-10-30 16:52:22] iter = 03060, loss = 27.3956
2024-10-30 16:52:26: [2024-10-30 16:52:26] iter = 03070, loss = 26.1929
2024-10-30 16:52:30: [2024-10-30 16:52:30] iter = 03080, loss = 14.7758
2024-10-30 16:52:34: [2024-10-30 16:52:34] iter = 03090, loss = 6.2004
2024-10-30 16:52:39: [2024-10-30 16:52:39] iter = 03100, loss = 3.1892
2024-10-30 16:52:44: [2024-10-30 16:52:44] iter = 03110, loss = 25.7953
2024-10-30 16:52:49: [2024-10-30 16:52:49] iter = 03120, loss = 5.0838
2024-10-30 16:52:53: [2024-10-30 16:52:53] iter = 03130, loss = 20.7756
2024-10-30 16:52:57: [2024-10-30 16:52:57] iter = 03140, loss = 37.6447
2024-10-30 16:53:00: [2024-10-30 16:53:00] iter = 03150, loss = 43.4310
2024-10-30 16:53:04: [2024-10-30 16:53:04] iter = 03160, loss = 14.9548
2024-10-30 16:53:09: [2024-10-30 16:53:09] iter = 03170, loss = 18.9879
2024-10-30 16:53:14: [2024-10-30 16:53:14] iter = 03180, loss = 36.6173
2024-10-30 16:53:18: [2024-10-30 16:53:18] iter = 03190, loss = 3.5388
2024-10-30 16:53:23: [2024-10-30 16:53:23] iter = 03200, loss = 3.0709
2024-10-30 16:53:25: [2024-10-30 16:53:25] iter = 03210, loss = 13.8642
2024-10-30 16:53:29: [2024-10-30 16:53:29] iter = 03220, loss = 6.1049
2024-10-30 16:53:32: [2024-10-30 16:53:32] iter = 03230, loss = 29.0612
2024-10-30 16:53:36: [2024-10-30 16:53:36] iter = 03240, loss = 62.9063
2024-10-30 16:53:40: [2024-10-30 16:53:40] iter = 03250, loss = 21.7587
2024-10-30 16:53:44: [2024-10-30 16:53:44] iter = 03260, loss = 15.8779
2024-10-30 16:53:47: [2024-10-30 16:53:47] iter = 03270, loss = 20.1127
2024-10-30 16:53:51: [2024-10-30 16:53:51] iter = 03280, loss = 25.0512
2024-10-30 16:53:55: [2024-10-30 16:53:55] iter = 03290, loss = 18.7434
2024-10-30 16:53:59: [2024-10-30 16:53:59] iter = 03300, loss = 90.7925
2024-10-30 16:54:02: [2024-10-30 16:54:02] iter = 03310, loss = 10.7973
2024-10-30 16:54:05: [2024-10-30 16:54:05] iter = 03320, loss = 13.5076
2024-10-30 16:54:10: [2024-10-30 16:54:10] iter = 03330, loss = 14.4514
2024-10-30 16:54:15: [2024-10-30 16:54:15] iter = 03340, loss = 25.8955
2024-10-30 16:54:19: [2024-10-30 16:54:19] iter = 03350, loss = 4.6782
2024-10-30 16:54:23: [2024-10-30 16:54:23] iter = 03360, loss = 25.8810
2024-10-30 16:54:28: [2024-10-30 16:54:28] iter = 03370, loss = 8.7092
2024-10-30 16:54:32: [2024-10-30 16:54:32] iter = 03380, loss = 9.4308
2024-10-30 16:54:37: [2024-10-30 16:54:37] iter = 03390, loss = 50.1718
2024-10-30 16:54:41: [2024-10-30 16:54:41] iter = 03400, loss = 5.2407
2024-10-30 16:54:44: [2024-10-30 16:54:44] iter = 03410, loss = 4.6844
2024-10-30 16:54:48: [2024-10-30 16:54:48] iter = 03420, loss = 40.6161
2024-10-30 16:54:53: [2024-10-30 16:54:53] iter = 03430, loss = 26.3341
2024-10-30 16:54:56: [2024-10-30 16:54:56] iter = 03440, loss = 30.1776
2024-10-30 16:54:59: [2024-10-30 16:54:59] iter = 03450, loss = 33.3406
2024-10-30 16:55:03: [2024-10-30 16:55:03] iter = 03460, loss = 26.4465
2024-10-30 16:55:08: [2024-10-30 16:55:08] iter = 03470, loss = 10.8476
2024-10-30 16:55:12: [2024-10-30 16:55:12] iter = 03480, loss = 6.5769
2024-10-30 16:55:16: [2024-10-30 16:55:16] iter = 03490, loss = 6.1829
2024-10-30 16:55:21: [2024-10-30 16:55:21] iter = 03500, loss = 24.5192
2024-10-30 16:55:26: [2024-10-30 16:55:26] iter = 03510, loss = 32.0139
2024-10-30 16:55:30: [2024-10-30 16:55:30] iter = 03520, loss = 5.7067
2024-10-30 16:55:34: [2024-10-30 16:55:34] iter = 03530, loss = 10.3410
2024-10-30 16:55:37: [2024-10-30 16:55:37] iter = 03540, loss = 32.6874
2024-10-30 16:55:41: [2024-10-30 16:55:41] iter = 03550, loss = 36.6942
2024-10-30 16:55:43: [2024-10-30 16:55:43] iter = 03560, loss = 32.8694
2024-10-30 16:55:47: [2024-10-30 16:55:47] iter = 03570, loss = 38.9355
2024-10-30 16:55:51: [2024-10-30 16:55:51] iter = 03580, loss = 5.0622
2024-10-30 16:55:54: [2024-10-30 16:55:54] iter = 03590, loss = 23.9049
2024-10-30 16:55:59: [2024-10-30 16:55:59] iter = 03600, loss = 5.0654
2024-10-30 16:56:03: [2024-10-30 16:56:03] iter = 03610, loss = 8.5813
2024-10-30 16:56:08: [2024-10-30 16:56:08] iter = 03620, loss = 5.7514
2024-10-30 16:56:13: [2024-10-30 16:56:13] iter = 03630, loss = 4.8112
2024-10-30 16:56:17: [2024-10-30 16:56:17] iter = 03640, loss = 3.6517
2024-10-30 16:56:21: [2024-10-30 16:56:21] iter = 03650, loss = 35.0817
2024-10-30 16:56:24: [2024-10-30 16:56:24] iter = 03660, loss = 4.7656
2024-10-30 16:56:26: [2024-10-30 16:56:26] iter = 03670, loss = 3.9106
2024-10-30 16:56:30: [2024-10-30 16:56:30] iter = 03680, loss = 3.6642
2024-10-30 16:56:35: [2024-10-30 16:56:35] iter = 03690, loss = 15.6376
2024-10-30 16:56:39: [2024-10-30 16:56:39] iter = 03700, loss = 51.1022
2024-10-30 16:56:43: [2024-10-30 16:56:43] iter = 03710, loss = 4.4270
2024-10-30 16:56:47: [2024-10-30 16:56:47] iter = 03720, loss = 21.6622
2024-10-30 16:56:51: [2024-10-30 16:56:51] iter = 03730, loss = 14.6229
2024-10-30 16:56:56: [2024-10-30 16:56:56] iter = 03740, loss = 29.4972
2024-10-30 16:57:01: [2024-10-30 16:57:01] iter = 03750, loss = 3.5798
2024-10-30 16:57:04: [2024-10-30 16:57:04] iter = 03760, loss = 5.1650
2024-10-30 16:57:08: [2024-10-30 16:57:08] iter = 03770, loss = 18.0038
2024-10-30 16:57:13: [2024-10-30 16:57:13] iter = 03780, loss = 3.8783
2024-10-30 16:57:17: [2024-10-30 16:57:17] iter = 03790, loss = 5.4582
2024-10-30 16:57:21: [2024-10-30 16:57:21] iter = 03800, loss = 5.7925
2024-10-30 16:57:25: [2024-10-30 16:57:25] iter = 03810, loss = 4.1277
2024-10-30 16:57:28: [2024-10-30 16:57:28] iter = 03820, loss = 9.8136
2024-10-30 16:57:33: [2024-10-30 16:57:33] iter = 03830, loss = 37.7537
2024-10-30 16:57:37: [2024-10-30 16:57:37] iter = 03840, loss = 30.4786
2024-10-30 16:57:41: [2024-10-30 16:57:41] iter = 03850, loss = 82.5696
2024-10-30 16:57:45: [2024-10-30 16:57:45] iter = 03860, loss = 12.7459
2024-10-30 16:57:49: [2024-10-30 16:57:49] iter = 03870, loss = 4.0437
2024-10-30 16:57:54: [2024-10-30 16:57:54] iter = 03880, loss = 11.0900
2024-10-30 16:57:58: [2024-10-30 16:57:58] iter = 03890, loss = 33.0257
2024-10-30 16:58:01: [2024-10-30 16:58:01] iter = 03900, loss = 56.3361
2024-10-30 16:58:05: [2024-10-30 16:58:05] iter = 03910, loss = 19.8794
2024-10-30 16:58:09: [2024-10-30 16:58:09] iter = 03920, loss = 10.8892
2024-10-30 16:58:12: [2024-10-30 16:58:12] iter = 03930, loss = 29.3194
2024-10-30 16:58:15: [2024-10-30 16:58:15] iter = 03940, loss = 18.7034
2024-10-30 16:58:19: [2024-10-30 16:58:19] iter = 03950, loss = 49.2347
2024-10-30 16:58:23: [2024-10-30 16:58:23] iter = 03960, loss = 6.3302
2024-10-30 16:58:26: [2024-10-30 16:58:26] iter = 03970, loss = 11.7928
2024-10-30 16:58:31: [2024-10-30 16:58:31] iter = 03980, loss = 4.4558
2024-10-30 16:58:34: [2024-10-30 16:58:34] iter = 03990, loss = 43.6563
2024-10-30 16:58:38: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 16:58:38: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 16:58:38: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 18624}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:01:12: Evaluate 5 random ConvNet, ACCmean = 0.3917 ACCstd = 0.0081
-------------------------
2024-10-30 17:01:12: Evaluate 5 random ConvNet, SENmean = 0.2979 SENstd = 0.0043
-------------------------
2024-10-30 17:01:12: Evaluate 5 random ConvNet, SPEmean = 0.9105 SPEstd = 0.0008
-------------------------
2024-10-30 17:01:12: Evaluate 5 random ConvNet, F!mean = 0.2810 F!std = 0.0052
-------------------------
2024-10-30 17:01:12: Evaluate 5 random ConvNet, mean = 0.3917 std = 0.0081
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:01:13: [2024-10-30 17:01:13] iter = 04000, loss = 5.5518
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:01:17: [2024-10-30 17:01:17] iter = 04010, loss = 22.3550
2024-10-30 17:01:21: [2024-10-30 17:01:21] iter = 04020, loss = 43.5329
2024-10-30 17:01:24: [2024-10-30 17:01:24] iter = 04030, loss = 4.4729
2024-10-30 17:01:28: [2024-10-30 17:01:28] iter = 04040, loss = 11.3581
2024-10-30 17:01:32: [2024-10-30 17:01:32] iter = 04050, loss = 8.1232
2024-10-30 17:01:36: [2024-10-30 17:01:36] iter = 04060, loss = 31.5945
2024-10-30 17:01:41: [2024-10-30 17:01:41] iter = 04070, loss = 13.0194
2024-10-30 17:01:47: [2024-10-30 17:01:47] iter = 04080, loss = 9.2003
2024-10-30 17:01:52: [2024-10-30 17:01:52] iter = 04090, loss = 11.4919
2024-10-30 17:01:57: [2024-10-30 17:01:57] iter = 04100, loss = 7.8264
2024-10-30 17:02:01: [2024-10-30 17:02:01] iter = 04110, loss = 16.0900
2024-10-30 17:02:06: [2024-10-30 17:02:06] iter = 04120, loss = 34.4006
2024-10-30 17:02:10: [2024-10-30 17:02:10] iter = 04130, loss = 53.2135
2024-10-30 17:02:15: [2024-10-30 17:02:15] iter = 04140, loss = 27.1497
2024-10-30 17:02:20: [2024-10-30 17:02:20] iter = 04150, loss = 14.2300
2024-10-30 17:02:25: [2024-10-30 17:02:25] iter = 04160, loss = 4.7885
2024-10-30 17:02:29: [2024-10-30 17:02:29] iter = 04170, loss = 46.4020
2024-10-30 17:02:34: [2024-10-30 17:02:34] iter = 04180, loss = 49.1123
2024-10-30 17:02:39: [2024-10-30 17:02:39] iter = 04190, loss = 4.4617
2024-10-30 17:02:43: [2024-10-30 17:02:43] iter = 04200, loss = 17.8074
2024-10-30 17:02:48: [2024-10-30 17:02:48] iter = 04210, loss = 3.8469
2024-10-30 17:02:53: [2024-10-30 17:02:53] iter = 04220, loss = 10.4085
2024-10-30 17:02:58: [2024-10-30 17:02:58] iter = 04230, loss = 4.7108
2024-10-30 17:03:03: [2024-10-30 17:03:03] iter = 04240, loss = 27.0378
2024-10-30 17:03:07: [2024-10-30 17:03:07] iter = 04250, loss = 10.1376
2024-10-30 17:03:12: [2024-10-30 17:03:12] iter = 04260, loss = 44.1233
2024-10-30 17:03:17: [2024-10-30 17:03:17] iter = 04270, loss = 13.4103
2024-10-30 17:03:21: [2024-10-30 17:03:21] iter = 04280, loss = 11.6220
2024-10-30 17:03:27: [2024-10-30 17:03:27] iter = 04290, loss = 3.5166
2024-10-30 17:03:31: [2024-10-30 17:03:31] iter = 04300, loss = 4.9102
2024-10-30 17:03:34: [2024-10-30 17:03:34] iter = 04310, loss = 5.3331
2024-10-30 17:03:38: [2024-10-30 17:03:38] iter = 04320, loss = 5.2841
2024-10-30 17:03:43: [2024-10-30 17:03:43] iter = 04330, loss = 3.4827
2024-10-30 17:03:48: [2024-10-30 17:03:48] iter = 04340, loss = 4.9298
2024-10-30 17:03:52: [2024-10-30 17:03:52] iter = 04350, loss = 19.1414
2024-10-30 17:03:55: [2024-10-30 17:03:55] iter = 04360, loss = 10.8330
2024-10-30 17:04:00: [2024-10-30 17:04:00] iter = 04370, loss = 37.0947
2024-10-30 17:04:04: [2024-10-30 17:04:04] iter = 04380, loss = 4.8992
2024-10-30 17:04:08: [2024-10-30 17:04:08] iter = 04390, loss = 30.7271
2024-10-30 17:04:12: [2024-10-30 17:04:12] iter = 04400, loss = 6.4221
2024-10-30 17:04:17: [2024-10-30 17:04:17] iter = 04410, loss = 19.5175
2024-10-30 17:04:21: [2024-10-30 17:04:21] iter = 04420, loss = 52.0024
2024-10-30 17:04:25: [2024-10-30 17:04:25] iter = 04430, loss = 56.6182
2024-10-30 17:04:30: [2024-10-30 17:04:30] iter = 04440, loss = 4.0871
2024-10-30 17:04:35: [2024-10-30 17:04:35] iter = 04450, loss = 3.6631
2024-10-30 17:04:39: [2024-10-30 17:04:39] iter = 04460, loss = 11.7397
2024-10-30 17:04:42: [2024-10-30 17:04:42] iter = 04470, loss = 34.4305
2024-10-30 17:04:46: [2024-10-30 17:04:46] iter = 04480, loss = 64.8915
2024-10-30 17:04:50: [2024-10-30 17:04:50] iter = 04490, loss = 5.4744
2024-10-30 17:04:55: [2024-10-30 17:04:55] iter = 04500, loss = 9.8489
2024-10-30 17:05:00: [2024-10-30 17:05:00] iter = 04510, loss = 6.2118
2024-10-30 17:05:04: [2024-10-30 17:05:04] iter = 04520, loss = 6.5287
2024-10-30 17:05:08: [2024-10-30 17:05:08] iter = 04530, loss = 26.5585
2024-10-30 17:05:12: [2024-10-30 17:05:12] iter = 04540, loss = 27.4272
2024-10-30 17:05:17: [2024-10-30 17:05:17] iter = 04550, loss = 5.2606
2024-10-30 17:05:21: [2024-10-30 17:05:21] iter = 04560, loss = 10.8111
2024-10-30 17:05:25: [2024-10-30 17:05:25] iter = 04570, loss = 5.6463
2024-10-30 17:05:30: [2024-10-30 17:05:30] iter = 04580, loss = 4.2371
2024-10-30 17:05:34: [2024-10-30 17:05:34] iter = 04590, loss = 96.1097
2024-10-30 17:05:39: [2024-10-30 17:05:39] iter = 04600, loss = 9.0508
2024-10-30 17:05:43: [2024-10-30 17:05:43] iter = 04610, loss = 61.5154
2024-10-30 17:05:47: [2024-10-30 17:05:47] iter = 04620, loss = 18.0731
2024-10-30 17:05:51: [2024-10-30 17:05:51] iter = 04630, loss = 31.2039
2024-10-30 17:05:56: [2024-10-30 17:05:56] iter = 04640, loss = 3.7296
2024-10-30 17:06:00: [2024-10-30 17:06:00] iter = 04650, loss = 23.5449
2024-10-30 17:06:02: [2024-10-30 17:06:02] iter = 04660, loss = 33.3004
2024-10-30 17:06:05: [2024-10-30 17:06:05] iter = 04670, loss = 3.8767
2024-10-30 17:06:10: [2024-10-30 17:06:10] iter = 04680, loss = 8.2786
2024-10-30 17:06:15: [2024-10-30 17:06:15] iter = 04690, loss = 3.8741
2024-10-30 17:06:19: [2024-10-30 17:06:19] iter = 04700, loss = 40.8384
2024-10-30 17:06:22: [2024-10-30 17:06:22] iter = 04710, loss = 8.6692
2024-10-30 17:06:26: [2024-10-30 17:06:26] iter = 04720, loss = 5.3319
2024-10-30 17:06:32: [2024-10-30 17:06:32] iter = 04730, loss = 47.4281
2024-10-30 17:06:37: [2024-10-30 17:06:37] iter = 04740, loss = 4.2972
2024-10-30 17:06:42: [2024-10-30 17:06:42] iter = 04750, loss = 10.4571
2024-10-30 17:06:46: [2024-10-30 17:06:46] iter = 04760, loss = 6.1716
2024-10-30 17:06:51: [2024-10-30 17:06:51] iter = 04770, loss = 27.8168
2024-10-30 17:06:55: [2024-10-30 17:06:55] iter = 04780, loss = 4.7047
2024-10-30 17:07:00: [2024-10-30 17:07:00] iter = 04790, loss = 13.8503
2024-10-30 17:07:04: [2024-10-30 17:07:04] iter = 04800, loss = 5.1144
2024-10-30 17:07:08: [2024-10-30 17:07:08] iter = 04810, loss = 63.6865
2024-10-30 17:07:13: [2024-10-30 17:07:13] iter = 04820, loss = 21.8040
2024-10-30 17:07:16: [2024-10-30 17:07:16] iter = 04830, loss = 14.1789
2024-10-30 17:07:18: [2024-10-30 17:07:18] iter = 04840, loss = 3.7798
2024-10-30 17:07:22: [2024-10-30 17:07:22] iter = 04850, loss = 5.4035
2024-10-30 17:07:26: [2024-10-30 17:07:26] iter = 04860, loss = 22.8252
2024-10-30 17:07:30: [2024-10-30 17:07:30] iter = 04870, loss = 12.3015
2024-10-30 17:07:34: [2024-10-30 17:07:34] iter = 04880, loss = 58.0949
2024-10-30 17:07:38: [2024-10-30 17:07:38] iter = 04890, loss = 62.3179
2024-10-30 17:07:43: [2024-10-30 17:07:43] iter = 04900, loss = 6.7860
2024-10-30 17:07:46: [2024-10-30 17:07:46] iter = 04910, loss = 4.6033
2024-10-30 17:07:50: [2024-10-30 17:07:50] iter = 04920, loss = 5.7664
2024-10-30 17:07:55: [2024-10-30 17:07:55] iter = 04930, loss = 5.5780
2024-10-30 17:07:59: [2024-10-30 17:07:59] iter = 04940, loss = 12.7528
2024-10-30 17:08:03: [2024-10-30 17:08:03] iter = 04950, loss = 22.0812
2024-10-30 17:08:07: [2024-10-30 17:08:07] iter = 04960, loss = 30.6836
2024-10-30 17:08:10: [2024-10-30 17:08:10] iter = 04970, loss = 29.0947
2024-10-30 17:08:13: [2024-10-30 17:08:13] iter = 04980, loss = 4.8754
2024-10-30 17:08:15: [2024-10-30 17:08:15] iter = 04990, loss = 4.5388
2024-10-30 17:08:17: [2024-10-30 17:08:17] iter = 05000, loss = 63.0783
2024-10-30 17:08:21: [2024-10-30 17:08:21] iter = 05010, loss = 6.7419
2024-10-30 17:08:25: [2024-10-30 17:08:25] iter = 05020, loss = 11.4892
2024-10-30 17:08:28: [2024-10-30 17:08:28] iter = 05030, loss = 10.2003
2024-10-30 17:08:32: [2024-10-30 17:08:32] iter = 05040, loss = 6.8122
2024-10-30 17:08:38: [2024-10-30 17:08:38] iter = 05050, loss = 5.2713
2024-10-30 17:08:42: [2024-10-30 17:08:42] iter = 05060, loss = 26.5487
2024-10-30 17:08:48: [2024-10-30 17:08:48] iter = 05070, loss = 9.1251
2024-10-30 17:08:52: [2024-10-30 17:08:52] iter = 05080, loss = 13.2969
2024-10-30 17:08:56: [2024-10-30 17:08:56] iter = 05090, loss = 5.3342
2024-10-30 17:09:00: [2024-10-30 17:09:00] iter = 05100, loss = 21.5612
2024-10-30 17:09:05: [2024-10-30 17:09:05] iter = 05110, loss = 44.4927
2024-10-30 17:09:09: [2024-10-30 17:09:09] iter = 05120, loss = 5.2742
2024-10-30 17:09:13: [2024-10-30 17:09:13] iter = 05130, loss = 32.5634
2024-10-30 17:09:17: [2024-10-30 17:09:17] iter = 05140, loss = 11.5123
2024-10-30 17:09:22: [2024-10-30 17:09:22] iter = 05150, loss = 34.1728
2024-10-30 17:09:26: [2024-10-30 17:09:26] iter = 05160, loss = 4.4392
2024-10-30 17:09:32: [2024-10-30 17:09:32] iter = 05170, loss = 4.4172
2024-10-30 17:09:37: [2024-10-30 17:09:37] iter = 05180, loss = 22.0314
2024-10-30 17:09:41: [2024-10-30 17:09:41] iter = 05190, loss = 9.0842
2024-10-30 17:09:47: [2024-10-30 17:09:47] iter = 05200, loss = 14.7965
2024-10-30 17:09:51: [2024-10-30 17:09:51] iter = 05210, loss = 31.5904
2024-10-30 17:09:55: [2024-10-30 17:09:55] iter = 05220, loss = 6.5727
2024-10-30 17:10:00: [2024-10-30 17:10:00] iter = 05230, loss = 17.7963
2024-10-30 17:10:04: [2024-10-30 17:10:04] iter = 05240, loss = 11.9057
2024-10-30 17:10:07: [2024-10-30 17:10:07] iter = 05250, loss = 5.0423
2024-10-30 17:10:12: [2024-10-30 17:10:12] iter = 05260, loss = 4.5556
2024-10-30 17:10:15: [2024-10-30 17:10:15] iter = 05270, loss = 7.8513
2024-10-30 17:10:20: [2024-10-30 17:10:20] iter = 05280, loss = 4.5286
2024-10-30 17:10:23: [2024-10-30 17:10:23] iter = 05290, loss = 10.9906
2024-10-30 17:10:27: [2024-10-30 17:10:27] iter = 05300, loss = 4.1683
2024-10-30 17:10:31: [2024-10-30 17:10:31] iter = 05310, loss = 4.9801
2024-10-30 17:10:36: [2024-10-30 17:10:36] iter = 05320, loss = 5.8440
2024-10-30 17:10:40: [2024-10-30 17:10:40] iter = 05330, loss = 6.6860
2024-10-30 17:10:43: [2024-10-30 17:10:43] iter = 05340, loss = 62.8181
2024-10-30 17:10:47: [2024-10-30 17:10:47] iter = 05350, loss = 10.0092
2024-10-30 17:10:51: [2024-10-30 17:10:51] iter = 05360, loss = 48.1672
2024-10-30 17:10:55: [2024-10-30 17:10:55] iter = 05370, loss = 5.1109
2024-10-30 17:10:59: [2024-10-30 17:10:59] iter = 05380, loss = 26.8596
2024-10-30 17:11:03: [2024-10-30 17:11:03] iter = 05390, loss = 9.7431
2024-10-30 17:11:08: [2024-10-30 17:11:08] iter = 05400, loss = 34.8145
2024-10-30 17:11:12: [2024-10-30 17:11:12] iter = 05410, loss = 6.7951
2024-10-30 17:11:17: [2024-10-30 17:11:17] iter = 05420, loss = 55.6035
2024-10-30 17:11:21: [2024-10-30 17:11:21] iter = 05430, loss = 7.2800
2024-10-30 17:11:25: [2024-10-30 17:11:25] iter = 05440, loss = 13.6324
2024-10-30 17:11:29: [2024-10-30 17:11:29] iter = 05450, loss = 7.2237
2024-10-30 17:11:33: [2024-10-30 17:11:33] iter = 05460, loss = 20.9933
2024-10-30 17:11:37: [2024-10-30 17:11:37] iter = 05470, loss = 6.0279
2024-10-30 17:11:42: [2024-10-30 17:11:42] iter = 05480, loss = 27.2777
2024-10-30 17:11:46: [2024-10-30 17:11:46] iter = 05490, loss = 50.2728
2024-10-30 17:11:50: [2024-10-30 17:11:50] iter = 05500, loss = 4.7159
2024-10-30 17:11:54: [2024-10-30 17:11:54] iter = 05510, loss = 3.9180
2024-10-30 17:11:59: [2024-10-30 17:11:59] iter = 05520, loss = 52.1457
2024-10-30 17:12:03: [2024-10-30 17:12:03] iter = 05530, loss = 5.0942
2024-10-30 17:12:07: [2024-10-30 17:12:07] iter = 05540, loss = 7.5947
2024-10-30 17:12:10: [2024-10-30 17:12:10] iter = 05550, loss = 16.8100
2024-10-30 17:12:13: [2024-10-30 17:12:13] iter = 05560, loss = 17.6770
2024-10-30 17:12:17: [2024-10-30 17:12:17] iter = 05570, loss = 39.6259
2024-10-30 17:12:20: [2024-10-30 17:12:20] iter = 05580, loss = 31.3824
2024-10-30 17:12:24: [2024-10-30 17:12:24] iter = 05590, loss = 5.6794
2024-10-30 17:12:29: [2024-10-30 17:12:29] iter = 05600, loss = 5.9425
2024-10-30 17:12:32: [2024-10-30 17:12:32] iter = 05610, loss = 104.3156
2024-10-30 17:12:35: [2024-10-30 17:12:35] iter = 05620, loss = 4.7380
2024-10-30 17:12:40: [2024-10-30 17:12:40] iter = 05630, loss = 34.8091
2024-10-30 17:12:44: [2024-10-30 17:12:44] iter = 05640, loss = 60.6952
2024-10-30 17:12:48: [2024-10-30 17:12:48] iter = 05650, loss = 9.5627
2024-10-30 17:12:52: [2024-10-30 17:12:52] iter = 05660, loss = 15.5146
2024-10-30 17:12:57: [2024-10-30 17:12:57] iter = 05670, loss = 19.9274
2024-10-30 17:13:01: [2024-10-30 17:13:01] iter = 05680, loss = 5.0029
2024-10-30 17:13:05: [2024-10-30 17:13:05] iter = 05690, loss = 31.7374
2024-10-30 17:13:08: [2024-10-30 17:13:08] iter = 05700, loss = 24.5934
2024-10-30 17:13:12: [2024-10-30 17:13:12] iter = 05710, loss = 14.3676
2024-10-30 17:13:16: [2024-10-30 17:13:16] iter = 05720, loss = 53.4459
2024-10-30 17:13:19: [2024-10-30 17:13:19] iter = 05730, loss = 45.9148
2024-10-30 17:13:23: [2024-10-30 17:13:23] iter = 05740, loss = 57.4169
2024-10-30 17:13:27: [2024-10-30 17:13:27] iter = 05750, loss = 41.0064
2024-10-30 17:13:29: [2024-10-30 17:13:29] iter = 05760, loss = 23.0509
2024-10-30 17:13:32: [2024-10-30 17:13:32] iter = 05770, loss = 15.4540
2024-10-30 17:13:36: [2024-10-30 17:13:36] iter = 05780, loss = 11.8525
2024-10-30 17:13:40: [2024-10-30 17:13:40] iter = 05790, loss = 15.6297
2024-10-30 17:13:44: [2024-10-30 17:13:44] iter = 05800, loss = 7.7278
2024-10-30 17:13:48: [2024-10-30 17:13:48] iter = 05810, loss = 8.3683
2024-10-30 17:13:53: [2024-10-30 17:13:53] iter = 05820, loss = 7.3540
2024-10-30 17:13:57: [2024-10-30 17:13:57] iter = 05830, loss = 42.4531
2024-10-30 17:14:01: [2024-10-30 17:14:01] iter = 05840, loss = 22.8194
2024-10-30 17:14:03: [2024-10-30 17:14:03] iter = 05850, loss = 4.4598
2024-10-30 17:14:06: [2024-10-30 17:14:06] iter = 05860, loss = 22.0400
2024-10-30 17:14:11: [2024-10-30 17:14:11] iter = 05870, loss = 15.8204
2024-10-30 17:14:15: [2024-10-30 17:14:15] iter = 05880, loss = 5.1248
2024-10-30 17:14:18: [2024-10-30 17:14:18] iter = 05890, loss = 66.3388
2024-10-30 17:14:21: [2024-10-30 17:14:21] iter = 05900, loss = 11.4055
2024-10-30 17:14:24: [2024-10-30 17:14:24] iter = 05910, loss = 48.3259
2024-10-30 17:14:28: [2024-10-30 17:14:28] iter = 05920, loss = 8.7875
2024-10-30 17:14:32: [2024-10-30 17:14:32] iter = 05930, loss = 4.2488
2024-10-30 17:14:36: [2024-10-30 17:14:36] iter = 05940, loss = 4.5336
2024-10-30 17:14:41: [2024-10-30 17:14:41] iter = 05950, loss = 64.8730
2024-10-30 17:14:44: [2024-10-30 17:14:44] iter = 05960, loss = 7.7927
2024-10-30 17:14:48: [2024-10-30 17:14:48] iter = 05970, loss = 42.5984
2024-10-30 17:14:52: [2024-10-30 17:14:52] iter = 05980, loss = 22.9482
2024-10-30 17:14:56: [2024-10-30 17:14:56] iter = 05990, loss = 17.9466
2024-10-30 17:15:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 17:15:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:15:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 277}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:24: Evaluate 5 random ConvNet, ACCmean = 0.3435 ACCstd = 0.0076
-------------------------
2024-10-30 17:17:24: Evaluate 5 random ConvNet, SENmean = 0.2851 SENstd = 0.0042
-------------------------
2024-10-30 17:17:24: Evaluate 5 random ConvNet, SPEmean = 0.9047 SPEstd = 0.0006
-------------------------
2024-10-30 17:17:24: Evaluate 5 random ConvNet, F!mean = 0.2662 F!std = 0.0051
-------------------------
2024-10-30 17:17:24: Evaluate 5 random ConvNet, mean = 0.3435 std = 0.0076
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:17:24: [2024-10-30 17:17:24] iter = 06000, loss = 19.1587
2024-10-30 17:17:29: [2024-10-30 17:17:29] iter = 06010, loss = 30.1356
2024-10-30 17:17:34: [2024-10-30 17:17:34] iter = 06020, loss = 4.5729
2024-10-30 17:17:39: [2024-10-30 17:17:39] iter = 06030, loss = 14.3279
2024-10-30 17:17:44: [2024-10-30 17:17:44] iter = 06040, loss = 38.3761
2024-10-30 17:17:47: [2024-10-30 17:17:47] iter = 06050, loss = 30.4063
2024-10-30 17:17:52: [2024-10-30 17:17:52] iter = 06060, loss = 45.3087
2024-10-30 17:17:55: [2024-10-30 17:17:55] iter = 06070, loss = 17.5149
2024-10-30 17:18:00: [2024-10-30 17:18:00] iter = 06080, loss = 4.1097
2024-10-30 17:18:04: [2024-10-30 17:18:04] iter = 06090, loss = 102.6388
2024-10-30 17:18:09: [2024-10-30 17:18:09] iter = 06100, loss = 11.6720
2024-10-30 17:18:14: [2024-10-30 17:18:14] iter = 06110, loss = 17.8540
2024-10-30 17:18:18: [2024-10-30 17:18:18] iter = 06120, loss = 13.6304
2024-10-30 17:18:23: [2024-10-30 17:18:23] iter = 06130, loss = 5.5340
2024-10-30 17:18:27: [2024-10-30 17:18:27] iter = 06140, loss = 5.1248
2024-10-30 17:18:29: [2024-10-30 17:18:29] iter = 06150, loss = 36.5847
2024-10-30 17:18:33: [2024-10-30 17:18:33] iter = 06160, loss = 63.5143
2024-10-30 17:18:38: [2024-10-30 17:18:38] iter = 06170, loss = 8.0115
2024-10-30 17:18:43: [2024-10-30 17:18:43] iter = 06180, loss = 21.9643
2024-10-30 17:18:47: [2024-10-30 17:18:47] iter = 06190, loss = 15.9265
2024-10-30 17:18:50: [2024-10-30 17:18:50] iter = 06200, loss = 5.6899
2024-10-30 17:18:54: [2024-10-30 17:18:54] iter = 06210, loss = 3.5040
2024-10-30 17:18:58: [2024-10-30 17:18:58] iter = 06220, loss = 26.7297
2024-10-30 17:19:02: [2024-10-30 17:19:02] iter = 06230, loss = 12.0334
2024-10-30 17:19:05: [2024-10-30 17:19:05] iter = 06240, loss = 22.9590
2024-10-30 17:19:10: [2024-10-30 17:19:10] iter = 06250, loss = 26.6247
2024-10-30 17:19:14: [2024-10-30 17:19:14] iter = 06260, loss = 4.9647
2024-10-30 17:19:19: [2024-10-30 17:19:19] iter = 06270, loss = 43.0018
2024-10-30 17:19:24: [2024-10-30 17:19:24] iter = 06280, loss = 18.5916
2024-10-30 17:19:29: [2024-10-30 17:19:29] iter = 06290, loss = 38.5493
2024-10-30 17:19:33: [2024-10-30 17:19:33] iter = 06300, loss = 4.0893
2024-10-30 17:19:38: [2024-10-30 17:19:38] iter = 06310, loss = 4.8524
2024-10-30 17:19:42: [2024-10-30 17:19:42] iter = 06320, loss = 49.0365
2024-10-30 17:19:47: [2024-10-30 17:19:47] iter = 06330, loss = 6.8335
2024-10-30 17:19:52: [2024-10-30 17:19:52] iter = 06340, loss = 6.7326
2024-10-30 17:19:56: [2024-10-30 17:19:56] iter = 06350, loss = 6.9318
2024-10-30 17:20:01: [2024-10-30 17:20:01] iter = 06360, loss = 8.4162
2024-10-30 17:20:04: [2024-10-30 17:20:04] iter = 06370, loss = 62.7505
2024-10-30 17:20:08: [2024-10-30 17:20:08] iter = 06380, loss = 4.1650
2024-10-30 17:20:13: [2024-10-30 17:20:13] iter = 06390, loss = 4.1887
2024-10-30 17:20:19: [2024-10-30 17:20:19] iter = 06400, loss = 14.0161
2024-10-30 17:20:23: [2024-10-30 17:20:23] iter = 06410, loss = 11.9163
2024-10-30 17:20:26: [2024-10-30 17:20:26] iter = 06420, loss = 45.9380
2024-10-30 17:20:31: [2024-10-30 17:20:31] iter = 06430, loss = 7.1572
2024-10-30 17:20:35: [2024-10-30 17:20:35] iter = 06440, loss = 11.7517
2024-10-30 17:20:39: [2024-10-30 17:20:39] iter = 06450, loss = 3.9858
2024-10-30 17:20:44: [2024-10-30 17:20:44] iter = 06460, loss = 4.8511
2024-10-30 17:20:48: [2024-10-30 17:20:48] iter = 06470, loss = 22.6624
2024-10-30 17:20:51: [2024-10-30 17:20:51] iter = 06480, loss = 6.4388
2024-10-30 17:20:57: [2024-10-30 17:20:57] iter = 06490, loss = 28.7388
2024-10-30 17:20:58: [2024-10-30 17:20:58] iter = 06500, loss = 6.3556
2024-10-30 17:21:01: [2024-10-30 17:21:01] iter = 06510, loss = 3.9741
2024-10-30 17:21:04: [2024-10-30 17:21:04] iter = 06520, loss = 22.0313
2024-10-30 17:21:07: [2024-10-30 17:21:07] iter = 06530, loss = 14.2368
2024-10-30 17:21:11: [2024-10-30 17:21:11] iter = 06540, loss = 4.0830
2024-10-30 17:21:16: [2024-10-30 17:21:16] iter = 06550, loss = 3.7989
2024-10-30 17:21:19: [2024-10-30 17:21:19] iter = 06560, loss = 35.3231
2024-10-30 17:21:23: [2024-10-30 17:21:23] iter = 06570, loss = 22.6523
2024-10-30 17:21:26: [2024-10-30 17:21:26] iter = 06580, loss = 5.0381
2024-10-30 17:21:30: [2024-10-30 17:21:30] iter = 06590, loss = 11.8872
2024-10-30 17:21:35: [2024-10-30 17:21:35] iter = 06600, loss = 6.2230
2024-10-30 17:21:39: [2024-10-30 17:21:39] iter = 06610, loss = 4.0030
2024-10-30 17:21:44: [2024-10-30 17:21:44] iter = 06620, loss = 18.3270
2024-10-30 17:21:47: [2024-10-30 17:21:47] iter = 06630, loss = 4.2833
2024-10-30 17:21:51: [2024-10-30 17:21:51] iter = 06640, loss = 39.0624
2024-10-30 17:21:55: [2024-10-30 17:21:55] iter = 06650, loss = 44.8848
2024-10-30 17:22:00: [2024-10-30 17:22:00] iter = 06660, loss = 54.9934
2024-10-30 17:22:04: [2024-10-30 17:22:04] iter = 06670, loss = 4.4884
2024-10-30 17:22:08: [2024-10-30 17:22:08] iter = 06680, loss = 11.2681
2024-10-30 17:22:12: [2024-10-30 17:22:12] iter = 06690, loss = 32.9133
2024-10-30 17:22:17: [2024-10-30 17:22:17] iter = 06700, loss = 10.5387
2024-10-30 17:22:22: [2024-10-30 17:22:22] iter = 06710, loss = 5.2131
2024-10-30 17:22:26: [2024-10-30 17:22:26] iter = 06720, loss = 4.9652
2024-10-30 17:22:29: [2024-10-30 17:22:29] iter = 06730, loss = 9.8442
2024-10-30 17:22:33: [2024-10-30 17:22:33] iter = 06740, loss = 4.8659
2024-10-30 17:22:37: [2024-10-30 17:22:37] iter = 06750, loss = 19.2837
2024-10-30 17:22:41: [2024-10-30 17:22:41] iter = 06760, loss = 10.9811
2024-10-30 17:22:44: [2024-10-30 17:22:44] iter = 06770, loss = 61.3320
2024-10-30 17:22:49: [2024-10-30 17:22:49] iter = 06780, loss = 25.6438
2024-10-30 17:22:53: [2024-10-30 17:22:53] iter = 06790, loss = 6.2771
2024-10-30 17:22:56: [2024-10-30 17:22:56] iter = 06800, loss = 17.4249
2024-10-30 17:22:59: [2024-10-30 17:22:59] iter = 06810, loss = 16.5277
2024-10-30 17:23:04: [2024-10-30 17:23:04] iter = 06820, loss = 21.0298
2024-10-30 17:23:07: [2024-10-30 17:23:07] iter = 06830, loss = 39.3478
2024-10-30 17:23:11: [2024-10-30 17:23:11] iter = 06840, loss = 4.4074
2024-10-30 17:23:15: [2024-10-30 17:23:15] iter = 06850, loss = 4.4581
2024-10-30 17:23:20: [2024-10-30 17:23:19] iter = 06860, loss = 12.7162
2024-10-30 17:23:23: [2024-10-30 17:23:23] iter = 06870, loss = 15.2886
2024-10-30 17:23:28: [2024-10-30 17:23:28] iter = 06880, loss = 6.4695
2024-10-30 17:23:32: [2024-10-30 17:23:32] iter = 06890, loss = 103.2690
2024-10-30 17:23:36: [2024-10-30 17:23:36] iter = 06900, loss = 69.5862
2024-10-30 17:23:41: [2024-10-30 17:23:41] iter = 06910, loss = 49.1390
2024-10-30 17:23:45: [2024-10-30 17:23:45] iter = 06920, loss = 14.8008
2024-10-30 17:23:50: [2024-10-30 17:23:50] iter = 06930, loss = 11.3142
2024-10-30 17:23:54: [2024-10-30 17:23:54] iter = 06940, loss = 5.0582
2024-10-30 17:23:59: [2024-10-30 17:23:59] iter = 06950, loss = 24.4324
2024-10-30 17:24:05: [2024-10-30 17:24:05] iter = 06960, loss = 7.6319
2024-10-30 17:24:09: [2024-10-30 17:24:09] iter = 06970, loss = 96.7179
2024-10-30 17:24:14: [2024-10-30 17:24:14] iter = 06980, loss = 11.8655
2024-10-30 17:24:18: [2024-10-30 17:24:18] iter = 06990, loss = 16.0458
2024-10-30 17:24:23: [2024-10-30 17:24:23] iter = 07000, loss = 32.1478
2024-10-30 17:24:29: [2024-10-30 17:24:29] iter = 07010, loss = 5.0284
2024-10-30 17:24:34: [2024-10-30 17:24:34] iter = 07020, loss = 24.6208
2024-10-30 17:24:38: [2024-10-30 17:24:38] iter = 07030, loss = 18.6680
2024-10-30 17:24:42: [2024-10-30 17:24:42] iter = 07040, loss = 9.0319
2024-10-30 17:24:46: [2024-10-30 17:24:46] iter = 07050, loss = 13.7009
2024-10-30 17:24:50: [2024-10-30 17:24:50] iter = 07060, loss = 8.1101
2024-10-30 17:24:53: [2024-10-30 17:24:53] iter = 07070, loss = 8.3175
2024-10-30 17:24:57: [2024-10-30 17:24:57] iter = 07080, loss = 11.6779
2024-10-30 17:25:01: [2024-10-30 17:25:01] iter = 07090, loss = 9.2589
2024-10-30 17:25:06: [2024-10-30 17:25:06] iter = 07100, loss = 5.7752
2024-10-30 17:25:10: [2024-10-30 17:25:10] iter = 07110, loss = 89.9023
2024-10-30 17:25:15: [2024-10-30 17:25:15] iter = 07120, loss = 27.5031
2024-10-30 17:25:20: [2024-10-30 17:25:20] iter = 07130, loss = 12.1158
2024-10-30 17:25:26: [2024-10-30 17:25:26] iter = 07140, loss = 48.1956
2024-10-30 17:25:31: [2024-10-30 17:25:31] iter = 07150, loss = 38.2910
2024-10-30 17:25:35: [2024-10-30 17:25:35] iter = 07160, loss = 4.0615
2024-10-30 17:25:40: [2024-10-30 17:25:40] iter = 07170, loss = 33.2310
2024-10-30 17:25:45: [2024-10-30 17:25:45] iter = 07180, loss = 14.0903
2024-10-30 17:25:49: [2024-10-30 17:25:49] iter = 07190, loss = 4.3072
2024-10-30 17:25:53: [2024-10-30 17:25:53] iter = 07200, loss = 3.9143
2024-10-30 17:25:58: [2024-10-30 17:25:58] iter = 07210, loss = 6.3818
2024-10-30 17:26:03: [2024-10-30 17:26:03] iter = 07220, loss = 17.6209
2024-10-30 17:26:06: [2024-10-30 17:26:06] iter = 07230, loss = 48.8340
2024-10-30 17:26:10: [2024-10-30 17:26:10] iter = 07240, loss = 6.1484
2024-10-30 17:26:14: [2024-10-30 17:26:14] iter = 07250, loss = 33.4280
2024-10-30 17:26:17: [2024-10-30 17:26:17] iter = 07260, loss = 36.7803
2024-10-30 17:26:21: [2024-10-30 17:26:21] iter = 07270, loss = 30.8597
2024-10-30 17:26:26: [2024-10-30 17:26:26] iter = 07280, loss = 10.9625
2024-10-30 17:26:31: [2024-10-30 17:26:31] iter = 07290, loss = 8.4292
2024-10-30 17:26:35: [2024-10-30 17:26:35] iter = 07300, loss = 6.6549
2024-10-30 17:26:40: [2024-10-30 17:26:40] iter = 07310, loss = 24.9521
2024-10-30 17:26:44: [2024-10-30 17:26:44] iter = 07320, loss = 4.4212
2024-10-30 17:26:49: [2024-10-30 17:26:49] iter = 07330, loss = 26.2001
2024-10-30 17:26:54: [2024-10-30 17:26:54] iter = 07340, loss = 3.7839
2024-10-30 17:26:58: [2024-10-30 17:26:58] iter = 07350, loss = 19.5745
2024-10-30 17:27:02: [2024-10-30 17:27:02] iter = 07360, loss = 5.4498
2024-10-30 17:27:07: [2024-10-30 17:27:07] iter = 07370, loss = 24.1057
2024-10-30 17:27:10: [2024-10-30 17:27:10] iter = 07380, loss = 8.9362
2024-10-30 17:27:12: [2024-10-30 17:27:12] iter = 07390, loss = 19.1343
2024-10-30 17:27:17: [2024-10-30 17:27:17] iter = 07400, loss = 31.2319
2024-10-30 17:27:22: [2024-10-30 17:27:22] iter = 07410, loss = 5.3434
2024-10-30 17:27:28: [2024-10-30 17:27:28] iter = 07420, loss = 7.0708
2024-10-30 17:27:33: [2024-10-30 17:27:33] iter = 07430, loss = 6.2551
2024-10-30 17:27:38: [2024-10-30 17:27:38] iter = 07440, loss = 8.5197
2024-10-30 17:27:41: [2024-10-30 17:27:41] iter = 07450, loss = 6.4562
2024-10-30 17:27:44: [2024-10-30 17:27:44] iter = 07460, loss = 72.0086
2024-10-30 17:27:49: [2024-10-30 17:27:49] iter = 07470, loss = 4.0782
2024-10-30 17:27:52: [2024-10-30 17:27:52] iter = 07480, loss = 9.0959
2024-10-30 17:27:56: [2024-10-30 17:27:56] iter = 07490, loss = 5.1069
2024-10-30 17:28:00: [2024-10-30 17:28:00] iter = 07500, loss = 7.3933
2024-10-30 17:28:05: [2024-10-30 17:28:05] iter = 07510, loss = 8.3166
2024-10-30 17:28:10: [2024-10-30 17:28:10] iter = 07520, loss = 3.7707
2024-10-30 17:28:14: [2024-10-30 17:28:14] iter = 07530, loss = 11.8736
2024-10-30 17:28:19: [2024-10-30 17:28:19] iter = 07540, loss = 14.9449
2024-10-30 17:28:22: [2024-10-30 17:28:22] iter = 07550, loss = 13.2864
2024-10-30 17:28:27: [2024-10-30 17:28:27] iter = 07560, loss = 13.8745
2024-10-30 17:28:31: [2024-10-30 17:28:31] iter = 07570, loss = 41.3207
2024-10-30 17:28:35: [2024-10-30 17:28:35] iter = 07580, loss = 4.9928
2024-10-30 17:28:39: [2024-10-30 17:28:39] iter = 07590, loss = 8.7034
2024-10-30 17:28:43: [2024-10-30 17:28:43] iter = 07600, loss = 47.0229
2024-10-30 17:28:47: [2024-10-30 17:28:47] iter = 07610, loss = 39.6916
2024-10-30 17:28:51: [2024-10-30 17:28:51] iter = 07620, loss = 7.3475
2024-10-30 17:28:55: [2024-10-30 17:28:55] iter = 07630, loss = 5.0882
2024-10-30 17:29:00: [2024-10-30 17:29:00] iter = 07640, loss = 7.3139
2024-10-30 17:29:03: [2024-10-30 17:29:03] iter = 07650, loss = 13.0099
2024-10-30 17:29:07: [2024-10-30 17:29:07] iter = 07660, loss = 75.4612
2024-10-30 17:29:11: [2024-10-30 17:29:11] iter = 07670, loss = 19.4059
2024-10-30 17:29:15: [2024-10-30 17:29:15] iter = 07680, loss = 4.1267
2024-10-30 17:29:19: [2024-10-30 17:29:19] iter = 07690, loss = 5.4188
2024-10-30 17:29:23: [2024-10-30 17:29:23] iter = 07700, loss = 16.1796
2024-10-30 17:29:27: [2024-10-30 17:29:27] iter = 07710, loss = 6.8957
2024-10-30 17:29:31: [2024-10-30 17:29:31] iter = 07720, loss = 12.0289
2024-10-30 17:29:36: [2024-10-30 17:29:36] iter = 07730, loss = 57.8630
2024-10-30 17:29:39: [2024-10-30 17:29:39] iter = 07740, loss = 5.8029
2024-10-30 17:29:43: [2024-10-30 17:29:43] iter = 07750, loss = 8.8494
2024-10-30 17:29:47: [2024-10-30 17:29:47] iter = 07760, loss = 8.0927
2024-10-30 17:29:50: [2024-10-30 17:29:50] iter = 07770, loss = 12.2031
2024-10-30 17:29:53: [2024-10-30 17:29:53] iter = 07780, loss = 11.5878
2024-10-30 17:29:57: [2024-10-30 17:29:57] iter = 07790, loss = 16.3140
2024-10-30 17:30:00: [2024-10-30 17:30:00] iter = 07800, loss = 21.0146
2024-10-30 17:30:05: [2024-10-30 17:30:05] iter = 07810, loss = 13.8652
2024-10-30 17:30:09: [2024-10-30 17:30:09] iter = 07820, loss = 3.5740
2024-10-30 17:30:13: [2024-10-30 17:30:13] iter = 07830, loss = 42.7959
2024-10-30 17:30:17: [2024-10-30 17:30:17] iter = 07840, loss = 42.3756
2024-10-30 17:30:22: [2024-10-30 17:30:22] iter = 07850, loss = 5.2714
2024-10-30 17:30:25: [2024-10-30 17:30:25] iter = 07860, loss = 18.1656
2024-10-30 17:30:30: [2024-10-30 17:30:30] iter = 07870, loss = 31.6672
2024-10-30 17:30:34: [2024-10-30 17:30:34] iter = 07880, loss = 13.5506
2024-10-30 17:30:38: [2024-10-30 17:30:38] iter = 07890, loss = 5.7874
2024-10-30 17:30:43: [2024-10-30 17:30:43] iter = 07900, loss = 24.4110
2024-10-30 17:30:48: [2024-10-30 17:30:48] iter = 07910, loss = 4.5741
2024-10-30 17:30:52: [2024-10-30 17:30:52] iter = 07920, loss = 20.9166
2024-10-30 17:30:57: [2024-10-30 17:30:57] iter = 07930, loss = 6.5195
2024-10-30 17:31:01: [2024-10-30 17:31:01] iter = 07940, loss = 41.2409
2024-10-30 17:31:05: [2024-10-30 17:31:05] iter = 07950, loss = 57.2597
2024-10-30 17:31:08: [2024-10-30 17:31:08] iter = 07960, loss = 9.1911
2024-10-30 17:31:12: [2024-10-30 17:31:12] iter = 07970, loss = 53.1020
2024-10-30 17:31:16: [2024-10-30 17:31:16] iter = 07980, loss = 4.4565
2024-10-30 17:31:20: [2024-10-30 17:31:20] iter = 07990, loss = 33.8059
2024-10-30 17:31:23: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 17:31:23: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:31:23: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 83483}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:54: Evaluate 5 random ConvNet, ACCmean = 0.3305 ACCstd = 0.0115
-------------------------
2024-10-30 17:33:54: Evaluate 5 random ConvNet, SENmean = 0.2879 SENstd = 0.0036
-------------------------
2024-10-30 17:33:54: Evaluate 5 random ConvNet, SPEmean = 0.9040 SPEstd = 0.0012
-------------------------
2024-10-30 17:33:54: Evaluate 5 random ConvNet, F!mean = 0.2397 F!std = 0.0055
-------------------------
2024-10-30 17:33:54: Evaluate 5 random ConvNet, mean = 0.3305 std = 0.0115
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:55: [2024-10-30 17:33:55] iter = 08000, loss = 12.1185
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:33:59: [2024-10-30 17:33:59] iter = 08010, loss = 41.8678
2024-10-30 17:34:03: [2024-10-30 17:34:03] iter = 08020, loss = 4.2664
2024-10-30 17:34:06: [2024-10-30 17:34:06] iter = 08030, loss = 53.7381
2024-10-30 17:34:08: [2024-10-30 17:34:08] iter = 08040, loss = 41.5118
2024-10-30 17:34:14: [2024-10-30 17:34:14] iter = 08050, loss = 6.8594
2024-10-30 17:34:18: [2024-10-30 17:34:18] iter = 08060, loss = 9.6421
2024-10-30 17:34:23: [2024-10-30 17:34:23] iter = 08070, loss = 7.2808
2024-10-30 17:34:27: [2024-10-30 17:34:27] iter = 08080, loss = 49.9208
2024-10-30 17:34:31: [2024-10-30 17:34:31] iter = 08090, loss = 24.6482
2024-10-30 17:34:35: [2024-10-30 17:34:35] iter = 08100, loss = 32.3211
2024-10-30 17:34:39: [2024-10-30 17:34:39] iter = 08110, loss = 55.7022
2024-10-30 17:34:43: [2024-10-30 17:34:43] iter = 08120, loss = 38.6570
2024-10-30 17:34:48: [2024-10-30 17:34:48] iter = 08130, loss = 4.9543
2024-10-30 17:34:52: [2024-10-30 17:34:52] iter = 08140, loss = 26.7885
2024-10-30 17:34:56: [2024-10-30 17:34:56] iter = 08150, loss = 5.7111
2024-10-30 17:35:00: [2024-10-30 17:35:00] iter = 08160, loss = 73.6832
2024-10-30 17:35:04: [2024-10-30 17:35:04] iter = 08170, loss = 10.2283
2024-10-30 17:35:08: [2024-10-30 17:35:08] iter = 08180, loss = 12.9546
2024-10-30 17:35:12: [2024-10-30 17:35:12] iter = 08190, loss = 5.7614
2024-10-30 17:35:17: [2024-10-30 17:35:17] iter = 08200, loss = 33.1045
2024-10-30 17:35:20: [2024-10-30 17:35:20] iter = 08210, loss = 4.1420
2024-10-30 17:35:24: [2024-10-30 17:35:24] iter = 08220, loss = 3.8156
2024-10-30 17:35:28: [2024-10-30 17:35:28] iter = 08230, loss = 3.8625
2024-10-30 17:35:32: [2024-10-30 17:35:32] iter = 08240, loss = 41.3530
2024-10-30 17:35:36: [2024-10-30 17:35:36] iter = 08250, loss = 38.1505
2024-10-30 17:35:40: [2024-10-30 17:35:40] iter = 08260, loss = 27.8924
2024-10-30 17:35:44: [2024-10-30 17:35:44] iter = 08270, loss = 10.7911
2024-10-30 17:35:49: [2024-10-30 17:35:49] iter = 08280, loss = 10.1880
2024-10-30 17:35:53: [2024-10-30 17:35:53] iter = 08290, loss = 13.0076
2024-10-30 17:35:58: [2024-10-30 17:35:58] iter = 08300, loss = 9.3093
2024-10-30 17:36:03: [2024-10-30 17:36:03] iter = 08310, loss = 6.0891
2024-10-30 17:36:07: [2024-10-30 17:36:07] iter = 08320, loss = 53.2561
2024-10-30 17:36:10: [2024-10-30 17:36:10] iter = 08330, loss = 9.6186
2024-10-30 17:36:14: [2024-10-30 17:36:14] iter = 08340, loss = 4.9034
2024-10-30 17:36:18: [2024-10-30 17:36:18] iter = 08350, loss = 6.2332
2024-10-30 17:36:23: [2024-10-30 17:36:23] iter = 08360, loss = 3.6195
2024-10-30 17:36:28: [2024-10-30 17:36:28] iter = 08370, loss = 41.0114
2024-10-30 17:36:33: [2024-10-30 17:36:33] iter = 08380, loss = 7.8186
2024-10-30 17:36:38: [2024-10-30 17:36:38] iter = 08390, loss = 33.1235
2024-10-30 17:36:42: [2024-10-30 17:36:42] iter = 08400, loss = 11.4834
2024-10-30 17:36:47: [2024-10-30 17:36:47] iter = 08410, loss = 5.7995
2024-10-30 17:36:51: [2024-10-30 17:36:51] iter = 08420, loss = 5.3606
2024-10-30 17:36:55: [2024-10-30 17:36:55] iter = 08430, loss = 4.6544
2024-10-30 17:36:59: [2024-10-30 17:36:59] iter = 08440, loss = 4.6917
2024-10-30 17:37:04: [2024-10-30 17:37:04] iter = 08450, loss = 11.6010
2024-10-30 17:37:07: [2024-10-30 17:37:07] iter = 08460, loss = 60.7894
2024-10-30 17:37:12: [2024-10-30 17:37:12] iter = 08470, loss = 21.2980
2024-10-30 17:37:16: [2024-10-30 17:37:16] iter = 08480, loss = 16.1703
2024-10-30 17:37:19: [2024-10-30 17:37:19] iter = 08490, loss = 3.6060
2024-10-30 17:37:22: [2024-10-30 17:37:22] iter = 08500, loss = 15.7579
2024-10-30 17:37:26: [2024-10-30 17:37:26] iter = 08510, loss = 4.3106
2024-10-30 17:37:30: [2024-10-30 17:37:30] iter = 08520, loss = 13.3979
2024-10-30 17:37:34: [2024-10-30 17:37:34] iter = 08530, loss = 7.3741
2024-10-30 17:37:39: [2024-10-30 17:37:39] iter = 08540, loss = 19.9420
2024-10-30 17:37:43: [2024-10-30 17:37:43] iter = 08550, loss = 11.3270
2024-10-30 17:37:48: [2024-10-30 17:37:48] iter = 08560, loss = 35.8321
2024-10-30 17:37:53: [2024-10-30 17:37:53] iter = 08570, loss = 19.2592
2024-10-30 17:37:57: [2024-10-30 17:37:57] iter = 08580, loss = 79.0557
2024-10-30 17:38:02: [2024-10-30 17:38:02] iter = 08590, loss = 13.0247
2024-10-30 17:38:06: [2024-10-30 17:38:06] iter = 08600, loss = 3.4401
2024-10-30 17:38:10: [2024-10-30 17:38:10] iter = 08610, loss = 16.6294
2024-10-30 17:38:15: [2024-10-30 17:38:15] iter = 08620, loss = 8.4626
2024-10-30 17:38:19: [2024-10-30 17:38:19] iter = 08630, loss = 11.6431
2024-10-30 17:38:24: [2024-10-30 17:38:24] iter = 08640, loss = 22.8206
2024-10-30 17:38:28: [2024-10-30 17:38:28] iter = 08650, loss = 4.8100
2024-10-30 17:38:33: [2024-10-30 17:38:33] iter = 08660, loss = 5.0191
2024-10-30 17:38:38: [2024-10-30 17:38:38] iter = 08670, loss = 43.7405
2024-10-30 17:38:42: [2024-10-30 17:38:42] iter = 08680, loss = 5.9410
2024-10-30 17:38:46: [2024-10-30 17:38:46] iter = 08690, loss = 15.4396
2024-10-30 17:38:50: [2024-10-30 17:38:50] iter = 08700, loss = 10.3022
2024-10-30 17:38:55: [2024-10-30 17:38:55] iter = 08710, loss = 6.9382
2024-10-30 17:38:59: [2024-10-30 17:38:59] iter = 08720, loss = 22.1829
2024-10-30 17:39:04: [2024-10-30 17:39:04] iter = 08730, loss = 4.4078
2024-10-30 17:39:08: [2024-10-30 17:39:08] iter = 08740, loss = 11.1264
2024-10-30 17:39:11: [2024-10-30 17:39:11] iter = 08750, loss = 7.1872
2024-10-30 17:39:16: [2024-10-30 17:39:16] iter = 08760, loss = 5.8526
2024-10-30 17:39:20: [2024-10-30 17:39:20] iter = 08770, loss = 8.6874
2024-10-30 17:39:25: [2024-10-30 17:39:25] iter = 08780, loss = 4.5336
2024-10-30 17:39:29: [2024-10-30 17:39:29] iter = 08790, loss = 10.8034
2024-10-30 17:39:33: [2024-10-30 17:39:33] iter = 08800, loss = 21.8074
2024-10-30 17:39:38: [2024-10-30 17:39:38] iter = 08810, loss = 35.0851
2024-10-30 17:39:42: [2024-10-30 17:39:42] iter = 08820, loss = 50.1579
2024-10-30 17:39:46: [2024-10-30 17:39:46] iter = 08830, loss = 8.4296
2024-10-30 17:39:49: [2024-10-30 17:39:49] iter = 08840, loss = 41.9210
2024-10-30 17:39:53: [2024-10-30 17:39:53] iter = 08850, loss = 62.5299
2024-10-30 17:39:57: [2024-10-30 17:39:57] iter = 08860, loss = 48.5191
2024-10-30 17:40:01: [2024-10-30 17:40:01] iter = 08870, loss = 34.9919
2024-10-30 17:40:04: [2024-10-30 17:40:04] iter = 08880, loss = 7.6005
2024-10-30 17:40:09: [2024-10-30 17:40:09] iter = 08890, loss = 21.6317
2024-10-30 17:40:13: [2024-10-30 17:40:13] iter = 08900, loss = 3.6910
2024-10-30 17:40:17: [2024-10-30 17:40:17] iter = 08910, loss = 53.4291
2024-10-30 17:40:21: [2024-10-30 17:40:21] iter = 08920, loss = 9.7179
2024-10-30 17:40:25: [2024-10-30 17:40:25] iter = 08930, loss = 3.5324
2024-10-30 17:40:29: [2024-10-30 17:40:29] iter = 08940, loss = 16.4845
2024-10-30 17:40:33: [2024-10-30 17:40:33] iter = 08950, loss = 47.5020
2024-10-30 17:40:37: [2024-10-30 17:40:37] iter = 08960, loss = 26.2254
2024-10-30 17:40:41: [2024-10-30 17:40:41] iter = 08970, loss = 80.6278
2024-10-30 17:40:46: [2024-10-30 17:40:46] iter = 08980, loss = 57.7542
2024-10-30 17:40:50: [2024-10-30 17:40:50] iter = 08990, loss = 11.3848
2024-10-30 17:40:54: [2024-10-30 17:40:54] iter = 09000, loss = 21.2334
2024-10-30 17:40:58: [2024-10-30 17:40:58] iter = 09010, loss = 13.8524
2024-10-30 17:41:02: [2024-10-30 17:41:02] iter = 09020, loss = 17.7988
2024-10-30 17:41:06: [2024-10-30 17:41:06] iter = 09030, loss = 22.2419
2024-10-30 17:41:11: [2024-10-30 17:41:11] iter = 09040, loss = 16.9103
2024-10-30 17:41:15: [2024-10-30 17:41:15] iter = 09050, loss = 6.4336
2024-10-30 17:41:20: [2024-10-30 17:41:20] iter = 09060, loss = 4.1394
2024-10-30 17:41:23: [2024-10-30 17:41:23] iter = 09070, loss = 5.6045
2024-10-30 17:41:26: [2024-10-30 17:41:26] iter = 09080, loss = 21.3198
2024-10-30 17:41:30: [2024-10-30 17:41:30] iter = 09090, loss = 79.2585
2024-10-30 17:41:34: [2024-10-30 17:41:34] iter = 09100, loss = 60.2725
2024-10-30 17:41:37: [2024-10-30 17:41:37] iter = 09110, loss = 50.2396
2024-10-30 17:41:41: [2024-10-30 17:41:41] iter = 09120, loss = 6.5610
2024-10-30 17:41:44: [2024-10-30 17:41:44] iter = 09130, loss = 5.7067
2024-10-30 17:41:47: [2024-10-30 17:41:47] iter = 09140, loss = 6.1032
2024-10-30 17:41:51: [2024-10-30 17:41:51] iter = 09150, loss = 11.3876
2024-10-30 17:41:55: [2024-10-30 17:41:55] iter = 09160, loss = 5.5893
2024-10-30 17:41:58: [2024-10-30 17:41:58] iter = 09170, loss = 9.5120
2024-10-30 17:42:02: [2024-10-30 17:42:02] iter = 09180, loss = 7.9438
2024-10-30 17:42:05: [2024-10-30 17:42:05] iter = 09190, loss = 6.2686
2024-10-30 17:42:09: [2024-10-30 17:42:09] iter = 09200, loss = 17.8242
2024-10-30 17:42:11: [2024-10-30 17:42:11] iter = 09210, loss = 4.3296
2024-10-30 17:42:14: [2024-10-30 17:42:14] iter = 09220, loss = 36.5661
2024-10-30 17:42:17: [2024-10-30 17:42:17] iter = 09230, loss = 5.6220
2024-10-30 17:42:21: [2024-10-30 17:42:21] iter = 09240, loss = 43.7505
2024-10-30 17:42:25: [2024-10-30 17:42:25] iter = 09250, loss = 24.6099
2024-10-30 17:42:29: [2024-10-30 17:42:29] iter = 09260, loss = 22.7313
2024-10-30 17:42:32: [2024-10-30 17:42:32] iter = 09270, loss = 4.1551
2024-10-30 17:42:36: [2024-10-30 17:42:36] iter = 09280, loss = 2.8945
2024-10-30 17:42:39: [2024-10-30 17:42:39] iter = 09290, loss = 16.6403
2024-10-30 17:42:43: [2024-10-30 17:42:43] iter = 09300, loss = 32.5036
2024-10-30 17:42:47: [2024-10-30 17:42:47] iter = 09310, loss = 13.6497
2024-10-30 17:42:52: [2024-10-30 17:42:52] iter = 09320, loss = 36.5085
2024-10-30 17:42:56: [2024-10-30 17:42:56] iter = 09330, loss = 46.3693
2024-10-30 17:43:01: [2024-10-30 17:43:01] iter = 09340, loss = 12.3832
2024-10-30 17:43:05: [2024-10-30 17:43:05] iter = 09350, loss = 14.1767
2024-10-30 17:43:10: [2024-10-30 17:43:10] iter = 09360, loss = 9.8114
2024-10-30 17:43:14: [2024-10-30 17:43:14] iter = 09370, loss = 10.3963
2024-10-30 17:43:16: [2024-10-30 17:43:16] iter = 09380, loss = 34.7537
2024-10-30 17:43:19: [2024-10-30 17:43:19] iter = 09390, loss = 5.7462
2024-10-30 17:43:22: [2024-10-30 17:43:22] iter = 09400, loss = 7.0279
2024-10-30 17:43:26: [2024-10-30 17:43:26] iter = 09410, loss = 32.9370
2024-10-30 17:43:30: [2024-10-30 17:43:30] iter = 09420, loss = 7.4899
2024-10-30 17:43:33: [2024-10-30 17:43:33] iter = 09430, loss = 4.4531
2024-10-30 17:43:38: [2024-10-30 17:43:38] iter = 09440, loss = 3.8178
2024-10-30 17:43:42: [2024-10-30 17:43:42] iter = 09450, loss = 4.6688
2024-10-30 17:43:45: [2024-10-30 17:43:45] iter = 09460, loss = 28.2535
2024-10-30 17:43:48: [2024-10-30 17:43:48] iter = 09470, loss = 4.6840
2024-10-30 17:43:52: [2024-10-30 17:43:52] iter = 09480, loss = 59.0811
2024-10-30 17:43:55: [2024-10-30 17:43:55] iter = 09490, loss = 20.7981
2024-10-30 17:43:59: [2024-10-30 17:43:59] iter = 09500, loss = 19.1262
2024-10-30 17:44:03: [2024-10-30 17:44:03] iter = 09510, loss = 37.1664
2024-10-30 17:44:07: [2024-10-30 17:44:07] iter = 09520, loss = 42.3928
2024-10-30 17:44:11: [2024-10-30 17:44:11] iter = 09530, loss = 5.2129
2024-10-30 17:44:15: [2024-10-30 17:44:15] iter = 09540, loss = 4.3749
2024-10-30 17:44:19: [2024-10-30 17:44:19] iter = 09550, loss = 15.0328
2024-10-30 17:44:23: [2024-10-30 17:44:23] iter = 09560, loss = 4.6713
2024-10-30 17:44:27: [2024-10-30 17:44:27] iter = 09570, loss = 16.4633
2024-10-30 17:44:31: [2024-10-30 17:44:31] iter = 09580, loss = 7.8387
2024-10-30 17:44:35: [2024-10-30 17:44:35] iter = 09590, loss = 13.3823
2024-10-30 17:44:38: [2024-10-30 17:44:38] iter = 09600, loss = 15.1623
2024-10-30 17:44:41: [2024-10-30 17:44:41] iter = 09610, loss = 7.2801
2024-10-30 17:44:46: [2024-10-30 17:44:46] iter = 09620, loss = 17.7912
2024-10-30 17:44:49: [2024-10-30 17:44:49] iter = 09630, loss = 13.1611
2024-10-30 17:44:54: [2024-10-30 17:44:54] iter = 09640, loss = 4.3389
2024-10-30 17:44:57: [2024-10-30 17:44:57] iter = 09650, loss = 10.5573
2024-10-30 17:45:00: [2024-10-30 17:45:00] iter = 09660, loss = 9.9006
2024-10-30 17:45:04: [2024-10-30 17:45:04] iter = 09670, loss = 17.8648
2024-10-30 17:45:07: [2024-10-30 17:45:07] iter = 09680, loss = 15.7720
2024-10-30 17:45:10: [2024-10-30 17:45:10] iter = 09690, loss = 4.1144
2024-10-30 17:45:13: [2024-10-30 17:45:13] iter = 09700, loss = 4.5396
2024-10-30 17:45:17: [2024-10-30 17:45:17] iter = 09710, loss = 9.1069
2024-10-30 17:45:21: [2024-10-30 17:45:21] iter = 09720, loss = 7.7534
2024-10-30 17:45:24: [2024-10-30 17:45:24] iter = 09730, loss = 7.1287
2024-10-30 17:45:28: [2024-10-30 17:45:28] iter = 09740, loss = 5.5713
2024-10-30 17:45:32: [2024-10-30 17:45:32] iter = 09750, loss = 8.7187
2024-10-30 17:45:36: [2024-10-30 17:45:36] iter = 09760, loss = 44.8605
2024-10-30 17:45:40: [2024-10-30 17:45:40] iter = 09770, loss = 44.4146
2024-10-30 17:45:44: [2024-10-30 17:45:44] iter = 09780, loss = 14.7583
2024-10-30 17:45:48: [2024-10-30 17:45:48] iter = 09790, loss = 19.8372
2024-10-30 17:45:53: [2024-10-30 17:45:53] iter = 09800, loss = 3.9747
2024-10-30 17:45:57: [2024-10-30 17:45:57] iter = 09810, loss = 39.0678
2024-10-30 17:45:59: [2024-10-30 17:45:59] iter = 09820, loss = 18.0205
2024-10-30 17:46:03: [2024-10-30 17:46:03] iter = 09830, loss = 15.2728
2024-10-30 17:46:07: [2024-10-30 17:46:07] iter = 09840, loss = 29.4259
2024-10-30 17:46:12: [2024-10-30 17:46:12] iter = 09850, loss = 41.8799
2024-10-30 17:46:16: [2024-10-30 17:46:16] iter = 09860, loss = 27.8439
2024-10-30 17:46:19: [2024-10-30 17:46:19] iter = 09870, loss = 29.2051
2024-10-30 17:46:24: [2024-10-30 17:46:24] iter = 09880, loss = 18.0217
2024-10-30 17:46:28: [2024-10-30 17:46:28] iter = 09890, loss = 4.2919
2024-10-30 17:46:32: [2024-10-30 17:46:32] iter = 09900, loss = 15.4160
2024-10-30 17:46:37: [2024-10-30 17:46:37] iter = 09910, loss = 6.3469
2024-10-30 17:46:41: [2024-10-30 17:46:41] iter = 09920, loss = 8.7780
2024-10-30 17:46:45: [2024-10-30 17:46:45] iter = 09930, loss = 44.3963
2024-10-30 17:46:49: [2024-10-30 17:46:49] iter = 09940, loss = 37.7976
2024-10-30 17:46:52: [2024-10-30 17:46:52] iter = 09950, loss = 28.0672
2024-10-30 17:46:56: [2024-10-30 17:46:56] iter = 09960, loss = 54.9132
2024-10-30 17:47:01: [2024-10-30 17:47:01] iter = 09970, loss = 10.9761
2024-10-30 17:47:05: [2024-10-30 17:47:05] iter = 09980, loss = 3.8023
2024-10-30 17:47:09: [2024-10-30 17:47:09] iter = 09990, loss = 7.6977
2024-10-30 17:47:12: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 17:47:12: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 17:47:12: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 32686}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:35: Evaluate 5 random ConvNet, ACCmean = 0.3662 ACCstd = 0.0108
-------------------------
2024-10-30 17:49:35: Evaluate 5 random ConvNet, SENmean = 0.3168 SENstd = 0.0048
-------------------------
2024-10-30 17:49:35: Evaluate 5 random ConvNet, SPEmean = 0.9080 SPEstd = 0.0010
-------------------------
2024-10-30 17:49:35: Evaluate 5 random ConvNet, F!mean = 0.2781 F!std = 0.0041
-------------------------
2024-10-30 17:49:35: Evaluate 5 random ConvNet, mean = 0.3662 std = 0.0108
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 17:49:36: [2024-10-30 17:49:36] iter = 10000, loss = 26.5307
2024-10-30 17:49:40: [2024-10-30 17:49:40] iter = 10010, loss = 3.7826
2024-10-30 17:49:44: [2024-10-30 17:49:44] iter = 10020, loss = 3.7901
2024-10-30 17:49:47: [2024-10-30 17:49:47] iter = 10030, loss = 15.1271
2024-10-30 17:49:50: [2024-10-30 17:49:50] iter = 10040, loss = 12.5866
2024-10-30 17:49:52: [2024-10-30 17:49:52] iter = 10050, loss = 11.6871
2024-10-30 17:49:56: [2024-10-30 17:49:56] iter = 10060, loss = 23.5814
2024-10-30 17:50:00: [2024-10-30 17:50:00] iter = 10070, loss = 43.3884
2024-10-30 17:50:04: [2024-10-30 17:50:04] iter = 10080, loss = 4.7583
2024-10-30 17:50:08: [2024-10-30 17:50:08] iter = 10090, loss = 19.6565
2024-10-30 17:50:11: [2024-10-30 17:50:11] iter = 10100, loss = 8.4503
2024-10-30 17:50:13: [2024-10-30 17:50:13] iter = 10110, loss = 40.0707
2024-10-30 17:50:17: [2024-10-30 17:50:17] iter = 10120, loss = 6.3016
2024-10-30 17:50:20: [2024-10-30 17:50:20] iter = 10130, loss = 13.7196
2024-10-30 17:50:24: [2024-10-30 17:50:24] iter = 10140, loss = 33.2227
2024-10-30 17:50:29: [2024-10-30 17:50:29] iter = 10150, loss = 5.2518
2024-10-30 17:50:32: [2024-10-30 17:50:32] iter = 10160, loss = 6.6425
2024-10-30 17:50:35: [2024-10-30 17:50:35] iter = 10170, loss = 24.8045
2024-10-30 17:50:38: [2024-10-30 17:50:38] iter = 10180, loss = 62.1475
2024-10-30 17:50:42: [2024-10-30 17:50:42] iter = 10190, loss = 50.4947
2024-10-30 17:50:46: [2024-10-30 17:50:46] iter = 10200, loss = 32.5084
2024-10-30 17:50:49: [2024-10-30 17:50:49] iter = 10210, loss = 5.0670
2024-10-30 17:50:53: [2024-10-30 17:50:53] iter = 10220, loss = 18.6969
2024-10-30 17:50:58: [2024-10-30 17:50:58] iter = 10230, loss = 44.6197
2024-10-30 17:51:02: [2024-10-30 17:51:02] iter = 10240, loss = 19.4193
2024-10-30 17:51:06: [2024-10-30 17:51:06] iter = 10250, loss = 7.3027
2024-10-30 17:51:10: [2024-10-30 17:51:10] iter = 10260, loss = 3.8153
2024-10-30 17:51:13: [2024-10-30 17:51:13] iter = 10270, loss = 14.5615
2024-10-30 17:51:16: [2024-10-30 17:51:16] iter = 10280, loss = 4.8658
2024-10-30 17:51:20: [2024-10-30 17:51:20] iter = 10290, loss = 8.1852
2024-10-30 17:51:25: [2024-10-30 17:51:25] iter = 10300, loss = 16.6493
2024-10-30 17:51:29: [2024-10-30 17:51:29] iter = 10310, loss = 6.9036
2024-10-30 17:51:33: [2024-10-30 17:51:33] iter = 10320, loss = 15.6485
2024-10-30 17:51:37: [2024-10-30 17:51:37] iter = 10330, loss = 21.0757
2024-10-30 17:51:40: [2024-10-30 17:51:40] iter = 10340, loss = 22.2429
2024-10-30 17:51:44: [2024-10-30 17:51:44] iter = 10350, loss = 66.5432
2024-10-30 17:51:48: [2024-10-30 17:51:48] iter = 10360, loss = 55.0585
2024-10-30 17:51:51: [2024-10-30 17:51:51] iter = 10370, loss = 11.6245
2024-10-30 17:51:54: [2024-10-30 17:51:54] iter = 10380, loss = 55.1424
2024-10-30 17:51:57: [2024-10-30 17:51:57] iter = 10390, loss = 5.9698
2024-10-30 17:52:01: [2024-10-30 17:52:01] iter = 10400, loss = 27.1768
2024-10-30 17:52:04: [2024-10-30 17:52:04] iter = 10410, loss = 4.5969
2024-10-30 17:52:07: [2024-10-30 17:52:07] iter = 10420, loss = 48.8555
2024-10-30 17:52:10: [2024-10-30 17:52:10] iter = 10430, loss = 48.2644
2024-10-30 17:52:14: [2024-10-30 17:52:14] iter = 10440, loss = 22.8481
2024-10-30 17:52:17: [2024-10-30 17:52:17] iter = 10450, loss = 5.5947
2024-10-30 17:52:21: [2024-10-30 17:52:21] iter = 10460, loss = 17.0008
2024-10-30 17:52:24: [2024-10-30 17:52:24] iter = 10470, loss = 24.9408
2024-10-30 17:52:27: [2024-10-30 17:52:27] iter = 10480, loss = 9.7700
2024-10-30 17:52:31: [2024-10-30 17:52:31] iter = 10490, loss = 19.2937
2024-10-30 17:52:34: [2024-10-30 17:52:34] iter = 10500, loss = 4.5159
2024-10-30 17:52:38: [2024-10-30 17:52:38] iter = 10510, loss = 23.7654
2024-10-30 17:52:41: [2024-10-30 17:52:41] iter = 10520, loss = 4.9743
2024-10-30 17:52:44: [2024-10-30 17:52:44] iter = 10530, loss = 7.2236
2024-10-30 17:52:47: [2024-10-30 17:52:47] iter = 10540, loss = 7.0656
2024-10-30 17:52:50: [2024-10-30 17:52:50] iter = 10550, loss = 76.1407
2024-10-30 17:52:52: [2024-10-30 17:52:52] iter = 10560, loss = 12.1739
2024-10-30 17:52:56: [2024-10-30 17:52:56] iter = 10570, loss = 51.9670
2024-10-30 17:53:00: [2024-10-30 17:53:00] iter = 10580, loss = 96.0722
2024-10-30 17:53:04: [2024-10-30 17:53:04] iter = 10590, loss = 19.6267
2024-10-30 17:53:08: [2024-10-30 17:53:08] iter = 10600, loss = 14.6881
2024-10-30 17:53:12: [2024-10-30 17:53:12] iter = 10610, loss = 15.1863
2024-10-30 17:53:15: [2024-10-30 17:53:15] iter = 10620, loss = 4.5407
2024-10-30 17:53:18: [2024-10-30 17:53:18] iter = 10630, loss = 16.4727
2024-10-30 17:53:23: [2024-10-30 17:53:23] iter = 10640, loss = 18.3253
2024-10-30 17:53:26: [2024-10-30 17:53:26] iter = 10650, loss = 15.8443
2024-10-30 17:53:31: [2024-10-30 17:53:31] iter = 10660, loss = 6.7434
2024-10-30 17:53:34: [2024-10-30 17:53:34] iter = 10670, loss = 6.3392
2024-10-30 17:53:37: [2024-10-30 17:53:37] iter = 10680, loss = 23.8835
2024-10-30 17:53:40: [2024-10-30 17:53:40] iter = 10690, loss = 23.7573
2024-10-30 17:53:43: [2024-10-30 17:53:43] iter = 10700, loss = 14.5469
2024-10-30 17:53:47: [2024-10-30 17:53:47] iter = 10710, loss = 13.4571
2024-10-30 17:53:50: [2024-10-30 17:53:50] iter = 10720, loss = 5.1541
2024-10-30 17:53:53: [2024-10-30 17:53:53] iter = 10730, loss = 32.2589
2024-10-30 17:53:57: [2024-10-30 17:53:57] iter = 10740, loss = 26.6006
2024-10-30 17:54:00: [2024-10-30 17:54:00] iter = 10750, loss = 47.7214
2024-10-30 17:54:03: [2024-10-30 17:54:03] iter = 10760, loss = 8.9195
2024-10-30 17:54:07: [2024-10-30 17:54:07] iter = 10770, loss = 8.1925
2024-10-30 17:54:10: [2024-10-30 17:54:10] iter = 10780, loss = 18.5643
2024-10-30 17:54:13: [2024-10-30 17:54:13] iter = 10790, loss = 4.6799
2024-10-30 17:54:17: [2024-10-30 17:54:17] iter = 10800, loss = 22.6659
2024-10-30 17:54:19: [2024-10-30 17:54:19] iter = 10810, loss = 3.3077
2024-10-30 17:54:22: [2024-10-30 17:54:22] iter = 10820, loss = 14.4918
2024-10-30 17:54:26: [2024-10-30 17:54:26] iter = 10830, loss = 3.3071
2024-10-30 17:54:30: [2024-10-30 17:54:30] iter = 10840, loss = 4.2263
2024-10-30 17:54:34: [2024-10-30 17:54:34] iter = 10850, loss = 43.1786
2024-10-30 17:54:37: [2024-10-30 17:54:37] iter = 10860, loss = 11.4078
2024-10-30 17:54:40: [2024-10-30 17:54:40] iter = 10870, loss = 10.1274
2024-10-30 17:54:43: [2024-10-30 17:54:43] iter = 10880, loss = 5.0632
2024-10-30 17:54:46: [2024-10-30 17:54:46] iter = 10890, loss = 5.0746
2024-10-30 17:54:51: [2024-10-30 17:54:51] iter = 10900, loss = 13.6406
2024-10-30 17:54:55: [2024-10-30 17:54:55] iter = 10910, loss = 12.5865
2024-10-30 17:55:00: [2024-10-30 17:55:00] iter = 10920, loss = 4.3810
2024-10-30 17:55:04: [2024-10-30 17:55:04] iter = 10930, loss = 9.8979
2024-10-30 17:55:08: [2024-10-30 17:55:08] iter = 10940, loss = 29.6344
2024-10-30 17:55:11: [2024-10-30 17:55:11] iter = 10950, loss = 65.7015
2024-10-30 17:55:14: [2024-10-30 17:55:14] iter = 10960, loss = 8.0913
2024-10-30 17:55:18: [2024-10-30 17:55:18] iter = 10970, loss = 10.6567
2024-10-30 17:55:22: [2024-10-30 17:55:22] iter = 10980, loss = 12.3157
2024-10-30 17:55:26: [2024-10-30 17:55:26] iter = 10990, loss = 21.3643
2024-10-30 17:55:30: [2024-10-30 17:55:30] iter = 11000, loss = 64.8520
2024-10-30 17:55:33: [2024-10-30 17:55:33] iter = 11010, loss = 21.5737
2024-10-30 17:55:37: [2024-10-30 17:55:37] iter = 11020, loss = 44.1145
2024-10-30 17:55:40: [2024-10-30 17:55:40] iter = 11030, loss = 15.1354
2024-10-30 17:55:43: [2024-10-30 17:55:43] iter = 11040, loss = 11.1192
2024-10-30 17:55:47: [2024-10-30 17:55:47] iter = 11050, loss = 18.9281
2024-10-30 17:55:51: [2024-10-30 17:55:51] iter = 11060, loss = 4.5629
2024-10-30 17:55:55: [2024-10-30 17:55:55] iter = 11070, loss = 4.5077
2024-10-30 17:55:58: [2024-10-30 17:55:58] iter = 11080, loss = 15.9126
2024-10-30 17:56:01: [2024-10-30 17:56:01] iter = 11090, loss = 4.8317
2024-10-30 17:56:06: [2024-10-30 17:56:06] iter = 11100, loss = 22.9261
2024-10-30 17:56:10: [2024-10-30 17:56:10] iter = 11110, loss = 3.9302
2024-10-30 17:56:13: [2024-10-30 17:56:13] iter = 11120, loss = 7.3465
2024-10-30 17:56:18: [2024-10-30 17:56:17] iter = 11130, loss = 13.4826
2024-10-30 17:56:22: [2024-10-30 17:56:22] iter = 11140, loss = 19.2262
2024-10-30 17:56:27: [2024-10-30 17:56:27] iter = 11150, loss = 10.0725
2024-10-30 17:56:31: [2024-10-30 17:56:31] iter = 11160, loss = 40.0344
2024-10-30 17:56:35: [2024-10-30 17:56:35] iter = 11170, loss = 5.5075
2024-10-30 17:56:39: [2024-10-30 17:56:39] iter = 11180, loss = 10.5513
2024-10-30 17:56:43: [2024-10-30 17:56:43] iter = 11190, loss = 15.5341
2024-10-30 17:56:46: [2024-10-30 17:56:46] iter = 11200, loss = 19.8900
2024-10-30 17:56:50: [2024-10-30 17:56:50] iter = 11210, loss = 5.7274
2024-10-30 17:56:54: [2024-10-30 17:56:54] iter = 11220, loss = 12.9340
2024-10-30 17:56:57: [2024-10-30 17:56:57] iter = 11230, loss = 16.3068
2024-10-30 17:57:00: [2024-10-30 17:57:00] iter = 11240, loss = 44.1191
2024-10-30 17:57:03: [2024-10-30 17:57:03] iter = 11250, loss = 4.6308
2024-10-30 17:57:07: [2024-10-30 17:57:07] iter = 11260, loss = 6.6105
2024-10-30 17:57:10: [2024-10-30 17:57:10] iter = 11270, loss = 4.6668
2024-10-30 17:57:14: [2024-10-30 17:57:14] iter = 11280, loss = 5.1326
2024-10-30 17:57:18: [2024-10-30 17:57:18] iter = 11290, loss = 38.2821
2024-10-30 17:57:22: [2024-10-30 17:57:22] iter = 11300, loss = 3.8823
2024-10-30 17:57:25: [2024-10-30 17:57:25] iter = 11310, loss = 3.9717
2024-10-30 17:57:28: [2024-10-30 17:57:28] iter = 11320, loss = 11.3182
2024-10-30 17:57:33: [2024-10-30 17:57:33] iter = 11330, loss = 12.4295
2024-10-30 17:57:35: [2024-10-30 17:57:35] iter = 11340, loss = 13.0145
2024-10-30 17:57:39: [2024-10-30 17:57:39] iter = 11350, loss = 55.6691
2024-10-30 17:57:41: [2024-10-30 17:57:41] iter = 11360, loss = 17.0300
2024-10-30 17:57:44: [2024-10-30 17:57:44] iter = 11370, loss = 15.6463
2024-10-30 17:57:49: [2024-10-30 17:57:49] iter = 11380, loss = 41.0283
2024-10-30 17:57:53: [2024-10-30 17:57:53] iter = 11390, loss = 14.8316
2024-10-30 17:57:57: [2024-10-30 17:57:57] iter = 11400, loss = 42.5509
2024-10-30 17:58:01: [2024-10-30 17:58:01] iter = 11410, loss = 42.5979
2024-10-30 17:58:06: [2024-10-30 17:58:06] iter = 11420, loss = 16.4716
2024-10-30 17:58:09: [2024-10-30 17:58:09] iter = 11430, loss = 24.1329
2024-10-30 17:58:13: [2024-10-30 17:58:13] iter = 11440, loss = 19.6742
2024-10-30 17:58:17: [2024-10-30 17:58:17] iter = 11450, loss = 4.9016
2024-10-30 17:58:22: [2024-10-30 17:58:22] iter = 11460, loss = 21.9126
2024-10-30 17:58:26: [2024-10-30 17:58:26] iter = 11470, loss = 5.2149
2024-10-30 17:58:30: [2024-10-30 17:58:30] iter = 11480, loss = 3.9206
2024-10-30 17:58:33: [2024-10-30 17:58:33] iter = 11490, loss = 28.4895
2024-10-30 17:58:38: [2024-10-30 17:58:38] iter = 11500, loss = 27.3550
2024-10-30 17:58:42: [2024-10-30 17:58:42] iter = 11510, loss = 20.9469
2024-10-30 17:58:46: [2024-10-30 17:58:46] iter = 11520, loss = 79.1833
2024-10-30 17:58:51: [2024-10-30 17:58:51] iter = 11530, loss = 32.0538
2024-10-30 17:58:55: [2024-10-30 17:58:55] iter = 11540, loss = 11.8763
2024-10-30 17:58:59: [2024-10-30 17:58:59] iter = 11550, loss = 4.1195
2024-10-30 17:59:02: [2024-10-30 17:59:02] iter = 11560, loss = 10.5365
2024-10-30 17:59:06: [2024-10-30 17:59:06] iter = 11570, loss = 32.8251
2024-10-30 17:59:10: [2024-10-30 17:59:10] iter = 11580, loss = 19.9804
2024-10-30 17:59:14: [2024-10-30 17:59:14] iter = 11590, loss = 76.2966
2024-10-30 17:59:19: [2024-10-30 17:59:19] iter = 11600, loss = 11.6530
2024-10-30 17:59:23: [2024-10-30 17:59:23] iter = 11610, loss = 4.5082
2024-10-30 17:59:27: [2024-10-30 17:59:27] iter = 11620, loss = 27.6882
2024-10-30 17:59:30: [2024-10-30 17:59:30] iter = 11630, loss = 10.2226
2024-10-30 17:59:34: [2024-10-30 17:59:34] iter = 11640, loss = 19.1257
2024-10-30 17:59:38: [2024-10-30 17:59:38] iter = 11650, loss = 13.5772
2024-10-30 17:59:42: [2024-10-30 17:59:42] iter = 11660, loss = 57.8965
2024-10-30 17:59:47: [2024-10-30 17:59:47] iter = 11670, loss = 5.7634
2024-10-30 17:59:51: [2024-10-30 17:59:51] iter = 11680, loss = 49.7230
2024-10-30 17:59:55: [2024-10-30 17:59:55] iter = 11690, loss = 46.7240
2024-10-30 18:00:00: [2024-10-30 18:00:00] iter = 11700, loss = 5.4614
2024-10-30 18:00:02: [2024-10-30 18:00:02] iter = 11710, loss = 28.6832
2024-10-30 18:00:05: [2024-10-30 18:00:05] iter = 11720, loss = 11.9996
2024-10-30 18:00:09: [2024-10-30 18:00:09] iter = 11730, loss = 8.5604
2024-10-30 18:00:11: [2024-10-30 18:00:11] iter = 11740, loss = 9.2743
2024-10-30 18:00:14: [2024-10-30 18:00:14] iter = 11750, loss = 4.5824
2024-10-30 18:00:18: [2024-10-30 18:00:18] iter = 11760, loss = 9.1502
2024-10-30 18:00:20: [2024-10-30 18:00:20] iter = 11770, loss = 16.4400
2024-10-30 18:00:23: [2024-10-30 18:00:23] iter = 11780, loss = 7.5481
2024-10-30 18:00:26: [2024-10-30 18:00:26] iter = 11790, loss = 50.4333
2024-10-30 18:00:29: [2024-10-30 18:00:29] iter = 11800, loss = 28.5700
2024-10-30 18:00:32: [2024-10-30 18:00:32] iter = 11810, loss = 16.7609
2024-10-30 18:00:36: [2024-10-30 18:00:36] iter = 11820, loss = 37.2584
2024-10-30 18:00:40: [2024-10-30 18:00:40] iter = 11830, loss = 10.0448
2024-10-30 18:00:43: [2024-10-30 18:00:43] iter = 11840, loss = 35.8109
2024-10-30 18:00:47: [2024-10-30 18:00:47] iter = 11850, loss = 7.9996
2024-10-30 18:00:51: [2024-10-30 18:00:51] iter = 11860, loss = 4.7303
2024-10-30 18:00:54: [2024-10-30 18:00:54] iter = 11870, loss = 9.1262
2024-10-30 18:00:58: [2024-10-30 18:00:58] iter = 11880, loss = 5.9579
2024-10-30 18:01:02: [2024-10-30 18:01:02] iter = 11890, loss = 7.0131
2024-10-30 18:01:06: [2024-10-30 18:01:06] iter = 11900, loss = 56.9481
2024-10-30 18:01:10: [2024-10-30 18:01:10] iter = 11910, loss = 9.8191
2024-10-30 18:01:14: [2024-10-30 18:01:14] iter = 11920, loss = 5.9534
2024-10-30 18:01:18: [2024-10-30 18:01:18] iter = 11930, loss = 23.2125
2024-10-30 18:01:22: [2024-10-30 18:01:22] iter = 11940, loss = 25.6047
2024-10-30 18:01:26: [2024-10-30 18:01:26] iter = 11950, loss = 4.4925
2024-10-30 18:01:30: [2024-10-30 18:01:30] iter = 11960, loss = 31.7243
2024-10-30 18:01:34: [2024-10-30 18:01:34] iter = 11970, loss = 7.3683
2024-10-30 18:01:37: [2024-10-30 18:01:37] iter = 11980, loss = 6.1684
2024-10-30 18:01:40: [2024-10-30 18:01:40] iter = 11990, loss = 29.9581
2024-10-30 18:01:44: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 18:01:44: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:01:44: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 4351}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:03:59: Evaluate 5 random ConvNet, ACCmean = 0.4011 ACCstd = 0.0045
-------------------------
2024-10-30 18:03:59: Evaluate 5 random ConvNet, SENmean = 0.3173 SENstd = 0.0023
-------------------------
2024-10-30 18:03:59: Evaluate 5 random ConvNet, SPEmean = 0.9116 SPEstd = 0.0003
-------------------------
2024-10-30 18:03:59: Evaluate 5 random ConvNet, F!mean = 0.2829 F!std = 0.0014
-------------------------
2024-10-30 18:03:59: Evaluate 5 random ConvNet, mean = 0.4011 std = 0.0045
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:04:00: [2024-10-30 18:04:00] iter = 12000, loss = 4.0516
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:04:04: [2024-10-30 18:04:04] iter = 12010, loss = 4.1666
2024-10-30 18:04:08: [2024-10-30 18:04:08] iter = 12020, loss = 37.1803
2024-10-30 18:04:12: [2024-10-30 18:04:12] iter = 12030, loss = 3.9397
2024-10-30 18:04:16: [2024-10-30 18:04:16] iter = 12040, loss = 6.2275
2024-10-30 18:04:20: [2024-10-30 18:04:20] iter = 12050, loss = 13.1774
2024-10-30 18:04:23: [2024-10-30 18:04:23] iter = 12060, loss = 4.0952
2024-10-30 18:04:27: [2024-10-30 18:04:27] iter = 12070, loss = 22.2250
2024-10-30 18:04:32: [2024-10-30 18:04:32] iter = 12080, loss = 51.0730
2024-10-30 18:04:34: [2024-10-30 18:04:34] iter = 12090, loss = 31.7532
2024-10-30 18:04:37: [2024-10-30 18:04:37] iter = 12100, loss = 3.7457
2024-10-30 18:04:41: [2024-10-30 18:04:41] iter = 12110, loss = 11.0685
2024-10-30 18:04:45: [2024-10-30 18:04:45] iter = 12120, loss = 26.1304
2024-10-30 18:04:49: [2024-10-30 18:04:49] iter = 12130, loss = 9.4269
2024-10-30 18:04:52: [2024-10-30 18:04:52] iter = 12140, loss = 63.2073
2024-10-30 18:04:57: [2024-10-30 18:04:57] iter = 12150, loss = 5.3852
2024-10-30 18:05:00: [2024-10-30 18:05:00] iter = 12160, loss = 57.6071
2024-10-30 18:05:04: [2024-10-30 18:05:04] iter = 12170, loss = 31.6002
2024-10-30 18:05:07: [2024-10-30 18:05:07] iter = 12180, loss = 9.5335
2024-10-30 18:05:12: [2024-10-30 18:05:12] iter = 12190, loss = 11.0184
2024-10-30 18:05:15: [2024-10-30 18:05:15] iter = 12200, loss = 4.8554
2024-10-30 18:05:18: [2024-10-30 18:05:18] iter = 12210, loss = 36.5399
2024-10-30 18:05:22: [2024-10-30 18:05:22] iter = 12220, loss = 13.8403
2024-10-30 18:05:26: [2024-10-30 18:05:26] iter = 12230, loss = 9.1746
2024-10-30 18:05:31: [2024-10-30 18:05:31] iter = 12240, loss = 4.1362
2024-10-30 18:05:35: [2024-10-30 18:05:35] iter = 12250, loss = 18.1463
2024-10-30 18:05:39: [2024-10-30 18:05:39] iter = 12260, loss = 4.9516
2024-10-30 18:05:43: [2024-10-30 18:05:43] iter = 12270, loss = 13.6264
2024-10-30 18:05:46: [2024-10-30 18:05:46] iter = 12280, loss = 4.4594
2024-10-30 18:05:49: [2024-10-30 18:05:49] iter = 12290, loss = 8.0264
2024-10-30 18:05:52: [2024-10-30 18:05:52] iter = 12300, loss = 9.9618
2024-10-30 18:05:55: [2024-10-30 18:05:55] iter = 12310, loss = 9.1291
2024-10-30 18:05:59: [2024-10-30 18:05:59] iter = 12320, loss = 27.3236
2024-10-30 18:06:04: [2024-10-30 18:06:04] iter = 12330, loss = 5.2249
2024-10-30 18:06:08: [2024-10-30 18:06:08] iter = 12340, loss = 7.2155
2024-10-30 18:06:12: [2024-10-30 18:06:12] iter = 12350, loss = 5.1392
2024-10-30 18:06:16: [2024-10-30 18:06:16] iter = 12360, loss = 58.9342
2024-10-30 18:06:19: [2024-10-30 18:06:19] iter = 12370, loss = 24.6399
2024-10-30 18:06:24: [2024-10-30 18:06:24] iter = 12380, loss = 15.2867
2024-10-30 18:06:28: [2024-10-30 18:06:28] iter = 12390, loss = 13.7041
2024-10-30 18:06:32: [2024-10-30 18:06:32] iter = 12400, loss = 55.5481
2024-10-30 18:06:36: [2024-10-30 18:06:36] iter = 12410, loss = 7.2712
2024-10-30 18:06:40: [2024-10-30 18:06:40] iter = 12420, loss = 18.2836
2024-10-30 18:06:45: [2024-10-30 18:06:45] iter = 12430, loss = 4.2905
2024-10-30 18:06:49: [2024-10-30 18:06:49] iter = 12440, loss = 18.8751
2024-10-30 18:06:53: [2024-10-30 18:06:53] iter = 12450, loss = 30.6497
2024-10-30 18:06:56: [2024-10-30 18:06:56] iter = 12460, loss = 4.7632
2024-10-30 18:07:01: [2024-10-30 18:07:01] iter = 12470, loss = 10.9960
2024-10-30 18:07:05: [2024-10-30 18:07:05] iter = 12480, loss = 4.5506
2024-10-30 18:07:10: [2024-10-30 18:07:10] iter = 12490, loss = 32.4695
2024-10-30 18:07:14: [2024-10-30 18:07:14] iter = 12500, loss = 6.4239
2024-10-30 18:07:18: [2024-10-30 18:07:18] iter = 12510, loss = 26.2321
2024-10-30 18:07:22: [2024-10-30 18:07:22] iter = 12520, loss = 15.8299
2024-10-30 18:07:24: [2024-10-30 18:07:24] iter = 12530, loss = 4.1327
2024-10-30 18:07:27: [2024-10-30 18:07:27] iter = 12540, loss = 64.0204
2024-10-30 18:07:32: [2024-10-30 18:07:32] iter = 12550, loss = 24.1778
2024-10-30 18:07:36: [2024-10-30 18:07:36] iter = 12560, loss = 18.1616
2024-10-30 18:07:40: [2024-10-30 18:07:39] iter = 12570, loss = 23.2284
2024-10-30 18:07:43: [2024-10-30 18:07:43] iter = 12580, loss = 20.3894
2024-10-30 18:07:48: [2024-10-30 18:07:48] iter = 12590, loss = 64.1417
2024-10-30 18:07:52: [2024-10-30 18:07:52] iter = 12600, loss = 3.6715
2024-10-30 18:07:57: [2024-10-30 18:07:56] iter = 12610, loss = 11.7714
2024-10-30 18:08:00: [2024-10-30 18:08:00] iter = 12620, loss = 43.5713
2024-10-30 18:08:03: [2024-10-30 18:08:03] iter = 12630, loss = 4.3349
2024-10-30 18:08:07: [2024-10-30 18:08:07] iter = 12640, loss = 21.7854
2024-10-30 18:08:10: [2024-10-30 18:08:10] iter = 12650, loss = 23.0598
2024-10-30 18:08:14: [2024-10-30 18:08:14] iter = 12660, loss = 41.7905
2024-10-30 18:08:19: [2024-10-30 18:08:19] iter = 12670, loss = 14.1872
2024-10-30 18:08:22: [2024-10-30 18:08:22] iter = 12680, loss = 15.3738
2024-10-30 18:08:26: [2024-10-30 18:08:26] iter = 12690, loss = 6.2083
2024-10-30 18:08:29: [2024-10-30 18:08:29] iter = 12700, loss = 4.6607
2024-10-30 18:08:32: [2024-10-30 18:08:32] iter = 12710, loss = 18.2678
2024-10-30 18:08:36: [2024-10-30 18:08:36] iter = 12720, loss = 71.9886
2024-10-30 18:08:39: [2024-10-30 18:08:39] iter = 12730, loss = 13.9872
2024-10-30 18:08:43: [2024-10-30 18:08:43] iter = 12740, loss = 9.7174
2024-10-30 18:08:46: [2024-10-30 18:08:46] iter = 12750, loss = 27.8289
2024-10-30 18:08:47: [2024-10-30 18:08:47] iter = 12760, loss = 7.5075
2024-10-30 18:08:51: [2024-10-30 18:08:51] iter = 12770, loss = 3.8446
2024-10-30 18:08:56: [2024-10-30 18:08:56] iter = 12780, loss = 30.0088
2024-10-30 18:09:00: [2024-10-30 18:09:00] iter = 12790, loss = 4.1720
2024-10-30 18:09:03: [2024-10-30 18:09:03] iter = 12800, loss = 9.7392
2024-10-30 18:09:06: [2024-10-30 18:09:06] iter = 12810, loss = 30.7094
2024-10-30 18:09:09: [2024-10-30 18:09:09] iter = 12820, loss = 16.0196
2024-10-30 18:09:12: [2024-10-30 18:09:12] iter = 12830, loss = 6.4884
2024-10-30 18:09:16: [2024-10-30 18:09:16] iter = 12840, loss = 64.0878
2024-10-30 18:09:20: [2024-10-30 18:09:20] iter = 12850, loss = 39.3946
2024-10-30 18:09:24: [2024-10-30 18:09:24] iter = 12860, loss = 4.1178
2024-10-30 18:09:29: [2024-10-30 18:09:29] iter = 12870, loss = 21.6753
2024-10-30 18:09:33: [2024-10-30 18:09:33] iter = 12880, loss = 6.0085
2024-10-30 18:09:37: [2024-10-30 18:09:37] iter = 12890, loss = 9.3581
2024-10-30 18:09:41: [2024-10-30 18:09:41] iter = 12900, loss = 5.4431
2024-10-30 18:09:44: [2024-10-30 18:09:44] iter = 12910, loss = 15.6907
2024-10-30 18:09:48: [2024-10-30 18:09:48] iter = 12920, loss = 49.4998
2024-10-30 18:09:53: [2024-10-30 18:09:53] iter = 12930, loss = 27.8417
2024-10-30 18:09:57: [2024-10-30 18:09:57] iter = 12940, loss = 53.8624
2024-10-30 18:10:01: [2024-10-30 18:10:01] iter = 12950, loss = 43.0540
2024-10-30 18:10:05: [2024-10-30 18:10:05] iter = 12960, loss = 11.3418
2024-10-30 18:10:09: [2024-10-30 18:10:09] iter = 12970, loss = 5.7528
2024-10-30 18:10:12: [2024-10-30 18:10:12] iter = 12980, loss = 15.0059
2024-10-30 18:10:15: [2024-10-30 18:10:15] iter = 12990, loss = 27.8072
2024-10-30 18:10:19: [2024-10-30 18:10:19] iter = 13000, loss = 7.1197
2024-10-30 18:10:23: [2024-10-30 18:10:23] iter = 13010, loss = 26.6050
2024-10-30 18:10:27: [2024-10-30 18:10:27] iter = 13020, loss = 7.9603
2024-10-30 18:10:31: [2024-10-30 18:10:31] iter = 13030, loss = 8.5701
2024-10-30 18:10:35: [2024-10-30 18:10:35] iter = 13040, loss = 5.7572
2024-10-30 18:10:39: [2024-10-30 18:10:39] iter = 13050, loss = 27.2038
2024-10-30 18:10:42: [2024-10-30 18:10:42] iter = 13060, loss = 38.2732
2024-10-30 18:10:45: [2024-10-30 18:10:45] iter = 13070, loss = 20.4809
2024-10-30 18:10:49: [2024-10-30 18:10:49] iter = 13080, loss = 12.7013
2024-10-30 18:10:53: [2024-10-30 18:10:53] iter = 13090, loss = 14.3826
2024-10-30 18:10:58: [2024-10-30 18:10:58] iter = 13100, loss = 8.2750
2024-10-30 18:11:02: [2024-10-30 18:11:02] iter = 13110, loss = 19.4940
2024-10-30 18:11:06: [2024-10-30 18:11:06] iter = 13120, loss = 3.7224
2024-10-30 18:11:10: [2024-10-30 18:11:10] iter = 13130, loss = 24.6395
2024-10-30 18:11:14: [2024-10-30 18:11:14] iter = 13140, loss = 15.4481
2024-10-30 18:11:18: [2024-10-30 18:11:18] iter = 13150, loss = 13.1047
2024-10-30 18:11:21: [2024-10-30 18:11:21] iter = 13160, loss = 12.5772
2024-10-30 18:11:24: [2024-10-30 18:11:24] iter = 13170, loss = 7.2942
2024-10-30 18:11:29: [2024-10-30 18:11:29] iter = 13180, loss = 28.5492
2024-10-30 18:11:34: [2024-10-30 18:11:34] iter = 13190, loss = 11.7526
2024-10-30 18:11:37: [2024-10-30 18:11:37] iter = 13200, loss = 4.5591
2024-10-30 18:11:42: [2024-10-30 18:11:42] iter = 13210, loss = 31.8671
2024-10-30 18:11:46: [2024-10-30 18:11:46] iter = 13220, loss = 4.8661
2024-10-30 18:11:50: [2024-10-30 18:11:50] iter = 13230, loss = 3.9101
2024-10-30 18:11:54: [2024-10-30 18:11:54] iter = 13240, loss = 7.9024
2024-10-30 18:11:58: [2024-10-30 18:11:58] iter = 13250, loss = 47.8933
2024-10-30 18:12:01: [2024-10-30 18:12:01] iter = 13260, loss = 5.0636
2024-10-30 18:12:05: [2024-10-30 18:12:05] iter = 13270, loss = 8.2148
2024-10-30 18:12:10: [2024-10-30 18:12:10] iter = 13280, loss = 17.6279
2024-10-30 18:12:14: [2024-10-30 18:12:14] iter = 13290, loss = 5.0255
2024-10-30 18:12:18: [2024-10-30 18:12:18] iter = 13300, loss = 4.4765
2024-10-30 18:12:21: [2024-10-30 18:12:21] iter = 13310, loss = 5.6663
2024-10-30 18:12:25: [2024-10-30 18:12:25] iter = 13320, loss = 31.7945
2024-10-30 18:12:29: [2024-10-30 18:12:29] iter = 13330, loss = 50.9802
2024-10-30 18:12:32: [2024-10-30 18:12:32] iter = 13340, loss = 29.8164
2024-10-30 18:12:35: [2024-10-30 18:12:35] iter = 13350, loss = 5.8573
2024-10-30 18:12:40: [2024-10-30 18:12:40] iter = 13360, loss = 11.5994
2024-10-30 18:12:44: [2024-10-30 18:12:44] iter = 13370, loss = 6.2952
2024-10-30 18:12:48: [2024-10-30 18:12:48] iter = 13380, loss = 4.7308
2024-10-30 18:12:51: [2024-10-30 18:12:51] iter = 13390, loss = 9.1846
2024-10-30 18:12:55: [2024-10-30 18:12:55] iter = 13400, loss = 50.5836
2024-10-30 18:12:58: [2024-10-30 18:12:58] iter = 13410, loss = 17.2730
2024-10-30 18:13:02: [2024-10-30 18:13:02] iter = 13420, loss = 5.6382
2024-10-30 18:13:06: [2024-10-30 18:13:06] iter = 13430, loss = 38.7879
2024-10-30 18:13:10: [2024-10-30 18:13:10] iter = 13440, loss = 10.0624
2024-10-30 18:13:16: [2024-10-30 18:13:16] iter = 13450, loss = 45.0178
2024-10-30 18:13:20: [2024-10-30 18:13:20] iter = 13460, loss = 7.9750
2024-10-30 18:13:25: [2024-10-30 18:13:25] iter = 13470, loss = 25.7955
2024-10-30 18:13:28: [2024-10-30 18:13:28] iter = 13480, loss = 8.2745
2024-10-30 18:13:33: [2024-10-30 18:13:33] iter = 13490, loss = 46.6931
2024-10-30 18:13:38: [2024-10-30 18:13:38] iter = 13500, loss = 12.1008
2024-10-30 18:13:41: [2024-10-30 18:13:41] iter = 13510, loss = 14.7859
2024-10-30 18:13:43: [2024-10-30 18:13:43] iter = 13520, loss = 37.8976
2024-10-30 18:13:48: [2024-10-30 18:13:48] iter = 13530, loss = 4.0576
2024-10-30 18:13:51: [2024-10-30 18:13:51] iter = 13540, loss = 41.3461
2024-10-30 18:13:54: [2024-10-30 18:13:54] iter = 13550, loss = 5.7541
2024-10-30 18:13:57: [2024-10-30 18:13:57] iter = 13560, loss = 21.7012
2024-10-30 18:14:01: [2024-10-30 18:14:01] iter = 13570, loss = 60.9435
2024-10-30 18:14:04: [2024-10-30 18:14:04] iter = 13580, loss = 11.5627
2024-10-30 18:14:08: [2024-10-30 18:14:08] iter = 13590, loss = 9.4636
2024-10-30 18:14:13: [2024-10-30 18:14:13] iter = 13600, loss = 18.1834
2024-10-30 18:14:17: [2024-10-30 18:14:17] iter = 13610, loss = 27.8560
2024-10-30 18:14:21: [2024-10-30 18:14:21] iter = 13620, loss = 8.4867
2024-10-30 18:14:25: [2024-10-30 18:14:25] iter = 13630, loss = 7.4564
2024-10-30 18:14:30: [2024-10-30 18:14:30] iter = 13640, loss = 3.4599
2024-10-30 18:14:34: [2024-10-30 18:14:34] iter = 13650, loss = 56.2090
2024-10-30 18:14:38: [2024-10-30 18:14:38] iter = 13660, loss = 5.9730
2024-10-30 18:14:42: [2024-10-30 18:14:42] iter = 13670, loss = 4.5303
2024-10-30 18:14:45: [2024-10-30 18:14:45] iter = 13680, loss = 19.6118
2024-10-30 18:14:49: [2024-10-30 18:14:48] iter = 13690, loss = 10.6217
2024-10-30 18:14:54: [2024-10-30 18:14:54] iter = 13700, loss = 5.8687
2024-10-30 18:14:56: [2024-10-30 18:14:56] iter = 13710, loss = 3.8535
2024-10-30 18:15:00: [2024-10-30 18:15:00] iter = 13720, loss = 6.4871
2024-10-30 18:15:03: [2024-10-30 18:15:03] iter = 13730, loss = 7.6354
2024-10-30 18:15:07: [2024-10-30 18:15:07] iter = 13740, loss = 8.8854
2024-10-30 18:15:12: [2024-10-30 18:15:12] iter = 13750, loss = 50.5283
2024-10-30 18:15:16: [2024-10-30 18:15:16] iter = 13760, loss = 4.7545
2024-10-30 18:15:20: [2024-10-30 18:15:20] iter = 13770, loss = 6.7775
2024-10-30 18:15:23: [2024-10-30 18:15:23] iter = 13780, loss = 29.6837
2024-10-30 18:15:27: [2024-10-30 18:15:27] iter = 13790, loss = 9.7000
2024-10-30 18:15:32: [2024-10-30 18:15:32] iter = 13800, loss = 12.8372
2024-10-30 18:15:36: [2024-10-30 18:15:36] iter = 13810, loss = 7.5912
2024-10-30 18:15:39: [2024-10-30 18:15:39] iter = 13820, loss = 10.0259
2024-10-30 18:15:44: [2024-10-30 18:15:44] iter = 13830, loss = 70.5640
2024-10-30 18:15:48: [2024-10-30 18:15:48] iter = 13840, loss = 33.1229
2024-10-30 18:15:52: [2024-10-30 18:15:52] iter = 13850, loss = 103.8155
2024-10-30 18:15:55: [2024-10-30 18:15:55] iter = 13860, loss = 16.5733
2024-10-30 18:15:59: [2024-10-30 18:15:59] iter = 13870, loss = 13.9574
2024-10-30 18:16:02: [2024-10-30 18:16:02] iter = 13880, loss = 10.3131
2024-10-30 18:16:05: [2024-10-30 18:16:05] iter = 13890, loss = 22.3242
2024-10-30 18:16:10: [2024-10-30 18:16:10] iter = 13900, loss = 5.9399
2024-10-30 18:16:14: [2024-10-30 18:16:14] iter = 13910, loss = 62.6829
2024-10-30 18:16:18: [2024-10-30 18:16:18] iter = 13920, loss = 37.2310
2024-10-30 18:16:21: [2024-10-30 18:16:21] iter = 13930, loss = 11.9304
2024-10-30 18:16:24: [2024-10-30 18:16:24] iter = 13940, loss = 34.7435
2024-10-30 18:16:27: [2024-10-30 18:16:27] iter = 13950, loss = 20.8875
2024-10-30 18:16:32: [2024-10-30 18:16:32] iter = 13960, loss = 14.3194
2024-10-30 18:16:36: [2024-10-30 18:16:36] iter = 13970, loss = 10.2500
2024-10-30 18:16:41: [2024-10-30 18:16:41] iter = 13980, loss = 13.0411
2024-10-30 18:16:45: [2024-10-30 18:16:45] iter = 13990, loss = 60.6864
2024-10-30 18:16:48: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 18:16:48: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:16:48: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 8854}

[2024-10-30 16:06:35] Evaluate_00: epoch = 1000 train time = 29 s train loss = 0.010738 train acc = 1.0000, test acc = 0.2562, test_sen =0.2822, test_spe =0.8961, test_f1 =0.2245
[2024-10-30 16:07:11] Evaluate_01: epoch = 1000 train time = 30 s train loss = 0.003647 train acc = 1.0000, test acc = 0.2525, test_sen =0.2855, test_spe =0.8958, test_f1 =0.2220
[2024-10-30 16:07:42] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.076984 train acc = 1.0000, test acc = 0.2574, test_sen =0.2799, test_spe =0.8962, test_f1 =0.2210
[2024-10-30 16:08:14] Evaluate_03: epoch = 1000 train time = 27 s train loss = 0.003118 train acc = 1.0000, test acc = 0.2585, test_sen =0.2819, test_spe =0.8960, test_f1 =0.2192
[2024-10-30 16:08:46] Evaluate_04: epoch = 1000 train time = 27 s train loss = 0.001469 train acc = 1.0000, test acc = 0.2421, test_sen =0.2783, test_spe =0.8947, test_f1 =0.2138
[2024-10-30 16:24:00] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.081323 train acc = 1.0000, test acc = 0.3735, test_sen =0.3003, test_spe =0.9086, test_f1 =0.2677
[2024-10-30 16:24:27] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.011499 train acc = 1.0000, test acc = 0.3677, test_sen =0.2981, test_spe =0.9083, test_f1 =0.2618
[2024-10-30 16:24:57] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.079420 train acc = 1.0000, test acc = 0.3629, test_sen =0.3000, test_spe =0.9078, test_f1 =0.2600
[2024-10-30 16:25:28] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.068253 train acc = 1.0000, test acc = 0.3683, test_sen =0.3014, test_spe =0.9085, test_f1 =0.2661
[2024-10-30 16:26:03] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.010110 train acc = 1.0000, test acc = 0.3748, test_sen =0.3022, test_spe =0.9089, test_f1 =0.2637
[2024-10-30 16:26:50] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.027460 train acc = 1.0000, test acc = 0.2702, test_sen =0.2518, test_spe =0.8945, test_f1 =0.2302
[2024-10-30 16:27:19] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.022512 train acc = 1.0000, test acc = 0.2769, test_sen =0.2580, test_spe =0.8952, test_f1 =0.2350
[2024-10-30 16:27:53] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.104632 train acc = 1.0000, test acc = 0.2729, test_sen =0.2518, test_spe =0.8949, test_f1 =0.2280
[2024-10-30 16:28:19] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.017585 train acc = 1.0000, test acc = 0.2698, test_sen =0.2553, test_spe =0.8947, test_f1 =0.2314
[2024-10-30 16:28:48] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.002710 train acc = 1.0000, test acc = 0.2766, test_sen =0.2567, test_spe =0.8953, test_f1 =0.2350
[2024-10-30 16:43:16] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.002626 train acc = 1.0000, test acc = 0.3108, test_sen =0.2878, test_spe =0.9022, test_f1 =0.2349
[2024-10-30 16:43:41] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.006586 train acc = 1.0000, test acc = 0.3085, test_sen =0.2876, test_spe =0.9021, test_f1 =0.2378
[2024-10-30 16:44:11] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.009480 train acc = 1.0000, test acc = 0.2963, test_sen =0.2875, test_spe =0.9011, test_f1 =0.2393
[2024-10-30 16:44:44] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.009171 train acc = 1.0000, test acc = 0.3093, test_sen =0.2913, test_spe =0.9022, test_f1 =0.2399
[2024-10-30 16:45:15] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.003819 train acc = 1.0000, test acc = 0.3067, test_sen =0.2887, test_spe =0.9016, test_f1 =0.2405
[2024-10-30 16:59:08] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.105121 train acc = 1.0000, test acc = 0.3903, test_sen =0.2932, test_spe =0.9100, test_f1 =0.2764
[2024-10-30 16:59:43] Evaluate_01: epoch = 1000 train time = 28 s train loss = 0.094311 train acc = 1.0000, test acc = 0.3936, test_sen =0.2983, test_spe =0.9106, test_f1 =0.2843
[2024-10-30 17:00:12] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.004897 train acc = 1.0000, test acc = 0.4001, test_sen =0.2943, test_spe =0.9111, test_f1 =0.2769
[2024-10-30 17:00:40] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.053427 train acc = 1.0000, test acc = 0.3975, test_sen =0.3055, test_spe =0.9114, test_f1 =0.2897
[2024-10-30 17:01:12] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.003707 train acc = 1.0000, test acc = 0.3769, test_sen =0.2985, test_spe =0.9091, test_f1 =0.2777
[2024-10-30 17:15:30] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.003520 train acc = 1.0000, test acc = 0.3503, test_sen =0.2902, test_spe =0.9054, test_f1 =0.2703
[2024-10-30 17:16:00] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.007635 train acc = 1.0000, test acc = 0.3366, test_sen =0.2795, test_spe =0.9041, test_f1 =0.2608
[2024-10-30 17:16:28] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.006589 train acc = 1.0000, test acc = 0.3441, test_sen =0.2878, test_spe =0.9047, test_f1 =0.2698
[2024-10-30 17:16:57] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.002962 train acc = 1.0000, test acc = 0.3333, test_sen =0.2808, test_spe =0.9040, test_f1 =0.2592
[2024-10-30 17:17:24] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.009138 train acc = 1.0000, test acc = 0.3530, test_sen =0.2871, test_spe =0.9053, test_f1 =0.2711
[2024-10-30 17:31:53] Evaluate_00: epoch = 1000 train time = 25 s train loss = 0.002154 train acc = 1.0000, test acc = 0.3507, test_sen =0.2901, test_spe =0.9060, test_f1 =0.2459
[2024-10-30 17:32:23] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.004227 train acc = 1.0000, test acc = 0.3343, test_sen =0.2937, test_spe =0.9044, test_f1 =0.2456
[2024-10-30 17:32:57] Evaluate_02: epoch = 1000 train time = 28 s train loss = 0.006367 train acc = 1.0000, test acc = 0.3181, test_sen =0.2873, test_spe =0.9028, test_f1 =0.2315
[2024-10-30 17:33:27] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.005160 train acc = 1.0000, test acc = 0.3220, test_sen =0.2840, test_spe =0.9031, test_f1 =0.2366
[2024-10-30 17:33:54] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.003695 train acc = 1.0000, test acc = 0.3272, test_sen =0.2845, test_spe =0.9034, test_f1 =0.2390
[2024-10-30 17:47:42] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.039438 train acc = 0.9875, test acc = 0.3721, test_sen =0.3135, test_spe =0.9081, test_f1 =0.2767
[2024-10-30 17:48:15] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.004204 train acc = 1.0000, test acc = 0.3777, test_sen =0.3244, test_spe =0.9095, test_f1 =0.2843
[2024-10-30 17:48:43] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.011130 train acc = 1.0000, test acc = 0.3546, test_sen =0.3178, test_spe =0.9071, test_f1 =0.2767
[2024-10-30 17:49:09] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.047772 train acc = 1.0000, test acc = 0.3519, test_sen =0.3101, test_spe =0.9067, test_f1 =0.2723
[2024-10-30 17:49:35] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.037528 train acc = 1.0000, test acc = 0.3746, test_sen =0.3182, test_spe =0.9088, test_f1 =0.2808
[2024-10-30 18:02:09] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.059834 train acc = 1.0000, test acc = 0.3997, test_sen =0.3206, test_spe =0.9116, test_f1 =0.2854
[2024-10-30 18:02:38] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.060543 train acc = 1.0000, test acc = 0.3994, test_sen =0.3157, test_spe =0.9114, test_f1 =0.2830
[2024-10-30 18:03:06] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.008218 train acc = 1.0000, test acc = 0.4100, test_sen =0.3174, test_spe =0.9122, test_f1 =0.2822
[2024-10-30 18:03:33] Evaluate_03: epoch = 1000 train time = 21 s train loss = 0.004897 train acc = 1.0000, test acc = 0.3995, test_sen =0.3139, test_spe =0.9115, test_f1 =0.2810
[2024-10-30 18:03:59] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.001565 train acc = 1.0000, test acc = 0.3969, test_sen =0.3188, test_spe =0.9113, test_f1 =0.2829
[2024-10-30 18:17:20] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.008157 train acc = 1.0000, test acc = 0.3645, test_sen =0.3193, test_spe =0.9081, test_f1 =0.2880/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:19:13: Evaluate 5 random ConvNet, ACCmean = 0.3530 ACCstd = 0.0096
-------------------------
2024-10-30 18:19:13: Evaluate 5 random ConvNet, SENmean = 0.3156 SENstd = 0.0037
-------------------------
2024-10-30 18:19:13: Evaluate 5 random ConvNet, SPEmean = 0.9067 SPEstd = 0.0011
-------------------------
2024-10-30 18:19:13: Evaluate 5 random ConvNet, F!mean = 0.2826 F!std = 0.0049
-------------------------
2024-10-30 18:19:13: Evaluate 5 random ConvNet, mean = 0.3530 std = 0.0096
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:19:13: [2024-10-30 18:19:13] iter = 14000, loss = 14.8210
2024-10-30 18:19:18: [2024-10-30 18:19:18] iter = 14010, loss = 7.9556
2024-10-30 18:19:22: [2024-10-30 18:19:22] iter = 14020, loss = 18.0487
2024-10-30 18:19:25: [2024-10-30 18:19:25] iter = 14030, loss = 6.8445
2024-10-30 18:19:29: [2024-10-30 18:19:29] iter = 14040, loss = 4.3606
2024-10-30 18:19:34: [2024-10-30 18:19:34] iter = 14050, loss = 4.0415
2024-10-30 18:19:37: [2024-10-30 18:19:37] iter = 14060, loss = 3.7567
2024-10-30 18:19:40: [2024-10-30 18:19:40] iter = 14070, loss = 41.3195
2024-10-30 18:19:45: [2024-10-30 18:19:45] iter = 14080, loss = 6.0049
2024-10-30 18:19:48: [2024-10-30 18:19:48] iter = 14090, loss = 4.5852
2024-10-30 18:19:52: [2024-10-30 18:19:52] iter = 14100, loss = 22.8535
2024-10-30 18:19:55: [2024-10-30 18:19:55] iter = 14110, loss = 7.0324
2024-10-30 18:19:58: [2024-10-30 18:19:58] iter = 14120, loss = 3.9697
2024-10-30 18:20:02: [2024-10-30 18:20:02] iter = 14130, loss = 15.7682
2024-10-30 18:20:06: [2024-10-30 18:20:06] iter = 14140, loss = 20.8789
2024-10-30 18:20:10: [2024-10-30 18:20:10] iter = 14150, loss = 5.9228
2024-10-30 18:20:14: [2024-10-30 18:20:14] iter = 14160, loss = 9.4252
2024-10-30 18:20:17: [2024-10-30 18:20:17] iter = 14170, loss = 4.5890
2024-10-30 18:20:20: [2024-10-30 18:20:20] iter = 14180, loss = 3.5277
2024-10-30 18:20:24: [2024-10-30 18:20:24] iter = 14190, loss = 3.5997
2024-10-30 18:20:30: [2024-10-30 18:20:30] iter = 14200, loss = 52.3425
2024-10-30 18:20:33: [2024-10-30 18:20:33] iter = 14210, loss = 22.2566
2024-10-30 18:20:36: [2024-10-30 18:20:36] iter = 14220, loss = 10.1104
2024-10-30 18:20:39: [2024-10-30 18:20:39] iter = 14230, loss = 21.4622
2024-10-30 18:20:43: [2024-10-30 18:20:43] iter = 14240, loss = 3.4166
2024-10-30 18:20:47: [2024-10-30 18:20:47] iter = 14250, loss = 26.1955
2024-10-30 18:20:51: [2024-10-30 18:20:51] iter = 14260, loss = 22.4167
2024-10-30 18:20:55: [2024-10-30 18:20:55] iter = 14270, loss = 5.4447
2024-10-30 18:20:58: [2024-10-30 18:20:58] iter = 14280, loss = 34.2684
2024-10-30 18:21:01: [2024-10-30 18:21:01] iter = 14290, loss = 13.8805
2024-10-30 18:21:05: [2024-10-30 18:21:05] iter = 14300, loss = 29.1787
2024-10-30 18:21:09: [2024-10-30 18:21:09] iter = 14310, loss = 16.5934
2024-10-30 18:21:12: [2024-10-30 18:21:12] iter = 14320, loss = 4.1797
2024-10-30 18:21:16: [2024-10-30 18:21:16] iter = 14330, loss = 15.2222
2024-10-30 18:21:19: [2024-10-30 18:21:19] iter = 14340, loss = 6.3136
2024-10-30 18:21:23: [2024-10-30 18:21:23] iter = 14350, loss = 3.4026
2024-10-30 18:21:28: [2024-10-30 18:21:28] iter = 14360, loss = 9.0874
2024-10-30 18:21:32: [2024-10-30 18:21:32] iter = 14370, loss = 66.4385
2024-10-30 18:21:35: [2024-10-30 18:21:35] iter = 14380, loss = 5.1212
2024-10-30 18:21:39: [2024-10-30 18:21:39] iter = 14390, loss = 42.8868
2024-10-30 18:21:43: [2024-10-30 18:21:43] iter = 14400, loss = 43.9273
2024-10-30 18:21:47: [2024-10-30 18:21:47] iter = 14410, loss = 6.3838
2024-10-30 18:21:51: [2024-10-30 18:21:51] iter = 14420, loss = 12.9427
2024-10-30 18:21:55: [2024-10-30 18:21:55] iter = 14430, loss = 21.9333
2024-10-30 18:21:59: [2024-10-30 18:21:59] iter = 14440, loss = 6.5379
2024-10-30 18:22:02: [2024-10-30 18:22:02] iter = 14450, loss = 9.7793
2024-10-30 18:22:06: [2024-10-30 18:22:06] iter = 14460, loss = 12.6747
2024-10-30 18:22:09: [2024-10-30 18:22:09] iter = 14470, loss = 21.7508
2024-10-30 18:22:13: [2024-10-30 18:22:13] iter = 14480, loss = 64.9758
2024-10-30 18:22:17: [2024-10-30 18:22:17] iter = 14490, loss = 4.6931
2024-10-30 18:22:21: [2024-10-30 18:22:21] iter = 14500, loss = 23.0166
2024-10-30 18:22:24: [2024-10-30 18:22:24] iter = 14510, loss = 43.6181
2024-10-30 18:22:28: [2024-10-30 18:22:28] iter = 14520, loss = 28.7672
2024-10-30 18:22:31: [2024-10-30 18:22:31] iter = 14530, loss = 22.1757
2024-10-30 18:22:35: [2024-10-30 18:22:35] iter = 14540, loss = 36.9333
2024-10-30 18:22:39: [2024-10-30 18:22:39] iter = 14550, loss = 38.3498
2024-10-30 18:22:43: [2024-10-30 18:22:43] iter = 14560, loss = 33.8365
2024-10-30 18:22:48: [2024-10-30 18:22:48] iter = 14570, loss = 7.9944
2024-10-30 18:22:51: [2024-10-30 18:22:51] iter = 14580, loss = 4.7810
2024-10-30 18:22:55: [2024-10-30 18:22:55] iter = 14590, loss = 73.2057
2024-10-30 18:22:59: [2024-10-30 18:22:59] iter = 14600, loss = 8.6538
2024-10-30 18:23:03: [2024-10-30 18:23:03] iter = 14610, loss = 24.6239
2024-10-30 18:23:08: [2024-10-30 18:23:08] iter = 14620, loss = 9.5904
2024-10-30 18:23:11: [2024-10-30 18:23:11] iter = 14630, loss = 4.8300
2024-10-30 18:23:16: [2024-10-30 18:23:16] iter = 14640, loss = 30.8635
2024-10-30 18:23:20: [2024-10-30 18:23:20] iter = 14650, loss = 20.1809
2024-10-30 18:23:24: [2024-10-30 18:23:24] iter = 14660, loss = 4.3804
2024-10-30 18:23:26: [2024-10-30 18:23:26] iter = 14670, loss = 53.6851
2024-10-30 18:23:30: [2024-10-30 18:23:30] iter = 14680, loss = 15.9467
2024-10-30 18:23:34: [2024-10-30 18:23:34] iter = 14690, loss = 9.5991
2024-10-30 18:23:38: [2024-10-30 18:23:38] iter = 14700, loss = 38.1695
2024-10-30 18:23:41: [2024-10-30 18:23:41] iter = 14710, loss = 40.8275
2024-10-30 18:23:45: [2024-10-30 18:23:45] iter = 14720, loss = 4.2179
2024-10-30 18:23:48: [2024-10-30 18:23:48] iter = 14730, loss = 11.5648
2024-10-30 18:23:52: [2024-10-30 18:23:52] iter = 14740, loss = 26.6544
2024-10-30 18:23:55: [2024-10-30 18:23:55] iter = 14750, loss = 35.4312
2024-10-30 18:23:58: [2024-10-30 18:23:58] iter = 14760, loss = 37.2259
2024-10-30 18:24:02: [2024-10-30 18:24:02] iter = 14770, loss = 15.2535
2024-10-30 18:24:06: [2024-10-30 18:24:06] iter = 14780, loss = 12.9305
2024-10-30 18:24:09: [2024-10-30 18:24:09] iter = 14790, loss = 11.2207
2024-10-30 18:24:13: [2024-10-30 18:24:13] iter = 14800, loss = 7.3623
2024-10-30 18:24:17: [2024-10-30 18:24:17] iter = 14810, loss = 13.2899
2024-10-30 18:24:19: [2024-10-30 18:24:19] iter = 14820, loss = 7.2287
2024-10-30 18:24:23: [2024-10-30 18:24:23] iter = 14830, loss = 4.8828
2024-10-30 18:24:27: [2024-10-30 18:24:27] iter = 14840, loss = 60.0854
2024-10-30 18:24:29: [2024-10-30 18:24:29] iter = 14850, loss = 57.1234
2024-10-30 18:24:33: [2024-10-30 18:24:33] iter = 14860, loss = 3.7436
2024-10-30 18:24:36: [2024-10-30 18:24:36] iter = 14870, loss = 31.9252
2024-10-30 18:24:38: [2024-10-30 18:24:38] iter = 14880, loss = 6.8662
2024-10-30 18:24:41: [2024-10-30 18:24:41] iter = 14890, loss = 13.8980
2024-10-30 18:24:45: [2024-10-30 18:24:45] iter = 14900, loss = 5.7894
2024-10-30 18:24:48: [2024-10-30 18:24:48] iter = 14910, loss = 31.3583
2024-10-30 18:24:53: [2024-10-30 18:24:53] iter = 14920, loss = 58.5538
2024-10-30 18:24:57: [2024-10-30 18:24:57] iter = 14930, loss = 4.1422
2024-10-30 18:25:00: [2024-10-30 18:25:00] iter = 14940, loss = 5.9032
2024-10-30 18:25:04: [2024-10-30 18:25:04] iter = 14950, loss = 5.4083
2024-10-30 18:25:08: [2024-10-30 18:25:08] iter = 14960, loss = 13.5995
2024-10-30 18:25:12: [2024-10-30 18:25:12] iter = 14970, loss = 7.0198
2024-10-30 18:25:15: [2024-10-30 18:25:15] iter = 14980, loss = 22.6450
2024-10-30 18:25:19: [2024-10-30 18:25:19] iter = 14990, loss = 18.7032
2024-10-30 18:25:22: [2024-10-30 18:25:22] iter = 15000, loss = 43.1826
2024-10-30 18:25:27: [2024-10-30 18:25:27] iter = 15010, loss = 16.5452
2024-10-30 18:25:29: [2024-10-30 18:25:29] iter = 15020, loss = 18.3712
2024-10-30 18:25:33: [2024-10-30 18:25:33] iter = 15030, loss = 118.3611
2024-10-30 18:25:37: [2024-10-30 18:25:37] iter = 15040, loss = 7.6522
2024-10-30 18:25:41: [2024-10-30 18:25:41] iter = 15050, loss = 4.3533
2024-10-30 18:25:44: [2024-10-30 18:25:44] iter = 15060, loss = 22.6651
2024-10-30 18:25:48: [2024-10-30 18:25:48] iter = 15070, loss = 75.9351
2024-10-30 18:25:52: [2024-10-30 18:25:52] iter = 15080, loss = 9.8743
2024-10-30 18:25:54: [2024-10-30 18:25:54] iter = 15090, loss = 28.3111
2024-10-30 18:25:58: [2024-10-30 18:25:58] iter = 15100, loss = 30.2136
2024-10-30 18:26:02: [2024-10-30 18:26:02] iter = 15110, loss = 50.5915
2024-10-30 18:26:06: [2024-10-30 18:26:06] iter = 15120, loss = 8.4303
2024-10-30 18:26:09: [2024-10-30 18:26:09] iter = 15130, loss = 30.0917
2024-10-30 18:26:12: [2024-10-30 18:26:12] iter = 15140, loss = 10.8503
2024-10-30 18:26:16: [2024-10-30 18:26:16] iter = 15150, loss = 47.9040
2024-10-30 18:26:19: [2024-10-30 18:26:19] iter = 15160, loss = 32.1255
2024-10-30 18:26:23: [2024-10-30 18:26:23] iter = 15170, loss = 4.3848
2024-10-30 18:26:27: [2024-10-30 18:26:27] iter = 15180, loss = 4.8173
2024-10-30 18:26:31: [2024-10-30 18:26:31] iter = 15190, loss = 7.0680
2024-10-30 18:26:33: [2024-10-30 18:26:33] iter = 15200, loss = 9.7928
2024-10-30 18:26:38: [2024-10-30 18:26:38] iter = 15210, loss = 13.7740
2024-10-30 18:26:42: [2024-10-30 18:26:42] iter = 15220, loss = 17.7214
2024-10-30 18:26:48: [2024-10-30 18:26:48] iter = 15230, loss = 4.4502
2024-10-30 18:26:51: [2024-10-30 18:26:51] iter = 15240, loss = 26.2569
2024-10-30 18:26:55: [2024-10-30 18:26:55] iter = 15250, loss = 5.8459
2024-10-30 18:27:00: [2024-10-30 18:27:00] iter = 15260, loss = 16.2885
2024-10-30 18:27:04: [2024-10-30 18:27:04] iter = 15270, loss = 15.2159
2024-10-30 18:27:08: [2024-10-30 18:27:08] iter = 15280, loss = 5.2831
2024-10-30 18:27:11: [2024-10-30 18:27:11] iter = 15290, loss = 41.4296
2024-10-30 18:27:14: [2024-10-30 18:27:14] iter = 15300, loss = 9.2055
2024-10-30 18:27:18: [2024-10-30 18:27:18] iter = 15310, loss = 4.9070
2024-10-30 18:27:23: [2024-10-30 18:27:23] iter = 15320, loss = 14.2556
2024-10-30 18:27:27: [2024-10-30 18:27:27] iter = 15330, loss = 41.4308
2024-10-30 18:27:31: [2024-10-30 18:27:31] iter = 15340, loss = 5.7654
2024-10-30 18:27:35: [2024-10-30 18:27:35] iter = 15350, loss = 6.0942
2024-10-30 18:27:40: [2024-10-30 18:27:40] iter = 15360, loss = 29.4054
2024-10-30 18:27:45: [2024-10-30 18:27:45] iter = 15370, loss = 62.5354
2024-10-30 18:27:48: [2024-10-30 18:27:48] iter = 15380, loss = 24.5223
2024-10-30 18:27:52: [2024-10-30 18:27:52] iter = 15390, loss = 13.0059
2024-10-30 18:27:55: [2024-10-30 18:27:55] iter = 15400, loss = 7.1034
2024-10-30 18:27:58: [2024-10-30 18:27:58] iter = 15410, loss = 4.5149
2024-10-30 18:28:02: [2024-10-30 18:28:02] iter = 15420, loss = 12.5277
2024-10-30 18:28:07: [2024-10-30 18:28:07] iter = 15430, loss = 14.0283
2024-10-30 18:28:11: [2024-10-30 18:28:11] iter = 15440, loss = 38.0983
2024-10-30 18:28:16: [2024-10-30 18:28:16] iter = 15450, loss = 5.8494
2024-10-30 18:28:19: [2024-10-30 18:28:19] iter = 15460, loss = 14.5817
2024-10-30 18:28:23: [2024-10-30 18:28:23] iter = 15470, loss = 34.5869
2024-10-30 18:28:26: [2024-10-30 18:28:26] iter = 15480, loss = 41.8734
2024-10-30 18:28:29: [2024-10-30 18:28:29] iter = 15490, loss = 10.1570
2024-10-30 18:28:32: [2024-10-30 18:28:32] iter = 15500, loss = 6.3220
2024-10-30 18:28:36: [2024-10-30 18:28:36] iter = 15510, loss = 23.2730
2024-10-30 18:28:39: [2024-10-30 18:28:39] iter = 15520, loss = 9.7279
2024-10-30 18:28:44: [2024-10-30 18:28:44] iter = 15530, loss = 35.2762
2024-10-30 18:28:47: [2024-10-30 18:28:47] iter = 15540, loss = 3.9205
2024-10-30 18:28:52: [2024-10-30 18:28:52] iter = 15550, loss = 29.4111
2024-10-30 18:28:55: [2024-10-30 18:28:55] iter = 15560, loss = 12.4291
2024-10-30 18:29:00: [2024-10-30 18:29:00] iter = 15570, loss = 10.9243
2024-10-30 18:29:04: [2024-10-30 18:29:04] iter = 15580, loss = 19.3241
2024-10-30 18:29:08: [2024-10-30 18:29:08] iter = 15590, loss = 4.7298
2024-10-30 18:29:12: [2024-10-30 18:29:12] iter = 15600, loss = 34.6010
2024-10-30 18:29:16: [2024-10-30 18:29:16] iter = 15610, loss = 18.3112
2024-10-30 18:29:21: [2024-10-30 18:29:21] iter = 15620, loss = 45.2252
2024-10-30 18:29:24: [2024-10-30 18:29:24] iter = 15630, loss = 10.7035
2024-10-30 18:29:28: [2024-10-30 18:29:28] iter = 15640, loss = 18.1868
2024-10-30 18:29:32: [2024-10-30 18:29:32] iter = 15650, loss = 19.1283
2024-10-30 18:29:36: [2024-10-30 18:29:36] iter = 15660, loss = 17.8303
2024-10-30 18:29:40: [2024-10-30 18:29:40] iter = 15670, loss = 21.2074
2024-10-30 18:29:44: [2024-10-30 18:29:44] iter = 15680, loss = 27.7299
2024-10-30 18:29:48: [2024-10-30 18:29:48] iter = 15690, loss = 41.6429
2024-10-30 18:29:52: [2024-10-30 18:29:52] iter = 15700, loss = 13.0110
2024-10-30 18:29:55: [2024-10-30 18:29:55] iter = 15710, loss = 5.4036
2024-10-30 18:29:59: [2024-10-30 18:29:59] iter = 15720, loss = 5.8555
2024-10-30 18:30:03: [2024-10-30 18:30:03] iter = 15730, loss = 4.4066
2024-10-30 18:30:07: [2024-10-30 18:30:07] iter = 15740, loss = 5.2560
2024-10-30 18:30:10: [2024-10-30 18:30:10] iter = 15750, loss = 4.0692
2024-10-30 18:30:14: [2024-10-30 18:30:14] iter = 15760, loss = 12.6293
2024-10-30 18:30:17: [2024-10-30 18:30:17] iter = 15770, loss = 10.9124
2024-10-30 18:30:19: [2024-10-30 18:30:19] iter = 15780, loss = 5.3666
2024-10-30 18:30:23: [2024-10-30 18:30:23] iter = 15790, loss = 43.6296
2024-10-30 18:30:27: [2024-10-30 18:30:27] iter = 15800, loss = 7.0068
2024-10-30 18:30:31: [2024-10-30 18:30:31] iter = 15810, loss = 12.8733
2024-10-30 18:30:34: [2024-10-30 18:30:34] iter = 15820, loss = 19.6494
2024-10-30 18:30:38: [2024-10-30 18:30:38] iter = 15830, loss = 19.2172
2024-10-30 18:30:42: [2024-10-30 18:30:42] iter = 15840, loss = 5.0328
2024-10-30 18:30:47: [2024-10-30 18:30:47] iter = 15850, loss = 3.8429
2024-10-30 18:30:52: [2024-10-30 18:30:52] iter = 15860, loss = 7.2413
2024-10-30 18:30:56: [2024-10-30 18:30:56] iter = 15870, loss = 5.9841
2024-10-30 18:31:01: [2024-10-30 18:31:01] iter = 15880, loss = 6.7121
2024-10-30 18:31:03: [2024-10-30 18:31:03] iter = 15890, loss = 15.5613
2024-10-30 18:31:07: [2024-10-30 18:31:07] iter = 15900, loss = 38.1708
2024-10-30 18:31:11: [2024-10-30 18:31:11] iter = 15910, loss = 27.9985
2024-10-30 18:31:14: [2024-10-30 18:31:14] iter = 15920, loss = 12.1887
2024-10-30 18:31:18: [2024-10-30 18:31:18] iter = 15930, loss = 44.7384
2024-10-30 18:31:22: [2024-10-30 18:31:22] iter = 15940, loss = 5.7221
2024-10-30 18:31:26: [2024-10-30 18:31:26] iter = 15950, loss = 12.6469
2024-10-30 18:31:29: [2024-10-30 18:31:29] iter = 15960, loss = 7.0301
2024-10-30 18:31:32: [2024-10-30 18:31:32] iter = 15970, loss = 24.8052
2024-10-30 18:31:36: [2024-10-30 18:31:36] iter = 15980, loss = 9.2007
2024-10-30 18:31:40: [2024-10-30 18:31:40] iter = 15990, loss = 4.4213
2024-10-30 18:31:43: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 18:31:43: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:31:43: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 3437}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:34:08: Evaluate 5 random ConvNet, ACCmean = 0.3133 ACCstd = 0.0044
-------------------------
2024-10-30 18:34:08: Evaluate 5 random ConvNet, SENmean = 0.3002 SENstd = 0.0035
-------------------------
2024-10-30 18:34:08: Evaluate 5 random ConvNet, SPEmean = 0.9031 SPEstd = 0.0006
-------------------------
2024-10-30 18:34:08: Evaluate 5 random ConvNet, F!mean = 0.2625 F!std = 0.0048
-------------------------
2024-10-30 18:34:08: Evaluate 5 random ConvNet, mean = 0.3133 std = 0.0044
-------------------------
2024-10-30 18:34:08: [2024-10-30 18:34:08] iter = 16000, loss = 7.5011
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:34:12: [2024-10-30 18:34:12] iter = 16010, loss = 19.9216
2024-10-30 18:34:15: [2024-10-30 18:34:15] iter = 16020, loss = 22.6381
2024-10-30 18:34:19: [2024-10-30 18:34:19] iter = 16030, loss = 14.7675
2024-10-30 18:34:23: [2024-10-30 18:34:23] iter = 16040, loss = 8.4221
2024-10-30 18:34:25: [2024-10-30 18:34:25] iter = 16050, loss = 6.3377
2024-10-30 18:34:29: [2024-10-30 18:34:29] iter = 16060, loss = 23.0938
2024-10-30 18:34:32: [2024-10-30 18:34:32] iter = 16070, loss = 8.7179
2024-10-30 18:34:35: [2024-10-30 18:34:35] iter = 16080, loss = 21.7877
2024-10-30 18:34:39: [2024-10-30 18:34:39] iter = 16090, loss = 18.7344
2024-10-30 18:34:43: [2024-10-30 18:34:43] iter = 16100, loss = 22.8045
2024-10-30 18:34:47: [2024-10-30 18:34:47] iter = 16110, loss = 7.9725
2024-10-30 18:34:51: [2024-10-30 18:34:51] iter = 16120, loss = 33.5529
2024-10-30 18:34:56: [2024-10-30 18:34:56] iter = 16130, loss = 6.6770
2024-10-30 18:34:58: [2024-10-30 18:34:58] iter = 16140, loss = 8.4379
2024-10-30 18:35:00: [2024-10-30 18:35:00] iter = 16150, loss = 15.4688
2024-10-30 18:35:04: [2024-10-30 18:35:04] iter = 16160, loss = 10.5795
2024-10-30 18:35:09: [2024-10-30 18:35:09] iter = 16170, loss = 4.2426
2024-10-30 18:35:12: [2024-10-30 18:35:12] iter = 16180, loss = 43.2311
2024-10-30 18:35:15: [2024-10-30 18:35:15] iter = 16190, loss = 19.1987
2024-10-30 18:35:19: [2024-10-30 18:35:19] iter = 16200, loss = 57.3557
2024-10-30 18:35:22: [2024-10-30 18:35:22] iter = 16210, loss = 12.4596
2024-10-30 18:35:26: [2024-10-30 18:35:26] iter = 16220, loss = 7.6200
2024-10-30 18:35:29: [2024-10-30 18:35:29] iter = 16230, loss = 97.8890
2024-10-30 18:35:33: [2024-10-30 18:35:33] iter = 16240, loss = 4.6677
2024-10-30 18:35:36: [2024-10-30 18:35:36] iter = 16250, loss = 5.1172
2024-10-30 18:35:39: [2024-10-30 18:35:39] iter = 16260, loss = 31.1916
2024-10-30 18:35:44: [2024-10-30 18:35:44] iter = 16270, loss = 69.9749
2024-10-30 18:35:49: [2024-10-30 18:35:49] iter = 16280, loss = 53.2973
2024-10-30 18:35:53: [2024-10-30 18:35:53] iter = 16290, loss = 4.6278
2024-10-30 18:35:56: [2024-10-30 18:35:56] iter = 16300, loss = 17.0870
2024-10-30 18:36:00: [2024-10-30 18:36:00] iter = 16310, loss = 9.2629
2024-10-30 18:36:04: [2024-10-30 18:36:04] iter = 16320, loss = 34.4195
2024-10-30 18:36:08: [2024-10-30 18:36:08] iter = 16330, loss = 23.6307
2024-10-30 18:36:11: [2024-10-30 18:36:11] iter = 16340, loss = 17.8216
2024-10-30 18:36:16: [2024-10-30 18:36:16] iter = 16350, loss = 11.1086
2024-10-30 18:36:21: [2024-10-30 18:36:21] iter = 16360, loss = 3.1122
2024-10-30 18:36:25: [2024-10-30 18:36:25] iter = 16370, loss = 52.8336
2024-10-30 18:36:29: [2024-10-30 18:36:29] iter = 16380, loss = 22.7694
2024-10-30 18:36:34: [2024-10-30 18:36:34] iter = 16390, loss = 67.4181
2024-10-30 18:36:36: [2024-10-30 18:36:36] iter = 16400, loss = 8.8860
2024-10-30 18:36:39: [2024-10-30 18:36:39] iter = 16410, loss = 23.3071
2024-10-30 18:36:42: [2024-10-30 18:36:42] iter = 16420, loss = 3.1494
2024-10-30 18:36:45: [2024-10-30 18:36:45] iter = 16430, loss = 39.5223
2024-10-30 18:36:50: [2024-10-30 18:36:50] iter = 16440, loss = 11.3252
2024-10-30 18:36:55: [2024-10-30 18:36:55] iter = 16450, loss = 3.3265
2024-10-30 18:37:00: [2024-10-30 18:37:00] iter = 16460, loss = 62.3733
2024-10-30 18:37:04: [2024-10-30 18:37:04] iter = 16470, loss = 10.2849
2024-10-30 18:37:08: [2024-10-30 18:37:08] iter = 16480, loss = 22.9304
2024-10-30 18:37:11: [2024-10-30 18:37:11] iter = 16490, loss = 14.9158
2024-10-30 18:37:16: [2024-10-30 18:37:16] iter = 16500, loss = 5.0765
2024-10-30 18:37:20: [2024-10-30 18:37:20] iter = 16510, loss = 8.4138
2024-10-30 18:37:24: [2024-10-30 18:37:24] iter = 16520, loss = 14.1562
2024-10-30 18:37:27: [2024-10-30 18:37:27] iter = 16530, loss = 4.5694
2024-10-30 18:37:31: [2024-10-30 18:37:31] iter = 16540, loss = 18.7047
2024-10-30 18:37:34: [2024-10-30 18:37:34] iter = 16550, loss = 11.3352
2024-10-30 18:37:37: [2024-10-30 18:37:37] iter = 16560, loss = 63.8047
2024-10-30 18:37:41: [2024-10-30 18:37:41] iter = 16570, loss = 6.7280
2024-10-30 18:37:44: [2024-10-30 18:37:44] iter = 16580, loss = 10.3989
2024-10-30 18:37:48: [2024-10-30 18:37:48] iter = 16590, loss = 57.3206
2024-10-30 18:37:52: [2024-10-30 18:37:52] iter = 16600, loss = 10.6462
2024-10-30 18:37:55: [2024-10-30 18:37:55] iter = 16610, loss = 3.7930
2024-10-30 18:37:59: [2024-10-30 18:37:59] iter = 16620, loss = 23.4015
2024-10-30 18:38:02: [2024-10-30 18:38:02] iter = 16630, loss = 10.2541
2024-10-30 18:38:07: [2024-10-30 18:38:07] iter = 16640, loss = 21.5343
2024-10-30 18:38:10: [2024-10-30 18:38:10] iter = 16650, loss = 2.9274
2024-10-30 18:38:15: [2024-10-30 18:38:15] iter = 16660, loss = 25.2527
2024-10-30 18:38:18: [2024-10-30 18:38:18] iter = 16670, loss = 27.4439
2024-10-30 18:38:21: [2024-10-30 18:38:21] iter = 16680, loss = 50.5347
2024-10-30 18:38:24: [2024-10-30 18:38:24] iter = 16690, loss = 13.2604
2024-10-30 18:38:27: [2024-10-30 18:38:27] iter = 16700, loss = 5.7313
2024-10-30 18:38:30: [2024-10-30 18:38:30] iter = 16710, loss = 14.4698
2024-10-30 18:38:34: [2024-10-30 18:38:34] iter = 16720, loss = 16.5634
2024-10-30 18:38:38: [2024-10-30 18:38:38] iter = 16730, loss = 13.9348
2024-10-30 18:38:42: [2024-10-30 18:38:42] iter = 16740, loss = 19.5873
2024-10-30 18:38:46: [2024-10-30 18:38:46] iter = 16750, loss = 3.5316
2024-10-30 18:38:49: [2024-10-30 18:38:49] iter = 16760, loss = 14.1616
2024-10-30 18:38:53: [2024-10-30 18:38:53] iter = 16770, loss = 5.2886
2024-10-30 18:38:58: [2024-10-30 18:38:58] iter = 16780, loss = 33.0780
2024-10-30 18:39:01: [2024-10-30 18:39:01] iter = 16790, loss = 6.1118
2024-10-30 18:39:05: [2024-10-30 18:39:05] iter = 16800, loss = 20.2740
2024-10-30 18:39:10: [2024-10-30 18:39:10] iter = 16810, loss = 60.3346
2024-10-30 18:39:15: [2024-10-30 18:39:15] iter = 16820, loss = 13.1230
2024-10-30 18:39:18: [2024-10-30 18:39:18] iter = 16830, loss = 8.5094
2024-10-30 18:39:21: [2024-10-30 18:39:21] iter = 16840, loss = 4.8566
2024-10-30 18:39:24: [2024-10-30 18:39:24] iter = 16850, loss = 3.8633
2024-10-30 18:39:28: [2024-10-30 18:39:28] iter = 16860, loss = 9.4715
2024-10-30 18:39:31: [2024-10-30 18:39:31] iter = 16870, loss = 13.0238
2024-10-30 18:39:35: [2024-10-30 18:39:35] iter = 16880, loss = 5.1522
2024-10-30 18:39:39: [2024-10-30 18:39:39] iter = 16890, loss = 97.6359
2024-10-30 18:39:44: [2024-10-30 18:39:44] iter = 16900, loss = 7.0827
2024-10-30 18:39:47: [2024-10-30 18:39:47] iter = 16910, loss = 4.8303
2024-10-30 18:39:52: [2024-10-30 18:39:52] iter = 16920, loss = 5.4037
2024-10-30 18:39:54: [2024-10-30 18:39:54] iter = 16930, loss = 5.4247
2024-10-30 18:39:58: [2024-10-30 18:39:58] iter = 16940, loss = 27.3171
2024-10-30 18:40:01: [2024-10-30 18:40:01] iter = 16950, loss = 30.3272
2024-10-30 18:40:05: [2024-10-30 18:40:05] iter = 16960, loss = 5.2130
2024-10-30 18:40:09: [2024-10-30 18:40:09] iter = 16970, loss = 66.8225
2024-10-30 18:40:12: [2024-10-30 18:40:12] iter = 16980, loss = 7.8900
2024-10-30 18:40:16: [2024-10-30 18:40:16] iter = 16990, loss = 30.2015
2024-10-30 18:40:19: [2024-10-30 18:40:19] iter = 17000, loss = 68.4713
2024-10-30 18:40:23: [2024-10-30 18:40:23] iter = 17010, loss = 17.3509
2024-10-30 18:40:27: [2024-10-30 18:40:27] iter = 17020, loss = 56.5153
2024-10-30 18:40:29: [2024-10-30 18:40:29] iter = 17030, loss = 43.0175
2024-10-30 18:40:33: [2024-10-30 18:40:33] iter = 17040, loss = 5.3978
2024-10-30 18:40:37: [2024-10-30 18:40:37] iter = 17050, loss = 70.8019
2024-10-30 18:40:40: [2024-10-30 18:40:40] iter = 17060, loss = 4.0493
2024-10-30 18:40:43: [2024-10-30 18:40:43] iter = 17070, loss = 15.1087
2024-10-30 18:40:48: [2024-10-30 18:40:48] iter = 17080, loss = 58.4554
2024-10-30 18:40:51: [2024-10-30 18:40:51] iter = 17090, loss = 6.3860
2024-10-30 18:40:55: [2024-10-30 18:40:55] iter = 17100, loss = 9.5492
2024-10-30 18:40:58: [2024-10-30 18:40:58] iter = 17110, loss = 32.5079
2024-10-30 18:41:02: [2024-10-30 18:41:02] iter = 17120, loss = 17.2071
2024-10-30 18:41:06: [2024-10-30 18:41:06] iter = 17130, loss = 63.4449
2024-10-30 18:41:09: [2024-10-30 18:41:09] iter = 17140, loss = 58.0529
2024-10-30 18:41:12: [2024-10-30 18:41:12] iter = 17150, loss = 124.9103
2024-10-30 18:41:15: [2024-10-30 18:41:15] iter = 17160, loss = 53.2319
2024-10-30 18:41:19: [2024-10-30 18:41:19] iter = 17170, loss = 29.4321
2024-10-30 18:41:21: [2024-10-30 18:41:21] iter = 17180, loss = 4.4869
2024-10-30 18:41:25: [2024-10-30 18:41:25] iter = 17190, loss = 4.0990
2024-10-30 18:41:28: [2024-10-30 18:41:28] iter = 17200, loss = 6.0103
2024-10-30 18:41:32: [2024-10-30 18:41:32] iter = 17210, loss = 64.4758
2024-10-30 18:41:35: [2024-10-30 18:41:35] iter = 17220, loss = 8.6290
2024-10-30 18:41:39: [2024-10-30 18:41:39] iter = 17230, loss = 66.2612
2024-10-30 18:41:42: [2024-10-30 18:41:42] iter = 17240, loss = 18.4623
2024-10-30 18:41:46: [2024-10-30 18:41:46] iter = 17250, loss = 42.9399
2024-10-30 18:41:50: [2024-10-30 18:41:50] iter = 17260, loss = 11.5744
2024-10-30 18:41:53: [2024-10-30 18:41:53] iter = 17270, loss = 3.8429
2024-10-30 18:41:58: [2024-10-30 18:41:58] iter = 17280, loss = 13.8715
2024-10-30 18:42:03: [2024-10-30 18:42:03] iter = 17290, loss = 5.9389
2024-10-30 18:42:07: [2024-10-30 18:42:07] iter = 17300, loss = 10.8293
2024-10-30 18:42:10: [2024-10-30 18:42:10] iter = 17310, loss = 54.3028
2024-10-30 18:42:14: [2024-10-30 18:42:14] iter = 17320, loss = 5.5395
2024-10-30 18:42:19: [2024-10-30 18:42:19] iter = 17330, loss = 3.9791
2024-10-30 18:42:22: [2024-10-30 18:42:22] iter = 17340, loss = 25.8975
2024-10-30 18:42:24: [2024-10-30 18:42:24] iter = 17350, loss = 24.3083
2024-10-30 18:42:28: [2024-10-30 18:42:28] iter = 17360, loss = 21.7272
2024-10-30 18:42:32: [2024-10-30 18:42:32] iter = 17370, loss = 6.3758
2024-10-30 18:42:36: [2024-10-30 18:42:36] iter = 17380, loss = 7.5726
2024-10-30 18:42:40: [2024-10-30 18:42:40] iter = 17390, loss = 5.4549
2024-10-30 18:42:43: [2024-10-30 18:42:43] iter = 17400, loss = 5.9552
2024-10-30 18:42:47: [2024-10-30 18:42:47] iter = 17410, loss = 5.1237
2024-10-30 18:42:50: [2024-10-30 18:42:50] iter = 17420, loss = 7.9487
2024-10-30 18:42:52: [2024-10-30 18:42:52] iter = 17430, loss = 11.9240
2024-10-30 18:42:56: [2024-10-30 18:42:56] iter = 17440, loss = 17.9808
2024-10-30 18:43:00: [2024-10-30 18:43:00] iter = 17450, loss = 21.2870
2024-10-30 18:43:04: [2024-10-30 18:43:04] iter = 17460, loss = 10.0380
2024-10-30 18:43:08: [2024-10-30 18:43:08] iter = 17470, loss = 4.4572
2024-10-30 18:43:11: [2024-10-30 18:43:11] iter = 17480, loss = 84.4841
2024-10-30 18:43:15: [2024-10-30 18:43:15] iter = 17490, loss = 34.1819
2024-10-30 18:43:18: [2024-10-30 18:43:18] iter = 17500, loss = 4.5839
2024-10-30 18:43:21: [2024-10-30 18:43:21] iter = 17510, loss = 39.4157
2024-10-30 18:43:23: [2024-10-30 18:43:23] iter = 17520, loss = 7.6870
2024-10-30 18:43:28: [2024-10-30 18:43:28] iter = 17530, loss = 11.2879
2024-10-30 18:43:32: [2024-10-30 18:43:32] iter = 17540, loss = 7.7871
2024-10-30 18:43:36: [2024-10-30 18:43:36] iter = 17550, loss = 43.3737
2024-10-30 18:43:39: [2024-10-30 18:43:39] iter = 17560, loss = 3.3130
2024-10-30 18:43:43: [2024-10-30 18:43:43] iter = 17570, loss = 47.9866
2024-10-30 18:43:47: [2024-10-30 18:43:47] iter = 17580, loss = 68.8177
2024-10-30 18:43:50: [2024-10-30 18:43:50] iter = 17590, loss = 5.0585
2024-10-30 18:43:53: [2024-10-30 18:43:53] iter = 17600, loss = 4.1682
2024-10-30 18:43:57: [2024-10-30 18:43:57] iter = 17610, loss = 4.9944
2024-10-30 18:44:01: [2024-10-30 18:44:01] iter = 17620, loss = 53.7176
2024-10-30 18:44:05: [2024-10-30 18:44:05] iter = 17630, loss = 5.0476
2024-10-30 18:44:09: [2024-10-30 18:44:09] iter = 17640, loss = 57.0036
2024-10-30 18:44:13: [2024-10-30 18:44:13] iter = 17650, loss = 15.9434
2024-10-30 18:44:16: [2024-10-30 18:44:16] iter = 17660, loss = 71.0137
2024-10-30 18:44:18: [2024-10-30 18:44:18] iter = 17670, loss = 61.4642
2024-10-30 18:44:22: [2024-10-30 18:44:22] iter = 17680, loss = 5.4268
2024-10-30 18:44:24: [2024-10-30 18:44:24] iter = 17690, loss = 34.8907
2024-10-30 18:44:28: [2024-10-30 18:44:28] iter = 17700, loss = 28.0465
2024-10-30 18:44:32: [2024-10-30 18:44:32] iter = 17710, loss = 14.8366
2024-10-30 18:44:36: [2024-10-30 18:44:36] iter = 17720, loss = 9.5618
2024-10-30 18:44:40: [2024-10-30 18:44:40] iter = 17730, loss = 22.4765
2024-10-30 18:44:44: [2024-10-30 18:44:44] iter = 17740, loss = 6.7036
2024-10-30 18:44:48: [2024-10-30 18:44:48] iter = 17750, loss = 19.6544
2024-10-30 18:44:52: [2024-10-30 18:44:52] iter = 17760, loss = 29.2568
2024-10-30 18:44:56: [2024-10-30 18:44:56] iter = 17770, loss = 7.7302
2024-10-30 18:45:00: [2024-10-30 18:45:00] iter = 17780, loss = 52.7591
2024-10-30 18:45:04: [2024-10-30 18:45:04] iter = 17790, loss = 15.0437
2024-10-30 18:45:07: [2024-10-30 18:45:07] iter = 17800, loss = 4.9938
2024-10-30 18:45:10: [2024-10-30 18:45:10] iter = 17810, loss = 5.3917
2024-10-30 18:45:14: [2024-10-30 18:45:14] iter = 17820, loss = 17.6655
2024-10-30 18:45:17: [2024-10-30 18:45:17] iter = 17830, loss = 19.2515
2024-10-30 18:45:21: [2024-10-30 18:45:21] iter = 17840, loss = 9.4719
2024-10-30 18:45:24: [2024-10-30 18:45:24] iter = 17850, loss = 27.3353
2024-10-30 18:45:27: [2024-10-30 18:45:27] iter = 17860, loss = 16.7513
2024-10-30 18:45:30: [2024-10-30 18:45:30] iter = 17870, loss = 10.7238
2024-10-30 18:45:33: [2024-10-30 18:45:33] iter = 17880, loss = 75.3738
2024-10-30 18:45:37: [2024-10-30 18:45:37] iter = 17890, loss = 13.2596
2024-10-30 18:45:41: [2024-10-30 18:45:41] iter = 17900, loss = 23.6455
2024-10-30 18:45:44: [2024-10-30 18:45:44] iter = 17910, loss = 8.5011
2024-10-30 18:45:48: [2024-10-30 18:45:48] iter = 17920, loss = 3.8246
2024-10-30 18:45:51: [2024-10-30 18:45:51] iter = 17930, loss = 13.4054
2024-10-30 18:45:55: [2024-10-30 18:45:55] iter = 17940, loss = 34.5261
2024-10-30 18:45:59: [2024-10-30 18:45:59] iter = 17950, loss = 8.9062
2024-10-30 18:46:03: [2024-10-30 18:46:03] iter = 17960, loss = 25.1827
2024-10-30 18:46:06: [2024-10-30 18:46:06] iter = 17970, loss = 14.9072
2024-10-30 18:46:10: [2024-10-30 18:46:10] iter = 17980, loss = 30.7689
2024-10-30 18:46:15: [2024-10-30 18:46:15] iter = 17990, loss = 6.2905
2024-10-30 18:46:18: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 18:46:18: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 18:46:18: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 78342}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:48:37: Evaluate 5 random ConvNet, ACCmean = 0.3321 ACCstd = 0.0078
-------------------------
2024-10-30 18:48:37: Evaluate 5 random ConvNet, SENmean = 0.3074 SENstd = 0.0025
-------------------------
2024-10-30 18:48:37: Evaluate 5 random ConvNet, SPEmean = 0.9060 SPEstd = 0.0007
-------------------------
2024-10-30 18:48:37: Evaluate 5 random ConvNet, F!mean = 0.2606 F!std = 0.0041
-------------------------
2024-10-30 18:48:37: Evaluate 5 random ConvNet, mean = 0.3321 std = 0.0078
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 18:48:37: [2024-10-30 18:48:37] iter = 18000, loss = 4.1816
2024-10-30 18:48:41: [2024-10-30 18:48:41] iter = 18010, loss = 6.0739
2024-10-30 18:48:44: [2024-10-30 18:48:44] iter = 18020, loss = 9.8665
2024-10-30 18:48:48: [2024-10-30 18:48:48] iter = 18030, loss = 19.4541
2024-10-30 18:48:52: [2024-10-30 18:48:52] iter = 18040, loss = 10.3587
2024-10-30 18:48:55: [2024-10-30 18:48:55] iter = 18050, loss = 4.4988
2024-10-30 18:48:59: [2024-10-30 18:48:59] iter = 18060, loss = 31.4322
2024-10-30 18:49:03: [2024-10-30 18:49:03] iter = 18070, loss = 7.0711
2024-10-30 18:49:06: [2024-10-30 18:49:06] iter = 18080, loss = 3.8053
2024-10-30 18:49:10: [2024-10-30 18:49:10] iter = 18090, loss = 3.0104
2024-10-30 18:49:14: [2024-10-30 18:49:14] iter = 18100, loss = 6.9789
2024-10-30 18:49:17: [2024-10-30 18:49:17] iter = 18110, loss = 37.1560
2024-10-30 18:49:21: [2024-10-30 18:49:20] iter = 18120, loss = 30.0694
2024-10-30 18:49:24: [2024-10-30 18:49:24] iter = 18130, loss = 5.5995
2024-10-30 18:49:28: [2024-10-30 18:49:28] iter = 18140, loss = 62.3421
2024-10-30 18:49:32: [2024-10-30 18:49:32] iter = 18150, loss = 8.4356
2024-10-30 18:49:35: [2024-10-30 18:49:35] iter = 18160, loss = 10.1654
2024-10-30 18:49:37: [2024-10-30 18:49:37] iter = 18170, loss = 19.8642
2024-10-30 18:49:42: [2024-10-30 18:49:42] iter = 18180, loss = 22.2352
2024-10-30 18:49:46: [2024-10-30 18:49:46] iter = 18190, loss = 72.0447
2024-10-30 18:49:51: [2024-10-30 18:49:51] iter = 18200, loss = 30.7906
2024-10-30 18:49:55: [2024-10-30 18:49:55] iter = 18210, loss = 5.9777
2024-10-30 18:49:58: [2024-10-30 18:49:58] iter = 18220, loss = 17.6053
2024-10-30 18:50:01: [2024-10-30 18:50:01] iter = 18230, loss = 11.2561
2024-10-30 18:50:04: [2024-10-30 18:50:04] iter = 18240, loss = 8.1251
2024-10-30 18:50:09: [2024-10-30 18:50:09] iter = 18250, loss = 9.8528
2024-10-30 18:50:13: [2024-10-30 18:50:13] iter = 18260, loss = 26.7140
2024-10-30 18:50:17: [2024-10-30 18:50:17] iter = 18270, loss = 8.4435
2024-10-30 18:50:21: [2024-10-30 18:50:21] iter = 18280, loss = 39.3811
2024-10-30 18:50:25: [2024-10-30 18:50:25] iter = 18290, loss = 13.9833
2024-10-30 18:50:28: [2024-10-30 18:50:28] iter = 18300, loss = 8.3503
2024-10-30 18:50:32: [2024-10-30 18:50:32] iter = 18310, loss = 61.5041
2024-10-30 18:50:36: [2024-10-30 18:50:36] iter = 18320, loss = 5.8485
2024-10-30 18:50:39: [2024-10-30 18:50:39] iter = 18330, loss = 10.6274
2024-10-30 18:50:43: [2024-10-30 18:50:43] iter = 18340, loss = 17.8298
2024-10-30 18:50:47: [2024-10-30 18:50:46] iter = 18350, loss = 4.2086
2024-10-30 18:50:50: [2024-10-30 18:50:50] iter = 18360, loss = 7.9247
2024-10-30 18:50:54: [2024-10-30 18:50:54] iter = 18370, loss = 14.1422
2024-10-30 18:50:58: [2024-10-30 18:50:58] iter = 18380, loss = 15.7558
2024-10-30 18:51:02: [2024-10-30 18:51:02] iter = 18390, loss = 7.8660
2024-10-30 18:51:06: [2024-10-30 18:51:06] iter = 18400, loss = 19.2869
2024-10-30 18:51:09: [2024-10-30 18:51:09] iter = 18410, loss = 55.9720
2024-10-30 18:51:12: [2024-10-30 18:51:12] iter = 18420, loss = 5.0432
2024-10-30 18:51:16: [2024-10-30 18:51:16] iter = 18430, loss = 8.0192
2024-10-30 18:51:20: [2024-10-30 18:51:20] iter = 18440, loss = 7.1742
2024-10-30 18:51:23: [2024-10-30 18:51:23] iter = 18450, loss = 25.7728
2024-10-30 18:51:28: [2024-10-30 18:51:28] iter = 18460, loss = 9.9731
2024-10-30 18:51:30: [2024-10-30 18:51:30] iter = 18470, loss = 24.9843
2024-10-30 18:51:34: [2024-10-30 18:51:34] iter = 18480, loss = 43.3170
2024-10-30 18:51:38: [2024-10-30 18:51:38] iter = 18490, loss = 34.2731
2024-10-30 18:51:43: [2024-10-30 18:51:43] iter = 18500, loss = 4.5525
2024-10-30 18:51:48: [2024-10-30 18:51:48] iter = 18510, loss = 36.5078
2024-10-30 18:51:52: [2024-10-30 18:51:52] iter = 18520, loss = 5.8327
2024-10-30 18:51:56: [2024-10-30 18:51:56] iter = 18530, loss = 5.4349
2024-10-30 18:51:59: [2024-10-30 18:51:59] iter = 18540, loss = 37.7189
2024-10-30 18:52:03: [2024-10-30 18:52:03] iter = 18550, loss = 32.6426
2024-10-30 18:52:07: [2024-10-30 18:52:07] iter = 18560, loss = 7.3591
2024-10-30 18:52:10: [2024-10-30 18:52:10] iter = 18570, loss = 24.9031
2024-10-30 18:52:14: [2024-10-30 18:52:14] iter = 18580, loss = 22.5210
2024-10-30 18:52:18: [2024-10-30 18:52:18] iter = 18590, loss = 21.8911
2024-10-30 18:52:22: [2024-10-30 18:52:22] iter = 18600, loss = 12.6763
2024-10-30 18:52:26: [2024-10-30 18:52:26] iter = 18610, loss = 36.7592
2024-10-30 18:52:30: [2024-10-30 18:52:30] iter = 18620, loss = 17.6332
2024-10-30 18:52:33: [2024-10-30 18:52:33] iter = 18630, loss = 40.9372
2024-10-30 18:52:37: [2024-10-30 18:52:37] iter = 18640, loss = 6.4032
2024-10-30 18:52:40: [2024-10-30 18:52:40] iter = 18650, loss = 7.0584
2024-10-30 18:52:43: [2024-10-30 18:52:43] iter = 18660, loss = 61.3217
2024-10-30 18:52:48: [2024-10-30 18:52:48] iter = 18670, loss = 4.7576
2024-10-30 18:52:51: [2024-10-30 18:52:51] iter = 18680, loss = 6.3903
2024-10-30 18:52:55: [2024-10-30 18:52:55] iter = 18690, loss = 5.6833
2024-10-30 18:52:58: [2024-10-30 18:52:58] iter = 18700, loss = 22.1173
2024-10-30 18:53:02: [2024-10-30 18:53:02] iter = 18710, loss = 10.9106
2024-10-30 18:53:05: [2024-10-30 18:53:05] iter = 18720, loss = 7.8029
2024-10-30 18:53:09: [2024-10-30 18:53:09] iter = 18730, loss = 5.0002
2024-10-30 18:53:13: [2024-10-30 18:53:13] iter = 18740, loss = 26.0564
2024-10-30 18:53:18: [2024-10-30 18:53:18] iter = 18750, loss = 13.5254
2024-10-30 18:53:23: [2024-10-30 18:53:23] iter = 18760, loss = 17.2285
2024-10-30 18:53:27: [2024-10-30 18:53:27] iter = 18770, loss = 7.5815
2024-10-30 18:53:30: [2024-10-30 18:53:30] iter = 18780, loss = 29.0567
2024-10-30 18:53:34: [2024-10-30 18:53:34] iter = 18790, loss = 5.2689
2024-10-30 18:53:37: [2024-10-30 18:53:37] iter = 18800, loss = 16.4762
2024-10-30 18:53:40: [2024-10-30 18:53:40] iter = 18810, loss = 15.2222
2024-10-30 18:53:43: [2024-10-30 18:53:43] iter = 18820, loss = 3.7016
2024-10-30 18:53:47: [2024-10-30 18:53:47] iter = 18830, loss = 16.2831
2024-10-30 18:53:51: [2024-10-30 18:53:51] iter = 18840, loss = 16.7184
2024-10-30 18:53:55: [2024-10-30 18:53:55] iter = 18850, loss = 9.2473
2024-10-30 18:53:58: [2024-10-30 18:53:58] iter = 18860, loss = 28.0904
2024-10-30 18:54:02: [2024-10-30 18:54:02] iter = 18870, loss = 5.9902
2024-10-30 18:54:06: [2024-10-30 18:54:06] iter = 18880, loss = 46.8818
2024-10-30 18:54:10: [2024-10-30 18:54:10] iter = 18890, loss = 5.7002
2024-10-30 18:54:12: [2024-10-30 18:54:12] iter = 18900, loss = 3.9079
2024-10-30 18:54:16: [2024-10-30 18:54:16] iter = 18910, loss = 76.8516
2024-10-30 18:54:19: [2024-10-30 18:54:19] iter = 18920, loss = 13.7856
2024-10-30 18:54:22: [2024-10-30 18:54:22] iter = 18930, loss = 16.2059
2024-10-30 18:54:24: [2024-10-30 18:54:24] iter = 18940, loss = 15.5254
2024-10-30 18:54:28: [2024-10-30 18:54:28] iter = 18950, loss = 94.5311
2024-10-30 18:54:32: [2024-10-30 18:54:32] iter = 18960, loss = 10.0780
2024-10-30 18:54:35: [2024-10-30 18:54:35] iter = 18970, loss = 19.4882
2024-10-30 18:54:40: [2024-10-30 18:54:40] iter = 18980, loss = 34.1879
2024-10-30 18:54:44: [2024-10-30 18:54:44] iter = 18990, loss = 4.5725
2024-10-30 18:54:48: [2024-10-30 18:54:48] iter = 19000, loss = 13.9016
2024-10-30 18:54:52: [2024-10-30 18:54:52] iter = 19010, loss = 3.9845
2024-10-30 18:54:56: [2024-10-30 18:54:56] iter = 19020, loss = 32.1131
2024-10-30 18:55:00: [2024-10-30 18:55:00] iter = 19030, loss = 11.9062
2024-10-30 18:55:04: [2024-10-30 18:55:04] iter = 19040, loss = 5.1302
2024-10-30 18:55:06: [2024-10-30 18:55:06] iter = 19050, loss = 35.7587
2024-10-30 18:55:09: [2024-10-30 18:55:09] iter = 19060, loss = 33.6027
2024-10-30 18:55:12: [2024-10-30 18:55:12] iter = 19070, loss = 6.5494
2024-10-30 18:55:16: [2024-10-30 18:55:16] iter = 19080, loss = 18.4766
2024-10-30 18:55:19: [2024-10-30 18:55:19] iter = 19090, loss = 9.5713
2024-10-30 18:55:23: [2024-10-30 18:55:23] iter = 19100, loss = 9.0237
2024-10-30 18:55:27: [2024-10-30 18:55:27] iter = 19110, loss = 27.0827
2024-10-30 18:55:30: [2024-10-30 18:55:30] iter = 19120, loss = 35.4885
2024-10-30 18:55:35: [2024-10-30 18:55:35] iter = 19130, loss = 17.4762
2024-10-30 18:55:38: [2024-10-30 18:55:38] iter = 19140, loss = 44.9952
2024-10-30 18:55:43: [2024-10-30 18:55:43] iter = 19150, loss = 5.4985
2024-10-30 18:55:47: [2024-10-30 18:55:47] iter = 19160, loss = 30.9065
2024-10-30 18:55:51: [2024-10-30 18:55:51] iter = 19170, loss = 6.2352
2024-10-30 18:55:55: [2024-10-30 18:55:55] iter = 19180, loss = 6.2580
2024-10-30 18:55:58: [2024-10-30 18:55:58] iter = 19190, loss = 89.8943
2024-10-30 18:56:01: [2024-10-30 18:56:01] iter = 19200, loss = 55.0874
2024-10-30 18:56:05: [2024-10-30 18:56:05] iter = 19210, loss = 43.5116
2024-10-30 18:56:10: [2024-10-30 18:56:10] iter = 19220, loss = 16.8770
2024-10-30 18:56:13: [2024-10-30 18:56:13] iter = 19230, loss = 18.1000
2024-10-30 18:56:17: [2024-10-30 18:56:17] iter = 19240, loss = 21.9785
2024-10-30 18:56:22: [2024-10-30 18:56:22] iter = 19250, loss = 5.0086
2024-10-30 18:56:25: [2024-10-30 18:56:25] iter = 19260, loss = 42.4904
2024-10-30 18:56:29: [2024-10-30 18:56:29] iter = 19270, loss = 36.6193
2024-10-30 18:56:33: [2024-10-30 18:56:33] iter = 19280, loss = 18.7752
2024-10-30 18:56:38: [2024-10-30 18:56:38] iter = 19290, loss = 4.0737
2024-10-30 18:56:42: [2024-10-30 18:56:42] iter = 19300, loss = 39.6092
2024-10-30 18:56:45: [2024-10-30 18:56:45] iter = 19310, loss = 10.4763
2024-10-30 18:56:50: [2024-10-30 18:56:50] iter = 19320, loss = 9.0630
2024-10-30 18:56:53: [2024-10-30 18:56:53] iter = 19330, loss = 3.8453
2024-10-30 18:56:57: [2024-10-30 18:56:57] iter = 19340, loss = 48.9111
2024-10-30 18:57:00: [2024-10-30 18:57:00] iter = 19350, loss = 21.8956
2024-10-30 18:57:03: [2024-10-30 18:57:03] iter = 19360, loss = 23.3487
2024-10-30 18:57:07: [2024-10-30 18:57:07] iter = 19370, loss = 3.2555
2024-10-30 18:57:10: [2024-10-30 18:57:10] iter = 19380, loss = 5.9082
2024-10-30 18:57:15: [2024-10-30 18:57:15] iter = 19390, loss = 10.7164
2024-10-30 18:57:20: [2024-10-30 18:57:20] iter = 19400, loss = 6.3546
2024-10-30 18:57:24: [2024-10-30 18:57:24] iter = 19410, loss = 4.8867
2024-10-30 18:57:28: [2024-10-30 18:57:28] iter = 19420, loss = 38.8012
2024-10-30 18:57:32: [2024-10-30 18:57:32] iter = 19430, loss = 26.0939
2024-10-30 18:57:36: [2024-10-30 18:57:36] iter = 19440, loss = 6.3319
2024-10-30 18:57:40: [2024-10-30 18:57:40] iter = 19450, loss = 5.2513
2024-10-30 18:57:44: [2024-10-30 18:57:44] iter = 19460, loss = 6.4413
2024-10-30 18:57:48: [2024-10-30 18:57:48] iter = 19470, loss = 7.0357
2024-10-30 18:57:52: [2024-10-30 18:57:52] iter = 19480, loss = 6.4318
2024-10-30 18:57:56: [2024-10-30 18:57:56] iter = 19490, loss = 10.9005
2024-10-30 18:58:00: [2024-10-30 18:58:00] iter = 19500, loss = 43.8422
2024-10-30 18:58:03: [2024-10-30 18:58:03] iter = 19510, loss = 20.7941
2024-10-30 18:58:08: [2024-10-30 18:58:08] iter = 19520, loss = 5.7748
2024-10-30 18:58:10: [2024-10-30 18:58:10] iter = 19530, loss = 12.4974
2024-10-30 18:58:13: [2024-10-30 18:58:13] iter = 19540, loss = 22.8839
2024-10-30 18:58:17: [2024-10-30 18:58:17] iter = 19550, loss = 3.1584
2024-10-30 18:58:20: [2024-10-30 18:58:20] iter = 19560, loss = 62.4661
2024-10-30 18:58:25: [2024-10-30 18:58:25] iter = 19570, loss = 49.2625
2024-10-30 18:58:29: [2024-10-30 18:58:29] iter = 19580, loss = 12.4746
2024-10-30 18:58:33: [2024-10-30 18:58:33] iter = 19590, loss = 4.3329
2024-10-30 18:58:36: [2024-10-30 18:58:36] iter = 19600, loss = 55.7362
2024-10-30 18:58:39: [2024-10-30 18:58:39] iter = 19610, loss = 28.8661
2024-10-30 18:58:44: [2024-10-30 18:58:44] iter = 19620, loss = 52.2320
2024-10-30 18:58:47: [2024-10-30 18:58:47] iter = 19630, loss = 63.5631
2024-10-30 18:58:52: [2024-10-30 18:58:52] iter = 19640, loss = 7.3005
2024-10-30 18:58:53: [2024-10-30 18:58:53] iter = 19650, loss = 26.8745
2024-10-30 18:58:57: [2024-10-30 18:58:57] iter = 19660, loss = 5.1491
2024-10-30 18:59:01: [2024-10-30 18:59:01] iter = 19670, loss = 5.2200
2024-10-30 18:59:05: [2024-10-30 18:59:05] iter = 19680, loss = 4.0256
2024-10-30 18:59:09: [2024-10-30 18:59:09] iter = 19690, loss = 6.5838
2024-10-30 18:59:13: [2024-10-30 18:59:13] iter = 19700, loss = 9.6104
2024-10-30 18:59:17: [2024-10-30 18:59:17] iter = 19710, loss = 35.1755
2024-10-30 18:59:22: [2024-10-30 18:59:22] iter = 19720, loss = 14.1481
2024-10-30 18:59:26: [2024-10-30 18:59:26] iter = 19730, loss = 7.4152
2024-10-30 18:59:29: [2024-10-30 18:59:29] iter = 19740, loss = 78.2325
2024-10-30 18:59:33: [2024-10-30 18:59:33] iter = 19750, loss = 34.6441
2024-10-30 18:59:37: [2024-10-30 18:59:37] iter = 19760, loss = 5.4032
2024-10-30 18:59:41: [2024-10-30 18:59:41] iter = 19770, loss = 5.2211
2024-10-30 18:59:45: [2024-10-30 18:59:45] iter = 19780, loss = 9.4786
2024-10-30 18:59:49: [2024-10-30 18:59:49] iter = 19790, loss = 19.7353
2024-10-30 18:59:52: [2024-10-30 18:59:52] iter = 19800, loss = 74.2691
2024-10-30 18:59:57: [2024-10-30 18:59:57] iter = 19810, loss = 21.6547
2024-10-30 19:00:02: [2024-10-30 19:00:02] iter = 19820, loss = 36.6396
2024-10-30 19:00:06: [2024-10-30 19:00:05] iter = 19830, loss = 18.9658
2024-10-30 19:00:10: [2024-10-30 19:00:10] iter = 19840, loss = 14.7795
2024-10-30 19:00:14: [2024-10-30 19:00:14] iter = 19850, loss = 10.1465
2024-10-30 19:00:18: [2024-10-30 19:00:18] iter = 19860, loss = 6.7960
2024-10-30 19:00:22: [2024-10-30 19:00:22] iter = 19870, loss = 66.1234
2024-10-30 19:00:24: [2024-10-30 19:00:24] iter = 19880, loss = 13.4756
2024-10-30 19:00:28: [2024-10-30 19:00:28] iter = 19890, loss = 31.0041
2024-10-30 19:00:31: [2024-10-30 19:00:31] iter = 19900, loss = 56.6016
2024-10-30 19:00:35: [2024-10-30 19:00:35] iter = 19910, loss = 11.1601
2024-10-30 19:00:40: [2024-10-30 19:00:40] iter = 19920, loss = 5.2168
2024-10-30 19:00:44: [2024-10-30 19:00:44] iter = 19930, loss = 27.5410
2024-10-30 19:00:48: [2024-10-30 19:00:48] iter = 19940, loss = 5.8498
2024-10-30 19:00:52: [2024-10-30 19:00:52] iter = 19950, loss = 12.5865
2024-10-30 19:00:55: [2024-10-30 19:00:55] iter = 19960, loss = 5.6981
2024-10-30 19:00:58: [2024-10-30 19:00:58] iter = 19970, loss = 5.3786
2024-10-30 19:01:02: [2024-10-30 19:01:02] iter = 19980, loss = 5.6684
2024-10-30 19:01:06: [2024-10-30 19:01:06] iter = 19990, loss = 51.3257
2024-10-30 19:01:10: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 19:01:10: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:01:10: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 70023}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:03:31: Evaluate 5 random ConvNet, ACCmean = 0.3840 ACCstd = 0.0041
-------------------------
2024-10-30 19:03:31: Evaluate 5 random ConvNet, SENmean = 0.3245 SENstd = 0.0016
-------------------------
2024-10-30 19:03:31: Evaluate 5 random ConvNet, SPEmean = 0.9109 SPEstd = 0.0004
-------------------------
2024-10-30 19:03:31: Evaluate 5 random ConvNet, F!mean = 0.2921 F!std = 0.0020
-------------------------
2024-10-30 19:03:31: Evaluate 5 random ConvNet, mean = 0.3840 std = 0.0041
-------------------------
2024-10-30 19:03:31: [2024-10-30 19:03:31] iter = 20000, loss = 7.7448
2024-10-30 19:03:31: 
================== Exp 2 ==================
 
2024-10-30 19:03:31: Hyper-parameters: 
{'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ffaf9964b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_TissueMNIST (INFO)>}
2024-10-30 19:03:31: Evaluation model pool: ['ConvNet']
2024-10-30 19:03:53: class c = 0: 53075 real images
2024-10-30 19:03:53: class c = 1: 7814 real images
2024-10-30 19:03:53: class c = 2: 5866 real images
2024-10-30 19:03:53: class c = 3: 15406 real images
2024-10-30 19:03:53: class c = 4: 11789 real images
2024-10-30 19:03:53: class c = 5: 7705 real images
2024-10-30 19:03:53: class c = 6: 39203 real images
2024-10-30 19:03:53: class c = 7: 24608 real images
2024-10-30 19:03:53: real images channel 0, mean = 0.1020, std = 0.1000
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 19:03:53: initialize synthetic data from random real images
2024-10-30 19:03:53: [2024-10-30 19:03:53] training begins
2024-10-30 19:03:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 19:03:53: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:03:53: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 11848}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:06:22: Evaluate 5 random ConvNet, ACCmean = 0.2617 ACCstd = 0.0063
-------------------------
2024-10-30 19:06:22: Evaluate 5 random ConvNet, SENmean = 0.2378 SENstd = 0.0021
-------------------------
2024-10-30 19:06:22: Evaluate 5 random ConvNet, SPEmean = 0.8923 SPEstd = 0.0004
-------------------------
2024-10-30 19:06:22: Evaluate 5 random ConvNet, F!mean = 0.2212 F!std = 0.0028
-------------------------
2024-10-30 19:06:22: Evaluate 5 random ConvNet, mean = 0.2617 std = 0.0063
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:06:22: [2024-10-30 19:06:22] iter = 00000, loss = 20.1602
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:06:24: [2024-10-30 19:06:24] iter = 00010, loss = 81.9457
2024-10-30 19:06:28: [2024-10-30 19:06:28] iter = 00020, loss = 16.1902
2024-10-30 19:06:32: [2024-10-30 19:06:32] iter = 00030, loss = 33.0406
2024-10-30 19:06:36: [2024-10-30 19:06:36] iter = 00040, loss = 47.2670
2024-10-30 19:06:39: [2024-10-30 19:06:39] iter = 00050, loss = 19.4366
2024-10-30 19:06:43: [2024-10-30 19:06:43] iter = 00060, loss = 8.0409
2024-10-30 19:06:47: [2024-10-30 19:06:47] iter = 00070, loss = 4.5876
2024-10-30 19:06:52: [2024-10-30 19:06:52] iter = 00080, loss = 6.4095
2024-10-30 19:06:56: [2024-10-30 19:06:56] iter = 00090, loss = 40.6892
2024-10-30 19:07:00: [2024-10-30 19:07:00] iter = 00100, loss = 13.1621
2024-10-30 19:07:04: [2024-10-30 19:07:04] iter = 00110, loss = 8.6545
2024-10-30 19:07:08: [2024-10-30 19:07:08] iter = 00120, loss = 17.0758
2024-10-30 19:07:12: [2024-10-30 19:07:12] iter = 00130, loss = 6.5567
2024-10-30 19:07:15: [2024-10-30 19:07:15] iter = 00140, loss = 35.0409
2024-10-30 19:07:19: [2024-10-30 19:07:19] iter = 00150, loss = 10.3120
2024-10-30 19:07:23: [2024-10-30 19:07:23] iter = 00160, loss = 25.2031
2024-10-30 19:07:27: [2024-10-30 19:07:27] iter = 00170, loss = 14.0036
2024-10-30 19:07:29: [2024-10-30 19:07:29] iter = 00180, loss = 16.4605
2024-10-30 19:07:33: [2024-10-30 19:07:33] iter = 00190, loss = 39.3506
2024-10-30 19:07:38: [2024-10-30 19:07:38] iter = 00200, loss = 83.7414
2024-10-30 19:07:41: [2024-10-30 19:07:41] iter = 00210, loss = 45.8596
2024-10-30 19:07:46: [2024-10-30 19:07:46] iter = 00220, loss = 48.7949
2024-10-30 19:07:49: [2024-10-30 19:07:49] iter = 00230, loss = 18.7469
2024-10-30 19:07:52: [2024-10-30 19:07:52] iter = 00240, loss = 5.2915
2024-10-30 19:07:57: [2024-10-30 19:07:57] iter = 00250, loss = 44.7820
2024-10-30 19:07:59: [2024-10-30 19:07:59] iter = 00260, loss = 32.2823
2024-10-30 19:08:02: [2024-10-30 19:08:02] iter = 00270, loss = 6.7163
2024-10-30 19:08:06: [2024-10-30 19:08:06] iter = 00280, loss = 16.7685
2024-10-30 19:08:10: [2024-10-30 19:08:10] iter = 00290, loss = 36.3806
2024-10-30 19:08:15: [2024-10-30 19:08:15] iter = 00300, loss = 107.0561
2024-10-30 19:08:19: [2024-10-30 19:08:19] iter = 00310, loss = 5.6118
2024-10-30 19:08:22: [2024-10-30 19:08:22] iter = 00320, loss = 47.8786
2024-10-30 19:08:26: [2024-10-30 19:08:26] iter = 00330, loss = 10.5380
2024-10-30 19:08:29: [2024-10-30 19:08:29] iter = 00340, loss = 4.7363
2024-10-30 19:08:32: [2024-10-30 19:08:32] iter = 00350, loss = 33.4147
2024-10-30 19:08:36: [2024-10-30 19:08:36] iter = 00360, loss = 37.0897
2024-10-30 19:08:39: [2024-10-30 19:08:39] iter = 00370, loss = 4.9680
2024-10-30 19:08:42: [2024-10-30 19:08:42] iter = 00380, loss = 17.3084
2024-10-30 19:08:46: [2024-10-30 19:08:46] iter = 00390, loss = 26.7184
2024-10-30 19:08:50: [2024-10-30 19:08:50] iter = 00400, loss = 4.5443
2024-10-30 19:08:54: [2024-10-30 19:08:54] iter = 00410, loss = 14.6358
2024-10-30 19:08:58: [2024-10-30 19:08:58] iter = 00420, loss = 6.5642
2024-10-30 19:09:00: [2024-10-30 19:09:00] iter = 00430, loss = 50.8901
2024-10-30 19:09:03: [2024-10-30 19:09:03] iter = 00440, loss = 18.0084
2024-10-30 19:09:07: [2024-10-30 19:09:07] iter = 00450, loss = 39.0697
2024-10-30 19:09:10: [2024-10-30 19:09:10] iter = 00460, loss = 5.3095
2024-10-30 19:09:15: [2024-10-30 19:09:15] iter = 00470, loss = 55.7388
2024-10-30 19:09:19: [2024-10-30 19:09:19] iter = 00480, loss = 68.0037
2024-10-30 19:09:23: [2024-10-30 19:09:23] iter = 00490, loss = 35.3208
2024-10-30 19:09:26: [2024-10-30 19:09:26] iter = 00500, loss = 8.9840
2024-10-30 19:09:30: [2024-10-30 19:09:30] iter = 00510, loss = 70.2405
2024-10-30 19:09:35: [2024-10-30 19:09:35] iter = 00520, loss = 10.5163
2024-10-30 19:09:37: [2024-10-30 19:09:37] iter = 00530, loss = 43.5290
2024-10-30 19:09:41: [2024-10-30 19:09:41] iter = 00540, loss = 4.5177
2024-10-30 19:09:45: [2024-10-30 19:09:45] iter = 00550, loss = 6.8354
2024-10-30 19:09:48: [2024-10-30 19:09:48] iter = 00560, loss = 9.4954
2024-10-30 19:09:52: [2024-10-30 19:09:52] iter = 00570, loss = 5.3487
2024-10-30 19:09:55: [2024-10-30 19:09:55] iter = 00580, loss = 13.4450
2024-10-30 19:09:59: [2024-10-30 19:09:59] iter = 00590, loss = 3.9748
2024-10-30 19:10:03: [2024-10-30 19:10:03] iter = 00600, loss = 14.9964
2024-10-30 19:10:07: [2024-10-30 19:10:07] iter = 00610, loss = 24.6635
2024-10-30 19:10:11: [2024-10-30 19:10:11] iter = 00620, loss = 9.2806
2024-10-30 19:10:15: [2024-10-30 19:10:15] iter = 00630, loss = 4.8009
2024-10-30 19:10:19: [2024-10-30 19:10:19] iter = 00640, loss = 5.4336
2024-10-30 19:10:22: [2024-10-30 19:10:22] iter = 00650, loss = 4.1615
2024-10-30 19:10:25: [2024-10-30 19:10:25] iter = 00660, loss = 10.9560
2024-10-30 19:10:30: [2024-10-30 19:10:30] iter = 00670, loss = 4.9239
2024-10-30 19:10:34: [2024-10-30 19:10:34] iter = 00680, loss = 9.3637
2024-10-30 19:10:38: [2024-10-30 19:10:38] iter = 00690, loss = 13.5314
2024-10-30 19:10:42: [2024-10-30 19:10:42] iter = 00700, loss = 9.1782
2024-10-30 19:10:45: [2024-10-30 19:10:45] iter = 00710, loss = 20.5272
2024-10-30 19:10:49: [2024-10-30 19:10:49] iter = 00720, loss = 12.6415
2024-10-30 19:10:53: [2024-10-30 19:10:53] iter = 00730, loss = 10.0117
2024-10-30 19:10:57: [2024-10-30 19:10:57] iter = 00740, loss = 36.8666
2024-10-30 19:11:01: [2024-10-30 19:11:01] iter = 00750, loss = 14.4830
2024-10-30 19:11:04: [2024-10-30 19:11:04] iter = 00760, loss = 6.1522
2024-10-30 19:11:07: [2024-10-30 19:11:07] iter = 00770, loss = 5.1456
2024-10-30 19:11:12: [2024-10-30 19:11:12] iter = 00780, loss = 53.3988
2024-10-30 19:11:15: [2024-10-30 19:11:15] iter = 00790, loss = 10.2810
2024-10-30 19:11:19: [2024-10-30 19:11:19] iter = 00800, loss = 21.6746
2024-10-30 19:11:23: [2024-10-30 19:11:23] iter = 00810, loss = 11.3058
2024-10-30 19:11:27: [2024-10-30 19:11:27] iter = 00820, loss = 17.0990
2024-10-30 19:11:31: [2024-10-30 19:11:31] iter = 00830, loss = 11.2799
2024-10-30 19:11:35: [2024-10-30 19:11:35] iter = 00840, loss = 5.0806
2024-10-30 19:11:37: [2024-10-30 19:11:37] iter = 00850, loss = 2.9779
2024-10-30 19:11:41: [2024-10-30 19:11:41] iter = 00860, loss = 79.9266
2024-10-30 19:11:44: [2024-10-30 19:11:44] iter = 00870, loss = 9.4298
2024-10-30 19:11:48: [2024-10-30 19:11:48] iter = 00880, loss = 3.1196
2024-10-30 19:11:51: [2024-10-30 19:11:51] iter = 00890, loss = 9.7389
2024-10-30 19:11:54: [2024-10-30 19:11:54] iter = 00900, loss = 11.2907
2024-10-30 19:11:57: [2024-10-30 19:11:57] iter = 00910, loss = 21.7207
2024-10-30 19:12:00: [2024-10-30 19:12:00] iter = 00920, loss = 15.7837
2024-10-30 19:12:03: [2024-10-30 19:12:03] iter = 00930, loss = 12.9230
2024-10-30 19:12:07: [2024-10-30 19:12:07] iter = 00940, loss = 45.3966
2024-10-30 19:12:11: [2024-10-30 19:12:11] iter = 00950, loss = 65.3759
2024-10-30 19:12:15: [2024-10-30 19:12:15] iter = 00960, loss = 20.0027
2024-10-30 19:12:18: [2024-10-30 19:12:18] iter = 00970, loss = 9.4462
2024-10-30 19:12:23: [2024-10-30 19:12:23] iter = 00980, loss = 16.3611
2024-10-30 19:12:27: [2024-10-30 19:12:27] iter = 00990, loss = 12.7788
2024-10-30 19:12:31: [2024-10-30 19:12:31] iter = 01000, loss = 45.9454
2024-10-30 19:12:35: [2024-10-30 19:12:35] iter = 01010, loss = 13.3916
2024-10-30 19:12:39: [2024-10-30 19:12:39] iter = 01020, loss = 50.9420
2024-10-30 19:12:43: [2024-10-30 19:12:43] iter = 01030, loss = 14.8652
2024-10-30 19:12:46: [2024-10-30 19:12:46] iter = 01040, loss = 13.1846
2024-10-30 19:12:51: [2024-10-30 19:12:51] iter = 01050, loss = 19.7282
2024-10-30 19:12:55: [2024-10-30 19:12:55] iter = 01060, loss = 30.3223
2024-10-30 19:12:59: [2024-10-30 19:12:59] iter = 01070, loss = 4.0090
2024-10-30 19:13:03: [2024-10-30 19:13:03] iter = 01080, loss = 3.2574
2024-10-30 19:13:08: [2024-10-30 19:13:08] iter = 01090, loss = 4.4121
2024-10-30 19:13:12: [2024-10-30 19:13:12] iter = 01100, loss = 19.4569
2024-10-30 19:13:17: [2024-10-30 19:13:17] iter = 01110, loss = 25.3595
2024-10-30 19:13:22: [2024-10-30 19:13:22] iter = 01120, loss = 16.6005
2024-10-30 19:13:25: [2024-10-30 19:13:25] iter = 01130, loss = 34.1965
2024-10-30 19:13:29: [2024-10-30 19:13:29] iter = 01140, loss = 51.7058
2024-10-30 19:13:31: [2024-10-30 19:13:31] iter = 01150, loss = 4.1477
2024-10-30 19:13:36: [2024-10-30 19:13:36] iter = 01160, loss = 4.5449
2024-10-30 19:13:39: [2024-10-30 19:13:39] iter = 01170, loss = 5.0210
2024-10-30 19:13:43: [2024-10-30 19:13:43] iter = 01180, loss = 33.6506
2024-10-30 19:13:47: [2024-10-30 19:13:47] iter = 01190, loss = 8.1117
2024-10-30 19:13:52: [2024-10-30 19:13:52] iter = 01200, loss = 50.4533
2024-10-30 19:13:56: [2024-10-30 19:13:56] iter = 01210, loss = 3.4318
2024-10-30 19:13:59: [2024-10-30 19:13:59] iter = 01220, loss = 3.8396
2024-10-30 19:14:02: [2024-10-30 19:14:01] iter = 01230, loss = 11.2669
2024-10-30 19:14:04: [2024-10-30 19:14:04] iter = 01240, loss = 49.1058
2024-10-30 19:14:07: [2024-10-30 19:14:07] iter = 01250, loss = 18.0063
2024-10-30 19:14:11: [2024-10-30 19:14:11] iter = 01260, loss = 7.5606
2024-10-30 19:14:15: [2024-10-30 19:14:15] iter = 01270, loss = 41.1458
2024-10-30 19:14:17: [2024-10-30 19:14:17] iter = 01280, loss = 16.0868
2024-10-30 19:14:21: [2024-10-30 19:14:21] iter = 01290, loss = 20.5433
2024-10-30 19:14:23: [2024-10-30 19:14:23] iter = 01300, loss = 3.7682
2024-10-30 19:14:27: [2024-10-30 19:14:27] iter = 01310, loss = 5.7888
2024-10-30 19:14:31: [2024-10-30 19:14:31] iter = 01320, loss = 11.4599
2024-10-30 19:14:33: [2024-10-30 19:14:33] iter = 01330, loss = 33.1854
2024-10-30 19:14:37: [2024-10-30 19:14:37] iter = 01340, loss = 18.9005
2024-10-30 19:14:41: [2024-10-30 19:14:41] iter = 01350, loss = 22.7643
2024-10-30 19:14:45: [2024-10-30 19:14:45] iter = 01360, loss = 14.6806
2024-10-30 19:14:49: [2024-10-30 19:14:49] iter = 01370, loss = 3.9823
2024-10-30 19:14:52: [2024-10-30 19:14:52] iter = 01380, loss = 17.6238
2024-10-30 19:14:56: [2024-10-30 19:14:56] iter = 01390, loss = 23.5551
2024-10-30 19:15:00: [2024-10-30 19:15:00] iter = 01400, loss = 74.8344
2024-10-30 19:15:04: [2024-10-30 19:15:04] iter = 01410, loss = 19.2856
2024-10-30 19:15:07: [2024-10-30 19:15:07] iter = 01420, loss = 5.6351
2024-10-30 19:15:11: [2024-10-30 19:15:11] iter = 01430, loss = 3.6183
2024-10-30 19:15:16: [2024-10-30 19:15:16] iter = 01440, loss = 5.6676
2024-10-30 19:15:19: [2024-10-30 19:15:19] iter = 01450, loss = 51.8892
2024-10-30 19:15:23: [2024-10-30 19:15:23] iter = 01460, loss = 57.5807
2024-10-30 19:15:27: [2024-10-30 19:15:27] iter = 01470, loss = 50.7922
2024-10-30 19:15:29: [2024-10-30 19:15:29] iter = 01480, loss = 12.4542
2024-10-30 19:15:33: [2024-10-30 19:15:33] iter = 01490, loss = 46.4501
2024-10-30 19:15:37: [2024-10-30 19:15:37] iter = 01500, loss = 53.1581
2024-10-30 19:15:41: [2024-10-30 19:15:41] iter = 01510, loss = 54.8967
2024-10-30 19:15:44: [2024-10-30 19:15:44] iter = 01520, loss = 7.5626
2024-10-30 19:15:48: [2024-10-30 19:15:48] iter = 01530, loss = 45.0005
2024-10-30 19:15:52: [2024-10-30 19:15:52] iter = 01540, loss = 5.4682
2024-10-30 19:15:57: [2024-10-30 19:15:57] iter = 01550, loss = 7.4240
2024-10-30 19:16:01: [2024-10-30 19:16:01] iter = 01560, loss = 18.4499
2024-10-30 19:16:04: [2024-10-30 19:16:04] iter = 01570, loss = 43.5385
2024-10-30 19:16:08: [2024-10-30 19:16:08] iter = 01580, loss = 17.9615
2024-10-30 19:16:11: [2024-10-30 19:16:11] iter = 01590, loss = 11.1684
2024-10-30 19:16:15: [2024-10-30 19:16:15] iter = 01600, loss = 54.5704
2024-10-30 19:16:19: [2024-10-30 19:16:19] iter = 01610, loss = 9.5778
2024-10-30 19:16:24: [2024-10-30 19:16:24] iter = 01620, loss = 4.1022
2024-10-30 19:16:28: [2024-10-30 19:16:28] iter = 01630, loss = 12.2558
2024-10-30 19:16:31: [2024-10-30 19:16:31] iter = 01640, loss = 4.5222
2024-10-30 19:16:35: [2024-10-30 19:16:35] iter = 01650, loss = 9.3506
2024-10-30 19:16:37: [2024-10-30 19:16:37] iter = 01660, loss = 4.7323
2024-10-30 19:16:41: [2024-10-30 19:16:41] iter = 01670, loss = 5.9615
2024-10-30 19:16:45: [2024-10-30 19:16:45] iter = 01680, loss = 11.0814
2024-10-30 19:16:49: [2024-10-30 19:16:49] iter = 01690, loss = 5.1604
2024-10-30 19:16:52: [2024-10-30 19:16:52] iter = 01700, loss = 7.9211
2024-10-30 19:16:55: [2024-10-30 19:16:55] iter = 01710, loss = 8.7385
2024-10-30 19:16:58: [2024-10-30 19:16:58] iter = 01720, loss = 4.7684
2024-10-30 19:17:01: [2024-10-30 19:17:01] iter = 01730, loss = 23.6602
2024-10-30 19:17:05: [2024-10-30 19:17:05] iter = 01740, loss = 23.4141
2024-10-30 19:17:09: [2024-10-30 19:17:09] iter = 01750, loss = 31.3722
2024-10-30 19:17:12: [2024-10-30 19:17:12] iter = 01760, loss = 15.5190
2024-10-30 19:17:17: [2024-10-30 19:17:17] iter = 01770, loss = 13.9368
2024-10-30 19:17:20: [2024-10-30 19:17:20] iter = 01780, loss = 46.1738
2024-10-30 19:17:24: [2024-10-30 19:17:24] iter = 01790, loss = 32.3842
2024-10-30 19:17:27: [2024-10-30 19:17:27] iter = 01800, loss = 3.7795
2024-10-30 19:17:30: [2024-10-30 19:17:30] iter = 01810, loss = 25.2143
2024-10-30 19:17:35: [2024-10-30 19:17:35] iter = 01820, loss = 38.0043
2024-10-30 19:17:39: [2024-10-30 19:17:39] iter = 01830, loss = 9.9757
2024-10-30 19:17:44: [2024-10-30 19:17:44] iter = 01840, loss = 37.4665
2024-10-30 19:17:47: [2024-10-30 19:17:47] iter = 01850, loss = 47.9506
2024-10-30 19:17:51: [2024-10-30 19:17:51] iter = 01860, loss = 16.0894
2024-10-30 19:17:55: [2024-10-30 19:17:55] iter = 01870, loss = 21.8906
2024-10-30 19:17:59: [2024-10-30 19:17:59] iter = 01880, loss = 16.5391
2024-10-30 19:18:01: [2024-10-30 19:18:01] iter = 01890, loss = 35.9188
2024-10-30 19:18:05: [2024-10-30 19:18:05] iter = 01900, loss = 80.0484
2024-10-30 19:18:08: [2024-10-30 19:18:08] iter = 01910, loss = 4.9613
2024-10-30 19:18:12: [2024-10-30 19:18:12] iter = 01920, loss = 113.8334
2024-10-30 19:18:17: [2024-10-30 19:18:17] iter = 01930, loss = 14.1552
2024-10-30 19:18:20: [2024-10-30 19:18:20] iter = 01940, loss = 77.8053
2024-10-30 19:18:25: [2024-10-30 19:18:25] iter = 01950, loss = 20.0042
2024-10-30 19:18:30: [2024-10-30 19:18:30] iter = 01960, loss = 34.0898
2024-10-30 19:18:33: [2024-10-30 19:18:33] iter = 01970, loss = 34.2011
2024-10-30 19:18:37: [2024-10-30 19:18:37] iter = 01980, loss = 5.8372
2024-10-30 19:18:40: [2024-10-30 19:18:40] iter = 01990, loss = 6.2234
2024-10-30 19:18:42: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 19:18:42: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:18:42: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 22927}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:21:01: Evaluate 5 random ConvNet, ACCmean = 0.2662 ACCstd = 0.0076
-------------------------
2024-10-30 19:21:01: Evaluate 5 random ConvNet, SENmean = 0.2671 SENstd = 0.0033
-------------------------
2024-10-30 19:21:01: Evaluate 5 random ConvNet, SPEmean = 0.8964 SPEstd = 0.0009
-------------------------
2024-10-30 19:21:01: Evaluate 5 random ConvNet, F!mean = 0.2119 F!std = 0.0050
-------------------------
2024-10-30 19:21:01: Evaluate 5 random ConvNet, mean = 0.2662 std = 0.0076
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:21:01: [2024-10-30 19:21:01] iter = 02000, loss = 13.2135
2024-10-30 19:21:04: [2024-10-30 19:21:04] iter = 02010, loss = 5.2776
2024-10-30 19:21:08: [2024-10-30 19:21:08] iter = 02020, loss = 20.4600
2024-10-30 19:21:11: [2024-10-30 19:21:11] iter = 02030, loss = 12.5302
2024-10-30 19:21:15: [2024-10-30 19:21:15] iter = 02040, loss = 6.7334
2024-10-30 19:21:18: [2024-10-30 19:21:18] iter = 02050, loss = 20.9161
2024-10-30 19:21:21: [2024-10-30 19:21:21] iter = 02060, loss = 6.1627
2024-10-30 19:21:24: [2024-10-30 19:21:24] iter = 02070, loss = 32.9668
2024-10-30 19:21:28: [2024-10-30 19:21:28] iter = 02080, loss = 50.5503
2024-10-30 19:21:32: [2024-10-30 19:21:32] iter = 02090, loss = 13.2375
2024-10-30 19:21:36: [2024-10-30 19:21:36] iter = 02100, loss = 46.8726
2024-10-30 19:21:39: [2024-10-30 19:21:39] iter = 02110, loss = 84.9317
2024-10-30 19:21:43: [2024-10-30 19:21:43] iter = 02120, loss = 80.3428
2024-10-30 19:21:46: [2024-10-30 19:21:46] iter = 02130, loss = 18.2189
2024-10-30 19:21:50: [2024-10-30 19:21:50] iter = 02140, loss = 49.3371
2024-10-30 19:21:53: [2024-10-30 19:21:53] iter = 02150, loss = 3.3452
2024-10-30 19:21:56: [2024-10-30 19:21:56] iter = 02160, loss = 5.1347
2024-10-30 19:21:59: [2024-10-30 19:21:59] iter = 02170, loss = 9.0024
2024-10-30 19:22:03: [2024-10-30 19:22:03] iter = 02180, loss = 16.0210
2024-10-30 19:22:06: [2024-10-30 19:22:06] iter = 02190, loss = 19.1560
2024-10-30 19:22:10: [2024-10-30 19:22:10] iter = 02200, loss = 4.1480
2024-10-30 19:22:14: [2024-10-30 19:22:14] iter = 02210, loss = 5.8115
2024-10-30 19:22:18: [2024-10-30 19:22:18] iter = 02220, loss = 11.6942
2024-10-30 19:22:21: [2024-10-30 19:22:21] iter = 02230, loss = 60.0604
2024-10-30 19:22:25: [2024-10-30 19:22:25] iter = 02240, loss = 14.5136
2024-10-30 19:22:29: [2024-10-30 19:22:29] iter = 02250, loss = 8.8176
2024-10-30 19:22:32: [2024-10-30 19:22:32] iter = 02260, loss = 45.8940
2024-10-30 19:22:35: [2024-10-30 19:22:35] iter = 02270, loss = 4.9480
2024-10-30 19:22:38: [2024-10-30 19:22:38] iter = 02280, loss = 56.0275
2024-10-30 19:22:41: [2024-10-30 19:22:41] iter = 02290, loss = 10.7154
2024-10-30 19:22:44: [2024-10-30 19:22:44] iter = 02300, loss = 15.3918
2024-10-30 19:22:48: [2024-10-30 19:22:48] iter = 02310, loss = 30.9944
2024-10-30 19:22:52: [2024-10-30 19:22:52] iter = 02320, loss = 6.2313
2024-10-30 19:22:55: [2024-10-30 19:22:55] iter = 02330, loss = 5.9838
2024-10-30 19:22:59: [2024-10-30 19:22:59] iter = 02340, loss = 8.6277
2024-10-30 19:23:04: [2024-10-30 19:23:04] iter = 02350, loss = 4.3435
2024-10-30 19:23:07: [2024-10-30 19:23:07] iter = 02360, loss = 51.9118
2024-10-30 19:23:10: [2024-10-30 19:23:10] iter = 02370, loss = 3.8519
2024-10-30 19:23:13: [2024-10-30 19:23:13] iter = 02380, loss = 7.4733
2024-10-30 19:23:16: [2024-10-30 19:23:16] iter = 02390, loss = 11.9830
2024-10-30 19:23:20: [2024-10-30 19:23:20] iter = 02400, loss = 100.0467
2024-10-30 19:23:22: [2024-10-30 19:23:22] iter = 02410, loss = 5.6061
2024-10-30 19:23:25: [2024-10-30 19:23:25] iter = 02420, loss = 52.9260
2024-10-30 19:23:29: [2024-10-30 19:23:29] iter = 02430, loss = 27.9771
2024-10-30 19:23:33: [2024-10-30 19:23:33] iter = 02440, loss = 10.7087
2024-10-30 19:23:36: [2024-10-30 19:23:36] iter = 02450, loss = 53.9540
2024-10-30 19:23:40: [2024-10-30 19:23:40] iter = 02460, loss = 27.1660
2024-10-30 19:23:44: [2024-10-30 19:23:44] iter = 02470, loss = 21.7052
2024-10-30 19:23:48: [2024-10-30 19:23:48] iter = 02480, loss = 5.1996
2024-10-30 19:23:52: [2024-10-30 19:23:52] iter = 02490, loss = 55.9751
2024-10-30 19:23:55: [2024-10-30 19:23:55] iter = 02500, loss = 5.6535
2024-10-30 19:23:59: [2024-10-30 19:23:59] iter = 02510, loss = 5.7599
2024-10-30 19:24:03: [2024-10-30 19:24:03] iter = 02520, loss = 10.2414
2024-10-30 19:24:06: [2024-10-30 19:24:06] iter = 02530, loss = 80.8649
2024-10-30 19:24:10: [2024-10-30 19:24:10] iter = 02540, loss = 13.6612
2024-10-30 19:24:13: [2024-10-30 19:24:13] iter = 02550, loss = 5.5752
2024-10-30 19:24:16: [2024-10-30 19:24:16] iter = 02560, loss = 21.7818
2024-10-30 19:24:20: [2024-10-30 19:24:20] iter = 02570, loss = 4.5808
2024-10-30 19:24:24: [2024-10-30 19:24:24] iter = 02580, loss = 5.7173
2024-10-30 19:24:27: [2024-10-30 19:24:27] iter = 02590, loss = 11.3324
2024-10-30 19:24:32: [2024-10-30 19:24:32] iter = 02600, loss = 23.3243
2024-10-30 19:24:36: [2024-10-30 19:24:36] iter = 02610, loss = 4.2679
2024-10-30 19:24:40: [2024-10-30 19:24:40] iter = 02620, loss = 8.9187
2024-10-30 19:24:44: [2024-10-30 19:24:44] iter = 02630, loss = 23.3978
2024-10-30 19:24:47: [2024-10-30 19:24:47] iter = 02640, loss = 28.4697
2024-10-30 19:24:49: [2024-10-30 19:24:49] iter = 02650, loss = 6.9936
2024-10-30 19:24:53: [2024-10-30 19:24:53] iter = 02660, loss = 11.6064
2024-10-30 19:24:58: [2024-10-30 19:24:58] iter = 02670, loss = 5.7495
2024-10-30 19:25:01: [2024-10-30 19:25:01] iter = 02680, loss = 9.4948
2024-10-30 19:25:05: [2024-10-30 19:25:05] iter = 02690, loss = 6.4189
2024-10-30 19:25:08: [2024-10-30 19:25:08] iter = 02700, loss = 20.9341
2024-10-30 19:25:13: [2024-10-30 19:25:13] iter = 02710, loss = 41.9511
2024-10-30 19:25:16: [2024-10-30 19:25:16] iter = 02720, loss = 3.4507
2024-10-30 19:25:20: [2024-10-30 19:25:19] iter = 02730, loss = 6.5840
2024-10-30 19:25:22: [2024-10-30 19:25:22] iter = 02740, loss = 6.6242
2024-10-30 19:25:23: [2024-10-30 19:25:23] iter = 02750, loss = 36.5968
2024-10-30 19:25:26: [2024-10-30 19:25:26] iter = 02760, loss = 71.5052
2024-10-30 19:25:28: [2024-10-30 19:25:28] iter = 02770, loss = 4.9341
2024-10-30 19:25:31: [2024-10-30 19:25:31] iter = 02780, loss = 8.0375
2024-10-30 19:25:36: [2024-10-30 19:25:36] iter = 02790, loss = 4.7225
2024-10-30 19:25:40: [2024-10-30 19:25:40] iter = 02800, loss = 21.3710
2024-10-30 19:25:44: [2024-10-30 19:25:44] iter = 02810, loss = 16.8276
2024-10-30 19:25:47: [2024-10-30 19:25:47] iter = 02820, loss = 6.0086
2024-10-30 19:25:51: [2024-10-30 19:25:51] iter = 02830, loss = 4.5126
2024-10-30 19:25:56: [2024-10-30 19:25:56] iter = 02840, loss = 4.6184
2024-10-30 19:25:59: [2024-10-30 19:25:59] iter = 02850, loss = 12.9276
2024-10-30 19:26:03: [2024-10-30 19:26:03] iter = 02860, loss = 47.9099
2024-10-30 19:26:07: [2024-10-30 19:26:07] iter = 02870, loss = 9.8052
2024-10-30 19:26:11: [2024-10-30 19:26:11] iter = 02880, loss = 14.6920
2024-10-30 19:26:16: [2024-10-30 19:26:16] iter = 02890, loss = 9.3113
2024-10-30 19:26:21: [2024-10-30 19:26:21] iter = 02900, loss = 17.1646
2024-10-30 19:26:25: [2024-10-30 19:26:25] iter = 02910, loss = 111.4529
2024-10-30 19:26:29: [2024-10-30 19:26:29] iter = 02920, loss = 6.1766
2024-10-30 19:26:34: [2024-10-30 19:26:33] iter = 02930, loss = 13.7532
2024-10-30 19:26:37: [2024-10-30 19:26:37] iter = 02940, loss = 4.2149
2024-10-30 19:26:42: [2024-10-30 19:26:42] iter = 02950, loss = 57.1445
2024-10-30 19:26:45: [2024-10-30 19:26:45] iter = 02960, loss = 33.9510
2024-10-30 19:26:49: [2024-10-30 19:26:49] iter = 02970, loss = 13.3525
2024-10-30 19:26:53: [2024-10-30 19:26:53] iter = 02980, loss = 14.6585
2024-10-30 19:26:57: [2024-10-30 19:26:57] iter = 02990, loss = 12.7487
2024-10-30 19:27:01: [2024-10-30 19:27:01] iter = 03000, loss = 38.6141
2024-10-30 19:27:04: [2024-10-30 19:27:04] iter = 03010, loss = 81.8337
2024-10-30 19:27:08: [2024-10-30 19:27:08] iter = 03020, loss = 28.8800
2024-10-30 19:27:12: [2024-10-30 19:27:12] iter = 03030, loss = 3.6266
2024-10-30 19:27:16: [2024-10-30 19:27:16] iter = 03040, loss = 20.0832
2024-10-30 19:27:19: [2024-10-30 19:27:19] iter = 03050, loss = 3.6264
2024-10-30 19:27:23: [2024-10-30 19:27:23] iter = 03060, loss = 25.8049
2024-10-30 19:27:26: [2024-10-30 19:27:26] iter = 03070, loss = 3.9030
2024-10-30 19:27:29: [2024-10-30 19:27:29] iter = 03080, loss = 4.8109
2024-10-30 19:27:33: [2024-10-30 19:27:33] iter = 03090, loss = 3.5868
2024-10-30 19:27:35: [2024-10-30 19:27:35] iter = 03100, loss = 19.1785
2024-10-30 19:27:39: [2024-10-30 19:27:39] iter = 03110, loss = 13.0110
2024-10-30 19:27:42: [2024-10-30 19:27:42] iter = 03120, loss = 15.1547
2024-10-30 19:27:45: [2024-10-30 19:27:45] iter = 03130, loss = 29.9661
2024-10-30 19:27:49: [2024-10-30 19:27:49] iter = 03140, loss = 7.8907
2024-10-30 19:27:53: [2024-10-30 19:27:53] iter = 03150, loss = 29.8050
2024-10-30 19:27:58: [2024-10-30 19:27:58] iter = 03160, loss = 10.2726
2024-10-30 19:28:02: [2024-10-30 19:28:01] iter = 03170, loss = 8.0109
2024-10-30 19:28:05: [2024-10-30 19:28:05] iter = 03180, loss = 32.4301
2024-10-30 19:28:09: [2024-10-30 19:28:09] iter = 03190, loss = 29.5909
2024-10-30 19:28:13: [2024-10-30 19:28:13] iter = 03200, loss = 34.8159
2024-10-30 19:28:17: [2024-10-30 19:28:17] iter = 03210, loss = 32.6027
2024-10-30 19:28:20: [2024-10-30 19:28:20] iter = 03220, loss = 5.2075
2024-10-30 19:28:24: [2024-10-30 19:28:24] iter = 03230, loss = 39.6431
2024-10-30 19:28:28: [2024-10-30 19:28:28] iter = 03240, loss = 4.6617
2024-10-30 19:28:32: [2024-10-30 19:28:32] iter = 03250, loss = 4.5095
2024-10-30 19:28:36: [2024-10-30 19:28:36] iter = 03260, loss = 3.7188
2024-10-30 19:28:40: [2024-10-30 19:28:40] iter = 03270, loss = 3.8330
2024-10-30 19:28:43: [2024-10-30 19:28:43] iter = 03280, loss = 12.3753
2024-10-30 19:28:47: [2024-10-30 19:28:47] iter = 03290, loss = 15.1970
2024-10-30 19:28:50: [2024-10-30 19:28:50] iter = 03300, loss = 7.4021
2024-10-30 19:28:54: [2024-10-30 19:28:54] iter = 03310, loss = 39.9000
2024-10-30 19:28:57: [2024-10-30 19:28:57] iter = 03320, loss = 16.4983
2024-10-30 19:29:00: [2024-10-30 19:29:00] iter = 03330, loss = 106.7296
2024-10-30 19:29:04: [2024-10-30 19:29:04] iter = 03340, loss = 29.3194
2024-10-30 19:29:09: [2024-10-30 19:29:09] iter = 03350, loss = 13.2314
2024-10-30 19:29:13: [2024-10-30 19:29:13] iter = 03360, loss = 23.4275
2024-10-30 19:29:17: [2024-10-30 19:29:17] iter = 03370, loss = 49.1279
2024-10-30 19:29:21: [2024-10-30 19:29:21] iter = 03380, loss = 6.2755
2024-10-30 19:29:24: [2024-10-30 19:29:24] iter = 03390, loss = 26.8006
2024-10-30 19:29:26: [2024-10-30 19:29:26] iter = 03400, loss = 4.3928
2024-10-30 19:29:29: [2024-10-30 19:29:29] iter = 03410, loss = 33.7214
2024-10-30 19:29:32: [2024-10-30 19:29:32] iter = 03420, loss = 5.0435
2024-10-30 19:29:36: [2024-10-30 19:29:36] iter = 03430, loss = 7.3787
2024-10-30 19:29:40: [2024-10-30 19:29:40] iter = 03440, loss = 13.3623
2024-10-30 19:29:44: [2024-10-30 19:29:44] iter = 03450, loss = 31.6952
2024-10-30 19:29:48: [2024-10-30 19:29:48] iter = 03460, loss = 3.8750
2024-10-30 19:29:51: [2024-10-30 19:29:51] iter = 03470, loss = 5.8339
2024-10-30 19:29:55: [2024-10-30 19:29:55] iter = 03480, loss = 17.6805
2024-10-30 19:29:59: [2024-10-30 19:29:59] iter = 03490, loss = 25.9389
2024-10-30 19:30:02: [2024-10-30 19:30:02] iter = 03500, loss = 4.6016
2024-10-30 19:30:06: [2024-10-30 19:30:06] iter = 03510, loss = 40.8009
2024-10-30 19:30:10: [2024-10-30 19:30:10] iter = 03520, loss = 25.7180
2024-10-30 19:30:15: [2024-10-30 19:30:15] iter = 03530, loss = 5.1610
2024-10-30 19:30:19: [2024-10-30 19:30:19] iter = 03540, loss = 13.8895
2024-10-30 19:30:21: [2024-10-30 19:30:21] iter = 03550, loss = 6.3288
2024-10-30 19:30:23: [2024-10-30 19:30:23] iter = 03560, loss = 10.6226
2024-10-30 19:30:25: [2024-10-30 19:30:25] iter = 03570, loss = 61.1508
2024-10-30 19:30:28: [2024-10-30 19:30:28] iter = 03580, loss = 5.0273
2024-10-30 19:30:32: [2024-10-30 19:30:32] iter = 03590, loss = 5.7400
2024-10-30 19:30:36: [2024-10-30 19:30:36] iter = 03600, loss = 33.3176
2024-10-30 19:30:40: [2024-10-30 19:30:40] iter = 03610, loss = 55.1916
2024-10-30 19:30:44: [2024-10-30 19:30:44] iter = 03620, loss = 22.1507
2024-10-30 19:30:47: [2024-10-30 19:30:47] iter = 03630, loss = 36.9118
2024-10-30 19:30:52: [2024-10-30 19:30:52] iter = 03640, loss = 5.6281
2024-10-30 19:30:56: [2024-10-30 19:30:56] iter = 03650, loss = 5.3565
2024-10-30 19:30:59: [2024-10-30 19:30:59] iter = 03660, loss = 6.0897
2024-10-30 19:31:03: [2024-10-30 19:31:03] iter = 03670, loss = 12.3273
2024-10-30 19:31:06: [2024-10-30 19:31:06] iter = 03680, loss = 7.1226
2024-10-30 19:31:10: [2024-10-30 19:31:10] iter = 03690, loss = 20.5149
2024-10-30 19:31:13: [2024-10-30 19:31:13] iter = 03700, loss = 38.6134
2024-10-30 19:31:16: [2024-10-30 19:31:16] iter = 03710, loss = 28.1831
2024-10-30 19:31:20: [2024-10-30 19:31:20] iter = 03720, loss = 10.7962
2024-10-30 19:31:25: [2024-10-30 19:31:25] iter = 03730, loss = 5.0687
2024-10-30 19:31:29: [2024-10-30 19:31:29] iter = 03740, loss = 23.6921
2024-10-30 19:31:33: [2024-10-30 19:31:33] iter = 03750, loss = 5.1020
2024-10-30 19:31:36: [2024-10-30 19:31:36] iter = 03760, loss = 12.6853
2024-10-30 19:31:39: [2024-10-30 19:31:39] iter = 03770, loss = 72.3561
2024-10-30 19:31:43: [2024-10-30 19:31:43] iter = 03780, loss = 5.2002
2024-10-30 19:31:46: [2024-10-30 19:31:46] iter = 03790, loss = 10.6674
2024-10-30 19:31:49: [2024-10-30 19:31:49] iter = 03800, loss = 47.9767
2024-10-30 19:31:53: [2024-10-30 19:31:53] iter = 03810, loss = 16.0660
2024-10-30 19:31:57: [2024-10-30 19:31:57] iter = 03820, loss = 18.4102
2024-10-30 19:32:01: [2024-10-30 19:32:01] iter = 03830, loss = 23.2088
2024-10-30 19:32:04: [2024-10-30 19:32:04] iter = 03840, loss = 9.4177
2024-10-30 19:32:08: [2024-10-30 19:32:08] iter = 03850, loss = 10.1674
2024-10-30 19:32:11: [2024-10-30 19:32:11] iter = 03860, loss = 5.4728
2024-10-30 19:32:14: [2024-10-30 19:32:14] iter = 03870, loss = 69.0567
2024-10-30 19:32:18: [2024-10-30 19:32:18] iter = 03880, loss = 16.2868
2024-10-30 19:32:22: [2024-10-30 19:32:22] iter = 03890, loss = 33.9578
2024-10-30 19:32:26: [2024-10-30 19:32:26] iter = 03900, loss = 4.5428
2024-10-30 19:32:29: [2024-10-30 19:32:29] iter = 03910, loss = 41.8065
2024-10-30 19:32:32: [2024-10-30 19:32:32] iter = 03920, loss = 11.9749
2024-10-30 19:32:36: [2024-10-30 19:32:36] iter = 03930, loss = 6.9300
2024-10-30 19:32:40: [2024-10-30 19:32:40] iter = 03940, loss = 6.2476
2024-10-30 19:32:43: [2024-10-30 19:32:43] iter = 03950, loss = 34.1349
2024-10-30 19:32:47: [2024-10-30 19:32:47] iter = 03960, loss = 6.2665
2024-10-30 19:32:51: [2024-10-30 19:32:51] iter = 03970, loss = 24.5481
2024-10-30 19:32:55: [2024-10-30 19:32:55] iter = 03980, loss = 28.0164
2024-10-30 19:32:59: [2024-10-30 19:32:59] iter = 03990, loss = 13.5569
2024-10-30 19:33:02: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 19:33:02: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:33:02: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 82017}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:35:16: Evaluate 5 random ConvNet, ACCmean = 0.3784 ACCstd = 0.0054
-------------------------
2024-10-30 19:35:16: Evaluate 5 random ConvNet, SENmean = 0.3140 SENstd = 0.0024
-------------------------
2024-10-30 19:35:16: Evaluate 5 random ConvNet, SPEmean = 0.9099 SPEstd = 0.0005
-------------------------
2024-10-30 19:35:16: Evaluate 5 random ConvNet, F!mean = 0.2981 F!std = 0.0026
-------------------------
2024-10-30 19:35:16: Evaluate 5 random ConvNet, mean = 0.3784 std = 0.0054
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:35:17: [2024-10-30 19:35:17] iter = 04000, loss = 4.0715
2024-10-30 19:35:21: [2024-10-30 19:35:21] iter = 04010, loss = 22.2371
2024-10-30 19:35:24: [2024-10-30 19:35:24] iter = 04020, loss = 29.2724
2024-10-30 19:35:28: [2024-10-30 19:35:28] iter = 04030, loss = 4.0973
2024-10-30 19:35:32: [2024-10-30 19:35:32] iter = 04040, loss = 3.3765
2024-10-30 19:35:37: [2024-10-30 19:35:37] iter = 04050, loss = 33.9980
2024-10-30 19:35:41: [2024-10-30 19:35:41] iter = 04060, loss = 6.5806
2024-10-30 19:35:45: [2024-10-30 19:35:45] iter = 04070, loss = 14.1963
2024-10-30 19:35:49: [2024-10-30 19:35:49] iter = 04080, loss = 36.7452
2024-10-30 19:35:53: [2024-10-30 19:35:53] iter = 04090, loss = 16.3099
2024-10-30 19:35:56: [2024-10-30 19:35:56] iter = 04100, loss = 20.4912
2024-10-30 19:35:59: [2024-10-30 19:35:59] iter = 04110, loss = 13.8119
2024-10-30 19:36:03: [2024-10-30 19:36:03] iter = 04120, loss = 15.4356
2024-10-30 19:36:07: [2024-10-30 19:36:07] iter = 04130, loss = 51.7487
2024-10-30 19:36:10: [2024-10-30 19:36:10] iter = 04140, loss = 6.2213
2024-10-30 19:36:14: [2024-10-30 19:36:14] iter = 04150, loss = 13.8395
2024-10-30 19:36:17: [2024-10-30 19:36:17] iter = 04160, loss = 9.2709
2024-10-30 19:36:21: [2024-10-30 19:36:21] iter = 04170, loss = 17.1059
2024-10-30 19:36:24: [2024-10-30 19:36:24] iter = 04180, loss = 16.1740
2024-10-30 19:36:29: [2024-10-30 19:36:29] iter = 04190, loss = 21.9258
2024-10-30 19:36:32: [2024-10-30 19:36:32] iter = 04200, loss = 8.2828
2024-10-30 19:36:36: [2024-10-30 19:36:36] iter = 04210, loss = 19.6729
2024-10-30 19:36:40: [2024-10-30 19:36:40] iter = 04220, loss = 4.8352
2024-10-30 19:36:43: [2024-10-30 19:36:43] iter = 04230, loss = 5.0188
2024-10-30 19:36:47: [2024-10-30 19:36:47] iter = 04240, loss = 7.4967
2024-10-30 19:36:51: [2024-10-30 19:36:51] iter = 04250, loss = 21.8283
2024-10-30 19:36:55: [2024-10-30 19:36:55] iter = 04260, loss = 58.0231
2024-10-30 19:36:58: [2024-10-30 19:36:58] iter = 04270, loss = 30.0545
2024-10-30 19:37:01: [2024-10-30 19:37:01] iter = 04280, loss = 17.0213
2024-10-30 19:37:05: [2024-10-30 19:37:05] iter = 04290, loss = 56.1559
2024-10-30 19:37:09: [2024-10-30 19:37:09] iter = 04300, loss = 9.3885
2024-10-30 19:37:12: [2024-10-30 19:37:12] iter = 04310, loss = 5.2995
2024-10-30 19:37:15: [2024-10-30 19:37:15] iter = 04320, loss = 17.4366
2024-10-30 19:37:18: [2024-10-30 19:37:18] iter = 04330, loss = 11.9493
2024-10-30 19:37:22: [2024-10-30 19:37:22] iter = 04340, loss = 11.5021
2024-10-30 19:37:25: [2024-10-30 19:37:25] iter = 04350, loss = 3.7400
2024-10-30 19:37:29: [2024-10-30 19:37:29] iter = 04360, loss = 24.7113
2024-10-30 19:37:31: [2024-10-30 19:37:31] iter = 04370, loss = 27.8239
2024-10-30 19:37:34: [2024-10-30 19:37:34] iter = 04380, loss = 22.0280
2024-10-30 19:37:37: [2024-10-30 19:37:37] iter = 04390, loss = 31.7646
2024-10-30 19:37:40: [2024-10-30 19:37:40] iter = 04400, loss = 7.3262
2024-10-30 19:37:44: [2024-10-30 19:37:44] iter = 04410, loss = 63.2548
2024-10-30 19:37:48: [2024-10-30 19:37:48] iter = 04420, loss = 4.5287
2024-10-30 19:37:51: [2024-10-30 19:37:51] iter = 04430, loss = 7.3978
2024-10-30 19:37:54: [2024-10-30 19:37:54] iter = 04440, loss = 5.3289
2024-10-30 19:37:57: [2024-10-30 19:37:57] iter = 04450, loss = 45.8024
2024-10-30 19:38:01: [2024-10-30 19:38:01] iter = 04460, loss = 12.5600
2024-10-30 19:38:05: [2024-10-30 19:38:05] iter = 04470, loss = 24.9882
2024-10-30 19:38:09: [2024-10-30 19:38:09] iter = 04480, loss = 5.5670
2024-10-30 19:38:12: [2024-10-30 19:38:12] iter = 04490, loss = 8.3653
2024-10-30 19:38:16: [2024-10-30 19:38:16] iter = 04500, loss = 17.5119
2024-10-30 19:38:19: [2024-10-30 19:38:19] iter = 04510, loss = 48.3391
2024-10-30 19:38:23: [2024-10-30 19:38:23] iter = 04520, loss = 15.9279
2024-10-30 19:38:27: [2024-10-30 19:38:27] iter = 04530, loss = 28.0629
2024-10-30 19:38:31: [2024-10-30 19:38:31] iter = 04540, loss = 10.1399
2024-10-30 19:38:36: [2024-10-30 19:38:36] iter = 04550, loss = 6.9310
2024-10-30 19:38:40: [2024-10-30 19:38:40] iter = 04560, loss = 4.7069
2024-10-30 19:38:43: [2024-10-30 19:38:43] iter = 04570, loss = 12.8256
2024-10-30 19:38:46: [2024-10-30 19:38:46] iter = 04580, loss = 50.0029
2024-10-30 19:38:50: [2024-10-30 19:38:50] iter = 04590, loss = 7.3904
2024-10-30 19:38:54: [2024-10-30 19:38:54] iter = 04600, loss = 4.7262
2024-10-30 19:38:57: [2024-10-30 19:38:57] iter = 04610, loss = 20.8623
2024-10-30 19:39:00: [2024-10-30 19:39:00] iter = 04620, loss = 62.7702
2024-10-30 19:39:04: [2024-10-30 19:39:04] iter = 04630, loss = 22.5848
2024-10-30 19:39:08: [2024-10-30 19:39:08] iter = 04640, loss = 26.8794
2024-10-30 19:39:12: [2024-10-30 19:39:12] iter = 04650, loss = 4.4470
2024-10-30 19:39:15: [2024-10-30 19:39:15] iter = 04660, loss = 4.5011
2024-10-30 19:39:18: [2024-10-30 19:39:18] iter = 04670, loss = 60.6404
2024-10-30 19:39:21: [2024-10-30 19:39:21] iter = 04680, loss = 4.8010
2024-10-30 19:39:24: [2024-10-30 19:39:24] iter = 04690, loss = 5.8269
2024-10-30 19:39:27: [2024-10-30 19:39:27] iter = 04700, loss = 21.9302
2024-10-30 19:39:31: [2024-10-30 19:39:31] iter = 04710, loss = 55.8159
2024-10-30 19:39:35: [2024-10-30 19:39:35] iter = 04720, loss = 19.6399
2024-10-30 19:39:39: [2024-10-30 19:39:39] iter = 04730, loss = 8.0252
2024-10-30 19:39:42: [2024-10-30 19:39:42] iter = 04740, loss = 3.5164
2024-10-30 19:39:46: [2024-10-30 19:39:46] iter = 04750, loss = 6.7516
2024-10-30 19:39:50: [2024-10-30 19:39:50] iter = 04760, loss = 17.0967
2024-10-30 19:39:54: [2024-10-30 19:39:54] iter = 04770, loss = 5.0960
2024-10-30 19:39:58: [2024-10-30 19:39:58] iter = 04780, loss = 61.6111
2024-10-30 19:40:01: [2024-10-30 19:40:01] iter = 04790, loss = 7.5137
2024-10-30 19:40:02: [2024-10-30 19:40:02] iter = 04800, loss = 6.2882
2024-10-30 19:40:05: [2024-10-30 19:40:05] iter = 04810, loss = 4.5859
2024-10-30 19:40:09: [2024-10-30 19:40:09] iter = 04820, loss = 22.1903
2024-10-30 19:40:12: [2024-10-30 19:40:12] iter = 04830, loss = 18.3508
2024-10-30 19:40:16: [2024-10-30 19:40:16] iter = 04840, loss = 25.2206
2024-10-30 19:40:20: [2024-10-30 19:40:20] iter = 04850, loss = 4.9985
2024-10-30 19:40:24: [2024-10-30 19:40:24] iter = 04860, loss = 4.8147
2024-10-30 19:40:27: [2024-10-30 19:40:27] iter = 04870, loss = 6.6794
2024-10-30 19:40:30: [2024-10-30 19:40:30] iter = 04880, loss = 12.9455
2024-10-30 19:40:34: [2024-10-30 19:40:34] iter = 04890, loss = 13.0266
2024-10-30 19:40:38: [2024-10-30 19:40:38] iter = 04900, loss = 33.6951
2024-10-30 19:40:42: [2024-10-30 19:40:42] iter = 04910, loss = 12.2465
2024-10-30 19:40:46: [2024-10-30 19:40:46] iter = 04920, loss = 7.1678
2024-10-30 19:40:51: [2024-10-30 19:40:51] iter = 04930, loss = 17.9267
2024-10-30 19:40:55: [2024-10-30 19:40:55] iter = 04940, loss = 37.2632
2024-10-30 19:40:59: [2024-10-30 19:40:59] iter = 04950, loss = 33.4095
2024-10-30 19:41:03: [2024-10-30 19:41:03] iter = 04960, loss = 15.7675
2024-10-30 19:41:08: [2024-10-30 19:41:08] iter = 04970, loss = 4.3913
2024-10-30 19:41:12: [2024-10-30 19:41:12] iter = 04980, loss = 30.3773
2024-10-30 19:41:16: [2024-10-30 19:41:16] iter = 04990, loss = 49.4528
2024-10-30 19:41:18: [2024-10-30 19:41:18] iter = 05000, loss = 23.0860
2024-10-30 19:41:21: [2024-10-30 19:41:21] iter = 05010, loss = 4.1064
2024-10-30 19:41:25: [2024-10-30 19:41:25] iter = 05020, loss = 6.3549
2024-10-30 19:41:28: [2024-10-30 19:41:28] iter = 05030, loss = 8.8432
2024-10-30 19:41:31: [2024-10-30 19:41:31] iter = 05040, loss = 9.7551
2024-10-30 19:41:34: [2024-10-30 19:41:34] iter = 05050, loss = 4.8555
2024-10-30 19:41:37: [2024-10-30 19:41:37] iter = 05060, loss = 7.6224
2024-10-30 19:41:42: [2024-10-30 19:41:42] iter = 05070, loss = 11.9325
2024-10-30 19:41:47: [2024-10-30 19:41:47] iter = 05080, loss = 30.1786
2024-10-30 19:41:51: [2024-10-30 19:41:51] iter = 05090, loss = 22.9693
2024-10-30 19:41:56: [2024-10-30 19:41:56] iter = 05100, loss = 20.5075
2024-10-30 19:41:59: [2024-10-30 19:41:59] iter = 05110, loss = 19.1483
2024-10-30 19:42:02: [2024-10-30 19:42:02] iter = 05120, loss = 22.9720
2024-10-30 19:42:06: [2024-10-30 19:42:06] iter = 05130, loss = 5.9906
2024-10-30 19:42:08: [2024-10-30 19:42:08] iter = 05140, loss = 19.1843
2024-10-30 19:42:10: [2024-10-30 19:42:10] iter = 05150, loss = 43.6410
2024-10-30 19:42:14: [2024-10-30 19:42:14] iter = 05160, loss = 14.6231
2024-10-30 19:42:17: [2024-10-30 19:42:17] iter = 05170, loss = 24.1196
2024-10-30 19:42:21: [2024-10-30 19:42:21] iter = 05180, loss = 9.8561
2024-10-30 19:42:25: [2024-10-30 19:42:25] iter = 05190, loss = 9.1472
2024-10-30 19:42:28: [2024-10-30 19:42:28] iter = 05200, loss = 18.2660
2024-10-30 19:42:31: [2024-10-30 19:42:31] iter = 05210, loss = 11.9215
2024-10-30 19:42:35: [2024-10-30 19:42:35] iter = 05220, loss = 17.1004
2024-10-30 19:42:38: [2024-10-30 19:42:38] iter = 05230, loss = 9.8433
2024-10-30 19:42:42: [2024-10-30 19:42:42] iter = 05240, loss = 70.4631
2024-10-30 19:42:44: [2024-10-30 19:42:44] iter = 05250, loss = 26.1100
2024-10-30 19:42:48: [2024-10-30 19:42:48] iter = 05260, loss = 13.7224
2024-10-30 19:42:52: [2024-10-30 19:42:52] iter = 05270, loss = 10.8524
2024-10-30 19:42:55: [2024-10-30 19:42:55] iter = 05280, loss = 10.4787
2024-10-30 19:42:59: [2024-10-30 19:42:59] iter = 05290, loss = 45.2016
2024-10-30 19:43:02: [2024-10-30 19:43:02] iter = 05300, loss = 4.9220
2024-10-30 19:43:04: [2024-10-30 19:43:04] iter = 05310, loss = 4.8693
2024-10-30 19:43:08: [2024-10-30 19:43:08] iter = 05320, loss = 46.2668
2024-10-30 19:43:13: [2024-10-30 19:43:13] iter = 05330, loss = 4.9083
2024-10-30 19:43:16: [2024-10-30 19:43:16] iter = 05340, loss = 28.9539
2024-10-30 19:43:20: [2024-10-30 19:43:20] iter = 05350, loss = 19.8589
2024-10-30 19:43:23: [2024-10-30 19:43:23] iter = 05360, loss = 12.6064
2024-10-30 19:43:27: [2024-10-30 19:43:27] iter = 05370, loss = 9.0499
2024-10-30 19:43:31: [2024-10-30 19:43:31] iter = 05380, loss = 3.8826
2024-10-30 19:43:34: [2024-10-30 19:43:34] iter = 05390, loss = 26.0505
2024-10-30 19:43:37: [2024-10-30 19:43:37] iter = 05400, loss = 24.5036
2024-10-30 19:43:41: [2024-10-30 19:43:41] iter = 05410, loss = 61.8295
2024-10-30 19:43:45: [2024-10-30 19:43:45] iter = 05420, loss = 42.4800
2024-10-30 19:43:48: [2024-10-30 19:43:48] iter = 05430, loss = 23.5774
2024-10-30 19:43:52: [2024-10-30 19:43:52] iter = 05440, loss = 6.9548
2024-10-30 19:43:56: [2024-10-30 19:43:56] iter = 05450, loss = 40.5880
2024-10-30 19:44:00: [2024-10-30 19:44:00] iter = 05460, loss = 3.8150
2024-10-30 19:44:03: [2024-10-30 19:44:03] iter = 05470, loss = 45.8195
2024-10-30 19:44:07: [2024-10-30 19:44:07] iter = 05480, loss = 5.8926
2024-10-30 19:44:11: [2024-10-30 19:44:11] iter = 05490, loss = 42.9962
2024-10-30 19:44:15: [2024-10-30 19:44:15] iter = 05500, loss = 82.1044
2024-10-30 19:44:19: [2024-10-30 19:44:19] iter = 05510, loss = 4.1093
2024-10-30 19:44:24: [2024-10-30 19:44:24] iter = 05520, loss = 13.4797
2024-10-30 19:44:26: [2024-10-30 19:44:26] iter = 05530, loss = 7.6865
2024-10-30 19:44:29: [2024-10-30 19:44:29] iter = 05540, loss = 15.0469
2024-10-30 19:44:34: [2024-10-30 19:44:34] iter = 05550, loss = 43.5163
2024-10-30 19:44:38: [2024-10-30 19:44:38] iter = 05560, loss = 7.1453
2024-10-30 19:44:42: [2024-10-30 19:44:42] iter = 05570, loss = 44.6628
2024-10-30 19:44:46: [2024-10-30 19:44:46] iter = 05580, loss = 13.0000
2024-10-30 19:44:49: [2024-10-30 19:44:49] iter = 05590, loss = 5.3417
2024-10-30 19:44:54: [2024-10-30 19:44:54] iter = 05600, loss = 20.3693
2024-10-30 19:44:58: [2024-10-30 19:44:58] iter = 05610, loss = 11.5093
2024-10-30 19:45:02: [2024-10-30 19:45:02] iter = 05620, loss = 15.1456
2024-10-30 19:45:07: [2024-10-30 19:45:07] iter = 05630, loss = 3.9705
2024-10-30 19:45:11: [2024-10-30 19:45:11] iter = 05640, loss = 44.1328
2024-10-30 19:45:15: [2024-10-30 19:45:15] iter = 05650, loss = 4.8925
2024-10-30 19:45:18: [2024-10-30 19:45:18] iter = 05660, loss = 71.9590
2024-10-30 19:45:22: [2024-10-30 19:45:22] iter = 05670, loss = 15.2897
2024-10-30 19:45:25: [2024-10-30 19:45:25] iter = 05680, loss = 3.5200
2024-10-30 19:45:28: [2024-10-30 19:45:28] iter = 05690, loss = 11.6290
2024-10-30 19:45:32: [2024-10-30 19:45:32] iter = 05700, loss = 15.8300
2024-10-30 19:45:36: [2024-10-30 19:45:36] iter = 05710, loss = 82.2237
2024-10-30 19:45:39: [2024-10-30 19:45:39] iter = 05720, loss = 40.4195
2024-10-30 19:45:43: [2024-10-30 19:45:43] iter = 05730, loss = 30.1114
2024-10-30 19:45:47: [2024-10-30 19:45:47] iter = 05740, loss = 17.7485
2024-10-30 19:45:51: [2024-10-30 19:45:51] iter = 05750, loss = 23.1412
2024-10-30 19:45:54: [2024-10-30 19:45:54] iter = 05760, loss = 53.6487
2024-10-30 19:45:58: [2024-10-30 19:45:58] iter = 05770, loss = 5.3492
2024-10-30 19:46:01: [2024-10-30 19:46:01] iter = 05780, loss = 6.7527
2024-10-30 19:46:04: [2024-10-30 19:46:04] iter = 05790, loss = 30.5630
2024-10-30 19:46:08: [2024-10-30 19:46:08] iter = 05800, loss = 13.9591
2024-10-30 19:46:12: [2024-10-30 19:46:12] iter = 05810, loss = 11.0478
2024-10-30 19:46:17: [2024-10-30 19:46:17] iter = 05820, loss = 8.9389
2024-10-30 19:46:22: [2024-10-30 19:46:22] iter = 05830, loss = 53.6155
2024-10-30 19:46:26: [2024-10-30 19:46:26] iter = 05840, loss = 9.1694
2024-10-30 19:46:30: [2024-10-30 19:46:30] iter = 05850, loss = 16.6601
2024-10-30 19:46:32: [2024-10-30 19:46:32] iter = 05860, loss = 38.4089
2024-10-30 19:46:36: [2024-10-30 19:46:36] iter = 05870, loss = 3.7910
2024-10-30 19:46:40: [2024-10-30 19:46:40] iter = 05880, loss = 6.1324
2024-10-30 19:46:43: [2024-10-30 19:46:43] iter = 05890, loss = 6.7144
2024-10-30 19:46:47: [2024-10-30 19:46:47] iter = 05900, loss = 5.8957
2024-10-30 19:46:51: [2024-10-30 19:46:51] iter = 05910, loss = 9.7096
2024-10-30 19:46:55: [2024-10-30 19:46:55] iter = 05920, loss = 13.4867
2024-10-30 19:46:59: [2024-10-30 19:46:59] iter = 05930, loss = 14.0392
2024-10-30 19:47:03: [2024-10-30 19:47:03] iter = 05940, loss = 18.8878
2024-10-30 19:47:07: [2024-10-30 19:47:07] iter = 05950, loss = 4.8451
2024-10-30 19:47:11: [2024-10-30 19:47:11] iter = 05960, loss = 26.5775
2024-10-30 19:47:15: [2024-10-30 19:47:14] iter = 05970, loss = 48.4585
2024-10-30 19:47:18: [2024-10-30 19:47:18] iter = 05980, loss = 5.7020
2024-10-30 19:47:23: [2024-10-30 19:47:23] iter = 05990, loss = 25.3019
2024-10-30 19:47:26: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 19:47:26: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 19:47:26: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 46903}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:49:45: Evaluate 5 random ConvNet, ACCmean = 0.3431 ACCstd = 0.0123
-------------------------
2024-10-30 19:49:45: Evaluate 5 random ConvNet, SENmean = 0.2953 SENstd = 0.0059
-------------------------
2024-10-30 19:49:45: Evaluate 5 random ConvNet, SPEmean = 0.9061 SPEstd = 0.0015
-------------------------
2024-10-30 19:49:45: Evaluate 5 random ConvNet, F!mean = 0.2578 F!std = 0.0072
-------------------------
2024-10-30 19:49:45: Evaluate 5 random ConvNet, mean = 0.3431 std = 0.0123
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 19:49:46: [2024-10-30 19:49:46] iter = 06000, loss = 24.5077
2024-10-30 19:49:51: [2024-10-30 19:49:51] iter = 06010, loss = 14.3162
2024-10-30 19:49:56: [2024-10-30 19:49:56] iter = 06020, loss = 40.4356
2024-10-30 19:50:00: [2024-10-30 19:50:00] iter = 06030, loss = 11.5114
2024-10-30 19:50:04: [2024-10-30 19:50:04] iter = 06040, loss = 4.8190
2024-10-30 19:50:07: [2024-10-30 19:50:07] iter = 06050, loss = 44.7556
2024-10-30 19:50:10: [2024-10-30 19:50:10] iter = 06060, loss = 62.3623
2024-10-30 19:50:15: [2024-10-30 19:50:15] iter = 06070, loss = 4.8357
2024-10-30 19:50:19: [2024-10-30 19:50:19] iter = 06080, loss = 80.8213
2024-10-30 19:50:22: [2024-10-30 19:50:22] iter = 06090, loss = 51.7667
2024-10-30 19:50:24: [2024-10-30 19:50:24] iter = 06100, loss = 10.8986
2024-10-30 19:50:27: [2024-10-30 19:50:27] iter = 06110, loss = 49.6716
2024-10-30 19:50:32: [2024-10-30 19:50:32] iter = 06120, loss = 26.7225
2024-10-30 19:50:36: [2024-10-30 19:50:36] iter = 06130, loss = 16.2132
2024-10-30 19:50:40: [2024-10-30 19:50:40] iter = 06140, loss = 27.1253
2024-10-30 19:50:43: [2024-10-30 19:50:43] iter = 06150, loss = 32.4773
2024-10-30 19:50:47: [2024-10-30 19:50:47] iter = 06160, loss = 3.3671
2024-10-30 19:50:51: [2024-10-30 19:50:51] iter = 06170, loss = 44.4393
2024-10-30 19:50:54: [2024-10-30 19:50:54] iter = 06180, loss = 43.5090
2024-10-30 19:50:58: [2024-10-30 19:50:58] iter = 06190, loss = 15.3786
2024-10-30 19:51:01: [2024-10-30 19:51:01] iter = 06200, loss = 20.7833
2024-10-30 19:51:05: [2024-10-30 19:51:05] iter = 06210, loss = 29.2663
2024-10-30 19:51:09: [2024-10-30 19:51:09] iter = 06220, loss = 73.0485
2024-10-30 19:51:12: [2024-10-30 19:51:12] iter = 06230, loss = 4.5959
2024-10-30 19:51:17: [2024-10-30 19:51:17] iter = 06240, loss = 4.0202
2024-10-30 19:51:21: [2024-10-30 19:51:21] iter = 06250, loss = 10.6696
2024-10-30 19:51:25: [2024-10-30 19:51:25] iter = 06260, loss = 12.0889
2024-10-30 19:51:29: [2024-10-30 19:51:29] iter = 06270, loss = 25.1647
2024-10-30 19:51:33: [2024-10-30 19:51:33] iter = 06280, loss = 82.1441
2024-10-30 19:51:38: [2024-10-30 19:51:38] iter = 06290, loss = 5.7269
2024-10-30 19:51:42: [2024-10-30 19:51:42] iter = 06300, loss = 15.0850
2024-10-30 19:51:46: [2024-10-30 19:51:46] iter = 06310, loss = 10.1542
2024-10-30 19:51:51: [2024-10-30 19:51:51] iter = 06320, loss = 4.5601
2024-10-30 19:51:54: [2024-10-30 19:51:54] iter = 06330, loss = 6.3534
2024-10-30 19:51:58: [2024-10-30 19:51:58] iter = 06340, loss = 21.7582
2024-10-30 19:52:01: [2024-10-30 19:52:01] iter = 06350, loss = 10.9139
2024-10-30 19:52:04: [2024-10-30 19:52:04] iter = 06360, loss = 44.6308
2024-10-30 19:52:08: [2024-10-30 19:52:08] iter = 06370, loss = 7.7249
2024-10-30 19:52:13: [2024-10-30 19:52:13] iter = 06380, loss = 43.4530
2024-10-30 19:52:16: [2024-10-30 19:52:16] iter = 06390, loss = 21.4616
2024-10-30 19:52:20: [2024-10-30 19:52:20] iter = 06400, loss = 18.8585
2024-10-30 19:52:24: [2024-10-30 19:52:24] iter = 06410, loss = 10.4159
2024-10-30 19:52:28: [2024-10-30 19:52:28] iter = 06420, loss = 16.7132
2024-10-30 19:52:31: [2024-10-30 19:52:31] iter = 06430, loss = 10.5760
2024-10-30 19:52:36: [2024-10-30 19:52:36] iter = 06440, loss = 9.4958
2024-10-30 19:52:40: [2024-10-30 19:52:40] iter = 06450, loss = 46.8719
2024-10-30 19:52:45: [2024-10-30 19:52:45] iter = 06460, loss = 29.9680
2024-10-30 19:52:49: [2024-10-30 19:52:49] iter = 06470, loss = 26.2372
2024-10-30 19:52:53: [2024-10-30 19:52:53] iter = 06480, loss = 30.8787
2024-10-30 19:52:56: [2024-10-30 19:52:56] iter = 06490, loss = 13.9167
2024-10-30 19:53:00: [2024-10-30 19:53:00] iter = 06500, loss = 33.9582
2024-10-30 19:53:03: [2024-10-30 19:53:03] iter = 06510, loss = 3.3699
2024-10-30 19:53:07: [2024-10-30 19:53:07] iter = 06520, loss = 19.7550
2024-10-30 19:53:12: [2024-10-30 19:53:12] iter = 06530, loss = 43.1189
2024-10-30 19:53:16: [2024-10-30 19:53:16] iter = 06540, loss = 86.6692
2024-10-30 19:53:20: [2024-10-30 19:53:20] iter = 06550, loss = 8.7352
2024-10-30 19:53:24: [2024-10-30 19:53:24] iter = 06560, loss = 23.4319
2024-10-30 19:53:29: [2024-10-30 19:53:29] iter = 06570, loss = 18.3063
2024-10-30 19:53:33: [2024-10-30 19:53:33] iter = 06580, loss = 3.8498
2024-10-30 19:53:37: [2024-10-30 19:53:37] iter = 06590, loss = 60.1706
2024-10-30 19:53:41: [2024-10-30 19:53:41] iter = 06600, loss = 55.1781
2024-10-30 19:53:45: [2024-10-30 19:53:45] iter = 06610, loss = 4.2511
2024-10-30 19:53:49: [2024-10-30 19:53:49] iter = 06620, loss = 17.5964
2024-10-30 19:53:52: [2024-10-30 19:53:52] iter = 06630, loss = 3.2351
2024-10-30 19:53:56: [2024-10-30 19:53:56] iter = 06640, loss = 5.2330
2024-10-30 19:54:00: [2024-10-30 19:54:00] iter = 06650, loss = 4.1756
2024-10-30 19:54:03: [2024-10-30 19:54:03] iter = 06660, loss = 16.9896
2024-10-30 19:54:07: [2024-10-30 19:54:07] iter = 06670, loss = 34.7332
2024-10-30 19:54:11: [2024-10-30 19:54:11] iter = 06680, loss = 10.4885
2024-10-30 19:54:16: [2024-10-30 19:54:16] iter = 06690, loss = 22.9509
2024-10-30 19:54:20: [2024-10-30 19:54:20] iter = 06700, loss = 8.8343
2024-10-30 19:54:23: [2024-10-30 19:54:23] iter = 06710, loss = 8.7096
2024-10-30 19:54:27: [2024-10-30 19:54:27] iter = 06720, loss = 42.4675
2024-10-30 19:54:32: [2024-10-30 19:54:32] iter = 06730, loss = 73.7676
2024-10-30 19:54:37: [2024-10-30 19:54:37] iter = 06740, loss = 23.6046
2024-10-30 19:54:40: [2024-10-30 19:54:40] iter = 06750, loss = 5.9369
2024-10-30 19:54:44: [2024-10-30 19:54:44] iter = 06760, loss = 54.5618
2024-10-30 19:54:49: [2024-10-30 19:54:49] iter = 06770, loss = 55.5491
2024-10-30 19:54:52: [2024-10-30 19:54:52] iter = 06780, loss = 13.6350
2024-10-30 19:54:56: [2024-10-30 19:54:56] iter = 06790, loss = 7.6908
2024-10-30 19:55:00: [2024-10-30 19:55:00] iter = 06800, loss = 12.8496
2024-10-30 19:55:04: [2024-10-30 19:55:04] iter = 06810, loss = 22.2283
2024-10-30 19:55:07: [2024-10-30 19:55:07] iter = 06820, loss = 4.7983
2024-10-30 19:55:11: [2024-10-30 19:55:11] iter = 06830, loss = 71.1514
2024-10-30 19:55:14: [2024-10-30 19:55:14] iter = 06840, loss = 9.6458
2024-10-30 19:55:17: [2024-10-30 19:55:17] iter = 06850, loss = 7.0075
2024-10-30 19:55:21: [2024-10-30 19:55:21] iter = 06860, loss = 7.2756
2024-10-30 19:55:25: [2024-10-30 19:55:25] iter = 06870, loss = 5.5559
2024-10-30 19:55:28: [2024-10-30 19:55:28] iter = 06880, loss = 45.8879
2024-10-30 19:55:32: [2024-10-30 19:55:32] iter = 06890, loss = 14.6198
2024-10-30 19:55:36: [2024-10-30 19:55:36] iter = 06900, loss = 14.1201
2024-10-30 19:55:42: [2024-10-30 19:55:42] iter = 06910, loss = 4.0135
2024-10-30 19:55:45: [2024-10-30 19:55:45] iter = 06920, loss = 3.7116
2024-10-30 19:55:49: [2024-10-30 19:55:49] iter = 06930, loss = 7.9884
2024-10-30 19:55:53: [2024-10-30 19:55:53] iter = 06940, loss = 12.5991
2024-10-30 19:55:57: [2024-10-30 19:55:57] iter = 06950, loss = 4.5711
2024-10-30 19:56:00: [2024-10-30 19:56:00] iter = 06960, loss = 24.4279
2024-10-30 19:56:02: [2024-10-30 19:56:02] iter = 06970, loss = 5.5237
2024-10-30 19:56:03: [2024-10-30 19:56:03] iter = 06980, loss = 4.8619
2024-10-30 19:56:07: [2024-10-30 19:56:07] iter = 06990, loss = 4.3589
2024-10-30 19:56:12: [2024-10-30 19:56:12] iter = 07000, loss = 4.4048
2024-10-30 19:56:14: [2024-10-30 19:56:14] iter = 07010, loss = 8.4906
2024-10-30 19:56:17: [2024-10-30 19:56:17] iter = 07020, loss = 13.6307
2024-10-30 19:56:21: [2024-10-30 19:56:21] iter = 07030, loss = 5.4171
2024-10-30 19:56:24: [2024-10-30 19:56:24] iter = 07040, loss = 16.4000
2024-10-30 19:56:29: [2024-10-30 19:56:29] iter = 07050, loss = 47.0210
2024-10-30 19:56:33: [2024-10-30 19:56:33] iter = 07060, loss = 30.3941
2024-10-30 19:56:36: [2024-10-30 19:56:36] iter = 07070, loss = 6.6030
2024-10-30 19:56:40: [2024-10-30 19:56:40] iter = 07080, loss = 21.5091
2024-10-30 19:56:44: [2024-10-30 19:56:44] iter = 07090, loss = 43.4773
2024-10-30 19:56:48: [2024-10-30 19:56:48] iter = 07100, loss = 5.4208
2024-10-30 19:56:51: [2024-10-30 19:56:51] iter = 07110, loss = 23.6794
2024-10-30 19:56:55: [2024-10-30 19:56:55] iter = 07120, loss = 15.5942
2024-10-30 19:56:59: [2024-10-30 19:56:59] iter = 07130, loss = 5.8827
2024-10-30 19:57:03: [2024-10-30 19:57:03] iter = 07140, loss = 6.5066
2024-10-30 19:57:07: [2024-10-30 19:57:07] iter = 07150, loss = 9.8488
2024-10-30 19:57:11: [2024-10-30 19:57:11] iter = 07160, loss = 12.7824
2024-10-30 19:57:15: [2024-10-30 19:57:15] iter = 07170, loss = 3.4605
2024-10-30 19:57:19: [2024-10-30 19:57:19] iter = 07180, loss = 5.3218
2024-10-30 19:57:23: [2024-10-30 19:57:23] iter = 07190, loss = 4.6749
2024-10-30 19:57:26: [2024-10-30 19:57:26] iter = 07200, loss = 29.9432
2024-10-30 19:57:29: [2024-10-30 19:57:29] iter = 07210, loss = 10.1693
2024-10-30 19:57:33: [2024-10-30 19:57:33] iter = 07220, loss = 22.1964
2024-10-30 19:57:37: [2024-10-30 19:57:37] iter = 07230, loss = 4.6742
2024-10-30 19:57:40: [2024-10-30 19:57:40] iter = 07240, loss = 5.1279
2024-10-30 19:57:44: [2024-10-30 19:57:44] iter = 07250, loss = 25.1192
2024-10-30 19:57:48: [2024-10-30 19:57:48] iter = 07260, loss = 5.3569
2024-10-30 19:57:52: [2024-10-30 19:57:52] iter = 07270, loss = 10.7371
2024-10-30 19:57:55: [2024-10-30 19:57:55] iter = 07280, loss = 28.1668
2024-10-30 19:57:58: [2024-10-30 19:57:58] iter = 07290, loss = 27.1187
2024-10-30 19:58:02: [2024-10-30 19:58:02] iter = 07300, loss = 5.3448
2024-10-30 19:58:05: [2024-10-30 19:58:05] iter = 07310, loss = 7.1390
2024-10-30 19:58:09: [2024-10-30 19:58:09] iter = 07320, loss = 3.8279
2024-10-30 19:58:12: [2024-10-30 19:58:12] iter = 07330, loss = 25.2555
2024-10-30 19:58:16: [2024-10-30 19:58:16] iter = 07340, loss = 36.6773
2024-10-30 19:58:20: [2024-10-30 19:58:20] iter = 07350, loss = 5.5525
2024-10-30 19:58:24: [2024-10-30 19:58:24] iter = 07360, loss = 18.7815
2024-10-30 19:58:27: [2024-10-30 19:58:27] iter = 07370, loss = 19.6169
2024-10-30 19:58:30: [2024-10-30 19:58:30] iter = 07380, loss = 26.4560
2024-10-30 19:58:34: [2024-10-30 19:58:34] iter = 07390, loss = 4.4352
2024-10-30 19:58:37: [2024-10-30 19:58:37] iter = 07400, loss = 38.4915
2024-10-30 19:58:41: [2024-10-30 19:58:41] iter = 07410, loss = 48.3664
2024-10-30 19:58:45: [2024-10-30 19:58:45] iter = 07420, loss = 4.3259
2024-10-30 19:58:46: [2024-10-30 19:58:46] iter = 07430, loss = 11.4437
2024-10-30 19:58:48: [2024-10-30 19:58:48] iter = 07440, loss = 6.7314
2024-10-30 19:58:51: [2024-10-30 19:58:51] iter = 07450, loss = 21.8551
2024-10-30 19:58:55: [2024-10-30 19:58:55] iter = 07460, loss = 11.9307
2024-10-30 19:58:59: [2024-10-30 19:58:59] iter = 07470, loss = 4.6439
2024-10-30 19:59:02: [2024-10-30 19:59:02] iter = 07480, loss = 17.5929
2024-10-30 19:59:06: [2024-10-30 19:59:06] iter = 07490, loss = 9.3243
2024-10-30 19:59:09: [2024-10-30 19:59:09] iter = 07500, loss = 5.7815
2024-10-30 19:59:13: [2024-10-30 19:59:13] iter = 07510, loss = 26.9976
2024-10-30 19:59:17: [2024-10-30 19:59:17] iter = 07520, loss = 9.5850
2024-10-30 19:59:21: [2024-10-30 19:59:21] iter = 07530, loss = 9.1117
2024-10-30 19:59:25: [2024-10-30 19:59:25] iter = 07540, loss = 10.0436
2024-10-30 19:59:29: [2024-10-30 19:59:29] iter = 07550, loss = 17.6927
2024-10-30 19:59:32: [2024-10-30 19:59:32] iter = 07560, loss = 18.7584
2024-10-30 19:59:34: [2024-10-30 19:59:34] iter = 07570, loss = 8.0261
2024-10-30 19:59:36: [2024-10-30 19:59:36] iter = 07580, loss = 6.9829
2024-10-30 19:59:38: [2024-10-30 19:59:38] iter = 07590, loss = 17.4275
2024-10-30 19:59:42: [2024-10-30 19:59:42] iter = 07600, loss = 29.6198
2024-10-30 19:59:46: [2024-10-30 19:59:46] iter = 07610, loss = 16.5049
2024-10-30 19:59:50: [2024-10-30 19:59:50] iter = 07620, loss = 4.3913
2024-10-30 19:59:54: [2024-10-30 19:59:54] iter = 07630, loss = 6.0345
2024-10-30 19:59:57: [2024-10-30 19:59:57] iter = 07640, loss = 5.2602
2024-10-30 20:00:01: [2024-10-30 20:00:01] iter = 07650, loss = 12.1001
2024-10-30 20:00:05: [2024-10-30 20:00:05] iter = 07660, loss = 16.5943
2024-10-30 20:00:08: [2024-10-30 20:00:08] iter = 07670, loss = 46.1280
2024-10-30 20:00:11: [2024-10-30 20:00:11] iter = 07680, loss = 7.4934
2024-10-30 20:00:15: [2024-10-30 20:00:15] iter = 07690, loss = 5.9924
2024-10-30 20:00:18: [2024-10-30 20:00:18] iter = 07700, loss = 15.5181
2024-10-30 20:00:21: [2024-10-30 20:00:21] iter = 07710, loss = 41.3151
2024-10-30 20:00:23: [2024-10-30 20:00:23] iter = 07720, loss = 19.6101
2024-10-30 20:00:26: [2024-10-30 20:00:26] iter = 07730, loss = 26.3081
2024-10-30 20:00:29: [2024-10-30 20:00:29] iter = 07740, loss = 4.1666
2024-10-30 20:00:32: [2024-10-30 20:00:32] iter = 07750, loss = 5.9057
2024-10-30 20:00:36: [2024-10-30 20:00:36] iter = 07760, loss = 50.1615
2024-10-30 20:00:39: [2024-10-30 20:00:39] iter = 07770, loss = 16.7683
2024-10-30 20:00:43: [2024-10-30 20:00:43] iter = 07780, loss = 50.2487
2024-10-30 20:00:48: [2024-10-30 20:00:48] iter = 07790, loss = 17.3742
2024-10-30 20:00:51: [2024-10-30 20:00:51] iter = 07800, loss = 19.9808
2024-10-30 20:00:55: [2024-10-30 20:00:55] iter = 07810, loss = 4.3489
2024-10-30 20:00:59: [2024-10-30 20:00:59] iter = 07820, loss = 71.3171
2024-10-30 20:01:03: [2024-10-30 20:01:03] iter = 07830, loss = 6.0307
2024-10-30 20:01:06: [2024-10-30 20:01:06] iter = 07840, loss = 3.6691
2024-10-30 20:01:10: [2024-10-30 20:01:10] iter = 07850, loss = 15.1014
2024-10-30 20:01:13: [2024-10-30 20:01:13] iter = 07860, loss = 23.9489
2024-10-30 20:01:17: [2024-10-30 20:01:17] iter = 07870, loss = 9.4401
2024-10-30 20:01:21: [2024-10-30 20:01:21] iter = 07880, loss = 4.9560
2024-10-30 20:01:24: [2024-10-30 20:01:24] iter = 07890, loss = 11.5644
2024-10-30 20:01:28: [2024-10-30 20:01:28] iter = 07900, loss = 7.1992
2024-10-30 20:01:31: [2024-10-30 20:01:31] iter = 07910, loss = 44.6921
2024-10-30 20:01:34: [2024-10-30 20:01:34] iter = 07920, loss = 24.0939
2024-10-30 20:01:38: [2024-10-30 20:01:38] iter = 07930, loss = 52.5795
2024-10-30 20:01:42: [2024-10-30 20:01:42] iter = 07940, loss = 18.3161
2024-10-30 20:01:46: [2024-10-30 20:01:46] iter = 07950, loss = 55.1285
2024-10-30 20:01:50: [2024-10-30 20:01:50] iter = 07960, loss = 57.5465
2024-10-30 20:01:54: [2024-10-30 20:01:54] iter = 07970, loss = 6.8143
2024-10-30 20:01:58: [2024-10-30 20:01:58] iter = 07980, loss = 15.7952
2024-10-30 20:02:02: [2024-10-30 20:02:02] iter = 07990, loss = 55.5808
2024-10-30 20:02:05: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 20:02:05: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:02:05: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 25577}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:04:18: Evaluate 5 random ConvNet, ACCmean = 0.2921 ACCstd = 0.0041
-------------------------
2024-10-30 20:04:18: Evaluate 5 random ConvNet, SENmean = 0.2841 SENstd = 0.0016
-------------------------
2024-10-30 20:04:18: Evaluate 5 random ConvNet, SPEmean = 0.8992 SPEstd = 0.0005
-------------------------
2024-10-30 20:04:18: Evaluate 5 random ConvNet, F!mean = 0.2219 F!std = 0.0025
-------------------------
2024-10-30 20:04:18: Evaluate 5 random ConvNet, mean = 0.2921 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:04:18: [2024-10-30 20:04:18] iter = 08000, loss = 43.2476
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:04:22: [2024-10-30 20:04:22] iter = 08010, loss = 10.2086
2024-10-30 20:04:26: [2024-10-30 20:04:26] iter = 08020, loss = 4.5907
2024-10-30 20:04:30: [2024-10-30 20:04:30] iter = 08030, loss = 22.3078
2024-10-30 20:04:34: [2024-10-30 20:04:34] iter = 08040, loss = 25.5896
2024-10-30 20:04:37: [2024-10-30 20:04:37] iter = 08050, loss = 12.2942
2024-10-30 20:04:41: [2024-10-30 20:04:41] iter = 08060, loss = 27.8119
2024-10-30 20:04:43: [2024-10-30 20:04:43] iter = 08070, loss = 3.6766
2024-10-30 20:04:47: [2024-10-30 20:04:47] iter = 08080, loss = 59.8075
2024-10-30 20:04:52: [2024-10-30 20:04:52] iter = 08090, loss = 4.7606
2024-10-30 20:04:56: [2024-10-30 20:04:56] iter = 08100, loss = 35.6454
2024-10-30 20:04:59: [2024-10-30 20:04:59] iter = 08110, loss = 7.6444
2024-10-30 20:05:03: [2024-10-30 20:05:03] iter = 08120, loss = 20.3629
2024-10-30 20:05:07: [2024-10-30 20:05:07] iter = 08130, loss = 6.1876
2024-10-30 20:05:11: [2024-10-30 20:05:11] iter = 08140, loss = 18.5309
2024-10-30 20:05:14: [2024-10-30 20:05:14] iter = 08150, loss = 4.2650
2024-10-30 20:05:18: [2024-10-30 20:05:18] iter = 08160, loss = 7.0265
2024-10-30 20:05:22: [2024-10-30 20:05:22] iter = 08170, loss = 17.2618
2024-10-30 20:05:26: [2024-10-30 20:05:26] iter = 08180, loss = 16.5224
2024-10-30 20:05:30: [2024-10-30 20:05:30] iter = 08190, loss = 50.1904
2024-10-30 20:05:34: [2024-10-30 20:05:34] iter = 08200, loss = 13.5998
2024-10-30 20:05:38: [2024-10-30 20:05:38] iter = 08210, loss = 12.8475
2024-10-30 20:05:41: [2024-10-30 20:05:41] iter = 08220, loss = 34.7766
2024-10-30 20:05:45: [2024-10-30 20:05:45] iter = 08230, loss = 23.2153
2024-10-30 20:05:48: [2024-10-30 20:05:48] iter = 08240, loss = 5.7141
2024-10-30 20:05:51: [2024-10-30 20:05:51] iter = 08250, loss = 10.2695
2024-10-30 20:05:55: [2024-10-30 20:05:55] iter = 08260, loss = 28.2139
2024-10-30 20:05:59: [2024-10-30 20:05:59] iter = 08270, loss = 9.2065
2024-10-30 20:06:02: [2024-10-30 20:06:02] iter = 08280, loss = 54.0964
2024-10-30 20:06:06: [2024-10-30 20:06:06] iter = 08290, loss = 43.3910
2024-10-30 20:06:10: [2024-10-30 20:06:10] iter = 08300, loss = 21.9768
2024-10-30 20:06:14: [2024-10-30 20:06:14] iter = 08310, loss = 4.6680
2024-10-30 20:06:18: [2024-10-30 20:06:18] iter = 08320, loss = 3.2943
2024-10-30 20:06:22: [2024-10-30 20:06:22] iter = 08330, loss = 25.0971
2024-10-30 20:06:23: [2024-10-30 20:06:23] iter = 08340, loss = 13.7545
2024-10-30 20:06:26: [2024-10-30 20:06:26] iter = 08350, loss = 16.3775
2024-10-30 20:06:29: [2024-10-30 20:06:29] iter = 08360, loss = 5.4985
2024-10-30 20:06:32: [2024-10-30 20:06:32] iter = 08370, loss = 76.8160
2024-10-30 20:06:37: [2024-10-30 20:06:37] iter = 08380, loss = 8.3113
2024-10-30 20:06:41: [2024-10-30 20:06:41] iter = 08390, loss = 10.6434
2024-10-30 20:06:45: [2024-10-30 20:06:45] iter = 08400, loss = 9.5538
2024-10-30 20:06:49: [2024-10-30 20:06:49] iter = 08410, loss = 19.4603
2024-10-30 20:06:53: [2024-10-30 20:06:53] iter = 08420, loss = 13.9704
2024-10-30 20:06:56: [2024-10-30 20:06:56] iter = 08430, loss = 92.8708
2024-10-30 20:06:59: [2024-10-30 20:06:59] iter = 08440, loss = 9.0632
2024-10-30 20:07:03: [2024-10-30 20:07:03] iter = 08450, loss = 65.7238
2024-10-30 20:07:07: [2024-10-30 20:07:07] iter = 08460, loss = 11.9862
2024-10-30 20:07:11: [2024-10-30 20:07:11] iter = 08470, loss = 44.7619
2024-10-30 20:07:14: [2024-10-30 20:07:14] iter = 08480, loss = 45.8873
2024-10-30 20:07:18: [2024-10-30 20:07:18] iter = 08490, loss = 5.0553
2024-10-30 20:07:21: [2024-10-30 20:07:21] iter = 08500, loss = 24.6312
2024-10-30 20:07:25: [2024-10-30 20:07:25] iter = 08510, loss = 3.6561
2024-10-30 20:07:29: [2024-10-30 20:07:29] iter = 08520, loss = 21.5732
2024-10-30 20:07:33: [2024-10-30 20:07:33] iter = 08530, loss = 70.3393
2024-10-30 20:07:37: [2024-10-30 20:07:37] iter = 08540, loss = 3.9147
2024-10-30 20:07:41: [2024-10-30 20:07:41] iter = 08550, loss = 6.8399
2024-10-30 20:07:45: [2024-10-30 20:07:45] iter = 08560, loss = 4.4312
2024-10-30 20:07:50: [2024-10-30 20:07:50] iter = 08570, loss = 3.2163
2024-10-30 20:07:54: [2024-10-30 20:07:54] iter = 08580, loss = 14.3053
2024-10-30 20:07:57: [2024-10-30 20:07:57] iter = 08590, loss = 5.2962
2024-10-30 20:08:00: [2024-10-30 20:08:00] iter = 08600, loss = 12.7706
2024-10-30 20:08:03: [2024-10-30 20:08:03] iter = 08610, loss = 18.0119
2024-10-30 20:08:07: [2024-10-30 20:08:07] iter = 08620, loss = 6.0547
2024-10-30 20:08:11: [2024-10-30 20:08:11] iter = 08630, loss = 85.8779
2024-10-30 20:08:14: [2024-10-30 20:08:14] iter = 08640, loss = 74.5056
2024-10-30 20:08:19: [2024-10-30 20:08:19] iter = 08650, loss = 4.5902
2024-10-30 20:08:23: [2024-10-30 20:08:23] iter = 08660, loss = 11.9650
2024-10-30 20:08:27: [2024-10-30 20:08:27] iter = 08670, loss = 17.6515
2024-10-30 20:08:31: [2024-10-30 20:08:31] iter = 08680, loss = 61.1668
2024-10-30 20:08:35: [2024-10-30 20:08:35] iter = 08690, loss = 10.2516
2024-10-30 20:08:38: [2024-10-30 20:08:38] iter = 08700, loss = 24.6364
2024-10-30 20:08:41: [2024-10-30 20:08:41] iter = 08710, loss = 23.1493
2024-10-30 20:08:44: [2024-10-30 20:08:44] iter = 08720, loss = 27.3325
2024-10-30 20:08:46: [2024-10-30 20:08:46] iter = 08730, loss = 40.4222
2024-10-30 20:08:50: [2024-10-30 20:08:50] iter = 08740, loss = 14.5786
2024-10-30 20:08:53: [2024-10-30 20:08:53] iter = 08750, loss = 48.4555
2024-10-30 20:08:57: [2024-10-30 20:08:57] iter = 08760, loss = 4.6627
2024-10-30 20:09:02: [2024-10-30 20:09:02] iter = 08770, loss = 8.9503
2024-10-30 20:09:06: [2024-10-30 20:09:06] iter = 08780, loss = 10.9609
2024-10-30 20:09:10: [2024-10-30 20:09:10] iter = 08790, loss = 11.0680
2024-10-30 20:09:14: [2024-10-30 20:09:14] iter = 08800, loss = 41.3426
2024-10-30 20:09:18: [2024-10-30 20:09:18] iter = 08810, loss = 18.6572
2024-10-30 20:09:22: [2024-10-30 20:09:22] iter = 08820, loss = 33.6902
2024-10-30 20:09:25: [2024-10-30 20:09:25] iter = 08830, loss = 32.8997
2024-10-30 20:09:29: [2024-10-30 20:09:29] iter = 08840, loss = 35.1836
2024-10-30 20:09:32: [2024-10-30 20:09:32] iter = 08850, loss = 57.4099
2024-10-30 20:09:35: [2024-10-30 20:09:35] iter = 08860, loss = 10.5632
2024-10-30 20:09:38: [2024-10-30 20:09:38] iter = 08870, loss = 8.9826
2024-10-30 20:09:42: [2024-10-30 20:09:42] iter = 08880, loss = 5.2034
2024-10-30 20:09:45: [2024-10-30 20:09:45] iter = 08890, loss = 7.7437
2024-10-30 20:09:49: [2024-10-30 20:09:49] iter = 08900, loss = 4.8243
2024-10-30 20:09:52: [2024-10-30 20:09:52] iter = 08910, loss = 38.8768
2024-10-30 20:09:56: [2024-10-30 20:09:56] iter = 08920, loss = 11.3318
2024-10-30 20:09:58: [2024-10-30 20:09:58] iter = 08930, loss = 4.9396
2024-10-30 20:10:00: [2024-10-30 20:10:00] iter = 08940, loss = 10.2321
2024-10-30 20:10:04: [2024-10-30 20:10:04] iter = 08950, loss = 43.4448
2024-10-30 20:10:07: [2024-10-30 20:10:07] iter = 08960, loss = 21.9580
2024-10-30 20:10:10: [2024-10-30 20:10:10] iter = 08970, loss = 29.0893
2024-10-30 20:10:14: [2024-10-30 20:10:14] iter = 08980, loss = 10.6613
2024-10-30 20:10:17: [2024-10-30 20:10:17] iter = 08990, loss = 4.9638
2024-10-30 20:10:21: [2024-10-30 20:10:21] iter = 09000, loss = 18.7672
2024-10-30 20:10:24: [2024-10-30 20:10:24] iter = 09010, loss = 6.5226
2024-10-30 20:10:28: [2024-10-30 20:10:28] iter = 09020, loss = 12.7946
2024-10-30 20:10:32: [2024-10-30 20:10:32] iter = 09030, loss = 16.6602
2024-10-30 20:10:35: [2024-10-30 20:10:35] iter = 09040, loss = 10.0612
2024-10-30 20:10:39: [2024-10-30 20:10:39] iter = 09050, loss = 27.5298
2024-10-30 20:10:43: [2024-10-30 20:10:43] iter = 09060, loss = 4.7782
2024-10-30 20:10:46: [2024-10-30 20:10:46] iter = 09070, loss = 13.6708
2024-10-30 20:10:50: [2024-10-30 20:10:50] iter = 09080, loss = 15.3716
2024-10-30 20:10:55: [2024-10-30 20:10:55] iter = 09090, loss = 24.0929
2024-10-30 20:10:59: [2024-10-30 20:10:59] iter = 09100, loss = 4.4791
2024-10-30 20:11:02: [2024-10-30 20:11:02] iter = 09110, loss = 20.8024
2024-10-30 20:11:06: [2024-10-30 20:11:06] iter = 09120, loss = 18.8367
2024-10-30 20:11:09: [2024-10-30 20:11:09] iter = 09130, loss = 10.3385
2024-10-30 20:11:12: [2024-10-30 20:11:12] iter = 09140, loss = 40.0441
2024-10-30 20:11:17: [2024-10-30 20:11:17] iter = 09150, loss = 25.7191
2024-10-30 20:11:20: [2024-10-30 20:11:20] iter = 09160, loss = 7.9508
2024-10-30 20:11:24: [2024-10-30 20:11:24] iter = 09170, loss = 14.7329
2024-10-30 20:11:28: [2024-10-30 20:11:28] iter = 09180, loss = 15.9086
2024-10-30 20:11:31: [2024-10-30 20:11:31] iter = 09190, loss = 29.5895
2024-10-30 20:11:34: [2024-10-30 20:11:34] iter = 09200, loss = 6.4491
2024-10-30 20:11:37: [2024-10-30 20:11:37] iter = 09210, loss = 18.7197
2024-10-30 20:11:41: [2024-10-30 20:11:41] iter = 09220, loss = 4.1034
2024-10-30 20:11:44: [2024-10-30 20:11:44] iter = 09230, loss = 53.6609
2024-10-30 20:11:46: [2024-10-30 20:11:46] iter = 09240, loss = 14.8417
2024-10-30 20:11:49: [2024-10-30 20:11:49] iter = 09250, loss = 10.9458
2024-10-30 20:11:52: [2024-10-30 20:11:52] iter = 09260, loss = 18.8483
2024-10-30 20:11:55: [2024-10-30 20:11:55] iter = 09270, loss = 27.3340
2024-10-30 20:11:58: [2024-10-30 20:11:58] iter = 09280, loss = 5.4943
2024-10-30 20:12:02: [2024-10-30 20:12:02] iter = 09290, loss = 5.5562
2024-10-30 20:12:04: [2024-10-30 20:12:04] iter = 09300, loss = 23.6373
2024-10-30 20:12:07: [2024-10-30 20:12:07] iter = 09310, loss = 35.5368
2024-10-30 20:12:10: [2024-10-30 20:12:10] iter = 09320, loss = 11.4763
2024-10-30 20:12:14: [2024-10-30 20:12:14] iter = 09330, loss = 4.5957
2024-10-30 20:12:18: [2024-10-30 20:12:18] iter = 09340, loss = 74.4006
2024-10-30 20:12:21: [2024-10-30 20:12:21] iter = 09350, loss = 11.4841
2024-10-30 20:12:25: [2024-10-30 20:12:25] iter = 09360, loss = 5.1676
2024-10-30 20:12:29: [2024-10-30 20:12:29] iter = 09370, loss = 4.0777
2024-10-30 20:12:32: [2024-10-30 20:12:32] iter = 09380, loss = 3.4748
2024-10-30 20:12:36: [2024-10-30 20:12:36] iter = 09390, loss = 19.8811
2024-10-30 20:12:39: [2024-10-30 20:12:39] iter = 09400, loss = 6.5424
2024-10-30 20:12:41: [2024-10-30 20:12:41] iter = 09410, loss = 20.6346
2024-10-30 20:12:43: [2024-10-30 20:12:43] iter = 09420, loss = 27.6031
2024-10-30 20:12:46: [2024-10-30 20:12:46] iter = 09430, loss = 5.1804
2024-10-30 20:12:50: [2024-10-30 20:12:50] iter = 09440, loss = 7.4242
2024-10-30 20:12:54: [2024-10-30 20:12:54] iter = 09450, loss = 15.9176
2024-10-30 20:12:58: [2024-10-30 20:12:58] iter = 09460, loss = 11.4369
2024-10-30 20:13:01: [2024-10-30 20:13:01] iter = 09470, loss = 52.5578
2024-10-30 20:13:03: [2024-10-30 20:13:03] iter = 09480, loss = 4.8878
2024-10-30 20:13:05: [2024-10-30 20:13:05] iter = 09490, loss = 19.6122
2024-10-30 20:13:10: [2024-10-30 20:13:10] iter = 09500, loss = 31.3621
2024-10-30 20:13:15: [2024-10-30 20:13:15] iter = 09510, loss = 10.1348
2024-10-30 20:13:19: [2024-10-30 20:13:19] iter = 09520, loss = 42.8725
2024-10-30 20:13:21: [2024-10-30 20:13:21] iter = 09530, loss = 7.4288
2024-10-30 20:13:26: [2024-10-30 20:13:26] iter = 09540, loss = 41.6777
2024-10-30 20:13:30: [2024-10-30 20:13:30] iter = 09550, loss = 12.1039
2024-10-30 20:13:34: [2024-10-30 20:13:34] iter = 09560, loss = 10.9094
2024-10-30 20:13:39: [2024-10-30 20:13:39] iter = 09570, loss = 20.1622
2024-10-30 20:13:43: [2024-10-30 20:13:43] iter = 09580, loss = 7.5849
2024-10-30 20:13:47: [2024-10-30 20:13:47] iter = 09590, loss = 19.1836
2024-10-30 20:13:49: [2024-10-30 20:13:49] iter = 09600, loss = 14.5766
2024-10-30 20:13:52: [2024-10-30 20:13:52] iter = 09610, loss = 32.9428
2024-10-30 20:13:56: [2024-10-30 20:13:56] iter = 09620, loss = 13.8871
2024-10-30 20:14:00: [2024-10-30 20:14:00] iter = 09630, loss = 5.2443
2024-10-30 20:14:04: [2024-10-30 20:14:04] iter = 09640, loss = 10.1964
2024-10-30 20:14:05: [2024-10-30 20:14:05] iter = 09650, loss = 3.0309
2024-10-30 20:14:09: [2024-10-30 20:14:09] iter = 09660, loss = 23.6633
2024-10-30 20:14:13: [2024-10-30 20:14:13] iter = 09670, loss = 29.0229
2024-10-30 20:14:17: [2024-10-30 20:14:17] iter = 09680, loss = 34.1230
2024-10-30 20:14:20: [2024-10-30 20:14:20] iter = 09690, loss = 11.4112
2024-10-30 20:14:23: [2024-10-30 20:14:23] iter = 09700, loss = 10.3396
2024-10-30 20:14:27: [2024-10-30 20:14:27] iter = 09710, loss = 3.9725
2024-10-30 20:14:30: [2024-10-30 20:14:30] iter = 09720, loss = 35.3080
2024-10-30 20:14:34: [2024-10-30 20:14:34] iter = 09730, loss = 9.0607
2024-10-30 20:14:37: [2024-10-30 20:14:37] iter = 09740, loss = 4.0158
2024-10-30 20:14:41: [2024-10-30 20:14:41] iter = 09750, loss = 4.3179
2024-10-30 20:14:45: [2024-10-30 20:14:45] iter = 09760, loss = 9.3721
2024-10-30 20:14:48: [2024-10-30 20:14:48] iter = 09770, loss = 8.7437
2024-10-30 20:14:52: [2024-10-30 20:14:52] iter = 09780, loss = 4.5742
2024-10-30 20:14:56: [2024-10-30 20:14:56] iter = 09790, loss = 28.7060
2024-10-30 20:15:00: [2024-10-30 20:15:00] iter = 09800, loss = 5.7611
2024-10-30 20:15:05: [2024-10-30 20:15:05] iter = 09810, loss = 47.7738
2024-10-30 20:15:09: [2024-10-30 20:15:09] iter = 09820, loss = 10.9755
2024-10-30 20:15:13: [2024-10-30 20:15:13] iter = 09830, loss = 40.0919
2024-10-30 20:15:17: [2024-10-30 20:15:17] iter = 09840, loss = 28.2972
2024-10-30 20:15:22: [2024-10-30 20:15:22] iter = 09850, loss = 53.3441
2024-10-30 20:15:25: [2024-10-30 20:15:25] iter = 09860, loss = 4.2920
2024-10-30 20:15:29: [2024-10-30 20:15:29] iter = 09870, loss = 19.2186
2024-10-30 20:15:34: [2024-10-30 20:15:34] iter = 09880, loss = 18.3611
2024-10-30 20:15:38: [2024-10-30 20:15:38] iter = 09890, loss = 37.3009
2024-10-30 20:15:42: [2024-10-30 20:15:42] iter = 09900, loss = 65.3325
2024-10-30 20:15:46: [2024-10-30 20:15:46] iter = 09910, loss = 20.6648
2024-10-30 20:15:51: [2024-10-30 20:15:51] iter = 09920, loss = 26.5737
2024-10-30 20:15:53: [2024-10-30 20:15:53] iter = 09930, loss = 37.8956
2024-10-30 20:15:56: [2024-10-30 20:15:56] iter = 09940, loss = 3.9393
2024-10-30 20:16:00: [2024-10-30 20:16:00] iter = 09950, loss = 48.3854
2024-10-30 20:16:04: [2024-10-30 20:16:04] iter = 09960, loss = 9.3213
2024-10-30 20:16:09: [2024-10-30 20:16:09] iter = 09970, loss = 4.8558
2024-10-30 20:16:14: [2024-10-30 20:16:14] iter = 09980, loss = 69.4381
2024-10-30 20:16:18: [2024-10-30 20:16:18] iter = 09990, loss = 25.3274
2024-10-30 20:16:21: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 20:16:21: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:16:21: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 81014}

[2024-10-30 18:17:51] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.003303 train acc = 1.0000, test acc = 0.3396, test_sen =0.3132, test_spe =0.9054, test_f1 =0.2781
[2024-10-30 18:18:21] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.062145 train acc = 0.9875, test acc = 0.3559, test_sen =0.3143, test_spe =0.9068, test_f1 =0.2833
[2024-10-30 18:18:47] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.010124 train acc = 1.0000, test acc = 0.3608, test_sen =0.3205, test_spe =0.9077, test_f1 =0.2875
[2024-10-30 18:19:13] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.067898 train acc = 0.9875, test acc = 0.3441, test_sen =0.3108, test_spe =0.9057, test_f1 =0.2759
[2024-10-30 18:32:09] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.002876 train acc = 1.0000, test acc = 0.3164, test_sen =0.2994, test_spe =0.9031, test_f1 =0.2614
[2024-10-30 18:32:41] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.005759 train acc = 1.0000, test acc = 0.3165, test_sen =0.3034, test_spe =0.9038, test_f1 =0.2657
[2024-10-30 18:33:10] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.034713 train acc = 1.0000, test acc = 0.3088, test_sen =0.2959, test_spe =0.9023, test_f1 =0.2560
[2024-10-30 18:33:40] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.004769 train acc = 1.0000, test acc = 0.3071, test_sen =0.2972, test_spe =0.9025, test_f1 =0.2596
[2024-10-30 18:34:08] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.036399 train acc = 1.0000, test acc = 0.3176, test_sen =0.3051, test_spe =0.9037, test_f1 =0.2700
[2024-10-30 18:46:46] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.002567 train acc = 1.0000, test acc = 0.3257, test_sen =0.3042, test_spe =0.9053, test_f1 =0.2586
[2024-10-30 18:47:12] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.071533 train acc = 1.0000, test acc = 0.3217, test_sen =0.3064, test_spe =0.9050, test_f1 =0.2547
[2024-10-30 18:47:40] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.004532 train acc = 1.0000, test acc = 0.3406, test_sen =0.3093, test_spe =0.9067, test_f1 =0.2663
[2024-10-30 18:48:08] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.010542 train acc = 1.0000, test acc = 0.3312, test_sen =0.3111, test_spe =0.9062, test_f1 =0.2637
[2024-10-30 18:48:37] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.004320 train acc = 1.0000, test acc = 0.3411, test_sen =0.3058, test_spe =0.9069, test_f1 =0.2597
[2024-10-30 19:01:37] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.004184 train acc = 1.0000, test acc = 0.3828, test_sen =0.3251, test_spe =0.9109, test_f1 =0.2931
[2024-10-30 19:02:05] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.009774 train acc = 1.0000, test acc = 0.3843, test_sen =0.3242, test_spe =0.9110, test_f1 =0.2919
[2024-10-30 19:02:31] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.003720 train acc = 1.0000, test acc = 0.3785, test_sen =0.3264, test_spe =0.9104, test_f1 =0.2916
[2024-10-30 19:03:01] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.002612 train acc = 1.0000, test acc = 0.3913, test_sen =0.3251, test_spe =0.9116, test_f1 =0.2948
[2024-10-30 19:03:31] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.006184 train acc = 1.0000, test acc = 0.3832, test_sen =0.3216, test_spe =0.9106, test_f1 =0.2889
[2024-10-30 19:04:27] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.069218 train acc = 0.9875, test acc = 0.2532, test_sen =0.2345, test_spe =0.8916, test_f1 =0.2170
[2024-10-30 19:04:59] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.029982 train acc = 1.0000, test acc = 0.2709, test_sen =0.2387, test_spe =0.8926, test_f1 =0.2240
[2024-10-30 19:05:26] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.001488 train acc = 1.0000, test acc = 0.2594, test_sen =0.2410, test_spe =0.8924, test_f1 =0.2213
[2024-10-30 19:05:53] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.059944 train acc = 0.9875, test acc = 0.2582, test_sen =0.2373, test_spe =0.8922, test_f1 =0.2194
[2024-10-30 19:06:22] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.129265 train acc = 0.9625, test acc = 0.2669, test_sen =0.2377, test_spe =0.8928, test_f1 =0.2244
[2024-10-30 19:19:10] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.000956 train acc = 1.0000, test acc = 0.2620, test_sen =0.2624, test_spe =0.8958, test_f1 =0.2070
[2024-10-30 19:19:38] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.001367 train acc = 1.0000, test acc = 0.2733, test_sen =0.2670, test_spe =0.8972, test_f1 =0.2131
[2024-10-30 19:20:04] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.009290 train acc = 1.0000, test acc = 0.2767, test_sen =0.2726, test_spe =0.8977, test_f1 =0.2199
[2024-10-30 19:20:33] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.082237 train acc = 0.9875, test acc = 0.2632, test_sen =0.2676, test_spe =0.8961, test_f1 =0.2134
[2024-10-30 19:21:01] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.047990 train acc = 0.9875, test acc = 0.2560, test_sen =0.2658, test_spe =0.8951, test_f1 =0.2062
[2024-10-30 19:33:28] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.003041 train acc = 1.0000, test acc = 0.3832, test_sen =0.3164, test_spe =0.9104, test_f1 =0.2992
[2024-10-30 19:33:56] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.102414 train acc = 0.9875, test acc = 0.3716, test_sen =0.3141, test_spe =0.9093, test_f1 =0.2969
[2024-10-30 19:34:21] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.001879 train acc = 1.0000, test acc = 0.3720, test_sen =0.3096, test_spe =0.9093, test_f1 =0.2937
[2024-10-30 19:34:48] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.097574 train acc = 0.9875, test acc = 0.3829, test_sen =0.3161, test_spe =0.9104, test_f1 =0.3011
[2024-10-30 19:35:16] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.003295 train acc = 1.0000, test acc = 0.3821, test_sen =0.3139, test_spe =0.9103, test_f1 =0.2995
[2024-10-30 19:47:54] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.005911 train acc = 1.0000, test acc = 0.3640, test_sen =0.3044, test_spe =0.9087, test_f1 =0.2688
[2024-10-30 19:48:22] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.008145 train acc = 1.0000, test acc = 0.3451, test_sen =0.2994, test_spe =0.9065, test_f1 =0.2599
[2024-10-30 19:48:47] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.013006 train acc = 1.0000, test acc = 0.3360, test_sen =0.2905, test_spe =0.9051, test_f1 =0.2544
[2024-10-30 19:49:16] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.007470 train acc = 1.0000, test acc = 0.3434, test_sen =0.2942, test_spe =0.9059, test_f1 =0.2592
[2024-10-30 19:49:45] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.002214 train acc = 1.0000, test acc = 0.3270, test_sen =0.2881, test_spe =0.9043, test_f1 =0.2469
[2024-10-30 20:02:29] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.009962 train acc = 1.0000, test acc = 0.2903, test_sen =0.2849, test_spe =0.8990, test_f1 =0.2217
[2024-10-30 20:02:54] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.004388 train acc = 1.0000, test acc = 0.2937, test_sen =0.2838, test_spe =0.8993, test_f1 =0.2188
[2024-10-30 20:03:20] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.011821 train acc = 1.0000, test acc = 0.2908, test_sen =0.2864, test_spe =0.8995, test_f1 =0.2238
[2024-10-30 20:03:46] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.009569 train acc = 1.0000, test acc = 0.2990, test_sen =0.2838, test_spe =0.9000, test_f1 =0.2255
[2024-10-30 20:04:18] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.035303 train acc = 1.0000, test acc = 0.2867, test_sen =0.2816, test_spe =0.8985, test_f1 =0.2199
[2024-10-30 20:16:50] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.000951 train acc = 1.0000, test acc = 0.4066, test_sen =0.2981, test_spe =0.9113, test_f1 =0.2770
[2024-10-30 20:17:21] Evaluate_01: epoch = 1000 train time = 26 s train loss = 0.004536 train acc = 1.0000, test acc = 0.3977, test_sen =0.3010, test_spe =0.9109, test_f1 =0.2810/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:18:52: Evaluate 5 random ConvNet, ACCmean = 0.3997 ACCstd = 0.0041
-------------------------
2024-10-30 20:18:52: Evaluate 5 random ConvNet, SENmean = 0.2996 SENstd = 0.0030
-------------------------
2024-10-30 20:18:52: Evaluate 5 random ConvNet, SPEmean = 0.9111 SPEstd = 0.0004
-------------------------
2024-10-30 20:18:52: Evaluate 5 random ConvNet, F!mean = 0.2781 F!std = 0.0021
-------------------------
2024-10-30 20:18:52: Evaluate 5 random ConvNet, mean = 0.3997 std = 0.0041
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:18:52: [2024-10-30 20:18:52] iter = 10000, loss = 15.3394
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:18:57: [2024-10-30 20:18:57] iter = 10010, loss = 22.8578
2024-10-30 20:19:00: [2024-10-30 20:19:00] iter = 10020, loss = 19.9608
2024-10-30 20:19:04: [2024-10-30 20:19:04] iter = 10030, loss = 42.0890
2024-10-30 20:19:07: [2024-10-30 20:19:07] iter = 10040, loss = 4.9668
2024-10-30 20:19:11: [2024-10-30 20:19:11] iter = 10050, loss = 11.8263
2024-10-30 20:19:13: [2024-10-30 20:19:13] iter = 10060, loss = 40.7374
2024-10-30 20:19:17: [2024-10-30 20:19:17] iter = 10070, loss = 29.7248
2024-10-30 20:19:22: [2024-10-30 20:19:22] iter = 10080, loss = 19.7410
2024-10-30 20:19:26: [2024-10-30 20:19:26] iter = 10090, loss = 14.9311
2024-10-30 20:19:31: [2024-10-30 20:19:31] iter = 10100, loss = 27.3217
2024-10-30 20:19:35: [2024-10-30 20:19:35] iter = 10110, loss = 8.0342
2024-10-30 20:19:39: [2024-10-30 20:19:39] iter = 10120, loss = 7.2708
2024-10-30 20:19:43: [2024-10-30 20:19:43] iter = 10130, loss = 13.9497
2024-10-30 20:19:47: [2024-10-30 20:19:47] iter = 10140, loss = 5.3471
2024-10-30 20:19:51: [2024-10-30 20:19:51] iter = 10150, loss = 60.3237
2024-10-30 20:19:55: [2024-10-30 20:19:55] iter = 10160, loss = 11.8046
2024-10-30 20:19:58: [2024-10-30 20:19:58] iter = 10170, loss = 3.6596
2024-10-30 20:20:03: [2024-10-30 20:20:03] iter = 10180, loss = 14.7237
2024-10-30 20:20:06: [2024-10-30 20:20:06] iter = 10190, loss = 11.1865
2024-10-30 20:20:11: [2024-10-30 20:20:11] iter = 10200, loss = 25.6380
2024-10-30 20:20:15: [2024-10-30 20:20:15] iter = 10210, loss = 4.4117
2024-10-30 20:20:18: [2024-10-30 20:20:18] iter = 10220, loss = 4.4635
2024-10-30 20:20:21: [2024-10-30 20:20:21] iter = 10230, loss = 57.9450
2024-10-30 20:20:24: [2024-10-30 20:20:24] iter = 10240, loss = 11.1220
2024-10-30 20:20:28: [2024-10-30 20:20:28] iter = 10250, loss = 19.9678
2024-10-30 20:20:31: [2024-10-30 20:20:31] iter = 10260, loss = 4.8527
2024-10-30 20:20:35: [2024-10-30 20:20:35] iter = 10270, loss = 24.0425
2024-10-30 20:20:39: [2024-10-30 20:20:39] iter = 10280, loss = 5.6240
2024-10-30 20:20:42: [2024-10-30 20:20:42] iter = 10290, loss = 36.7352
2024-10-30 20:20:47: [2024-10-30 20:20:47] iter = 10300, loss = 27.6927
2024-10-30 20:20:52: [2024-10-30 20:20:52] iter = 10310, loss = 3.3837
2024-10-30 20:20:56: [2024-10-30 20:20:56] iter = 10320, loss = 4.0481
2024-10-30 20:21:01: [2024-10-30 20:21:01] iter = 10330, loss = 12.6514
2024-10-30 20:21:05: [2024-10-30 20:21:05] iter = 10340, loss = 4.7304
2024-10-30 20:21:08: [2024-10-30 20:21:08] iter = 10350, loss = 5.8432
2024-10-30 20:21:12: [2024-10-30 20:21:12] iter = 10360, loss = 7.7987
2024-10-30 20:21:17: [2024-10-30 20:21:17] iter = 10370, loss = 9.5217
2024-10-30 20:21:21: [2024-10-30 20:21:21] iter = 10380, loss = 24.2512
2024-10-30 20:21:25: [2024-10-30 20:21:25] iter = 10390, loss = 15.9669
2024-10-30 20:21:30: [2024-10-30 20:21:30] iter = 10400, loss = 16.0701
2024-10-30 20:21:35: [2024-10-30 20:21:35] iter = 10410, loss = 11.9788
2024-10-30 20:21:38: [2024-10-30 20:21:38] iter = 10420, loss = 101.6996
2024-10-30 20:21:43: [2024-10-30 20:21:43] iter = 10430, loss = 15.6760
2024-10-30 20:21:47: [2024-10-30 20:21:47] iter = 10440, loss = 19.6262
2024-10-30 20:21:50: [2024-10-30 20:21:50] iter = 10450, loss = 10.9837
2024-10-30 20:21:54: [2024-10-30 20:21:54] iter = 10460, loss = 18.4970
2024-10-30 20:21:58: [2024-10-30 20:21:58] iter = 10470, loss = 73.8387
2024-10-30 20:22:01: [2024-10-30 20:22:01] iter = 10480, loss = 31.6815
2024-10-30 20:22:05: [2024-10-30 20:22:05] iter = 10490, loss = 17.5660
2024-10-30 20:22:08: [2024-10-30 20:22:08] iter = 10500, loss = 4.5425
2024-10-30 20:22:12: [2024-10-30 20:22:12] iter = 10510, loss = 10.2395
2024-10-30 20:22:16: [2024-10-30 20:22:16] iter = 10520, loss = 6.7830
2024-10-30 20:22:21: [2024-10-30 20:22:21] iter = 10530, loss = 28.9340
2024-10-30 20:22:24: [2024-10-30 20:22:24] iter = 10540, loss = 9.4105
2024-10-30 20:22:27: [2024-10-30 20:22:27] iter = 10550, loss = 7.7552
2024-10-30 20:22:32: [2024-10-30 20:22:32] iter = 10560, loss = 3.8886
2024-10-30 20:22:36: [2024-10-30 20:22:36] iter = 10570, loss = 10.6483
2024-10-30 20:22:41: [2024-10-30 20:22:41] iter = 10580, loss = 12.6133
2024-10-30 20:22:44: [2024-10-30 20:22:44] iter = 10590, loss = 4.5503
2024-10-30 20:22:48: [2024-10-30 20:22:48] iter = 10600, loss = 11.4332
2024-10-30 20:22:53: [2024-10-30 20:22:53] iter = 10610, loss = 54.8885
2024-10-30 20:22:56: [2024-10-30 20:22:56] iter = 10620, loss = 7.5105
2024-10-30 20:23:01: [2024-10-30 20:23:01] iter = 10630, loss = 3.9402
2024-10-30 20:23:06: [2024-10-30 20:23:06] iter = 10640, loss = 12.5233
2024-10-30 20:23:10: [2024-10-30 20:23:10] iter = 10650, loss = 14.7459
2024-10-30 20:23:14: [2024-10-30 20:23:14] iter = 10660, loss = 39.0506
2024-10-30 20:23:18: [2024-10-30 20:23:18] iter = 10670, loss = 18.2034
2024-10-30 20:23:22: [2024-10-30 20:23:22] iter = 10680, loss = 12.3317
2024-10-30 20:23:26: [2024-10-30 20:23:26] iter = 10690, loss = 5.0367
2024-10-30 20:23:30: [2024-10-30 20:23:30] iter = 10700, loss = 11.0634
2024-10-30 20:23:34: [2024-10-30 20:23:34] iter = 10710, loss = 9.1594
2024-10-30 20:23:37: [2024-10-30 20:23:37] iter = 10720, loss = 19.5366
2024-10-30 20:23:42: [2024-10-30 20:23:42] iter = 10730, loss = 15.9652
2024-10-30 20:23:45: [2024-10-30 20:23:45] iter = 10740, loss = 25.9553
2024-10-30 20:23:50: [2024-10-30 20:23:50] iter = 10750, loss = 4.4607
2024-10-30 20:23:54: [2024-10-30 20:23:54] iter = 10760, loss = 4.1045
2024-10-30 20:23:59: [2024-10-30 20:23:59] iter = 10770, loss = 11.7560
2024-10-30 20:24:04: [2024-10-30 20:24:04] iter = 10780, loss = 4.0403
2024-10-30 20:24:07: [2024-10-30 20:24:07] iter = 10790, loss = 35.3421
2024-10-30 20:24:10: [2024-10-30 20:24:10] iter = 10800, loss = 7.8417
2024-10-30 20:24:14: [2024-10-30 20:24:14] iter = 10810, loss = 11.6540
2024-10-30 20:24:20: [2024-10-30 20:24:20] iter = 10820, loss = 4.2641
2024-10-30 20:24:24: [2024-10-30 20:24:24] iter = 10830, loss = 19.0886
2024-10-30 20:24:28: [2024-10-30 20:24:28] iter = 10840, loss = 10.9668
2024-10-30 20:24:32: [2024-10-30 20:24:32] iter = 10850, loss = 23.9629
2024-10-30 20:24:36: [2024-10-30 20:24:36] iter = 10860, loss = 8.0367
2024-10-30 20:24:39: [2024-10-30 20:24:39] iter = 10870, loss = 38.3197
2024-10-30 20:24:43: [2024-10-30 20:24:43] iter = 10880, loss = 19.8704
2024-10-30 20:24:47: [2024-10-30 20:24:47] iter = 10890, loss = 14.8945
2024-10-30 20:24:51: [2024-10-30 20:24:51] iter = 10900, loss = 74.8823
2024-10-30 20:24:55: [2024-10-30 20:24:55] iter = 10910, loss = 17.0956
2024-10-30 20:24:59: [2024-10-30 20:24:59] iter = 10920, loss = 5.1861
2024-10-30 20:25:02: [2024-10-30 20:25:02] iter = 10930, loss = 6.3843
2024-10-30 20:25:07: [2024-10-30 20:25:07] iter = 10940, loss = 50.1070
2024-10-30 20:25:10: [2024-10-30 20:25:10] iter = 10950, loss = 17.8028
2024-10-30 20:25:14: [2024-10-30 20:25:14] iter = 10960, loss = 6.2302
2024-10-30 20:25:17: [2024-10-30 20:25:17] iter = 10970, loss = 13.5260
2024-10-30 20:25:22: [2024-10-30 20:25:22] iter = 10980, loss = 3.5872
2024-10-30 20:25:26: [2024-10-30 20:25:26] iter = 10990, loss = 4.7213
2024-10-30 20:25:30: [2024-10-30 20:25:30] iter = 11000, loss = 12.9255
2024-10-30 20:25:35: [2024-10-30 20:25:35] iter = 11010, loss = 6.8816
2024-10-30 20:25:39: [2024-10-30 20:25:39] iter = 11020, loss = 4.6170
2024-10-30 20:25:43: [2024-10-30 20:25:43] iter = 11030, loss = 16.0807
2024-10-30 20:25:47: [2024-10-30 20:25:47] iter = 11040, loss = 20.5928
2024-10-30 20:25:51: [2024-10-30 20:25:51] iter = 11050, loss = 5.9349
2024-10-30 20:25:55: [2024-10-30 20:25:55] iter = 11060, loss = 10.1741
2024-10-30 20:25:59: [2024-10-30 20:25:59] iter = 11070, loss = 24.1921
2024-10-30 20:26:01: [2024-10-30 20:26:01] iter = 11080, loss = 11.1093
2024-10-30 20:26:04: [2024-10-30 20:26:04] iter = 11090, loss = 30.0200
2024-10-30 20:26:08: [2024-10-30 20:26:08] iter = 11100, loss = 48.8597
2024-10-30 20:26:13: [2024-10-30 20:26:13] iter = 11110, loss = 28.9939
2024-10-30 20:26:16: [2024-10-30 20:26:16] iter = 11120, loss = 43.3218
2024-10-30 20:26:17: [2024-10-30 20:26:17] iter = 11130, loss = 9.0308
2024-10-30 20:26:21: [2024-10-30 20:26:21] iter = 11140, loss = 15.5523
2024-10-30 20:26:25: [2024-10-30 20:26:25] iter = 11150, loss = 6.8160
2024-10-30 20:26:29: [2024-10-30 20:26:29] iter = 11160, loss = 6.8225
2024-10-30 20:26:33: [2024-10-30 20:26:33] iter = 11170, loss = 37.1146
2024-10-30 20:26:38: [2024-10-30 20:26:38] iter = 11180, loss = 47.2581
2024-10-30 20:26:41: [2024-10-30 20:26:41] iter = 11190, loss = 23.2874
2024-10-30 20:26:45: [2024-10-30 20:26:45] iter = 11200, loss = 17.9602
2024-10-30 20:26:49: [2024-10-30 20:26:49] iter = 11210, loss = 14.2723
2024-10-30 20:26:53: [2024-10-30 20:26:53] iter = 11220, loss = 8.8072
2024-10-30 20:26:59: [2024-10-30 20:26:59] iter = 11230, loss = 9.1134
2024-10-30 20:27:03: [2024-10-30 20:27:03] iter = 11240, loss = 3.8440
2024-10-30 20:27:07: [2024-10-30 20:27:07] iter = 11250, loss = 5.1211
2024-10-30 20:27:11: [2024-10-30 20:27:11] iter = 11260, loss = 10.5827
2024-10-30 20:27:15: [2024-10-30 20:27:15] iter = 11270, loss = 7.5118
2024-10-30 20:27:19: [2024-10-30 20:27:19] iter = 11280, loss = 21.8501
2024-10-30 20:27:23: [2024-10-30 20:27:23] iter = 11290, loss = 6.2315
2024-10-30 20:27:27: [2024-10-30 20:27:27] iter = 11300, loss = 7.5340
2024-10-30 20:27:29: [2024-10-30 20:27:29] iter = 11310, loss = 4.3385
2024-10-30 20:27:32: [2024-10-30 20:27:32] iter = 11320, loss = 6.5736
2024-10-30 20:27:36: [2024-10-30 20:27:36] iter = 11330, loss = 29.6994
2024-10-30 20:27:39: [2024-10-30 20:27:39] iter = 11340, loss = 3.5928
2024-10-30 20:27:43: [2024-10-30 20:27:43] iter = 11350, loss = 15.0616
2024-10-30 20:27:47: [2024-10-30 20:27:47] iter = 11360, loss = 4.3245
2024-10-30 20:27:51: [2024-10-30 20:27:51] iter = 11370, loss = 24.1681
2024-10-30 20:27:56: [2024-10-30 20:27:56] iter = 11380, loss = 24.1145
2024-10-30 20:28:00: [2024-10-30 20:28:00] iter = 11390, loss = 6.5878
2024-10-30 20:28:04: [2024-10-30 20:28:04] iter = 11400, loss = 7.6038
2024-10-30 20:28:08: [2024-10-30 20:28:08] iter = 11410, loss = 4.2977
2024-10-30 20:28:10: [2024-10-30 20:28:10] iter = 11420, loss = 35.5390
2024-10-30 20:28:13: [2024-10-30 20:28:13] iter = 11430, loss = 4.3641
2024-10-30 20:28:17: [2024-10-30 20:28:17] iter = 11440, loss = 30.7242
2024-10-30 20:28:21: [2024-10-30 20:28:21] iter = 11450, loss = 22.6604
2024-10-30 20:28:25: [2024-10-30 20:28:25] iter = 11460, loss = 41.0754
2024-10-30 20:28:29: [2024-10-30 20:28:29] iter = 11470, loss = 27.4777
2024-10-30 20:28:33: [2024-10-30 20:28:33] iter = 11480, loss = 98.3401
2024-10-30 20:28:36: [2024-10-30 20:28:36] iter = 11490, loss = 19.6195
2024-10-30 20:28:40: [2024-10-30 20:28:40] iter = 11500, loss = 56.8212
2024-10-30 20:28:45: [2024-10-30 20:28:45] iter = 11510, loss = 17.7697
2024-10-30 20:28:48: [2024-10-30 20:28:48] iter = 11520, loss = 15.2039
2024-10-30 20:28:53: [2024-10-30 20:28:53] iter = 11530, loss = 45.4629
2024-10-30 20:28:57: [2024-10-30 20:28:57] iter = 11540, loss = 6.5965
2024-10-30 20:29:01: [2024-10-30 20:29:01] iter = 11550, loss = 45.2857
2024-10-30 20:29:05: [2024-10-30 20:29:05] iter = 11560, loss = 4.4700
2024-10-30 20:29:08: [2024-10-30 20:29:08] iter = 11570, loss = 12.3366
2024-10-30 20:29:13: [2024-10-30 20:29:13] iter = 11580, loss = 5.8021
2024-10-30 20:29:17: [2024-10-30 20:29:17] iter = 11590, loss = 5.9351
2024-10-30 20:29:20: [2024-10-30 20:29:20] iter = 11600, loss = 11.5206
2024-10-30 20:29:25: [2024-10-30 20:29:25] iter = 11610, loss = 15.9243
2024-10-30 20:29:30: [2024-10-30 20:29:30] iter = 11620, loss = 5.0531
2024-10-30 20:29:34: [2024-10-30 20:29:34] iter = 11630, loss = 43.2539
2024-10-30 20:29:38: [2024-10-30 20:29:38] iter = 11640, loss = 39.4630
2024-10-30 20:29:43: [2024-10-30 20:29:43] iter = 11650, loss = 5.2359
2024-10-30 20:29:46: [2024-10-30 20:29:46] iter = 11660, loss = 10.1225
2024-10-30 20:29:49: [2024-10-30 20:29:49] iter = 11670, loss = 4.4659
2024-10-30 20:29:53: [2024-10-30 20:29:53] iter = 11680, loss = 4.8646
2024-10-30 20:29:58: [2024-10-30 20:29:58] iter = 11690, loss = 4.6151
2024-10-30 20:30:01: [2024-10-30 20:30:01] iter = 11700, loss = 5.1365
2024-10-30 20:30:05: [2024-10-30 20:30:05] iter = 11710, loss = 11.0617
2024-10-30 20:30:10: [2024-10-30 20:30:10] iter = 11720, loss = 20.3331
2024-10-30 20:30:13: [2024-10-30 20:30:13] iter = 11730, loss = 24.8438
2024-10-30 20:30:17: [2024-10-30 20:30:17] iter = 11740, loss = 10.4933
2024-10-30 20:30:21: [2024-10-30 20:30:21] iter = 11750, loss = 7.5802
2024-10-30 20:30:26: [2024-10-30 20:30:26] iter = 11760, loss = 4.7161
2024-10-30 20:30:30: [2024-10-30 20:30:30] iter = 11770, loss = 13.8387
2024-10-30 20:30:35: [2024-10-30 20:30:35] iter = 11780, loss = 7.9223
2024-10-30 20:30:39: [2024-10-30 20:30:39] iter = 11790, loss = 105.6725
2024-10-30 20:30:43: [2024-10-30 20:30:43] iter = 11800, loss = 5.8711
2024-10-30 20:30:47: [2024-10-30 20:30:47] iter = 11810, loss = 65.1914
2024-10-30 20:30:52: [2024-10-30 20:30:52] iter = 11820, loss = 23.3616
2024-10-30 20:30:56: [2024-10-30 20:30:56] iter = 11830, loss = 28.2573
2024-10-30 20:31:01: [2024-10-30 20:31:01] iter = 11840, loss = 5.1251
2024-10-30 20:31:04: [2024-10-30 20:31:04] iter = 11850, loss = 15.4847
2024-10-30 20:31:09: [2024-10-30 20:31:09] iter = 11860, loss = 5.8096
2024-10-30 20:31:12: [2024-10-30 20:31:12] iter = 11870, loss = 4.3003
2024-10-30 20:31:16: [2024-10-30 20:31:16] iter = 11880, loss = 10.7041
2024-10-30 20:31:19: [2024-10-30 20:31:19] iter = 11890, loss = 4.6226
2024-10-30 20:31:22: [2024-10-30 20:31:22] iter = 11900, loss = 7.0322
2024-10-30 20:31:26: [2024-10-30 20:31:26] iter = 11910, loss = 20.5855
2024-10-30 20:31:30: [2024-10-30 20:31:30] iter = 11920, loss = 6.0665
2024-10-30 20:31:35: [2024-10-30 20:31:35] iter = 11930, loss = 5.8067
2024-10-30 20:31:40: [2024-10-30 20:31:40] iter = 11940, loss = 10.8133
2024-10-30 20:31:45: [2024-10-30 20:31:45] iter = 11950, loss = 9.0790
2024-10-30 20:31:51: [2024-10-30 20:31:51] iter = 11960, loss = 4.8481
2024-10-30 20:31:56: [2024-10-30 20:31:56] iter = 11970, loss = 18.3789
2024-10-30 20:32:01: [2024-10-30 20:32:01] iter = 11980, loss = 6.4398
2024-10-30 20:32:06: [2024-10-30 20:32:06] iter = 11990, loss = 27.7544
2024-10-30 20:32:11: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 20:32:11: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:32:11: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 31358}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:34:52: Evaluate 5 random ConvNet, ACCmean = 0.3375 ACCstd = 0.0120
-------------------------
2024-10-30 20:34:52: Evaluate 5 random ConvNet, SENmean = 0.3093 SENstd = 0.0055
-------------------------
2024-10-30 20:34:52: Evaluate 5 random ConvNet, SPEmean = 0.9052 SPEstd = 0.0014
-------------------------
2024-10-30 20:34:52: Evaluate 5 random ConvNet, F!mean = 0.2816 F!std = 0.0067
-------------------------
2024-10-30 20:34:52: Evaluate 5 random ConvNet, mean = 0.3375 std = 0.0120
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:34:53: [2024-10-30 20:34:53] iter = 12000, loss = 84.1037
2024-10-30 20:34:58: [2024-10-30 20:34:58] iter = 12010, loss = 10.2008
2024-10-30 20:35:01: [2024-10-30 20:35:01] iter = 12020, loss = 16.1597
2024-10-30 20:35:06: [2024-10-30 20:35:06] iter = 12030, loss = 7.9964
2024-10-30 20:35:11: [2024-10-30 20:35:11] iter = 12040, loss = 18.9362
2024-10-30 20:35:17: [2024-10-30 20:35:17] iter = 12050, loss = 4.9246
2024-10-30 20:35:21: [2024-10-30 20:35:21] iter = 12060, loss = 52.7713
2024-10-30 20:35:26: [2024-10-30 20:35:26] iter = 12070, loss = 46.7908
2024-10-30 20:35:31: [2024-10-30 20:35:31] iter = 12080, loss = 15.0800
2024-10-30 20:35:35: [2024-10-30 20:35:35] iter = 12090, loss = 50.6346
2024-10-30 20:35:39: [2024-10-30 20:35:39] iter = 12100, loss = 4.1407
2024-10-30 20:35:44: [2024-10-30 20:35:44] iter = 12110, loss = 77.5708
2024-10-30 20:35:48: [2024-10-30 20:35:48] iter = 12120, loss = 16.9352
2024-10-30 20:35:52: [2024-10-30 20:35:52] iter = 12130, loss = 6.1657
2024-10-30 20:35:56: [2024-10-30 20:35:56] iter = 12140, loss = 3.5791
2024-10-30 20:36:01: [2024-10-30 20:36:01] iter = 12150, loss = 11.8154
2024-10-30 20:36:06: [2024-10-30 20:36:06] iter = 12160, loss = 4.0863
2024-10-30 20:36:10: [2024-10-30 20:36:10] iter = 12170, loss = 3.7538
2024-10-30 20:36:15: [2024-10-30 20:36:15] iter = 12180, loss = 5.1970
2024-10-30 20:36:20: [2024-10-30 20:36:20] iter = 12190, loss = 52.9596
2024-10-30 20:36:25: [2024-10-30 20:36:25] iter = 12200, loss = 40.1090
2024-10-30 20:36:30: [2024-10-30 20:36:30] iter = 12210, loss = 9.4794
2024-10-30 20:36:34: [2024-10-30 20:36:34] iter = 12220, loss = 44.7082
2024-10-30 20:36:39: [2024-10-30 20:36:39] iter = 12230, loss = 5.9933
2024-10-30 20:36:43: [2024-10-30 20:36:43] iter = 12240, loss = 8.3109
2024-10-30 20:36:47: [2024-10-30 20:36:47] iter = 12250, loss = 27.8542
2024-10-30 20:36:51: [2024-10-30 20:36:51] iter = 12260, loss = 20.2772
2024-10-30 20:36:55: [2024-10-30 20:36:55] iter = 12270, loss = 6.3248
2024-10-30 20:36:58: [2024-10-30 20:36:58] iter = 12280, loss = 18.8509
2024-10-30 20:37:02: [2024-10-30 20:37:02] iter = 12290, loss = 35.9058
2024-10-30 20:37:06: [2024-10-30 20:37:06] iter = 12300, loss = 16.9650
2024-10-30 20:37:10: [2024-10-30 20:37:10] iter = 12310, loss = 8.5733
2024-10-30 20:37:14: [2024-10-30 20:37:14] iter = 12320, loss = 5.6913
2024-10-30 20:37:19: [2024-10-30 20:37:19] iter = 12330, loss = 4.8798
2024-10-30 20:37:23: [2024-10-30 20:37:23] iter = 12340, loss = 6.1558
2024-10-30 20:37:26: [2024-10-30 20:37:26] iter = 12350, loss = 19.1767
2024-10-30 20:37:31: [2024-10-30 20:37:31] iter = 12360, loss = 13.5443
2024-10-30 20:37:34: [2024-10-30 20:37:34] iter = 12370, loss = 5.6543
2024-10-30 20:37:37: [2024-10-30 20:37:37] iter = 12380, loss = 4.7568
2024-10-30 20:37:40: [2024-10-30 20:37:40] iter = 12390, loss = 20.2295
2024-10-30 20:37:45: [2024-10-30 20:37:45] iter = 12400, loss = 15.2953
2024-10-30 20:37:49: [2024-10-30 20:37:49] iter = 12410, loss = 33.5049
2024-10-30 20:37:54: [2024-10-30 20:37:54] iter = 12420, loss = 6.1458
2024-10-30 20:37:57: [2024-10-30 20:37:57] iter = 12430, loss = 8.4934
2024-10-30 20:38:01: [2024-10-30 20:38:01] iter = 12440, loss = 4.4965
2024-10-30 20:38:05: [2024-10-30 20:38:05] iter = 12450, loss = 4.8535
2024-10-30 20:38:10: [2024-10-30 20:38:10] iter = 12460, loss = 33.9241
2024-10-30 20:38:13: [2024-10-30 20:38:13] iter = 12470, loss = 4.7922
2024-10-30 20:38:17: [2024-10-30 20:38:17] iter = 12480, loss = 5.1644
2024-10-30 20:38:21: [2024-10-30 20:38:21] iter = 12490, loss = 32.9310
2024-10-30 20:38:25: [2024-10-30 20:38:25] iter = 12500, loss = 6.4738
2024-10-30 20:38:30: [2024-10-30 20:38:30] iter = 12510, loss = 3.2238
2024-10-30 20:38:34: [2024-10-30 20:38:34] iter = 12520, loss = 46.6230
2024-10-30 20:38:38: [2024-10-30 20:38:38] iter = 12530, loss = 20.0746
2024-10-30 20:38:42: [2024-10-30 20:38:42] iter = 12540, loss = 9.4843
2024-10-30 20:38:48: [2024-10-30 20:38:48] iter = 12550, loss = 7.4710
2024-10-30 20:38:53: [2024-10-30 20:38:53] iter = 12560, loss = 5.1305
2024-10-30 20:38:56: [2024-10-30 20:38:56] iter = 12570, loss = 24.5338
2024-10-30 20:39:01: [2024-10-30 20:39:01] iter = 12580, loss = 31.2025
2024-10-30 20:39:04: [2024-10-30 20:39:04] iter = 12590, loss = 5.3113
2024-10-30 20:39:08: [2024-10-30 20:39:08] iter = 12600, loss = 37.4158
2024-10-30 20:39:12: [2024-10-30 20:39:12] iter = 12610, loss = 13.2982
2024-10-30 20:39:18: [2024-10-30 20:39:18] iter = 12620, loss = 4.5665
2024-10-30 20:39:23: [2024-10-30 20:39:23] iter = 12630, loss = 14.2530
2024-10-30 20:39:27: [2024-10-30 20:39:27] iter = 12640, loss = 3.8286
2024-10-30 20:39:31: [2024-10-30 20:39:31] iter = 12650, loss = 86.5262
2024-10-30 20:39:35: [2024-10-30 20:39:35] iter = 12660, loss = 4.5419
2024-10-30 20:39:39: [2024-10-30 20:39:39] iter = 12670, loss = 24.2953
2024-10-30 20:39:43: [2024-10-30 20:39:43] iter = 12680, loss = 8.7263
2024-10-30 20:39:47: [2024-10-30 20:39:47] iter = 12690, loss = 11.8870
2024-10-30 20:39:52: [2024-10-30 20:39:52] iter = 12700, loss = 11.2707
2024-10-30 20:39:57: [2024-10-30 20:39:57] iter = 12710, loss = 10.3325
2024-10-30 20:40:01: [2024-10-30 20:40:01] iter = 12720, loss = 28.4534
2024-10-30 20:40:05: [2024-10-30 20:40:05] iter = 12730, loss = 20.5649
2024-10-30 20:40:09: [2024-10-30 20:40:09] iter = 12740, loss = 5.1776
2024-10-30 20:40:13: [2024-10-30 20:40:13] iter = 12750, loss = 4.0684
2024-10-30 20:40:18: [2024-10-30 20:40:18] iter = 12760, loss = 14.7793
2024-10-30 20:40:22: [2024-10-30 20:40:22] iter = 12770, loss = 10.5516
2024-10-30 20:40:27: [2024-10-30 20:40:27] iter = 12780, loss = 11.9093
2024-10-30 20:40:31: [2024-10-30 20:40:31] iter = 12790, loss = 5.1421
2024-10-30 20:40:35: [2024-10-30 20:40:35] iter = 12800, loss = 71.8967
2024-10-30 20:40:40: [2024-10-30 20:40:40] iter = 12810, loss = 21.9965
2024-10-30 20:40:44: [2024-10-30 20:40:44] iter = 12820, loss = 9.3757
2024-10-30 20:40:49: [2024-10-30 20:40:49] iter = 12830, loss = 21.8726
2024-10-30 20:40:53: [2024-10-30 20:40:53] iter = 12840, loss = 5.7516
2024-10-30 20:40:59: [2024-10-30 20:40:59] iter = 12850, loss = 9.8048
2024-10-30 20:41:04: [2024-10-30 20:41:04] iter = 12860, loss = 4.2662
2024-10-30 20:41:09: [2024-10-30 20:41:09] iter = 12870, loss = 20.0430
2024-10-30 20:41:11: [2024-10-30 20:41:11] iter = 12880, loss = 16.7103
2024-10-30 20:41:14: [2024-10-30 20:41:14] iter = 12890, loss = 33.7065
2024-10-30 20:41:17: [2024-10-30 20:41:17] iter = 12900, loss = 18.2081
2024-10-30 20:41:22: [2024-10-30 20:41:22] iter = 12910, loss = 5.8711
2024-10-30 20:41:26: [2024-10-30 20:41:26] iter = 12920, loss = 11.2694
2024-10-30 20:41:30: [2024-10-30 20:41:30] iter = 12930, loss = 29.2422
2024-10-30 20:41:34: [2024-10-30 20:41:34] iter = 12940, loss = 9.9010
2024-10-30 20:41:39: [2024-10-30 20:41:39] iter = 12950, loss = 19.7311
2024-10-30 20:41:43: [2024-10-30 20:41:43] iter = 12960, loss = 3.5041
2024-10-30 20:41:47: [2024-10-30 20:41:47] iter = 12970, loss = 3.6418
2024-10-30 20:41:51: [2024-10-30 20:41:51] iter = 12980, loss = 47.8630
2024-10-30 20:41:55: [2024-10-30 20:41:55] iter = 12990, loss = 11.1268
2024-10-30 20:41:58: [2024-10-30 20:41:58] iter = 13000, loss = 53.7097
2024-10-30 20:42:01: [2024-10-30 20:42:01] iter = 13010, loss = 7.4817
2024-10-30 20:42:05: [2024-10-30 20:42:05] iter = 13020, loss = 53.8079
2024-10-30 20:42:09: [2024-10-30 20:42:09] iter = 13030, loss = 62.0516
2024-10-30 20:42:13: [2024-10-30 20:42:13] iter = 13040, loss = 8.2786
2024-10-30 20:42:17: [2024-10-30 20:42:17] iter = 13050, loss = 5.0339
2024-10-30 20:42:21: [2024-10-30 20:42:21] iter = 13060, loss = 34.0710
2024-10-30 20:42:26: [2024-10-30 20:42:26] iter = 13070, loss = 6.5571
2024-10-30 20:42:31: [2024-10-30 20:42:31] iter = 13080, loss = 4.0951
2024-10-30 20:42:35: [2024-10-30 20:42:35] iter = 13090, loss = 26.1660
2024-10-30 20:42:40: [2024-10-30 20:42:40] iter = 13100, loss = 18.2909
2024-10-30 20:42:42: [2024-10-30 20:42:42] iter = 13110, loss = 19.8107
2024-10-30 20:42:45: [2024-10-30 20:42:45] iter = 13120, loss = 21.2659
2024-10-30 20:42:50: [2024-10-30 20:42:50] iter = 13130, loss = 15.0490
2024-10-30 20:42:54: [2024-10-30 20:42:54] iter = 13140, loss = 62.3703
2024-10-30 20:42:59: [2024-10-30 20:42:59] iter = 13150, loss = 4.9008
2024-10-30 20:43:04: [2024-10-30 20:43:04] iter = 13160, loss = 15.6213
2024-10-30 20:43:07: [2024-10-30 20:43:07] iter = 13170, loss = 3.7889
2024-10-30 20:43:12: [2024-10-30 20:43:12] iter = 13180, loss = 9.4442
2024-10-30 20:43:15: [2024-10-30 20:43:15] iter = 13190, loss = 7.2791
2024-10-30 20:43:19: [2024-10-30 20:43:19] iter = 13200, loss = 49.6991
2024-10-30 20:43:24: [2024-10-30 20:43:24] iter = 13210, loss = 13.3252
2024-10-30 20:43:28: [2024-10-30 20:43:28] iter = 13220, loss = 69.6161
2024-10-30 20:43:32: [2024-10-30 20:43:32] iter = 13230, loss = 14.5684
2024-10-30 20:43:37: [2024-10-30 20:43:37] iter = 13240, loss = 5.9084
2024-10-30 20:43:41: [2024-10-30 20:43:41] iter = 13250, loss = 22.2211
2024-10-30 20:43:45: [2024-10-30 20:43:45] iter = 13260, loss = 11.2278
2024-10-30 20:43:49: [2024-10-30 20:43:49] iter = 13270, loss = 30.9175
2024-10-30 20:43:52: [2024-10-30 20:43:52] iter = 13280, loss = 3.6816
2024-10-30 20:43:55: [2024-10-30 20:43:55] iter = 13290, loss = 12.2213
2024-10-30 20:44:00: [2024-10-30 20:44:00] iter = 13300, loss = 83.0618
2024-10-30 20:44:04: [2024-10-30 20:44:04] iter = 13310, loss = 12.5486
2024-10-30 20:44:09: [2024-10-30 20:44:09] iter = 13320, loss = 4.3571
2024-10-30 20:44:14: [2024-10-30 20:44:14] iter = 13330, loss = 7.4359
2024-10-30 20:44:17: [2024-10-30 20:44:17] iter = 13340, loss = 33.4055
2024-10-30 20:44:21: [2024-10-30 20:44:21] iter = 13350, loss = 5.5512
2024-10-30 20:44:27: [2024-10-30 20:44:27] iter = 13360, loss = 8.7949
2024-10-30 20:44:32: [2024-10-30 20:44:32] iter = 13370, loss = 9.4328
2024-10-30 20:44:37: [2024-10-30 20:44:37] iter = 13380, loss = 11.6831
2024-10-30 20:44:42: [2024-10-30 20:44:42] iter = 13390, loss = 40.4973
2024-10-30 20:44:46: [2024-10-30 20:44:46] iter = 13400, loss = 6.3004
2024-10-30 20:44:49: [2024-10-30 20:44:49] iter = 13410, loss = 11.0059
2024-10-30 20:44:54: [2024-10-30 20:44:54] iter = 13420, loss = 4.4695
2024-10-30 20:44:58: [2024-10-30 20:44:58] iter = 13430, loss = 14.2219
2024-10-30 20:45:04: [2024-10-30 20:45:04] iter = 13440, loss = 25.2460
2024-10-30 20:45:08: [2024-10-30 20:45:08] iter = 13450, loss = 7.2151
2024-10-30 20:45:12: [2024-10-30 20:45:12] iter = 13460, loss = 4.3651
2024-10-30 20:45:17: [2024-10-30 20:45:17] iter = 13470, loss = 12.8134
2024-10-30 20:45:22: [2024-10-30 20:45:22] iter = 13480, loss = 10.0867
2024-10-30 20:45:24: [2024-10-30 20:45:24] iter = 13490, loss = 67.6148
2024-10-30 20:45:28: [2024-10-30 20:45:28] iter = 13500, loss = 8.8686
2024-10-30 20:45:32: [2024-10-30 20:45:32] iter = 13510, loss = 21.2450
2024-10-30 20:45:35: [2024-10-30 20:45:35] iter = 13520, loss = 6.9100
2024-10-30 20:45:40: [2024-10-30 20:45:40] iter = 13530, loss = 76.5236
2024-10-30 20:45:45: [2024-10-30 20:45:45] iter = 13540, loss = 10.7347
2024-10-30 20:45:50: [2024-10-30 20:45:50] iter = 13550, loss = 21.5483
2024-10-30 20:45:54: [2024-10-30 20:45:54] iter = 13560, loss = 4.7061
2024-10-30 20:45:59: [2024-10-30 20:45:59] iter = 13570, loss = 7.0274
2024-10-30 20:46:01: [2024-10-30 20:46:01] iter = 13580, loss = 31.6222
2024-10-30 20:46:05: [2024-10-30 20:46:05] iter = 13590, loss = 51.5518
2024-10-30 20:46:10: [2024-10-30 20:46:10] iter = 13600, loss = 7.0504
2024-10-30 20:46:14: [2024-10-30 20:46:14] iter = 13610, loss = 5.3328
2024-10-30 20:46:18: [2024-10-30 20:46:18] iter = 13620, loss = 12.5938
2024-10-30 20:46:23: [2024-10-30 20:46:23] iter = 13630, loss = 10.3090
2024-10-30 20:46:28: [2024-10-30 20:46:28] iter = 13640, loss = 12.2045
2024-10-30 20:46:33: [2024-10-30 20:46:33] iter = 13650, loss = 17.2116
2024-10-30 20:46:36: [2024-10-30 20:46:36] iter = 13660, loss = 20.7430
2024-10-30 20:46:42: [2024-10-30 20:46:42] iter = 13670, loss = 43.7638
2024-10-30 20:46:46: [2024-10-30 20:46:46] iter = 13680, loss = 40.3930
2024-10-30 20:46:50: [2024-10-30 20:46:50] iter = 13690, loss = 54.2257
2024-10-30 20:46:54: [2024-10-30 20:46:54] iter = 13700, loss = 50.7243
2024-10-30 20:46:58: [2024-10-30 20:46:58] iter = 13710, loss = 5.0035
2024-10-30 20:47:02: [2024-10-30 20:47:02] iter = 13720, loss = 8.8927
2024-10-30 20:47:08: [2024-10-30 20:47:08] iter = 13730, loss = 28.1746
2024-10-30 20:47:11: [2024-10-30 20:47:11] iter = 13740, loss = 10.7101
2024-10-30 20:47:16: [2024-10-30 20:47:16] iter = 13750, loss = 77.1252
2024-10-30 20:47:20: [2024-10-30 20:47:20] iter = 13760, loss = 11.7748
2024-10-30 20:47:25: [2024-10-30 20:47:25] iter = 13770, loss = 7.5535
2024-10-30 20:47:28: [2024-10-30 20:47:28] iter = 13780, loss = 46.5719
2024-10-30 20:47:33: [2024-10-30 20:47:33] iter = 13790, loss = 4.7230
2024-10-30 20:47:36: [2024-10-30 20:47:36] iter = 13800, loss = 9.2184
2024-10-30 20:47:40: [2024-10-30 20:47:40] iter = 13810, loss = 35.8241
2024-10-30 20:47:44: [2024-10-30 20:47:44] iter = 13820, loss = 16.7266
2024-10-30 20:47:49: [2024-10-30 20:47:49] iter = 13830, loss = 33.9471
2024-10-30 20:47:53: [2024-10-30 20:47:53] iter = 13840, loss = 4.8629
2024-10-30 20:47:57: [2024-10-30 20:47:57] iter = 13850, loss = 5.1904
2024-10-30 20:48:00: [2024-10-30 20:48:00] iter = 13860, loss = 5.8397
2024-10-30 20:48:04: [2024-10-30 20:48:04] iter = 13870, loss = 9.8988
2024-10-30 20:48:08: [2024-10-30 20:48:08] iter = 13880, loss = 3.4350
2024-10-30 20:48:12: [2024-10-30 20:48:12] iter = 13890, loss = 29.7988
2024-10-30 20:48:17: [2024-10-30 20:48:17] iter = 13900, loss = 10.4868
2024-10-30 20:48:21: [2024-10-30 20:48:21] iter = 13910, loss = 15.1458
2024-10-30 20:48:25: [2024-10-30 20:48:25] iter = 13920, loss = 53.5064
2024-10-30 20:48:29: [2024-10-30 20:48:29] iter = 13930, loss = 5.2602
2024-10-30 20:48:33: [2024-10-30 20:48:33] iter = 13940, loss = 35.3411
2024-10-30 20:48:38: [2024-10-30 20:48:38] iter = 13950, loss = 3.9642
2024-10-30 20:48:42: [2024-10-30 20:48:42] iter = 13960, loss = 101.5930
2024-10-30 20:48:46: [2024-10-30 20:48:46] iter = 13970, loss = 14.9534
2024-10-30 20:48:49: [2024-10-30 20:48:49] iter = 13980, loss = 78.1060
2024-10-30 20:48:52: [2024-10-30 20:48:52] iter = 13990, loss = 50.0301
2024-10-30 20:48:55: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 20:48:55: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 20:48:55: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 35693}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:51:22: Evaluate 5 random ConvNet, ACCmean = 0.3460 ACCstd = 0.0121
-------------------------
2024-10-30 20:51:22: Evaluate 5 random ConvNet, SENmean = 0.2918 SENstd = 0.0022
-------------------------
2024-10-30 20:51:22: Evaluate 5 random ConvNet, SPEmean = 0.9055 SPEstd = 0.0010
-------------------------
2024-10-30 20:51:22: Evaluate 5 random ConvNet, F!mean = 0.2569 F!std = 0.0036
-------------------------
2024-10-30 20:51:22: Evaluate 5 random ConvNet, mean = 0.3460 std = 0.0121
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:51:22: [2024-10-30 20:51:22] iter = 14000, loss = 40.1583
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 20:51:27: [2024-10-30 20:51:27] iter = 14010, loss = 31.8618
2024-10-30 20:51:31: [2024-10-30 20:51:31] iter = 14020, loss = 4.8821
2024-10-30 20:51:34: [2024-10-30 20:51:34] iter = 14030, loss = 16.3554
2024-10-30 20:51:38: [2024-10-30 20:51:38] iter = 14040, loss = 7.7692
2024-10-30 20:51:42: [2024-10-30 20:51:42] iter = 14050, loss = 10.5977
2024-10-30 20:51:46: [2024-10-30 20:51:46] iter = 14060, loss = 4.4928
2024-10-30 20:51:50: [2024-10-30 20:51:50] iter = 14070, loss = 10.0447
2024-10-30 20:51:54: [2024-10-30 20:51:54] iter = 14080, loss = 10.0290
2024-10-30 20:51:59: [2024-10-30 20:51:59] iter = 14090, loss = 4.9361
2024-10-30 20:52:02: [2024-10-30 20:52:02] iter = 14100, loss = 12.7834
2024-10-30 20:52:07: [2024-10-30 20:52:07] iter = 14110, loss = 5.3680
2024-10-30 20:52:10: [2024-10-30 20:52:10] iter = 14120, loss = 75.7838
2024-10-30 20:52:12: [2024-10-30 20:52:12] iter = 14130, loss = 5.7578
2024-10-30 20:52:17: [2024-10-30 20:52:17] iter = 14140, loss = 33.7788
2024-10-30 20:52:20: [2024-10-30 20:52:20] iter = 14150, loss = 16.5351
2024-10-30 20:52:24: [2024-10-30 20:52:24] iter = 14160, loss = 5.7514
2024-10-30 20:52:28: [2024-10-30 20:52:28] iter = 14170, loss = 55.3546
2024-10-30 20:52:33: [2024-10-30 20:52:33] iter = 14180, loss = 5.1221
2024-10-30 20:52:37: [2024-10-30 20:52:37] iter = 14190, loss = 44.9500
2024-10-30 20:52:41: [2024-10-30 20:52:41] iter = 14200, loss = 5.7476
2024-10-30 20:52:46: [2024-10-30 20:52:46] iter = 14210, loss = 3.3115
2024-10-30 20:52:50: [2024-10-30 20:52:50] iter = 14220, loss = 12.4385
2024-10-30 20:52:52: [2024-10-30 20:52:52] iter = 14230, loss = 13.1374
2024-10-30 20:52:58: [2024-10-30 20:52:58] iter = 14240, loss = 58.1856
2024-10-30 20:53:02: [2024-10-30 20:53:02] iter = 14250, loss = 19.2258
2024-10-30 20:53:06: [2024-10-30 20:53:06] iter = 14260, loss = 9.0852
2024-10-30 20:53:10: [2024-10-30 20:53:10] iter = 14270, loss = 6.6587
2024-10-30 20:53:13: [2024-10-30 20:53:13] iter = 14280, loss = 21.0350
2024-10-30 20:53:18: [2024-10-30 20:53:18] iter = 14290, loss = 11.5985
2024-10-30 20:53:23: [2024-10-30 20:53:23] iter = 14300, loss = 4.4632
2024-10-30 20:53:28: [2024-10-30 20:53:28] iter = 14310, loss = 9.5117
2024-10-30 20:53:32: [2024-10-30 20:53:32] iter = 14320, loss = 4.8399
2024-10-30 20:53:35: [2024-10-30 20:53:35] iter = 14330, loss = 27.1274
2024-10-30 20:53:40: [2024-10-30 20:53:40] iter = 14340, loss = 15.7735
2024-10-30 20:53:45: [2024-10-30 20:53:45] iter = 14350, loss = 4.5884
2024-10-30 20:53:50: [2024-10-30 20:53:50] iter = 14360, loss = 12.8143
2024-10-30 20:53:55: [2024-10-30 20:53:55] iter = 14370, loss = 8.7560
2024-10-30 20:54:00: [2024-10-30 20:54:00] iter = 14380, loss = 16.3143
2024-10-30 20:54:05: [2024-10-30 20:54:05] iter = 14390, loss = 27.4601
2024-10-30 20:54:09: [2024-10-30 20:54:09] iter = 14400, loss = 5.5057
2024-10-30 20:54:13: [2024-10-30 20:54:13] iter = 14410, loss = 20.6056
2024-10-30 20:54:18: [2024-10-30 20:54:18] iter = 14420, loss = 4.3181
2024-10-30 20:54:23: [2024-10-30 20:54:23] iter = 14430, loss = 6.2224
2024-10-30 20:54:27: [2024-10-30 20:54:27] iter = 14440, loss = 4.0513
2024-10-30 20:54:33: [2024-10-30 20:54:33] iter = 14450, loss = 44.5139
2024-10-30 20:54:37: [2024-10-30 20:54:37] iter = 14460, loss = 4.7528
2024-10-30 20:54:44: [2024-10-30 20:54:44] iter = 14470, loss = 17.5626
2024-10-30 20:54:50: [2024-10-30 20:54:50] iter = 14480, loss = 12.5170
2024-10-30 20:54:54: [2024-10-30 20:54:54] iter = 14490, loss = 22.0688
2024-10-30 20:54:56: [2024-10-30 20:54:56] iter = 14500, loss = 49.8995
2024-10-30 20:55:00: [2024-10-30 20:55:00] iter = 14510, loss = 24.8002
2024-10-30 20:55:04: [2024-10-30 20:55:04] iter = 14520, loss = 48.9555
2024-10-30 20:55:09: [2024-10-30 20:55:09] iter = 14530, loss = 5.6734
2024-10-30 20:55:13: [2024-10-30 20:55:13] iter = 14540, loss = 33.8113
2024-10-30 20:55:17: [2024-10-30 20:55:17] iter = 14550, loss = 37.9670
2024-10-30 20:55:21: [2024-10-30 20:55:21] iter = 14560, loss = 11.1281
2024-10-30 20:55:26: [2024-10-30 20:55:26] iter = 14570, loss = 6.2643
2024-10-30 20:55:31: [2024-10-30 20:55:31] iter = 14580, loss = 6.4403
2024-10-30 20:55:35: [2024-10-30 20:55:35] iter = 14590, loss = 7.3767
2024-10-30 20:55:39: [2024-10-30 20:55:39] iter = 14600, loss = 50.6898
2024-10-30 20:55:44: [2024-10-30 20:55:44] iter = 14610, loss = 3.6727
2024-10-30 20:55:48: [2024-10-30 20:55:48] iter = 14620, loss = 17.9795
2024-10-30 20:55:52: [2024-10-30 20:55:52] iter = 14630, loss = 84.9512
2024-10-30 20:55:56: [2024-10-30 20:55:56] iter = 14640, loss = 4.6836
2024-10-30 20:56:00: [2024-10-30 20:56:00] iter = 14650, loss = 29.1323
2024-10-30 20:56:04: [2024-10-30 20:56:04] iter = 14660, loss = 21.2799
2024-10-30 20:56:08: [2024-10-30 20:56:08] iter = 14670, loss = 9.8779
2024-10-30 20:56:13: [2024-10-30 20:56:13] iter = 14680, loss = 10.8931
2024-10-30 20:56:17: [2024-10-30 20:56:17] iter = 14690, loss = 18.2622
2024-10-30 20:56:21: [2024-10-30 20:56:21] iter = 14700, loss = 3.6478
2024-10-30 20:56:26: [2024-10-30 20:56:26] iter = 14710, loss = 15.9721
2024-10-30 20:56:30: [2024-10-30 20:56:30] iter = 14720, loss = 5.0379
2024-10-30 20:56:35: [2024-10-30 20:56:35] iter = 14730, loss = 75.1613
2024-10-30 20:56:39: [2024-10-30 20:56:39] iter = 14740, loss = 32.2044
2024-10-30 20:56:44: [2024-10-30 20:56:44] iter = 14750, loss = 8.5730
2024-10-30 20:56:49: [2024-10-30 20:56:49] iter = 14760, loss = 13.6018
2024-10-30 20:56:53: [2024-10-30 20:56:53] iter = 14770, loss = 8.7279
2024-10-30 20:56:56: [2024-10-30 20:56:56] iter = 14780, loss = 3.7103
2024-10-30 20:57:00: [2024-10-30 20:57:00] iter = 14790, loss = 5.2373
2024-10-30 20:57:05: [2024-10-30 20:57:05] iter = 14800, loss = 5.0850
2024-10-30 20:57:10: [2024-10-30 20:57:10] iter = 14810, loss = 15.2025
2024-10-30 20:57:14: [2024-10-30 20:57:14] iter = 14820, loss = 8.5288
2024-10-30 20:57:19: [2024-10-30 20:57:19] iter = 14830, loss = 4.6576
2024-10-30 20:57:23: [2024-10-30 20:57:23] iter = 14840, loss = 10.8547
2024-10-30 20:57:27: [2024-10-30 20:57:27] iter = 14850, loss = 25.1220
2024-10-30 20:57:32: [2024-10-30 20:57:32] iter = 14860, loss = 9.7325
2024-10-30 20:57:36: [2024-10-30 20:57:36] iter = 14870, loss = 23.2279
2024-10-30 20:57:41: [2024-10-30 20:57:41] iter = 14880, loss = 37.3685
2024-10-30 20:57:46: [2024-10-30 20:57:46] iter = 14890, loss = 7.7752
2024-10-30 20:57:51: [2024-10-30 20:57:51] iter = 14900, loss = 49.7018
2024-10-30 20:57:55: [2024-10-30 20:57:55] iter = 14910, loss = 27.1410
2024-10-30 20:57:59: [2024-10-30 20:57:59] iter = 14920, loss = 25.7443
2024-10-30 20:58:05: [2024-10-30 20:58:05] iter = 14930, loss = 6.0709
2024-10-30 20:58:09: [2024-10-30 20:58:09] iter = 14940, loss = 8.2270
2024-10-30 20:58:14: [2024-10-30 20:58:14] iter = 14950, loss = 50.8375
2024-10-30 20:58:18: [2024-10-30 20:58:18] iter = 14960, loss = 23.4326
2024-10-30 20:58:23: [2024-10-30 20:58:23] iter = 14970, loss = 38.5270
2024-10-30 20:58:27: [2024-10-30 20:58:27] iter = 14980, loss = 8.2926
2024-10-30 20:58:32: [2024-10-30 20:58:32] iter = 14990, loss = 14.5460
2024-10-30 20:58:36: [2024-10-30 20:58:36] iter = 15000, loss = 11.6777
2024-10-30 20:58:40: [2024-10-30 20:58:40] iter = 15010, loss = 12.7220
2024-10-30 20:58:44: [2024-10-30 20:58:44] iter = 15020, loss = 12.8298
2024-10-30 20:58:48: [2024-10-30 20:58:48] iter = 15030, loss = 3.7196
2024-10-30 20:58:51: [2024-10-30 20:58:51] iter = 15040, loss = 5.4345
2024-10-30 20:58:56: [2024-10-30 20:58:56] iter = 15050, loss = 15.8649
2024-10-30 20:58:59: [2024-10-30 20:58:59] iter = 15060, loss = 21.6702
2024-10-30 20:59:05: [2024-10-30 20:59:05] iter = 15070, loss = 10.6557
2024-10-30 20:59:10: [2024-10-30 20:59:10] iter = 15080, loss = 7.1434
2024-10-30 20:59:16: [2024-10-30 20:59:16] iter = 15090, loss = 32.1375
2024-10-30 20:59:20: [2024-10-30 20:59:20] iter = 15100, loss = 5.1352
2024-10-30 20:59:25: [2024-10-30 20:59:25] iter = 15110, loss = 11.1641
2024-10-30 20:59:30: [2024-10-30 20:59:30] iter = 15120, loss = 31.2912
2024-10-30 20:59:35: [2024-10-30 20:59:35] iter = 15130, loss = 85.7710
2024-10-30 20:59:41: [2024-10-30 20:59:41] iter = 15140, loss = 18.7430
2024-10-30 20:59:45: [2024-10-30 20:59:45] iter = 15150, loss = 77.4825
2024-10-30 20:59:50: [2024-10-30 20:59:50] iter = 15160, loss = 3.8335
2024-10-30 20:59:55: [2024-10-30 20:59:55] iter = 15170, loss = 37.5249
2024-10-30 21:00:00: [2024-10-30 21:00:00] iter = 15180, loss = 13.1723
2024-10-30 21:00:05: [2024-10-30 21:00:05] iter = 15190, loss = 4.6568
2024-10-30 21:00:09: [2024-10-30 21:00:09] iter = 15200, loss = 69.3392
2024-10-30 21:00:15: [2024-10-30 21:00:15] iter = 15210, loss = 29.5120
2024-10-30 21:00:19: [2024-10-30 21:00:19] iter = 15220, loss = 16.5366
2024-10-30 21:00:23: [2024-10-30 21:00:23] iter = 15230, loss = 6.5229
2024-10-30 21:00:26: [2024-10-30 21:00:26] iter = 15240, loss = 28.3906
2024-10-30 21:00:31: [2024-10-30 21:00:31] iter = 15250, loss = 38.5339
2024-10-30 21:00:37: [2024-10-30 21:00:37] iter = 15260, loss = 7.2228
2024-10-30 21:00:41: [2024-10-30 21:00:41] iter = 15270, loss = 60.2978
2024-10-30 21:00:45: [2024-10-30 21:00:45] iter = 15280, loss = 19.7197
2024-10-30 21:00:51: [2024-10-30 21:00:51] iter = 15290, loss = 3.7511
2024-10-30 21:00:55: [2024-10-30 21:00:55] iter = 15300, loss = 5.4139
2024-10-30 21:01:01: [2024-10-30 21:01:01] iter = 15310, loss = 8.3269
2024-10-30 21:01:05: [2024-10-30 21:01:05] iter = 15320, loss = 9.3125
2024-10-30 21:01:10: [2024-10-30 21:01:10] iter = 15330, loss = 4.1206
2024-10-30 21:01:14: [2024-10-30 21:01:14] iter = 15340, loss = 5.0148
2024-10-30 21:01:17: [2024-10-30 21:01:17] iter = 15350, loss = 19.2142
2024-10-30 21:01:21: [2024-10-30 21:01:21] iter = 15360, loss = 40.1818
2024-10-30 21:01:26: [2024-10-30 21:01:26] iter = 15370, loss = 11.2409
2024-10-30 21:01:31: [2024-10-30 21:01:31] iter = 15380, loss = 48.2367
2024-10-30 21:01:35: [2024-10-30 21:01:35] iter = 15390, loss = 8.9511
2024-10-30 21:01:40: [2024-10-30 21:01:40] iter = 15400, loss = 37.3653
2024-10-30 21:01:44: [2024-10-30 21:01:44] iter = 15410, loss = 62.8115
2024-10-30 21:01:51: [2024-10-30 21:01:51] iter = 15420, loss = 11.7411
2024-10-30 21:01:56: [2024-10-30 21:01:56] iter = 15430, loss = 3.8654
2024-10-30 21:02:01: [2024-10-30 21:02:01] iter = 15440, loss = 9.7864
2024-10-30 21:02:03: [2024-10-30 21:02:03] iter = 15450, loss = 30.0677
2024-10-30 21:02:07: [2024-10-30 21:02:07] iter = 15460, loss = 7.9718
2024-10-30 21:02:11: [2024-10-30 21:02:11] iter = 15470, loss = 28.9519
2024-10-30 21:02:15: [2024-10-30 21:02:15] iter = 15480, loss = 53.4023
2024-10-30 21:02:19: [2024-10-30 21:02:19] iter = 15490, loss = 5.4591
2024-10-30 21:02:24: [2024-10-30 21:02:24] iter = 15500, loss = 3.5967
2024-10-30 21:02:28: [2024-10-30 21:02:28] iter = 15510, loss = 9.8903
2024-10-30 21:02:32: [2024-10-30 21:02:32] iter = 15520, loss = 25.1692
2024-10-30 21:02:36: [2024-10-30 21:02:36] iter = 15530, loss = 21.9225
2024-10-30 21:02:41: [2024-10-30 21:02:41] iter = 15540, loss = 22.4119
2024-10-30 21:02:45: [2024-10-30 21:02:45] iter = 15550, loss = 35.0351
2024-10-30 21:02:50: [2024-10-30 21:02:50] iter = 15560, loss = 13.6643
2024-10-30 21:02:54: [2024-10-30 21:02:54] iter = 15570, loss = 18.7779
2024-10-30 21:02:58: [2024-10-30 21:02:58] iter = 15580, loss = 5.0979
2024-10-30 21:03:03: [2024-10-30 21:03:03] iter = 15590, loss = 4.8965
2024-10-30 21:03:08: [2024-10-30 21:03:08] iter = 15600, loss = 4.9830
2024-10-30 21:03:12: [2024-10-30 21:03:12] iter = 15610, loss = 5.6571
2024-10-30 21:03:16: [2024-10-30 21:03:16] iter = 15620, loss = 4.4357
2024-10-30 21:03:20: [2024-10-30 21:03:20] iter = 15630, loss = 16.7396
2024-10-30 21:03:24: [2024-10-30 21:03:24] iter = 15640, loss = 4.1582
2024-10-30 21:03:28: [2024-10-30 21:03:28] iter = 15650, loss = 4.4787
2024-10-30 21:03:33: [2024-10-30 21:03:33] iter = 15660, loss = 19.0693
2024-10-30 21:03:37: [2024-10-30 21:03:37] iter = 15670, loss = 17.4838
2024-10-30 21:03:41: [2024-10-30 21:03:41] iter = 15680, loss = 20.7909
2024-10-30 21:03:46: [2024-10-30 21:03:46] iter = 15690, loss = 4.4095
2024-10-30 21:03:49: [2024-10-30 21:03:49] iter = 15700, loss = 9.3387
2024-10-30 21:03:53: [2024-10-30 21:03:53] iter = 15710, loss = 16.4592
2024-10-30 21:03:58: [2024-10-30 21:03:58] iter = 15720, loss = 8.7745
2024-10-30 21:04:02: [2024-10-30 21:04:02] iter = 15730, loss = 9.6469
2024-10-30 21:04:05: [2024-10-30 21:04:05] iter = 15740, loss = 3.3658
2024-10-30 21:04:09: [2024-10-30 21:04:09] iter = 15750, loss = 68.9527
2024-10-30 21:04:14: [2024-10-30 21:04:14] iter = 15760, loss = 25.9612
2024-10-30 21:04:18: [2024-10-30 21:04:18] iter = 15770, loss = 42.2332
2024-10-30 21:04:22: [2024-10-30 21:04:22] iter = 15780, loss = 4.0685
2024-10-30 21:04:26: [2024-10-30 21:04:26] iter = 15790, loss = 4.2462
2024-10-30 21:04:31: [2024-10-30 21:04:31] iter = 15800, loss = 10.0961
2024-10-30 21:04:35: [2024-10-30 21:04:35] iter = 15810, loss = 3.2500
2024-10-30 21:04:39: [2024-10-30 21:04:39] iter = 15820, loss = 5.1492
2024-10-30 21:04:44: [2024-10-30 21:04:44] iter = 15830, loss = 14.1328
2024-10-30 21:04:48: [2024-10-30 21:04:48] iter = 15840, loss = 7.0362
2024-10-30 21:04:53: [2024-10-30 21:04:53] iter = 15850, loss = 5.3435
2024-10-30 21:04:57: [2024-10-30 21:04:57] iter = 15860, loss = 38.2703
2024-10-30 21:05:02: [2024-10-30 21:05:02] iter = 15870, loss = 19.3113
2024-10-30 21:05:07: [2024-10-30 21:05:07] iter = 15880, loss = 28.1823
2024-10-30 21:05:11: [2024-10-30 21:05:11] iter = 15890, loss = 20.1167
2024-10-30 21:05:16: [2024-10-30 21:05:16] iter = 15900, loss = 3.7009
2024-10-30 21:05:22: [2024-10-30 21:05:22] iter = 15910, loss = 10.2017
2024-10-30 21:05:26: [2024-10-30 21:05:26] iter = 15920, loss = 9.9732
2024-10-30 21:05:31: [2024-10-30 21:05:31] iter = 15930, loss = 6.1878
2024-10-30 21:05:35: [2024-10-30 21:05:35] iter = 15940, loss = 48.6227
2024-10-30 21:05:38: [2024-10-30 21:05:38] iter = 15950, loss = 4.1471
2024-10-30 21:05:43: [2024-10-30 21:05:43] iter = 15960, loss = 11.1468
2024-10-30 21:05:47: [2024-10-30 21:05:47] iter = 15970, loss = 5.2232
2024-10-30 21:05:51: [2024-10-30 21:05:51] iter = 15980, loss = 4.9912
2024-10-30 21:05:56: [2024-10-30 21:05:56] iter = 15990, loss = 43.7403
2024-10-30 21:06:00: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 21:06:00: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:06:00: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 60263}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:08:27: Evaluate 5 random ConvNet, ACCmean = 0.3282 ACCstd = 0.0098
-------------------------
2024-10-30 21:08:27: Evaluate 5 random ConvNet, SENmean = 0.3181 SENstd = 0.0037
-------------------------
2024-10-30 21:08:27: Evaluate 5 random ConvNet, SPEmean = 0.9054 SPEstd = 0.0009
-------------------------
2024-10-30 21:08:27: Evaluate 5 random ConvNet, F!mean = 0.2695 F!std = 0.0071
-------------------------
2024-10-30 21:08:27: Evaluate 5 random ConvNet, mean = 0.3282 std = 0.0098
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:08:27: [2024-10-30 21:08:27] iter = 16000, loss = 4.2744
2024-10-30 21:08:31: [2024-10-30 21:08:31] iter = 16010, loss = 71.2789
2024-10-30 21:08:35: [2024-10-30 21:08:35] iter = 16020, loss = 28.6392
2024-10-30 21:08:39: [2024-10-30 21:08:39] iter = 16030, loss = 4.3626
2024-10-30 21:08:43: [2024-10-30 21:08:43] iter = 16040, loss = 3.9013
2024-10-30 21:08:47: [2024-10-30 21:08:47] iter = 16050, loss = 4.3166
2024-10-30 21:08:51: [2024-10-30 21:08:51] iter = 16060, loss = 16.9383
2024-10-30 21:08:54: [2024-10-30 21:08:54] iter = 16070, loss = 5.7474
2024-10-30 21:08:58: [2024-10-30 21:08:58] iter = 16080, loss = 11.0973
2024-10-30 21:09:01: [2024-10-30 21:09:01] iter = 16090, loss = 27.8262
2024-10-30 21:09:05: [2024-10-30 21:09:05] iter = 16100, loss = 17.1759
2024-10-30 21:09:10: [2024-10-30 21:09:10] iter = 16110, loss = 8.2100
2024-10-30 21:09:15: [2024-10-30 21:09:15] iter = 16120, loss = 4.8360
2024-10-30 21:09:17: [2024-10-30 21:09:17] iter = 16130, loss = 10.5075
2024-10-30 21:09:21: [2024-10-30 21:09:21] iter = 16140, loss = 4.6075
2024-10-30 21:09:25: [2024-10-30 21:09:25] iter = 16150, loss = 58.9642
2024-10-30 21:09:29: [2024-10-30 21:09:29] iter = 16160, loss = 11.3797
2024-10-30 21:09:33: [2024-10-30 21:09:33] iter = 16170, loss = 21.4792
2024-10-30 21:09:37: [2024-10-30 21:09:37] iter = 16180, loss = 45.8966
2024-10-30 21:09:40: [2024-10-30 21:09:40] iter = 16190, loss = 9.2811
2024-10-30 21:09:45: [2024-10-30 21:09:45] iter = 16200, loss = 35.3869
2024-10-30 21:09:50: [2024-10-30 21:09:50] iter = 16210, loss = 12.5196
2024-10-30 21:09:55: [2024-10-30 21:09:55] iter = 16220, loss = 5.6675
2024-10-30 21:10:00: [2024-10-30 21:10:00] iter = 16230, loss = 8.1637
2024-10-30 21:10:04: [2024-10-30 21:10:04] iter = 16240, loss = 20.7838
2024-10-30 21:10:08: [2024-10-30 21:10:08] iter = 16250, loss = 4.4771
2024-10-30 21:10:13: [2024-10-30 21:10:13] iter = 16260, loss = 18.4979
2024-10-30 21:10:18: [2024-10-30 21:10:18] iter = 16270, loss = 11.8312
2024-10-30 21:10:21: [2024-10-30 21:10:21] iter = 16280, loss = 16.3070
2024-10-30 21:10:25: [2024-10-30 21:10:25] iter = 16290, loss = 92.2848
2024-10-30 21:10:28: [2024-10-30 21:10:28] iter = 16300, loss = 52.0042
2024-10-30 21:10:31: [2024-10-30 21:10:31] iter = 16310, loss = 7.2399
2024-10-30 21:10:36: [2024-10-30 21:10:36] iter = 16320, loss = 37.4054
2024-10-30 21:10:39: [2024-10-30 21:10:39] iter = 16330, loss = 6.3571
2024-10-30 21:10:43: [2024-10-30 21:10:43] iter = 16340, loss = 7.6827
2024-10-30 21:10:47: [2024-10-30 21:10:47] iter = 16350, loss = 26.8758
2024-10-30 21:10:52: [2024-10-30 21:10:52] iter = 16360, loss = 32.7931
2024-10-30 21:10:57: [2024-10-30 21:10:57] iter = 16370, loss = 10.3128
2024-10-30 21:11:01: [2024-10-30 21:11:01] iter = 16380, loss = 41.7970
2024-10-30 21:11:05: [2024-10-30 21:11:05] iter = 16390, loss = 15.2549
2024-10-30 21:11:08: [2024-10-30 21:11:08] iter = 16400, loss = 12.2119
2024-10-30 21:11:11: [2024-10-30 21:11:11] iter = 16410, loss = 13.4103
2024-10-30 21:11:12: [2024-10-30 21:11:12] iter = 16420, loss = 22.5903
2024-10-30 21:11:14: [2024-10-30 21:11:14] iter = 16430, loss = 28.5354
2024-10-30 21:11:17: [2024-10-30 21:11:17] iter = 16440, loss = 5.7324
2024-10-30 21:11:20: [2024-10-30 21:11:20] iter = 16450, loss = 37.3662
2024-10-30 21:11:22: [2024-10-30 21:11:22] iter = 16460, loss = 4.8722
2024-10-30 21:11:26: [2024-10-30 21:11:26] iter = 16470, loss = 53.1482
2024-10-30 21:11:30: [2024-10-30 21:11:30] iter = 16480, loss = 6.1068
2024-10-30 21:11:34: [2024-10-30 21:11:34] iter = 16490, loss = 11.6577
2024-10-30 21:11:38: [2024-10-30 21:11:38] iter = 16500, loss = 47.7472
2024-10-30 21:11:42: [2024-10-30 21:11:42] iter = 16510, loss = 16.6024
2024-10-30 21:11:47: [2024-10-30 21:11:47] iter = 16520, loss = 61.7272
2024-10-30 21:11:51: [2024-10-30 21:11:51] iter = 16530, loss = 6.2958
2024-10-30 21:11:54: [2024-10-30 21:11:54] iter = 16540, loss = 33.4375
2024-10-30 21:11:58: [2024-10-30 21:11:58] iter = 16550, loss = 37.6679
2024-10-30 21:12:02: [2024-10-30 21:12:02] iter = 16560, loss = 3.3726
2024-10-30 21:12:05: [2024-10-30 21:12:05] iter = 16570, loss = 13.8838
2024-10-30 21:12:08: [2024-10-30 21:12:08] iter = 16580, loss = 4.8940
2024-10-30 21:12:12: [2024-10-30 21:12:12] iter = 16590, loss = 3.9840
2024-10-30 21:12:16: [2024-10-30 21:12:16] iter = 16600, loss = 46.6807
2024-10-30 21:12:20: [2024-10-30 21:12:20] iter = 16610, loss = 29.4746
2024-10-30 21:12:23: [2024-10-30 21:12:23] iter = 16620, loss = 51.0683
2024-10-30 21:12:26: [2024-10-30 21:12:26] iter = 16630, loss = 42.1139
2024-10-30 21:12:30: [2024-10-30 21:12:30] iter = 16640, loss = 5.4804
2024-10-30 21:12:33: [2024-10-30 21:12:33] iter = 16650, loss = 13.6266
2024-10-30 21:12:38: [2024-10-30 21:12:38] iter = 16660, loss = 10.8139
2024-10-30 21:12:42: [2024-10-30 21:12:42] iter = 16670, loss = 9.2450
2024-10-30 21:12:46: [2024-10-30 21:12:46] iter = 16680, loss = 6.4356
2024-10-30 21:12:49: [2024-10-30 21:12:49] iter = 16690, loss = 6.8998
2024-10-30 21:12:53: [2024-10-30 21:12:53] iter = 16700, loss = 4.8324
2024-10-30 21:12:58: [2024-10-30 21:12:58] iter = 16710, loss = 8.1008
2024-10-30 21:13:02: [2024-10-30 21:13:02] iter = 16720, loss = 13.0963
2024-10-30 21:13:05: [2024-10-30 21:13:05] iter = 16730, loss = 12.6679
2024-10-30 21:13:09: [2024-10-30 21:13:09] iter = 16740, loss = 3.7777
2024-10-30 21:13:14: [2024-10-30 21:13:14] iter = 16750, loss = 12.0009
2024-10-30 21:13:18: [2024-10-30 21:13:18] iter = 16760, loss = 97.8904
2024-10-30 21:13:22: [2024-10-30 21:13:22] iter = 16770, loss = 25.7638
2024-10-30 21:13:26: [2024-10-30 21:13:26] iter = 16780, loss = 10.7889
2024-10-30 21:13:30: [2024-10-30 21:13:30] iter = 16790, loss = 47.3740
2024-10-30 21:13:34: [2024-10-30 21:13:34] iter = 16800, loss = 6.3649
2024-10-30 21:13:37: [2024-10-30 21:13:37] iter = 16810, loss = 32.8373
2024-10-30 21:13:41: [2024-10-30 21:13:41] iter = 16820, loss = 28.1140
2024-10-30 21:13:45: [2024-10-30 21:13:45] iter = 16830, loss = 59.5409
2024-10-30 21:13:48: [2024-10-30 21:13:48] iter = 16840, loss = 13.3431
2024-10-30 21:13:52: [2024-10-30 21:13:51] iter = 16850, loss = 28.0270
2024-10-30 21:13:55: [2024-10-30 21:13:55] iter = 16860, loss = 42.2540
2024-10-30 21:13:59: [2024-10-30 21:13:59] iter = 16870, loss = 7.1424
2024-10-30 21:14:02: [2024-10-30 21:14:02] iter = 16880, loss = 39.6575
2024-10-30 21:14:07: [2024-10-30 21:14:06] iter = 16890, loss = 4.7198
2024-10-30 21:14:11: [2024-10-30 21:14:11] iter = 16900, loss = 38.0831
2024-10-30 21:14:15: [2024-10-30 21:14:15] iter = 16910, loss = 16.2509
2024-10-30 21:14:20: [2024-10-30 21:14:20] iter = 16920, loss = 7.4763
2024-10-30 21:14:25: [2024-10-30 21:14:25] iter = 16930, loss = 17.0021
2024-10-30 21:14:29: [2024-10-30 21:14:29] iter = 16940, loss = 6.4394
2024-10-30 21:14:30: [2024-10-30 21:14:30] iter = 16950, loss = 63.2463
2024-10-30 21:14:33: [2024-10-30 21:14:33] iter = 16960, loss = 6.6720
2024-10-30 21:14:37: [2024-10-30 21:14:37] iter = 16970, loss = 65.9928
2024-10-30 21:14:40: [2024-10-30 21:14:40] iter = 16980, loss = 22.5298
2024-10-30 21:14:44: [2024-10-30 21:14:44] iter = 16990, loss = 4.7395
2024-10-30 21:14:48: [2024-10-30 21:14:48] iter = 17000, loss = 24.4133
2024-10-30 21:14:52: [2024-10-30 21:14:52] iter = 17010, loss = 6.6329
2024-10-30 21:14:56: [2024-10-30 21:14:56] iter = 17020, loss = 5.3440
2024-10-30 21:14:59: [2024-10-30 21:14:59] iter = 17030, loss = 5.8870
2024-10-30 21:15:02: [2024-10-30 21:15:02] iter = 17040, loss = 8.9452
2024-10-30 21:15:06: [2024-10-30 21:15:06] iter = 17050, loss = 30.8499
2024-10-30 21:15:10: [2024-10-30 21:15:10] iter = 17060, loss = 24.3714
2024-10-30 21:15:14: [2024-10-30 21:15:14] iter = 17070, loss = 18.3117
2024-10-30 21:15:17: [2024-10-30 21:15:17] iter = 17080, loss = 31.1933
2024-10-30 21:15:19: [2024-10-30 21:15:19] iter = 17090, loss = 11.0239
2024-10-30 21:15:22: [2024-10-30 21:15:22] iter = 17100, loss = 43.9250
2024-10-30 21:15:26: [2024-10-30 21:15:26] iter = 17110, loss = 23.4233
2024-10-30 21:15:30: [2024-10-30 21:15:30] iter = 17120, loss = 12.3896
2024-10-30 21:15:35: [2024-10-30 21:15:35] iter = 17130, loss = 15.0142
2024-10-30 21:15:39: [2024-10-30 21:15:39] iter = 17140, loss = 8.8037
2024-10-30 21:15:43: [2024-10-30 21:15:43] iter = 17150, loss = 5.9817
2024-10-30 21:15:46: [2024-10-30 21:15:46] iter = 17160, loss = 3.5605
2024-10-30 21:15:49: [2024-10-30 21:15:49] iter = 17170, loss = 29.8591
2024-10-30 21:15:52: [2024-10-30 21:15:52] iter = 17180, loss = 4.1124
2024-10-30 21:15:55: [2024-10-30 21:15:55] iter = 17190, loss = 50.2497
2024-10-30 21:15:59: [2024-10-30 21:15:59] iter = 17200, loss = 87.6430
2024-10-30 21:16:02: [2024-10-30 21:16:02] iter = 17210, loss = 19.2941
2024-10-30 21:16:06: [2024-10-30 21:16:06] iter = 17220, loss = 4.8744
2024-10-30 21:16:10: [2024-10-30 21:16:10] iter = 17230, loss = 47.8817
2024-10-30 21:16:14: [2024-10-30 21:16:14] iter = 17240, loss = 29.6915
2024-10-30 21:16:18: [2024-10-30 21:16:18] iter = 17250, loss = 52.6652
2024-10-30 21:16:22: [2024-10-30 21:16:22] iter = 17260, loss = 3.4754
2024-10-30 21:16:26: [2024-10-30 21:16:26] iter = 17270, loss = 17.2735
2024-10-30 21:16:30: [2024-10-30 21:16:30] iter = 17280, loss = 28.4441
2024-10-30 21:16:34: [2024-10-30 21:16:34] iter = 17290, loss = 6.2082
2024-10-30 21:16:39: [2024-10-30 21:16:39] iter = 17300, loss = 20.6183
2024-10-30 21:16:43: [2024-10-30 21:16:43] iter = 17310, loss = 25.1284
2024-10-30 21:16:47: [2024-10-30 21:16:47] iter = 17320, loss = 3.9970
2024-10-30 21:16:51: [2024-10-30 21:16:51] iter = 17330, loss = 60.5691
2024-10-30 21:16:54: [2024-10-30 21:16:54] iter = 17340, loss = 37.9034
2024-10-30 21:16:58: [2024-10-30 21:16:58] iter = 17350, loss = 21.2178
2024-10-30 21:17:02: [2024-10-30 21:17:02] iter = 17360, loss = 47.0611
2024-10-30 21:17:06: [2024-10-30 21:17:06] iter = 17370, loss = 6.3427
2024-10-30 21:17:10: [2024-10-30 21:17:10] iter = 17380, loss = 5.6485
2024-10-30 21:17:15: [2024-10-30 21:17:15] iter = 17390, loss = 33.5749
2024-10-30 21:17:18: [2024-10-30 21:17:18] iter = 17400, loss = 3.8732
2024-10-30 21:17:23: [2024-10-30 21:17:23] iter = 17410, loss = 3.4440
2024-10-30 21:17:27: [2024-10-30 21:17:27] iter = 17420, loss = 4.1697
2024-10-30 21:17:32: [2024-10-30 21:17:32] iter = 17430, loss = 69.4828
2024-10-30 21:17:35: [2024-10-30 21:17:35] iter = 17440, loss = 11.0819
2024-10-30 21:17:37: [2024-10-30 21:17:37] iter = 17450, loss = 4.3400
2024-10-30 21:17:41: [2024-10-30 21:17:41] iter = 17460, loss = 12.3879
2024-10-30 21:17:45: [2024-10-30 21:17:45] iter = 17470, loss = 45.2905
2024-10-30 21:17:47: [2024-10-30 21:17:47] iter = 17480, loss = 4.4039
2024-10-30 21:17:51: [2024-10-30 21:17:51] iter = 17490, loss = 16.3128
2024-10-30 21:17:55: [2024-10-30 21:17:55] iter = 17500, loss = 18.8008
2024-10-30 21:17:59: [2024-10-30 21:17:59] iter = 17510, loss = 6.0514
2024-10-30 21:18:03: [2024-10-30 21:18:03] iter = 17520, loss = 5.0732
2024-10-30 21:18:07: [2024-10-30 21:18:07] iter = 17530, loss = 31.5145
2024-10-30 21:18:11: [2024-10-30 21:18:11] iter = 17540, loss = 6.2163
2024-10-30 21:18:15: [2024-10-30 21:18:15] iter = 17550, loss = 8.0798
2024-10-30 21:18:19: [2024-10-30 21:18:19] iter = 17560, loss = 40.4047
2024-10-30 21:18:23: [2024-10-30 21:18:23] iter = 17570, loss = 8.2114
2024-10-30 21:18:27: [2024-10-30 21:18:27] iter = 17580, loss = 5.1040
2024-10-30 21:18:32: [2024-10-30 21:18:32] iter = 17590, loss = 32.6051
2024-10-30 21:18:36: [2024-10-30 21:18:36] iter = 17600, loss = 4.8717
2024-10-30 21:18:40: [2024-10-30 21:18:40] iter = 17610, loss = 30.7658
2024-10-30 21:18:44: [2024-10-30 21:18:44] iter = 17620, loss = 10.5040
2024-10-30 21:18:48: [2024-10-30 21:18:48] iter = 17630, loss = 11.7160
2024-10-30 21:18:51: [2024-10-30 21:18:51] iter = 17640, loss = 16.3922
2024-10-30 21:18:54: [2024-10-30 21:18:54] iter = 17650, loss = 14.6688
2024-10-30 21:18:57: [2024-10-30 21:18:57] iter = 17660, loss = 60.2696
2024-10-30 21:19:01: [2024-10-30 21:19:01] iter = 17670, loss = 44.2504
2024-10-30 21:19:04: [2024-10-30 21:19:04] iter = 17680, loss = 5.1154
2024-10-30 21:19:08: [2024-10-30 21:19:08] iter = 17690, loss = 22.0611
2024-10-30 21:19:11: [2024-10-30 21:19:11] iter = 17700, loss = 13.1563
2024-10-30 21:19:15: [2024-10-30 21:19:15] iter = 17710, loss = 19.8272
2024-10-30 21:19:19: [2024-10-30 21:19:19] iter = 17720, loss = 11.9372
2024-10-30 21:19:22: [2024-10-30 21:19:22] iter = 17730, loss = 22.5237
2024-10-30 21:19:26: [2024-10-30 21:19:26] iter = 17740, loss = 5.6059
2024-10-30 21:19:29: [2024-10-30 21:19:29] iter = 17750, loss = 19.8980
2024-10-30 21:19:33: [2024-10-30 21:19:33] iter = 17760, loss = 3.5674
2024-10-30 21:19:37: [2024-10-30 21:19:37] iter = 17770, loss = 11.1568
2024-10-30 21:19:40: [2024-10-30 21:19:40] iter = 17780, loss = 12.3586
2024-10-30 21:19:43: [2024-10-30 21:19:43] iter = 17790, loss = 16.1636
2024-10-30 21:19:45: [2024-10-30 21:19:45] iter = 17800, loss = 58.0830
2024-10-30 21:19:48: [2024-10-30 21:19:48] iter = 17810, loss = 3.5470
2024-10-30 21:19:52: [2024-10-30 21:19:52] iter = 17820, loss = 26.4781
2024-10-30 21:19:56: [2024-10-30 21:19:56] iter = 17830, loss = 18.1643
2024-10-30 21:19:59: [2024-10-30 21:19:59] iter = 17840, loss = 18.2262
2024-10-30 21:20:03: [2024-10-30 21:20:03] iter = 17850, loss = 5.3383
2024-10-30 21:20:07: [2024-10-30 21:20:07] iter = 17860, loss = 25.6112
2024-10-30 21:20:10: [2024-10-30 21:20:10] iter = 17870, loss = 30.9394
2024-10-30 21:20:15: [2024-10-30 21:20:15] iter = 17880, loss = 5.6773
2024-10-30 21:20:19: [2024-10-30 21:20:19] iter = 17890, loss = 4.8023
2024-10-30 21:20:23: [2024-10-30 21:20:23] iter = 17900, loss = 11.8026
2024-10-30 21:20:27: [2024-10-30 21:20:27] iter = 17910, loss = 12.6906
2024-10-30 21:20:31: [2024-10-30 21:20:31] iter = 17920, loss = 10.9345
2024-10-30 21:20:35: [2024-10-30 21:20:35] iter = 17930, loss = 37.6574
2024-10-30 21:20:39: [2024-10-30 21:20:39] iter = 17940, loss = 32.9304
2024-10-30 21:20:43: [2024-10-30 21:20:43] iter = 17950, loss = 16.4436
2024-10-30 21:20:47: [2024-10-30 21:20:47] iter = 17960, loss = 5.4623
2024-10-30 21:20:51: [2024-10-30 21:20:51] iter = 17970, loss = 33.7234
2024-10-30 21:20:55: [2024-10-30 21:20:55] iter = 17980, loss = 10.2264
2024-10-30 21:20:59: [2024-10-30 21:20:59] iter = 17990, loss = 13.6610
2024-10-30 21:21:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 21:21:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:21:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63285}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:23:29: Evaluate 5 random ConvNet, ACCmean = 0.2169 ACCstd = 0.0105
-------------------------
2024-10-30 21:23:29: Evaluate 5 random ConvNet, SENmean = 0.2624 SENstd = 0.0052
-------------------------
2024-10-30 21:23:29: Evaluate 5 random ConvNet, SPEmean = 0.8930 SPEstd = 0.0011
-------------------------
2024-10-30 21:23:29: Evaluate 5 random ConvNet, F!mean = 0.1907 F!std = 0.0113
-------------------------
2024-10-30 21:23:29: Evaluate 5 random ConvNet, mean = 0.2169 std = 0.0105
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:23:30: [2024-10-30 21:23:30] iter = 18000, loss = 40.0790
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:23:34: [2024-10-30 21:23:34] iter = 18010, loss = 93.7702
2024-10-30 21:23:37: [2024-10-30 21:23:37] iter = 18020, loss = 43.8788
2024-10-30 21:23:42: [2024-10-30 21:23:42] iter = 18030, loss = 75.1899
2024-10-30 21:23:46: [2024-10-30 21:23:46] iter = 18040, loss = 17.2386
2024-10-30 21:23:50: [2024-10-30 21:23:50] iter = 18050, loss = 34.8743
2024-10-30 21:23:54: [2024-10-30 21:23:54] iter = 18060, loss = 14.5551
2024-10-30 21:23:58: [2024-10-30 21:23:58] iter = 18070, loss = 9.3462
2024-10-30 21:24:02: [2024-10-30 21:24:02] iter = 18080, loss = 4.3426
2024-10-30 21:24:06: [2024-10-30 21:24:06] iter = 18090, loss = 10.6210
2024-10-30 21:24:10: [2024-10-30 21:24:10] iter = 18100, loss = 6.1678
2024-10-30 21:24:14: [2024-10-30 21:24:14] iter = 18110, loss = 48.9740
2024-10-30 21:24:17: [2024-10-30 21:24:17] iter = 18120, loss = 13.0187
2024-10-30 21:24:20: [2024-10-30 21:24:20] iter = 18130, loss = 24.9032
2024-10-30 21:24:24: [2024-10-30 21:24:24] iter = 18140, loss = 20.3561
2024-10-30 21:24:28: [2024-10-30 21:24:28] iter = 18150, loss = 8.4327
2024-10-30 21:24:32: [2024-10-30 21:24:32] iter = 18160, loss = 12.9042
2024-10-30 21:24:35: [2024-10-30 21:24:35] iter = 18170, loss = 18.0729
2024-10-30 21:24:38: [2024-10-30 21:24:38] iter = 18180, loss = 4.7677
2024-10-30 21:24:42: [2024-10-30 21:24:42] iter = 18190, loss = 51.0441
2024-10-30 21:24:46: [2024-10-30 21:24:46] iter = 18200, loss = 4.1802
2024-10-30 21:24:50: [2024-10-30 21:24:50] iter = 18210, loss = 9.7540
2024-10-30 21:24:55: [2024-10-30 21:24:55] iter = 18220, loss = 67.5476
2024-10-30 21:24:58: [2024-10-30 21:24:58] iter = 18230, loss = 8.5041
2024-10-30 21:25:02: [2024-10-30 21:25:02] iter = 18240, loss = 7.8054
2024-10-30 21:25:05: [2024-10-30 21:25:05] iter = 18250, loss = 44.3609
2024-10-30 21:25:09: [2024-10-30 21:25:09] iter = 18260, loss = 11.9439
2024-10-30 21:25:14: [2024-10-30 21:25:14] iter = 18270, loss = 5.3279
2024-10-30 21:25:19: [2024-10-30 21:25:19] iter = 18280, loss = 5.3619
2024-10-30 21:25:22: [2024-10-30 21:25:22] iter = 18290, loss = 6.8398
2024-10-30 21:25:26: [2024-10-30 21:25:26] iter = 18300, loss = 7.9952
2024-10-30 21:25:31: [2024-10-30 21:25:31] iter = 18310, loss = 6.3739
2024-10-30 21:25:35: [2024-10-30 21:25:35] iter = 18320, loss = 31.8234
2024-10-30 21:25:40: [2024-10-30 21:25:40] iter = 18330, loss = 40.4372
2024-10-30 21:25:44: [2024-10-30 21:25:44] iter = 18340, loss = 65.9804
2024-10-30 21:25:47: [2024-10-30 21:25:47] iter = 18350, loss = 14.9162
2024-10-30 21:25:51: [2024-10-30 21:25:51] iter = 18360, loss = 20.7165
2024-10-30 21:25:56: [2024-10-30 21:25:56] iter = 18370, loss = 3.0999
2024-10-30 21:26:00: [2024-10-30 21:26:00] iter = 18380, loss = 12.0631
2024-10-30 21:26:04: [2024-10-30 21:26:04] iter = 18390, loss = 5.8601
2024-10-30 21:26:09: [2024-10-30 21:26:09] iter = 18400, loss = 24.4078
2024-10-30 21:26:13: [2024-10-30 21:26:13] iter = 18410, loss = 27.8518
2024-10-30 21:26:17: [2024-10-30 21:26:17] iter = 18420, loss = 8.6807
2024-10-30 21:26:21: [2024-10-30 21:26:21] iter = 18430, loss = 10.2022
2024-10-30 21:26:26: [2024-10-30 21:26:26] iter = 18440, loss = 4.5466
2024-10-30 21:26:30: [2024-10-30 21:26:30] iter = 18450, loss = 49.3478
2024-10-30 21:26:34: [2024-10-30 21:26:34] iter = 18460, loss = 4.9896
2024-10-30 21:26:37: [2024-10-30 21:26:37] iter = 18470, loss = 26.4189
2024-10-30 21:26:42: [2024-10-30 21:26:42] iter = 18480, loss = 65.9457
2024-10-30 21:26:46: [2024-10-30 21:26:46] iter = 18490, loss = 27.7884
2024-10-30 21:26:50: [2024-10-30 21:26:50] iter = 18500, loss = 26.3217
2024-10-30 21:26:53: [2024-10-30 21:26:53] iter = 18510, loss = 7.3958
2024-10-30 21:26:58: [2024-10-30 21:26:58] iter = 18520, loss = 21.3256
2024-10-30 21:27:01: [2024-10-30 21:27:01] iter = 18530, loss = 8.6185
2024-10-30 21:27:06: [2024-10-30 21:27:06] iter = 18540, loss = 68.1001
2024-10-30 21:27:09: [2024-10-30 21:27:09] iter = 18550, loss = 12.2591
2024-10-30 21:27:13: [2024-10-30 21:27:13] iter = 18560, loss = 7.0191
2024-10-30 21:27:17: [2024-10-30 21:27:17] iter = 18570, loss = 12.5478
2024-10-30 21:27:21: [2024-10-30 21:27:21] iter = 18580, loss = 15.3248
2024-10-30 21:27:26: [2024-10-30 21:27:26] iter = 18590, loss = 48.5046
2024-10-30 21:27:30: [2024-10-30 21:27:30] iter = 18600, loss = 7.8765
2024-10-30 21:27:35: [2024-10-30 21:27:35] iter = 18610, loss = 6.3403
2024-10-30 21:27:38: [2024-10-30 21:27:38] iter = 18620, loss = 27.2930
2024-10-30 21:27:41: [2024-10-30 21:27:41] iter = 18630, loss = 42.3435
2024-10-30 21:27:46: [2024-10-30 21:27:46] iter = 18640, loss = 5.3901
2024-10-30 21:27:50: [2024-10-30 21:27:50] iter = 18650, loss = 18.0551
2024-10-30 21:27:54: [2024-10-30 21:27:54] iter = 18660, loss = 54.7841
2024-10-30 21:27:58: [2024-10-30 21:27:58] iter = 18670, loss = 6.5554
2024-10-30 21:28:02: [2024-10-30 21:28:02] iter = 18680, loss = 54.0107
2024-10-30 21:28:05: [2024-10-30 21:28:05] iter = 18690, loss = 17.9046
2024-10-30 21:28:09: [2024-10-30 21:28:09] iter = 18700, loss = 28.6767
2024-10-30 21:28:13: [2024-10-30 21:28:13] iter = 18710, loss = 14.6488
2024-10-30 21:28:18: [2024-10-30 21:28:18] iter = 18720, loss = 9.9121
2024-10-30 21:28:23: [2024-10-30 21:28:23] iter = 18730, loss = 4.1543
2024-10-30 21:28:27: [2024-10-30 21:28:27] iter = 18740, loss = 19.7580
2024-10-30 21:28:31: [2024-10-30 21:28:31] iter = 18750, loss = 5.2190
2024-10-30 21:28:35: [2024-10-30 21:28:35] iter = 18760, loss = 5.6280
2024-10-30 21:28:39: [2024-10-30 21:28:39] iter = 18770, loss = 28.7031
2024-10-30 21:28:43: [2024-10-30 21:28:43] iter = 18780, loss = 46.6187
2024-10-30 21:28:46: [2024-10-30 21:28:46] iter = 18790, loss = 4.6607
2024-10-30 21:28:49: [2024-10-30 21:28:49] iter = 18800, loss = 3.7491
2024-10-30 21:28:52: [2024-10-30 21:28:52] iter = 18810, loss = 4.4256
2024-10-30 21:28:56: [2024-10-30 21:28:56] iter = 18820, loss = 14.1061
2024-10-30 21:29:00: [2024-10-30 21:29:00] iter = 18830, loss = 11.4351
2024-10-30 21:29:03: [2024-10-30 21:29:03] iter = 18840, loss = 6.5874
2024-10-30 21:29:06: [2024-10-30 21:29:06] iter = 18850, loss = 6.1392
2024-10-30 21:29:09: [2024-10-30 21:29:09] iter = 18860, loss = 4.2281
2024-10-30 21:29:13: [2024-10-30 21:29:13] iter = 18870, loss = 6.5738
2024-10-30 21:29:17: [2024-10-30 21:29:17] iter = 18880, loss = 3.3608
2024-10-30 21:29:21: [2024-10-30 21:29:21] iter = 18890, loss = 17.8264
2024-10-30 21:29:24: [2024-10-30 21:29:24] iter = 18900, loss = 32.6142
2024-10-30 21:29:28: [2024-10-30 21:29:28] iter = 18910, loss = 4.7953
2024-10-30 21:29:32: [2024-10-30 21:29:32] iter = 18920, loss = 11.0306
2024-10-30 21:29:36: [2024-10-30 21:29:36] iter = 18930, loss = 30.0983
2024-10-30 21:29:40: [2024-10-30 21:29:40] iter = 18940, loss = 25.6940
2024-10-30 21:29:44: [2024-10-30 21:29:44] iter = 18950, loss = 26.0326
2024-10-30 21:29:47: [2024-10-30 21:29:47] iter = 18960, loss = 4.4666
2024-10-30 21:29:50: [2024-10-30 21:29:50] iter = 18970, loss = 26.0632
2024-10-30 21:29:53: [2024-10-30 21:29:53] iter = 18980, loss = 21.6819
2024-10-30 21:29:56: [2024-10-30 21:29:56] iter = 18990, loss = 26.5056
2024-10-30 21:29:59: [2024-10-30 21:29:59] iter = 19000, loss = 13.0550
2024-10-30 21:30:03: [2024-10-30 21:30:03] iter = 19010, loss = 5.8493
2024-10-30 21:30:07: [2024-10-30 21:30:07] iter = 19020, loss = 21.7461
2024-10-30 21:30:10: [2024-10-30 21:30:10] iter = 19030, loss = 47.4940
2024-10-30 21:30:14: [2024-10-30 21:30:14] iter = 19040, loss = 21.9026
2024-10-30 21:30:18: [2024-10-30 21:30:18] iter = 19050, loss = 15.5231
2024-10-30 21:30:22: [2024-10-30 21:30:22] iter = 19060, loss = 8.0673
2024-10-30 21:30:25: [2024-10-30 21:30:25] iter = 19070, loss = 36.2903
2024-10-30 21:30:29: [2024-10-30 21:30:29] iter = 19080, loss = 13.2704
2024-10-30 21:30:33: [2024-10-30 21:30:33] iter = 19090, loss = 18.7048
2024-10-30 21:30:38: [2024-10-30 21:30:38] iter = 19100, loss = 18.6237
2024-10-30 21:30:41: [2024-10-30 21:30:41] iter = 19110, loss = 84.8823
2024-10-30 21:30:45: [2024-10-30 21:30:45] iter = 19120, loss = 4.0095
2024-10-30 21:30:49: [2024-10-30 21:30:49] iter = 19130, loss = 11.1516
2024-10-30 21:30:53: [2024-10-30 21:30:53] iter = 19140, loss = 13.7657
2024-10-30 21:30:58: [2024-10-30 21:30:58] iter = 19150, loss = 5.8861
2024-10-30 21:31:02: [2024-10-30 21:31:02] iter = 19160, loss = 30.8675
2024-10-30 21:31:06: [2024-10-30 21:31:06] iter = 19170, loss = 42.9418
2024-10-30 21:31:10: [2024-10-30 21:31:10] iter = 19180, loss = 13.8283
2024-10-30 21:31:14: [2024-10-30 21:31:14] iter = 19190, loss = 24.5683
2024-10-30 21:31:17: [2024-10-30 21:31:17] iter = 19200, loss = 4.6973
2024-10-30 21:31:21: [2024-10-30 21:31:21] iter = 19210, loss = 23.7153
2024-10-30 21:31:25: [2024-10-30 21:31:25] iter = 19220, loss = 17.3790
2024-10-30 21:31:30: [2024-10-30 21:31:30] iter = 19230, loss = 38.6076
2024-10-30 21:31:34: [2024-10-30 21:31:34] iter = 19240, loss = 27.3741
2024-10-30 21:31:38: [2024-10-30 21:31:38] iter = 19250, loss = 17.8109
2024-10-30 21:31:42: [2024-10-30 21:31:42] iter = 19260, loss = 35.0859
2024-10-30 21:31:46: [2024-10-30 21:31:46] iter = 19270, loss = 5.2095
2024-10-30 21:31:50: [2024-10-30 21:31:50] iter = 19280, loss = 4.1261
2024-10-30 21:31:55: [2024-10-30 21:31:55] iter = 19290, loss = 30.4318
2024-10-30 21:31:58: [2024-10-30 21:31:58] iter = 19300, loss = 8.0391
2024-10-30 21:32:00: [2024-10-30 21:32:00] iter = 19310, loss = 21.7123
2024-10-30 21:32:04: [2024-10-30 21:32:04] iter = 19320, loss = 46.9130
2024-10-30 21:32:07: [2024-10-30 21:32:07] iter = 19330, loss = 21.8892
2024-10-30 21:32:09: [2024-10-30 21:32:09] iter = 19340, loss = 6.0733
2024-10-30 21:32:12: [2024-10-30 21:32:12] iter = 19350, loss = 5.8324
2024-10-30 21:32:16: [2024-10-30 21:32:16] iter = 19360, loss = 12.0920
2024-10-30 21:32:19: [2024-10-30 21:32:19] iter = 19370, loss = 25.7220
2024-10-30 21:32:22: [2024-10-30 21:32:22] iter = 19380, loss = 8.6338
2024-10-30 21:32:26: [2024-10-30 21:32:26] iter = 19390, loss = 4.0116
2024-10-30 21:32:29: [2024-10-30 21:32:29] iter = 19400, loss = 22.2293
2024-10-30 21:32:32: [2024-10-30 21:32:32] iter = 19410, loss = 10.6780
2024-10-30 21:32:35: [2024-10-30 21:32:35] iter = 19420, loss = 17.6482
2024-10-30 21:32:37: [2024-10-30 21:32:37] iter = 19430, loss = 30.1265
2024-10-30 21:32:42: [2024-10-30 21:32:42] iter = 19440, loss = 37.4320
2024-10-30 21:32:46: [2024-10-30 21:32:46] iter = 19450, loss = 32.8773
2024-10-30 21:32:50: [2024-10-30 21:32:50] iter = 19460, loss = 8.2322
2024-10-30 21:32:54: [2024-10-30 21:32:54] iter = 19470, loss = 32.5537
2024-10-30 21:32:57: [2024-10-30 21:32:57] iter = 19480, loss = 15.5658
2024-10-30 21:33:01: [2024-10-30 21:33:01] iter = 19490, loss = 6.0617
2024-10-30 21:33:05: [2024-10-30 21:33:05] iter = 19500, loss = 4.0661
2024-10-30 21:33:08: [2024-10-30 21:33:08] iter = 19510, loss = 74.2188
2024-10-30 21:33:11: [2024-10-30 21:33:11] iter = 19520, loss = 14.1526
2024-10-30 21:33:14: [2024-10-30 21:33:14] iter = 19530, loss = 10.6847
2024-10-30 21:33:19: [2024-10-30 21:33:19] iter = 19540, loss = 7.1377
2024-10-30 21:33:22: [2024-10-30 21:33:22] iter = 19550, loss = 30.2252
2024-10-30 21:33:27: [2024-10-30 21:33:27] iter = 19560, loss = 75.7267
2024-10-30 21:33:30: [2024-10-30 21:33:30] iter = 19570, loss = 15.2062
2024-10-30 21:33:34: [2024-10-30 21:33:34] iter = 19580, loss = 14.5758
2024-10-30 21:33:37: [2024-10-30 21:33:37] iter = 19590, loss = 39.3270
2024-10-30 21:33:40: [2024-10-30 21:33:40] iter = 19600, loss = 36.2654
2024-10-30 21:33:43: [2024-10-30 21:33:43] iter = 19610, loss = 34.7664
2024-10-30 21:33:45: [2024-10-30 21:33:45] iter = 19620, loss = 11.0937
2024-10-30 21:33:48: [2024-10-30 21:33:48] iter = 19630, loss = 61.6127
2024-10-30 21:33:52: [2024-10-30 21:33:52] iter = 19640, loss = 25.9978
2024-10-30 21:33:56: [2024-10-30 21:33:56] iter = 19650, loss = 5.7776
2024-10-30 21:33:59: [2024-10-30 21:33:59] iter = 19660, loss = 5.3344
2024-10-30 21:34:03: [2024-10-30 21:34:03] iter = 19670, loss = 7.4144
2024-10-30 21:34:06: [2024-10-30 21:34:06] iter = 19680, loss = 71.8458
2024-10-30 21:34:10: [2024-10-30 21:34:10] iter = 19690, loss = 19.1679
2024-10-30 21:34:13: [2024-10-30 21:34:13] iter = 19700, loss = 8.6177
2024-10-30 21:34:17: [2024-10-30 21:34:17] iter = 19710, loss = 13.7353
2024-10-30 21:34:20: [2024-10-30 21:34:20] iter = 19720, loss = 34.2359
2024-10-30 21:34:24: [2024-10-30 21:34:24] iter = 19730, loss = 5.1801
2024-10-30 21:34:28: [2024-10-30 21:34:28] iter = 19740, loss = 6.3255
2024-10-30 21:34:32: [2024-10-30 21:34:32] iter = 19750, loss = 4.2398
2024-10-30 21:34:36: [2024-10-30 21:34:36] iter = 19760, loss = 11.6241
2024-10-30 21:34:41: [2024-10-30 21:34:41] iter = 19770, loss = 14.8565
2024-10-30 21:34:45: [2024-10-30 21:34:45] iter = 19780, loss = 44.1252
2024-10-30 21:34:49: [2024-10-30 21:34:49] iter = 19790, loss = 7.6471
2024-10-30 21:34:52: [2024-10-30 21:34:52] iter = 19800, loss = 5.9884
2024-10-30 21:34:56: [2024-10-30 21:34:56] iter = 19810, loss = 4.5409
2024-10-30 21:35:00: [2024-10-30 21:35:00] iter = 19820, loss = 38.9044
2024-10-30 21:35:05: [2024-10-30 21:35:05] iter = 19830, loss = 4.8085
2024-10-30 21:35:10: [2024-10-30 21:35:10] iter = 19840, loss = 23.1665
2024-10-30 21:35:14: [2024-10-30 21:35:14] iter = 19850, loss = 3.7454
2024-10-30 21:35:19: [2024-10-30 21:35:19] iter = 19860, loss = 56.0482
2024-10-30 21:35:23: [2024-10-30 21:35:23] iter = 19870, loss = 12.7432
2024-10-30 21:35:28: [2024-10-30 21:35:28] iter = 19880, loss = 41.0727
2024-10-30 21:35:32: [2024-10-30 21:35:32] iter = 19890, loss = 28.8172
2024-10-30 21:35:37: [2024-10-30 21:35:37] iter = 19900, loss = 5.1051
2024-10-30 21:35:40: [2024-10-30 21:35:40] iter = 19910, loss = 4.2839
2024-10-30 21:35:44: [2024-10-30 21:35:44] iter = 19920, loss = 9.9934
2024-10-30 21:35:49: [2024-10-30 21:35:49] iter = 19930, loss = 4.4451
2024-10-30 21:35:54: [2024-10-30 21:35:54] iter = 19940, loss = 11.6896
2024-10-30 21:35:59: [2024-10-30 21:35:59] iter = 19950, loss = 6.1052
2024-10-30 21:36:04: [2024-10-30 21:36:04] iter = 19960, loss = 15.5297
2024-10-30 21:36:10: [2024-10-30 21:36:10] iter = 19970, loss = 57.6981
2024-10-30 21:36:14: [2024-10-30 21:36:14] iter = 19980, loss = 5.3129
2024-10-30 21:36:19: [2024-10-30 21:36:19] iter = 19990, loss = 14.1979
2024-10-30 21:36:22: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 21:36:22: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:36:22: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 82910}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:38:49: Evaluate 5 random ConvNet, ACCmean = 0.3260 ACCstd = 0.0076
-------------------------
2024-10-30 21:38:50: Evaluate 5 random ConvNet, SENmean = 0.3181 SENstd = 0.0035
-------------------------
2024-10-30 21:38:50: Evaluate 5 random ConvNet, SPEmean = 0.9043 SPEstd = 0.0008
-------------------------
2024-10-30 21:38:50: Evaluate 5 random ConvNet, F!mean = 0.2706 F!std = 0.0071
-------------------------
2024-10-30 21:38:50: Evaluate 5 random ConvNet, mean = 0.3260 std = 0.0076
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:38:50: [2024-10-30 21:38:50] iter = 20000, loss = 17.8682
2024-10-30 21:38:50: 
================== Exp 3 ==================
 
2024-10-30 21:38:50: Hyper-parameters: 
{'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ffaf9964b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_TissueMNIST (INFO)>}
2024-10-30 21:38:50: Evaluation model pool: ['ConvNet']
2024-10-30 21:39:09: class c = 0: 53075 real images
2024-10-30 21:39:09: class c = 1: 7814 real images
2024-10-30 21:39:09: class c = 2: 5866 real images
2024-10-30 21:39:09: class c = 3: 15406 real images
2024-10-30 21:39:09: class c = 4: 11789 real images
2024-10-30 21:39:09: class c = 5: 7705 real images
2024-10-30 21:39:09: class c = 6: 39203 real images
2024-10-30 21:39:09: class c = 7: 24608 real images
2024-10-30 21:39:09: real images channel 0, mean = 0.1020, std = 0.1000
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-30 21:39:09: initialize synthetic data from random real images
2024-10-30 21:39:09: [2024-10-30 21:39:09] training begins
2024-10-30 21:39:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-30 21:39:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:39:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 30498}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:41:38: Evaluate 5 random ConvNet, ACCmean = 0.2403 ACCstd = 0.0062
-------------------------
2024-10-30 21:41:38: Evaluate 5 random ConvNet, SENmean = 0.2308 SENstd = 0.0027
-------------------------
2024-10-30 21:41:38: Evaluate 5 random ConvNet, SPEmean = 0.8903 SPEstd = 0.0005
-------------------------
2024-10-30 21:41:38: Evaluate 5 random ConvNet, F!mean = 0.2097 F!std = 0.0031
-------------------------
2024-10-30 21:41:38: Evaluate 5 random ConvNet, mean = 0.2403 std = 0.0062
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:41:39: [2024-10-30 21:41:39] iter = 00000, loss = 21.6773
2024-10-30 21:41:43: [2024-10-30 21:41:43] iter = 00010, loss = 47.7114
2024-10-30 21:41:47: [2024-10-30 21:41:47] iter = 00020, loss = 20.5293
2024-10-30 21:41:50: [2024-10-30 21:41:50] iter = 00030, loss = 40.1371
2024-10-30 21:41:54: [2024-10-30 21:41:54] iter = 00040, loss = 8.3490
2024-10-30 21:41:57: [2024-10-30 21:41:57] iter = 00050, loss = 23.4635
2024-10-30 21:42:01: [2024-10-30 21:42:01] iter = 00060, loss = 7.7548
2024-10-30 21:42:04: [2024-10-30 21:42:04] iter = 00070, loss = 20.1607
2024-10-30 21:42:09: [2024-10-30 21:42:09] iter = 00080, loss = 10.0001
2024-10-30 21:42:12: [2024-10-30 21:42:12] iter = 00090, loss = 8.2803
2024-10-30 21:42:16: [2024-10-30 21:42:16] iter = 00100, loss = 15.8766
2024-10-30 21:42:20: [2024-10-30 21:42:20] iter = 00110, loss = 16.4447
2024-10-30 21:42:23: [2024-10-30 21:42:23] iter = 00120, loss = 14.4521
2024-10-30 21:42:26: [2024-10-30 21:42:26] iter = 00130, loss = 30.7227
2024-10-30 21:42:31: [2024-10-30 21:42:31] iter = 00140, loss = 3.5630
2024-10-30 21:42:34: [2024-10-30 21:42:34] iter = 00150, loss = 12.2776
2024-10-30 21:42:39: [2024-10-30 21:42:39] iter = 00160, loss = 45.2222
2024-10-30 21:42:43: [2024-10-30 21:42:43] iter = 00170, loss = 20.0568
2024-10-30 21:42:49: [2024-10-30 21:42:49] iter = 00180, loss = 22.3896
2024-10-30 21:42:53: [2024-10-30 21:42:53] iter = 00190, loss = 8.4182
2024-10-30 21:42:58: [2024-10-30 21:42:58] iter = 00200, loss = 4.7099
2024-10-30 21:43:02: [2024-10-30 21:43:02] iter = 00210, loss = 26.7559
2024-10-30 21:43:06: [2024-10-30 21:43:06] iter = 00220, loss = 62.1042
2024-10-30 21:43:10: [2024-10-30 21:43:10] iter = 00230, loss = 15.6289
2024-10-30 21:43:15: [2024-10-30 21:43:15] iter = 00240, loss = 4.3261
2024-10-30 21:43:20: [2024-10-30 21:43:20] iter = 00250, loss = 11.3052
2024-10-30 21:43:25: [2024-10-30 21:43:25] iter = 00260, loss = 79.9542
2024-10-30 21:43:29: [2024-10-30 21:43:29] iter = 00270, loss = 5.1627
2024-10-30 21:43:34: [2024-10-30 21:43:34] iter = 00280, loss = 38.6907
2024-10-30 21:43:38: [2024-10-30 21:43:38] iter = 00290, loss = 3.6183
2024-10-30 21:43:42: [2024-10-30 21:43:42] iter = 00300, loss = 10.7559
2024-10-30 21:43:46: [2024-10-30 21:43:46] iter = 00310, loss = 94.8093
2024-10-30 21:43:50: [2024-10-30 21:43:50] iter = 00320, loss = 6.6964
2024-10-30 21:43:53: [2024-10-30 21:43:53] iter = 00330, loss = 7.6464
2024-10-30 21:43:57: [2024-10-30 21:43:57] iter = 00340, loss = 62.7444
2024-10-30 21:44:01: [2024-10-30 21:44:01] iter = 00350, loss = 16.1094
2024-10-30 21:44:05: [2024-10-30 21:44:05] iter = 00360, loss = 46.4381
2024-10-30 21:44:09: [2024-10-30 21:44:09] iter = 00370, loss = 28.4635
2024-10-30 21:44:12: [2024-10-30 21:44:12] iter = 00380, loss = 49.8060
2024-10-30 21:44:16: [2024-10-30 21:44:16] iter = 00390, loss = 6.5568
2024-10-30 21:44:20: [2024-10-30 21:44:20] iter = 00400, loss = 18.6908
2024-10-30 21:44:24: [2024-10-30 21:44:24] iter = 00410, loss = 41.4426
2024-10-30 21:44:29: [2024-10-30 21:44:29] iter = 00420, loss = 53.8212
2024-10-30 21:44:34: [2024-10-30 21:44:34] iter = 00430, loss = 5.6678
2024-10-30 21:44:38: [2024-10-30 21:44:38] iter = 00440, loss = 7.3034
2024-10-30 21:44:41: [2024-10-30 21:44:41] iter = 00450, loss = 7.7807
2024-10-30 21:44:44: [2024-10-30 21:44:44] iter = 00460, loss = 12.0429
2024-10-30 21:44:47: [2024-10-30 21:44:47] iter = 00470, loss = 25.7098
2024-10-30 21:44:51: [2024-10-30 21:44:51] iter = 00480, loss = 42.7775
2024-10-30 21:44:55: [2024-10-30 21:44:55] iter = 00490, loss = 12.4531
2024-10-30 21:44:59: [2024-10-30 21:44:59] iter = 00500, loss = 53.8844
2024-10-30 21:45:02: [2024-10-30 21:45:02] iter = 00510, loss = 24.0067
2024-10-30 21:45:07: [2024-10-30 21:45:07] iter = 00520, loss = 36.0870
2024-10-30 21:45:11: [2024-10-30 21:45:11] iter = 00530, loss = 14.0997
2024-10-30 21:45:16: [2024-10-30 21:45:16] iter = 00540, loss = 35.5631
2024-10-30 21:45:20: [2024-10-30 21:45:20] iter = 00550, loss = 4.6835
2024-10-30 21:45:23: [2024-10-30 21:45:23] iter = 00560, loss = 5.9393
2024-10-30 21:45:28: [2024-10-30 21:45:28] iter = 00570, loss = 22.3965
2024-10-30 21:45:32: [2024-10-30 21:45:32] iter = 00580, loss = 6.3732
2024-10-30 21:45:36: [2024-10-30 21:45:36] iter = 00590, loss = 4.9972
2024-10-30 21:45:41: [2024-10-30 21:45:41] iter = 00600, loss = 10.1734
2024-10-30 21:45:45: [2024-10-30 21:45:45] iter = 00610, loss = 7.6284
2024-10-30 21:45:48: [2024-10-30 21:45:48] iter = 00620, loss = 21.9767
2024-10-30 21:45:52: [2024-10-30 21:45:52] iter = 00630, loss = 10.9469
2024-10-30 21:45:56: [2024-10-30 21:45:56] iter = 00640, loss = 38.1282
2024-10-30 21:46:01: [2024-10-30 21:46:01] iter = 00650, loss = 29.0303
2024-10-30 21:46:04: [2024-10-30 21:46:04] iter = 00660, loss = 18.5283
2024-10-30 21:46:09: [2024-10-30 21:46:09] iter = 00670, loss = 16.9033
2024-10-30 21:46:13: [2024-10-30 21:46:13] iter = 00680, loss = 23.3159
2024-10-30 21:46:17: [2024-10-30 21:46:17] iter = 00690, loss = 27.7672
2024-10-30 21:46:21: [2024-10-30 21:46:21] iter = 00700, loss = 3.7125
2024-10-30 21:46:25: [2024-10-30 21:46:25] iter = 00710, loss = 15.9818
2024-10-30 21:46:29: [2024-10-30 21:46:29] iter = 00720, loss = 11.5120
2024-10-30 21:46:33: [2024-10-30 21:46:33] iter = 00730, loss = 27.8202
2024-10-30 21:46:37: [2024-10-30 21:46:37] iter = 00740, loss = 47.7583
2024-10-30 21:46:41: [2024-10-30 21:46:41] iter = 00750, loss = 7.7884
2024-10-30 21:46:45: [2024-10-30 21:46:45] iter = 00760, loss = 36.0377
2024-10-30 21:46:49: [2024-10-30 21:46:49] iter = 00770, loss = 23.9661
2024-10-30 21:46:54: [2024-10-30 21:46:54] iter = 00780, loss = 11.5807
2024-10-30 21:46:59: [2024-10-30 21:46:59] iter = 00790, loss = 4.1823
2024-10-30 21:47:03: [2024-10-30 21:47:03] iter = 00800, loss = 4.1219
2024-10-30 21:47:06: [2024-10-30 21:47:06] iter = 00810, loss = 5.1221
2024-10-30 21:47:09: [2024-10-30 21:47:09] iter = 00820, loss = 15.5020
2024-10-30 21:47:13: [2024-10-30 21:47:13] iter = 00830, loss = 18.3918
2024-10-30 21:47:17: [2024-10-30 21:47:17] iter = 00840, loss = 37.4573
2024-10-30 21:47:20: [2024-10-30 21:47:20] iter = 00850, loss = 16.3148
2024-10-30 21:47:24: [2024-10-30 21:47:24] iter = 00860, loss = 38.3660
2024-10-30 21:47:28: [2024-10-30 21:47:28] iter = 00870, loss = 5.4877
2024-10-30 21:47:31: [2024-10-30 21:47:31] iter = 00880, loss = 64.6373
2024-10-30 21:47:35: [2024-10-30 21:47:35] iter = 00890, loss = 9.1651
2024-10-30 21:47:38: [2024-10-30 21:47:38] iter = 00900, loss = 8.6435
2024-10-30 21:47:41: [2024-10-30 21:47:41] iter = 00910, loss = 18.6408
2024-10-30 21:47:45: [2024-10-30 21:47:45] iter = 00920, loss = 38.9069
2024-10-30 21:47:49: [2024-10-30 21:47:49] iter = 00930, loss = 51.2779
2024-10-30 21:47:53: [2024-10-30 21:47:53] iter = 00940, loss = 67.4810
2024-10-30 21:47:57: [2024-10-30 21:47:57] iter = 00950, loss = 11.3176
2024-10-30 21:48:01: [2024-10-30 21:48:01] iter = 00960, loss = 12.1996
2024-10-30 21:48:04: [2024-10-30 21:48:04] iter = 00970, loss = 9.3192
2024-10-30 21:48:07: [2024-10-30 21:48:07] iter = 00980, loss = 22.9363
2024-10-30 21:48:11: [2024-10-30 21:48:11] iter = 00990, loss = 8.9886
2024-10-30 21:48:15: [2024-10-30 21:48:15] iter = 01000, loss = 36.0388
2024-10-30 21:48:19: [2024-10-30 21:48:19] iter = 01010, loss = 9.9101
2024-10-30 21:48:23: [2024-10-30 21:48:23] iter = 01020, loss = 29.9258
2024-10-30 21:48:27: [2024-10-30 21:48:27] iter = 01030, loss = 18.9264
2024-10-30 21:48:31: [2024-10-30 21:48:31] iter = 01040, loss = 6.1727
2024-10-30 21:48:34: [2024-10-30 21:48:34] iter = 01050, loss = 3.7550
2024-10-30 21:48:36: [2024-10-30 21:48:36] iter = 01060, loss = 4.5313
2024-10-30 21:48:39: [2024-10-30 21:48:39] iter = 01070, loss = 4.3968
2024-10-30 21:48:42: [2024-10-30 21:48:42] iter = 01080, loss = 5.1571
2024-10-30 21:48:45: [2024-10-30 21:48:45] iter = 01090, loss = 11.0536
2024-10-30 21:48:49: [2024-10-30 21:48:49] iter = 01100, loss = 18.5749
2024-10-30 21:48:54: [2024-10-30 21:48:54] iter = 01110, loss = 51.2455
2024-10-30 21:48:58: [2024-10-30 21:48:58] iter = 01120, loss = 25.2844
2024-10-30 21:49:01: [2024-10-30 21:49:01] iter = 01130, loss = 9.8084
2024-10-30 21:49:04: [2024-10-30 21:49:04] iter = 01140, loss = 20.6437
2024-10-30 21:49:08: [2024-10-30 21:49:08] iter = 01150, loss = 31.5683
2024-10-30 21:49:12: [2024-10-30 21:49:12] iter = 01160, loss = 59.3590
2024-10-30 21:49:16: [2024-10-30 21:49:16] iter = 01170, loss = 24.2871
2024-10-30 21:49:20: [2024-10-30 21:49:20] iter = 01180, loss = 4.0730
2024-10-30 21:49:24: [2024-10-30 21:49:24] iter = 01190, loss = 22.5579
2024-10-30 21:49:28: [2024-10-30 21:49:28] iter = 01200, loss = 63.1085
2024-10-30 21:49:33: [2024-10-30 21:49:33] iter = 01210, loss = 4.4383
2024-10-30 21:49:37: [2024-10-30 21:49:37] iter = 01220, loss = 3.8358
2024-10-30 21:49:41: [2024-10-30 21:49:41] iter = 01230, loss = 13.0042
2024-10-30 21:49:45: [2024-10-30 21:49:45] iter = 01240, loss = 4.1756
2024-10-30 21:49:49: [2024-10-30 21:49:49] iter = 01250, loss = 42.5220
2024-10-30 21:49:52: [2024-10-30 21:49:52] iter = 01260, loss = 10.9988
2024-10-30 21:49:55: [2024-10-30 21:49:55] iter = 01270, loss = 90.0351
2024-10-30 21:50:00: [2024-10-30 21:50:00] iter = 01280, loss = 22.9238
2024-10-30 21:50:03: [2024-10-30 21:50:03] iter = 01290, loss = 4.4017
2024-10-30 21:50:07: [2024-10-30 21:50:07] iter = 01300, loss = 3.6223
2024-10-30 21:50:12: [2024-10-30 21:50:12] iter = 01310, loss = 11.2322
2024-10-30 21:50:15: [2024-10-30 21:50:15] iter = 01320, loss = 23.0282
2024-10-30 21:50:18: [2024-10-30 21:50:18] iter = 01330, loss = 9.5156
2024-10-30 21:50:21: [2024-10-30 21:50:21] iter = 01340, loss = 29.2827
2024-10-30 21:50:26: [2024-10-30 21:50:26] iter = 01350, loss = 9.5536
2024-10-30 21:50:30: [2024-10-30 21:50:30] iter = 01360, loss = 8.2553
2024-10-30 21:50:34: [2024-10-30 21:50:34] iter = 01370, loss = 14.1065
2024-10-30 21:50:38: [2024-10-30 21:50:38] iter = 01380, loss = 35.6775
2024-10-30 21:50:43: [2024-10-30 21:50:43] iter = 01390, loss = 18.6096
2024-10-30 21:50:46: [2024-10-30 21:50:46] iter = 01400, loss = 50.9368
2024-10-30 21:50:50: [2024-10-30 21:50:50] iter = 01410, loss = 87.5332
2024-10-30 21:50:53: [2024-10-30 21:50:53] iter = 01420, loss = 7.6611
2024-10-30 21:50:57: [2024-10-30 21:50:57] iter = 01430, loss = 22.5119
2024-10-30 21:51:01: [2024-10-30 21:51:01] iter = 01440, loss = 9.5151
2024-10-30 21:51:05: [2024-10-30 21:51:05] iter = 01450, loss = 14.0632
2024-10-30 21:51:09: [2024-10-30 21:51:09] iter = 01460, loss = 17.8066
2024-10-30 21:51:13: [2024-10-30 21:51:13] iter = 01470, loss = 4.4561
2024-10-30 21:51:15: [2024-10-30 21:51:15] iter = 01480, loss = 34.8650
2024-10-30 21:51:19: [2024-10-30 21:51:19] iter = 01490, loss = 11.8462
2024-10-30 21:51:23: [2024-10-30 21:51:23] iter = 01500, loss = 3.4500
2024-10-30 21:51:27: [2024-10-30 21:51:27] iter = 01510, loss = 7.0925
2024-10-30 21:51:30: [2024-10-30 21:51:30] iter = 01520, loss = 29.0896
2024-10-30 21:51:33: [2024-10-30 21:51:33] iter = 01530, loss = 20.4336
2024-10-30 21:51:36: [2024-10-30 21:51:36] iter = 01540, loss = 9.8293
2024-10-30 21:51:40: [2024-10-30 21:51:40] iter = 01550, loss = 64.8175
2024-10-30 21:51:44: [2024-10-30 21:51:44] iter = 01560, loss = 66.4018
2024-10-30 21:51:48: [2024-10-30 21:51:48] iter = 01570, loss = 43.6919
2024-10-30 21:51:51: [2024-10-30 21:51:51] iter = 01580, loss = 16.3228
2024-10-30 21:51:55: [2024-10-30 21:51:55] iter = 01590, loss = 29.4402
2024-10-30 21:51:59: [2024-10-30 21:51:59] iter = 01600, loss = 50.1949
2024-10-30 21:52:03: [2024-10-30 21:52:03] iter = 01610, loss = 15.0709
2024-10-30 21:52:06: [2024-10-30 21:52:06] iter = 01620, loss = 7.8269
2024-10-30 21:52:10: [2024-10-30 21:52:10] iter = 01630, loss = 14.9448
2024-10-30 21:52:14: [2024-10-30 21:52:14] iter = 01640, loss = 8.7761
2024-10-30 21:52:17: [2024-10-30 21:52:17] iter = 01650, loss = 4.1003
2024-10-30 21:52:19: [2024-10-30 21:52:19] iter = 01660, loss = 8.6811
2024-10-30 21:52:22: [2024-10-30 21:52:22] iter = 01670, loss = 7.0191
2024-10-30 21:52:27: [2024-10-30 21:52:27] iter = 01680, loss = 4.3092
2024-10-30 21:52:30: [2024-10-30 21:52:30] iter = 01690, loss = 18.9372
2024-10-30 21:52:34: [2024-10-30 21:52:34] iter = 01700, loss = 20.5847
2024-10-30 21:52:37: [2024-10-30 21:52:37] iter = 01710, loss = 38.8551
2024-10-30 21:52:41: [2024-10-30 21:52:41] iter = 01720, loss = 22.3080
2024-10-30 21:52:44: [2024-10-30 21:52:44] iter = 01730, loss = 26.9728
2024-10-30 21:52:49: [2024-10-30 21:52:49] iter = 01740, loss = 41.8361
2024-10-30 21:52:53: [2024-10-30 21:52:53] iter = 01750, loss = 8.4858
2024-10-30 21:52:58: [2024-10-30 21:52:58] iter = 01760, loss = 10.0061
2024-10-30 21:53:01: [2024-10-30 21:53:01] iter = 01770, loss = 17.1315
2024-10-30 21:53:06: [2024-10-30 21:53:06] iter = 01780, loss = 23.9460
2024-10-30 21:53:10: [2024-10-30 21:53:10] iter = 01790, loss = 4.1904
2024-10-30 21:53:13: [2024-10-30 21:53:13] iter = 01800, loss = 4.9821
2024-10-30 21:53:17: [2024-10-30 21:53:17] iter = 01810, loss = 6.7356
2024-10-30 21:53:21: [2024-10-30 21:53:21] iter = 01820, loss = 11.6158
2024-10-30 21:53:24: [2024-10-30 21:53:24] iter = 01830, loss = 11.7303
2024-10-30 21:53:28: [2024-10-30 21:53:28] iter = 01840, loss = 4.7781
2024-10-30 21:53:32: [2024-10-30 21:53:32] iter = 01850, loss = 21.1378
2024-10-30 21:53:36: [2024-10-30 21:53:36] iter = 01860, loss = 15.5578
2024-10-30 21:53:39: [2024-10-30 21:53:39] iter = 01870, loss = 5.1270
2024-10-30 21:53:43: [2024-10-30 21:53:43] iter = 01880, loss = 4.2357
2024-10-30 21:53:47: [2024-10-30 21:53:47] iter = 01890, loss = 11.3478
2024-10-30 21:53:52: [2024-10-30 21:53:52] iter = 01900, loss = 4.1876
2024-10-30 21:53:56: [2024-10-30 21:53:56] iter = 01910, loss = 29.3437
2024-10-30 21:54:00: [2024-10-30 21:54:00] iter = 01920, loss = 13.0635
2024-10-30 21:54:04: [2024-10-30 21:54:04] iter = 01930, loss = 5.5500
2024-10-30 21:54:08: [2024-10-30 21:54:08] iter = 01940, loss = 6.1282
2024-10-30 21:54:12: [2024-10-30 21:54:12] iter = 01950, loss = 47.9923
2024-10-30 21:54:17: [2024-10-30 21:54:17] iter = 01960, loss = 27.7406
2024-10-30 21:54:20: [2024-10-30 21:54:20] iter = 01970, loss = 9.4973
2024-10-30 21:54:24: [2024-10-30 21:54:24] iter = 01980, loss = 26.7696
2024-10-30 21:54:28: [2024-10-30 21:54:28] iter = 01990, loss = 7.9177
2024-10-30 21:54:33: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-30 21:54:33: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 21:54:33: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 73492}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:57:28: Evaluate 5 random ConvNet, ACCmean = 0.3651 ACCstd = 0.0066
-------------------------
2024-10-30 21:57:28: Evaluate 5 random ConvNet, SENmean = 0.3327 SENstd = 0.0026
-------------------------
2024-10-30 21:57:28: Evaluate 5 random ConvNet, SPEmean = 0.9095 SPEstd = 0.0008
-------------------------
2024-10-30 21:57:28: Evaluate 5 random ConvNet, F!mean = 0.3030 F!std = 0.0035
-------------------------
2024-10-30 21:57:28: Evaluate 5 random ConvNet, mean = 0.3651 std = 0.0066
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:57:28: [2024-10-30 21:57:28] iter = 02000, loss = 3.8694
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 21:57:32: [2024-10-30 21:57:32] iter = 02010, loss = 16.5368
2024-10-30 21:57:36: [2024-10-30 21:57:36] iter = 02020, loss = 23.6863
2024-10-30 21:57:42: [2024-10-30 21:57:42] iter = 02030, loss = 17.9050
2024-10-30 21:57:47: [2024-10-30 21:57:47] iter = 02040, loss = 54.1265
2024-10-30 21:57:52: [2024-10-30 21:57:52] iter = 02050, loss = 10.0128
2024-10-30 21:57:57: [2024-10-30 21:57:57] iter = 02060, loss = 10.3459
2024-10-30 21:57:59: [2024-10-30 21:57:59] iter = 02070, loss = 25.3290
2024-10-30 21:58:02: [2024-10-30 21:58:02] iter = 02080, loss = 3.9883
2024-10-30 21:58:05: [2024-10-30 21:58:05] iter = 02090, loss = 5.5156
2024-10-30 21:58:10: [2024-10-30 21:58:10] iter = 02100, loss = 8.0744
2024-10-30 21:58:15: [2024-10-30 21:58:15] iter = 02110, loss = 24.0433
2024-10-30 21:58:19: [2024-10-30 21:58:19] iter = 02120, loss = 18.1112
2024-10-30 21:58:23: [2024-10-30 21:58:23] iter = 02130, loss = 58.8314
2024-10-30 21:58:28: [2024-10-30 21:58:28] iter = 02140, loss = 4.8182
2024-10-30 21:58:31: [2024-10-30 21:58:31] iter = 02150, loss = 60.1063
2024-10-30 21:58:35: [2024-10-30 21:58:35] iter = 02160, loss = 12.1193
2024-10-30 21:58:39: [2024-10-30 21:58:39] iter = 02170, loss = 42.1747
2024-10-30 21:58:43: [2024-10-30 21:58:43] iter = 02180, loss = 3.3914
2024-10-30 21:58:48: [2024-10-30 21:58:48] iter = 02190, loss = 18.2159
2024-10-30 21:58:52: [2024-10-30 21:58:52] iter = 02200, loss = 3.7104
2024-10-30 21:58:57: [2024-10-30 21:58:57] iter = 02210, loss = 12.0073
2024-10-30 21:59:01: [2024-10-30 21:59:01] iter = 02220, loss = 49.2477
2024-10-30 21:59:05: [2024-10-30 21:59:05] iter = 02230, loss = 5.0857
2024-10-30 21:59:09: [2024-10-30 21:59:09] iter = 02240, loss = 11.3401
2024-10-30 21:59:14: [2024-10-30 21:59:14] iter = 02250, loss = 6.9614
2024-10-30 21:59:16: [2024-10-30 21:59:16] iter = 02260, loss = 10.0079
2024-10-30 21:59:20: [2024-10-30 21:59:20] iter = 02270, loss = 13.5618
2024-10-30 21:59:24: [2024-10-30 21:59:24] iter = 02280, loss = 39.7119
2024-10-30 21:59:28: [2024-10-30 21:59:28] iter = 02290, loss = 31.1669
2024-10-30 21:59:33: [2024-10-30 21:59:33] iter = 02300, loss = 20.0896
2024-10-30 21:59:37: [2024-10-30 21:59:37] iter = 02310, loss = 3.7187
2024-10-30 21:59:41: [2024-10-30 21:59:41] iter = 02320, loss = 6.1362
2024-10-30 21:59:48: [2024-10-30 21:59:48] iter = 02330, loss = 13.7775
2024-10-30 21:59:53: [2024-10-30 21:59:53] iter = 02340, loss = 25.3300
2024-10-30 21:59:58: [2024-10-30 21:59:58] iter = 02350, loss = 46.6211
2024-10-30 22:00:03: [2024-10-30 22:00:03] iter = 02360, loss = 43.2998
2024-10-30 22:00:09: [2024-10-30 22:00:09] iter = 02370, loss = 4.9658
2024-10-30 22:00:14: [2024-10-30 22:00:14] iter = 02380, loss = 70.8167
2024-10-30 22:00:20: [2024-10-30 22:00:20] iter = 02390, loss = 10.8111
2024-10-30 22:00:24: [2024-10-30 22:00:24] iter = 02400, loss = 10.6210
2024-10-30 22:00:28: [2024-10-30 22:00:28] iter = 02410, loss = 10.9423
2024-10-30 22:00:33: [2024-10-30 22:00:33] iter = 02420, loss = 13.6789
2024-10-30 22:00:38: [2024-10-30 22:00:38] iter = 02430, loss = 10.3228
2024-10-30 22:00:43: [2024-10-30 22:00:43] iter = 02440, loss = 35.6309
2024-10-30 22:00:47: [2024-10-30 22:00:47] iter = 02450, loss = 36.8397
2024-10-30 22:00:53: [2024-10-30 22:00:53] iter = 02460, loss = 34.4136
2024-10-30 22:00:59: [2024-10-30 22:00:59] iter = 02470, loss = 74.4557
2024-10-30 22:01:04: [2024-10-30 22:01:04] iter = 02480, loss = 8.9222
2024-10-30 22:01:08: [2024-10-30 22:01:08] iter = 02490, loss = 16.6355
2024-10-30 22:01:12: [2024-10-30 22:01:12] iter = 02500, loss = 42.6830
2024-10-30 22:01:17: [2024-10-30 22:01:17] iter = 02510, loss = 6.2782
2024-10-30 22:01:22: [2024-10-30 22:01:22] iter = 02520, loss = 27.5593
2024-10-30 22:01:26: [2024-10-30 22:01:26] iter = 02530, loss = 9.7541
2024-10-30 22:01:30: [2024-10-30 22:01:30] iter = 02540, loss = 30.6013
2024-10-30 22:01:34: [2024-10-30 22:01:34] iter = 02550, loss = 6.3652
2024-10-30 22:01:37: [2024-10-30 22:01:37] iter = 02560, loss = 5.6137
2024-10-30 22:01:41: [2024-10-30 22:01:41] iter = 02570, loss = 6.7545
2024-10-30 22:01:45: [2024-10-30 22:01:45] iter = 02580, loss = 19.9289
2024-10-30 22:01:49: [2024-10-30 22:01:49] iter = 02590, loss = 13.7123
2024-10-30 22:01:54: [2024-10-30 22:01:54] iter = 02600, loss = 33.6374
2024-10-30 22:01:59: [2024-10-30 22:01:59] iter = 02610, loss = 62.3494
2024-10-30 22:02:05: [2024-10-30 22:02:05] iter = 02620, loss = 5.3481
2024-10-30 22:02:10: [2024-10-30 22:02:10] iter = 02630, loss = 6.7078
2024-10-30 22:02:13: [2024-10-30 22:02:13] iter = 02640, loss = 3.2140
2024-10-30 22:02:17: [2024-10-30 22:02:17] iter = 02650, loss = 6.2827
2024-10-30 22:02:22: [2024-10-30 22:02:22] iter = 02660, loss = 8.4311
2024-10-30 22:02:26: [2024-10-30 22:02:26] iter = 02670, loss = 31.2737
2024-10-30 22:02:29: [2024-10-30 22:02:29] iter = 02680, loss = 11.9195
2024-10-30 22:02:33: [2024-10-30 22:02:33] iter = 02690, loss = 5.3169
2024-10-30 22:02:36: [2024-10-30 22:02:36] iter = 02700, loss = 3.7199
2024-10-30 22:02:40: [2024-10-30 22:02:40] iter = 02710, loss = 9.6258
2024-10-30 22:02:43: [2024-10-30 22:02:43] iter = 02720, loss = 31.2600
2024-10-30 22:02:46: [2024-10-30 22:02:46] iter = 02730, loss = 22.3689
2024-10-30 22:02:50: [2024-10-30 22:02:50] iter = 02740, loss = 72.4649
2024-10-30 22:02:54: [2024-10-30 22:02:54] iter = 02750, loss = 26.2065
2024-10-30 22:02:58: [2024-10-30 22:02:58] iter = 02760, loss = 8.0992
2024-10-30 22:03:02: [2024-10-30 22:03:02] iter = 02770, loss = 48.1417
2024-10-30 22:03:06: [2024-10-30 22:03:06] iter = 02780, loss = 38.5815
2024-10-30 22:03:11: [2024-10-30 22:03:11] iter = 02790, loss = 4.1101
2024-10-30 22:03:14: [2024-10-30 22:03:14] iter = 02800, loss = 5.6717
2024-10-30 22:03:19: [2024-10-30 22:03:19] iter = 02810, loss = 3.8808
2024-10-30 22:03:22: [2024-10-30 22:03:22] iter = 02820, loss = 12.1075
2024-10-30 22:03:26: [2024-10-30 22:03:26] iter = 02830, loss = 11.7390
2024-10-30 22:03:30: [2024-10-30 22:03:30] iter = 02840, loss = 57.9337
2024-10-30 22:03:35: [2024-10-30 22:03:35] iter = 02850, loss = 17.5012
2024-10-30 22:03:39: [2024-10-30 22:03:39] iter = 02860, loss = 19.1320
2024-10-30 22:03:43: [2024-10-30 22:03:43] iter = 02870, loss = 4.3110
2024-10-30 22:03:46: [2024-10-30 22:03:46] iter = 02880, loss = 35.9652
2024-10-30 22:03:51: [2024-10-30 22:03:51] iter = 02890, loss = 4.8037
2024-10-30 22:03:54: [2024-10-30 22:03:54] iter = 02900, loss = 55.9280
2024-10-30 22:03:58: [2024-10-30 22:03:58] iter = 02910, loss = 14.7283
2024-10-30 22:04:02: [2024-10-30 22:04:02] iter = 02920, loss = 6.3534
2024-10-30 22:04:06: [2024-10-30 22:04:06] iter = 02930, loss = 5.5200
2024-10-30 22:04:10: [2024-10-30 22:04:10] iter = 02940, loss = 4.3858
2024-10-30 22:04:14: [2024-10-30 22:04:14] iter = 02950, loss = 16.1397
2024-10-30 22:04:17: [2024-10-30 22:04:17] iter = 02960, loss = 26.7295
2024-10-30 22:04:21: [2024-10-30 22:04:21] iter = 02970, loss = 3.5774
2024-10-30 22:04:24: [2024-10-30 22:04:24] iter = 02980, loss = 32.3315
2024-10-30 22:04:28: [2024-10-30 22:04:28] iter = 02990, loss = 26.8964
2024-10-30 22:04:32: [2024-10-30 22:04:32] iter = 03000, loss = 9.4658
2024-10-30 22:04:37: [2024-10-30 22:04:37] iter = 03010, loss = 3.5298
2024-10-30 22:04:39: [2024-10-30 22:04:39] iter = 03020, loss = 65.7106
2024-10-30 22:04:42: [2024-10-30 22:04:42] iter = 03030, loss = 82.4603
2024-10-30 22:04:45: [2024-10-30 22:04:45] iter = 03040, loss = 58.3522
2024-10-30 22:04:48: [2024-10-30 22:04:48] iter = 03050, loss = 42.4786
2024-10-30 22:04:52: [2024-10-30 22:04:52] iter = 03060, loss = 17.6991
2024-10-30 22:04:56: [2024-10-30 22:04:56] iter = 03070, loss = 67.2155
2024-10-30 22:04:59: [2024-10-30 22:04:59] iter = 03080, loss = 26.4567
2024-10-30 22:05:02: [2024-10-30 22:05:02] iter = 03090, loss = 5.2536
2024-10-30 22:05:05: [2024-10-30 22:05:05] iter = 03100, loss = 5.3921
2024-10-30 22:05:08: [2024-10-30 22:05:08] iter = 03110, loss = 3.6296
2024-10-30 22:05:12: [2024-10-30 22:05:12] iter = 03120, loss = 3.7977
2024-10-30 22:05:16: [2024-10-30 22:05:16] iter = 03130, loss = 6.2131
2024-10-30 22:05:19: [2024-10-30 22:05:19] iter = 03140, loss = 4.8781
2024-10-30 22:05:22: [2024-10-30 22:05:22] iter = 03150, loss = 3.3527
2024-10-30 22:05:26: [2024-10-30 22:05:26] iter = 03160, loss = 4.7887
2024-10-30 22:05:29: [2024-10-30 22:05:29] iter = 03170, loss = 52.9598
2024-10-30 22:05:32: [2024-10-30 22:05:32] iter = 03180, loss = 4.0066
2024-10-30 22:05:37: [2024-10-30 22:05:37] iter = 03190, loss = 59.7111
2024-10-30 22:05:39: [2024-10-30 22:05:39] iter = 03200, loss = 12.0658
2024-10-30 22:05:43: [2024-10-30 22:05:43] iter = 03210, loss = 36.2202
2024-10-30 22:05:46: [2024-10-30 22:05:46] iter = 03220, loss = 65.0857
2024-10-30 22:05:49: [2024-10-30 22:05:49] iter = 03230, loss = 38.5286
2024-10-30 22:05:53: [2024-10-30 22:05:53] iter = 03240, loss = 4.6090
2024-10-30 22:05:57: [2024-10-30 22:05:57] iter = 03250, loss = 8.5629
2024-10-30 22:06:01: [2024-10-30 22:06:01] iter = 03260, loss = 52.3838
2024-10-30 22:06:05: [2024-10-30 22:06:05] iter = 03270, loss = 5.1103
2024-10-30 22:06:08: [2024-10-30 22:06:08] iter = 03280, loss = 52.1535
2024-10-30 22:06:11: [2024-10-30 22:06:11] iter = 03290, loss = 49.6287
2024-10-30 22:06:15: [2024-10-30 22:06:15] iter = 03300, loss = 5.9493
2024-10-30 22:06:19: [2024-10-30 22:06:19] iter = 03310, loss = 41.6285
2024-10-30 22:06:24: [2024-10-30 22:06:24] iter = 03320, loss = 15.7286
2024-10-30 22:06:28: [2024-10-30 22:06:28] iter = 03330, loss = 17.0445
2024-10-30 22:06:31: [2024-10-30 22:06:31] iter = 03340, loss = 38.2596
2024-10-30 22:06:34: [2024-10-30 22:06:34] iter = 03350, loss = 4.2453
2024-10-30 22:06:37: [2024-10-30 22:06:37] iter = 03360, loss = 14.9933
2024-10-30 22:06:41: [2024-10-30 22:06:41] iter = 03370, loss = 22.0521
2024-10-30 22:06:45: [2024-10-30 22:06:45] iter = 03380, loss = 16.4893
2024-10-30 22:06:48: [2024-10-30 22:06:48] iter = 03390, loss = 12.5967
2024-10-30 22:06:51: [2024-10-30 22:06:51] iter = 03400, loss = 5.5854
2024-10-30 22:06:55: [2024-10-30 22:06:55] iter = 03410, loss = 10.5159
2024-10-30 22:06:59: [2024-10-30 22:06:59] iter = 03420, loss = 30.9814
2024-10-30 22:07:03: [2024-10-30 22:07:03] iter = 03430, loss = 4.7468
2024-10-30 22:07:06: [2024-10-30 22:07:06] iter = 03440, loss = 10.2467
2024-10-30 22:07:08: [2024-10-30 22:07:08] iter = 03450, loss = 22.0963
2024-10-30 22:07:11: [2024-10-30 22:07:11] iter = 03460, loss = 11.9807
2024-10-30 22:07:14: [2024-10-30 22:07:14] iter = 03470, loss = 8.5160
2024-10-30 22:07:17: [2024-10-30 22:07:17] iter = 03480, loss = 6.4386
2024-10-30 22:07:20: [2024-10-30 22:07:20] iter = 03490, loss = 10.4778
2024-10-30 22:07:24: [2024-10-30 22:07:24] iter = 03500, loss = 10.6626
2024-10-30 22:07:27: [2024-10-30 22:07:27] iter = 03510, loss = 19.0780
2024-10-30 22:07:30: [2024-10-30 22:07:30] iter = 03520, loss = 9.8127
2024-10-30 22:07:33: [2024-10-30 22:07:33] iter = 03530, loss = 3.7151
2024-10-30 22:07:36: [2024-10-30 22:07:36] iter = 03540, loss = 5.8433
2024-10-30 22:07:38: [2024-10-30 22:07:38] iter = 03550, loss = 42.5831
2024-10-30 22:07:42: [2024-10-30 22:07:42] iter = 03560, loss = 4.3136
2024-10-30 22:07:45: [2024-10-30 22:07:45] iter = 03570, loss = 9.3564
2024-10-30 22:07:47: [2024-10-30 22:07:47] iter = 03580, loss = 3.8614
2024-10-30 22:07:51: [2024-10-30 22:07:51] iter = 03590, loss = 3.8078
2024-10-30 22:07:55: [2024-10-30 22:07:55] iter = 03600, loss = 11.5894
2024-10-30 22:07:59: [2024-10-30 22:07:59] iter = 03610, loss = 12.7126
2024-10-30 22:08:01: [2024-10-30 22:08:01] iter = 03620, loss = 23.3771
2024-10-30 22:08:04: [2024-10-30 22:08:04] iter = 03630, loss = 53.8112
2024-10-30 22:08:08: [2024-10-30 22:08:08] iter = 03640, loss = 47.6597
2024-10-30 22:08:11: [2024-10-30 22:08:11] iter = 03650, loss = 37.4748
2024-10-30 22:08:16: [2024-10-30 22:08:16] iter = 03660, loss = 59.7292
2024-10-30 22:08:18: [2024-10-30 22:08:18] iter = 03670, loss = 5.9508
2024-10-30 22:08:22: [2024-10-30 22:08:22] iter = 03680, loss = 43.9499
2024-10-30 22:08:27: [2024-10-30 22:08:27] iter = 03690, loss = 15.7374
2024-10-30 22:08:31: [2024-10-30 22:08:31] iter = 03700, loss = 10.8895
2024-10-30 22:08:34: [2024-10-30 22:08:34] iter = 03710, loss = 41.8792
2024-10-30 22:08:38: [2024-10-30 22:08:38] iter = 03720, loss = 9.1194
2024-10-30 22:08:42: [2024-10-30 22:08:42] iter = 03730, loss = 25.5814
2024-10-30 22:08:47: [2024-10-30 22:08:47] iter = 03740, loss = 27.6626
2024-10-30 22:08:50: [2024-10-30 22:08:50] iter = 03750, loss = 22.0017
2024-10-30 22:08:54: [2024-10-30 22:08:54] iter = 03760, loss = 17.1870
2024-10-30 22:08:57: [2024-10-30 22:08:57] iter = 03770, loss = 6.0380
2024-10-30 22:09:00: [2024-10-30 22:09:00] iter = 03780, loss = 22.7516
2024-10-30 22:09:04: [2024-10-30 22:09:04] iter = 03790, loss = 40.9375
2024-10-30 22:09:07: [2024-10-30 22:09:07] iter = 03800, loss = 28.1787
2024-10-30 22:09:09: [2024-10-30 22:09:09] iter = 03810, loss = 81.3312
2024-10-30 22:09:12: [2024-10-30 22:09:12] iter = 03820, loss = 9.2987
2024-10-30 22:09:15: [2024-10-30 22:09:15] iter = 03830, loss = 5.7216
2024-10-30 22:09:20: [2024-10-30 22:09:20] iter = 03840, loss = 21.2385
2024-10-30 22:09:23: [2024-10-30 22:09:23] iter = 03850, loss = 12.5391
2024-10-30 22:09:27: [2024-10-30 22:09:27] iter = 03860, loss = 27.8529
2024-10-30 22:09:30: [2024-10-30 22:09:30] iter = 03870, loss = 70.8039
2024-10-30 22:09:32: [2024-10-30 22:09:32] iter = 03880, loss = 15.4019
2024-10-30 22:09:35: [2024-10-30 22:09:35] iter = 03890, loss = 75.0025
2024-10-30 22:09:38: [2024-10-30 22:09:38] iter = 03900, loss = 6.4286
2024-10-30 22:09:43: [2024-10-30 22:09:43] iter = 03910, loss = 5.1020
2024-10-30 22:09:48: [2024-10-30 22:09:48] iter = 03920, loss = 37.0607
2024-10-30 22:09:52: [2024-10-30 22:09:52] iter = 03930, loss = 11.0770
2024-10-30 22:09:55: [2024-10-30 22:09:55] iter = 03940, loss = 27.1922
2024-10-30 22:09:59: [2024-10-30 22:09:59] iter = 03950, loss = 7.4513
2024-10-30 22:10:03: [2024-10-30 22:10:03] iter = 03960, loss = 27.5812
2024-10-30 22:10:05: [2024-10-30 22:10:05] iter = 03970, loss = 39.0705
2024-10-30 22:10:10: [2024-10-30 22:10:10] iter = 03980, loss = 35.5058
2024-10-30 22:10:14: [2024-10-30 22:10:14] iter = 03990, loss = 56.5551
2024-10-30 22:10:17: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-30 22:10:17: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:10:17: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 17274}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:12:40: Evaluate 5 random ConvNet, ACCmean = 0.3428 ACCstd = 0.0060
-------------------------
2024-10-30 22:12:40: Evaluate 5 random ConvNet, SENmean = 0.3072 SENstd = 0.0019
-------------------------
2024-10-30 22:12:40: Evaluate 5 random ConvNet, SPEmean = 0.9065 SPEstd = 0.0005
-------------------------
2024-10-30 22:12:40: Evaluate 5 random ConvNet, F!mean = 0.2672 F!std = 0.0010
-------------------------
2024-10-30 22:12:40: Evaluate 5 random ConvNet, mean = 0.3428 std = 0.0060
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:12:41: [2024-10-30 22:12:41] iter = 04000, loss = 5.3965
2024-10-30 22:12:45: [2024-10-30 22:12:45] iter = 04010, loss = 77.7258
2024-10-30 22:12:48: [2024-10-30 22:12:48] iter = 04020, loss = 5.5400
2024-10-30 22:12:52: [2024-10-30 22:12:52] iter = 04030, loss = 21.9655
2024-10-30 22:12:55: [2024-10-30 22:12:55] iter = 04040, loss = 9.3659
2024-10-30 22:12:59: [2024-10-30 22:12:59] iter = 04050, loss = 60.6670
2024-10-30 22:13:03: [2024-10-30 22:13:03] iter = 04060, loss = 23.3743
2024-10-30 22:13:07: [2024-10-30 22:13:07] iter = 04070, loss = 38.8704
2024-10-30 22:13:09: [2024-10-30 22:13:09] iter = 04080, loss = 12.6300
2024-10-30 22:13:13: [2024-10-30 22:13:13] iter = 04090, loss = 3.9301
2024-10-30 22:13:17: [2024-10-30 22:13:17] iter = 04100, loss = 29.3259
2024-10-30 22:13:20: [2024-10-30 22:13:20] iter = 04110, loss = 72.4189
2024-10-30 22:13:23: [2024-10-30 22:13:23] iter = 04120, loss = 48.1462
2024-10-30 22:13:26: [2024-10-30 22:13:26] iter = 04130, loss = 5.0932
2024-10-30 22:13:31: [2024-10-30 22:13:31] iter = 04140, loss = 43.3005
2024-10-30 22:13:35: [2024-10-30 22:13:35] iter = 04150, loss = 4.2658
2024-10-30 22:13:39: [2024-10-30 22:13:39] iter = 04160, loss = 49.0984
2024-10-30 22:13:44: [2024-10-30 22:13:44] iter = 04170, loss = 15.3945
2024-10-30 22:13:47: [2024-10-30 22:13:47] iter = 04180, loss = 6.1961
2024-10-30 22:13:50: [2024-10-30 22:13:50] iter = 04190, loss = 13.1436
2024-10-30 22:13:53: [2024-10-30 22:13:53] iter = 04200, loss = 5.2020
2024-10-30 22:13:56: [2024-10-30 22:13:56] iter = 04210, loss = 4.2603
2024-10-30 22:14:01: [2024-10-30 22:14:01] iter = 04220, loss = 3.0356
2024-10-30 22:14:04: [2024-10-30 22:14:04] iter = 04230, loss = 14.4219
2024-10-30 22:14:09: [2024-10-30 22:14:09] iter = 04240, loss = 36.1408
2024-10-30 22:14:13: [2024-10-30 22:14:13] iter = 04250, loss = 63.0829
2024-10-30 22:14:18: [2024-10-30 22:14:18] iter = 04260, loss = 6.1491
2024-10-30 22:14:21: [2024-10-30 22:14:21] iter = 04270, loss = 58.0892
2024-10-30 22:14:25: [2024-10-30 22:14:25] iter = 04280, loss = 11.6821
2024-10-30 22:14:29: [2024-10-30 22:14:29] iter = 04290, loss = 5.9681
2024-10-30 22:14:32: [2024-10-30 22:14:32] iter = 04300, loss = 16.9742
2024-10-30 22:14:36: [2024-10-30 22:14:36] iter = 04310, loss = 7.1300
2024-10-30 22:14:41: [2024-10-30 22:14:41] iter = 04320, loss = 6.4059
2024-10-30 22:14:45: [2024-10-30 22:14:45] iter = 04330, loss = 5.7340
2024-10-30 22:14:48: [2024-10-30 22:14:48] iter = 04340, loss = 19.2188
2024-10-30 22:14:51: [2024-10-30 22:14:51] iter = 04350, loss = 4.7900
2024-10-30 22:14:54: [2024-10-30 22:14:54] iter = 04360, loss = 9.6543
2024-10-30 22:14:58: [2024-10-30 22:14:58] iter = 04370, loss = 5.2338
2024-10-30 22:15:01: [2024-10-30 22:15:01] iter = 04380, loss = 37.2804
2024-10-30 22:15:04: [2024-10-30 22:15:04] iter = 04390, loss = 40.7238
2024-10-30 22:15:09: [2024-10-30 22:15:09] iter = 04400, loss = 19.5113
2024-10-30 22:15:14: [2024-10-30 22:15:14] iter = 04410, loss = 14.7253
2024-10-30 22:15:18: [2024-10-30 22:15:18] iter = 04420, loss = 6.7750
2024-10-30 22:15:22: [2024-10-30 22:15:22] iter = 04430, loss = 5.6307
2024-10-30 22:15:26: [2024-10-30 22:15:26] iter = 04440, loss = 32.5609
2024-10-30 22:15:30: [2024-10-30 22:15:30] iter = 04450, loss = 13.8920
2024-10-30 22:15:34: [2024-10-30 22:15:34] iter = 04460, loss = 39.3779
2024-10-30 22:15:38: [2024-10-30 22:15:38] iter = 04470, loss = 5.8650
2024-10-30 22:15:43: [2024-10-30 22:15:43] iter = 04480, loss = 46.2606
2024-10-30 22:15:46: [2024-10-30 22:15:46] iter = 04490, loss = 15.0053
2024-10-30 22:15:49: [2024-10-30 22:15:49] iter = 04500, loss = 10.8733
2024-10-30 22:15:54: [2024-10-30 22:15:54] iter = 04510, loss = 17.3727
2024-10-30 22:15:58: [2024-10-30 22:15:58] iter = 04520, loss = 38.2448
2024-10-30 22:16:03: [2024-10-30 22:16:03] iter = 04530, loss = 7.9074
2024-10-30 22:16:07: [2024-10-30 22:16:07] iter = 04540, loss = 20.2385
2024-10-30 22:16:11: [2024-10-30 22:16:11] iter = 04550, loss = 7.1963
2024-10-30 22:16:16: [2024-10-30 22:16:16] iter = 04560, loss = 4.8356
2024-10-30 22:16:21: [2024-10-30 22:16:21] iter = 04570, loss = 5.7646
2024-10-30 22:16:26: [2024-10-30 22:16:26] iter = 04580, loss = 59.8319
2024-10-30 22:16:29: [2024-10-30 22:16:29] iter = 04590, loss = 6.1722
2024-10-30 22:16:33: [2024-10-30 22:16:33] iter = 04600, loss = 50.1094
2024-10-30 22:16:37: [2024-10-30 22:16:37] iter = 04610, loss = 22.8586
2024-10-30 22:16:42: [2024-10-30 22:16:42] iter = 04620, loss = 4.9013
2024-10-30 22:16:46: [2024-10-30 22:16:46] iter = 04630, loss = 27.1049
2024-10-30 22:16:50: [2024-10-30 22:16:50] iter = 04640, loss = 5.5193
2024-10-30 22:16:54: [2024-10-30 22:16:54] iter = 04650, loss = 6.0406
2024-10-30 22:16:58: [2024-10-30 22:16:58] iter = 04660, loss = 12.1882
2024-10-30 22:17:02: [2024-10-30 22:17:02] iter = 04670, loss = 12.1178
2024-10-30 22:17:06: [2024-10-30 22:17:06] iter = 04680, loss = 33.7423
2024-10-30 22:17:10: [2024-10-30 22:17:10] iter = 04690, loss = 6.8047
2024-10-30 22:17:15: [2024-10-30 22:17:15] iter = 04700, loss = 18.7821
2024-10-30 22:17:18: [2024-10-30 22:17:18] iter = 04710, loss = 21.2307
2024-10-30 22:17:22: [2024-10-30 22:17:22] iter = 04720, loss = 60.7536
2024-10-30 22:17:26: [2024-10-30 22:17:26] iter = 04730, loss = 3.2262
2024-10-30 22:17:30: [2024-10-30 22:17:30] iter = 04740, loss = 4.4742
2024-10-30 22:17:35: [2024-10-30 22:17:35] iter = 04750, loss = 18.0816
2024-10-30 22:17:40: [2024-10-30 22:17:40] iter = 04760, loss = 13.7683
2024-10-30 22:17:44: [2024-10-30 22:17:44] iter = 04770, loss = 69.6534
2024-10-30 22:17:48: [2024-10-30 22:17:48] iter = 04780, loss = 6.6431
2024-10-30 22:17:53: [2024-10-30 22:17:53] iter = 04790, loss = 7.1978
2024-10-30 22:17:57: [2024-10-30 22:17:57] iter = 04800, loss = 66.7349
2024-10-30 22:18:03: [2024-10-30 22:18:03] iter = 04810, loss = 6.3647
2024-10-30 22:18:07: [2024-10-30 22:18:07] iter = 04820, loss = 5.5644
2024-10-30 22:18:13: [2024-10-30 22:18:13] iter = 04830, loss = 6.5041
2024-10-30 22:18:18: [2024-10-30 22:18:18] iter = 04840, loss = 42.6565
2024-10-30 22:18:23: [2024-10-30 22:18:23] iter = 04850, loss = 5.6514
2024-10-30 22:18:28: [2024-10-30 22:18:28] iter = 04860, loss = 9.7037
2024-10-30 22:18:33: [2024-10-30 22:18:33] iter = 04870, loss = 63.0566
2024-10-30 22:18:39: [2024-10-30 22:18:39] iter = 04880, loss = 16.8093
2024-10-30 22:18:44: [2024-10-30 22:18:44] iter = 04890, loss = 9.8776
2024-10-30 22:18:48: [2024-10-30 22:18:48] iter = 04900, loss = 4.8955
2024-10-30 22:18:53: [2024-10-30 22:18:53] iter = 04910, loss = 35.0428
2024-10-30 22:18:57: [2024-10-30 22:18:57] iter = 04920, loss = 61.3627
2024-10-30 22:19:01: [2024-10-30 22:19:01] iter = 04930, loss = 24.4534
2024-10-30 22:19:05: [2024-10-30 22:19:05] iter = 04940, loss = 35.1539
2024-10-30 22:19:10: [2024-10-30 22:19:10] iter = 04950, loss = 30.7395
2024-10-30 22:19:15: [2024-10-30 22:19:15] iter = 04960, loss = 10.1963
2024-10-30 22:19:21: [2024-10-30 22:19:21] iter = 04970, loss = 32.3025
2024-10-30 22:19:26: [2024-10-30 22:19:26] iter = 04980, loss = 17.4881
2024-10-30 22:19:30: [2024-10-30 22:19:30] iter = 04990, loss = 15.9079
2024-10-30 22:19:35: [2024-10-30 22:19:35] iter = 05000, loss = 7.1401
2024-10-30 22:19:40: [2024-10-30 22:19:40] iter = 05010, loss = 7.1789
2024-10-30 22:19:43: [2024-10-30 22:19:43] iter = 05020, loss = 13.6441
2024-10-30 22:19:47: [2024-10-30 22:19:47] iter = 05030, loss = 44.6984
2024-10-30 22:19:51: [2024-10-30 22:19:51] iter = 05040, loss = 36.3744
2024-10-30 22:19:55: [2024-10-30 22:19:55] iter = 05050, loss = 5.5023
2024-10-30 22:19:59: [2024-10-30 22:19:59] iter = 05060, loss = 66.1259
2024-10-30 22:20:02: [2024-10-30 22:20:02] iter = 05070, loss = 60.5071
2024-10-30 22:20:07: [2024-10-30 22:20:07] iter = 05080, loss = 8.2197
2024-10-30 22:20:11: [2024-10-30 22:20:11] iter = 05090, loss = 3.5693
2024-10-30 22:20:15: [2024-10-30 22:20:15] iter = 05100, loss = 3.7127
2024-10-30 22:20:19: [2024-10-30 22:20:19] iter = 05110, loss = 4.1663
2024-10-30 22:20:22: [2024-10-30 22:20:22] iter = 05120, loss = 52.0564
2024-10-30 22:20:25: [2024-10-30 22:20:25] iter = 05130, loss = 10.1882
2024-10-30 22:20:29: [2024-10-30 22:20:29] iter = 05140, loss = 70.1103
2024-10-30 22:20:33: [2024-10-30 22:20:33] iter = 05150, loss = 29.2795
2024-10-30 22:20:36: [2024-10-30 22:20:36] iter = 05160, loss = 60.5260
2024-10-30 22:20:40: [2024-10-30 22:20:40] iter = 05170, loss = 33.5596
2024-10-30 22:20:43: [2024-10-30 22:20:43] iter = 05180, loss = 10.8889
2024-10-30 22:20:48: [2024-10-30 22:20:48] iter = 05190, loss = 5.2789
2024-10-30 22:20:52: [2024-10-30 22:20:52] iter = 05200, loss = 9.7406
2024-10-30 22:20:56: [2024-10-30 22:20:56] iter = 05210, loss = 4.4666
2024-10-30 22:20:59: [2024-10-30 22:20:59] iter = 05220, loss = 29.1784
2024-10-30 22:21:02: [2024-10-30 22:21:02] iter = 05230, loss = 5.7762
2024-10-30 22:21:07: [2024-10-30 22:21:07] iter = 05240, loss = 17.8616
2024-10-30 22:21:11: [2024-10-30 22:21:11] iter = 05250, loss = 14.6342
2024-10-30 22:21:15: [2024-10-30 22:21:15] iter = 05260, loss = 5.5024
2024-10-30 22:21:18: [2024-10-30 22:21:18] iter = 05270, loss = 25.2833
2024-10-30 22:21:22: [2024-10-30 22:21:22] iter = 05280, loss = 12.8455
2024-10-30 22:21:26: [2024-10-30 22:21:26] iter = 05290, loss = 7.1700
2024-10-30 22:21:30: [2024-10-30 22:21:30] iter = 05300, loss = 34.2682
2024-10-30 22:21:34: [2024-10-30 22:21:34] iter = 05310, loss = 66.2925
2024-10-30 22:21:38: [2024-10-30 22:21:38] iter = 05320, loss = 5.5116
2024-10-30 22:21:41: [2024-10-30 22:21:41] iter = 05330, loss = 16.7370
2024-10-30 22:21:46: [2024-10-30 22:21:46] iter = 05340, loss = 5.3855
2024-10-30 22:21:50: [2024-10-30 22:21:50] iter = 05350, loss = 66.8072
2024-10-30 22:21:54: [2024-10-30 22:21:54] iter = 05360, loss = 5.1906
2024-10-30 22:21:57: [2024-10-30 22:21:57] iter = 05370, loss = 23.8208
2024-10-30 22:22:01: [2024-10-30 22:22:01] iter = 05380, loss = 12.8757
2024-10-30 22:22:05: [2024-10-30 22:22:05] iter = 05390, loss = 5.1889
2024-10-30 22:22:09: [2024-10-30 22:22:09] iter = 05400, loss = 11.1683
2024-10-30 22:22:13: [2024-10-30 22:22:13] iter = 05410, loss = 53.3847
2024-10-30 22:22:16: [2024-10-30 22:22:16] iter = 05420, loss = 6.0702
2024-10-30 22:22:19: [2024-10-30 22:22:19] iter = 05430, loss = 13.0736
2024-10-30 22:22:23: [2024-10-30 22:22:23] iter = 05440, loss = 15.8228
2024-10-30 22:22:27: [2024-10-30 22:22:26] iter = 05450, loss = 40.6118
2024-10-30 22:22:30: [2024-10-30 22:22:30] iter = 05460, loss = 4.2030
2024-10-30 22:22:33: [2024-10-30 22:22:33] iter = 05470, loss = 3.6752
2024-10-30 22:22:36: [2024-10-30 22:22:36] iter = 05480, loss = 6.2682
2024-10-30 22:22:40: [2024-10-30 22:22:40] iter = 05490, loss = 33.9247
2024-10-30 22:22:44: [2024-10-30 22:22:44] iter = 05500, loss = 18.8186
2024-10-30 22:22:47: [2024-10-30 22:22:47] iter = 05510, loss = 19.0794
2024-10-30 22:22:51: [2024-10-30 22:22:51] iter = 05520, loss = 12.8345
2024-10-30 22:22:55: [2024-10-30 22:22:55] iter = 05530, loss = 37.0083
2024-10-30 22:22:57: [2024-10-30 22:22:57] iter = 05540, loss = 5.4021
2024-10-30 22:23:01: [2024-10-30 22:23:01] iter = 05550, loss = 24.4209
2024-10-30 22:23:05: [2024-10-30 22:23:05] iter = 05560, loss = 14.5584
2024-10-30 22:23:09: [2024-10-30 22:23:09] iter = 05570, loss = 38.0355
2024-10-30 22:23:13: [2024-10-30 22:23:13] iter = 05580, loss = 12.9526
2024-10-30 22:23:16: [2024-10-30 22:23:16] iter = 05590, loss = 34.1626
2024-10-30 22:23:20: [2024-10-30 22:23:20] iter = 05600, loss = 37.4571
2024-10-30 22:23:24: [2024-10-30 22:23:24] iter = 05610, loss = 9.3927
2024-10-30 22:23:28: [2024-10-30 22:23:28] iter = 05620, loss = 19.0609
2024-10-30 22:23:32: [2024-10-30 22:23:32] iter = 05630, loss = 5.4901
2024-10-30 22:23:34: [2024-10-30 22:23:34] iter = 05640, loss = 5.5017
2024-10-30 22:23:38: [2024-10-30 22:23:38] iter = 05650, loss = 70.7068
2024-10-30 22:23:42: [2024-10-30 22:23:42] iter = 05660, loss = 26.1569
2024-10-30 22:23:46: [2024-10-30 22:23:46] iter = 05670, loss = 40.8092
2024-10-30 22:23:50: [2024-10-30 22:23:50] iter = 05680, loss = 9.2710
2024-10-30 22:23:54: [2024-10-30 22:23:54] iter = 05690, loss = 5.2371
2024-10-30 22:23:58: [2024-10-30 22:23:58] iter = 05700, loss = 4.6766
2024-10-30 22:24:01: [2024-10-30 22:24:01] iter = 05710, loss = 13.9343
2024-10-30 22:24:06: [2024-10-30 22:24:06] iter = 05720, loss = 42.7456
2024-10-30 22:24:09: [2024-10-30 22:24:09] iter = 05730, loss = 7.7476
2024-10-30 22:24:13: [2024-10-30 22:24:13] iter = 05740, loss = 10.0096
2024-10-30 22:24:15: [2024-10-30 22:24:15] iter = 05750, loss = 17.2616
2024-10-30 22:24:19: [2024-10-30 22:24:19] iter = 05760, loss = 38.6020
2024-10-30 22:24:24: [2024-10-30 22:24:24] iter = 05770, loss = 28.1853
2024-10-30 22:24:28: [2024-10-30 22:24:28] iter = 05780, loss = 10.1828
2024-10-30 22:24:32: [2024-10-30 22:24:32] iter = 05790, loss = 4.7556
2024-10-30 22:24:37: [2024-10-30 22:24:37] iter = 05800, loss = 46.6074
2024-10-30 22:24:42: [2024-10-30 22:24:42] iter = 05810, loss = 5.8442
2024-10-30 22:24:46: [2024-10-30 22:24:46] iter = 05820, loss = 16.1006
2024-10-30 22:24:51: [2024-10-30 22:24:51] iter = 05830, loss = 26.4196
2024-10-30 22:24:55: [2024-10-30 22:24:55] iter = 05840, loss = 3.6513
2024-10-30 22:24:58: [2024-10-30 22:24:58] iter = 05850, loss = 14.9123
2024-10-30 22:25:02: [2024-10-30 22:25:02] iter = 05860, loss = 5.6953
2024-10-30 22:25:06: [2024-10-30 22:25:06] iter = 05870, loss = 5.5172
2024-10-30 22:25:11: [2024-10-30 22:25:11] iter = 05880, loss = 8.3202
2024-10-30 22:25:14: [2024-10-30 22:25:14] iter = 05890, loss = 3.2671
2024-10-30 22:25:18: [2024-10-30 22:25:18] iter = 05900, loss = 10.3848
2024-10-30 22:25:22: [2024-10-30 22:25:22] iter = 05910, loss = 7.4692
2024-10-30 22:25:26: [2024-10-30 22:25:26] iter = 05920, loss = 27.8026
2024-10-30 22:25:31: [2024-10-30 22:25:31] iter = 05930, loss = 80.1174
2024-10-30 22:25:35: [2024-10-30 22:25:35] iter = 05940, loss = 32.9463
2024-10-30 22:25:39: [2024-10-30 22:25:39] iter = 05950, loss = 12.6217
2024-10-30 22:25:43: [2024-10-30 22:25:43] iter = 05960, loss = 9.4097
2024-10-30 22:25:47: [2024-10-30 22:25:47] iter = 05970, loss = 5.8062
2024-10-30 22:25:50: [2024-10-30 22:25:50] iter = 05980, loss = 12.4179
2024-10-30 22:25:54: [2024-10-30 22:25:54] iter = 05990, loss = 10.6178
2024-10-30 22:25:57: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-30 22:25:57: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:25:57: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 57366}

[2024-10-30 20:17:52] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.002870 train acc = 1.0000, test acc = 0.3995, test_sen =0.2990, test_spe =0.9112, test_f1 =0.2786
[2024-10-30 20:18:23] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.049263 train acc = 1.0000, test acc = 0.4007, test_sen =0.3044, test_spe =0.9116, test_f1 =0.2791
[2024-10-30 20:18:52] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.006842 train acc = 1.0000, test acc = 0.3942, test_sen =0.2955, test_spe =0.9105, test_f1 =0.2749
[2024-10-30 20:32:47] Evaluate_00: epoch = 1000 train time = 30 s train loss = 0.048738 train acc = 0.9875, test acc = 0.3460, test_sen =0.3147, test_spe =0.9064, test_f1 =0.2893
[2024-10-30 20:33:19] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.088933 train acc = 0.9875, test acc = 0.3198, test_sen =0.3002, test_spe =0.9031, test_f1 =0.2716
[2024-10-30 20:33:49] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.004036 train acc = 1.0000, test acc = 0.3445, test_sen =0.3114, test_spe =0.9061, test_f1 =0.2829
[2024-10-30 20:34:18] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.002767 train acc = 1.0000, test acc = 0.3267, test_sen =0.3058, test_spe =0.9040, test_f1 =0.2767
[2024-10-30 20:34:52] Evaluate_04: epoch = 1000 train time = 28 s train loss = 0.010877 train acc = 1.0000, test acc = 0.3504, test_sen =0.3143, test_spe =0.9066, test_f1 =0.2878
[2024-10-30 20:49:21] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.032418 train acc = 1.0000, test acc = 0.3579, test_sen =0.2919, test_spe =0.9062, test_f1 =0.2604
[2024-10-30 20:49:51] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.009786 train acc = 1.0000, test acc = 0.3377, test_sen =0.2884, test_spe =0.9049, test_f1 =0.2521
[2024-10-30 20:50:20] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.081496 train acc = 1.0000, test acc = 0.3275, test_sen =0.2909, test_spe =0.9038, test_f1 =0.2532
[2024-10-30 20:50:51] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.002202 train acc = 1.0000, test acc = 0.3478, test_sen =0.2923, test_spe =0.9056, test_f1 =0.2593
[2024-10-30 20:51:22] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.033247 train acc = 1.0000, test acc = 0.3592, test_sen =0.2953, test_spe =0.9068, test_f1 =0.2598
[2024-10-30 21:06:28] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.010458 train acc = 1.0000, test acc = 0.3236, test_sen =0.3150, test_spe =0.9048, test_f1 =0.2655
[2024-10-30 21:06:58] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.003249 train acc = 1.0000, test acc = 0.3168, test_sen =0.3175, test_spe =0.9045, test_f1 =0.2611
[2024-10-30 21:07:24] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.002864 train acc = 1.0000, test acc = 0.3406, test_sen =0.3192, test_spe =0.9065, test_f1 =0.2741
[2024-10-30 21:07:55] Evaluate_03: epoch = 1000 train time = 25 s train loss = 0.005211 train acc = 1.0000, test acc = 0.3207, test_sen =0.3141, test_spe =0.9048, test_f1 =0.2659
[2024-10-30 21:08:27] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.001900 train acc = 1.0000, test acc = 0.3393, test_sen =0.3244, test_spe =0.9067, test_f1 =0.2809
[2024-10-30 21:21:32] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.004277 train acc = 1.0000, test acc = 0.2350, test_sen =0.2702, test_spe =0.8948, test_f1 =0.2095
[2024-10-30 21:21:59] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.045846 train acc = 1.0000, test acc = 0.2167, test_sen =0.2588, test_spe =0.8929, test_f1 =0.1865
[2024-10-30 21:22:30] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.001840 train acc = 1.0000, test acc = 0.2198, test_sen =0.2646, test_spe =0.8932, test_f1 =0.1961
[2024-10-30 21:23:01] Evaluate_03: epoch = 1000 train time = 26 s train loss = 0.064593 train acc = 0.9875, test acc = 0.2075, test_sen =0.2631, test_spe =0.8922, test_f1 =0.1848
[2024-10-30 21:23:29] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.026323 train acc = 1.0000, test acc = 0.2056, test_sen =0.2550, test_spe =0.8917, test_f1 =0.1766
[2024-10-30 21:36:55] Evaluate_00: epoch = 1000 train time = 26 s train loss = 0.002528 train acc = 1.0000, test acc = 0.3253, test_sen =0.3144, test_spe =0.9039, test_f1 =0.2644
[2024-10-30 21:37:23] Evaluate_01: epoch = 1000 train time = 23 s train loss = 0.002372 train acc = 1.0000, test acc = 0.3241, test_sen =0.3153, test_spe =0.9039, test_f1 =0.2676
[2024-10-30 21:37:57] Evaluate_02: epoch = 1000 train time = 29 s train loss = 0.054076 train acc = 1.0000, test acc = 0.3164, test_sen =0.3172, test_spe =0.9036, test_f1 =0.2659
[2024-10-30 21:38:21] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.010489 train acc = 1.0000, test acc = 0.3246, test_sen =0.3196, test_spe =0.9043, test_f1 =0.2712
[2024-10-30 21:38:49] Evaluate_04: epoch = 1000 train time = 23 s train loss = 0.004796 train acc = 1.0000, test acc = 0.3398, test_sen =0.3240, test_spe =0.9059, test_f1 =0.2842
[2024-10-30 21:39:36] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.042012 train acc = 1.0000, test acc = 0.2419, test_sen =0.2331, test_spe =0.8902, test_f1 =0.2114
[2024-10-30 21:40:06] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.015608 train acc = 1.0000, test acc = 0.2449, test_sen =0.2295, test_spe =0.8905, test_f1 =0.2112
[2024-10-30 21:40:36] Evaluate_02: epoch = 1000 train time = 25 s train loss = 0.001029 train acc = 1.0000, test acc = 0.2342, test_sen =0.2321, test_spe =0.8901, test_f1 =0.2087
[2024-10-30 21:41:06] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.075750 train acc = 1.0000, test acc = 0.2322, test_sen =0.2261, test_spe =0.8897, test_f1 =0.2042
[2024-10-30 21:41:38] Evaluate_04: epoch = 1000 train time = 26 s train loss = 0.033318 train acc = 0.9875, test acc = 0.2483, test_sen =0.2333, test_spe =0.8911, test_f1 =0.2132
[2024-10-30 21:55:06] Evaluate_00: epoch = 1000 train time = 27 s train loss = 0.002129 train acc = 1.0000, test acc = 0.3530, test_sen =0.3277, test_spe =0.9079, test_f1 =0.2974
[2024-10-30 21:55:41] Evaluate_01: epoch = 1000 train time = 27 s train loss = 0.004412 train acc = 1.0000, test acc = 0.3716, test_sen =0.3352, test_spe =0.9101, test_f1 =0.3077
[2024-10-30 21:56:22] Evaluate_02: epoch = 1000 train time = 34 s train loss = 0.002292 train acc = 1.0000, test acc = 0.3697, test_sen =0.3332, test_spe =0.9100, test_f1 =0.3054
[2024-10-30 21:57:04] Evaluate_03: epoch = 1000 train time = 35 s train loss = 0.005963 train acc = 1.0000, test acc = 0.3636, test_sen =0.3329, test_spe =0.9095, test_f1 =0.3023
[2024-10-30 21:57:28] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.083481 train acc = 0.9750, test acc = 0.3675, test_sen =0.3343, test_spe =0.9098, test_f1 =0.3023
[2024-10-30 22:10:45] Evaluate_00: epoch = 1000 train time = 23 s train loss = 0.024224 train acc = 1.0000, test acc = 0.3519, test_sen =0.3051, test_spe =0.9073, test_f1 =0.2675
[2024-10-30 22:11:14] Evaluate_01: epoch = 1000 train time = 24 s train loss = 0.003878 train acc = 1.0000, test acc = 0.3345, test_sen =0.3084, test_spe =0.9058, test_f1 =0.2664
[2024-10-30 22:11:43] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.011444 train acc = 1.0000, test acc = 0.3465, test_sen =0.3103, test_spe =0.9070, test_f1 =0.2689
[2024-10-30 22:12:11] Evaluate_03: epoch = 1000 train time = 23 s train loss = 0.001573 train acc = 1.0000, test acc = 0.3402, test_sen =0.3063, test_spe =0.9064, test_f1 =0.2660
[2024-10-30 22:12:40] Evaluate_04: epoch = 1000 train time = 24 s train loss = 0.034247 train acc = 1.0000, test acc = 0.3407, test_sen =0.3061, test_spe =0.9063, test_f1 =0.2669
[2024-10-30 22:26:25] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.041391 train acc = 1.0000, test acc = 0.4358, test_sen =0.3163, test_spe =0.9136, test_f1 =0.3040
[2024-10-30 22:26:57] Evaluate_01: epoch = 1000 train time = 25 s train loss = 0.006299 train acc = 1.0000, test acc = 0.4454, test_sen =0.3185, test_spe =0.9141, test_f1 =0.3041
[2024-10-30 22:27:25] Evaluate_02: epoch = 1000 train time = 23 s train loss = 0.003713 train acc = 1.0000, test acc = 0.4241, test_sen =0.3179, test_spe =0.9132, test_f1 =0.3067/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:28:10: Evaluate 5 random ConvNet, ACCmean = 0.4367 ACCstd = 0.0073
-------------------------
2024-10-30 22:28:10: Evaluate 5 random ConvNet, SENmean = 0.3195 SENstd = 0.0025
-------------------------
2024-10-30 22:28:10: Evaluate 5 random ConvNet, SPEmean = 0.9139 SPEstd = 0.0004
-------------------------
2024-10-30 22:28:10: Evaluate 5 random ConvNet, F!mean = 0.3047 F!std = 0.0010
-------------------------
2024-10-30 22:28:10: Evaluate 5 random ConvNet, mean = 0.4367 std = 0.0073
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:28:10: [2024-10-30 22:28:10] iter = 06000, loss = 5.3740
2024-10-30 22:28:14: [2024-10-30 22:28:14] iter = 06010, loss = 3.8967
2024-10-30 22:28:18: [2024-10-30 22:28:18] iter = 06020, loss = 5.5231
2024-10-30 22:28:21: [2024-10-30 22:28:21] iter = 06030, loss = 28.3334
2024-10-30 22:28:25: [2024-10-30 22:28:25] iter = 06040, loss = 23.1587
2024-10-30 22:28:27: [2024-10-30 22:28:27] iter = 06050, loss = 9.8005
2024-10-30 22:28:31: [2024-10-30 22:28:31] iter = 06060, loss = 6.4700
2024-10-30 22:28:34: [2024-10-30 22:28:34] iter = 06070, loss = 6.5849
2024-10-30 22:28:37: [2024-10-30 22:28:37] iter = 06080, loss = 6.6578
2024-10-30 22:28:41: [2024-10-30 22:28:41] iter = 06090, loss = 8.7185
2024-10-30 22:28:44: [2024-10-30 22:28:44] iter = 06100, loss = 14.5579
2024-10-30 22:28:48: [2024-10-30 22:28:48] iter = 06110, loss = 9.3752
2024-10-30 22:28:52: [2024-10-30 22:28:52] iter = 06120, loss = 4.2600
2024-10-30 22:28:55: [2024-10-30 22:28:55] iter = 06130, loss = 17.5608
2024-10-30 22:28:59: [2024-10-30 22:28:59] iter = 06140, loss = 15.1491
2024-10-30 22:29:02: [2024-10-30 22:29:02] iter = 06150, loss = 5.9985
2024-10-30 22:29:05: [2024-10-30 22:29:05] iter = 06160, loss = 9.1329
2024-10-30 22:29:08: [2024-10-30 22:29:08] iter = 06170, loss = 28.9739
2024-10-30 22:29:12: [2024-10-30 22:29:12] iter = 06180, loss = 18.5153
2024-10-30 22:29:16: [2024-10-30 22:29:16] iter = 06190, loss = 10.2886
2024-10-30 22:29:18: [2024-10-30 22:29:18] iter = 06200, loss = 23.4703
2024-10-30 22:29:21: [2024-10-30 22:29:21] iter = 06210, loss = 4.5968
2024-10-30 22:29:23: [2024-10-30 22:29:23] iter = 06220, loss = 5.4809
2024-10-30 22:29:26: [2024-10-30 22:29:26] iter = 06230, loss = 14.6139
2024-10-30 22:29:30: [2024-10-30 22:29:30] iter = 06240, loss = 3.3798
2024-10-30 22:29:31: [2024-10-30 22:29:31] iter = 06250, loss = 8.2689
2024-10-30 22:29:34: [2024-10-30 22:29:34] iter = 06260, loss = 20.6839
2024-10-30 22:29:37: [2024-10-30 22:29:37] iter = 06270, loss = 61.3181
2024-10-30 22:29:40: [2024-10-30 22:29:40] iter = 06280, loss = 6.4362
2024-10-30 22:29:43: [2024-10-30 22:29:43] iter = 06290, loss = 6.4334
2024-10-30 22:29:47: [2024-10-30 22:29:47] iter = 06300, loss = 63.5246
2024-10-30 22:29:50: [2024-10-30 22:29:50] iter = 06310, loss = 42.0697
2024-10-30 22:29:54: [2024-10-30 22:29:54] iter = 06320, loss = 59.2019
2024-10-30 22:29:57: [2024-10-30 22:29:57] iter = 06330, loss = 6.4910
2024-10-30 22:29:59: [2024-10-30 22:29:59] iter = 06340, loss = 5.2581
2024-10-30 22:30:03: [2024-10-30 22:30:03] iter = 06350, loss = 3.9796
2024-10-30 22:30:07: [2024-10-30 22:30:07] iter = 06360, loss = 4.1795
2024-10-30 22:30:11: [2024-10-30 22:30:11] iter = 06370, loss = 13.4411
2024-10-30 22:30:14: [2024-10-30 22:30:14] iter = 06380, loss = 41.1155
2024-10-30 22:30:16: [2024-10-30 22:30:16] iter = 06390, loss = 15.5594
2024-10-30 22:30:19: [2024-10-30 22:30:19] iter = 06400, loss = 10.9320
2024-10-30 22:30:22: [2024-10-30 22:30:22] iter = 06410, loss = 15.5109
2024-10-30 22:30:25: [2024-10-30 22:30:25] iter = 06420, loss = 5.1831
2024-10-30 22:30:27: [2024-10-30 22:30:27] iter = 06430, loss = 4.0471
2024-10-30 22:30:30: [2024-10-30 22:30:30] iter = 06440, loss = 58.4587
2024-10-30 22:30:34: [2024-10-30 22:30:34] iter = 06450, loss = 18.8932
2024-10-30 22:30:38: [2024-10-30 22:30:38] iter = 06460, loss = 17.3182
2024-10-30 22:30:41: [2024-10-30 22:30:41] iter = 06470, loss = 42.7096
2024-10-30 22:30:45: [2024-10-30 22:30:45] iter = 06480, loss = 13.6362
2024-10-30 22:30:48: [2024-10-30 22:30:48] iter = 06490, loss = 28.1515
2024-10-30 22:30:52: [2024-10-30 22:30:52] iter = 06500, loss = 9.6823
2024-10-30 22:30:56: [2024-10-30 22:30:56] iter = 06510, loss = 8.1437
2024-10-30 22:31:00: [2024-10-30 22:31:00] iter = 06520, loss = 9.9588
2024-10-30 22:31:03: [2024-10-30 22:31:03] iter = 06530, loss = 6.7864
2024-10-30 22:31:06: [2024-10-30 22:31:06] iter = 06540, loss = 12.3522
2024-10-30 22:31:09: [2024-10-30 22:31:09] iter = 06550, loss = 9.1804
2024-10-30 22:31:13: [2024-10-30 22:31:13] iter = 06560, loss = 45.1043
2024-10-30 22:31:16: [2024-10-30 22:31:16] iter = 06570, loss = 6.6456
2024-10-30 22:31:19: [2024-10-30 22:31:19] iter = 06580, loss = 24.8694
2024-10-30 22:31:23: [2024-10-30 22:31:23] iter = 06590, loss = 43.5413
2024-10-30 22:31:27: [2024-10-30 22:31:27] iter = 06600, loss = 5.8352
2024-10-30 22:31:30: [2024-10-30 22:31:30] iter = 06610, loss = 5.7605
2024-10-30 22:31:34: [2024-10-30 22:31:34] iter = 06620, loss = 4.6261
2024-10-30 22:31:37: [2024-10-30 22:31:37] iter = 06630, loss = 4.5944
2024-10-30 22:31:41: [2024-10-30 22:31:41] iter = 06640, loss = 58.2525
2024-10-30 22:31:44: [2024-10-30 22:31:44] iter = 06650, loss = 29.2802
2024-10-30 22:31:47: [2024-10-30 22:31:47] iter = 06660, loss = 25.3655
2024-10-30 22:31:51: [2024-10-30 22:31:51] iter = 06670, loss = 10.5714
2024-10-30 22:31:53: [2024-10-30 22:31:53] iter = 06680, loss = 33.4474
2024-10-30 22:31:56: [2024-10-30 22:31:56] iter = 06690, loss = 4.0234
2024-10-30 22:31:59: [2024-10-30 22:31:59] iter = 06700, loss = 15.1759
2024-10-30 22:32:01: [2024-10-30 22:32:01] iter = 06710, loss = 11.6445
2024-10-30 22:32:04: [2024-10-30 22:32:04] iter = 06720, loss = 17.4544
2024-10-30 22:32:08: [2024-10-30 22:32:08] iter = 06730, loss = 62.9564
2024-10-30 22:32:12: [2024-10-30 22:32:12] iter = 06740, loss = 7.5377
2024-10-30 22:32:15: [2024-10-30 22:32:15] iter = 06750, loss = 11.0623
2024-10-30 22:32:19: [2024-10-30 22:32:19] iter = 06760, loss = 37.0129
2024-10-30 22:32:22: [2024-10-30 22:32:22] iter = 06770, loss = 15.7628
2024-10-30 22:32:25: [2024-10-30 22:32:25] iter = 06780, loss = 28.6715
2024-10-30 22:32:30: [2024-10-30 22:32:30] iter = 06790, loss = 35.4574
2024-10-30 22:32:33: [2024-10-30 22:32:33] iter = 06800, loss = 26.2169
2024-10-30 22:32:36: [2024-10-30 22:32:36] iter = 06810, loss = 10.0119
2024-10-30 22:32:40: [2024-10-30 22:32:40] iter = 06820, loss = 7.0562
2024-10-30 22:32:42: [2024-10-30 22:32:42] iter = 06830, loss = 6.3989
2024-10-30 22:32:47: [2024-10-30 22:32:47] iter = 06840, loss = 19.0940
2024-10-30 22:32:50: [2024-10-30 22:32:50] iter = 06850, loss = 14.7639
2024-10-30 22:32:55: [2024-10-30 22:32:55] iter = 06860, loss = 9.1805
2024-10-30 22:33:00: [2024-10-30 22:33:00] iter = 06870, loss = 93.6463
2024-10-30 22:33:04: [2024-10-30 22:33:04] iter = 06880, loss = 28.1558
2024-10-30 22:33:08: [2024-10-30 22:33:08] iter = 06890, loss = 56.3739
2024-10-30 22:33:11: [2024-10-30 22:33:11] iter = 06900, loss = 41.5946
2024-10-30 22:33:15: [2024-10-30 22:33:15] iter = 06910, loss = 9.3649
2024-10-30 22:33:19: [2024-10-30 22:33:19] iter = 06920, loss = 45.4684
2024-10-30 22:33:23: [2024-10-30 22:33:23] iter = 06930, loss = 13.6813
2024-10-30 22:33:27: [2024-10-30 22:33:27] iter = 06940, loss = 33.6198
2024-10-30 22:33:31: [2024-10-30 22:33:31] iter = 06950, loss = 6.7232
2024-10-30 22:33:34: [2024-10-30 22:33:34] iter = 06960, loss = 14.4431
2024-10-30 22:33:37: [2024-10-30 22:33:37] iter = 06970, loss = 31.4895
2024-10-30 22:33:42: [2024-10-30 22:33:42] iter = 06980, loss = 14.9893
2024-10-30 22:33:45: [2024-10-30 22:33:45] iter = 06990, loss = 10.5745
2024-10-30 22:33:48: [2024-10-30 22:33:48] iter = 07000, loss = 4.9142
2024-10-30 22:33:52: [2024-10-30 22:33:52] iter = 07010, loss = 8.3882
2024-10-30 22:33:54: [2024-10-30 22:33:54] iter = 07020, loss = 10.2018
2024-10-30 22:33:58: [2024-10-30 22:33:58] iter = 07030, loss = 5.4404
2024-10-30 22:34:01: [2024-10-30 22:34:01] iter = 07040, loss = 12.5695
2024-10-30 22:34:04: [2024-10-30 22:34:04] iter = 07050, loss = 11.5640
2024-10-30 22:34:07: [2024-10-30 22:34:07] iter = 07060, loss = 49.8979
2024-10-30 22:34:10: [2024-10-30 22:34:10] iter = 07070, loss = 4.2460
2024-10-30 22:34:14: [2024-10-30 22:34:14] iter = 07080, loss = 4.7036
2024-10-30 22:34:17: [2024-10-30 22:34:17] iter = 07090, loss = 21.1288
2024-10-30 22:34:20: [2024-10-30 22:34:20] iter = 07100, loss = 18.4162
2024-10-30 22:34:23: [2024-10-30 22:34:23] iter = 07110, loss = 5.5181
2024-10-30 22:34:26: [2024-10-30 22:34:26] iter = 07120, loss = 16.8691
2024-10-30 22:34:30: [2024-10-30 22:34:30] iter = 07130, loss = 6.6224
2024-10-30 22:34:34: [2024-10-30 22:34:34] iter = 07140, loss = 5.3534
2024-10-30 22:34:38: [2024-10-30 22:34:38] iter = 07150, loss = 4.8675
2024-10-30 22:34:42: [2024-10-30 22:34:42] iter = 07160, loss = 29.9094
2024-10-30 22:34:45: [2024-10-30 22:34:45] iter = 07170, loss = 76.3766
2024-10-30 22:34:49: [2024-10-30 22:34:49] iter = 07180, loss = 4.9123
2024-10-30 22:34:52: [2024-10-30 22:34:52] iter = 07190, loss = 24.2174
2024-10-30 22:34:55: [2024-10-30 22:34:55] iter = 07200, loss = 9.0776
2024-10-30 22:34:59: [2024-10-30 22:34:59] iter = 07210, loss = 12.3895
2024-10-30 22:35:03: [2024-10-30 22:35:03] iter = 07220, loss = 35.1147
2024-10-30 22:35:05: [2024-10-30 22:35:05] iter = 07230, loss = 29.2123
2024-10-30 22:35:09: [2024-10-30 22:35:09] iter = 07240, loss = 4.0738
2024-10-30 22:35:12: [2024-10-30 22:35:12] iter = 07250, loss = 12.5088
2024-10-30 22:35:15: [2024-10-30 22:35:15] iter = 07260, loss = 4.9188
2024-10-30 22:35:18: [2024-10-30 22:35:18] iter = 07270, loss = 20.6587
2024-10-30 22:35:22: [2024-10-30 22:35:22] iter = 07280, loss = 5.7569
2024-10-30 22:35:25: [2024-10-30 22:35:25] iter = 07290, loss = 14.1625
2024-10-30 22:35:30: [2024-10-30 22:35:30] iter = 07300, loss = 4.5334
2024-10-30 22:35:33: [2024-10-30 22:35:33] iter = 07310, loss = 6.5619
2024-10-30 22:35:37: [2024-10-30 22:35:37] iter = 07320, loss = 3.8915
2024-10-30 22:35:41: [2024-10-30 22:35:41] iter = 07330, loss = 18.2376
2024-10-30 22:35:44: [2024-10-30 22:35:44] iter = 07340, loss = 3.6774
2024-10-30 22:35:48: [2024-10-30 22:35:48] iter = 07350, loss = 10.0375
2024-10-30 22:35:51: [2024-10-30 22:35:51] iter = 07360, loss = 4.1496
2024-10-30 22:35:54: [2024-10-30 22:35:54] iter = 07370, loss = 10.6261
2024-10-30 22:35:57: [2024-10-30 22:35:57] iter = 07380, loss = 20.7159
2024-10-30 22:36:00: [2024-10-30 22:36:00] iter = 07390, loss = 6.6119
2024-10-30 22:36:03: [2024-10-30 22:36:03] iter = 07400, loss = 30.0181
2024-10-30 22:36:08: [2024-10-30 22:36:08] iter = 07410, loss = 26.3151
2024-10-30 22:36:12: [2024-10-30 22:36:12] iter = 07420, loss = 34.6167
2024-10-30 22:36:15: [2024-10-30 22:36:15] iter = 07430, loss = 4.4245
2024-10-30 22:36:19: [2024-10-30 22:36:19] iter = 07440, loss = 9.6182
2024-10-30 22:36:23: [2024-10-30 22:36:23] iter = 07450, loss = 4.9608
2024-10-30 22:36:27: [2024-10-30 22:36:27] iter = 07460, loss = 7.8963
2024-10-30 22:36:30: [2024-10-30 22:36:30] iter = 07470, loss = 4.1974
2024-10-30 22:36:33: [2024-10-30 22:36:33] iter = 07480, loss = 4.3590
2024-10-30 22:36:36: [2024-10-30 22:36:36] iter = 07490, loss = 6.9598
2024-10-30 22:36:40: [2024-10-30 22:36:40] iter = 07500, loss = 8.3613
2024-10-30 22:36:42: [2024-10-30 22:36:42] iter = 07510, loss = 19.2213
2024-10-30 22:36:46: [2024-10-30 22:36:46] iter = 07520, loss = 9.7511
2024-10-30 22:36:49: [2024-10-30 22:36:49] iter = 07530, loss = 30.5634
2024-10-30 22:36:52: [2024-10-30 22:36:52] iter = 07540, loss = 16.2646
2024-10-30 22:36:56: [2024-10-30 22:36:56] iter = 07550, loss = 21.2189
2024-10-30 22:36:59: [2024-10-30 22:36:59] iter = 07560, loss = 6.8350
2024-10-30 22:37:01: [2024-10-30 22:37:01] iter = 07570, loss = 6.0535
2024-10-30 22:37:04: [2024-10-30 22:37:04] iter = 07580, loss = 9.2720
2024-10-30 22:37:07: [2024-10-30 22:37:07] iter = 07590, loss = 4.2391
2024-10-30 22:37:10: [2024-10-30 22:37:10] iter = 07600, loss = 20.3731
2024-10-30 22:37:14: [2024-10-30 22:37:14] iter = 07610, loss = 11.6543
2024-10-30 22:37:17: [2024-10-30 22:37:17] iter = 07620, loss = 17.0637
2024-10-30 22:37:21: [2024-10-30 22:37:21] iter = 07630, loss = 17.4494
2024-10-30 22:37:25: [2024-10-30 22:37:25] iter = 07640, loss = 60.9468
2024-10-30 22:37:28: [2024-10-30 22:37:28] iter = 07650, loss = 13.8157
2024-10-30 22:37:30: [2024-10-30 22:37:30] iter = 07660, loss = 8.1005
2024-10-30 22:37:34: [2024-10-30 22:37:34] iter = 07670, loss = 3.7703
2024-10-30 22:37:37: [2024-10-30 22:37:37] iter = 07680, loss = 7.8364
2024-10-30 22:37:40: [2024-10-30 22:37:40] iter = 07690, loss = 28.6598
2024-10-30 22:37:44: [2024-10-30 22:37:44] iter = 07700, loss = 5.0327
2024-10-30 22:37:48: [2024-10-30 22:37:48] iter = 07710, loss = 7.5966
2024-10-30 22:37:51: [2024-10-30 22:37:51] iter = 07720, loss = 5.4974
2024-10-30 22:37:54: [2024-10-30 22:37:54] iter = 07730, loss = 4.8040
2024-10-30 22:37:58: [2024-10-30 22:37:58] iter = 07740, loss = 64.3501
2024-10-30 22:38:02: [2024-10-30 22:38:02] iter = 07750, loss = 5.6421
2024-10-30 22:38:06: [2024-10-30 22:38:06] iter = 07760, loss = 6.7784
2024-10-30 22:38:09: [2024-10-30 22:38:09] iter = 07770, loss = 3.8782
2024-10-30 22:38:12: [2024-10-30 22:38:12] iter = 07780, loss = 6.1388
2024-10-30 22:38:16: [2024-10-30 22:38:16] iter = 07790, loss = 43.3020
2024-10-30 22:38:19: [2024-10-30 22:38:19] iter = 07800, loss = 18.9613
2024-10-30 22:38:21: [2024-10-30 22:38:21] iter = 07810, loss = 19.6911
2024-10-30 22:38:24: [2024-10-30 22:38:24] iter = 07820, loss = 24.8116
2024-10-30 22:38:28: [2024-10-30 22:38:28] iter = 07830, loss = 15.4850
2024-10-30 22:38:31: [2024-10-30 22:38:31] iter = 07840, loss = 12.8522
2024-10-30 22:38:34: [2024-10-30 22:38:34] iter = 07850, loss = 23.1561
2024-10-30 22:38:37: [2024-10-30 22:38:37] iter = 07860, loss = 4.1942
2024-10-30 22:38:40: [2024-10-30 22:38:40] iter = 07870, loss = 32.1332
2024-10-30 22:38:43: [2024-10-30 22:38:43] iter = 07880, loss = 13.5413
2024-10-30 22:38:47: [2024-10-30 22:38:47] iter = 07890, loss = 13.9014
2024-10-30 22:38:49: [2024-10-30 22:38:49] iter = 07900, loss = 57.8501
2024-10-30 22:38:53: [2024-10-30 22:38:53] iter = 07910, loss = 15.4816
2024-10-30 22:38:55: [2024-10-30 22:38:55] iter = 07920, loss = 4.8413
2024-10-30 22:38:59: [2024-10-30 22:38:59] iter = 07930, loss = 10.2394
2024-10-30 22:39:03: [2024-10-30 22:39:03] iter = 07940, loss = 33.5332
2024-10-30 22:39:07: [2024-10-30 22:39:07] iter = 07950, loss = 20.1958
2024-10-30 22:39:09: [2024-10-30 22:39:09] iter = 07960, loss = 14.1159
2024-10-30 22:39:12: [2024-10-30 22:39:12] iter = 07970, loss = 8.6676
2024-10-30 22:39:16: [2024-10-30 22:39:16] iter = 07980, loss = 22.7522
2024-10-30 22:39:20: [2024-10-30 22:39:20] iter = 07990, loss = 4.3779
2024-10-30 22:39:23: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-30 22:39:23: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:39:23: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63379}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:41:29: Evaluate 5 random ConvNet, ACCmean = 0.3062 ACCstd = 0.0140
-------------------------
2024-10-30 22:41:29: Evaluate 5 random ConvNet, SENmean = 0.2961 SENstd = 0.0052
-------------------------
2024-10-30 22:41:29: Evaluate 5 random ConvNet, SPEmean = 0.9030 SPEstd = 0.0015
-------------------------
2024-10-30 22:41:29: Evaluate 5 random ConvNet, F!mean = 0.2532 F!std = 0.0072
-------------------------
2024-10-30 22:41:29: Evaluate 5 random ConvNet, mean = 0.3062 std = 0.0140
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:41:30: [2024-10-30 22:41:30] iter = 08000, loss = 11.2373
2024-10-30 22:41:33: [2024-10-30 22:41:33] iter = 08010, loss = 25.1895
2024-10-30 22:41:36: [2024-10-30 22:41:36] iter = 08020, loss = 19.9546
2024-10-30 22:41:40: [2024-10-30 22:41:40] iter = 08030, loss = 41.2845
2024-10-30 22:41:44: [2024-10-30 22:41:44] iter = 08040, loss = 16.9943
2024-10-30 22:41:47: [2024-10-30 22:41:47] iter = 08050, loss = 25.0956
2024-10-30 22:41:50: [2024-10-30 22:41:50] iter = 08060, loss = 26.2856
2024-10-30 22:41:54: [2024-10-30 22:41:54] iter = 08070, loss = 3.9906
2024-10-30 22:41:58: [2024-10-30 22:41:58] iter = 08080, loss = 5.8387
2024-10-30 22:42:02: [2024-10-30 22:42:02] iter = 08090, loss = 4.5956
2024-10-30 22:42:05: [2024-10-30 22:42:05] iter = 08100, loss = 14.4896
2024-10-30 22:42:09: [2024-10-30 22:42:09] iter = 08110, loss = 4.2075
2024-10-30 22:42:13: [2024-10-30 22:42:13] iter = 08120, loss = 15.7067
2024-10-30 22:42:16: [2024-10-30 22:42:16] iter = 08130, loss = 43.2834
2024-10-30 22:42:19: [2024-10-30 22:42:19] iter = 08140, loss = 10.3095
2024-10-30 22:42:23: [2024-10-30 22:42:23] iter = 08150, loss = 51.6682
2024-10-30 22:42:26: [2024-10-30 22:42:26] iter = 08160, loss = 6.0134
2024-10-30 22:42:29: [2024-10-30 22:42:29] iter = 08170, loss = 6.5378
2024-10-30 22:42:34: [2024-10-30 22:42:34] iter = 08180, loss = 18.2815
2024-10-30 22:42:36: [2024-10-30 22:42:36] iter = 08190, loss = 9.3301
2024-10-30 22:42:39: [2024-10-30 22:42:39] iter = 08200, loss = 8.5640
2024-10-30 22:42:42: [2024-10-30 22:42:42] iter = 08210, loss = 31.3523
2024-10-30 22:42:46: [2024-10-30 22:42:46] iter = 08220, loss = 4.7383
2024-10-30 22:42:49: [2024-10-30 22:42:49] iter = 08230, loss = 21.9150
2024-10-30 22:42:53: [2024-10-30 22:42:53] iter = 08240, loss = 61.5560
2024-10-30 22:42:57: [2024-10-30 22:42:57] iter = 08250, loss = 32.0703
2024-10-30 22:43:00: [2024-10-30 22:43:00] iter = 08260, loss = 10.2862
2024-10-30 22:43:03: [2024-10-30 22:43:03] iter = 08270, loss = 4.6829
2024-10-30 22:43:07: [2024-10-30 22:43:07] iter = 08280, loss = 25.7302
2024-10-30 22:43:11: [2024-10-30 22:43:11] iter = 08290, loss = 5.1694
2024-10-30 22:43:13: [2024-10-30 22:43:13] iter = 08300, loss = 6.3286
2024-10-30 22:43:17: [2024-10-30 22:43:17] iter = 08310, loss = 3.6912
2024-10-30 22:43:20: [2024-10-30 22:43:20] iter = 08320, loss = 4.1944
2024-10-30 22:43:23: [2024-10-30 22:43:23] iter = 08330, loss = 9.5134
2024-10-30 22:43:26: [2024-10-30 22:43:26] iter = 08340, loss = 23.5929
2024-10-30 22:43:29: [2024-10-30 22:43:29] iter = 08350, loss = 7.5659
2024-10-30 22:43:33: [2024-10-30 22:43:33] iter = 08360, loss = 11.8985
2024-10-30 22:43:36: [2024-10-30 22:43:36] iter = 08370, loss = 24.5000
2024-10-30 22:43:39: [2024-10-30 22:43:39] iter = 08380, loss = 8.2017
2024-10-30 22:43:42: [2024-10-30 22:43:42] iter = 08390, loss = 6.9162
2024-10-30 22:43:45: [2024-10-30 22:43:45] iter = 08400, loss = 10.4214
2024-10-30 22:43:48: [2024-10-30 22:43:48] iter = 08410, loss = 6.3778
2024-10-30 22:43:50: [2024-10-30 22:43:50] iter = 08420, loss = 47.0079
2024-10-30 22:43:54: [2024-10-30 22:43:54] iter = 08430, loss = 40.0913
2024-10-30 22:43:58: [2024-10-30 22:43:58] iter = 08440, loss = 23.3396
2024-10-30 22:44:01: [2024-10-30 22:44:01] iter = 08450, loss = 41.9808
2024-10-30 22:44:05: [2024-10-30 22:44:05] iter = 08460, loss = 8.9287
2024-10-30 22:44:08: [2024-10-30 22:44:08] iter = 08470, loss = 39.2920
2024-10-30 22:44:11: [2024-10-30 22:44:11] iter = 08480, loss = 6.1560
2024-10-30 22:44:15: [2024-10-30 22:44:15] iter = 08490, loss = 21.7011
2024-10-30 22:44:19: [2024-10-30 22:44:19] iter = 08500, loss = 4.2886
2024-10-30 22:44:23: [2024-10-30 22:44:23] iter = 08510, loss = 47.2031
2024-10-30 22:44:26: [2024-10-30 22:44:26] iter = 08520, loss = 4.3638
2024-10-30 22:44:30: [2024-10-30 22:44:30] iter = 08530, loss = 7.0281
2024-10-30 22:44:33: [2024-10-30 22:44:33] iter = 08540, loss = 3.2470
2024-10-30 22:44:36: [2024-10-30 22:44:36] iter = 08550, loss = 14.4200
2024-10-30 22:44:40: [2024-10-30 22:44:40] iter = 08560, loss = 21.9570
2024-10-30 22:44:42: [2024-10-30 22:44:42] iter = 08570, loss = 16.8808
2024-10-30 22:44:44: [2024-10-30 22:44:44] iter = 08580, loss = 32.7530
2024-10-30 22:44:48: [2024-10-30 22:44:48] iter = 08590, loss = 11.1447
2024-10-30 22:44:51: [2024-10-30 22:44:51] iter = 08600, loss = 4.1362
2024-10-30 22:44:54: [2024-10-30 22:44:54] iter = 08610, loss = 11.4462
2024-10-30 22:44:57: [2024-10-30 22:44:57] iter = 08620, loss = 4.4368
2024-10-30 22:45:02: [2024-10-30 22:45:02] iter = 08630, loss = 5.4594
2024-10-30 22:45:06: [2024-10-30 22:45:06] iter = 08640, loss = 5.5485
2024-10-30 22:45:09: [2024-10-30 22:45:09] iter = 08650, loss = 6.5600
2024-10-30 22:45:13: [2024-10-30 22:45:13] iter = 08660, loss = 12.2896
2024-10-30 22:45:17: [2024-10-30 22:45:17] iter = 08670, loss = 18.4900
2024-10-30 22:45:20: [2024-10-30 22:45:20] iter = 08680, loss = 3.9705
2024-10-30 22:45:23: [2024-10-30 22:45:23] iter = 08690, loss = 57.1177
2024-10-30 22:45:26: [2024-10-30 22:45:26] iter = 08700, loss = 5.3632
2024-10-30 22:45:29: [2024-10-30 22:45:29] iter = 08710, loss = 128.7142
2024-10-30 22:45:33: [2024-10-30 22:45:33] iter = 08720, loss = 12.3975
2024-10-30 22:45:36: [2024-10-30 22:45:36] iter = 08730, loss = 9.2311
2024-10-30 22:45:40: [2024-10-30 22:45:40] iter = 08740, loss = 10.5465
2024-10-30 22:45:43: [2024-10-30 22:45:43] iter = 08750, loss = 8.9702
2024-10-30 22:45:47: [2024-10-30 22:45:47] iter = 08760, loss = 13.0530
2024-10-30 22:45:51: [2024-10-30 22:45:51] iter = 08770, loss = 4.8165
2024-10-30 22:45:54: [2024-10-30 22:45:54] iter = 08780, loss = 8.5867
2024-10-30 22:45:58: [2024-10-30 22:45:58] iter = 08790, loss = 12.7209
2024-10-30 22:46:03: [2024-10-30 22:46:03] iter = 08800, loss = 4.8743
2024-10-30 22:46:06: [2024-10-30 22:46:06] iter = 08810, loss = 3.2000
2024-10-30 22:46:10: [2024-10-30 22:46:10] iter = 08820, loss = 23.3953
2024-10-30 22:46:14: [2024-10-30 22:46:14] iter = 08830, loss = 8.6882
2024-10-30 22:46:17: [2024-10-30 22:46:17] iter = 08840, loss = 56.4505
2024-10-30 22:46:20: [2024-10-30 22:46:20] iter = 08850, loss = 61.9116
2024-10-30 22:46:24: [2024-10-30 22:46:24] iter = 08860, loss = 16.3424
2024-10-30 22:46:28: [2024-10-30 22:46:28] iter = 08870, loss = 50.2982
2024-10-30 22:46:31: [2024-10-30 22:46:31] iter = 08880, loss = 59.6143
2024-10-30 22:46:34: [2024-10-30 22:46:34] iter = 08890, loss = 11.4697
2024-10-30 22:46:38: [2024-10-30 22:46:38] iter = 08900, loss = 47.6910
2024-10-30 22:46:40: [2024-10-30 22:46:40] iter = 08910, loss = 26.6565
2024-10-30 22:46:43: [2024-10-30 22:46:43] iter = 08920, loss = 37.2140
2024-10-30 22:46:46: [2024-10-30 22:46:46] iter = 08930, loss = 30.2015
2024-10-30 22:46:49: [2024-10-30 22:46:49] iter = 08940, loss = 5.9631
2024-10-30 22:46:51: [2024-10-30 22:46:51] iter = 08950, loss = 23.2500
2024-10-30 22:46:54: [2024-10-30 22:46:54] iter = 08960, loss = 8.8809
2024-10-30 22:46:58: [2024-10-30 22:46:58] iter = 08970, loss = 6.1243
2024-10-30 22:47:00: [2024-10-30 22:47:00] iter = 08980, loss = 11.3544
2024-10-30 22:47:02: [2024-10-30 22:47:02] iter = 08990, loss = 59.0377
2024-10-30 22:47:03: [2024-10-30 22:47:03] iter = 09000, loss = 16.4763
2024-10-30 22:47:06: [2024-10-30 22:47:06] iter = 09010, loss = 6.7453
2024-10-30 22:47:10: [2024-10-30 22:47:10] iter = 09020, loss = 92.7550
2024-10-30 22:47:14: [2024-10-30 22:47:14] iter = 09030, loss = 11.1022
2024-10-30 22:47:17: [2024-10-30 22:47:17] iter = 09040, loss = 28.8025
2024-10-30 22:47:21: [2024-10-30 22:47:21] iter = 09050, loss = 75.3550
2024-10-30 22:47:24: [2024-10-30 22:47:24] iter = 09060, loss = 6.5234
2024-10-30 22:47:28: [2024-10-30 22:47:28] iter = 09070, loss = 15.8947
2024-10-30 22:47:32: [2024-10-30 22:47:32] iter = 09080, loss = 15.7011
2024-10-30 22:47:35: [2024-10-30 22:47:35] iter = 09090, loss = 11.1203
2024-10-30 22:47:38: [2024-10-30 22:47:38] iter = 09100, loss = 4.4091
2024-10-30 22:47:42: [2024-10-30 22:47:42] iter = 09110, loss = 15.7077
2024-10-30 22:47:44: [2024-10-30 22:47:44] iter = 09120, loss = 4.9508
2024-10-30 22:47:48: [2024-10-30 22:47:48] iter = 09130, loss = 12.5528
2024-10-30 22:47:51: [2024-10-30 22:47:51] iter = 09140, loss = 33.4941
2024-10-30 22:47:55: [2024-10-30 22:47:55] iter = 09150, loss = 4.5043
2024-10-30 22:47:58: [2024-10-30 22:47:58] iter = 09160, loss = 52.2819
2024-10-30 22:48:01: [2024-10-30 22:48:01] iter = 09170, loss = 44.3131
2024-10-30 22:48:06: [2024-10-30 22:48:06] iter = 09180, loss = 37.4316
2024-10-30 22:48:09: [2024-10-30 22:48:09] iter = 09190, loss = 13.0140
2024-10-30 22:48:13: [2024-10-30 22:48:13] iter = 09200, loss = 19.1408
2024-10-30 22:48:16: [2024-10-30 22:48:16] iter = 09210, loss = 21.3969
2024-10-30 22:48:20: [2024-10-30 22:48:20] iter = 09220, loss = 33.2525
2024-10-30 22:48:23: [2024-10-30 22:48:23] iter = 09230, loss = 10.6516
2024-10-30 22:48:26: [2024-10-30 22:48:26] iter = 09240, loss = 29.3971
2024-10-30 22:48:30: [2024-10-30 22:48:30] iter = 09250, loss = 34.2032
2024-10-30 22:48:34: [2024-10-30 22:48:34] iter = 09260, loss = 33.8425
2024-10-30 22:48:37: [2024-10-30 22:48:37] iter = 09270, loss = 69.3265
2024-10-30 22:48:40: [2024-10-30 22:48:40] iter = 09280, loss = 4.2008
2024-10-30 22:48:43: [2024-10-30 22:48:43] iter = 09290, loss = 19.6339
2024-10-30 22:48:47: [2024-10-30 22:48:47] iter = 09300, loss = 33.1777
2024-10-30 22:48:50: [2024-10-30 22:48:50] iter = 09310, loss = 20.1444
2024-10-30 22:48:54: [2024-10-30 22:48:54] iter = 09320, loss = 13.7884
2024-10-30 22:48:57: [2024-10-30 22:48:57] iter = 09330, loss = 25.1170
2024-10-30 22:49:00: [2024-10-30 22:49:00] iter = 09340, loss = 35.2062
2024-10-30 22:49:03: [2024-10-30 22:49:03] iter = 09350, loss = 29.8166
2024-10-30 22:49:07: [2024-10-30 22:49:07] iter = 09360, loss = 10.3261
2024-10-30 22:49:11: [2024-10-30 22:49:11] iter = 09370, loss = 12.8462
2024-10-30 22:49:15: [2024-10-30 22:49:15] iter = 09380, loss = 22.3095
2024-10-30 22:49:18: [2024-10-30 22:49:18] iter = 09390, loss = 19.3537
2024-10-30 22:49:21: [2024-10-30 22:49:21] iter = 09400, loss = 34.5440
2024-10-30 22:49:25: [2024-10-30 22:49:25] iter = 09410, loss = 8.9612
2024-10-30 22:49:28: [2024-10-30 22:49:28] iter = 09420, loss = 30.1919
2024-10-30 22:49:31: [2024-10-30 22:49:31] iter = 09430, loss = 19.3213
2024-10-30 22:49:35: [2024-10-30 22:49:35] iter = 09440, loss = 4.8361
2024-10-30 22:49:38: [2024-10-30 22:49:38] iter = 09450, loss = 6.2310
2024-10-30 22:49:41: [2024-10-30 22:49:41] iter = 09460, loss = 4.7888
2024-10-30 22:49:45: [2024-10-30 22:49:45] iter = 09470, loss = 52.4628
2024-10-30 22:49:48: [2024-10-30 22:49:48] iter = 09480, loss = 13.3462
2024-10-30 22:49:51: [2024-10-30 22:49:51] iter = 09490, loss = 31.5979
2024-10-30 22:49:55: [2024-10-30 22:49:55] iter = 09500, loss = 28.1234
2024-10-30 22:49:58: [2024-10-30 22:49:58] iter = 09510, loss = 21.6966
2024-10-30 22:50:01: [2024-10-30 22:50:01] iter = 09520, loss = 4.6519
2024-10-30 22:50:05: [2024-10-30 22:50:05] iter = 09530, loss = 95.9196
2024-10-30 22:50:08: [2024-10-30 22:50:08] iter = 09540, loss = 21.4370
2024-10-30 22:50:11: [2024-10-30 22:50:11] iter = 09550, loss = 8.1205
2024-10-30 22:50:14: [2024-10-30 22:50:14] iter = 09560, loss = 6.6344
2024-10-30 22:50:17: [2024-10-30 22:50:17] iter = 09570, loss = 4.7344
2024-10-30 22:50:19: [2024-10-30 22:50:19] iter = 09580, loss = 5.8173
2024-10-30 22:50:23: [2024-10-30 22:50:23] iter = 09590, loss = 4.0902
2024-10-30 22:50:26: [2024-10-30 22:50:26] iter = 09600, loss = 5.2270
2024-10-30 22:50:29: [2024-10-30 22:50:29] iter = 09610, loss = 5.4867
2024-10-30 22:50:32: [2024-10-30 22:50:32] iter = 09620, loss = 25.0665
2024-10-30 22:50:35: [2024-10-30 22:50:35] iter = 09630, loss = 12.8359
2024-10-30 22:50:39: [2024-10-30 22:50:39] iter = 09640, loss = 7.1206
2024-10-30 22:50:42: [2024-10-30 22:50:42] iter = 09650, loss = 36.7378
2024-10-30 22:50:45: [2024-10-30 22:50:45] iter = 09660, loss = 11.1831
2024-10-30 22:50:49: [2024-10-30 22:50:48] iter = 09670, loss = 13.2615
2024-10-30 22:50:52: [2024-10-30 22:50:52] iter = 09680, loss = 4.9358
2024-10-30 22:50:55: [2024-10-30 22:50:55] iter = 09690, loss = 9.2323
2024-10-30 22:50:59: [2024-10-30 22:50:59] iter = 09700, loss = 19.0408
2024-10-30 22:51:01: [2024-10-30 22:51:01] iter = 09710, loss = 21.3950
2024-10-30 22:51:06: [2024-10-30 22:51:06] iter = 09720, loss = 34.2550
2024-10-30 22:51:10: [2024-10-30 22:51:10] iter = 09730, loss = 29.6886
2024-10-30 22:51:13: [2024-10-30 22:51:13] iter = 09740, loss = 7.3844
2024-10-30 22:51:16: [2024-10-30 22:51:16] iter = 09750, loss = 21.8037
2024-10-30 22:51:20: [2024-10-30 22:51:20] iter = 09760, loss = 12.4128
2024-10-30 22:51:22: [2024-10-30 22:51:22] iter = 09770, loss = 29.5164
2024-10-30 22:51:25: [2024-10-30 22:51:25] iter = 09780, loss = 7.9350
2024-10-30 22:51:28: [2024-10-30 22:51:28] iter = 09790, loss = 13.6328
2024-10-30 22:51:32: [2024-10-30 22:51:32] iter = 09800, loss = 19.3271
2024-10-30 22:51:35: [2024-10-30 22:51:35] iter = 09810, loss = 23.6944
2024-10-30 22:51:38: [2024-10-30 22:51:38] iter = 09820, loss = 13.0997
2024-10-30 22:51:40: [2024-10-30 22:51:40] iter = 09830, loss = 5.9995
2024-10-30 22:51:43: [2024-10-30 22:51:43] iter = 09840, loss = 11.6558
2024-10-30 22:51:47: [2024-10-30 22:51:47] iter = 09850, loss = 19.1941
2024-10-30 22:51:51: [2024-10-30 22:51:51] iter = 09860, loss = 12.5264
2024-10-30 22:51:54: [2024-10-30 22:51:54] iter = 09870, loss = 21.3891
2024-10-30 22:51:57: [2024-10-30 22:51:57] iter = 09880, loss = 57.6932
2024-10-30 22:52:00: [2024-10-30 22:52:00] iter = 09890, loss = 6.0751
2024-10-30 22:52:02: [2024-10-30 22:52:02] iter = 09900, loss = 57.8669
2024-10-30 22:52:06: [2024-10-30 22:52:06] iter = 09910, loss = 17.4286
2024-10-30 22:52:09: [2024-10-30 22:52:09] iter = 09920, loss = 31.6733
2024-10-30 22:52:12: [2024-10-30 22:52:12] iter = 09930, loss = 5.0434
2024-10-30 22:52:15: [2024-10-30 22:52:15] iter = 09940, loss = 5.3877
2024-10-30 22:52:18: [2024-10-30 22:52:18] iter = 09950, loss = 8.3379
2024-10-30 22:52:22: [2024-10-30 22:52:22] iter = 09960, loss = 11.8417
2024-10-30 22:52:25: [2024-10-30 22:52:25] iter = 09970, loss = 29.1509
2024-10-30 22:52:27: [2024-10-30 22:52:27] iter = 09980, loss = 5.5018
2024-10-30 22:52:29: [2024-10-30 22:52:29] iter = 09990, loss = 18.0273
2024-10-30 22:52:32: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-30 22:52:32: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 22:52:32: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52237}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:54:31: Evaluate 5 random ConvNet, ACCmean = 0.3649 ACCstd = 0.0099
-------------------------
2024-10-30 22:54:31: Evaluate 5 random ConvNet, SENmean = 0.3070 SENstd = 0.0060
-------------------------
2024-10-30 22:54:31: Evaluate 5 random ConvNet, SPEmean = 0.9088 SPEstd = 0.0009
-------------------------
2024-10-30 22:54:31: Evaluate 5 random ConvNet, F!mean = 0.2607 F!std = 0.0078
-------------------------
2024-10-30 22:54:31: Evaluate 5 random ConvNet, mean = 0.3649 std = 0.0099
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 22:54:32: [2024-10-30 22:54:32] iter = 10000, loss = 37.3567
2024-10-30 22:54:36: [2024-10-30 22:54:36] iter = 10010, loss = 13.6412
2024-10-30 22:54:39: [2024-10-30 22:54:39] iter = 10020, loss = 104.5467
2024-10-30 22:54:43: [2024-10-30 22:54:43] iter = 10030, loss = 50.0573
2024-10-30 22:54:46: [2024-10-30 22:54:46] iter = 10040, loss = 11.4312
2024-10-30 22:54:49: [2024-10-30 22:54:49] iter = 10050, loss = 4.8654
2024-10-30 22:54:53: [2024-10-30 22:54:53] iter = 10060, loss = 37.7309
2024-10-30 22:54:57: [2024-10-30 22:54:57] iter = 10070, loss = 9.5747
2024-10-30 22:55:01: [2024-10-30 22:55:01] iter = 10080, loss = 110.4448
2024-10-30 22:55:04: [2024-10-30 22:55:04] iter = 10090, loss = 16.7156
2024-10-30 22:55:08: [2024-10-30 22:55:08] iter = 10100, loss = 7.2859
2024-10-30 22:55:12: [2024-10-30 22:55:12] iter = 10110, loss = 3.8801
2024-10-30 22:55:15: [2024-10-30 22:55:15] iter = 10120, loss = 26.0615
2024-10-30 22:55:19: [2024-10-30 22:55:19] iter = 10130, loss = 43.5075
2024-10-30 22:55:23: [2024-10-30 22:55:23] iter = 10140, loss = 8.0343
2024-10-30 22:55:26: [2024-10-30 22:55:26] iter = 10150, loss = 15.3222
2024-10-30 22:55:29: [2024-10-30 22:55:29] iter = 10160, loss = 49.8590
2024-10-30 22:55:31: [2024-10-30 22:55:31] iter = 10170, loss = 3.8514
2024-10-30 22:55:34: [2024-10-30 22:55:34] iter = 10180, loss = 15.1331
2024-10-30 22:55:36: [2024-10-30 22:55:36] iter = 10190, loss = 5.6230
2024-10-30 22:55:39: [2024-10-30 22:55:39] iter = 10200, loss = 11.3274
2024-10-30 22:55:42: [2024-10-30 22:55:42] iter = 10210, loss = 8.4690
2024-10-30 22:55:44: [2024-10-30 22:55:44] iter = 10220, loss = 11.8644
2024-10-30 22:55:47: [2024-10-30 22:55:47] iter = 10230, loss = 3.0966
2024-10-30 22:55:50: [2024-10-30 22:55:50] iter = 10240, loss = 4.0774
2024-10-30 22:55:52: [2024-10-30 22:55:52] iter = 10250, loss = 32.0830
2024-10-30 22:55:55: [2024-10-30 22:55:55] iter = 10260, loss = 4.0658
2024-10-30 22:55:59: [2024-10-30 22:55:59] iter = 10270, loss = 37.5193
2024-10-30 22:56:02: [2024-10-30 22:56:02] iter = 10280, loss = 26.8506
2024-10-30 22:56:06: [2024-10-30 22:56:06] iter = 10290, loss = 6.2475
2024-10-30 22:56:09: [2024-10-30 22:56:09] iter = 10300, loss = 10.7607
2024-10-30 22:56:12: [2024-10-30 22:56:12] iter = 10310, loss = 31.1683
2024-10-30 22:56:16: [2024-10-30 22:56:16] iter = 10320, loss = 11.7166
2024-10-30 22:56:18: [2024-10-30 22:56:18] iter = 10330, loss = 19.1497
2024-10-30 22:56:21: [2024-10-30 22:56:21] iter = 10340, loss = 37.9448
2024-10-30 22:56:24: [2024-10-30 22:56:24] iter = 10350, loss = 50.5861
2024-10-30 22:56:28: [2024-10-30 22:56:28] iter = 10360, loss = 23.5326
2024-10-30 22:56:31: [2024-10-30 22:56:31] iter = 10370, loss = 77.1513
2024-10-30 22:56:34: [2024-10-30 22:56:34] iter = 10380, loss = 20.6517
2024-10-30 22:56:37: [2024-10-30 22:56:37] iter = 10390, loss = 53.6792
2024-10-30 22:56:41: [2024-10-30 22:56:41] iter = 10400, loss = 43.5485
2024-10-30 22:56:44: [2024-10-30 22:56:44] iter = 10410, loss = 31.9022
2024-10-30 22:56:47: [2024-10-30 22:56:47] iter = 10420, loss = 13.8456
2024-10-30 22:56:50: [2024-10-30 22:56:50] iter = 10430, loss = 31.1560
2024-10-30 22:56:54: [2024-10-30 22:56:54] iter = 10440, loss = 24.5430
2024-10-30 22:56:58: [2024-10-30 22:56:58] iter = 10450, loss = 25.1551
2024-10-30 22:57:01: [2024-10-30 22:57:01] iter = 10460, loss = 8.7133
2024-10-30 22:57:04: [2024-10-30 22:57:04] iter = 10470, loss = 5.7447
2024-10-30 22:57:08: [2024-10-30 22:57:08] iter = 10480, loss = 26.5354
2024-10-30 22:57:11: [2024-10-30 22:57:11] iter = 10490, loss = 47.6535
2024-10-30 22:57:14: [2024-10-30 22:57:14] iter = 10500, loss = 56.4651
2024-10-30 22:57:18: [2024-10-30 22:57:18] iter = 10510, loss = 14.1170
2024-10-30 22:57:21: [2024-10-30 22:57:21] iter = 10520, loss = 8.6786
2024-10-30 22:57:24: [2024-10-30 22:57:24] iter = 10530, loss = 17.6999
2024-10-30 22:57:28: [2024-10-30 22:57:28] iter = 10540, loss = 5.4579
2024-10-30 22:57:30: [2024-10-30 22:57:30] iter = 10550, loss = 55.9586
2024-10-30 22:57:35: [2024-10-30 22:57:35] iter = 10560, loss = 5.7404
2024-10-30 22:57:39: [2024-10-30 22:57:39] iter = 10570, loss = 21.0132
2024-10-30 22:57:42: [2024-10-30 22:57:42] iter = 10580, loss = 20.3956
2024-10-30 22:57:45: [2024-10-30 22:57:45] iter = 10590, loss = 20.0765
2024-10-30 22:57:49: [2024-10-30 22:57:49] iter = 10600, loss = 28.1924
2024-10-30 22:57:53: [2024-10-30 22:57:53] iter = 10610, loss = 51.1553
2024-10-30 22:57:56: [2024-10-30 22:57:56] iter = 10620, loss = 18.7621
2024-10-30 22:58:00: [2024-10-30 22:58:00] iter = 10630, loss = 4.7455
2024-10-30 22:58:04: [2024-10-30 22:58:04] iter = 10640, loss = 30.5606
2024-10-30 22:58:08: [2024-10-30 22:58:08] iter = 10650, loss = 8.0226
2024-10-30 22:58:11: [2024-10-30 22:58:11] iter = 10660, loss = 8.7149
2024-10-30 22:58:14: [2024-10-30 22:58:14] iter = 10670, loss = 16.1872
2024-10-30 22:58:17: [2024-10-30 22:58:17] iter = 10680, loss = 4.1675
2024-10-30 22:58:21: [2024-10-30 22:58:21] iter = 10690, loss = 46.4196
2024-10-30 22:58:24: [2024-10-30 22:58:24] iter = 10700, loss = 4.8149
2024-10-30 22:58:29: [2024-10-30 22:58:29] iter = 10710, loss = 6.7863
2024-10-30 22:58:32: [2024-10-30 22:58:32] iter = 10720, loss = 10.9893
2024-10-30 22:58:36: [2024-10-30 22:58:36] iter = 10730, loss = 3.1234
2024-10-30 22:58:39: [2024-10-30 22:58:39] iter = 10740, loss = 26.6850
2024-10-30 22:58:43: [2024-10-30 22:58:43] iter = 10750, loss = 5.4515
2024-10-30 22:58:47: [2024-10-30 22:58:47] iter = 10760, loss = 29.5815
2024-10-30 22:58:51: [2024-10-30 22:58:51] iter = 10770, loss = 51.8932
2024-10-30 22:58:55: [2024-10-30 22:58:55] iter = 10780, loss = 5.6191
2024-10-30 22:58:59: [2024-10-30 22:58:59] iter = 10790, loss = 6.4528
2024-10-30 22:59:03: [2024-10-30 22:59:03] iter = 10800, loss = 11.6129
2024-10-30 22:59:08: [2024-10-30 22:59:08] iter = 10810, loss = 10.7198
2024-10-30 22:59:12: [2024-10-30 22:59:12] iter = 10820, loss = 22.5114
2024-10-30 22:59:17: [2024-10-30 22:59:17] iter = 10830, loss = 5.0536
2024-10-30 22:59:21: [2024-10-30 22:59:21] iter = 10840, loss = 17.4688
2024-10-30 22:59:25: [2024-10-30 22:59:25] iter = 10850, loss = 37.5510
2024-10-30 22:59:29: [2024-10-30 22:59:29] iter = 10860, loss = 11.7030
2024-10-30 22:59:33: [2024-10-30 22:59:33] iter = 10870, loss = 4.9483
2024-10-30 22:59:36: [2024-10-30 22:59:36] iter = 10880, loss = 9.1232
2024-10-30 22:59:39: [2024-10-30 22:59:39] iter = 10890, loss = 7.0699
2024-10-30 22:59:41: [2024-10-30 22:59:41] iter = 10900, loss = 9.5564
2024-10-30 22:59:45: [2024-10-30 22:59:45] iter = 10910, loss = 57.2104
2024-10-30 22:59:48: [2024-10-30 22:59:48] iter = 10920, loss = 10.8967
2024-10-30 22:59:52: [2024-10-30 22:59:52] iter = 10930, loss = 3.3882
2024-10-30 22:59:55: [2024-10-30 22:59:55] iter = 10940, loss = 51.4982
2024-10-30 22:59:59: [2024-10-30 22:59:59] iter = 10950, loss = 35.3193
2024-10-30 23:00:02: [2024-10-30 23:00:02] iter = 10960, loss = 13.0651
2024-10-30 23:00:06: [2024-10-30 23:00:06] iter = 10970, loss = 12.0559
2024-10-30 23:00:09: [2024-10-30 23:00:09] iter = 10980, loss = 12.3060
2024-10-30 23:00:12: [2024-10-30 23:00:12] iter = 10990, loss = 6.3509
2024-10-30 23:00:16: [2024-10-30 23:00:16] iter = 11000, loss = 4.0305
2024-10-30 23:00:19: [2024-10-30 23:00:19] iter = 11010, loss = 20.9685
2024-10-30 23:00:23: [2024-10-30 23:00:23] iter = 11020, loss = 54.7551
2024-10-30 23:00:26: [2024-10-30 23:00:26] iter = 11030, loss = 10.6261
2024-10-30 23:00:30: [2024-10-30 23:00:30] iter = 11040, loss = 7.8683
2024-10-30 23:00:33: [2024-10-30 23:00:33] iter = 11050, loss = 4.4447
2024-10-30 23:00:36: [2024-10-30 23:00:36] iter = 11060, loss = 7.9056
2024-10-30 23:00:40: [2024-10-30 23:00:40] iter = 11070, loss = 3.3862
2024-10-30 23:00:44: [2024-10-30 23:00:44] iter = 11080, loss = 7.8829
2024-10-30 23:00:47: [2024-10-30 23:00:47] iter = 11090, loss = 4.4046
2024-10-30 23:00:50: [2024-10-30 23:00:50] iter = 11100, loss = 32.6648
2024-10-30 23:00:53: [2024-10-30 23:00:53] iter = 11110, loss = 11.8557
2024-10-30 23:00:56: [2024-10-30 23:00:56] iter = 11120, loss = 30.6282
2024-10-30 23:00:59: [2024-10-30 23:00:59] iter = 11130, loss = 4.7083
2024-10-30 23:01:03: [2024-10-30 23:01:03] iter = 11140, loss = 49.0008
2024-10-30 23:01:04: [2024-10-30 23:01:04] iter = 11150, loss = 51.8804
2024-10-30 23:01:07: [2024-10-30 23:01:07] iter = 11160, loss = 9.6189
2024-10-30 23:01:10: [2024-10-30 23:01:10] iter = 11170, loss = 79.1427
2024-10-30 23:01:13: [2024-10-30 23:01:13] iter = 11180, loss = 19.0086
2024-10-30 23:01:16: [2024-10-30 23:01:16] iter = 11190, loss = 6.2625
2024-10-30 23:01:20: [2024-10-30 23:01:20] iter = 11200, loss = 51.2797
2024-10-30 23:01:24: [2024-10-30 23:01:24] iter = 11210, loss = 8.3176
2024-10-30 23:01:28: [2024-10-30 23:01:28] iter = 11220, loss = 6.8975
2024-10-30 23:01:31: [2024-10-30 23:01:31] iter = 11230, loss = 52.9095
2024-10-30 23:01:34: [2024-10-30 23:01:34] iter = 11240, loss = 41.8311
2024-10-30 23:01:39: [2024-10-30 23:01:39] iter = 11250, loss = 6.8727
2024-10-30 23:01:42: [2024-10-30 23:01:42] iter = 11260, loss = 40.5390
2024-10-30 23:01:47: [2024-10-30 23:01:47] iter = 11270, loss = 7.6455
2024-10-30 23:01:51: [2024-10-30 23:01:51] iter = 11280, loss = 46.1328
2024-10-30 23:01:56: [2024-10-30 23:01:56] iter = 11290, loss = 5.1780
2024-10-30 23:02:00: [2024-10-30 23:02:00] iter = 11300, loss = 25.8021
2024-10-30 23:02:04: [2024-10-30 23:02:04] iter = 11310, loss = 25.2761
2024-10-30 23:02:09: [2024-10-30 23:02:09] iter = 11320, loss = 4.9250
2024-10-30 23:02:13: [2024-10-30 23:02:13] iter = 11330, loss = 23.7955
2024-10-30 23:02:17: [2024-10-30 23:02:17] iter = 11340, loss = 58.4848
2024-10-30 23:02:22: [2024-10-30 23:02:21] iter = 11350, loss = 7.8439
2024-10-30 23:02:24: [2024-10-30 23:02:24] iter = 11360, loss = 10.4467
2024-10-30 23:02:28: [2024-10-30 23:02:28] iter = 11370, loss = 11.6078
2024-10-30 23:02:32: [2024-10-30 23:02:32] iter = 11380, loss = 6.1989
2024-10-30 23:02:35: [2024-10-30 23:02:35] iter = 11390, loss = 22.7853
2024-10-30 23:02:39: [2024-10-30 23:02:39] iter = 11400, loss = 50.0270
2024-10-30 23:02:42: [2024-10-30 23:02:42] iter = 11410, loss = 24.4256
2024-10-30 23:02:46: [2024-10-30 23:02:46] iter = 11420, loss = 3.7814
2024-10-30 23:02:48: [2024-10-30 23:02:48] iter = 11430, loss = 58.1299
2024-10-30 23:02:50: [2024-10-30 23:02:50] iter = 11440, loss = 4.8989
2024-10-30 23:02:54: [2024-10-30 23:02:54] iter = 11450, loss = 30.1364
2024-10-30 23:02:57: [2024-10-30 23:02:57] iter = 11460, loss = 17.9196
2024-10-30 23:03:01: [2024-10-30 23:03:01] iter = 11470, loss = 10.7133
2024-10-30 23:03:05: [2024-10-30 23:03:05] iter = 11480, loss = 16.1581
2024-10-30 23:03:08: [2024-10-30 23:03:08] iter = 11490, loss = 46.3743
2024-10-30 23:03:13: [2024-10-30 23:03:13] iter = 11500, loss = 41.6274
2024-10-30 23:03:16: [2024-10-30 23:03:16] iter = 11510, loss = 23.5657
2024-10-30 23:03:19: [2024-10-30 23:03:19] iter = 11520, loss = 33.1537
2024-10-30 23:03:25: [2024-10-30 23:03:25] iter = 11530, loss = 4.0211
2024-10-30 23:03:28: [2024-10-30 23:03:28] iter = 11540, loss = 8.6192
2024-10-30 23:03:32: [2024-10-30 23:03:32] iter = 11550, loss = 16.8453
2024-10-30 23:03:35: [2024-10-30 23:03:35] iter = 11560, loss = 24.9408
2024-10-30 23:03:39: [2024-10-30 23:03:39] iter = 11570, loss = 7.8028
2024-10-30 23:03:41: [2024-10-30 23:03:41] iter = 11580, loss = 52.8984
2024-10-30 23:03:44: [2024-10-30 23:03:44] iter = 11590, loss = 13.3082
2024-10-30 23:03:48: [2024-10-30 23:03:48] iter = 11600, loss = 17.3376
2024-10-30 23:03:51: [2024-10-30 23:03:51] iter = 11610, loss = 34.3859
2024-10-30 23:03:54: [2024-10-30 23:03:54] iter = 11620, loss = 35.5893
2024-10-30 23:03:57: [2024-10-30 23:03:57] iter = 11630, loss = 20.9040
2024-10-30 23:04:01: [2024-10-30 23:04:01] iter = 11640, loss = 37.8608
2024-10-30 23:04:04: [2024-10-30 23:04:04] iter = 11650, loss = 5.8085
2024-10-30 23:04:08: [2024-10-30 23:04:08] iter = 11660, loss = 4.4109
2024-10-30 23:04:11: [2024-10-30 23:04:11] iter = 11670, loss = 15.1650
2024-10-30 23:04:15: [2024-10-30 23:04:15] iter = 11680, loss = 12.3333
2024-10-30 23:04:18: [2024-10-30 23:04:18] iter = 11690, loss = 8.4237
2024-10-30 23:04:22: [2024-10-30 23:04:22] iter = 11700, loss = 5.4869
2024-10-30 23:04:25: [2024-10-30 23:04:25] iter = 11710, loss = 4.5375
2024-10-30 23:04:29: [2024-10-30 23:04:29] iter = 11720, loss = 4.9988
2024-10-30 23:04:33: [2024-10-30 23:04:33] iter = 11730, loss = 6.3404
2024-10-30 23:04:36: [2024-10-30 23:04:36] iter = 11740, loss = 3.9948
2024-10-30 23:04:39: [2024-10-30 23:04:39] iter = 11750, loss = 15.9097
2024-10-30 23:04:42: [2024-10-30 23:04:42] iter = 11760, loss = 5.1926
2024-10-30 23:04:45: [2024-10-30 23:04:45] iter = 11770, loss = 62.2179
2024-10-30 23:04:48: [2024-10-30 23:04:48] iter = 11780, loss = 9.1972
2024-10-30 23:04:51: [2024-10-30 23:04:51] iter = 11790, loss = 23.2984
2024-10-30 23:04:55: [2024-10-30 23:04:55] iter = 11800, loss = 31.5932
2024-10-30 23:04:59: [2024-10-30 23:04:59] iter = 11810, loss = 14.0800
2024-10-30 23:05:02: [2024-10-30 23:05:02] iter = 11820, loss = 25.0537
2024-10-30 23:05:05: [2024-10-30 23:05:05] iter = 11830, loss = 18.3520
2024-10-30 23:05:08: [2024-10-30 23:05:08] iter = 11840, loss = 13.2886
2024-10-30 23:05:12: [2024-10-30 23:05:12] iter = 11850, loss = 22.5777
2024-10-30 23:05:15: [2024-10-30 23:05:15] iter = 11860, loss = 4.2027
2024-10-30 23:05:18: [2024-10-30 23:05:18] iter = 11870, loss = 10.3576
2024-10-30 23:05:22: [2024-10-30 23:05:22] iter = 11880, loss = 6.7901
2024-10-30 23:05:26: [2024-10-30 23:05:26] iter = 11890, loss = 6.6630
2024-10-30 23:05:30: [2024-10-30 23:05:30] iter = 11900, loss = 19.5730
2024-10-30 23:05:34: [2024-10-30 23:05:34] iter = 11910, loss = 3.7087
2024-10-30 23:05:36: [2024-10-30 23:05:36] iter = 11920, loss = 20.9359
2024-10-30 23:05:39: [2024-10-30 23:05:39] iter = 11930, loss = 5.2783
2024-10-30 23:05:43: [2024-10-30 23:05:43] iter = 11940, loss = 43.9195
2024-10-30 23:05:47: [2024-10-30 23:05:47] iter = 11950, loss = 4.0920
2024-10-30 23:05:50: [2024-10-30 23:05:50] iter = 11960, loss = 18.1848
2024-10-30 23:05:54: [2024-10-30 23:05:54] iter = 11970, loss = 9.3505
2024-10-30 23:05:57: [2024-10-30 23:05:57] iter = 11980, loss = 13.6065
2024-10-30 23:06:00: [2024-10-30 23:06:00] iter = 11990, loss = 8.8918
2024-10-30 23:06:03: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-30 23:06:03: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:06:03: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63285}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:08:14: Evaluate 5 random ConvNet, ACCmean = 0.3028 ACCstd = 0.0088
-------------------------
2024-10-30 23:08:14: Evaluate 5 random ConvNet, SENmean = 0.3015 SENstd = 0.0045
-------------------------
2024-10-30 23:08:14: Evaluate 5 random ConvNet, SPEmean = 0.9032 SPEstd = 0.0010
-------------------------
2024-10-30 23:08:14: Evaluate 5 random ConvNet, F!mean = 0.2361 F!std = 0.0054
-------------------------
2024-10-30 23:08:14: Evaluate 5 random ConvNet, mean = 0.3028 std = 0.0088
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:08:14: [2024-10-30 23:08:14] iter = 12000, loss = 7.0536
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:08:17: [2024-10-30 23:08:17] iter = 12010, loss = 6.7713
2024-10-30 23:08:20: [2024-10-30 23:08:20] iter = 12020, loss = 13.8083
2024-10-30 23:08:24: [2024-10-30 23:08:24] iter = 12030, loss = 4.4599
2024-10-30 23:08:27: [2024-10-30 23:08:27] iter = 12040, loss = 5.7011
2024-10-30 23:08:31: [2024-10-30 23:08:31] iter = 12050, loss = 52.5993
2024-10-30 23:08:35: [2024-10-30 23:08:35] iter = 12060, loss = 4.4035
2024-10-30 23:08:39: [2024-10-30 23:08:39] iter = 12070, loss = 3.5847
2024-10-30 23:08:43: [2024-10-30 23:08:43] iter = 12080, loss = 9.9359
2024-10-30 23:08:46: [2024-10-30 23:08:46] iter = 12090, loss = 14.4388
2024-10-30 23:08:50: [2024-10-30 23:08:50] iter = 12100, loss = 35.8530
2024-10-30 23:08:54: [2024-10-30 23:08:54] iter = 12110, loss = 10.6661
2024-10-30 23:08:57: [2024-10-30 23:08:57] iter = 12120, loss = 22.9538
2024-10-30 23:09:00: [2024-10-30 23:09:00] iter = 12130, loss = 45.8497
2024-10-30 23:09:03: [2024-10-30 23:09:03] iter = 12140, loss = 22.8534
2024-10-30 23:09:07: [2024-10-30 23:09:07] iter = 12150, loss = 37.8117
2024-10-30 23:09:10: [2024-10-30 23:09:10] iter = 12160, loss = 42.9910
2024-10-30 23:09:14: [2024-10-30 23:09:14] iter = 12170, loss = 95.1567
2024-10-30 23:09:18: [2024-10-30 23:09:18] iter = 12180, loss = 3.4986
2024-10-30 23:09:22: [2024-10-30 23:09:22] iter = 12190, loss = 25.2502
2024-10-30 23:09:25: [2024-10-30 23:09:25] iter = 12200, loss = 6.2452
2024-10-30 23:09:30: [2024-10-30 23:09:30] iter = 12210, loss = 4.4996
2024-10-30 23:09:33: [2024-10-30 23:09:33] iter = 12220, loss = 46.0826
2024-10-30 23:09:37: [2024-10-30 23:09:37] iter = 12230, loss = 3.6528
2024-10-30 23:09:41: [2024-10-30 23:09:41] iter = 12240, loss = 23.0333
2024-10-30 23:09:45: [2024-10-30 23:09:45] iter = 12250, loss = 11.7856
2024-10-30 23:09:48: [2024-10-30 23:09:48] iter = 12260, loss = 13.9986
2024-10-30 23:09:52: [2024-10-30 23:09:52] iter = 12270, loss = 10.9373
2024-10-30 23:09:55: [2024-10-30 23:09:55] iter = 12280, loss = 17.6019
2024-10-30 23:09:59: [2024-10-30 23:09:59] iter = 12290, loss = 18.6475
2024-10-30 23:10:03: [2024-10-30 23:10:03] iter = 12300, loss = 5.7828
2024-10-30 23:10:07: [2024-10-30 23:10:07] iter = 12310, loss = 5.1937
2024-10-30 23:10:10: [2024-10-30 23:10:10] iter = 12320, loss = 6.7712
2024-10-30 23:10:13: [2024-10-30 23:10:13] iter = 12330, loss = 10.6546
2024-10-30 23:10:16: [2024-10-30 23:10:16] iter = 12340, loss = 21.2532
2024-10-30 23:10:19: [2024-10-30 23:10:19] iter = 12350, loss = 32.7622
2024-10-30 23:10:22: [2024-10-30 23:10:22] iter = 12360, loss = 15.4032
2024-10-30 23:10:26: [2024-10-30 23:10:26] iter = 12370, loss = 10.8452
2024-10-30 23:10:29: [2024-10-30 23:10:29] iter = 12380, loss = 16.6822
2024-10-30 23:10:33: [2024-10-30 23:10:33] iter = 12390, loss = 3.9641
2024-10-30 23:10:36: [2024-10-30 23:10:36] iter = 12400, loss = 3.9343
2024-10-30 23:10:40: [2024-10-30 23:10:40] iter = 12410, loss = 20.2717
2024-10-30 23:10:43: [2024-10-30 23:10:43] iter = 12420, loss = 13.1959
2024-10-30 23:10:47: [2024-10-30 23:10:47] iter = 12430, loss = 9.6347
2024-10-30 23:10:50: [2024-10-30 23:10:50] iter = 12440, loss = 4.4786
2024-10-30 23:10:54: [2024-10-30 23:10:54] iter = 12450, loss = 5.1662
2024-10-30 23:10:58: [2024-10-30 23:10:58] iter = 12460, loss = 55.8979
2024-10-30 23:11:02: [2024-10-30 23:11:02] iter = 12470, loss = 9.3428
2024-10-30 23:11:07: [2024-10-30 23:11:07] iter = 12480, loss = 6.8346
2024-10-30 23:11:11: [2024-10-30 23:11:11] iter = 12490, loss = 6.9569
2024-10-30 23:11:14: [2024-10-30 23:11:14] iter = 12500, loss = 13.0251
2024-10-30 23:11:17: [2024-10-30 23:11:17] iter = 12510, loss = 9.7723
2024-10-30 23:11:20: [2024-10-30 23:11:20] iter = 12520, loss = 49.5197
2024-10-30 23:11:23: [2024-10-30 23:11:23] iter = 12530, loss = 47.2058
2024-10-30 23:11:27: [2024-10-30 23:11:27] iter = 12540, loss = 20.3732
2024-10-30 23:11:30: [2024-10-30 23:11:30] iter = 12550, loss = 7.0601
2024-10-30 23:11:33: [2024-10-30 23:11:33] iter = 12560, loss = 35.6976
2024-10-30 23:11:36: [2024-10-30 23:11:36] iter = 12570, loss = 5.7691
2024-10-30 23:11:40: [2024-10-30 23:11:40] iter = 12580, loss = 6.6571
2024-10-30 23:11:43: [2024-10-30 23:11:43] iter = 12590, loss = 51.0203
2024-10-30 23:11:46: [2024-10-30 23:11:46] iter = 12600, loss = 40.6472
2024-10-30 23:11:49: [2024-10-30 23:11:49] iter = 12610, loss = 4.8564
2024-10-30 23:11:52: [2024-10-30 23:11:52] iter = 12620, loss = 18.2352
2024-10-30 23:11:55: [2024-10-30 23:11:55] iter = 12630, loss = 3.6246
2024-10-30 23:11:57: [2024-10-30 23:11:57] iter = 12640, loss = 81.6153
2024-10-30 23:12:01: [2024-10-30 23:12:01] iter = 12650, loss = 18.8563
2024-10-30 23:12:03: [2024-10-30 23:12:03] iter = 12660, loss = 61.1252
2024-10-30 23:12:06: [2024-10-30 23:12:06] iter = 12670, loss = 46.8301
2024-10-30 23:12:10: [2024-10-30 23:12:10] iter = 12680, loss = 10.9185
2024-10-30 23:12:13: [2024-10-30 23:12:13] iter = 12690, loss = 31.1939
2024-10-30 23:12:16: [2024-10-30 23:12:16] iter = 12700, loss = 19.6294
2024-10-30 23:12:19: [2024-10-30 23:12:19] iter = 12710, loss = 44.8897
2024-10-30 23:12:22: [2024-10-30 23:12:22] iter = 12720, loss = 15.3512
2024-10-30 23:12:24: [2024-10-30 23:12:24] iter = 12730, loss = 5.6313
2024-10-30 23:12:27: [2024-10-30 23:12:27] iter = 12740, loss = 6.4313
2024-10-30 23:12:28: [2024-10-30 23:12:28] iter = 12750, loss = 4.2620
2024-10-30 23:12:31: [2024-10-30 23:12:31] iter = 12760, loss = 73.1375
2024-10-30 23:12:34: [2024-10-30 23:12:34] iter = 12770, loss = 13.7706
2024-10-30 23:12:37: [2024-10-30 23:12:37] iter = 12780, loss = 4.8936
2024-10-30 23:12:39: [2024-10-30 23:12:39] iter = 12790, loss = 11.5077
2024-10-30 23:12:41: [2024-10-30 23:12:41] iter = 12800, loss = 13.7495
2024-10-30 23:12:44: [2024-10-30 23:12:44] iter = 12810, loss = 23.9398
2024-10-30 23:12:47: [2024-10-30 23:12:47] iter = 12820, loss = 5.1947
2024-10-30 23:12:50: [2024-10-30 23:12:50] iter = 12830, loss = 12.7259
2024-10-30 23:12:53: [2024-10-30 23:12:53] iter = 12840, loss = 14.5893
2024-10-30 23:12:55: [2024-10-30 23:12:55] iter = 12850, loss = 4.0285
2024-10-30 23:12:58: [2024-10-30 23:12:58] iter = 12860, loss = 7.8758
2024-10-30 23:13:01: [2024-10-30 23:13:01] iter = 12870, loss = 14.4025
2024-10-30 23:13:05: [2024-10-30 23:13:05] iter = 12880, loss = 3.9928
2024-10-30 23:13:08: [2024-10-30 23:13:08] iter = 12890, loss = 17.1944
2024-10-30 23:13:10: [2024-10-30 23:13:10] iter = 12900, loss = 19.9762
2024-10-30 23:13:13: [2024-10-30 23:13:13] iter = 12910, loss = 9.2636
2024-10-30 23:13:17: [2024-10-30 23:13:17] iter = 12920, loss = 10.4344
2024-10-30 23:13:20: [2024-10-30 23:13:20] iter = 12930, loss = 4.3660
2024-10-30 23:13:23: [2024-10-30 23:13:23] iter = 12940, loss = 4.6845
2024-10-30 23:13:27: [2024-10-30 23:13:27] iter = 12950, loss = 9.6011
2024-10-30 23:13:31: [2024-10-30 23:13:31] iter = 12960, loss = 10.3613
2024-10-30 23:13:34: [2024-10-30 23:13:34] iter = 12970, loss = 8.1304
2024-10-30 23:13:38: [2024-10-30 23:13:38] iter = 12980, loss = 24.7221
2024-10-30 23:13:42: [2024-10-30 23:13:42] iter = 12990, loss = 16.9286
2024-10-30 23:13:44: [2024-10-30 23:13:44] iter = 13000, loss = 31.5890
2024-10-30 23:13:47: [2024-10-30 23:13:47] iter = 13010, loss = 8.8038
2024-10-30 23:13:49: [2024-10-30 23:13:49] iter = 13020, loss = 16.4861
2024-10-30 23:13:51: [2024-10-30 23:13:51] iter = 13030, loss = 26.1959
2024-10-30 23:13:54: [2024-10-30 23:13:54] iter = 13040, loss = 13.2452
2024-10-30 23:13:56: [2024-10-30 23:13:56] iter = 13050, loss = 46.5142
2024-10-30 23:13:59: [2024-10-30 23:13:59] iter = 13060, loss = 4.3557
2024-10-30 23:14:02: [2024-10-30 23:14:02] iter = 13070, loss = 5.1741
2024-10-30 23:14:06: [2024-10-30 23:14:06] iter = 13080, loss = 8.7822
2024-10-30 23:14:09: [2024-10-30 23:14:09] iter = 13090, loss = 30.1684
2024-10-30 23:14:11: [2024-10-30 23:14:11] iter = 13100, loss = 8.5192
2024-10-30 23:14:15: [2024-10-30 23:14:15] iter = 13110, loss = 5.2072
2024-10-30 23:14:18: [2024-10-30 23:14:18] iter = 13120, loss = 39.9260
2024-10-30 23:14:21: [2024-10-30 23:14:21] iter = 13130, loss = 52.7598
2024-10-30 23:14:24: [2024-10-30 23:14:24] iter = 13140, loss = 9.3702
2024-10-30 23:14:27: [2024-10-30 23:14:27] iter = 13150, loss = 12.5182
2024-10-30 23:14:31: [2024-10-30 23:14:31] iter = 13160, loss = 5.7358
2024-10-30 23:14:34: [2024-10-30 23:14:34] iter = 13170, loss = 3.8170
2024-10-30 23:14:38: [2024-10-30 23:14:38] iter = 13180, loss = 15.2550
2024-10-30 23:14:41: [2024-10-30 23:14:41] iter = 13190, loss = 18.5593
2024-10-30 23:14:44: [2024-10-30 23:14:44] iter = 13200, loss = 6.4774
2024-10-30 23:14:47: [2024-10-30 23:14:47] iter = 13210, loss = 15.9499
2024-10-30 23:14:50: [2024-10-30 23:14:50] iter = 13220, loss = 11.5134
2024-10-30 23:14:53: [2024-10-30 23:14:53] iter = 13230, loss = 34.4946
2024-10-30 23:14:57: [2024-10-30 23:14:57] iter = 13240, loss = 3.5443
2024-10-30 23:15:01: [2024-10-30 23:15:01] iter = 13250, loss = 4.2953
2024-10-30 23:15:04: [2024-10-30 23:15:04] iter = 13260, loss = 5.1227
2024-10-30 23:15:07: [2024-10-30 23:15:07] iter = 13270, loss = 3.7103
2024-10-30 23:15:10: [2024-10-30 23:15:10] iter = 13280, loss = 57.8279
2024-10-30 23:15:14: [2024-10-30 23:15:14] iter = 13290, loss = 12.4312
2024-10-30 23:15:18: [2024-10-30 23:15:18] iter = 13300, loss = 59.6244
2024-10-30 23:15:21: [2024-10-30 23:15:21] iter = 13310, loss = 5.6985
2024-10-30 23:15:24: [2024-10-30 23:15:24] iter = 13320, loss = 5.6331
2024-10-30 23:15:27: [2024-10-30 23:15:27] iter = 13330, loss = 39.0447
2024-10-30 23:15:29: [2024-10-30 23:15:29] iter = 13340, loss = 15.6866
2024-10-30 23:15:33: [2024-10-30 23:15:33] iter = 13350, loss = 4.8531
2024-10-30 23:15:36: [2024-10-30 23:15:36] iter = 13360, loss = 7.3399
2024-10-30 23:15:40: [2024-10-30 23:15:40] iter = 13370, loss = 18.6475
2024-10-30 23:15:44: [2024-10-30 23:15:44] iter = 13380, loss = 43.2177
2024-10-30 23:15:47: [2024-10-30 23:15:47] iter = 13390, loss = 56.6069
2024-10-30 23:15:51: [2024-10-30 23:15:51] iter = 13400, loss = 5.4891
2024-10-30 23:15:54: [2024-10-30 23:15:54] iter = 13410, loss = 4.0018
2024-10-30 23:15:58: [2024-10-30 23:15:58] iter = 13420, loss = 23.2629
2024-10-30 23:16:01: [2024-10-30 23:16:01] iter = 13430, loss = 5.3863
2024-10-30 23:16:06: [2024-10-30 23:16:06] iter = 13440, loss = 6.6879
2024-10-30 23:16:09: [2024-10-30 23:16:09] iter = 13450, loss = 101.9327
2024-10-30 23:16:13: [2024-10-30 23:16:13] iter = 13460, loss = 4.7080
2024-10-30 23:16:16: [2024-10-30 23:16:16] iter = 13470, loss = 13.7891
2024-10-30 23:16:19: [2024-10-30 23:16:19] iter = 13480, loss = 4.5354
2024-10-30 23:16:22: [2024-10-30 23:16:22] iter = 13490, loss = 6.4863
2024-10-30 23:16:25: [2024-10-30 23:16:25] iter = 13500, loss = 16.4253
2024-10-30 23:16:28: [2024-10-30 23:16:28] iter = 13510, loss = 18.6229
2024-10-30 23:16:32: [2024-10-30 23:16:32] iter = 13520, loss = 47.8385
2024-10-30 23:16:35: [2024-10-30 23:16:35] iter = 13530, loss = 30.0430
2024-10-30 23:16:37: [2024-10-30 23:16:37] iter = 13540, loss = 61.6106
2024-10-30 23:16:40: [2024-10-30 23:16:40] iter = 13550, loss = 11.0291
2024-10-30 23:16:44: [2024-10-30 23:16:44] iter = 13560, loss = 15.6981
2024-10-30 23:16:46: [2024-10-30 23:16:46] iter = 13570, loss = 15.5418
2024-10-30 23:16:49: [2024-10-30 23:16:49] iter = 13580, loss = 8.5479
2024-10-30 23:16:51: [2024-10-30 23:16:51] iter = 13590, loss = 50.7258
2024-10-30 23:16:55: [2024-10-30 23:16:55] iter = 13600, loss = 6.1434
2024-10-30 23:16:59: [2024-10-30 23:16:59] iter = 13610, loss = 4.7343
2024-10-30 23:17:03: [2024-10-30 23:17:03] iter = 13620, loss = 45.4019
2024-10-30 23:17:07: [2024-10-30 23:17:07] iter = 13630, loss = 8.4250
2024-10-30 23:17:11: [2024-10-30 23:17:10] iter = 13640, loss = 10.2814
2024-10-30 23:17:14: [2024-10-30 23:17:14] iter = 13650, loss = 9.9542
2024-10-30 23:17:17: [2024-10-30 23:17:17] iter = 13660, loss = 13.0378
2024-10-30 23:17:20: [2024-10-30 23:17:20] iter = 13670, loss = 35.9104
2024-10-30 23:17:23: [2024-10-30 23:17:23] iter = 13680, loss = 12.7362
2024-10-30 23:17:27: [2024-10-30 23:17:27] iter = 13690, loss = 3.5888
2024-10-30 23:17:31: [2024-10-30 23:17:31] iter = 13700, loss = 63.4811
2024-10-30 23:17:34: [2024-10-30 23:17:34] iter = 13710, loss = 14.5419
2024-10-30 23:17:37: [2024-10-30 23:17:37] iter = 13720, loss = 52.9117
2024-10-30 23:17:40: [2024-10-30 23:17:40] iter = 13730, loss = 3.4923
2024-10-30 23:17:43: [2024-10-30 23:17:43] iter = 13740, loss = 9.2958
2024-10-30 23:17:46: [2024-10-30 23:17:46] iter = 13750, loss = 4.2390
2024-10-30 23:17:50: [2024-10-30 23:17:50] iter = 13760, loss = 6.6322
2024-10-30 23:17:53: [2024-10-30 23:17:53] iter = 13770, loss = 5.6260
2024-10-30 23:17:56: [2024-10-30 23:17:56] iter = 13780, loss = 5.2532
2024-10-30 23:18:00: [2024-10-30 23:18:00] iter = 13790, loss = 13.5573
2024-10-30 23:18:03: [2024-10-30 23:18:03] iter = 13800, loss = 47.2605
2024-10-30 23:18:06: [2024-10-30 23:18:06] iter = 13810, loss = 5.2829
2024-10-30 23:18:09: [2024-10-30 23:18:09] iter = 13820, loss = 10.0750
2024-10-30 23:18:12: [2024-10-30 23:18:12] iter = 13830, loss = 12.9587
2024-10-30 23:18:15: [2024-10-30 23:18:15] iter = 13840, loss = 10.2228
2024-10-30 23:18:17: [2024-10-30 23:18:17] iter = 13850, loss = 25.5072
2024-10-30 23:18:21: [2024-10-30 23:18:21] iter = 13860, loss = 15.3395
2024-10-30 23:18:24: [2024-10-30 23:18:24] iter = 13870, loss = 29.1911
2024-10-30 23:18:28: [2024-10-30 23:18:28] iter = 13880, loss = 5.1939
2024-10-30 23:18:32: [2024-10-30 23:18:32] iter = 13890, loss = 39.7632
2024-10-30 23:18:36: [2024-10-30 23:18:36] iter = 13900, loss = 27.0158
2024-10-30 23:18:39: [2024-10-30 23:18:39] iter = 13910, loss = 22.9090
2024-10-30 23:18:42: [2024-10-30 23:18:42] iter = 13920, loss = 4.8096
2024-10-30 23:18:44: [2024-10-30 23:18:44] iter = 13930, loss = 32.1799
2024-10-30 23:18:46: [2024-10-30 23:18:46] iter = 13940, loss = 28.0743
2024-10-30 23:18:50: [2024-10-30 23:18:50] iter = 13950, loss = 18.7870
2024-10-30 23:18:53: [2024-10-30 23:18:53] iter = 13960, loss = 26.7302
2024-10-30 23:18:55: [2024-10-30 23:18:55] iter = 13970, loss = 11.3081
2024-10-30 23:18:59: [2024-10-30 23:18:59] iter = 13980, loss = 25.0841
2024-10-30 23:19:02: [2024-10-30 23:19:02] iter = 13990, loss = 20.7158
2024-10-30 23:19:05: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-30 23:19:05: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:19:05: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 45572}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:21:03: Evaluate 5 random ConvNet, ACCmean = 0.3944 ACCstd = 0.0077
-------------------------
2024-10-30 23:21:03: Evaluate 5 random ConvNet, SENmean = 0.3116 SENstd = 0.0033
-------------------------
2024-10-30 23:21:03: Evaluate 5 random ConvNet, SPEmean = 0.9102 SPEstd = 0.0009
-------------------------
2024-10-30 23:21:03: Evaluate 5 random ConvNet, F!mean = 0.2756 F!std = 0.0045
-------------------------
2024-10-30 23:21:03: Evaluate 5 random ConvNet, mean = 0.3944 std = 0.0077
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:21:03: [2024-10-30 23:21:03] iter = 14000, loss = 9.9223
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:21:07: [2024-10-30 23:21:07] iter = 14010, loss = 14.8672
2024-10-30 23:21:10: [2024-10-30 23:21:10] iter = 14020, loss = 3.7390
2024-10-30 23:21:12: [2024-10-30 23:21:12] iter = 14030, loss = 14.0354
2024-10-30 23:21:16: [2024-10-30 23:21:16] iter = 14040, loss = 76.3541
2024-10-30 23:21:18: [2024-10-30 23:21:18] iter = 14050, loss = 11.6900
2024-10-30 23:21:21: [2024-10-30 23:21:21] iter = 14060, loss = 5.1300
2024-10-30 23:21:25: [2024-10-30 23:21:25] iter = 14070, loss = 15.4083
2024-10-30 23:21:28: [2024-10-30 23:21:28] iter = 14080, loss = 11.1184
2024-10-30 23:21:32: [2024-10-30 23:21:32] iter = 14090, loss = 5.1974
2024-10-30 23:21:34: [2024-10-30 23:21:34] iter = 14100, loss = 5.0548
2024-10-30 23:21:36: [2024-10-30 23:21:36] iter = 14110, loss = 46.3265
2024-10-30 23:21:39: [2024-10-30 23:21:39] iter = 14120, loss = 7.2069
2024-10-30 23:21:43: [2024-10-30 23:21:43] iter = 14130, loss = 26.2736
2024-10-30 23:21:47: [2024-10-30 23:21:47] iter = 14140, loss = 13.4746
2024-10-30 23:21:50: [2024-10-30 23:21:50] iter = 14150, loss = 4.7694
2024-10-30 23:21:52: [2024-10-30 23:21:52] iter = 14160, loss = 20.6799
2024-10-30 23:21:56: [2024-10-30 23:21:56] iter = 14170, loss = 8.8652
2024-10-30 23:22:00: [2024-10-30 23:22:00] iter = 14180, loss = 32.7850
2024-10-30 23:22:04: [2024-10-30 23:22:04] iter = 14190, loss = 34.2688
2024-10-30 23:22:07: [2024-10-30 23:22:07] iter = 14200, loss = 7.9046
2024-10-30 23:22:11: [2024-10-30 23:22:11] iter = 14210, loss = 57.8541
2024-10-30 23:22:15: [2024-10-30 23:22:15] iter = 14220, loss = 52.2229
2024-10-30 23:22:19: [2024-10-30 23:22:19] iter = 14230, loss = 24.1290
2024-10-30 23:22:22: [2024-10-30 23:22:22] iter = 14240, loss = 14.2610
2024-10-30 23:22:25: [2024-10-30 23:22:25] iter = 14250, loss = 58.2966
2024-10-30 23:22:29: [2024-10-30 23:22:29] iter = 14260, loss = 5.8258
2024-10-30 23:22:33: [2024-10-30 23:22:33] iter = 14270, loss = 9.0845
2024-10-30 23:22:36: [2024-10-30 23:22:36] iter = 14280, loss = 4.1871
2024-10-30 23:22:39: [2024-10-30 23:22:39] iter = 14290, loss = 8.2563
2024-10-30 23:22:43: [2024-10-30 23:22:43] iter = 14300, loss = 7.6300
2024-10-30 23:22:47: [2024-10-30 23:22:47] iter = 14310, loss = 43.8587
2024-10-30 23:22:51: [2024-10-30 23:22:51] iter = 14320, loss = 17.4275
2024-10-30 23:22:55: [2024-10-30 23:22:55] iter = 14330, loss = 51.5666
2024-10-30 23:22:59: [2024-10-30 23:22:59] iter = 14340, loss = 33.9121
2024-10-30 23:23:02: [2024-10-30 23:23:02] iter = 14350, loss = 23.9100
2024-10-30 23:23:05: [2024-10-30 23:23:05] iter = 14360, loss = 14.3265
2024-10-30 23:23:09: [2024-10-30 23:23:09] iter = 14370, loss = 6.4192
2024-10-30 23:23:13: [2024-10-30 23:23:13] iter = 14380, loss = 8.0161
2024-10-30 23:23:17: [2024-10-30 23:23:17] iter = 14390, loss = 45.7382
2024-10-30 23:23:20: [2024-10-30 23:23:20] iter = 14400, loss = 28.3713
2024-10-30 23:23:23: [2024-10-30 23:23:23] iter = 14410, loss = 26.8186
2024-10-30 23:23:26: [2024-10-30 23:23:26] iter = 14420, loss = 13.2742
2024-10-30 23:23:29: [2024-10-30 23:23:29] iter = 14430, loss = 6.9401
2024-10-30 23:23:33: [2024-10-30 23:23:33] iter = 14440, loss = 64.7667
2024-10-30 23:23:36: [2024-10-30 23:23:36] iter = 14450, loss = 4.9239
2024-10-30 23:23:39: [2024-10-30 23:23:39] iter = 14460, loss = 79.1552
2024-10-30 23:23:42: [2024-10-30 23:23:42] iter = 14470, loss = 16.8615
2024-10-30 23:23:44: [2024-10-30 23:23:44] iter = 14480, loss = 19.5812
2024-10-30 23:23:48: [2024-10-30 23:23:48] iter = 14490, loss = 22.1063
2024-10-30 23:23:52: [2024-10-30 23:23:52] iter = 14500, loss = 38.4620
2024-10-30 23:23:56: [2024-10-30 23:23:56] iter = 14510, loss = 4.9477
2024-10-30 23:23:59: [2024-10-30 23:23:59] iter = 14520, loss = 4.6960
2024-10-30 23:24:03: [2024-10-30 23:24:03] iter = 14530, loss = 5.4717
2024-10-30 23:24:06: [2024-10-30 23:24:06] iter = 14540, loss = 49.5178
2024-10-30 23:24:10: [2024-10-30 23:24:10] iter = 14550, loss = 7.3592
2024-10-30 23:24:13: [2024-10-30 23:24:13] iter = 14560, loss = 13.5203
2024-10-30 23:24:16: [2024-10-30 23:24:16] iter = 14570, loss = 22.2333
2024-10-30 23:24:20: [2024-10-30 23:24:20] iter = 14580, loss = 4.7130
2024-10-30 23:24:24: [2024-10-30 23:24:24] iter = 14590, loss = 4.1176
2024-10-30 23:24:27: [2024-10-30 23:24:27] iter = 14600, loss = 20.6452
2024-10-30 23:24:30: [2024-10-30 23:24:30] iter = 14610, loss = 15.8218
2024-10-30 23:24:33: [2024-10-30 23:24:33] iter = 14620, loss = 13.4826
2024-10-30 23:24:36: [2024-10-30 23:24:36] iter = 14630, loss = 5.7932
2024-10-30 23:24:38: [2024-10-30 23:24:38] iter = 14640, loss = 5.7762
2024-10-30 23:24:42: [2024-10-30 23:24:42] iter = 14650, loss = 44.6522
2024-10-30 23:24:45: [2024-10-30 23:24:45] iter = 14660, loss = 37.7572
2024-10-30 23:24:49: [2024-10-30 23:24:49] iter = 14670, loss = 5.3742
2024-10-30 23:24:53: [2024-10-30 23:24:53] iter = 14680, loss = 36.3238
2024-10-30 23:24:57: [2024-10-30 23:24:57] iter = 14690, loss = 29.2559
2024-10-30 23:25:00: [2024-10-30 23:25:00] iter = 14700, loss = 4.6862
2024-10-30 23:25:04: [2024-10-30 23:25:04] iter = 14710, loss = 7.5570
2024-10-30 23:25:07: [2024-10-30 23:25:07] iter = 14720, loss = 22.2239
2024-10-30 23:25:10: [2024-10-30 23:25:10] iter = 14730, loss = 22.5700
2024-10-30 23:25:14: [2024-10-30 23:25:14] iter = 14740, loss = 13.9728
2024-10-30 23:25:17: [2024-10-30 23:25:17] iter = 14750, loss = 7.3277
2024-10-30 23:25:21: [2024-10-30 23:25:21] iter = 14760, loss = 3.7943
2024-10-30 23:25:24: [2024-10-30 23:25:24] iter = 14770, loss = 31.8208
2024-10-30 23:25:28: [2024-10-30 23:25:28] iter = 14780, loss = 10.4588
2024-10-30 23:25:31: [2024-10-30 23:25:31] iter = 14790, loss = 6.9231
2024-10-30 23:25:35: [2024-10-30 23:25:35] iter = 14800, loss = 14.9789
2024-10-30 23:25:38: [2024-10-30 23:25:38] iter = 14810, loss = 37.1663
2024-10-30 23:25:41: [2024-10-30 23:25:41] iter = 14820, loss = 4.9920
2024-10-30 23:25:44: [2024-10-30 23:25:44] iter = 14830, loss = 23.1629
2024-10-30 23:25:46: [2024-10-30 23:25:46] iter = 14840, loss = 8.0307
2024-10-30 23:25:50: [2024-10-30 23:25:50] iter = 14850, loss = 64.4148
2024-10-30 23:25:53: [2024-10-30 23:25:53] iter = 14860, loss = 30.1992
2024-10-30 23:25:57: [2024-10-30 23:25:57] iter = 14870, loss = 15.2998
2024-10-30 23:26:01: [2024-10-30 23:26:01] iter = 14880, loss = 4.2740
2024-10-30 23:26:04: [2024-10-30 23:26:04] iter = 14890, loss = 4.8631
2024-10-30 23:26:08: [2024-10-30 23:26:08] iter = 14900, loss = 30.1120
2024-10-30 23:26:11: [2024-10-30 23:26:11] iter = 14910, loss = 11.9726
2024-10-30 23:26:14: [2024-10-30 23:26:14] iter = 14920, loss = 21.4583
2024-10-30 23:26:18: [2024-10-30 23:26:18] iter = 14930, loss = 56.3507
2024-10-30 23:26:22: [2024-10-30 23:26:22] iter = 14940, loss = 24.7513
2024-10-30 23:26:25: [2024-10-30 23:26:25] iter = 14950, loss = 31.6271
2024-10-30 23:26:29: [2024-10-30 23:26:29] iter = 14960, loss = 4.5041
2024-10-30 23:26:32: [2024-10-30 23:26:32] iter = 14970, loss = 21.1775
2024-10-30 23:26:36: [2024-10-30 23:26:36] iter = 14980, loss = 41.0432
2024-10-30 23:26:41: [2024-10-30 23:26:41] iter = 14990, loss = 14.4187
2024-10-30 23:26:45: [2024-10-30 23:26:45] iter = 15000, loss = 43.4091
2024-10-30 23:26:48: [2024-10-30 23:26:48] iter = 15010, loss = 19.2998
2024-10-30 23:26:51: [2024-10-30 23:26:51] iter = 15020, loss = 38.3312
2024-10-30 23:26:54: [2024-10-30 23:26:54] iter = 15030, loss = 5.8280
2024-10-30 23:26:57: [2024-10-30 23:26:57] iter = 15040, loss = 15.9627
2024-10-30 23:27:00: [2024-10-30 23:27:00] iter = 15050, loss = 12.3830
2024-10-30 23:27:04: [2024-10-30 23:27:04] iter = 15060, loss = 9.7967
2024-10-30 23:27:08: [2024-10-30 23:27:08] iter = 15070, loss = 13.2219
2024-10-30 23:27:12: [2024-10-30 23:27:12] iter = 15080, loss = 62.7573
2024-10-30 23:27:15: [2024-10-30 23:27:15] iter = 15090, loss = 20.4840
2024-10-30 23:27:19: [2024-10-30 23:27:18] iter = 15100, loss = 8.9322
2024-10-30 23:27:22: [2024-10-30 23:27:22] iter = 15110, loss = 4.5863
2024-10-30 23:27:25: [2024-10-30 23:27:25] iter = 15120, loss = 11.9314
2024-10-30 23:27:28: [2024-10-30 23:27:28] iter = 15130, loss = 44.6763
2024-10-30 23:27:32: [2024-10-30 23:27:32] iter = 15140, loss = 25.1525
2024-10-30 23:27:35: [2024-10-30 23:27:35] iter = 15150, loss = 5.4746
2024-10-30 23:27:39: [2024-10-30 23:27:39] iter = 15160, loss = 4.1596
2024-10-30 23:27:42: [2024-10-30 23:27:42] iter = 15170, loss = 12.0326
2024-10-30 23:27:46: [2024-10-30 23:27:46] iter = 15180, loss = 4.6236
2024-10-30 23:27:49: [2024-10-30 23:27:49] iter = 15190, loss = 20.6303
2024-10-30 23:27:53: [2024-10-30 23:27:53] iter = 15200, loss = 9.3574
2024-10-30 23:27:56: [2024-10-30 23:27:56] iter = 15210, loss = 5.7277
2024-10-30 23:27:59: [2024-10-30 23:27:59] iter = 15220, loss = 3.9258
2024-10-30 23:28:02: [2024-10-30 23:28:02] iter = 15230, loss = 27.6432
2024-10-30 23:28:06: [2024-10-30 23:28:06] iter = 15240, loss = 17.3682
2024-10-30 23:28:10: [2024-10-30 23:28:10] iter = 15250, loss = 4.6581
2024-10-30 23:28:14: [2024-10-30 23:28:14] iter = 15260, loss = 110.9831
2024-10-30 23:28:17: [2024-10-30 23:28:17] iter = 15270, loss = 53.6222
2024-10-30 23:28:20: [2024-10-30 23:28:20] iter = 15280, loss = 51.3875
2024-10-30 23:28:24: [2024-10-30 23:28:24] iter = 15290, loss = 7.7461
2024-10-30 23:28:27: [2024-10-30 23:28:27] iter = 15300, loss = 6.7662
2024-10-30 23:28:30: [2024-10-30 23:28:30] iter = 15310, loss = 33.9836
2024-10-30 23:28:32: [2024-10-30 23:28:32] iter = 15320, loss = 12.8167
2024-10-30 23:28:35: [2024-10-30 23:28:35] iter = 15330, loss = 36.2324
2024-10-30 23:28:39: [2024-10-30 23:28:39] iter = 15340, loss = 5.5367
2024-10-30 23:28:42: [2024-10-30 23:28:42] iter = 15350, loss = 3.9273
2024-10-30 23:28:46: [2024-10-30 23:28:46] iter = 15360, loss = 69.4030
2024-10-30 23:28:49: [2024-10-30 23:28:49] iter = 15370, loss = 4.3634
2024-10-30 23:28:54: [2024-10-30 23:28:54] iter = 15380, loss = 15.4900
2024-10-30 23:28:57: [2024-10-30 23:28:57] iter = 15390, loss = 10.9713
2024-10-30 23:29:00: [2024-10-30 23:29:00] iter = 15400, loss = 9.6739
2024-10-30 23:29:04: [2024-10-30 23:29:04] iter = 15410, loss = 5.7570
2024-10-30 23:29:07: [2024-10-30 23:29:07] iter = 15420, loss = 28.5854
2024-10-30 23:29:10: [2024-10-30 23:29:10] iter = 15430, loss = 6.8214
2024-10-30 23:29:14: [2024-10-30 23:29:14] iter = 15440, loss = 7.1652
2024-10-30 23:29:17: [2024-10-30 23:29:17] iter = 15450, loss = 6.0623
2024-10-30 23:29:22: [2024-10-30 23:29:22] iter = 15460, loss = 4.8454
2024-10-30 23:29:27: [2024-10-30 23:29:27] iter = 15470, loss = 33.8805
2024-10-30 23:29:30: [2024-10-30 23:29:30] iter = 15480, loss = 46.6677
2024-10-30 23:29:34: [2024-10-30 23:29:34] iter = 15490, loss = 7.6353
2024-10-30 23:29:37: [2024-10-30 23:29:37] iter = 15500, loss = 9.4150
2024-10-30 23:29:41: [2024-10-30 23:29:41] iter = 15510, loss = 29.3724
2024-10-30 23:29:43: [2024-10-30 23:29:43] iter = 15520, loss = 30.9677
2024-10-30 23:29:47: [2024-10-30 23:29:47] iter = 15530, loss = 13.0450
2024-10-30 23:29:51: [2024-10-30 23:29:51] iter = 15540, loss = 24.1009
2024-10-30 23:29:55: [2024-10-30 23:29:55] iter = 15550, loss = 4.2276
2024-10-30 23:29:59: [2024-10-30 23:29:59] iter = 15560, loss = 57.7438
2024-10-30 23:30:01: [2024-10-30 23:30:01] iter = 15570, loss = 71.1926
2024-10-30 23:30:04: [2024-10-30 23:30:04] iter = 15580, loss = 7.8783
2024-10-30 23:30:08: [2024-10-30 23:30:08] iter = 15590, loss = 15.2707
2024-10-30 23:30:12: [2024-10-30 23:30:12] iter = 15600, loss = 8.4578
2024-10-30 23:30:15: [2024-10-30 23:30:15] iter = 15610, loss = 6.5284
2024-10-30 23:30:19: [2024-10-30 23:30:19] iter = 15620, loss = 33.5541
2024-10-30 23:30:22: [2024-10-30 23:30:22] iter = 15630, loss = 11.2843
2024-10-30 23:30:25: [2024-10-30 23:30:25] iter = 15640, loss = 15.7463
2024-10-30 23:30:27: [2024-10-30 23:30:27] iter = 15650, loss = 32.6661
2024-10-30 23:30:29: [2024-10-30 23:30:29] iter = 15660, loss = 14.0434
2024-10-30 23:30:32: [2024-10-30 23:30:32] iter = 15670, loss = 21.6832
2024-10-30 23:30:36: [2024-10-30 23:30:36] iter = 15680, loss = 14.7890
2024-10-30 23:30:40: [2024-10-30 23:30:40] iter = 15690, loss = 11.4589
2024-10-30 23:30:43: [2024-10-30 23:30:43] iter = 15700, loss = 7.2158
2024-10-30 23:30:48: [2024-10-30 23:30:48] iter = 15710, loss = 27.6823
2024-10-30 23:30:52: [2024-10-30 23:30:52] iter = 15720, loss = 5.6293
2024-10-30 23:30:55: [2024-10-30 23:30:55] iter = 15730, loss = 57.4457
2024-10-30 23:31:00: [2024-10-30 23:31:00] iter = 15740, loss = 4.8503
2024-10-30 23:31:03: [2024-10-30 23:31:03] iter = 15750, loss = 4.9093
2024-10-30 23:31:07: [2024-10-30 23:31:07] iter = 15760, loss = 5.5402
2024-10-30 23:31:12: [2024-10-30 23:31:12] iter = 15770, loss = 3.5799
2024-10-30 23:31:16: [2024-10-30 23:31:16] iter = 15780, loss = 6.0560
2024-10-30 23:31:19: [2024-10-30 23:31:19] iter = 15790, loss = 51.4251
2024-10-30 23:31:23: [2024-10-30 23:31:23] iter = 15800, loss = 4.2448
2024-10-30 23:31:26: [2024-10-30 23:31:26] iter = 15810, loss = 8.5722
2024-10-30 23:31:30: [2024-10-30 23:31:30] iter = 15820, loss = 13.1930
2024-10-30 23:31:33: [2024-10-30 23:31:33] iter = 15830, loss = 44.2601
2024-10-30 23:31:37: [2024-10-30 23:31:37] iter = 15840, loss = 4.0615
2024-10-30 23:31:42: [2024-10-30 23:31:42] iter = 15850, loss = 9.5752
2024-10-30 23:31:45: [2024-10-30 23:31:45] iter = 15860, loss = 15.4577
2024-10-30 23:31:49: [2024-10-30 23:31:49] iter = 15870, loss = 6.2242
2024-10-30 23:31:53: [2024-10-30 23:31:53] iter = 15880, loss = 15.7911
2024-10-30 23:31:56: [2024-10-30 23:31:56] iter = 15890, loss = 28.3209
2024-10-30 23:31:59: [2024-10-30 23:31:59] iter = 15900, loss = 16.1638
2024-10-30 23:32:03: [2024-10-30 23:32:03] iter = 15910, loss = 3.6998
2024-10-30 23:32:06: [2024-10-30 23:32:06] iter = 15920, loss = 9.4114
2024-10-30 23:32:10: [2024-10-30 23:32:10] iter = 15930, loss = 24.2312
2024-10-30 23:32:15: [2024-10-30 23:32:15] iter = 15940, loss = 17.3534
2024-10-30 23:32:19: [2024-10-30 23:32:19] iter = 15950, loss = 18.1627
2024-10-30 23:32:24: [2024-10-30 23:32:24] iter = 15960, loss = 5.4378
2024-10-30 23:32:28: [2024-10-30 23:32:28] iter = 15970, loss = 23.7301
2024-10-30 23:32:32: [2024-10-30 23:32:32] iter = 15980, loss = 13.5835
2024-10-30 23:32:35: [2024-10-30 23:32:35] iter = 15990, loss = 3.9696
2024-10-30 23:32:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-30 23:32:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:32:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59617}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:34:42: Evaluate 5 random ConvNet, ACCmean = 0.4098 ACCstd = 0.0081
-------------------------
2024-10-30 23:34:42: Evaluate 5 random ConvNet, SENmean = 0.3242 SENstd = 0.0016
-------------------------
2024-10-30 23:34:42: Evaluate 5 random ConvNet, SPEmean = 0.9132 SPEstd = 0.0007
-------------------------
2024-10-30 23:34:42: Evaluate 5 random ConvNet, F!mean = 0.2977 F!std = 0.0022
-------------------------
2024-10-30 23:34:42: Evaluate 5 random ConvNet, mean = 0.4098 std = 0.0081
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:34:42: [2024-10-30 23:34:42] iter = 16000, loss = 23.1984
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:34:45: [2024-10-30 23:34:45] iter = 16010, loss = 18.5673
2024-10-30 23:34:49: [2024-10-30 23:34:49] iter = 16020, loss = 11.6950
2024-10-30 23:34:53: [2024-10-30 23:34:53] iter = 16030, loss = 19.2835
2024-10-30 23:34:58: [2024-10-30 23:34:58] iter = 16040, loss = 4.7287
2024-10-30 23:35:01: [2024-10-30 23:35:01] iter = 16050, loss = 43.8456
2024-10-30 23:35:04: [2024-10-30 23:35:04] iter = 16060, loss = 24.6191
2024-10-30 23:35:09: [2024-10-30 23:35:09] iter = 16070, loss = 4.3861
2024-10-30 23:35:12: [2024-10-30 23:35:12] iter = 16080, loss = 7.0980
2024-10-30 23:35:17: [2024-10-30 23:35:17] iter = 16090, loss = 17.5151
2024-10-30 23:35:20: [2024-10-30 23:35:20] iter = 16100, loss = 5.3072
2024-10-30 23:35:23: [2024-10-30 23:35:23] iter = 16110, loss = 12.0863
2024-10-30 23:35:26: [2024-10-30 23:35:26] iter = 16120, loss = 4.7114
2024-10-30 23:35:30: [2024-10-30 23:35:30] iter = 16130, loss = 8.6750
2024-10-30 23:35:33: [2024-10-30 23:35:33] iter = 16140, loss = 18.3028
2024-10-30 23:35:36: [2024-10-30 23:35:36] iter = 16150, loss = 73.1844
2024-10-30 23:35:40: [2024-10-30 23:35:40] iter = 16160, loss = 30.3515
2024-10-30 23:35:43: [2024-10-30 23:35:43] iter = 16170, loss = 15.1310
2024-10-30 23:35:46: [2024-10-30 23:35:46] iter = 16180, loss = 9.0199
2024-10-30 23:35:49: [2024-10-30 23:35:49] iter = 16190, loss = 4.4479
2024-10-30 23:35:53: [2024-10-30 23:35:53] iter = 16200, loss = 48.1829
2024-10-30 23:35:56: [2024-10-30 23:35:56] iter = 16210, loss = 11.7467
2024-10-30 23:36:00: [2024-10-30 23:36:00] iter = 16220, loss = 42.2085
2024-10-30 23:36:05: [2024-10-30 23:36:05] iter = 16230, loss = 6.6687
2024-10-30 23:36:09: [2024-10-30 23:36:09] iter = 16240, loss = 26.8157
2024-10-30 23:36:12: [2024-10-30 23:36:12] iter = 16250, loss = 13.5004
2024-10-30 23:36:15: [2024-10-30 23:36:15] iter = 16260, loss = 19.7784
2024-10-30 23:36:18: [2024-10-30 23:36:18] iter = 16270, loss = 4.2708
2024-10-30 23:36:22: [2024-10-30 23:36:22] iter = 16280, loss = 80.8527
2024-10-30 23:36:26: [2024-10-30 23:36:26] iter = 16290, loss = 11.5781
2024-10-30 23:36:29: [2024-10-30 23:36:29] iter = 16300, loss = 9.0127
2024-10-30 23:36:32: [2024-10-30 23:36:32] iter = 16310, loss = 12.7662
2024-10-30 23:36:35: [2024-10-30 23:36:35] iter = 16320, loss = 6.8212
2024-10-30 23:36:38: [2024-10-30 23:36:38] iter = 16330, loss = 51.8343
2024-10-30 23:36:42: [2024-10-30 23:36:42] iter = 16340, loss = 3.7984
2024-10-30 23:36:46: [2024-10-30 23:36:46] iter = 16350, loss = 8.2680
2024-10-30 23:36:49: [2024-10-30 23:36:49] iter = 16360, loss = 10.1368
2024-10-30 23:36:52: [2024-10-30 23:36:52] iter = 16370, loss = 13.7871
2024-10-30 23:36:56: [2024-10-30 23:36:56] iter = 16380, loss = 33.7200
2024-10-30 23:37:00: [2024-10-30 23:37:00] iter = 16390, loss = 5.7772
2024-10-30 23:37:04: [2024-10-30 23:37:04] iter = 16400, loss = 4.6175
2024-10-30 23:37:08: [2024-10-30 23:37:08] iter = 16410, loss = 16.3118
2024-10-30 23:37:11: [2024-10-30 23:37:11] iter = 16420, loss = 16.1296
2024-10-30 23:37:14: [2024-10-30 23:37:14] iter = 16430, loss = 60.1630
2024-10-30 23:37:18: [2024-10-30 23:37:18] iter = 16440, loss = 3.7116
2024-10-30 23:37:22: [2024-10-30 23:37:22] iter = 16450, loss = 4.7073
2024-10-30 23:37:25: [2024-10-30 23:37:25] iter = 16460, loss = 20.9555
2024-10-30 23:37:27: [2024-10-30 23:37:27] iter = 16470, loss = 5.2304
2024-10-30 23:37:31: [2024-10-30 23:37:31] iter = 16480, loss = 19.4736
2024-10-30 23:37:34: [2024-10-30 23:37:34] iter = 16490, loss = 11.8797
2024-10-30 23:37:38: [2024-10-30 23:37:38] iter = 16500, loss = 4.5685
2024-10-30 23:37:41: [2024-10-30 23:37:41] iter = 16510, loss = 4.5712
2024-10-30 23:37:44: [2024-10-30 23:37:44] iter = 16520, loss = 19.6574
2024-10-30 23:37:48: [2024-10-30 23:37:48] iter = 16530, loss = 6.5876
2024-10-30 23:37:50: [2024-10-30 23:37:50] iter = 16540, loss = 15.2533
2024-10-30 23:37:53: [2024-10-30 23:37:53] iter = 16550, loss = 66.1597
2024-10-30 23:37:57: [2024-10-30 23:37:57] iter = 16560, loss = 61.2092
2024-10-30 23:37:59: [2024-10-30 23:37:59] iter = 16570, loss = 12.6639
2024-10-30 23:38:02: [2024-10-30 23:38:02] iter = 16580, loss = 4.5198
2024-10-30 23:38:06: [2024-10-30 23:38:06] iter = 16590, loss = 36.0732
2024-10-30 23:38:09: [2024-10-30 23:38:09] iter = 16600, loss = 26.3577
2024-10-30 23:38:13: [2024-10-30 23:38:13] iter = 16610, loss = 25.3256
2024-10-30 23:38:17: [2024-10-30 23:38:17] iter = 16620, loss = 8.0871
2024-10-30 23:38:20: [2024-10-30 23:38:20] iter = 16630, loss = 6.0397
2024-10-30 23:38:23: [2024-10-30 23:38:23] iter = 16640, loss = 9.3269
2024-10-30 23:38:26: [2024-10-30 23:38:26] iter = 16650, loss = 7.3734
2024-10-30 23:38:30: [2024-10-30 23:38:30] iter = 16660, loss = 7.1858
2024-10-30 23:38:33: [2024-10-30 23:38:33] iter = 16670, loss = 8.9654
2024-10-30 23:38:36: [2024-10-30 23:38:36] iter = 16680, loss = 43.0641
2024-10-30 23:38:39: [2024-10-30 23:38:39] iter = 16690, loss = 20.2949
2024-10-30 23:38:42: [2024-10-30 23:38:42] iter = 16700, loss = 40.0799
2024-10-30 23:38:45: [2024-10-30 23:38:45] iter = 16710, loss = 9.7692
2024-10-30 23:38:48: [2024-10-30 23:38:48] iter = 16720, loss = 4.9119
2024-10-30 23:38:51: [2024-10-30 23:38:51] iter = 16730, loss = 26.7173
2024-10-30 23:38:54: [2024-10-30 23:38:54] iter = 16740, loss = 10.5986
2024-10-30 23:38:56: [2024-10-30 23:38:56] iter = 16750, loss = 5.6963
2024-10-30 23:38:59: [2024-10-30 23:38:59] iter = 16760, loss = 38.4209
2024-10-30 23:39:02: [2024-10-30 23:39:02] iter = 16770, loss = 7.9344
2024-10-30 23:39:05: [2024-10-30 23:39:05] iter = 16780, loss = 3.5299
2024-10-30 23:39:08: [2024-10-30 23:39:08] iter = 16790, loss = 17.8423
2024-10-30 23:39:11: [2024-10-30 23:39:11] iter = 16800, loss = 3.3960
2024-10-30 23:39:14: [2024-10-30 23:39:14] iter = 16810, loss = 4.5322
2024-10-30 23:39:18: [2024-10-30 23:39:18] iter = 16820, loss = 10.1615
2024-10-30 23:39:21: [2024-10-30 23:39:21] iter = 16830, loss = 75.5115
2024-10-30 23:39:24: [2024-10-30 23:39:24] iter = 16840, loss = 6.3595
2024-10-30 23:39:29: [2024-10-30 23:39:29] iter = 16850, loss = 7.8779
2024-10-30 23:39:31: [2024-10-30 23:39:31] iter = 16860, loss = 18.0196
2024-10-30 23:39:34: [2024-10-30 23:39:34] iter = 16870, loss = 4.0664
2024-10-30 23:39:37: [2024-10-30 23:39:37] iter = 16880, loss = 4.4062
2024-10-30 23:39:40: [2024-10-30 23:39:40] iter = 16890, loss = 4.7829
2024-10-30 23:39:43: [2024-10-30 23:39:43] iter = 16900, loss = 6.5271
2024-10-30 23:39:47: [2024-10-30 23:39:47] iter = 16910, loss = 9.4272
2024-10-30 23:39:51: [2024-10-30 23:39:51] iter = 16920, loss = 59.8307
2024-10-30 23:39:53: [2024-10-30 23:39:53] iter = 16930, loss = 7.2849
2024-10-30 23:39:57: [2024-10-30 23:39:57] iter = 16940, loss = 18.8859
2024-10-30 23:40:01: [2024-10-30 23:40:01] iter = 16950, loss = 10.9444
2024-10-30 23:40:04: [2024-10-30 23:40:04] iter = 16960, loss = 97.5717
2024-10-30 23:40:07: [2024-10-30 23:40:07] iter = 16970, loss = 5.9906
2024-10-30 23:40:11: [2024-10-30 23:40:11] iter = 16980, loss = 5.8593
2024-10-30 23:40:15: [2024-10-30 23:40:15] iter = 16990, loss = 60.0272
2024-10-30 23:40:18: [2024-10-30 23:40:18] iter = 17000, loss = 17.3705
2024-10-30 23:40:21: [2024-10-30 23:40:21] iter = 17010, loss = 12.6270
2024-10-30 23:40:23: [2024-10-30 23:40:23] iter = 17020, loss = 5.0213
2024-10-30 23:40:26: [2024-10-30 23:40:26] iter = 17030, loss = 14.4631
2024-10-30 23:40:30: [2024-10-30 23:40:30] iter = 17040, loss = 6.9329
2024-10-30 23:40:33: [2024-10-30 23:40:33] iter = 17050, loss = 27.2201
2024-10-30 23:40:36: [2024-10-30 23:40:36] iter = 17060, loss = 4.7960
2024-10-30 23:40:40: [2024-10-30 23:40:40] iter = 17070, loss = 70.6691
2024-10-30 23:40:43: [2024-10-30 23:40:43] iter = 17080, loss = 33.6865
2024-10-30 23:40:46: [2024-10-30 23:40:46] iter = 17090, loss = 39.6020
2024-10-30 23:40:50: [2024-10-30 23:40:50] iter = 17100, loss = 79.1103
2024-10-30 23:40:53: [2024-10-30 23:40:53] iter = 17110, loss = 13.3661
2024-10-30 23:40:57: [2024-10-30 23:40:57] iter = 17120, loss = 9.0724
2024-10-30 23:41:00: [2024-10-30 23:41:00] iter = 17130, loss = 5.0129
2024-10-30 23:41:03: [2024-10-30 23:41:03] iter = 17140, loss = 12.4834
2024-10-30 23:41:07: [2024-10-30 23:41:07] iter = 17150, loss = 46.5868
2024-10-30 23:41:10: [2024-10-30 23:41:10] iter = 17160, loss = 6.0001
2024-10-30 23:41:14: [2024-10-30 23:41:14] iter = 17170, loss = 7.0351
2024-10-30 23:41:17: [2024-10-30 23:41:17] iter = 17180, loss = 13.5017
2024-10-30 23:41:20: [2024-10-30 23:41:20] iter = 17190, loss = 5.7974
2024-10-30 23:41:23: [2024-10-30 23:41:23] iter = 17200, loss = 28.9928
2024-10-30 23:41:27: [2024-10-30 23:41:27] iter = 17210, loss = 28.3310
2024-10-30 23:41:31: [2024-10-30 23:41:31] iter = 17220, loss = 26.8538
2024-10-30 23:41:34: [2024-10-30 23:41:34] iter = 17230, loss = 7.0524
2024-10-30 23:41:37: [2024-10-30 23:41:37] iter = 17240, loss = 5.4802
2024-10-30 23:41:41: [2024-10-30 23:41:41] iter = 17250, loss = 59.3315
2024-10-30 23:41:44: [2024-10-30 23:41:44] iter = 17260, loss = 18.5735
2024-10-30 23:41:46: [2024-10-30 23:41:46] iter = 17270, loss = 31.4717
2024-10-30 23:41:48: [2024-10-30 23:41:48] iter = 17280, loss = 15.8874
2024-10-30 23:41:53: [2024-10-30 23:41:53] iter = 17290, loss = 26.7719
2024-10-30 23:41:56: [2024-10-30 23:41:56] iter = 17300, loss = 10.7112
2024-10-30 23:41:59: [2024-10-30 23:41:59] iter = 17310, loss = 15.0829
2024-10-30 23:42:02: [2024-10-30 23:42:02] iter = 17320, loss = 25.1172
2024-10-30 23:42:06: [2024-10-30 23:42:06] iter = 17330, loss = 15.1051
2024-10-30 23:42:10: [2024-10-30 23:42:10] iter = 17340, loss = 43.9169
2024-10-30 23:42:14: [2024-10-30 23:42:14] iter = 17350, loss = 16.9090
2024-10-30 23:42:18: [2024-10-30 23:42:18] iter = 17360, loss = 20.2337
2024-10-30 23:42:21: [2024-10-30 23:42:21] iter = 17370, loss = 4.0670
2024-10-30 23:42:24: [2024-10-30 23:42:24] iter = 17380, loss = 13.8917
2024-10-30 23:42:28: [2024-10-30 23:42:28] iter = 17390, loss = 23.8535
2024-10-30 23:42:32: [2024-10-30 23:42:32] iter = 17400, loss = 29.8228
2024-10-30 23:42:35: [2024-10-30 23:42:35] iter = 17410, loss = 5.5222
2024-10-30 23:42:39: [2024-10-30 23:42:39] iter = 17420, loss = 47.6012
2024-10-30 23:42:41: [2024-10-30 23:42:41] iter = 17430, loss = 4.9939
2024-10-30 23:42:45: [2024-10-30 23:42:45] iter = 17440, loss = 11.1674
2024-10-30 23:42:48: [2024-10-30 23:42:48] iter = 17450, loss = 4.9286
2024-10-30 23:42:51: [2024-10-30 23:42:51] iter = 17460, loss = 13.8340
2024-10-30 23:42:54: [2024-10-30 23:42:54] iter = 17470, loss = 6.0917
2024-10-30 23:42:58: [2024-10-30 23:42:58] iter = 17480, loss = 5.4400
2024-10-30 23:43:01: [2024-10-30 23:43:01] iter = 17490, loss = 10.8741
2024-10-30 23:43:04: [2024-10-30 23:43:04] iter = 17500, loss = 50.2891
2024-10-30 23:43:06: [2024-10-30 23:43:06] iter = 17510, loss = 9.1586
2024-10-30 23:43:09: [2024-10-30 23:43:09] iter = 17520, loss = 6.1572
2024-10-30 23:43:11: [2024-10-30 23:43:11] iter = 17530, loss = 23.7547
2024-10-30 23:43:15: [2024-10-30 23:43:15] iter = 17540, loss = 24.2434
2024-10-30 23:43:19: [2024-10-30 23:43:19] iter = 17550, loss = 9.8105
2024-10-30 23:43:22: [2024-10-30 23:43:22] iter = 17560, loss = 6.5898
2024-10-30 23:43:26: [2024-10-30 23:43:26] iter = 17570, loss = 13.9293
2024-10-30 23:43:29: [2024-10-30 23:43:29] iter = 17580, loss = 6.5518
2024-10-30 23:43:32: [2024-10-30 23:43:32] iter = 17590, loss = 5.8104
2024-10-30 23:43:35: [2024-10-30 23:43:35] iter = 17600, loss = 3.9422
2024-10-30 23:43:38: [2024-10-30 23:43:38] iter = 17610, loss = 17.8174
2024-10-30 23:43:40: [2024-10-30 23:43:40] iter = 17620, loss = 5.7472
2024-10-30 23:43:43: [2024-10-30 23:43:43] iter = 17630, loss = 11.8504
2024-10-30 23:43:47: [2024-10-30 23:43:47] iter = 17640, loss = 14.9621
2024-10-30 23:43:49: [2024-10-30 23:43:49] iter = 17650, loss = 25.7013
2024-10-30 23:43:53: [2024-10-30 23:43:53] iter = 17660, loss = 18.9181
2024-10-30 23:43:57: [2024-10-30 23:43:57] iter = 17670, loss = 23.5554
2024-10-30 23:44:01: [2024-10-30 23:44:01] iter = 17680, loss = 10.7922
2024-10-30 23:44:04: [2024-10-30 23:44:04] iter = 17690, loss = 30.6545
2024-10-30 23:44:07: [2024-10-30 23:44:07] iter = 17700, loss = 22.2499
2024-10-30 23:44:11: [2024-10-30 23:44:11] iter = 17710, loss = 5.1960
2024-10-30 23:44:13: [2024-10-30 23:44:13] iter = 17720, loss = 12.4092
2024-10-30 23:44:16: [2024-10-30 23:44:16] iter = 17730, loss = 14.5435
2024-10-30 23:44:19: [2024-10-30 23:44:19] iter = 17740, loss = 26.6903
2024-10-30 23:44:22: [2024-10-30 23:44:22] iter = 17750, loss = 10.7543
2024-10-30 23:44:25: [2024-10-30 23:44:25] iter = 17760, loss = 12.5153
2024-10-30 23:44:29: [2024-10-30 23:44:29] iter = 17770, loss = 19.0757
2024-10-30 23:44:33: [2024-10-30 23:44:33] iter = 17780, loss = 11.2936
2024-10-30 23:44:37: [2024-10-30 23:44:37] iter = 17790, loss = 30.3045
2024-10-30 23:44:39: [2024-10-30 23:44:39] iter = 17800, loss = 10.8916
2024-10-30 23:44:41: [2024-10-30 23:44:41] iter = 17810, loss = 14.6959
2024-10-30 23:44:46: [2024-10-30 23:44:46] iter = 17820, loss = 35.4490
2024-10-30 23:44:49: [2024-10-30 23:44:49] iter = 17830, loss = 16.3028
2024-10-30 23:44:53: [2024-10-30 23:44:53] iter = 17840, loss = 30.8421
2024-10-30 23:44:56: [2024-10-30 23:44:56] iter = 17850, loss = 3.0837
2024-10-30 23:45:00: [2024-10-30 23:45:00] iter = 17860, loss = 8.9550
2024-10-30 23:45:03: [2024-10-30 23:45:03] iter = 17870, loss = 61.2460
2024-10-30 23:45:06: [2024-10-30 23:45:06] iter = 17880, loss = 5.4443
2024-10-30 23:45:09: [2024-10-30 23:45:09] iter = 17890, loss = 5.0416
2024-10-30 23:45:13: [2024-10-30 23:45:13] iter = 17900, loss = 5.3577
2024-10-30 23:45:17: [2024-10-30 23:45:17] iter = 17910, loss = 9.2973
2024-10-30 23:45:20: [2024-10-30 23:45:20] iter = 17920, loss = 11.8490
2024-10-30 23:45:24: [2024-10-30 23:45:24] iter = 17930, loss = 49.6522
2024-10-30 23:45:27: [2024-10-30 23:45:27] iter = 17940, loss = 3.7085
2024-10-30 23:45:31: [2024-10-30 23:45:31] iter = 17950, loss = 33.7504
2024-10-30 23:45:36: [2024-10-30 23:45:36] iter = 17960, loss = 12.6576
2024-10-30 23:45:40: [2024-10-30 23:45:40] iter = 17970, loss = 49.7755
2024-10-30 23:45:43: [2024-10-30 23:45:43] iter = 17980, loss = 17.1262
2024-10-30 23:45:46: [2024-10-30 23:45:46] iter = 17990, loss = 6.1488
2024-10-30 23:45:50: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-30 23:45:50: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:45:50: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 50238}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:47:46: Evaluate 5 random ConvNet, ACCmean = 0.2776 ACCstd = 0.0099
-------------------------
2024-10-30 23:47:46: Evaluate 5 random ConvNet, SENmean = 0.2784 SENstd = 0.0037
-------------------------
2024-10-30 23:47:46: Evaluate 5 random ConvNet, SPEmean = 0.8992 SPEstd = 0.0010
-------------------------
2024-10-30 23:47:46: Evaluate 5 random ConvNet, F!mean = 0.2288 F!std = 0.0068
-------------------------
2024-10-30 23:47:46: Evaluate 5 random ConvNet, mean = 0.2776 std = 0.0099
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-30 23:47:46: [2024-10-30 23:47:46] iter = 18000, loss = 22.8928
2024-10-30 23:47:49: [2024-10-30 23:47:49] iter = 18010, loss = 49.5100
2024-10-30 23:47:52: [2024-10-30 23:47:52] iter = 18020, loss = 24.4860
2024-10-30 23:47:55: [2024-10-30 23:47:55] iter = 18030, loss = 8.9722
2024-10-30 23:47:59: [2024-10-30 23:47:59] iter = 18040, loss = 47.6324
2024-10-30 23:48:03: [2024-10-30 23:48:03] iter = 18050, loss = 9.2708
2024-10-30 23:48:06: [2024-10-30 23:48:06] iter = 18060, loss = 47.7500
2024-10-30 23:48:09: [2024-10-30 23:48:09] iter = 18070, loss = 20.0797
2024-10-30 23:48:13: [2024-10-30 23:48:13] iter = 18080, loss = 40.1722
2024-10-30 23:48:17: [2024-10-30 23:48:17] iter = 18090, loss = 7.8401
2024-10-30 23:48:19: [2024-10-30 23:48:19] iter = 18100, loss = 3.6698
2024-10-30 23:48:21: [2024-10-30 23:48:21] iter = 18110, loss = 24.5616
2024-10-30 23:48:24: [2024-10-30 23:48:24] iter = 18120, loss = 17.1781
2024-10-30 23:48:27: [2024-10-30 23:48:27] iter = 18130, loss = 5.7491
2024-10-30 23:48:30: [2024-10-30 23:48:30] iter = 18140, loss = 31.3774
2024-10-30 23:48:33: [2024-10-30 23:48:33] iter = 18150, loss = 35.0236
2024-10-30 23:48:38: [2024-10-30 23:48:38] iter = 18160, loss = 10.3098
2024-10-30 23:48:41: [2024-10-30 23:48:41] iter = 18170, loss = 20.1251
2024-10-30 23:48:44: [2024-10-30 23:48:44] iter = 18180, loss = 8.6404
2024-10-30 23:48:48: [2024-10-30 23:48:48] iter = 18190, loss = 49.6491
2024-10-30 23:48:51: [2024-10-30 23:48:51] iter = 18200, loss = 54.6319
2024-10-30 23:48:55: [2024-10-30 23:48:55] iter = 18210, loss = 7.0195
2024-10-30 23:48:58: [2024-10-30 23:48:58] iter = 18220, loss = 8.7362
2024-10-30 23:49:01: [2024-10-30 23:49:01] iter = 18230, loss = 44.4068
2024-10-30 23:49:05: [2024-10-30 23:49:05] iter = 18240, loss = 4.5901
2024-10-30 23:49:08: [2024-10-30 23:49:08] iter = 18250, loss = 4.3140
2024-10-30 23:49:12: [2024-10-30 23:49:12] iter = 18260, loss = 11.6174
2024-10-30 23:49:15: [2024-10-30 23:49:15] iter = 18270, loss = 12.2395
2024-10-30 23:49:19: [2024-10-30 23:49:19] iter = 18280, loss = 55.4195
2024-10-30 23:49:23: [2024-10-30 23:49:23] iter = 18290, loss = 21.4515
2024-10-30 23:49:26: [2024-10-30 23:49:26] iter = 18300, loss = 5.5490
2024-10-30 23:49:29: [2024-10-30 23:49:29] iter = 18310, loss = 19.5971
2024-10-30 23:49:32: [2024-10-30 23:49:32] iter = 18320, loss = 12.5250
2024-10-30 23:49:35: [2024-10-30 23:49:35] iter = 18330, loss = 4.5005
2024-10-30 23:49:38: [2024-10-30 23:49:38] iter = 18340, loss = 4.7337
2024-10-30 23:49:42: [2024-10-30 23:49:42] iter = 18350, loss = 3.7279
2024-10-30 23:49:44: [2024-10-30 23:49:44] iter = 18360, loss = 8.3890
2024-10-30 23:49:48: [2024-10-30 23:49:48] iter = 18370, loss = 3.3631
2024-10-30 23:49:50: [2024-10-30 23:49:50] iter = 18380, loss = 17.8305
2024-10-30 23:49:53: [2024-10-30 23:49:53] iter = 18390, loss = 8.1402
2024-10-30 23:49:57: [2024-10-30 23:49:57] iter = 18400, loss = 3.6621
2024-10-30 23:50:00: [2024-10-30 23:50:00] iter = 18410, loss = 3.2566
2024-10-30 23:50:04: [2024-10-30 23:50:04] iter = 18420, loss = 22.3476
2024-10-30 23:50:08: [2024-10-30 23:50:08] iter = 18430, loss = 3.9057
2024-10-30 23:50:11: [2024-10-30 23:50:11] iter = 18440, loss = 24.5047
2024-10-30 23:50:14: [2024-10-30 23:50:14] iter = 18450, loss = 31.5712
2024-10-30 23:50:17: [2024-10-30 23:50:17] iter = 18460, loss = 23.5523
2024-10-30 23:50:20: [2024-10-30 23:50:20] iter = 18470, loss = 20.1242
2024-10-30 23:50:23: [2024-10-30 23:50:23] iter = 18480, loss = 17.9061
2024-10-30 23:50:26: [2024-10-30 23:50:26] iter = 18490, loss = 63.6124
2024-10-30 23:50:29: [2024-10-30 23:50:29] iter = 18500, loss = 12.8450
2024-10-30 23:50:32: [2024-10-30 23:50:32] iter = 18510, loss = 7.1825
2024-10-30 23:50:35: [2024-10-30 23:50:35] iter = 18520, loss = 49.9457
2024-10-30 23:50:38: [2024-10-30 23:50:38] iter = 18530, loss = 6.1438
2024-10-30 23:50:41: [2024-10-30 23:50:41] iter = 18540, loss = 23.5223
2024-10-30 23:50:44: [2024-10-30 23:50:44] iter = 18550, loss = 4.0522
2024-10-30 23:50:47: [2024-10-30 23:50:47] iter = 18560, loss = 8.2038
2024-10-30 23:50:51: [2024-10-30 23:50:51] iter = 18570, loss = 38.0144
2024-10-30 23:50:54: [2024-10-30 23:50:54] iter = 18580, loss = 36.5619
2024-10-30 23:50:58: [2024-10-30 23:50:58] iter = 18590, loss = 4.4349
2024-10-30 23:51:01: [2024-10-30 23:51:01] iter = 18600, loss = 77.1351
2024-10-30 23:51:05: [2024-10-30 23:51:05] iter = 18610, loss = 8.6389
2024-10-30 23:51:08: [2024-10-30 23:51:08] iter = 18620, loss = 8.1204
2024-10-30 23:51:12: [2024-10-30 23:51:12] iter = 18630, loss = 3.6942
2024-10-30 23:51:17: [2024-10-30 23:51:17] iter = 18640, loss = 13.6183
2024-10-30 23:51:20: [2024-10-30 23:51:20] iter = 18650, loss = 11.3304
2024-10-30 23:51:24: [2024-10-30 23:51:24] iter = 18660, loss = 20.6169
2024-10-30 23:51:28: [2024-10-30 23:51:28] iter = 18670, loss = 4.4281
2024-10-30 23:51:31: [2024-10-30 23:51:31] iter = 18680, loss = 76.4535
2024-10-30 23:51:35: [2024-10-30 23:51:35] iter = 18690, loss = 10.3542
2024-10-30 23:51:39: [2024-10-30 23:51:39] iter = 18700, loss = 59.5016
2024-10-30 23:51:41: [2024-10-30 23:51:41] iter = 18710, loss = 25.7066
2024-10-30 23:51:44: [2024-10-30 23:51:44] iter = 18720, loss = 59.4968
2024-10-30 23:51:47: [2024-10-30 23:51:47] iter = 18730, loss = 7.4545
2024-10-30 23:51:50: [2024-10-30 23:51:50] iter = 18740, loss = 17.4002
2024-10-30 23:51:52: [2024-10-30 23:51:52] iter = 18750, loss = 5.2593
2024-10-30 23:51:55: [2024-10-30 23:51:55] iter = 18760, loss = 49.0083
2024-10-30 23:51:58: [2024-10-30 23:51:58] iter = 18770, loss = 18.0570
2024-10-30 23:52:01: [2024-10-30 23:52:01] iter = 18780, loss = 30.5241
2024-10-30 23:52:04: [2024-10-30 23:52:04] iter = 18790, loss = 8.5323
2024-10-30 23:52:08: [2024-10-30 23:52:08] iter = 18800, loss = 45.6355
2024-10-30 23:52:11: [2024-10-30 23:52:11] iter = 18810, loss = 8.2262
2024-10-30 23:52:13: [2024-10-30 23:52:13] iter = 18820, loss = 4.0564
2024-10-30 23:52:16: [2024-10-30 23:52:16] iter = 18830, loss = 17.4261
2024-10-30 23:52:20: [2024-10-30 23:52:20] iter = 18840, loss = 8.5006
2024-10-30 23:52:24: [2024-10-30 23:52:24] iter = 18850, loss = 3.4742
2024-10-30 23:52:26: [2024-10-30 23:52:26] iter = 18860, loss = 52.1057
2024-10-30 23:52:28: [2024-10-30 23:52:28] iter = 18870, loss = 4.4759
2024-10-30 23:52:31: [2024-10-30 23:52:31] iter = 18880, loss = 4.4401
2024-10-30 23:52:34: [2024-10-30 23:52:34] iter = 18890, loss = 42.9999
2024-10-30 23:52:39: [2024-10-30 23:52:39] iter = 18900, loss = 6.6469
2024-10-30 23:52:42: [2024-10-30 23:52:42] iter = 18910, loss = 42.2298
2024-10-30 23:52:46: [2024-10-30 23:52:46] iter = 18920, loss = 6.4341
2024-10-30 23:52:48: [2024-10-30 23:52:48] iter = 18930, loss = 12.0379
2024-10-30 23:52:53: [2024-10-30 23:52:53] iter = 18940, loss = 9.5550
2024-10-30 23:52:56: [2024-10-30 23:52:56] iter = 18950, loss = 38.1802
2024-10-30 23:52:58: [2024-10-30 23:52:58] iter = 18960, loss = 40.4759
2024-10-30 23:53:00: [2024-10-30 23:53:00] iter = 18970, loss = 109.3853
2024-10-30 23:53:03: [2024-10-30 23:53:03] iter = 18980, loss = 59.6276
2024-10-30 23:53:06: [2024-10-30 23:53:06] iter = 18990, loss = 15.0412
2024-10-30 23:53:09: [2024-10-30 23:53:09] iter = 19000, loss = 9.6672
2024-10-30 23:53:13: [2024-10-30 23:53:13] iter = 19010, loss = 6.3539
2024-10-30 23:53:17: [2024-10-30 23:53:17] iter = 19020, loss = 4.5331
2024-10-30 23:53:20: [2024-10-30 23:53:20] iter = 19030, loss = 14.0554
2024-10-30 23:53:23: [2024-10-30 23:53:23] iter = 19040, loss = 6.0376
2024-10-30 23:53:27: [2024-10-30 23:53:27] iter = 19050, loss = 45.6019
2024-10-30 23:53:30: [2024-10-30 23:53:30] iter = 19060, loss = 8.4308
2024-10-30 23:53:33: [2024-10-30 23:53:33] iter = 19070, loss = 5.7969
2024-10-30 23:53:37: [2024-10-30 23:53:37] iter = 19080, loss = 49.5981
2024-10-30 23:53:41: [2024-10-30 23:53:41] iter = 19090, loss = 29.8286
2024-10-30 23:53:45: [2024-10-30 23:53:45] iter = 19100, loss = 79.1860
2024-10-30 23:53:48: [2024-10-30 23:53:48] iter = 19110, loss = 9.0542
2024-10-30 23:53:51: [2024-10-30 23:53:51] iter = 19120, loss = 5.2417
2024-10-30 23:53:54: [2024-10-30 23:53:54] iter = 19130, loss = 57.0244
2024-10-30 23:53:59: [2024-10-30 23:53:59] iter = 19140, loss = 34.8627
2024-10-30 23:54:03: [2024-10-30 23:54:03] iter = 19150, loss = 44.1243
2024-10-30 23:54:07: [2024-10-30 23:54:07] iter = 19160, loss = 46.6641
2024-10-30 23:54:10: [2024-10-30 23:54:10] iter = 19170, loss = 4.6521
2024-10-30 23:54:13: [2024-10-30 23:54:13] iter = 19180, loss = 4.1212
2024-10-30 23:54:17: [2024-10-30 23:54:17] iter = 19190, loss = 91.3636
2024-10-30 23:54:20: [2024-10-30 23:54:20] iter = 19200, loss = 53.6290
2024-10-30 23:54:24: [2024-10-30 23:54:24] iter = 19210, loss = 4.0561
2024-10-30 23:54:28: [2024-10-30 23:54:28] iter = 19220, loss = 11.3216
2024-10-30 23:54:32: [2024-10-30 23:54:32] iter = 19230, loss = 29.7256
2024-10-30 23:54:35: [2024-10-30 23:54:35] iter = 19240, loss = 49.2382
2024-10-30 23:54:38: [2024-10-30 23:54:38] iter = 19250, loss = 8.1242
2024-10-30 23:54:42: [2024-10-30 23:54:42] iter = 19260, loss = 30.2864
2024-10-30 23:54:45: [2024-10-30 23:54:45] iter = 19270, loss = 6.7467
2024-10-30 23:54:48: [2024-10-30 23:54:48] iter = 19280, loss = 5.6603
2024-10-30 23:54:51: [2024-10-30 23:54:51] iter = 19290, loss = 61.1932
2024-10-30 23:54:55: [2024-10-30 23:54:55] iter = 19300, loss = 13.6774
2024-10-30 23:54:58: [2024-10-30 23:54:58] iter = 19310, loss = 32.2612
2024-10-30 23:55:01: [2024-10-30 23:55:01] iter = 19320, loss = 4.2477
2024-10-30 23:55:05: [2024-10-30 23:55:05] iter = 19330, loss = 66.7751
2024-10-30 23:55:08: [2024-10-30 23:55:08] iter = 19340, loss = 21.3363
2024-10-30 23:55:12: [2024-10-30 23:55:12] iter = 19350, loss = 4.5173
2024-10-30 23:55:15: [2024-10-30 23:55:15] iter = 19360, loss = 4.5746
2024-10-30 23:55:17: [2024-10-30 23:55:17] iter = 19370, loss = 30.3460
2024-10-30 23:55:21: [2024-10-30 23:55:21] iter = 19380, loss = 22.0065
2024-10-30 23:55:24: [2024-10-30 23:55:24] iter = 19390, loss = 41.3901
2024-10-30 23:55:28: [2024-10-30 23:55:28] iter = 19400, loss = 4.8688
2024-10-30 23:55:31: [2024-10-30 23:55:31] iter = 19410, loss = 49.0200
2024-10-30 23:55:35: [2024-10-30 23:55:35] iter = 19420, loss = 5.6630
2024-10-30 23:55:39: [2024-10-30 23:55:39] iter = 19430, loss = 75.5176
2024-10-30 23:55:42: [2024-10-30 23:55:42] iter = 19440, loss = 6.4991
2024-10-30 23:55:45: [2024-10-30 23:55:45] iter = 19450, loss = 4.4794
2024-10-30 23:55:49: [2024-10-30 23:55:49] iter = 19460, loss = 4.4962
2024-10-30 23:55:53: [2024-10-30 23:55:53] iter = 19470, loss = 40.2752
2024-10-30 23:55:57: [2024-10-30 23:55:57] iter = 19480, loss = 7.2048
2024-10-30 23:56:00: [2024-10-30 23:56:00] iter = 19490, loss = 28.4274
2024-10-30 23:56:04: [2024-10-30 23:56:04] iter = 19500, loss = 12.0222
2024-10-30 23:56:08: [2024-10-30 23:56:08] iter = 19510, loss = 22.7924
2024-10-30 23:56:11: [2024-10-30 23:56:11] iter = 19520, loss = 4.5765
2024-10-30 23:56:14: [2024-10-30 23:56:14] iter = 19530, loss = 4.6365
2024-10-30 23:56:17: [2024-10-30 23:56:17] iter = 19540, loss = 18.2444
2024-10-30 23:56:21: [2024-10-30 23:56:21] iter = 19550, loss = 6.0903
2024-10-30 23:56:23: [2024-10-30 23:56:23] iter = 19560, loss = 3.7410
2024-10-30 23:56:26: [2024-10-30 23:56:26] iter = 19570, loss = 3.7253
2024-10-30 23:56:30: [2024-10-30 23:56:30] iter = 19580, loss = 3.8094
2024-10-30 23:56:34: [2024-10-30 23:56:34] iter = 19590, loss = 17.0627
2024-10-30 23:56:37: [2024-10-30 23:56:37] iter = 19600, loss = 36.1968
2024-10-30 23:56:41: [2024-10-30 23:56:41] iter = 19610, loss = 9.9349
2024-10-30 23:56:45: [2024-10-30 23:56:45] iter = 19620, loss = 4.8333
2024-10-30 23:56:49: [2024-10-30 23:56:49] iter = 19630, loss = 41.6623
2024-10-30 23:56:52: [2024-10-30 23:56:52] iter = 19640, loss = 5.2822
2024-10-30 23:56:55: [2024-10-30 23:56:55] iter = 19650, loss = 111.4445
2024-10-30 23:56:59: [2024-10-30 23:56:59] iter = 19660, loss = 4.5382
2024-10-30 23:57:03: [2024-10-30 23:57:03] iter = 19670, loss = 5.9653
2024-10-30 23:57:07: [2024-10-30 23:57:07] iter = 19680, loss = 14.4013
2024-10-30 23:57:10: [2024-10-30 23:57:10] iter = 19690, loss = 5.6954
2024-10-30 23:57:14: [2024-10-30 23:57:14] iter = 19700, loss = 36.1269
2024-10-30 23:57:18: [2024-10-30 23:57:18] iter = 19710, loss = 19.1280
2024-10-30 23:57:22: [2024-10-30 23:57:22] iter = 19720, loss = 4.0104
2024-10-30 23:57:26: [2024-10-30 23:57:26] iter = 19730, loss = 6.2596
2024-10-30 23:57:29: [2024-10-30 23:57:29] iter = 19740, loss = 18.8890
2024-10-30 23:57:33: [2024-10-30 23:57:33] iter = 19750, loss = 18.9697
2024-10-30 23:57:36: [2024-10-30 23:57:36] iter = 19760, loss = 6.3910
2024-10-30 23:57:39: [2024-10-30 23:57:39] iter = 19770, loss = 13.8516
2024-10-30 23:57:42: [2024-10-30 23:57:42] iter = 19780, loss = 6.1097
2024-10-30 23:57:46: [2024-10-30 23:57:46] iter = 19790, loss = 7.5088
2024-10-30 23:57:49: [2024-10-30 23:57:49] iter = 19800, loss = 18.3187
2024-10-30 23:57:52: [2024-10-30 23:57:52] iter = 19810, loss = 5.6630
2024-10-30 23:57:56: [2024-10-30 23:57:56] iter = 19820, loss = 5.0539
2024-10-30 23:57:59: [2024-10-30 23:57:59] iter = 19830, loss = 22.7934
2024-10-30 23:58:02: [2024-10-30 23:58:02] iter = 19840, loss = 4.9797
2024-10-30 23:58:05: [2024-10-30 23:58:05] iter = 19850, loss = 11.1190
2024-10-30 23:58:09: [2024-10-30 23:58:09] iter = 19860, loss = 37.8262
2024-10-30 23:58:12: [2024-10-30 23:58:12] iter = 19870, loss = 43.4341
2024-10-30 23:58:16: [2024-10-30 23:58:16] iter = 19880, loss = 9.8890
2024-10-30 23:58:19: [2024-10-30 23:58:19] iter = 19890, loss = 59.4942
2024-10-30 23:58:22: [2024-10-30 23:58:22] iter = 19900, loss = 4.3993
2024-10-30 23:58:26: [2024-10-30 23:58:26] iter = 19910, loss = 18.7416
2024-10-30 23:58:30: [2024-10-30 23:58:30] iter = 19920, loss = 7.8708
2024-10-30 23:58:34: [2024-10-30 23:58:34] iter = 19930, loss = 42.4386
2024-10-30 23:58:37: [2024-10-30 23:58:37] iter = 19940, loss = 4.1791
2024-10-30 23:58:41: [2024-10-30 23:58:41] iter = 19950, loss = 3.5137
2024-10-30 23:58:44: [2024-10-30 23:58:44] iter = 19960, loss = 50.7836
2024-10-30 23:58:47: [2024-10-30 23:58:47] iter = 19970, loss = 28.9122
2024-10-30 23:58:50: [2024-10-30 23:58:50] iter = 19980, loss = 4.2686
2024-10-30 23:58:54: [2024-10-30 23:58:54] iter = 19990, loss = 6.8438
2024-10-30 23:58:56: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-30 23:58:56: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-30 23:58:56: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 36783}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:01:07: Evaluate 5 random ConvNet, ACCmean = 0.3413 ACCstd = 0.0106
-------------------------
2024-10-31 00:01:07: Evaluate 5 random ConvNet, SENmean = 0.2989 SENstd = 0.0030
-------------------------
2024-10-31 00:01:07: Evaluate 5 random ConvNet, SPEmean = 0.9066 SPEstd = 0.0010
-------------------------
2024-10-31 00:01:07: Evaluate 5 random ConvNet, F!mean = 0.2578 F!std = 0.0053
-------------------------
2024-10-31 00:01:07: Evaluate 5 random ConvNet, mean = 0.3413 std = 0.0106
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:01:07: [2024-10-31 00:01:07] iter = 20000, loss = 36.5408
2024-10-31 00:01:07: 
================== Exp 4 ==================
 
2024-10-31 00:01:07: Hyper-parameters: 
{'dataset': 'TissueMNIST', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 1000, 'Iteration': 20000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/data/users/xiongyuxuan/DD/OBJDD/DatasetCondensation-master/data', 'save_path': 'result', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7ffaf9964b20>, 'dsa': True, 'logger': <Logger DM_IPC=10_Model_ConvNet_Data_TissueMNIST (INFO)>}
2024-10-31 00:01:07: Evaluation model pool: ['ConvNet']
2024-10-31 00:01:25: class c = 0: 53075 real images
2024-10-31 00:01:25: class c = 1: 7814 real images
2024-10-31 00:01:25: class c = 2: 5866 real images
2024-10-31 00:01:25: class c = 3: 15406 real images
2024-10-31 00:01:25: class c = 4: 11789 real images
2024-10-31 00:01:25: class c = 5: 7705 real images
2024-10-31 00:01:25: class c = 6: 39203 real images
2024-10-31 00:01:25: class c = 7: 24608 real images
2024-10-31 00:01:25: real images channel 0, mean = 0.1020, std = 0.1000
main_DM.py:120: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
2024-10-31 00:01:25: initialize synthetic data from random real images
2024-10-31 00:01:25: [2024-10-31 00:01:25] training begins
2024-10-31 00:01:25: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2024-10-31 00:01:25: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:01:25: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 67451}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:03:36: Evaluate 5 random ConvNet, ACCmean = 0.2964 ACCstd = 0.0064
-------------------------
2024-10-31 00:03:36: Evaluate 5 random ConvNet, SENmean = 0.2541 SENstd = 0.0043
-------------------------
2024-10-31 00:03:36: Evaluate 5 random ConvNet, SPEmean = 0.8981 SPEstd = 0.0010
-------------------------
2024-10-31 00:03:36: Evaluate 5 random ConvNet, F!mean = 0.2394 F!std = 0.0044
-------------------------
2024-10-31 00:03:36: Evaluate 5 random ConvNet, mean = 0.2964 std = 0.0064
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:03:36: [2024-10-31 00:03:36] iter = 00000, loss = 15.1331
2024-10-31 00:03:39: [2024-10-31 00:03:39] iter = 00010, loss = 52.6840
2024-10-31 00:03:42: [2024-10-31 00:03:42] iter = 00020, loss = 19.4991
2024-10-31 00:03:45: [2024-10-31 00:03:45] iter = 00030, loss = 15.2847
2024-10-31 00:03:49: [2024-10-31 00:03:49] iter = 00040, loss = 55.6181
2024-10-31 00:03:52: [2024-10-31 00:03:52] iter = 00050, loss = 5.5299
2024-10-31 00:03:55: [2024-10-31 00:03:55] iter = 00060, loss = 53.2874
2024-10-31 00:03:59: [2024-10-31 00:03:59] iter = 00070, loss = 11.3723
2024-10-31 00:04:02: [2024-10-31 00:04:02] iter = 00080, loss = 11.7321
2024-10-31 00:04:04: [2024-10-31 00:04:04] iter = 00090, loss = 6.6933
2024-10-31 00:04:08: [2024-10-31 00:04:08] iter = 00100, loss = 25.6585
2024-10-31 00:04:11: [2024-10-31 00:04:11] iter = 00110, loss = 13.3677
2024-10-31 00:04:14: [2024-10-31 00:04:14] iter = 00120, loss = 15.6046
2024-10-31 00:04:18: [2024-10-31 00:04:18] iter = 00130, loss = 10.7446
2024-10-31 00:04:21: [2024-10-31 00:04:21] iter = 00140, loss = 6.3630
2024-10-31 00:04:25: [2024-10-31 00:04:25] iter = 00150, loss = 12.6153
2024-10-31 00:04:28: [2024-10-31 00:04:28] iter = 00160, loss = 3.8350
2024-10-31 00:04:31: [2024-10-31 00:04:31] iter = 00170, loss = 14.3018
2024-10-31 00:04:35: [2024-10-31 00:04:35] iter = 00180, loss = 13.8718
2024-10-31 00:04:39: [2024-10-31 00:04:39] iter = 00190, loss = 12.7078
2024-10-31 00:04:41: [2024-10-31 00:04:41] iter = 00200, loss = 23.4035
2024-10-31 00:04:45: [2024-10-31 00:04:45] iter = 00210, loss = 59.3920
2024-10-31 00:04:49: [2024-10-31 00:04:49] iter = 00220, loss = 5.5291
2024-10-31 00:04:52: [2024-10-31 00:04:52] iter = 00230, loss = 7.9267
2024-10-31 00:04:55: [2024-10-31 00:04:55] iter = 00240, loss = 25.4466
2024-10-31 00:04:58: [2024-10-31 00:04:58] iter = 00250, loss = 4.6325
2024-10-31 00:05:01: [2024-10-31 00:05:01] iter = 00260, loss = 5.7245
2024-10-31 00:05:05: [2024-10-31 00:05:05] iter = 00270, loss = 28.9520
2024-10-31 00:05:07: [2024-10-31 00:05:07] iter = 00280, loss = 12.3480
2024-10-31 00:05:10: [2024-10-31 00:05:10] iter = 00290, loss = 50.5544
2024-10-31 00:05:13: [2024-10-31 00:05:13] iter = 00300, loss = 34.5094
2024-10-31 00:05:16: [2024-10-31 00:05:16] iter = 00310, loss = 51.7583
2024-10-31 00:05:19: [2024-10-31 00:05:19] iter = 00320, loss = 5.2087
2024-10-31 00:05:22: [2024-10-31 00:05:22] iter = 00330, loss = 17.6726
2024-10-31 00:05:25: [2024-10-31 00:05:25] iter = 00340, loss = 33.2515
2024-10-31 00:05:29: [2024-10-31 00:05:29] iter = 00350, loss = 18.8211
2024-10-31 00:05:32: [2024-10-31 00:05:32] iter = 00360, loss = 6.3466
2024-10-31 00:05:36: [2024-10-31 00:05:36] iter = 00370, loss = 26.3977
2024-10-31 00:05:39: [2024-10-31 00:05:39] iter = 00380, loss = 5.2662
2024-10-31 00:05:43: [2024-10-31 00:05:43] iter = 00390, loss = 31.2787
2024-10-31 00:05:47: [2024-10-31 00:05:47] iter = 00400, loss = 97.8171
2024-10-31 00:05:51: [2024-10-31 00:05:51] iter = 00410, loss = 14.0266
2024-10-31 00:05:55: [2024-10-31 00:05:55] iter = 00420, loss = 3.8293
2024-10-31 00:05:58: [2024-10-31 00:05:58] iter = 00430, loss = 6.5493
2024-10-31 00:06:01: [2024-10-31 00:06:01] iter = 00440, loss = 31.4589
2024-10-31 00:06:04: [2024-10-31 00:06:04] iter = 00450, loss = 25.4313
2024-10-31 00:06:07: [2024-10-31 00:06:07] iter = 00460, loss = 15.0164
2024-10-31 00:06:10: [2024-10-31 00:06:10] iter = 00470, loss = 8.3581
2024-10-31 00:06:13: [2024-10-31 00:06:13] iter = 00480, loss = 28.9607
2024-10-31 00:06:16: [2024-10-31 00:06:16] iter = 00490, loss = 42.2926
2024-10-31 00:06:19: [2024-10-31 00:06:19] iter = 00500, loss = 16.0354
2024-10-31 00:06:21: [2024-10-31 00:06:21] iter = 00510, loss = 46.3025
2024-10-31 00:06:23: [2024-10-31 00:06:23] iter = 00520, loss = 26.8420
2024-10-31 00:06:26: [2024-10-31 00:06:26] iter = 00530, loss = 8.4656
2024-10-31 00:06:30: [2024-10-31 00:06:30] iter = 00540, loss = 35.3134
2024-10-31 00:06:33: [2024-10-31 00:06:33] iter = 00550, loss = 8.3453
2024-10-31 00:06:36: [2024-10-31 00:06:36] iter = 00560, loss = 24.9291
2024-10-31 00:06:39: [2024-10-31 00:06:39] iter = 00570, loss = 16.6159
2024-10-31 00:06:42: [2024-10-31 00:06:42] iter = 00580, loss = 53.4353
2024-10-31 00:06:46: [2024-10-31 00:06:46] iter = 00590, loss = 9.4238
2024-10-31 00:06:48: [2024-10-31 00:06:48] iter = 00600, loss = 64.8157
2024-10-31 00:06:51: [2024-10-31 00:06:51] iter = 00610, loss = 35.7111
2024-10-31 00:06:54: [2024-10-31 00:06:54] iter = 00620, loss = 14.6726
2024-10-31 00:06:58: [2024-10-31 00:06:58] iter = 00630, loss = 39.2342
2024-10-31 00:07:01: [2024-10-31 00:07:01] iter = 00640, loss = 18.9034
2024-10-31 00:07:04: [2024-10-31 00:07:04] iter = 00650, loss = 11.6968
2024-10-31 00:07:07: [2024-10-31 00:07:07] iter = 00660, loss = 4.3933
2024-10-31 00:07:11: [2024-10-31 00:07:11] iter = 00670, loss = 10.0812
2024-10-31 00:07:14: [2024-10-31 00:07:14] iter = 00680, loss = 18.5933
2024-10-31 00:07:17: [2024-10-31 00:07:17] iter = 00690, loss = 28.5148
2024-10-31 00:07:21: [2024-10-31 00:07:21] iter = 00700, loss = 5.1619
2024-10-31 00:07:25: [2024-10-31 00:07:25] iter = 00710, loss = 7.1104
2024-10-31 00:07:28: [2024-10-31 00:07:28] iter = 00720, loss = 5.0369
2024-10-31 00:07:31: [2024-10-31 00:07:31] iter = 00730, loss = 8.8372
2024-10-31 00:07:35: [2024-10-31 00:07:35] iter = 00740, loss = 4.4512
2024-10-31 00:07:38: [2024-10-31 00:07:38] iter = 00750, loss = 11.7088
2024-10-31 00:07:41: [2024-10-31 00:07:41] iter = 00760, loss = 37.2238
2024-10-31 00:07:44: [2024-10-31 00:07:44] iter = 00770, loss = 23.5625
2024-10-31 00:07:47: [2024-10-31 00:07:47] iter = 00780, loss = 9.0107
2024-10-31 00:07:51: [2024-10-31 00:07:51] iter = 00790, loss = 4.6657
2024-10-31 00:07:54: [2024-10-31 00:07:54] iter = 00800, loss = 3.8441
2024-10-31 00:07:58: [2024-10-31 00:07:58] iter = 00810, loss = 12.8457
2024-10-31 00:08:00: [2024-10-31 00:08:00] iter = 00820, loss = 86.8106
2024-10-31 00:08:03: [2024-10-31 00:08:03] iter = 00830, loss = 3.2721
2024-10-31 00:08:06: [2024-10-31 00:08:06] iter = 00840, loss = 10.2208
2024-10-31 00:08:10: [2024-10-31 00:08:10] iter = 00850, loss = 41.8140
2024-10-31 00:08:14: [2024-10-31 00:08:14] iter = 00860, loss = 8.6926
2024-10-31 00:08:17: [2024-10-31 00:08:17] iter = 00870, loss = 98.1711
2024-10-31 00:08:21: [2024-10-31 00:08:21] iter = 00880, loss = 25.7960
2024-10-31 00:08:24: [2024-10-31 00:08:24] iter = 00890, loss = 25.3696
2024-10-31 00:08:28: [2024-10-31 00:08:28] iter = 00900, loss = 24.3607
2024-10-31 00:08:30: [2024-10-31 00:08:30] iter = 00910, loss = 6.5410
2024-10-31 00:08:32: [2024-10-31 00:08:32] iter = 00920, loss = 4.7893
2024-10-31 00:08:35: [2024-10-31 00:08:35] iter = 00930, loss = 6.2795
2024-10-31 00:08:39: [2024-10-31 00:08:39] iter = 00940, loss = 9.6685
2024-10-31 00:08:41: [2024-10-31 00:08:41] iter = 00950, loss = 23.7300
2024-10-31 00:08:45: [2024-10-31 00:08:45] iter = 00960, loss = 11.8916
2024-10-31 00:08:48: [2024-10-31 00:08:48] iter = 00970, loss = 7.9477
2024-10-31 00:08:52: [2024-10-31 00:08:52] iter = 00980, loss = 13.3790
2024-10-31 00:08:56: [2024-10-31 00:08:56] iter = 00990, loss = 7.5579
2024-10-31 00:08:59: [2024-10-31 00:08:59] iter = 01000, loss = 20.7851
2024-10-31 00:09:02: [2024-10-31 00:09:02] iter = 01010, loss = 5.8548
2024-10-31 00:09:06: [2024-10-31 00:09:06] iter = 01020, loss = 16.1112
2024-10-31 00:09:09: [2024-10-31 00:09:09] iter = 01030, loss = 12.2252
2024-10-31 00:09:12: [2024-10-31 00:09:12] iter = 01040, loss = 19.2368
2024-10-31 00:09:16: [2024-10-31 00:09:16] iter = 01050, loss = 62.6822
2024-10-31 00:09:19: [2024-10-31 00:09:19] iter = 01060, loss = 16.3089
2024-10-31 00:09:22: [2024-10-31 00:09:22] iter = 01070, loss = 12.0399
2024-10-31 00:09:25: [2024-10-31 00:09:25] iter = 01080, loss = 8.3892
2024-10-31 00:09:28: [2024-10-31 00:09:28] iter = 01090, loss = 4.3550
2024-10-31 00:09:31: [2024-10-31 00:09:31] iter = 01100, loss = 59.1811
2024-10-31 00:09:35: [2024-10-31 00:09:35] iter = 01110, loss = 9.7453
2024-10-31 00:09:38: [2024-10-31 00:09:38] iter = 01120, loss = 3.4804
2024-10-31 00:09:42: [2024-10-31 00:09:42] iter = 01130, loss = 13.7986
2024-10-31 00:09:45: [2024-10-31 00:09:45] iter = 01140, loss = 47.9079
2024-10-31 00:09:48: [2024-10-31 00:09:48] iter = 01150, loss = 3.6474
2024-10-31 00:09:52: [2024-10-31 00:09:52] iter = 01160, loss = 37.6276
2024-10-31 00:09:55: [2024-10-31 00:09:55] iter = 01170, loss = 49.2960
2024-10-31 00:09:58: [2024-10-31 00:09:58] iter = 01180, loss = 5.7863
2024-10-31 00:10:01: [2024-10-31 00:10:01] iter = 01190, loss = 6.0185
2024-10-31 00:10:05: [2024-10-31 00:10:05] iter = 01200, loss = 11.2367
2024-10-31 00:10:08: [2024-10-31 00:10:08] iter = 01210, loss = 4.9682
2024-10-31 00:10:12: [2024-10-31 00:10:12] iter = 01220, loss = 3.5908
2024-10-31 00:10:15: [2024-10-31 00:10:15] iter = 01230, loss = 49.8861
2024-10-31 00:10:19: [2024-10-31 00:10:19] iter = 01240, loss = 15.7966
2024-10-31 00:10:23: [2024-10-31 00:10:23] iter = 01250, loss = 15.3708
2024-10-31 00:10:27: [2024-10-31 00:10:27] iter = 01260, loss = 4.2629
2024-10-31 00:10:30: [2024-10-31 00:10:30] iter = 01270, loss = 72.4796
2024-10-31 00:10:34: [2024-10-31 00:10:34] iter = 01280, loss = 5.7211
2024-10-31 00:10:37: [2024-10-31 00:10:37] iter = 01290, loss = 70.0226
2024-10-31 00:10:40: [2024-10-31 00:10:40] iter = 01300, loss = 4.5123
2024-10-31 00:10:43: [2024-10-31 00:10:43] iter = 01310, loss = 13.2038
2024-10-31 00:10:46: [2024-10-31 00:10:46] iter = 01320, loss = 86.6575
2024-10-31 00:10:50: [2024-10-31 00:10:50] iter = 01330, loss = 8.0348
2024-10-31 00:10:53: [2024-10-31 00:10:53] iter = 01340, loss = 19.6144
2024-10-31 00:10:56: [2024-10-31 00:10:56] iter = 01350, loss = 7.2529
2024-10-31 00:10:59: [2024-10-31 00:10:59] iter = 01360, loss = 13.5838
2024-10-31 00:11:01: [2024-10-31 00:11:01] iter = 01370, loss = 19.4894
2024-10-31 00:11:04: [2024-10-31 00:11:04] iter = 01380, loss = 4.7056
2024-10-31 00:11:07: [2024-10-31 00:11:07] iter = 01390, loss = 16.0985
2024-10-31 00:11:10: [2024-10-31 00:11:10] iter = 01400, loss = 11.8463
2024-10-31 00:11:12: [2024-10-31 00:11:12] iter = 01410, loss = 11.6502
2024-10-31 00:11:15: [2024-10-31 00:11:15] iter = 01420, loss = 4.2027
2024-10-31 00:11:18: [2024-10-31 00:11:18] iter = 01430, loss = 39.8327
2024-10-31 00:11:22: [2024-10-31 00:11:22] iter = 01440, loss = 18.3200
2024-10-31 00:11:25: [2024-10-31 00:11:25] iter = 01450, loss = 7.7072
2024-10-31 00:11:28: [2024-10-31 00:11:28] iter = 01460, loss = 18.8204
2024-10-31 00:11:30: [2024-10-31 00:11:30] iter = 01470, loss = 53.7515
2024-10-31 00:11:34: [2024-10-31 00:11:34] iter = 01480, loss = 6.7631
2024-10-31 00:11:38: [2024-10-31 00:11:38] iter = 01490, loss = 12.4143
2024-10-31 00:11:41: [2024-10-31 00:11:41] iter = 01500, loss = 3.8034
2024-10-31 00:11:44: [2024-10-31 00:11:44] iter = 01510, loss = 28.2607
2024-10-31 00:11:48: [2024-10-31 00:11:47] iter = 01520, loss = 65.1023
2024-10-31 00:11:51: [2024-10-31 00:11:51] iter = 01530, loss = 40.1647
2024-10-31 00:11:55: [2024-10-31 00:11:55] iter = 01540, loss = 6.9223
2024-10-31 00:11:59: [2024-10-31 00:11:59] iter = 01550, loss = 14.3544
2024-10-31 00:12:02: [2024-10-31 00:12:02] iter = 01560, loss = 9.7773
2024-10-31 00:12:05: [2024-10-31 00:12:05] iter = 01570, loss = 35.9359
2024-10-31 00:12:08: [2024-10-31 00:12:08] iter = 01580, loss = 9.6405
2024-10-31 00:12:11: [2024-10-31 00:12:11] iter = 01590, loss = 7.1311
2024-10-31 00:12:14: [2024-10-31 00:12:14] iter = 01600, loss = 4.0365
2024-10-31 00:12:16: [2024-10-31 00:12:16] iter = 01610, loss = 22.6838
2024-10-31 00:12:19: [2024-10-31 00:12:19] iter = 01620, loss = 6.1892
2024-10-31 00:12:22: [2024-10-31 00:12:22] iter = 01630, loss = 5.9616
2024-10-31 00:12:24: [2024-10-31 00:12:24] iter = 01640, loss = 84.9004
2024-10-31 00:12:26: [2024-10-31 00:12:26] iter = 01650, loss = 8.7200
2024-10-31 00:12:29: [2024-10-31 00:12:29] iter = 01660, loss = 86.3163
2024-10-31 00:12:32: [2024-10-31 00:12:32] iter = 01670, loss = 24.6614
2024-10-31 00:12:35: [2024-10-31 00:12:35] iter = 01680, loss = 19.9100
2024-10-31 00:12:38: [2024-10-31 00:12:38] iter = 01690, loss = 61.0023
2024-10-31 00:12:41: [2024-10-31 00:12:41] iter = 01700, loss = 12.3078
2024-10-31 00:12:45: [2024-10-31 00:12:45] iter = 01710, loss = 5.9852
2024-10-31 00:12:49: [2024-10-31 00:12:49] iter = 01720, loss = 38.9616
2024-10-31 00:12:52: [2024-10-31 00:12:52] iter = 01730, loss = 5.4973
2024-10-31 00:12:54: [2024-10-31 00:12:54] iter = 01740, loss = 8.4134
2024-10-31 00:12:57: [2024-10-31 00:12:57] iter = 01750, loss = 3.3003
2024-10-31 00:13:01: [2024-10-31 00:13:01] iter = 01760, loss = 35.7356
2024-10-31 00:13:04: [2024-10-31 00:13:04] iter = 01770, loss = 16.0778
2024-10-31 00:13:07: [2024-10-31 00:13:07] iter = 01780, loss = 30.2421
2024-10-31 00:13:11: [2024-10-31 00:13:11] iter = 01790, loss = 11.0212
2024-10-31 00:13:15: [2024-10-31 00:13:15] iter = 01800, loss = 3.9198
2024-10-31 00:13:19: [2024-10-31 00:13:19] iter = 01810, loss = 21.1558
2024-10-31 00:13:22: [2024-10-31 00:13:22] iter = 01820, loss = 11.1075
2024-10-31 00:13:25: [2024-10-31 00:13:25] iter = 01830, loss = 4.3921
2024-10-31 00:13:30: [2024-10-31 00:13:30] iter = 01840, loss = 9.5871
2024-10-31 00:13:33: [2024-10-31 00:13:33] iter = 01850, loss = 6.5037
2024-10-31 00:13:36: [2024-10-31 00:13:36] iter = 01860, loss = 73.5248
2024-10-31 00:13:39: [2024-10-31 00:13:39] iter = 01870, loss = 16.8735
2024-10-31 00:13:43: [2024-10-31 00:13:43] iter = 01880, loss = 50.9723
2024-10-31 00:13:46: [2024-10-31 00:13:46] iter = 01890, loss = 5.9652
2024-10-31 00:13:49: [2024-10-31 00:13:49] iter = 01900, loss = 43.5776
2024-10-31 00:13:52: [2024-10-31 00:13:52] iter = 01910, loss = 16.9231
2024-10-31 00:13:55: [2024-10-31 00:13:55] iter = 01920, loss = 11.8398
2024-10-31 00:13:58: [2024-10-31 00:13:58] iter = 01930, loss = 5.6936
2024-10-31 00:14:01: [2024-10-31 00:14:01] iter = 01940, loss = 109.7121
2024-10-31 00:14:05: [2024-10-31 00:14:05] iter = 01950, loss = 15.4451
2024-10-31 00:14:09: [2024-10-31 00:14:09] iter = 01960, loss = 13.1351
2024-10-31 00:14:13: [2024-10-31 00:14:13] iter = 01970, loss = 6.1147
2024-10-31 00:14:16: [2024-10-31 00:14:16] iter = 01980, loss = 7.4648
2024-10-31 00:14:20: [2024-10-31 00:14:20] iter = 01990, loss = 107.9041
2024-10-31 00:14:23: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2024-10-31 00:14:23: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:14:23: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 63215}

[2024-10-30 22:27:49] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.004896 train acc = 1.0000, test acc = 0.4358, test_sen =0.3230, test_spe =0.9140, test_f1 =0.3041
[2024-10-30 22:28:10] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.031434 train acc = 1.0000, test acc = 0.4425, test_sen =0.3218, test_spe =0.9144, test_f1 =0.3046
[2024-10-30 22:39:46] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.010056 train acc = 1.0000, test acc = 0.2830, test_sen =0.2889, test_spe =0.9004, test_f1 =0.2428
[2024-10-30 22:40:12] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.010883 train acc = 1.0000, test acc = 0.2992, test_sen =0.2936, test_spe =0.9024, test_f1 =0.2489
[2024-10-30 22:40:40] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.006529 train acc = 1.0000, test acc = 0.3180, test_sen =0.2985, test_spe =0.9042, test_f1 =0.2589
[2024-10-30 22:41:04] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.004937 train acc = 1.0000, test acc = 0.3089, test_sen =0.2949, test_spe =0.9034, test_f1 =0.2522
[2024-10-30 22:41:29] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.002743 train acc = 1.0000, test acc = 0.3219, test_sen =0.3046, test_spe =0.9047, test_f1 =0.2631
[2024-10-30 22:52:56] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.048560 train acc = 1.0000, test acc = 0.3527, test_sen =0.3056, test_spe =0.9077, test_f1 =0.2567
[2024-10-30 22:53:21] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.003764 train acc = 1.0000, test acc = 0.3544, test_sen =0.2986, test_spe =0.9078, test_f1 =0.2523
[2024-10-30 22:53:44] Evaluate_02: epoch = 1000 train time = 18 s train loss = 0.072068 train acc = 1.0000, test acc = 0.3700, test_sen =0.3096, test_spe =0.9094, test_f1 =0.2603
[2024-10-30 22:54:07] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.012105 train acc = 1.0000, test acc = 0.3787, test_sen =0.3168, test_spe =0.9100, test_f1 =0.2753
[2024-10-30 22:54:31] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.002390 train acc = 1.0000, test acc = 0.3686, test_sen =0.3047, test_spe =0.9091, test_f1 =0.2590
[2024-10-30 23:06:26] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.006994 train acc = 1.0000, test acc = 0.2986, test_sen =0.3032, test_spe =0.9029, test_f1 =0.2389
[2024-10-30 23:06:48] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.006284 train acc = 1.0000, test acc = 0.2969, test_sen =0.2931, test_spe =0.9023, test_f1 =0.2289
[2024-10-30 23:07:18] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.053898 train acc = 1.0000, test acc = 0.2921, test_sen =0.3011, test_spe =0.9022, test_f1 =0.2317
[2024-10-30 23:07:48] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.039579 train acc = 1.0000, test acc = 0.3157, test_sen =0.3064, test_spe =0.9045, test_f1 =0.2442
[2024-10-30 23:08:14] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.078008 train acc = 1.0000, test acc = 0.3105, test_sen =0.3037, test_spe =0.9043, test_f1 =0.2366
[2024-10-30 23:19:31] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.042643 train acc = 1.0000, test acc = 0.3842, test_sen =0.3082, test_spe =0.9092, test_f1 =0.2702
[2024-10-30 23:19:52] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.007791 train acc = 1.0000, test acc = 0.3932, test_sen =0.3094, test_spe =0.9101, test_f1 =0.2730
[2024-10-30 23:20:16] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.001953 train acc = 1.0000, test acc = 0.3883, test_sen =0.3093, test_spe =0.9094, test_f1 =0.2744
[2024-10-30 23:20:39] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.003410 train acc = 1.0000, test acc = 0.4041, test_sen =0.3164, test_spe =0.9114, test_f1 =0.2835
[2024-10-30 23:21:03] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.002601 train acc = 1.0000, test acc = 0.4021, test_sen =0.3146, test_spe =0.9110, test_f1 =0.2771
[2024-10-30 23:33:05] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.054920 train acc = 1.0000, test acc = 0.3993, test_sen =0.3221, test_spe =0.9121, test_f1 =0.2949
[2024-10-30 23:33:29] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.002024 train acc = 1.0000, test acc = 0.4187, test_sen =0.3226, test_spe =0.9138, test_f1 =0.2958
[2024-10-30 23:33:53] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.036953 train acc = 1.0000, test acc = 0.4098, test_sen =0.3261, test_spe =0.9133, test_f1 =0.2978
[2024-10-30 23:34:15] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.001948 train acc = 1.0000, test acc = 0.4025, test_sen =0.3258, test_spe =0.9127, test_f1 =0.2998
[2024-10-30 23:34:42] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.070537 train acc = 1.0000, test acc = 0.4189, test_sen =0.3242, test_spe =0.9139, test_f1 =0.3004
[2024-10-30 23:46:15] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.002317 train acc = 1.0000, test acc = 0.2732, test_sen =0.2776, test_spe =0.8988, test_f1 =0.2273
[2024-10-30 23:46:39] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.002831 train acc = 1.0000, test acc = 0.2740, test_sen =0.2754, test_spe =0.8986, test_f1 =0.2253
[2024-10-30 23:47:02] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.001776 train acc = 1.0000, test acc = 0.2663, test_sen =0.2790, test_spe =0.8984, test_f1 =0.2230
[2024-10-30 23:47:24] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.071274 train acc = 0.9875, test acc = 0.2787, test_sen =0.2748, test_spe =0.8991, test_f1 =0.2264
[2024-10-30 23:47:46] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.032071 train acc = 1.0000, test acc = 0.2956, test_sen =0.2851, test_spe =0.9011, test_f1 =0.2421
[2024-10-30 23:59:22] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.039473 train acc = 1.0000, test acc = 0.3300, test_sen =0.2950, test_spe =0.9054, test_f1 =0.2502
[2024-10-30 23:59:45] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.002627 train acc = 1.0000, test acc = 0.3485, test_sen =0.3035, test_spe =0.9076, test_f1 =0.2637
[2024-10-31 00:00:15] Evaluate_02: epoch = 1000 train time = 24 s train loss = 0.075909 train acc = 1.0000, test acc = 0.3392, test_sen =0.2970, test_spe =0.9065, test_f1 =0.2565
[2024-10-31 00:00:42] Evaluate_03: epoch = 1000 train time = 22 s train loss = 0.035585 train acc = 1.0000, test acc = 0.3312, test_sen =0.2978, test_spe =0.9058, test_f1 =0.2546
[2024-10-31 00:01:07] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.003565 train acc = 1.0000, test acc = 0.3578, test_sen =0.3011, test_spe =0.9078, test_f1 =0.2639
[2024-10-31 00:01:51] Evaluate_00: epoch = 1000 train time = 22 s train loss = 0.002009 train acc = 1.0000, test acc = 0.3080, test_sen =0.2612, test_spe =0.8999, test_f1 =0.2473
[2024-10-31 00:02:15] Evaluate_01: epoch = 1000 train time = 19 s train loss = 0.055613 train acc = 1.0000, test acc = 0.2984, test_sen =0.2553, test_spe =0.8985, test_f1 =0.2407
[2024-10-31 00:02:41] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.016537 train acc = 1.0000, test acc = 0.2926, test_sen =0.2544, test_spe =0.8977, test_f1 =0.2373
[2024-10-31 00:03:10] Evaluate_03: epoch = 1000 train time = 24 s train loss = 0.021651 train acc = 1.0000, test acc = 0.2912, test_sen =0.2514, test_spe =0.8975, test_f1 =0.2368
[2024-10-31 00:03:36] Evaluate_04: epoch = 1000 train time = 21 s train loss = 0.023541 train acc = 1.0000, test acc = 0.2916, test_sen =0.2481, test_spe =0.8969, test_f1 =0.2347
[2024-10-31 00:14:45] Evaluate_00: epoch = 1000 train time = 18 s train loss = 0.003683 train acc = 1.0000, test acc = 0.3556, test_sen =0.2960, test_spe =0.9071, test_f1 =0.2663
[2024-10-31 00:15:12] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.044618 train acc = 1.0000, test acc = 0.3468, test_sen =0.2962, test_spe =0.9063, test_f1 =0.2624
[2024-10-31 00:15:38] Evaluate_02: epoch = 1000 train time = 21 s train loss = 0.074017 train acc = 1.0000, test acc = 0.3261, test_sen =0.2915, test_spe =0.9042, test_f1 =0.2518
[2024-10-31 00:16:02] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.031043 train acc = 1.0000, test acc = 0.3474, test_sen =0.2888, test_spe =0.9062, test_f1 =0.2568/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:16:27: Evaluate 5 random ConvNet, ACCmean = 0.3463 ACCstd = 0.0108
-------------------------
2024-10-31 00:16:27: Evaluate 5 random ConvNet, SENmean = 0.2947 SENstd = 0.0043
-------------------------
2024-10-31 00:16:27: Evaluate 5 random ConvNet, SPEmean = 0.9062 SPEstd = 0.0011
-------------------------
2024-10-31 00:16:27: Evaluate 5 random ConvNet, F!mean = 0.2609 F!std = 0.0059
-------------------------
2024-10-31 00:16:27: Evaluate 5 random ConvNet, mean = 0.3463 std = 0.0108
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:16:27: [2024-10-31 00:16:27] iter = 02000, loss = 38.4773
2024-10-31 00:16:31: [2024-10-31 00:16:31] iter = 02010, loss = 24.8974
2024-10-31 00:16:34: [2024-10-31 00:16:34] iter = 02020, loss = 66.4418
2024-10-31 00:16:38: [2024-10-31 00:16:38] iter = 02030, loss = 27.7570
2024-10-31 00:16:41: [2024-10-31 00:16:41] iter = 02040, loss = 13.0958
2024-10-31 00:16:44: [2024-10-31 00:16:44] iter = 02050, loss = 50.1198
2024-10-31 00:16:49: [2024-10-31 00:16:49] iter = 02060, loss = 104.3574
2024-10-31 00:16:53: [2024-10-31 00:16:53] iter = 02070, loss = 5.2166
2024-10-31 00:16:56: [2024-10-31 00:16:56] iter = 02080, loss = 27.7588
2024-10-31 00:17:00: [2024-10-31 00:17:00] iter = 02090, loss = 13.8826
2024-10-31 00:17:03: [2024-10-31 00:17:03] iter = 02100, loss = 38.5570
2024-10-31 00:17:06: [2024-10-31 00:17:06] iter = 02110, loss = 25.6867
2024-10-31 00:17:09: [2024-10-31 00:17:09] iter = 02120, loss = 75.4337
2024-10-31 00:17:12: [2024-10-31 00:17:12] iter = 02130, loss = 30.6142
2024-10-31 00:17:14: [2024-10-31 00:17:14] iter = 02140, loss = 32.2959
2024-10-31 00:17:18: [2024-10-31 00:17:18] iter = 02150, loss = 13.9612
2024-10-31 00:17:22: [2024-10-31 00:17:22] iter = 02160, loss = 19.7523
2024-10-31 00:17:25: [2024-10-31 00:17:25] iter = 02170, loss = 17.9731
2024-10-31 00:17:29: [2024-10-31 00:17:29] iter = 02180, loss = 5.3357
2024-10-31 00:17:32: [2024-10-31 00:17:32] iter = 02190, loss = 3.6340
2024-10-31 00:17:35: [2024-10-31 00:17:35] iter = 02200, loss = 64.4567
2024-10-31 00:17:40: [2024-10-31 00:17:40] iter = 02210, loss = 49.0096
2024-10-31 00:17:43: [2024-10-31 00:17:43] iter = 02220, loss = 26.1792
2024-10-31 00:17:46: [2024-10-31 00:17:46] iter = 02230, loss = 12.1431
2024-10-31 00:17:48: [2024-10-31 00:17:48] iter = 02240, loss = 28.9469
2024-10-31 00:17:51: [2024-10-31 00:17:51] iter = 02250, loss = 9.7728
2024-10-31 00:17:54: [2024-10-31 00:17:54] iter = 02260, loss = 37.8818
2024-10-31 00:17:58: [2024-10-31 00:17:58] iter = 02270, loss = 3.9902
2024-10-31 00:18:01: [2024-10-31 00:18:01] iter = 02280, loss = 4.4255
2024-10-31 00:18:05: [2024-10-31 00:18:05] iter = 02290, loss = 4.6588
2024-10-31 00:18:08: [2024-10-31 00:18:08] iter = 02300, loss = 18.6664
2024-10-31 00:18:12: [2024-10-31 00:18:12] iter = 02310, loss = 9.1402
2024-10-31 00:18:15: [2024-10-31 00:18:15] iter = 02320, loss = 18.6733
2024-10-31 00:18:19: [2024-10-31 00:18:19] iter = 02330, loss = 5.8905
2024-10-31 00:18:22: [2024-10-31 00:18:22] iter = 02340, loss = 48.0496
2024-10-31 00:18:25: [2024-10-31 00:18:25] iter = 02350, loss = 15.9317
2024-10-31 00:18:30: [2024-10-31 00:18:30] iter = 02360, loss = 8.6202
2024-10-31 00:18:33: [2024-10-31 00:18:33] iter = 02370, loss = 8.7962
2024-10-31 00:18:37: [2024-10-31 00:18:37] iter = 02380, loss = 6.9094
2024-10-31 00:18:41: [2024-10-31 00:18:41] iter = 02390, loss = 15.7401
2024-10-31 00:18:45: [2024-10-31 00:18:45] iter = 02400, loss = 25.8561
2024-10-31 00:18:49: [2024-10-31 00:18:49] iter = 02410, loss = 4.9648
2024-10-31 00:18:52: [2024-10-31 00:18:52] iter = 02420, loss = 12.3336
2024-10-31 00:18:55: [2024-10-31 00:18:55] iter = 02430, loss = 5.8625
2024-10-31 00:18:57: [2024-10-31 00:18:57] iter = 02440, loss = 23.4144
2024-10-31 00:19:01: [2024-10-31 00:19:01] iter = 02450, loss = 8.6149
2024-10-31 00:19:04: [2024-10-31 00:19:04] iter = 02460, loss = 24.6212
2024-10-31 00:19:07: [2024-10-31 00:19:07] iter = 02470, loss = 55.3391
2024-10-31 00:19:11: [2024-10-31 00:19:11] iter = 02480, loss = 4.2129
2024-10-31 00:19:15: [2024-10-31 00:19:15] iter = 02490, loss = 8.3737
2024-10-31 00:19:18: [2024-10-31 00:19:18] iter = 02500, loss = 105.2322
2024-10-31 00:19:22: [2024-10-31 00:19:22] iter = 02510, loss = 10.0954
2024-10-31 00:19:25: [2024-10-31 00:19:25] iter = 02520, loss = 12.7065
2024-10-31 00:19:30: [2024-10-31 00:19:30] iter = 02530, loss = 28.2279
2024-10-31 00:19:34: [2024-10-31 00:19:34] iter = 02540, loss = 10.7922
2024-10-31 00:19:38: [2024-10-31 00:19:38] iter = 02550, loss = 5.0197
2024-10-31 00:19:42: [2024-10-31 00:19:42] iter = 02560, loss = 4.7921
2024-10-31 00:19:46: [2024-10-31 00:19:46] iter = 02570, loss = 6.0140
2024-10-31 00:19:49: [2024-10-31 00:19:49] iter = 02580, loss = 11.2269
2024-10-31 00:19:53: [2024-10-31 00:19:53] iter = 02590, loss = 28.3172
2024-10-31 00:19:57: [2024-10-31 00:19:57] iter = 02600, loss = 5.7489
2024-10-31 00:20:00: [2024-10-31 00:20:00] iter = 02610, loss = 5.6821
2024-10-31 00:20:03: [2024-10-31 00:20:03] iter = 02620, loss = 14.6869
2024-10-31 00:20:07: [2024-10-31 00:20:07] iter = 02630, loss = 18.6638
2024-10-31 00:20:10: [2024-10-31 00:20:10] iter = 02640, loss = 39.6275
2024-10-31 00:20:13: [2024-10-31 00:20:13] iter = 02650, loss = 26.3933
2024-10-31 00:20:16: [2024-10-31 00:20:16] iter = 02660, loss = 18.5537
2024-10-31 00:20:20: [2024-10-31 00:20:20] iter = 02670, loss = 25.8743
2024-10-31 00:20:22: [2024-10-31 00:20:22] iter = 02680, loss = 4.6399
2024-10-31 00:20:26: [2024-10-31 00:20:26] iter = 02690, loss = 9.3098
2024-10-31 00:20:29: [2024-10-31 00:20:29] iter = 02700, loss = 29.1530
2024-10-31 00:20:31: [2024-10-31 00:20:31] iter = 02710, loss = 7.8081
2024-10-31 00:20:35: [2024-10-31 00:20:35] iter = 02720, loss = 46.3116
2024-10-31 00:20:39: [2024-10-31 00:20:39] iter = 02730, loss = 31.1769
2024-10-31 00:20:43: [2024-10-31 00:20:43] iter = 02740, loss = 3.4170
2024-10-31 00:20:46: [2024-10-31 00:20:46] iter = 02750, loss = 14.8722
2024-10-31 00:20:50: [2024-10-31 00:20:50] iter = 02760, loss = 54.4540
2024-10-31 00:20:53: [2024-10-31 00:20:53] iter = 02770, loss = 8.7696
2024-10-31 00:20:56: [2024-10-31 00:20:56] iter = 02780, loss = 3.3598
2024-10-31 00:20:59: [2024-10-31 00:20:59] iter = 02790, loss = 67.9678
2024-10-31 00:21:02: [2024-10-31 00:21:02] iter = 02800, loss = 15.2848
2024-10-31 00:21:05: [2024-10-31 00:21:05] iter = 02810, loss = 7.7071
2024-10-31 00:21:09: [2024-10-31 00:21:09] iter = 02820, loss = 4.0045
2024-10-31 00:21:12: [2024-10-31 00:21:12] iter = 02830, loss = 3.8221
2024-10-31 00:21:16: [2024-10-31 00:21:16] iter = 02840, loss = 44.1044
2024-10-31 00:21:19: [2024-10-31 00:21:19] iter = 02850, loss = 31.2032
2024-10-31 00:21:22: [2024-10-31 00:21:22] iter = 02860, loss = 4.1711
2024-10-31 00:21:25: [2024-10-31 00:21:25] iter = 02870, loss = 10.6644
2024-10-31 00:21:28: [2024-10-31 00:21:28] iter = 02880, loss = 28.3791
2024-10-31 00:21:31: [2024-10-31 00:21:31] iter = 02890, loss = 29.6686
2024-10-31 00:21:34: [2024-10-31 00:21:34] iter = 02900, loss = 4.1321
2024-10-31 00:21:37: [2024-10-31 00:21:37] iter = 02910, loss = 7.1346
2024-10-31 00:21:41: [2024-10-31 00:21:41] iter = 02920, loss = 8.8407
2024-10-31 00:21:45: [2024-10-31 00:21:45] iter = 02930, loss = 26.8764
2024-10-31 00:21:48: [2024-10-31 00:21:48] iter = 02940, loss = 26.0697
2024-10-31 00:21:52: [2024-10-31 00:21:52] iter = 02950, loss = 26.5395
2024-10-31 00:21:56: [2024-10-31 00:21:56] iter = 02960, loss = 56.7739
2024-10-31 00:21:59: [2024-10-31 00:21:59] iter = 02970, loss = 22.9423
2024-10-31 00:22:03: [2024-10-31 00:22:03] iter = 02980, loss = 18.1830
2024-10-31 00:22:07: [2024-10-31 00:22:07] iter = 02990, loss = 7.5693
2024-10-31 00:22:09: [2024-10-31 00:22:09] iter = 03000, loss = 16.1401
2024-10-31 00:22:12: [2024-10-31 00:22:12] iter = 03010, loss = 10.2538
2024-10-31 00:22:16: [2024-10-31 00:22:16] iter = 03020, loss = 4.1251
2024-10-31 00:22:20: [2024-10-31 00:22:20] iter = 03030, loss = 4.1779
2024-10-31 00:22:23: [2024-10-31 00:22:23] iter = 03040, loss = 58.5269
2024-10-31 00:22:27: [2024-10-31 00:22:27] iter = 03050, loss = 3.3417
2024-10-31 00:22:29: [2024-10-31 00:22:29] iter = 03060, loss = 11.1942
2024-10-31 00:22:32: [2024-10-31 00:22:32] iter = 03070, loss = 36.8127
2024-10-31 00:22:36: [2024-10-31 00:22:36] iter = 03080, loss = 7.4864
2024-10-31 00:22:40: [2024-10-31 00:22:40] iter = 03090, loss = 5.5668
2024-10-31 00:22:43: [2024-10-31 00:22:43] iter = 03100, loss = 21.3406
2024-10-31 00:22:47: [2024-10-31 00:22:47] iter = 03110, loss = 5.0735
2024-10-31 00:22:50: [2024-10-31 00:22:50] iter = 03120, loss = 8.9127
2024-10-31 00:22:52: [2024-10-31 00:22:52] iter = 03130, loss = 21.5327
2024-10-31 00:22:55: [2024-10-31 00:22:55] iter = 03140, loss = 59.6701
2024-10-31 00:22:59: [2024-10-31 00:22:58] iter = 03150, loss = 4.8084
2024-10-31 00:23:02: [2024-10-31 00:23:02] iter = 03160, loss = 5.3256
2024-10-31 00:23:05: [2024-10-31 00:23:05] iter = 03170, loss = 3.7688
2024-10-31 00:23:08: [2024-10-31 00:23:08] iter = 03180, loss = 22.2699
2024-10-31 00:23:12: [2024-10-31 00:23:11] iter = 03190, loss = 21.7215
2024-10-31 00:23:15: [2024-10-31 00:23:15] iter = 03200, loss = 32.3476
2024-10-31 00:23:20: [2024-10-31 00:23:20] iter = 03210, loss = 22.6501
2024-10-31 00:23:24: [2024-10-31 00:23:24] iter = 03220, loss = 5.1471
2024-10-31 00:23:25: [2024-10-31 00:23:25] iter = 03230, loss = 5.0538
2024-10-31 00:23:29: [2024-10-31 00:23:29] iter = 03240, loss = 27.8336
2024-10-31 00:23:32: [2024-10-31 00:23:32] iter = 03250, loss = 31.0733
2024-10-31 00:23:35: [2024-10-31 00:23:35] iter = 03260, loss = 6.0246
2024-10-31 00:23:38: [2024-10-31 00:23:38] iter = 03270, loss = 9.2215
2024-10-31 00:23:40: [2024-10-31 00:23:40] iter = 03280, loss = 4.3781
2024-10-31 00:23:43: [2024-10-31 00:23:43] iter = 03290, loss = 47.3399
2024-10-31 00:23:47: [2024-10-31 00:23:47] iter = 03300, loss = 33.3053
2024-10-31 00:23:51: [2024-10-31 00:23:51] iter = 03310, loss = 3.5946
2024-10-31 00:23:54: [2024-10-31 00:23:54] iter = 03320, loss = 18.4848
2024-10-31 00:23:57: [2024-10-31 00:23:57] iter = 03330, loss = 2.8378
2024-10-31 00:24:00: [2024-10-31 00:24:00] iter = 03340, loss = 3.6572
2024-10-31 00:24:03: [2024-10-31 00:24:03] iter = 03350, loss = 8.4971
2024-10-31 00:24:07: [2024-10-31 00:24:07] iter = 03360, loss = 12.6235
2024-10-31 00:24:11: [2024-10-31 00:24:11] iter = 03370, loss = 44.7197
2024-10-31 00:24:14: [2024-10-31 00:24:14] iter = 03380, loss = 68.2222
2024-10-31 00:24:18: [2024-10-31 00:24:18] iter = 03390, loss = 4.8325
2024-10-31 00:24:22: [2024-10-31 00:24:22] iter = 03400, loss = 19.5007
2024-10-31 00:24:25: [2024-10-31 00:24:25] iter = 03410, loss = 4.5492
2024-10-31 00:24:28: [2024-10-31 00:24:28] iter = 03420, loss = 17.6017
2024-10-31 00:24:33: [2024-10-31 00:24:33] iter = 03430, loss = 12.1034
2024-10-31 00:24:36: [2024-10-31 00:24:36] iter = 03440, loss = 21.5432
2024-10-31 00:24:39: [2024-10-31 00:24:39] iter = 03450, loss = 6.1566
2024-10-31 00:24:43: [2024-10-31 00:24:43] iter = 03460, loss = 30.3263
2024-10-31 00:24:46: [2024-10-31 00:24:46] iter = 03470, loss = 5.1852
2024-10-31 00:24:49: [2024-10-31 00:24:49] iter = 03480, loss = 4.1570
2024-10-31 00:24:53: [2024-10-31 00:24:53] iter = 03490, loss = 30.4802
2024-10-31 00:24:56: [2024-10-31 00:24:56] iter = 03500, loss = 86.2448
2024-10-31 00:24:58: [2024-10-31 00:24:58] iter = 03510, loss = 15.2120
2024-10-31 00:25:01: [2024-10-31 00:25:01] iter = 03520, loss = 30.6121
2024-10-31 00:25:05: [2024-10-31 00:25:05] iter = 03530, loss = 7.9015
2024-10-31 00:25:08: [2024-10-31 00:25:08] iter = 03540, loss = 14.2936
2024-10-31 00:25:12: [2024-10-31 00:25:12] iter = 03550, loss = 4.6412
2024-10-31 00:25:16: [2024-10-31 00:25:16] iter = 03560, loss = 11.4811
2024-10-31 00:25:19: [2024-10-31 00:25:19] iter = 03570, loss = 30.7652
2024-10-31 00:25:23: [2024-10-31 00:25:23] iter = 03580, loss = 24.8501
2024-10-31 00:25:28: [2024-10-31 00:25:28] iter = 03590, loss = 16.7127
2024-10-31 00:25:32: [2024-10-31 00:25:32] iter = 03600, loss = 12.4545
2024-10-31 00:25:35: [2024-10-31 00:25:35] iter = 03610, loss = 14.2982
2024-10-31 00:25:37: [2024-10-31 00:25:37] iter = 03620, loss = 12.7819
2024-10-31 00:25:40: [2024-10-31 00:25:40] iter = 03630, loss = 31.6600
2024-10-31 00:25:42: [2024-10-31 00:25:42] iter = 03640, loss = 4.9003
2024-10-31 00:25:47: [2024-10-31 00:25:47] iter = 03650, loss = 33.2291
2024-10-31 00:25:50: [2024-10-31 00:25:50] iter = 03660, loss = 8.0477
2024-10-31 00:25:54: [2024-10-31 00:25:54] iter = 03670, loss = 11.0144
2024-10-31 00:25:57: [2024-10-31 00:25:57] iter = 03680, loss = 8.4890
2024-10-31 00:26:00: [2024-10-31 00:26:00] iter = 03690, loss = 6.7573
2024-10-31 00:26:03: [2024-10-31 00:26:03] iter = 03700, loss = 32.5802
2024-10-31 00:26:07: [2024-10-31 00:26:07] iter = 03710, loss = 13.2694
2024-10-31 00:26:10: [2024-10-31 00:26:10] iter = 03720, loss = 4.7801
2024-10-31 00:26:13: [2024-10-31 00:26:13] iter = 03730, loss = 11.5837
2024-10-31 00:26:16: [2024-10-31 00:26:16] iter = 03740, loss = 36.0520
2024-10-31 00:26:19: [2024-10-31 00:26:19] iter = 03750, loss = 34.6382
2024-10-31 00:26:23: [2024-10-31 00:26:23] iter = 03760, loss = 7.6231
2024-10-31 00:26:26: [2024-10-31 00:26:26] iter = 03770, loss = 15.2062
2024-10-31 00:26:29: [2024-10-31 00:26:29] iter = 03780, loss = 4.2083
2024-10-31 00:26:32: [2024-10-31 00:26:32] iter = 03790, loss = 4.6228
2024-10-31 00:26:35: [2024-10-31 00:26:35] iter = 03800, loss = 4.8511
2024-10-31 00:26:39: [2024-10-31 00:26:39] iter = 03810, loss = 13.7242
2024-10-31 00:26:42: [2024-10-31 00:26:42] iter = 03820, loss = 18.8032
2024-10-31 00:26:46: [2024-10-31 00:26:46] iter = 03830, loss = 3.3107
2024-10-31 00:26:49: [2024-10-31 00:26:49] iter = 03840, loss = 2.9686
2024-10-31 00:26:52: [2024-10-31 00:26:52] iter = 03850, loss = 23.1301
2024-10-31 00:26:55: [2024-10-31 00:26:55] iter = 03860, loss = 28.6846
2024-10-31 00:26:58: [2024-10-31 00:26:58] iter = 03870, loss = 10.8269
2024-10-31 00:27:02: [2024-10-31 00:27:02] iter = 03880, loss = 19.9122
2024-10-31 00:27:05: [2024-10-31 00:27:05] iter = 03890, loss = 9.4295
2024-10-31 00:27:07: [2024-10-31 00:27:07] iter = 03900, loss = 6.6673
2024-10-31 00:27:10: [2024-10-31 00:27:10] iter = 03910, loss = 7.8670
2024-10-31 00:27:13: [2024-10-31 00:27:13] iter = 03920, loss = 19.7200
2024-10-31 00:27:16: [2024-10-31 00:27:16] iter = 03930, loss = 26.2434
2024-10-31 00:27:19: [2024-10-31 00:27:19] iter = 03940, loss = 6.3347
2024-10-31 00:27:23: [2024-10-31 00:27:23] iter = 03950, loss = 15.3428
2024-10-31 00:27:27: [2024-10-31 00:27:27] iter = 03960, loss = 28.4377
2024-10-31 00:27:30: [2024-10-31 00:27:30] iter = 03970, loss = 33.5698
2024-10-31 00:27:33: [2024-10-31 00:27:33] iter = 03980, loss = 3.5804
2024-10-31 00:27:37: [2024-10-31 00:27:37] iter = 03990, loss = 44.3728
2024-10-31 00:27:39: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2024-10-31 00:27:39: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:27:39: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 59878}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:29:44: Evaluate 5 random ConvNet, ACCmean = 0.2948 ACCstd = 0.0096
-------------------------
2024-10-31 00:29:44: Evaluate 5 random ConvNet, SENmean = 0.2844 SENstd = 0.0057
-------------------------
2024-10-31 00:29:44: Evaluate 5 random ConvNet, SPEmean = 0.9007 SPEstd = 0.0011
-------------------------
2024-10-31 00:29:44: Evaluate 5 random ConvNet, F!mean = 0.2517 F!std = 0.0065
-------------------------
2024-10-31 00:29:44: Evaluate 5 random ConvNet, mean = 0.2948 std = 0.0096
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:29:45: [2024-10-31 00:29:45] iter = 04000, loss = 24.3899
2024-10-31 00:29:48: [2024-10-31 00:29:48] iter = 04010, loss = 5.9207
2024-10-31 00:29:51: [2024-10-31 00:29:51] iter = 04020, loss = 70.6805
2024-10-31 00:29:55: [2024-10-31 00:29:55] iter = 04030, loss = 27.5656
2024-10-31 00:29:58: [2024-10-31 00:29:58] iter = 04040, loss = 43.3243
2024-10-31 00:30:01: [2024-10-31 00:30:01] iter = 04050, loss = 6.1259
2024-10-31 00:30:05: [2024-10-31 00:30:05] iter = 04060, loss = 8.8985
2024-10-31 00:30:09: [2024-10-31 00:30:09] iter = 04070, loss = 4.1716
2024-10-31 00:30:13: [2024-10-31 00:30:13] iter = 04080, loss = 3.6969
2024-10-31 00:30:17: [2024-10-31 00:30:17] iter = 04090, loss = 11.3694
2024-10-31 00:30:20: [2024-10-31 00:30:20] iter = 04100, loss = 4.0402
2024-10-31 00:30:24: [2024-10-31 00:30:24] iter = 04110, loss = 54.7630
2024-10-31 00:30:28: [2024-10-31 00:30:28] iter = 04120, loss = 4.4092
2024-10-31 00:30:32: [2024-10-31 00:30:32] iter = 04130, loss = 7.6171
2024-10-31 00:30:35: [2024-10-31 00:30:35] iter = 04140, loss = 51.5290
2024-10-31 00:30:39: [2024-10-31 00:30:39] iter = 04150, loss = 8.3997
2024-10-31 00:30:43: [2024-10-31 00:30:43] iter = 04160, loss = 5.1746
2024-10-31 00:30:45: [2024-10-31 00:30:45] iter = 04170, loss = 85.9034
2024-10-31 00:30:48: [2024-10-31 00:30:48] iter = 04180, loss = 6.4213
2024-10-31 00:30:51: [2024-10-31 00:30:51] iter = 04190, loss = 13.0696
2024-10-31 00:30:53: [2024-10-31 00:30:53] iter = 04200, loss = 51.3923
2024-10-31 00:30:56: [2024-10-31 00:30:56] iter = 04210, loss = 22.6556
2024-10-31 00:31:01: [2024-10-31 00:31:01] iter = 04220, loss = 83.5926
2024-10-31 00:31:04: [2024-10-31 00:31:04] iter = 04230, loss = 36.9140
2024-10-31 00:31:06: [2024-10-31 00:31:06] iter = 04240, loss = 3.9237
2024-10-31 00:31:09: [2024-10-31 00:31:09] iter = 04250, loss = 5.4935
2024-10-31 00:31:11: [2024-10-31 00:31:11] iter = 04260, loss = 58.0991
2024-10-31 00:31:14: [2024-10-31 00:31:14] iter = 04270, loss = 20.2909
2024-10-31 00:31:18: [2024-10-31 00:31:18] iter = 04280, loss = 41.5084
2024-10-31 00:31:21: [2024-10-31 00:31:21] iter = 04290, loss = 47.1331
2024-10-31 00:31:25: [2024-10-31 00:31:25] iter = 04300, loss = 4.6106
2024-10-31 00:31:28: [2024-10-31 00:31:28] iter = 04310, loss = 46.9917
2024-10-31 00:31:31: [2024-10-31 00:31:31] iter = 04320, loss = 19.1601
2024-10-31 00:31:34: [2024-10-31 00:31:34] iter = 04330, loss = 7.6675
2024-10-31 00:31:38: [2024-10-31 00:31:38] iter = 04340, loss = 36.4721
2024-10-31 00:31:42: [2024-10-31 00:31:42] iter = 04350, loss = 8.2519
2024-10-31 00:31:45: [2024-10-31 00:31:45] iter = 04360, loss = 71.7016
2024-10-31 00:31:48: [2024-10-31 00:31:48] iter = 04370, loss = 25.5260
2024-10-31 00:31:50: [2024-10-31 00:31:50] iter = 04380, loss = 52.1867
2024-10-31 00:31:53: [2024-10-31 00:31:53] iter = 04390, loss = 34.3680
2024-10-31 00:31:56: [2024-10-31 00:31:56] iter = 04400, loss = 15.4962
2024-10-31 00:32:00: [2024-10-31 00:32:00] iter = 04410, loss = 5.2805
2024-10-31 00:32:04: [2024-10-31 00:32:04] iter = 04420, loss = 7.1828
2024-10-31 00:32:07: [2024-10-31 00:32:07] iter = 04430, loss = 18.2656
2024-10-31 00:32:11: [2024-10-31 00:32:11] iter = 04440, loss = 4.6437
2024-10-31 00:32:15: [2024-10-31 00:32:15] iter = 04450, loss = 11.6772
2024-10-31 00:32:19: [2024-10-31 00:32:19] iter = 04460, loss = 9.2638
2024-10-31 00:32:23: [2024-10-31 00:32:23] iter = 04470, loss = 7.1899
2024-10-31 00:32:27: [2024-10-31 00:32:27] iter = 04480, loss = 4.3810
2024-10-31 00:32:30: [2024-10-31 00:32:30] iter = 04490, loss = 28.8699
2024-10-31 00:32:33: [2024-10-31 00:32:33] iter = 04500, loss = 5.9064
2024-10-31 00:32:36: [2024-10-31 00:32:36] iter = 04510, loss = 37.4621
2024-10-31 00:32:39: [2024-10-31 00:32:39] iter = 04520, loss = 96.4662
2024-10-31 00:32:42: [2024-10-31 00:32:42] iter = 04530, loss = 14.5638
2024-10-31 00:32:46: [2024-10-31 00:32:46] iter = 04540, loss = 97.8633
2024-10-31 00:32:50: [2024-10-31 00:32:50] iter = 04550, loss = 6.6384
2024-10-31 00:32:54: [2024-10-31 00:32:54] iter = 04560, loss = 3.9063
2024-10-31 00:32:58: [2024-10-31 00:32:58] iter = 04570, loss = 8.5845
2024-10-31 00:33:00: [2024-10-31 00:33:00] iter = 04580, loss = 5.7658
2024-10-31 00:33:03: [2024-10-31 00:33:03] iter = 04590, loss = 29.0511
2024-10-31 00:33:06: [2024-10-31 00:33:06] iter = 04600, loss = 39.1656
2024-10-31 00:33:09: [2024-10-31 00:33:09] iter = 04610, loss = 13.7187
2024-10-31 00:33:12: [2024-10-31 00:33:12] iter = 04620, loss = 22.2162
2024-10-31 00:33:15: [2024-10-31 00:33:15] iter = 04630, loss = 15.0749
2024-10-31 00:33:18: [2024-10-31 00:33:18] iter = 04640, loss = 12.0710
2024-10-31 00:33:21: [2024-10-31 00:33:21] iter = 04650, loss = 4.5319
2024-10-31 00:33:24: [2024-10-31 00:33:24] iter = 04660, loss = 15.2246
2024-10-31 00:33:27: [2024-10-31 00:33:27] iter = 04670, loss = 77.2916
2024-10-31 00:33:31: [2024-10-31 00:33:31] iter = 04680, loss = 26.0942
2024-10-31 00:33:33: [2024-10-31 00:33:33] iter = 04690, loss = 29.3143
2024-10-31 00:33:37: [2024-10-31 00:33:37] iter = 04700, loss = 9.6543
2024-10-31 00:33:40: [2024-10-31 00:33:40] iter = 04710, loss = 48.6372
2024-10-31 00:33:44: [2024-10-31 00:33:44] iter = 04720, loss = 7.5776
2024-10-31 00:33:47: [2024-10-31 00:33:47] iter = 04730, loss = 3.7718
2024-10-31 00:33:51: [2024-10-31 00:33:51] iter = 04740, loss = 6.7910
2024-10-31 00:33:54: [2024-10-31 00:33:54] iter = 04750, loss = 60.6447
2024-10-31 00:33:58: [2024-10-31 00:33:58] iter = 04760, loss = 15.5828
2024-10-31 00:34:02: [2024-10-31 00:34:02] iter = 04770, loss = 58.1746
2024-10-31 00:34:05: [2024-10-31 00:34:05] iter = 04780, loss = 29.4088
2024-10-31 00:34:09: [2024-10-31 00:34:09] iter = 04790, loss = 4.2826
2024-10-31 00:34:12: [2024-10-31 00:34:12] iter = 04800, loss = 16.8011
2024-10-31 00:34:15: [2024-10-31 00:34:15] iter = 04810, loss = 21.6150
2024-10-31 00:34:19: [2024-10-31 00:34:19] iter = 04820, loss = 5.7491
2024-10-31 00:34:22: [2024-10-31 00:34:22] iter = 04830, loss = 59.7772
2024-10-31 00:34:26: [2024-10-31 00:34:26] iter = 04840, loss = 10.5181
2024-10-31 00:34:29: [2024-10-31 00:34:29] iter = 04850, loss = 36.4487
2024-10-31 00:34:31: [2024-10-31 00:34:31] iter = 04860, loss = 63.7911
2024-10-31 00:34:36: [2024-10-31 00:34:36] iter = 04870, loss = 18.0200
2024-10-31 00:34:39: [2024-10-31 00:34:39] iter = 04880, loss = 6.5076
2024-10-31 00:34:43: [2024-10-31 00:34:43] iter = 04890, loss = 4.1111
2024-10-31 00:34:45: [2024-10-31 00:34:45] iter = 04900, loss = 51.2379
2024-10-31 00:34:47: [2024-10-31 00:34:47] iter = 04910, loss = 6.8502
2024-10-31 00:34:51: [2024-10-31 00:34:51] iter = 04920, loss = 10.0564
2024-10-31 00:34:55: [2024-10-31 00:34:55] iter = 04930, loss = 37.2163
2024-10-31 00:34:59: [2024-10-31 00:34:59] iter = 04940, loss = 5.7104
2024-10-31 00:35:04: [2024-10-31 00:35:04] iter = 04950, loss = 14.5878
2024-10-31 00:35:07: [2024-10-31 00:35:07] iter = 04960, loss = 53.7765
2024-10-31 00:35:11: [2024-10-31 00:35:11] iter = 04970, loss = 49.9422
2024-10-31 00:35:15: [2024-10-31 00:35:15] iter = 04980, loss = 23.6451
2024-10-31 00:35:19: [2024-10-31 00:35:19] iter = 04990, loss = 60.6688
2024-10-31 00:35:23: [2024-10-31 00:35:23] iter = 05000, loss = 10.4836
2024-10-31 00:35:25: [2024-10-31 00:35:25] iter = 05010, loss = 8.1760
2024-10-31 00:35:27: [2024-10-31 00:35:27] iter = 05020, loss = 43.6421
2024-10-31 00:35:30: [2024-10-31 00:35:30] iter = 05030, loss = 13.2524
2024-10-31 00:35:33: [2024-10-31 00:35:33] iter = 05040, loss = 7.2716
2024-10-31 00:35:35: [2024-10-31 00:35:35] iter = 05050, loss = 37.2755
2024-10-31 00:35:38: [2024-10-31 00:35:38] iter = 05060, loss = 5.8665
2024-10-31 00:35:42: [2024-10-31 00:35:42] iter = 05070, loss = 34.1734
2024-10-31 00:35:45: [2024-10-31 00:35:45] iter = 05080, loss = 56.9755
2024-10-31 00:35:49: [2024-10-31 00:35:49] iter = 05090, loss = 12.7360
2024-10-31 00:35:53: [2024-10-31 00:35:53] iter = 05100, loss = 17.5528
2024-10-31 00:35:56: [2024-10-31 00:35:56] iter = 05110, loss = 5.1968
2024-10-31 00:36:00: [2024-10-31 00:36:00] iter = 05120, loss = 3.5101
2024-10-31 00:36:03: [2024-10-31 00:36:03] iter = 05130, loss = 8.7757
2024-10-31 00:36:06: [2024-10-31 00:36:06] iter = 05140, loss = 24.3547
2024-10-31 00:36:10: [2024-10-31 00:36:10] iter = 05150, loss = 9.6045
2024-10-31 00:36:13: [2024-10-31 00:36:13] iter = 05160, loss = 5.3185
2024-10-31 00:36:17: [2024-10-31 00:36:17] iter = 05170, loss = 17.4403
2024-10-31 00:36:20: [2024-10-31 00:36:20] iter = 05180, loss = 7.5120
2024-10-31 00:36:25: [2024-10-31 00:36:25] iter = 05190, loss = 8.2510
2024-10-31 00:36:29: [2024-10-31 00:36:29] iter = 05200, loss = 10.1024
2024-10-31 00:36:32: [2024-10-31 00:36:32] iter = 05210, loss = 7.8254
2024-10-31 00:36:36: [2024-10-31 00:36:36] iter = 05220, loss = 14.6656
2024-10-31 00:36:39: [2024-10-31 00:36:39] iter = 05230, loss = 4.9344
2024-10-31 00:36:42: [2024-10-31 00:36:42] iter = 05240, loss = 9.0119
2024-10-31 00:36:46: [2024-10-31 00:36:46] iter = 05250, loss = 36.2144
2024-10-31 00:36:49: [2024-10-31 00:36:49] iter = 05260, loss = 5.0464
2024-10-31 00:36:54: [2024-10-31 00:36:54] iter = 05270, loss = 48.0067
2024-10-31 00:36:58: [2024-10-31 00:36:58] iter = 05280, loss = 4.7088
2024-10-31 00:37:01: [2024-10-31 00:37:01] iter = 05290, loss = 10.9623
2024-10-31 00:37:05: [2024-10-31 00:37:05] iter = 05300, loss = 9.4253
2024-10-31 00:37:08: [2024-10-31 00:37:08] iter = 05310, loss = 42.2294
2024-10-31 00:37:11: [2024-10-31 00:37:11] iter = 05320, loss = 8.7833
2024-10-31 00:37:15: [2024-10-31 00:37:15] iter = 05330, loss = 24.2959
2024-10-31 00:37:17: [2024-10-31 00:37:17] iter = 05340, loss = 14.3256
2024-10-31 00:37:20: [2024-10-31 00:37:20] iter = 05350, loss = 35.8476
2024-10-31 00:37:23: [2024-10-31 00:37:23] iter = 05360, loss = 14.7468
2024-10-31 00:37:26: [2024-10-31 00:37:26] iter = 05370, loss = 10.7194
2024-10-31 00:37:29: [2024-10-31 00:37:29] iter = 05380, loss = 12.7726
2024-10-31 00:37:32: [2024-10-31 00:37:32] iter = 05390, loss = 15.7941
2024-10-31 00:37:36: [2024-10-31 00:37:36] iter = 05400, loss = 5.3234
2024-10-31 00:37:39: [2024-10-31 00:37:39] iter = 05410, loss = 8.3905
2024-10-31 00:37:43: [2024-10-31 00:37:43] iter = 05420, loss = 20.8301
2024-10-31 00:37:46: [2024-10-31 00:37:46] iter = 05430, loss = 68.8964
2024-10-31 00:37:50: [2024-10-31 00:37:50] iter = 05440, loss = 4.9003
2024-10-31 00:37:53: [2024-10-31 00:37:53] iter = 05450, loss = 36.7430
2024-10-31 00:37:57: [2024-10-31 00:37:57] iter = 05460, loss = 4.7324
2024-10-31 00:37:59: [2024-10-31 00:37:59] iter = 05470, loss = 4.1984
2024-10-31 00:38:02: [2024-10-31 00:38:02] iter = 05480, loss = 46.7651
2024-10-31 00:38:05: [2024-10-31 00:38:05] iter = 05490, loss = 3.9453
2024-10-31 00:38:09: [2024-10-31 00:38:09] iter = 05500, loss = 4.5508
2024-10-31 00:38:12: [2024-10-31 00:38:12] iter = 05510, loss = 6.1564
2024-10-31 00:38:16: [2024-10-31 00:38:16] iter = 05520, loss = 38.4213
2024-10-31 00:38:19: [2024-10-31 00:38:19] iter = 05530, loss = 18.0193
2024-10-31 00:38:23: [2024-10-31 00:38:23] iter = 05540, loss = 5.4996
2024-10-31 00:38:27: [2024-10-31 00:38:27] iter = 05550, loss = 44.8227
2024-10-31 00:38:31: [2024-10-31 00:38:31] iter = 05560, loss = 3.7384
2024-10-31 00:38:35: [2024-10-31 00:38:35] iter = 05570, loss = 18.8824
2024-10-31 00:38:38: [2024-10-31 00:38:38] iter = 05580, loss = 4.0911
2024-10-31 00:38:42: [2024-10-31 00:38:42] iter = 05590, loss = 23.0657
2024-10-31 00:38:45: [2024-10-31 00:38:45] iter = 05600, loss = 9.8844
2024-10-31 00:38:48: [2024-10-31 00:38:48] iter = 05610, loss = 10.2690
2024-10-31 00:38:51: [2024-10-31 00:38:51] iter = 05620, loss = 21.2926
2024-10-31 00:38:55: [2024-10-31 00:38:55] iter = 05630, loss = 27.3875
2024-10-31 00:38:58: [2024-10-31 00:38:58] iter = 05640, loss = 12.7987
2024-10-31 00:39:01: [2024-10-31 00:39:01] iter = 05650, loss = 18.8771
2024-10-31 00:39:04: [2024-10-31 00:39:04] iter = 05660, loss = 49.9231
2024-10-31 00:39:08: [2024-10-31 00:39:08] iter = 05670, loss = 12.5864
2024-10-31 00:39:12: [2024-10-31 00:39:12] iter = 05680, loss = 5.8629
2024-10-31 00:39:15: [2024-10-31 00:39:15] iter = 05690, loss = 3.7453
2024-10-31 00:39:19: [2024-10-31 00:39:19] iter = 05700, loss = 31.0469
2024-10-31 00:39:22: [2024-10-31 00:39:22] iter = 05710, loss = 35.9011
2024-10-31 00:39:26: [2024-10-31 00:39:26] iter = 05720, loss = 12.8828
2024-10-31 00:39:30: [2024-10-31 00:39:30] iter = 05730, loss = 34.6781
2024-10-31 00:39:34: [2024-10-31 00:39:34] iter = 05740, loss = 5.3011
2024-10-31 00:39:37: [2024-10-31 00:39:37] iter = 05750, loss = 4.4758
2024-10-31 00:39:40: [2024-10-31 00:39:40] iter = 05760, loss = 5.5594
2024-10-31 00:39:44: [2024-10-31 00:39:44] iter = 05770, loss = 12.5690
2024-10-31 00:39:47: [2024-10-31 00:39:47] iter = 05780, loss = 7.0113
2024-10-31 00:39:52: [2024-10-31 00:39:52] iter = 05790, loss = 32.2522
2024-10-31 00:39:56: [2024-10-31 00:39:56] iter = 05800, loss = 16.8990
2024-10-31 00:40:00: [2024-10-31 00:40:00] iter = 05810, loss = 5.2496
2024-10-31 00:40:02: [2024-10-31 00:40:02] iter = 05820, loss = 13.2185
2024-10-31 00:40:06: [2024-10-31 00:40:06] iter = 05830, loss = 12.5177
2024-10-31 00:40:09: [2024-10-31 00:40:09] iter = 05840, loss = 61.7597
2024-10-31 00:40:12: [2024-10-31 00:40:12] iter = 05850, loss = 16.5811
2024-10-31 00:40:14: [2024-10-31 00:40:14] iter = 05860, loss = 22.6288
2024-10-31 00:40:17: [2024-10-31 00:40:17] iter = 05870, loss = 33.4702
2024-10-31 00:40:20: [2024-10-31 00:40:20] iter = 05880, loss = 6.4748
2024-10-31 00:40:24: [2024-10-31 00:40:24] iter = 05890, loss = 79.6041
2024-10-31 00:40:27: [2024-10-31 00:40:27] iter = 05900, loss = 4.9668
2024-10-31 00:40:32: [2024-10-31 00:40:32] iter = 05910, loss = 23.0033
2024-10-31 00:40:35: [2024-10-31 00:40:35] iter = 05920, loss = 23.9338
2024-10-31 00:40:38: [2024-10-31 00:40:38] iter = 05930, loss = 19.5490
2024-10-31 00:40:41: [2024-10-31 00:40:41] iter = 05940, loss = 10.9324
2024-10-31 00:40:45: [2024-10-31 00:40:45] iter = 05950, loss = 11.9703
2024-10-31 00:40:48: [2024-10-31 00:40:48] iter = 05960, loss = 21.3353
2024-10-31 00:40:52: [2024-10-31 00:40:52] iter = 05970, loss = 43.5832
2024-10-31 00:40:55: [2024-10-31 00:40:55] iter = 05980, loss = 5.3941
2024-10-31 00:40:58: [2024-10-31 00:40:58] iter = 05990, loss = 4.7523
2024-10-31 00:41:01: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 6000
2024-10-31 00:41:01: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:41:01: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 61333}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:43:02: Evaluate 5 random ConvNet, ACCmean = 0.3495 ACCstd = 0.0087
-------------------------
2024-10-31 00:43:02: Evaluate 5 random ConvNet, SENmean = 0.2924 SENstd = 0.0022
-------------------------
2024-10-31 00:43:02: Evaluate 5 random ConvNet, SPEmean = 0.9064 SPEstd = 0.0007
-------------------------
2024-10-31 00:43:02: Evaluate 5 random ConvNet, F!mean = 0.2589 F!std = 0.0038
-------------------------
2024-10-31 00:43:02: Evaluate 5 random ConvNet, mean = 0.3495 std = 0.0087
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:43:02: [2024-10-31 00:43:02] iter = 06000, loss = 17.4125
2024-10-31 00:43:05: [2024-10-31 00:43:05] iter = 06010, loss = 51.9128
2024-10-31 00:43:09: [2024-10-31 00:43:09] iter = 06020, loss = 14.3046
2024-10-31 00:43:13: [2024-10-31 00:43:13] iter = 06030, loss = 10.1779
2024-10-31 00:43:16: [2024-10-31 00:43:16] iter = 06040, loss = 38.5454
2024-10-31 00:43:18: [2024-10-31 00:43:18] iter = 06050, loss = 27.1511
2024-10-31 00:43:22: [2024-10-31 00:43:22] iter = 06060, loss = 41.9090
2024-10-31 00:43:25: [2024-10-31 00:43:25] iter = 06070, loss = 10.3320
2024-10-31 00:43:28: [2024-10-31 00:43:28] iter = 06080, loss = 26.8991
2024-10-31 00:43:31: [2024-10-31 00:43:31] iter = 06090, loss = 4.2162
2024-10-31 00:43:35: [2024-10-31 00:43:35] iter = 06100, loss = 31.8173
2024-10-31 00:43:38: [2024-10-31 00:43:38] iter = 06110, loss = 9.6923
2024-10-31 00:43:41: [2024-10-31 00:43:41] iter = 06120, loss = 17.6972
2024-10-31 00:43:44: [2024-10-31 00:43:44] iter = 06130, loss = 67.6408
2024-10-31 00:43:47: [2024-10-31 00:43:47] iter = 06140, loss = 21.0635
2024-10-31 00:43:51: [2024-10-31 00:43:51] iter = 06150, loss = 12.1088
2024-10-31 00:43:54: [2024-10-31 00:43:54] iter = 06160, loss = 15.4056
2024-10-31 00:43:56: [2024-10-31 00:43:56] iter = 06170, loss = 34.5100
2024-10-31 00:44:00: [2024-10-31 00:44:00] iter = 06180, loss = 4.5096
2024-10-31 00:44:02: [2024-10-31 00:44:02] iter = 06190, loss = 15.1834
2024-10-31 00:44:06: [2024-10-31 00:44:06] iter = 06200, loss = 16.3384
2024-10-31 00:44:11: [2024-10-31 00:44:11] iter = 06210, loss = 60.0128
2024-10-31 00:44:14: [2024-10-31 00:44:14] iter = 06220, loss = 9.9060
2024-10-31 00:44:18: [2024-10-31 00:44:18] iter = 06230, loss = 31.3248
2024-10-31 00:44:21: [2024-10-31 00:44:21] iter = 06240, loss = 8.5173
2024-10-31 00:44:24: [2024-10-31 00:44:24] iter = 06250, loss = 14.6398
2024-10-31 00:44:28: [2024-10-31 00:44:28] iter = 06260, loss = 20.7674
2024-10-31 00:44:32: [2024-10-31 00:44:32] iter = 06270, loss = 30.0147
2024-10-31 00:44:36: [2024-10-31 00:44:36] iter = 06280, loss = 4.8736
2024-10-31 00:44:40: [2024-10-31 00:44:40] iter = 06290, loss = 16.1830
2024-10-31 00:44:44: [2024-10-31 00:44:44] iter = 06300, loss = 7.0699
2024-10-31 00:44:46: [2024-10-31 00:44:46] iter = 06310, loss = 5.9898
2024-10-31 00:44:49: [2024-10-31 00:44:49] iter = 06320, loss = 4.1207
2024-10-31 00:44:52: [2024-10-31 00:44:52] iter = 06330, loss = 13.3414
2024-10-31 00:44:55: [2024-10-31 00:44:55] iter = 06340, loss = 7.1439
2024-10-31 00:44:58: [2024-10-31 00:44:58] iter = 06350, loss = 4.6126
2024-10-31 00:45:02: [2024-10-31 00:45:02] iter = 06360, loss = 5.5858
2024-10-31 00:45:05: [2024-10-31 00:45:05] iter = 06370, loss = 74.3072
2024-10-31 00:45:09: [2024-10-31 00:45:09] iter = 06380, loss = 16.5398
2024-10-31 00:45:11: [2024-10-31 00:45:11] iter = 06390, loss = 7.4929
2024-10-31 00:45:13: [2024-10-31 00:45:13] iter = 06400, loss = 46.4324
2024-10-31 00:45:17: [2024-10-31 00:45:17] iter = 06410, loss = 23.5255
2024-10-31 00:45:19: [2024-10-31 00:45:19] iter = 06420, loss = 16.1299
2024-10-31 00:45:23: [2024-10-31 00:45:23] iter = 06430, loss = 4.9292
2024-10-31 00:45:26: [2024-10-31 00:45:26] iter = 06440, loss = 3.8910
2024-10-31 00:45:29: [2024-10-31 00:45:29] iter = 06450, loss = 8.6300
2024-10-31 00:45:31: [2024-10-31 00:45:31] iter = 06460, loss = 28.5573
2024-10-31 00:45:34: [2024-10-31 00:45:34] iter = 06470, loss = 9.2390
2024-10-31 00:45:38: [2024-10-31 00:45:38] iter = 06480, loss = 4.2026
2024-10-31 00:45:42: [2024-10-31 00:45:42] iter = 06490, loss = 4.1722
2024-10-31 00:45:46: [2024-10-31 00:45:46] iter = 06500, loss = 15.9526
2024-10-31 00:45:49: [2024-10-31 00:45:49] iter = 06510, loss = 12.1056
2024-10-31 00:45:52: [2024-10-31 00:45:52] iter = 06520, loss = 3.4176
2024-10-31 00:45:55: [2024-10-31 00:45:55] iter = 06530, loss = 10.4788
2024-10-31 00:45:57: [2024-10-31 00:45:57] iter = 06540, loss = 6.7762
2024-10-31 00:46:01: [2024-10-31 00:46:01] iter = 06550, loss = 23.8716
2024-10-31 00:46:04: [2024-10-31 00:46:04] iter = 06560, loss = 9.0215
2024-10-31 00:46:06: [2024-10-31 00:46:06] iter = 06570, loss = 28.9959
2024-10-31 00:46:10: [2024-10-31 00:46:10] iter = 06580, loss = 7.2846
2024-10-31 00:46:15: [2024-10-31 00:46:15] iter = 06590, loss = 5.3514
2024-10-31 00:46:18: [2024-10-31 00:46:18] iter = 06600, loss = 11.9504
2024-10-31 00:46:22: [2024-10-31 00:46:22] iter = 06610, loss = 17.3500
2024-10-31 00:46:25: [2024-10-31 00:46:25] iter = 06620, loss = 7.4683
2024-10-31 00:46:29: [2024-10-31 00:46:29] iter = 06630, loss = 28.8549
2024-10-31 00:46:33: [2024-10-31 00:46:33] iter = 06640, loss = 5.4935
2024-10-31 00:46:36: [2024-10-31 00:46:36] iter = 06650, loss = 53.3319
2024-10-31 00:46:39: [2024-10-31 00:46:39] iter = 06660, loss = 5.3856
2024-10-31 00:46:42: [2024-10-31 00:46:42] iter = 06670, loss = 11.4736
2024-10-31 00:46:45: [2024-10-31 00:46:45] iter = 06680, loss = 5.3524
2024-10-31 00:46:49: [2024-10-31 00:46:49] iter = 06690, loss = 4.9868
2024-10-31 00:46:52: [2024-10-31 00:46:52] iter = 06700, loss = 3.5949
2024-10-31 00:46:57: [2024-10-31 00:46:57] iter = 06710, loss = 6.1116
2024-10-31 00:47:00: [2024-10-31 00:47:00] iter = 06720, loss = 32.8415
2024-10-31 00:47:03: [2024-10-31 00:47:03] iter = 06730, loss = 32.4409
2024-10-31 00:47:06: [2024-10-31 00:47:06] iter = 06740, loss = 12.0164
2024-10-31 00:47:10: [2024-10-31 00:47:10] iter = 06750, loss = 56.9388
2024-10-31 00:47:13: [2024-10-31 00:47:13] iter = 06760, loss = 10.6684
2024-10-31 00:47:15: [2024-10-31 00:47:15] iter = 06770, loss = 57.3890
2024-10-31 00:47:18: [2024-10-31 00:47:18] iter = 06780, loss = 20.2291
2024-10-31 00:47:21: [2024-10-31 00:47:21] iter = 06790, loss = 30.6820
2024-10-31 00:47:25: [2024-10-31 00:47:25] iter = 06800, loss = 60.9759
2024-10-31 00:47:29: [2024-10-31 00:47:29] iter = 06810, loss = 28.9044
2024-10-31 00:47:33: [2024-10-31 00:47:33] iter = 06820, loss = 9.8040
2024-10-31 00:47:35: [2024-10-31 00:47:35] iter = 06830, loss = 18.4162
2024-10-31 00:47:38: [2024-10-31 00:47:38] iter = 06840, loss = 22.7062
2024-10-31 00:47:42: [2024-10-31 00:47:42] iter = 06850, loss = 11.4804
2024-10-31 00:47:44: [2024-10-31 00:47:44] iter = 06860, loss = 17.5861
2024-10-31 00:47:46: [2024-10-31 00:47:46] iter = 06870, loss = 20.2294
2024-10-31 00:47:49: [2024-10-31 00:47:49] iter = 06880, loss = 24.0296
2024-10-31 00:47:52: [2024-10-31 00:47:52] iter = 06890, loss = 11.7093
2024-10-31 00:47:55: [2024-10-31 00:47:55] iter = 06900, loss = 25.4489
2024-10-31 00:47:59: [2024-10-31 00:47:59] iter = 06910, loss = 24.5958
2024-10-31 00:48:01: [2024-10-31 00:48:01] iter = 06920, loss = 38.2095
2024-10-31 00:48:05: [2024-10-31 00:48:05] iter = 06930, loss = 3.9631
2024-10-31 00:48:08: [2024-10-31 00:48:08] iter = 06940, loss = 17.8617
2024-10-31 00:48:12: [2024-10-31 00:48:12] iter = 06950, loss = 24.0660
2024-10-31 00:48:16: [2024-10-31 00:48:16] iter = 06960, loss = 5.6221
2024-10-31 00:48:19: [2024-10-31 00:48:19] iter = 06970, loss = 4.8821
2024-10-31 00:48:23: [2024-10-31 00:48:23] iter = 06980, loss = 15.5531
2024-10-31 00:48:26: [2024-10-31 00:48:26] iter = 06990, loss = 8.5541
2024-10-31 00:48:29: [2024-10-31 00:48:29] iter = 07000, loss = 27.9916
2024-10-31 00:48:32: [2024-10-31 00:48:32] iter = 07010, loss = 6.7867
2024-10-31 00:48:36: [2024-10-31 00:48:36] iter = 07020, loss = 69.7561
2024-10-31 00:48:39: [2024-10-31 00:48:39] iter = 07030, loss = 6.4571
2024-10-31 00:48:42: [2024-10-31 00:48:42] iter = 07040, loss = 3.8551
2024-10-31 00:48:46: [2024-10-31 00:48:46] iter = 07050, loss = 7.4370
2024-10-31 00:48:49: [2024-10-31 00:48:49] iter = 07060, loss = 11.6846
2024-10-31 00:48:52: [2024-10-31 00:48:52] iter = 07070, loss = 6.2705
2024-10-31 00:48:55: [2024-10-31 00:48:55] iter = 07080, loss = 13.6491
2024-10-31 00:48:58: [2024-10-31 00:48:58] iter = 07090, loss = 16.3605
2024-10-31 00:49:01: [2024-10-31 00:49:01] iter = 07100, loss = 10.4276
2024-10-31 00:49:04: [2024-10-31 00:49:04] iter = 07110, loss = 9.2669
2024-10-31 00:49:08: [2024-10-31 00:49:08] iter = 07120, loss = 27.2863
2024-10-31 00:49:12: [2024-10-31 00:49:12] iter = 07130, loss = 13.5045
2024-10-31 00:49:16: [2024-10-31 00:49:16] iter = 07140, loss = 39.9552
2024-10-31 00:49:20: [2024-10-31 00:49:20] iter = 07150, loss = 21.2127
2024-10-31 00:49:24: [2024-10-31 00:49:24] iter = 07160, loss = 41.3255
2024-10-31 00:49:28: [2024-10-31 00:49:28] iter = 07170, loss = 4.3055
2024-10-31 00:49:32: [2024-10-31 00:49:32] iter = 07180, loss = 4.6932
2024-10-31 00:49:35: [2024-10-31 00:49:35] iter = 07190, loss = 5.7029
2024-10-31 00:49:38: [2024-10-31 00:49:38] iter = 07200, loss = 62.5821
2024-10-31 00:49:40: [2024-10-31 00:49:40] iter = 07210, loss = 33.6875
2024-10-31 00:49:42: [2024-10-31 00:49:42] iter = 07220, loss = 18.3476
2024-10-31 00:49:46: [2024-10-31 00:49:46] iter = 07230, loss = 13.1311
2024-10-31 00:49:49: [2024-10-31 00:49:49] iter = 07240, loss = 5.6787
2024-10-31 00:49:51: [2024-10-31 00:49:51] iter = 07250, loss = 6.3314
2024-10-31 00:49:54: [2024-10-31 00:49:54] iter = 07260, loss = 56.6628
2024-10-31 00:49:57: [2024-10-31 00:49:57] iter = 07270, loss = 4.8809
2024-10-31 00:50:01: [2024-10-31 00:50:01] iter = 07280, loss = 11.4066
2024-10-31 00:50:04: [2024-10-31 00:50:04] iter = 07290, loss = 9.9626
2024-10-31 00:50:08: [2024-10-31 00:50:08] iter = 07300, loss = 17.2160
2024-10-31 00:50:11: [2024-10-31 00:50:11] iter = 07310, loss = 15.2286
2024-10-31 00:50:15: [2024-10-31 00:50:15] iter = 07320, loss = 29.0956
2024-10-31 00:50:18: [2024-10-31 00:50:18] iter = 07330, loss = 24.4750
2024-10-31 00:50:21: [2024-10-31 00:50:21] iter = 07340, loss = 81.6175
2024-10-31 00:50:23: [2024-10-31 00:50:23] iter = 07350, loss = 5.7814
2024-10-31 00:50:26: [2024-10-31 00:50:26] iter = 07360, loss = 6.1728
2024-10-31 00:50:29: [2024-10-31 00:50:29] iter = 07370, loss = 29.3837
2024-10-31 00:50:32: [2024-10-31 00:50:32] iter = 07380, loss = 4.7889
2024-10-31 00:50:35: [2024-10-31 00:50:35] iter = 07390, loss = 12.7490
2024-10-31 00:50:39: [2024-10-31 00:50:39] iter = 07400, loss = 3.8733
2024-10-31 00:50:41: [2024-10-31 00:50:41] iter = 07410, loss = 4.9976
2024-10-31 00:50:44: [2024-10-31 00:50:44] iter = 07420, loss = 27.5717
2024-10-31 00:50:48: [2024-10-31 00:50:48] iter = 07430, loss = 55.4844
2024-10-31 00:50:51: [2024-10-31 00:50:51] iter = 07440, loss = 4.2198
2024-10-31 00:50:54: [2024-10-31 00:50:54] iter = 07450, loss = 16.0598
2024-10-31 00:50:58: [2024-10-31 00:50:58] iter = 07460, loss = 5.5587
2024-10-31 00:51:01: [2024-10-31 00:51:01] iter = 07470, loss = 16.9468
2024-10-31 00:51:04: [2024-10-31 00:51:04] iter = 07480, loss = 7.2452
2024-10-31 00:51:07: [2024-10-31 00:51:07] iter = 07490, loss = 33.6471
2024-10-31 00:51:10: [2024-10-31 00:51:10] iter = 07500, loss = 54.0838
2024-10-31 00:51:14: [2024-10-31 00:51:14] iter = 07510, loss = 16.8758
2024-10-31 00:51:17: [2024-10-31 00:51:17] iter = 07520, loss = 51.8424
2024-10-31 00:51:20: [2024-10-31 00:51:20] iter = 07530, loss = 4.5040
2024-10-31 00:51:23: [2024-10-31 00:51:23] iter = 07540, loss = 17.7820
2024-10-31 00:51:26: [2024-10-31 00:51:26] iter = 07550, loss = 39.4913
2024-10-31 00:51:30: [2024-10-31 00:51:30] iter = 07560, loss = 28.1068
2024-10-31 00:51:33: [2024-10-31 00:51:33] iter = 07570, loss = 22.0539
2024-10-31 00:51:38: [2024-10-31 00:51:38] iter = 07580, loss = 38.9147
2024-10-31 00:51:41: [2024-10-31 00:51:41] iter = 07590, loss = 17.9065
2024-10-31 00:51:44: [2024-10-31 00:51:44] iter = 07600, loss = 32.2725
2024-10-31 00:51:46: [2024-10-31 00:51:46] iter = 07610, loss = 4.7506
2024-10-31 00:51:49: [2024-10-31 00:51:49] iter = 07620, loss = 33.6170
2024-10-31 00:51:51: [2024-10-31 00:51:51] iter = 07630, loss = 3.4132
2024-10-31 00:51:53: [2024-10-31 00:51:53] iter = 07640, loss = 55.8109
2024-10-31 00:51:57: [2024-10-31 00:51:57] iter = 07650, loss = 3.9915
2024-10-31 00:52:00: [2024-10-31 00:52:00] iter = 07660, loss = 4.9158
2024-10-31 00:52:03: [2024-10-31 00:52:03] iter = 07670, loss = 36.2472
2024-10-31 00:52:07: [2024-10-31 00:52:07] iter = 07680, loss = 35.6304
2024-10-31 00:52:10: [2024-10-31 00:52:10] iter = 07690, loss = 23.7312
2024-10-31 00:52:14: [2024-10-31 00:52:14] iter = 07700, loss = 11.4366
2024-10-31 00:52:18: [2024-10-31 00:52:18] iter = 07710, loss = 5.7458
2024-10-31 00:52:21: [2024-10-31 00:52:21] iter = 07720, loss = 25.5316
2024-10-31 00:52:24: [2024-10-31 00:52:24] iter = 07730, loss = 40.2689
2024-10-31 00:52:26: [2024-10-31 00:52:26] iter = 07740, loss = 31.2364
2024-10-31 00:52:29: [2024-10-31 00:52:29] iter = 07750, loss = 5.8721
2024-10-31 00:52:32: [2024-10-31 00:52:32] iter = 07760, loss = 22.7061
2024-10-31 00:52:36: [2024-10-31 00:52:36] iter = 07770, loss = 3.8250
2024-10-31 00:52:40: [2024-10-31 00:52:40] iter = 07780, loss = 5.6601
2024-10-31 00:52:43: [2024-10-31 00:52:43] iter = 07790, loss = 15.9007
2024-10-31 00:52:46: [2024-10-31 00:52:46] iter = 07800, loss = 23.5689
2024-10-31 00:52:50: [2024-10-31 00:52:50] iter = 07810, loss = 3.4108
2024-10-31 00:52:55: [2024-10-31 00:52:55] iter = 07820, loss = 60.6420
2024-10-31 00:53:00: [2024-10-31 00:53:00] iter = 07830, loss = 59.6517
2024-10-31 00:53:03: [2024-10-31 00:53:03] iter = 07840, loss = 33.8184
2024-10-31 00:53:06: [2024-10-31 00:53:06] iter = 07850, loss = 16.8988
2024-10-31 00:53:08: [2024-10-31 00:53:08] iter = 07860, loss = 51.2883
2024-10-31 00:53:12: [2024-10-31 00:53:12] iter = 07870, loss = 8.2598
2024-10-31 00:53:16: [2024-10-31 00:53:16] iter = 07880, loss = 42.3385
2024-10-31 00:53:19: [2024-10-31 00:53:19] iter = 07890, loss = 21.8075
2024-10-31 00:53:22: [2024-10-31 00:53:22] iter = 07900, loss = 24.5417
2024-10-31 00:53:25: [2024-10-31 00:53:25] iter = 07910, loss = 5.6832
2024-10-31 00:53:28: [2024-10-31 00:53:28] iter = 07920, loss = 6.0121
2024-10-31 00:53:32: [2024-10-31 00:53:32] iter = 07930, loss = 5.2141
2024-10-31 00:53:35: [2024-10-31 00:53:35] iter = 07940, loss = 10.1398
2024-10-31 00:53:38: [2024-10-31 00:53:38] iter = 07950, loss = 51.4104
2024-10-31 00:53:42: [2024-10-31 00:53:42] iter = 07960, loss = 21.5834
2024-10-31 00:53:46: [2024-10-31 00:53:46] iter = 07970, loss = 32.3252
2024-10-31 00:53:49: [2024-10-31 00:53:49] iter = 07980, loss = 37.8814
2024-10-31 00:53:53: [2024-10-31 00:53:53] iter = 07990, loss = 66.2772
2024-10-31 00:53:56: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 8000
2024-10-31 00:53:56: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 00:53:56: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 36482}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:56:04: Evaluate 5 random ConvNet, ACCmean = 0.3008 ACCstd = 0.0086
-------------------------
2024-10-31 00:56:04: Evaluate 5 random ConvNet, SENmean = 0.2900 SENstd = 0.0025
-------------------------
2024-10-31 00:56:04: Evaluate 5 random ConvNet, SPEmean = 0.9021 SPEstd = 0.0008
-------------------------
2024-10-31 00:56:04: Evaluate 5 random ConvNet, F!mean = 0.2499 F!std = 0.0047
-------------------------
2024-10-31 00:56:04: Evaluate 5 random ConvNet, mean = 0.3008 std = 0.0086
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:56:05: [2024-10-31 00:56:05] iter = 08000, loss = 4.4234
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 00:56:09: [2024-10-31 00:56:09] iter = 08010, loss = 4.8679
2024-10-31 00:56:13: [2024-10-31 00:56:13] iter = 08020, loss = 3.8598
2024-10-31 00:56:17: [2024-10-31 00:56:17] iter = 08030, loss = 52.4281
2024-10-31 00:56:20: [2024-10-31 00:56:20] iter = 08040, loss = 31.8160
2024-10-31 00:56:23: [2024-10-31 00:56:23] iter = 08050, loss = 8.1011
2024-10-31 00:56:26: [2024-10-31 00:56:26] iter = 08060, loss = 13.0522
2024-10-31 00:56:30: [2024-10-31 00:56:30] iter = 08070, loss = 4.7547
2024-10-31 00:56:35: [2024-10-31 00:56:35] iter = 08080, loss = 4.6363
2024-10-31 00:56:38: [2024-10-31 00:56:38] iter = 08090, loss = 49.6666
2024-10-31 00:56:43: [2024-10-31 00:56:43] iter = 08100, loss = 4.5607
2024-10-31 00:56:47: [2024-10-31 00:56:47] iter = 08110, loss = 41.5956
2024-10-31 00:56:50: [2024-10-31 00:56:50] iter = 08120, loss = 6.4451
2024-10-31 00:56:51: [2024-10-31 00:56:51] iter = 08130, loss = 4.3691
2024-10-31 00:56:53: [2024-10-31 00:56:53] iter = 08140, loss = 18.7824
2024-10-31 00:56:56: [2024-10-31 00:56:56] iter = 08150, loss = 10.0162
2024-10-31 00:57:00: [2024-10-31 00:57:00] iter = 08160, loss = 14.2489
2024-10-31 00:57:04: [2024-10-31 00:57:04] iter = 08170, loss = 27.4714
2024-10-31 00:57:07: [2024-10-31 00:57:07] iter = 08180, loss = 4.6021
2024-10-31 00:57:11: [2024-10-31 00:57:11] iter = 08190, loss = 21.5683
2024-10-31 00:57:15: [2024-10-31 00:57:15] iter = 08200, loss = 31.2953
2024-10-31 00:57:18: [2024-10-31 00:57:18] iter = 08210, loss = 6.6338
2024-10-31 00:57:22: [2024-10-31 00:57:22] iter = 08220, loss = 5.1179
2024-10-31 00:57:25: [2024-10-31 00:57:25] iter = 08230, loss = 39.8125
2024-10-31 00:57:28: [2024-10-31 00:57:28] iter = 08240, loss = 70.9236
2024-10-31 00:57:30: [2024-10-31 00:57:30] iter = 08250, loss = 5.9296
2024-10-31 00:57:34: [2024-10-31 00:57:34] iter = 08260, loss = 5.9603
2024-10-31 00:57:36: [2024-10-31 00:57:36] iter = 08270, loss = 4.5663
2024-10-31 00:57:40: [2024-10-31 00:57:40] iter = 08280, loss = 23.5261
2024-10-31 00:57:44: [2024-10-31 00:57:44] iter = 08290, loss = 38.1927
2024-10-31 00:57:48: [2024-10-31 00:57:48] iter = 08300, loss = 10.3706
2024-10-31 00:57:52: [2024-10-31 00:57:52] iter = 08310, loss = 13.4914
2024-10-31 00:57:55: [2024-10-31 00:57:55] iter = 08320, loss = 5.3812
2024-10-31 00:57:58: [2024-10-31 00:57:58] iter = 08330, loss = 3.5839
2024-10-31 00:58:01: [2024-10-31 00:58:01] iter = 08340, loss = 3.9242
2024-10-31 00:58:03: [2024-10-31 00:58:03] iter = 08350, loss = 15.0188
2024-10-31 00:58:07: [2024-10-31 00:58:07] iter = 08360, loss = 27.2123
2024-10-31 00:58:10: [2024-10-31 00:58:10] iter = 08370, loss = 4.0281
2024-10-31 00:58:13: [2024-10-31 00:58:13] iter = 08380, loss = 5.6435
2024-10-31 00:58:17: [2024-10-31 00:58:17] iter = 08390, loss = 9.9737
2024-10-31 00:58:20: [2024-10-31 00:58:20] iter = 08400, loss = 28.0410
2024-10-31 00:58:23: [2024-10-31 00:58:23] iter = 08410, loss = 4.5477
2024-10-31 00:58:25: [2024-10-31 00:58:25] iter = 08420, loss = 9.8457
2024-10-31 00:58:29: [2024-10-31 00:58:29] iter = 08430, loss = 4.0252
2024-10-31 00:58:32: [2024-10-31 00:58:32] iter = 08440, loss = 4.3602
2024-10-31 00:58:37: [2024-10-31 00:58:37] iter = 08450, loss = 8.0740
2024-10-31 00:58:41: [2024-10-31 00:58:41] iter = 08460, loss = 25.3722
2024-10-31 00:58:44: [2024-10-31 00:58:44] iter = 08470, loss = 16.6703
2024-10-31 00:58:47: [2024-10-31 00:58:47] iter = 08480, loss = 6.0725
2024-10-31 00:58:51: [2024-10-31 00:58:51] iter = 08490, loss = 18.9558
2024-10-31 00:58:54: [2024-10-31 00:58:54] iter = 08500, loss = 10.9891
2024-10-31 00:58:58: [2024-10-31 00:58:58] iter = 08510, loss = 23.3319
2024-10-31 00:59:01: [2024-10-31 00:59:01] iter = 08520, loss = 45.2945
2024-10-31 00:59:05: [2024-10-31 00:59:05] iter = 08530, loss = 9.9899
2024-10-31 00:59:09: [2024-10-31 00:59:09] iter = 08540, loss = 12.9001
2024-10-31 00:59:12: [2024-10-31 00:59:12] iter = 08550, loss = 28.9979
2024-10-31 00:59:15: [2024-10-31 00:59:15] iter = 08560, loss = 5.3814
2024-10-31 00:59:18: [2024-10-31 00:59:18] iter = 08570, loss = 24.4691
2024-10-31 00:59:21: [2024-10-31 00:59:21] iter = 08580, loss = 6.0158
2024-10-31 00:59:25: [2024-10-31 00:59:25] iter = 08590, loss = 6.4832
2024-10-31 00:59:28: [2024-10-31 00:59:28] iter = 08600, loss = 4.0365
2024-10-31 00:59:32: [2024-10-31 00:59:32] iter = 08610, loss = 32.5500
2024-10-31 00:59:36: [2024-10-31 00:59:36] iter = 08620, loss = 8.9139
2024-10-31 00:59:38: [2024-10-31 00:59:38] iter = 08630, loss = 4.1860
2024-10-31 00:59:40: [2024-10-31 00:59:40] iter = 08640, loss = 4.8470
2024-10-31 00:59:43: [2024-10-31 00:59:43] iter = 08650, loss = 4.0479
2024-10-31 00:59:46: [2024-10-31 00:59:46] iter = 08660, loss = 8.9883
2024-10-31 00:59:49: [2024-10-31 00:59:49] iter = 08670, loss = 4.3643
2024-10-31 00:59:52: [2024-10-31 00:59:52] iter = 08680, loss = 12.1322
2024-10-31 00:59:55: [2024-10-31 00:59:55] iter = 08690, loss = 10.5878
2024-10-31 00:59:58: [2024-10-31 00:59:58] iter = 08700, loss = 5.8907
2024-10-31 01:00:02: [2024-10-31 01:00:02] iter = 08710, loss = 14.3424
2024-10-31 01:00:05: [2024-10-31 01:00:05] iter = 08720, loss = 19.9562
2024-10-31 01:00:07: [2024-10-31 01:00:07] iter = 08730, loss = 4.6077
2024-10-31 01:00:10: [2024-10-31 01:00:10] iter = 08740, loss = 5.8894
2024-10-31 01:00:13: [2024-10-31 01:00:13] iter = 08750, loss = 13.7072
2024-10-31 01:00:15: [2024-10-31 01:00:15] iter = 08760, loss = 13.0323
2024-10-31 01:00:18: [2024-10-31 01:00:18] iter = 08770, loss = 4.4055
2024-10-31 01:00:20: [2024-10-31 01:00:20] iter = 08780, loss = 3.8306
2024-10-31 01:00:22: [2024-10-31 01:00:22] iter = 08790, loss = 6.1938
2024-10-31 01:00:25: [2024-10-31 01:00:25] iter = 08800, loss = 4.2916
2024-10-31 01:00:29: [2024-10-31 01:00:29] iter = 08810, loss = 13.4864
2024-10-31 01:00:32: [2024-10-31 01:00:32] iter = 08820, loss = 23.5281
2024-10-31 01:00:35: [2024-10-31 01:00:35] iter = 08830, loss = 90.3028
2024-10-31 01:00:38: [2024-10-31 01:00:38] iter = 08840, loss = 37.2579
2024-10-31 01:00:41: [2024-10-31 01:00:41] iter = 08850, loss = 13.1797
2024-10-31 01:00:44: [2024-10-31 01:00:44] iter = 08860, loss = 6.2883
2024-10-31 01:00:47: [2024-10-31 01:00:47] iter = 08870, loss = 4.6703
2024-10-31 01:00:51: [2024-10-31 01:00:51] iter = 08880, loss = 72.4670
2024-10-31 01:00:55: [2024-10-31 01:00:55] iter = 08890, loss = 53.4768
2024-10-31 01:00:57: [2024-10-31 01:00:57] iter = 08900, loss = 6.1689
2024-10-31 01:01:01: [2024-10-31 01:01:01] iter = 08910, loss = 17.5363
2024-10-31 01:01:05: [2024-10-31 01:01:05] iter = 08920, loss = 5.4748
2024-10-31 01:01:08: [2024-10-31 01:01:08] iter = 08930, loss = 73.0765
2024-10-31 01:01:12: [2024-10-31 01:01:12] iter = 08940, loss = 6.7803
2024-10-31 01:01:16: [2024-10-31 01:01:16] iter = 08950, loss = 9.4847
2024-10-31 01:01:19: [2024-10-31 01:01:19] iter = 08960, loss = 7.3577
2024-10-31 01:01:23: [2024-10-31 01:01:23] iter = 08970, loss = 5.7361
2024-10-31 01:01:26: [2024-10-31 01:01:26] iter = 08980, loss = 4.5803
2024-10-31 01:01:30: [2024-10-31 01:01:30] iter = 08990, loss = 12.9047
2024-10-31 01:01:33: [2024-10-31 01:01:33] iter = 09000, loss = 9.8112
2024-10-31 01:01:37: [2024-10-31 01:01:37] iter = 09010, loss = 23.6102
2024-10-31 01:01:40: [2024-10-31 01:01:40] iter = 09020, loss = 5.7955
2024-10-31 01:01:43: [2024-10-31 01:01:43] iter = 09030, loss = 4.8099
2024-10-31 01:01:46: [2024-10-31 01:01:46] iter = 09040, loss = 23.3830
2024-10-31 01:01:50: [2024-10-31 01:01:50] iter = 09050, loss = 40.9078
2024-10-31 01:01:54: [2024-10-31 01:01:54] iter = 09060, loss = 28.7320
2024-10-31 01:01:57: [2024-10-31 01:01:57] iter = 09070, loss = 6.2460
2024-10-31 01:02:00: [2024-10-31 01:02:00] iter = 09080, loss = 6.9538
2024-10-31 01:02:02: [2024-10-31 01:02:02] iter = 09090, loss = 39.8894
2024-10-31 01:02:06: [2024-10-31 01:02:06] iter = 09100, loss = 61.1821
2024-10-31 01:02:09: [2024-10-31 01:02:09] iter = 09110, loss = 7.5463
2024-10-31 01:02:13: [2024-10-31 01:02:13] iter = 09120, loss = 11.0249
2024-10-31 01:02:17: [2024-10-31 01:02:17] iter = 09130, loss = 14.7313
2024-10-31 01:02:20: [2024-10-31 01:02:20] iter = 09140, loss = 11.8525
2024-10-31 01:02:23: [2024-10-31 01:02:23] iter = 09150, loss = 5.4196
2024-10-31 01:02:26: [2024-10-31 01:02:26] iter = 09160, loss = 21.3411
2024-10-31 01:02:30: [2024-10-31 01:02:30] iter = 09170, loss = 25.1634
2024-10-31 01:02:33: [2024-10-31 01:02:33] iter = 09180, loss = 23.6350
2024-10-31 01:02:36: [2024-10-31 01:02:36] iter = 09190, loss = 4.4097
2024-10-31 01:02:39: [2024-10-31 01:02:39] iter = 09200, loss = 13.8798
2024-10-31 01:02:43: [2024-10-31 01:02:43] iter = 09210, loss = 22.3929
2024-10-31 01:02:47: [2024-10-31 01:02:47] iter = 09220, loss = 15.3691
2024-10-31 01:02:50: [2024-10-31 01:02:50] iter = 09230, loss = 6.1243
2024-10-31 01:02:54: [2024-10-31 01:02:54] iter = 09240, loss = 33.7366
2024-10-31 01:02:58: [2024-10-31 01:02:58] iter = 09250, loss = 4.9389
2024-10-31 01:03:02: [2024-10-31 01:03:02] iter = 09260, loss = 4.0188
2024-10-31 01:03:05: [2024-10-31 01:03:05] iter = 09270, loss = 13.0304
2024-10-31 01:03:09: [2024-10-31 01:03:09] iter = 09280, loss = 9.8062
2024-10-31 01:03:12: [2024-10-31 01:03:12] iter = 09290, loss = 10.5313
2024-10-31 01:03:15: [2024-10-31 01:03:15] iter = 09300, loss = 22.9646
2024-10-31 01:03:19: [2024-10-31 01:03:19] iter = 09310, loss = 8.2449
2024-10-31 01:03:22: [2024-10-31 01:03:22] iter = 09320, loss = 20.5766
2024-10-31 01:03:25: [2024-10-31 01:03:25] iter = 09330, loss = 61.5584
2024-10-31 01:03:28: [2024-10-31 01:03:28] iter = 09340, loss = 14.0360
2024-10-31 01:03:31: [2024-10-31 01:03:31] iter = 09350, loss = 5.2918
2024-10-31 01:03:35: [2024-10-31 01:03:35] iter = 09360, loss = 14.2856
2024-10-31 01:03:38: [2024-10-31 01:03:38] iter = 09370, loss = 51.1013
2024-10-31 01:03:41: [2024-10-31 01:03:41] iter = 09380, loss = 19.2476
2024-10-31 01:03:45: [2024-10-31 01:03:45] iter = 09390, loss = 15.8600
2024-10-31 01:03:48: [2024-10-31 01:03:48] iter = 09400, loss = 6.4010
2024-10-31 01:03:52: [2024-10-31 01:03:52] iter = 09410, loss = 19.3530
2024-10-31 01:03:56: [2024-10-31 01:03:56] iter = 09420, loss = 30.4709
2024-10-31 01:03:59: [2024-10-31 01:03:59] iter = 09430, loss = 18.2769
2024-10-31 01:04:03: [2024-10-31 01:04:03] iter = 09440, loss = 43.1455
2024-10-31 01:04:07: [2024-10-31 01:04:07] iter = 09450, loss = 6.3330
2024-10-31 01:04:11: [2024-10-31 01:04:11] iter = 09460, loss = 14.1463
2024-10-31 01:04:14: [2024-10-31 01:04:14] iter = 09470, loss = 34.3480
2024-10-31 01:04:17: [2024-10-31 01:04:17] iter = 09480, loss = 3.9500
2024-10-31 01:04:20: [2024-10-31 01:04:20] iter = 09490, loss = 3.6037
2024-10-31 01:04:23: [2024-10-31 01:04:23] iter = 09500, loss = 23.9520
2024-10-31 01:04:27: [2024-10-31 01:04:27] iter = 09510, loss = 11.4081
2024-10-31 01:04:31: [2024-10-31 01:04:31] iter = 09520, loss = 8.8733
2024-10-31 01:04:35: [2024-10-31 01:04:35] iter = 09530, loss = 3.4778
2024-10-31 01:04:38: [2024-10-31 01:04:38] iter = 09540, loss = 3.9891
2024-10-31 01:04:40: [2024-10-31 01:04:40] iter = 09550, loss = 20.1786
2024-10-31 01:04:43: [2024-10-31 01:04:43] iter = 09560, loss = 5.9142
2024-10-31 01:04:47: [2024-10-31 01:04:47] iter = 09570, loss = 9.2902
2024-10-31 01:04:49: [2024-10-31 01:04:49] iter = 09580, loss = 17.2601
2024-10-31 01:04:53: [2024-10-31 01:04:53] iter = 09590, loss = 8.7134
2024-10-31 01:04:56: [2024-10-31 01:04:56] iter = 09600, loss = 17.4305
2024-10-31 01:04:59: [2024-10-31 01:04:59] iter = 09610, loss = 18.6133
2024-10-31 01:05:03: [2024-10-31 01:05:03] iter = 09620, loss = 37.6500
2024-10-31 01:05:07: [2024-10-31 01:05:07] iter = 09630, loss = 3.7469
2024-10-31 01:05:11: [2024-10-31 01:05:11] iter = 09640, loss = 42.6063
2024-10-31 01:05:13: [2024-10-31 01:05:13] iter = 09650, loss = 17.2478
2024-10-31 01:05:16: [2024-10-31 01:05:16] iter = 09660, loss = 3.3926
2024-10-31 01:05:19: [2024-10-31 01:05:19] iter = 09670, loss = 5.3392
2024-10-31 01:05:22: [2024-10-31 01:05:22] iter = 09680, loss = 5.4673
2024-10-31 01:05:26: [2024-10-31 01:05:26] iter = 09690, loss = 4.7228
2024-10-31 01:05:30: [2024-10-31 01:05:30] iter = 09700, loss = 42.3111
2024-10-31 01:05:34: [2024-10-31 01:05:34] iter = 09710, loss = 5.4064
2024-10-31 01:05:37: [2024-10-31 01:05:37] iter = 09720, loss = 18.1150
2024-10-31 01:05:40: [2024-10-31 01:05:40] iter = 09730, loss = 10.6241
2024-10-31 01:05:43: [2024-10-31 01:05:43] iter = 09740, loss = 4.1877
2024-10-31 01:05:47: [2024-10-31 01:05:47] iter = 09750, loss = 6.7131
2024-10-31 01:05:49: [2024-10-31 01:05:49] iter = 09760, loss = 10.4305
2024-10-31 01:05:52: [2024-10-31 01:05:52] iter = 09770, loss = 44.6802
2024-10-31 01:05:56: [2024-10-31 01:05:56] iter = 09780, loss = 57.5041
2024-10-31 01:05:59: [2024-10-31 01:05:59] iter = 09790, loss = 12.9131
2024-10-31 01:06:03: [2024-10-31 01:06:03] iter = 09800, loss = 4.5804
2024-10-31 01:06:06: [2024-10-31 01:06:06] iter = 09810, loss = 3.4976
2024-10-31 01:06:09: [2024-10-31 01:06:09] iter = 09820, loss = 39.5056
2024-10-31 01:06:13: [2024-10-31 01:06:13] iter = 09830, loss = 29.1586
2024-10-31 01:06:16: [2024-10-31 01:06:16] iter = 09840, loss = 59.3027
2024-10-31 01:06:19: [2024-10-31 01:06:19] iter = 09850, loss = 4.0762
2024-10-31 01:06:23: [2024-10-31 01:06:23] iter = 09860, loss = 23.4002
2024-10-31 01:06:27: [2024-10-31 01:06:27] iter = 09870, loss = 6.1136
2024-10-31 01:06:30: [2024-10-31 01:06:30] iter = 09880, loss = 37.6344
2024-10-31 01:06:33: [2024-10-31 01:06:33] iter = 09890, loss = 76.5196
2024-10-31 01:06:37: [2024-10-31 01:06:37] iter = 09900, loss = 14.0833
2024-10-31 01:06:40: [2024-10-31 01:06:40] iter = 09910, loss = 29.6292
2024-10-31 01:06:43: [2024-10-31 01:06:43] iter = 09920, loss = 32.3370
2024-10-31 01:06:45: [2024-10-31 01:06:45] iter = 09930, loss = 29.5617
2024-10-31 01:06:48: [2024-10-31 01:06:48] iter = 09940, loss = 4.9341
2024-10-31 01:06:52: [2024-10-31 01:06:52] iter = 09950, loss = 17.9771
2024-10-31 01:06:56: [2024-10-31 01:06:56] iter = 09960, loss = 67.5730
2024-10-31 01:06:59: [2024-10-31 01:06:59] iter = 09970, loss = 4.2638
2024-10-31 01:07:03: [2024-10-31 01:07:03] iter = 09980, loss = 55.5115
2024-10-31 01:07:06: [2024-10-31 01:07:06] iter = 09990, loss = 5.8078
2024-10-31 01:07:09: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 10000
2024-10-31 01:07:09: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:07:09: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 29504}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:09:17: Evaluate 5 random ConvNet, ACCmean = 0.3988 ACCstd = 0.0027
-------------------------
2024-10-31 01:09:17: Evaluate 5 random ConvNet, SENmean = 0.3166 SENstd = 0.0036
-------------------------
2024-10-31 01:09:17: Evaluate 5 random ConvNet, SPEmean = 0.9113 SPEstd = 0.0004
-------------------------
2024-10-31 01:09:17: Evaluate 5 random ConvNet, F!mean = 0.3034 F!std = 0.0025
-------------------------
2024-10-31 01:09:17: Evaluate 5 random ConvNet, mean = 0.3988 std = 0.0027
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:09:17: [2024-10-31 01:09:17] iter = 10000, loss = 4.3831
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:09:21: [2024-10-31 01:09:21] iter = 10010, loss = 4.7111
2024-10-31 01:09:25: [2024-10-31 01:09:25] iter = 10020, loss = 5.2696
2024-10-31 01:09:28: [2024-10-31 01:09:28] iter = 10030, loss = 13.3075
2024-10-31 01:09:31: [2024-10-31 01:09:31] iter = 10040, loss = 7.0046
2024-10-31 01:09:33: [2024-10-31 01:09:33] iter = 10050, loss = 17.0691
2024-10-31 01:09:37: [2024-10-31 01:09:37] iter = 10060, loss = 5.1854
2024-10-31 01:09:40: [2024-10-31 01:09:40] iter = 10070, loss = 4.2104
2024-10-31 01:09:44: [2024-10-31 01:09:44] iter = 10080, loss = 10.1189
2024-10-31 01:09:47: [2024-10-31 01:09:47] iter = 10090, loss = 5.1271
2024-10-31 01:09:50: [2024-10-31 01:09:50] iter = 10100, loss = 50.5104
2024-10-31 01:09:52: [2024-10-31 01:09:52] iter = 10110, loss = 5.4425
2024-10-31 01:09:54: [2024-10-31 01:09:54] iter = 10120, loss = 25.1887
2024-10-31 01:09:58: [2024-10-31 01:09:58] iter = 10130, loss = 10.4261
2024-10-31 01:10:01: [2024-10-31 01:10:01] iter = 10140, loss = 28.5403
2024-10-31 01:10:04: [2024-10-31 01:10:04] iter = 10150, loss = 15.1686
2024-10-31 01:10:08: [2024-10-31 01:10:08] iter = 10160, loss = 16.9237
2024-10-31 01:10:11: [2024-10-31 01:10:11] iter = 10170, loss = 33.5968
2024-10-31 01:10:14: [2024-10-31 01:10:14] iter = 10180, loss = 20.0525
2024-10-31 01:10:17: [2024-10-31 01:10:17] iter = 10190, loss = 8.3807
2024-10-31 01:10:20: [2024-10-31 01:10:20] iter = 10200, loss = 4.1844
2024-10-31 01:10:23: [2024-10-31 01:10:23] iter = 10210, loss = 10.6673
2024-10-31 01:10:26: [2024-10-31 01:10:26] iter = 10220, loss = 19.5505
2024-10-31 01:10:30: [2024-10-31 01:10:30] iter = 10230, loss = 10.5216
2024-10-31 01:10:33: [2024-10-31 01:10:33] iter = 10240, loss = 12.2768
2024-10-31 01:10:37: [2024-10-31 01:10:37] iter = 10250, loss = 35.3912
2024-10-31 01:10:42: [2024-10-31 01:10:42] iter = 10260, loss = 23.6297
2024-10-31 01:10:45: [2024-10-31 01:10:45] iter = 10270, loss = 11.8804
2024-10-31 01:10:50: [2024-10-31 01:10:50] iter = 10280, loss = 65.6459
2024-10-31 01:10:53: [2024-10-31 01:10:53] iter = 10290, loss = 24.5024
2024-10-31 01:10:57: [2024-10-31 01:10:57] iter = 10300, loss = 5.0612
2024-10-31 01:11:01: [2024-10-31 01:11:01] iter = 10310, loss = 4.7417
2024-10-31 01:11:05: [2024-10-31 01:11:05] iter = 10320, loss = 19.1553
2024-10-31 01:11:09: [2024-10-31 01:11:09] iter = 10330, loss = 12.5173
2024-10-31 01:11:13: [2024-10-31 01:11:13] iter = 10340, loss = 8.4360
2024-10-31 01:11:16: [2024-10-31 01:11:16] iter = 10350, loss = 3.9133
2024-10-31 01:11:20: [2024-10-31 01:11:20] iter = 10360, loss = 4.9986
2024-10-31 01:11:23: [2024-10-31 01:11:23] iter = 10370, loss = 39.4784
2024-10-31 01:11:27: [2024-10-31 01:11:27] iter = 10380, loss = 10.1462
2024-10-31 01:11:30: [2024-10-31 01:11:30] iter = 10390, loss = 15.4086
2024-10-31 01:11:34: [2024-10-31 01:11:34] iter = 10400, loss = 19.0932
2024-10-31 01:11:36: [2024-10-31 01:11:36] iter = 10410, loss = 15.0403
2024-10-31 01:11:40: [2024-10-31 01:11:40] iter = 10420, loss = 61.7569
2024-10-31 01:11:44: [2024-10-31 01:11:44] iter = 10430, loss = 30.7149
2024-10-31 01:11:47: [2024-10-31 01:11:47] iter = 10440, loss = 44.8318
2024-10-31 01:11:51: [2024-10-31 01:11:51] iter = 10450, loss = 8.8385
2024-10-31 01:11:54: [2024-10-31 01:11:54] iter = 10460, loss = 42.2750
2024-10-31 01:11:57: [2024-10-31 01:11:57] iter = 10470, loss = 9.8532
2024-10-31 01:12:00: [2024-10-31 01:12:00] iter = 10480, loss = 5.0131
2024-10-31 01:12:04: [2024-10-31 01:12:04] iter = 10490, loss = 63.5494
2024-10-31 01:12:07: [2024-10-31 01:12:07] iter = 10500, loss = 40.5677
2024-10-31 01:12:11: [2024-10-31 01:12:11] iter = 10510, loss = 20.4114
2024-10-31 01:12:15: [2024-10-31 01:12:15] iter = 10520, loss = 58.4140
2024-10-31 01:12:19: [2024-10-31 01:12:19] iter = 10530, loss = 33.5774
2024-10-31 01:12:22: [2024-10-31 01:12:22] iter = 10540, loss = 13.8143
2024-10-31 01:12:25: [2024-10-31 01:12:25] iter = 10550, loss = 4.2880
2024-10-31 01:12:29: [2024-10-31 01:12:29] iter = 10560, loss = 13.8395
2024-10-31 01:12:33: [2024-10-31 01:12:33] iter = 10570, loss = 23.0295
2024-10-31 01:12:38: [2024-10-31 01:12:38] iter = 10580, loss = 3.7543
2024-10-31 01:12:40: [2024-10-31 01:12:40] iter = 10590, loss = 43.1624
2024-10-31 01:12:43: [2024-10-31 01:12:43] iter = 10600, loss = 6.9983
2024-10-31 01:12:46: [2024-10-31 01:12:46] iter = 10610, loss = 42.2249
2024-10-31 01:12:50: [2024-10-31 01:12:50] iter = 10620, loss = 8.9301
2024-10-31 01:12:52: [2024-10-31 01:12:52] iter = 10630, loss = 40.2573
2024-10-31 01:12:55: [2024-10-31 01:12:55] iter = 10640, loss = 40.9913
2024-10-31 01:12:58: [2024-10-31 01:12:58] iter = 10650, loss = 8.9150
2024-10-31 01:13:00: [2024-10-31 01:13:00] iter = 10660, loss = 3.8297
2024-10-31 01:13:02: [2024-10-31 01:13:02] iter = 10670, loss = 3.9908
2024-10-31 01:13:06: [2024-10-31 01:13:06] iter = 10680, loss = 15.0665
2024-10-31 01:13:10: [2024-10-31 01:13:10] iter = 10690, loss = 27.9083
2024-10-31 01:13:14: [2024-10-31 01:13:14] iter = 10700, loss = 3.6971
2024-10-31 01:13:16: [2024-10-31 01:13:16] iter = 10710, loss = 16.3990
2024-10-31 01:13:18: [2024-10-31 01:13:18] iter = 10720, loss = 50.2920
2024-10-31 01:13:21: [2024-10-31 01:13:21] iter = 10730, loss = 21.4896
2024-10-31 01:13:23: [2024-10-31 01:13:23] iter = 10740, loss = 32.7540
2024-10-31 01:13:27: [2024-10-31 01:13:27] iter = 10750, loss = 26.4965
2024-10-31 01:13:31: [2024-10-31 01:13:31] iter = 10760, loss = 17.0760
2024-10-31 01:13:35: [2024-10-31 01:13:35] iter = 10770, loss = 13.8002
2024-10-31 01:13:39: [2024-10-31 01:13:39] iter = 10780, loss = 4.7330
2024-10-31 01:13:43: [2024-10-31 01:13:43] iter = 10790, loss = 40.6540
2024-10-31 01:13:47: [2024-10-31 01:13:47] iter = 10800, loss = 38.1688
2024-10-31 01:13:52: [2024-10-31 01:13:52] iter = 10810, loss = 4.7928
2024-10-31 01:13:56: [2024-10-31 01:13:56] iter = 10820, loss = 7.8551
2024-10-31 01:14:00: [2024-10-31 01:14:00] iter = 10830, loss = 9.8510
2024-10-31 01:14:03: [2024-10-31 01:14:03] iter = 10840, loss = 46.7429
2024-10-31 01:14:05: [2024-10-31 01:14:05] iter = 10850, loss = 13.0838
2024-10-31 01:14:07: [2024-10-31 01:14:07] iter = 10860, loss = 5.8257
2024-10-31 01:14:10: [2024-10-31 01:14:10] iter = 10870, loss = 6.7921
2024-10-31 01:14:13: [2024-10-31 01:14:13] iter = 10880, loss = 44.1417
2024-10-31 01:14:16: [2024-10-31 01:14:16] iter = 10890, loss = 19.8976
2024-10-31 01:14:20: [2024-10-31 01:14:20] iter = 10900, loss = 43.6589
2024-10-31 01:14:24: [2024-10-31 01:14:24] iter = 10910, loss = 6.0520
2024-10-31 01:14:27: [2024-10-31 01:14:27] iter = 10920, loss = 49.7764
2024-10-31 01:14:30: [2024-10-31 01:14:30] iter = 10930, loss = 6.8349
2024-10-31 01:14:34: [2024-10-31 01:14:34] iter = 10940, loss = 14.5159
2024-10-31 01:14:36: [2024-10-31 01:14:36] iter = 10950, loss = 10.4165
2024-10-31 01:14:40: [2024-10-31 01:14:40] iter = 10960, loss = 11.9046
2024-10-31 01:14:44: [2024-10-31 01:14:44] iter = 10970, loss = 6.2836
2024-10-31 01:14:47: [2024-10-31 01:14:47] iter = 10980, loss = 25.5424
2024-10-31 01:14:50: [2024-10-31 01:14:50] iter = 10990, loss = 11.5490
2024-10-31 01:14:54: [2024-10-31 01:14:54] iter = 11000, loss = 3.3363
2024-10-31 01:14:57: [2024-10-31 01:14:57] iter = 11010, loss = 9.3627
2024-10-31 01:15:00: [2024-10-31 01:15:00] iter = 11020, loss = 27.2544
2024-10-31 01:15:04: [2024-10-31 01:15:04] iter = 11030, loss = 6.1434
2024-10-31 01:15:07: [2024-10-31 01:15:07] iter = 11040, loss = 11.4749
2024-10-31 01:15:11: [2024-10-31 01:15:11] iter = 11050, loss = 5.7024
2024-10-31 01:15:14: [2024-10-31 01:15:14] iter = 11060, loss = 26.1351
2024-10-31 01:15:18: [2024-10-31 01:15:18] iter = 11070, loss = 6.7940
2024-10-31 01:15:22: [2024-10-31 01:15:22] iter = 11080, loss = 12.3638
2024-10-31 01:15:26: [2024-10-31 01:15:26] iter = 11090, loss = 11.9204
2024-10-31 01:15:30: [2024-10-31 01:15:30] iter = 11100, loss = 16.8833
2024-10-31 01:15:33: [2024-10-31 01:15:33] iter = 11110, loss = 3.7685
2024-10-31 01:15:37: [2024-10-31 01:15:37] iter = 11120, loss = 17.7666
2024-10-31 01:15:40: [2024-10-31 01:15:40] iter = 11130, loss = 4.1391
2024-10-31 01:15:43: [2024-10-31 01:15:43] iter = 11140, loss = 16.7572
2024-10-31 01:15:47: [2024-10-31 01:15:47] iter = 11150, loss = 4.4982
2024-10-31 01:15:51: [2024-10-31 01:15:51] iter = 11160, loss = 10.8895
2024-10-31 01:15:54: [2024-10-31 01:15:54] iter = 11170, loss = 6.1385
2024-10-31 01:15:58: [2024-10-31 01:15:58] iter = 11180, loss = 46.3108
2024-10-31 01:16:01: [2024-10-31 01:16:01] iter = 11190, loss = 53.2723
2024-10-31 01:16:06: [2024-10-31 01:16:06] iter = 11200, loss = 4.1580
2024-10-31 01:16:10: [2024-10-31 01:16:10] iter = 11210, loss = 5.5131
2024-10-31 01:16:13: [2024-10-31 01:16:13] iter = 11220, loss = 6.2706
2024-10-31 01:16:17: [2024-10-31 01:16:17] iter = 11230, loss = 85.0193
2024-10-31 01:16:20: [2024-10-31 01:16:20] iter = 11240, loss = 26.4644
2024-10-31 01:16:23: [2024-10-31 01:16:23] iter = 11250, loss = 64.6233
2024-10-31 01:16:27: [2024-10-31 01:16:27] iter = 11260, loss = 12.9823
2024-10-31 01:16:30: [2024-10-31 01:16:30] iter = 11270, loss = 14.4941
2024-10-31 01:16:35: [2024-10-31 01:16:35] iter = 11280, loss = 6.4278
2024-10-31 01:16:38: [2024-10-31 01:16:38] iter = 11290, loss = 5.6479
2024-10-31 01:16:42: [2024-10-31 01:16:42] iter = 11300, loss = 52.9850
2024-10-31 01:16:47: [2024-10-31 01:16:47] iter = 11310, loss = 10.6284
2024-10-31 01:16:50: [2024-10-31 01:16:50] iter = 11320, loss = 30.7690
2024-10-31 01:16:54: [2024-10-31 01:16:54] iter = 11330, loss = 8.3039
2024-10-31 01:16:57: [2024-10-31 01:16:57] iter = 11340, loss = 6.0519
2024-10-31 01:17:00: [2024-10-31 01:17:00] iter = 11350, loss = 5.3371
2024-10-31 01:17:03: [2024-10-31 01:17:03] iter = 11360, loss = 17.4618
2024-10-31 01:17:06: [2024-10-31 01:17:06] iter = 11370, loss = 8.3040
2024-10-31 01:17:08: [2024-10-31 01:17:08] iter = 11380, loss = 55.5479
2024-10-31 01:17:10: [2024-10-31 01:17:10] iter = 11390, loss = 5.0458
2024-10-31 01:17:12: [2024-10-31 01:17:12] iter = 11400, loss = 52.0199
2024-10-31 01:17:15: [2024-10-31 01:17:15] iter = 11410, loss = 5.2230
2024-10-31 01:17:18: [2024-10-31 01:17:18] iter = 11420, loss = 22.0892
2024-10-31 01:17:22: [2024-10-31 01:17:22] iter = 11430, loss = 3.1975
2024-10-31 01:17:26: [2024-10-31 01:17:26] iter = 11440, loss = 5.1241
2024-10-31 01:17:29: [2024-10-31 01:17:29] iter = 11450, loss = 27.5974
2024-10-31 01:17:32: [2024-10-31 01:17:32] iter = 11460, loss = 11.3344
2024-10-31 01:17:35: [2024-10-31 01:17:35] iter = 11470, loss = 4.2701
2024-10-31 01:17:39: [2024-10-31 01:17:39] iter = 11480, loss = 42.2347
2024-10-31 01:17:42: [2024-10-31 01:17:42] iter = 11490, loss = 8.0946
2024-10-31 01:17:45: [2024-10-31 01:17:45] iter = 11500, loss = 4.4638
2024-10-31 01:17:48: [2024-10-31 01:17:48] iter = 11510, loss = 52.8710
2024-10-31 01:17:52: [2024-10-31 01:17:52] iter = 11520, loss = 11.4855
2024-10-31 01:17:56: [2024-10-31 01:17:56] iter = 11530, loss = 19.5304
2024-10-31 01:17:58: [2024-10-31 01:17:58] iter = 11540, loss = 5.0083
2024-10-31 01:18:02: [2024-10-31 01:18:02] iter = 11550, loss = 3.9876
2024-10-31 01:18:05: [2024-10-31 01:18:05] iter = 11560, loss = 57.6235
2024-10-31 01:18:09: [2024-10-31 01:18:09] iter = 11570, loss = 4.5855
2024-10-31 01:18:13: [2024-10-31 01:18:13] iter = 11580, loss = 44.1670
2024-10-31 01:18:18: [2024-10-31 01:18:18] iter = 11590, loss = 50.3460
2024-10-31 01:18:21: [2024-10-31 01:18:21] iter = 11600, loss = 37.6098
2024-10-31 01:18:24: [2024-10-31 01:18:24] iter = 11610, loss = 7.5341
2024-10-31 01:18:28: [2024-10-31 01:18:28] iter = 11620, loss = 10.7117
2024-10-31 01:18:32: [2024-10-31 01:18:32] iter = 11630, loss = 33.5696
2024-10-31 01:18:36: [2024-10-31 01:18:36] iter = 11640, loss = 25.8951
2024-10-31 01:18:40: [2024-10-31 01:18:40] iter = 11650, loss = 14.4810
2024-10-31 01:18:43: [2024-10-31 01:18:43] iter = 11660, loss = 40.9855
2024-10-31 01:18:46: [2024-10-31 01:18:46] iter = 11670, loss = 8.9353
2024-10-31 01:18:49: [2024-10-31 01:18:49] iter = 11680, loss = 5.9063
2024-10-31 01:18:52: [2024-10-31 01:18:52] iter = 11690, loss = 31.7164
2024-10-31 01:18:56: [2024-10-31 01:18:56] iter = 11700, loss = 23.9424
2024-10-31 01:19:00: [2024-10-31 01:19:00] iter = 11710, loss = 14.1426
2024-10-31 01:19:03: [2024-10-31 01:19:03] iter = 11720, loss = 31.9806
2024-10-31 01:19:08: [2024-10-31 01:19:08] iter = 11730, loss = 15.9650
2024-10-31 01:19:11: [2024-10-31 01:19:11] iter = 11740, loss = 4.9831
2024-10-31 01:19:15: [2024-10-31 01:19:15] iter = 11750, loss = 46.1102
2024-10-31 01:19:18: [2024-10-31 01:19:18] iter = 11760, loss = 6.3560
2024-10-31 01:19:22: [2024-10-31 01:19:22] iter = 11770, loss = 31.0949
2024-10-31 01:19:25: [2024-10-31 01:19:25] iter = 11780, loss = 29.3589
2024-10-31 01:19:28: [2024-10-31 01:19:28] iter = 11790, loss = 7.9205
2024-10-31 01:19:31: [2024-10-31 01:19:31] iter = 11800, loss = 23.5248
2024-10-31 01:19:35: [2024-10-31 01:19:35] iter = 11810, loss = 20.4987
2024-10-31 01:19:39: [2024-10-31 01:19:39] iter = 11820, loss = 87.9105
2024-10-31 01:19:41: [2024-10-31 01:19:41] iter = 11830, loss = 4.7840
2024-10-31 01:19:44: [2024-10-31 01:19:44] iter = 11840, loss = 37.4097
2024-10-31 01:19:47: [2024-10-31 01:19:47] iter = 11850, loss = 23.6470
2024-10-31 01:19:50: [2024-10-31 01:19:50] iter = 11860, loss = 5.8095
2024-10-31 01:19:54: [2024-10-31 01:19:54] iter = 11870, loss = 4.2946
2024-10-31 01:19:57: [2024-10-31 01:19:57] iter = 11880, loss = 10.9714
2024-10-31 01:20:01: [2024-10-31 01:20:01] iter = 11890, loss = 75.8797
2024-10-31 01:20:04: [2024-10-31 01:20:04] iter = 11900, loss = 4.3254
2024-10-31 01:20:07: [2024-10-31 01:20:07] iter = 11910, loss = 4.2884
2024-10-31 01:20:10: [2024-10-31 01:20:10] iter = 11920, loss = 15.5499
2024-10-31 01:20:13: [2024-10-31 01:20:13] iter = 11930, loss = 4.0805
2024-10-31 01:20:17: [2024-10-31 01:20:17] iter = 11940, loss = 21.3685
2024-10-31 01:20:19: [2024-10-31 01:20:19] iter = 11950, loss = 5.5448
2024-10-31 01:20:23: [2024-10-31 01:20:23] iter = 11960, loss = 13.0478
2024-10-31 01:20:27: [2024-10-31 01:20:27] iter = 11970, loss = 3.9865
2024-10-31 01:20:31: [2024-10-31 01:20:31] iter = 11980, loss = 20.2123
2024-10-31 01:20:34: [2024-10-31 01:20:34] iter = 11990, loss = 5.0887
2024-10-31 01:20:37: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 12000
2024-10-31 01:20:37: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:20:37: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 37030}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:22:40: Evaluate 5 random ConvNet, ACCmean = 0.4200 ACCstd = 0.0059
-------------------------
2024-10-31 01:22:40: Evaluate 5 random ConvNet, SENmean = 0.3076 SENstd = 0.0034
-------------------------
2024-10-31 01:22:40: Evaluate 5 random ConvNet, SPEmean = 0.9122 SPEstd = 0.0002
-------------------------
2024-10-31 01:22:40: Evaluate 5 random ConvNet, F!mean = 0.2873 F!std = 0.0036
-------------------------
2024-10-31 01:22:40: Evaluate 5 random ConvNet, mean = 0.4200 std = 0.0059
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:22:41: [2024-10-31 01:22:41] iter = 12000, loss = 12.0760
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:22:44: [2024-10-31 01:22:44] iter = 12010, loss = 16.9483
2024-10-31 01:22:47: [2024-10-31 01:22:47] iter = 12020, loss = 7.5407
2024-10-31 01:22:51: [2024-10-31 01:22:51] iter = 12030, loss = 27.9020
2024-10-31 01:22:55: [2024-10-31 01:22:55] iter = 12040, loss = 49.9230
2024-10-31 01:22:58: [2024-10-31 01:22:58] iter = 12050, loss = 7.2361
2024-10-31 01:23:01: [2024-10-31 01:23:01] iter = 12060, loss = 7.5695
2024-10-31 01:23:04: [2024-10-31 01:23:04] iter = 12070, loss = 6.3689
2024-10-31 01:23:07: [2024-10-31 01:23:07] iter = 12080, loss = 9.5222
2024-10-31 01:23:09: [2024-10-31 01:23:09] iter = 12090, loss = 34.6097
2024-10-31 01:23:12: [2024-10-31 01:23:12] iter = 12100, loss = 17.6549
2024-10-31 01:23:16: [2024-10-31 01:23:16] iter = 12110, loss = 45.9032
2024-10-31 01:23:20: [2024-10-31 01:23:20] iter = 12120, loss = 9.2896
2024-10-31 01:23:24: [2024-10-31 01:23:24] iter = 12130, loss = 4.5482
2024-10-31 01:23:27: [2024-10-31 01:23:27] iter = 12140, loss = 5.0717
2024-10-31 01:23:29: [2024-10-31 01:23:29] iter = 12150, loss = 4.2553
2024-10-31 01:23:33: [2024-10-31 01:23:33] iter = 12160, loss = 23.7546
2024-10-31 01:23:37: [2024-10-31 01:23:37] iter = 12170, loss = 42.8068
2024-10-31 01:23:41: [2024-10-31 01:23:41] iter = 12180, loss = 38.3480
2024-10-31 01:23:44: [2024-10-31 01:23:44] iter = 12190, loss = 6.6555
2024-10-31 01:23:47: [2024-10-31 01:23:47] iter = 12200, loss = 4.9594
2024-10-31 01:23:51: [2024-10-31 01:23:51] iter = 12210, loss = 16.3585
2024-10-31 01:23:54: [2024-10-31 01:23:54] iter = 12220, loss = 24.2983
2024-10-31 01:23:58: [2024-10-31 01:23:58] iter = 12230, loss = 31.4565
2024-10-31 01:24:02: [2024-10-31 01:24:02] iter = 12240, loss = 31.4967
2024-10-31 01:24:07: [2024-10-31 01:24:07] iter = 12250, loss = 43.7058
2024-10-31 01:24:11: [2024-10-31 01:24:11] iter = 12260, loss = 12.8056
2024-10-31 01:24:15: [2024-10-31 01:24:15] iter = 12270, loss = 4.5390
2024-10-31 01:24:20: [2024-10-31 01:24:20] iter = 12280, loss = 5.4021
2024-10-31 01:24:23: [2024-10-31 01:24:23] iter = 12290, loss = 12.9496
2024-10-31 01:24:27: [2024-10-31 01:24:27] iter = 12300, loss = 20.9767
2024-10-31 01:24:32: [2024-10-31 01:24:32] iter = 12310, loss = 59.5999
2024-10-31 01:24:35: [2024-10-31 01:24:35] iter = 12320, loss = 11.2452
2024-10-31 01:24:38: [2024-10-31 01:24:38] iter = 12330, loss = 10.1209
2024-10-31 01:24:41: [2024-10-31 01:24:41] iter = 12340, loss = 39.2472
2024-10-31 01:24:44: [2024-10-31 01:24:44] iter = 12350, loss = 6.5073
2024-10-31 01:24:47: [2024-10-31 01:24:47] iter = 12360, loss = 6.4193
2024-10-31 01:24:50: [2024-10-31 01:24:50] iter = 12370, loss = 4.7750
2024-10-31 01:24:52: [2024-10-31 01:24:52] iter = 12380, loss = 6.6222
2024-10-31 01:24:56: [2024-10-31 01:24:56] iter = 12390, loss = 5.4531
2024-10-31 01:24:58: [2024-10-31 01:24:58] iter = 12400, loss = 9.9003
2024-10-31 01:25:01: [2024-10-31 01:25:01] iter = 12410, loss = 6.5578
2024-10-31 01:25:04: [2024-10-31 01:25:04] iter = 12420, loss = 5.1301
2024-10-31 01:25:05: [2024-10-31 01:25:05] iter = 12430, loss = 6.6764
2024-10-31 01:25:09: [2024-10-31 01:25:09] iter = 12440, loss = 7.9199
2024-10-31 01:25:12: [2024-10-31 01:25:12] iter = 12450, loss = 33.1524
2024-10-31 01:25:16: [2024-10-31 01:25:16] iter = 12460, loss = 20.8990
2024-10-31 01:25:20: [2024-10-31 01:25:20] iter = 12470, loss = 5.4074
2024-10-31 01:25:24: [2024-10-31 01:25:24] iter = 12480, loss = 5.1147
2024-10-31 01:25:28: [2024-10-31 01:25:28] iter = 12490, loss = 6.7722
2024-10-31 01:25:31: [2024-10-31 01:25:31] iter = 12500, loss = 6.5838
2024-10-31 01:25:35: [2024-10-31 01:25:35] iter = 12510, loss = 5.9492
2024-10-31 01:25:39: [2024-10-31 01:25:39] iter = 12520, loss = 41.5549
2024-10-31 01:25:42: [2024-10-31 01:25:42] iter = 12530, loss = 4.7854
2024-10-31 01:25:46: [2024-10-31 01:25:46] iter = 12540, loss = 16.1584
2024-10-31 01:25:51: [2024-10-31 01:25:51] iter = 12550, loss = 58.4769
2024-10-31 01:25:55: [2024-10-31 01:25:55] iter = 12560, loss = 4.2827
2024-10-31 01:25:58: [2024-10-31 01:25:58] iter = 12570, loss = 14.3271
2024-10-31 01:26:02: [2024-10-31 01:26:02] iter = 12580, loss = 63.8063
2024-10-31 01:26:06: [2024-10-31 01:26:06] iter = 12590, loss = 16.4963
2024-10-31 01:26:09: [2024-10-31 01:26:09] iter = 12600, loss = 6.0986
2024-10-31 01:26:13: [2024-10-31 01:26:13] iter = 12610, loss = 14.2942
2024-10-31 01:26:16: [2024-10-31 01:26:16] iter = 12620, loss = 18.5221
2024-10-31 01:26:19: [2024-10-31 01:26:19] iter = 12630, loss = 4.7241
2024-10-31 01:26:23: [2024-10-31 01:26:23] iter = 12640, loss = 4.5272
2024-10-31 01:26:27: [2024-10-31 01:26:27] iter = 12650, loss = 12.7276
2024-10-31 01:26:30: [2024-10-31 01:26:30] iter = 12660, loss = 10.5979
2024-10-31 01:26:33: [2024-10-31 01:26:33] iter = 12670, loss = 5.9968
2024-10-31 01:26:36: [2024-10-31 01:26:36] iter = 12680, loss = 7.2355
2024-10-31 01:26:38: [2024-10-31 01:26:38] iter = 12690, loss = 46.7934
2024-10-31 01:26:42: [2024-10-31 01:26:42] iter = 12700, loss = 9.2716
2024-10-31 01:26:46: [2024-10-31 01:26:46] iter = 12710, loss = 4.4554
2024-10-31 01:26:49: [2024-10-31 01:26:49] iter = 12720, loss = 11.4910
2024-10-31 01:26:53: [2024-10-31 01:26:53] iter = 12730, loss = 32.8414
2024-10-31 01:26:57: [2024-10-31 01:26:57] iter = 12740, loss = 24.0742
2024-10-31 01:27:01: [2024-10-31 01:27:01] iter = 12750, loss = 35.2547
2024-10-31 01:27:05: [2024-10-31 01:27:05] iter = 12760, loss = 11.2463
2024-10-31 01:27:08: [2024-10-31 01:27:08] iter = 12770, loss = 5.8688
2024-10-31 01:27:12: [2024-10-31 01:27:12] iter = 12780, loss = 9.7250
2024-10-31 01:27:15: [2024-10-31 01:27:15] iter = 12790, loss = 8.3628
2024-10-31 01:27:18: [2024-10-31 01:27:18] iter = 12800, loss = 10.3947
2024-10-31 01:27:21: [2024-10-31 01:27:21] iter = 12810, loss = 27.9007
2024-10-31 01:27:24: [2024-10-31 01:27:24] iter = 12820, loss = 28.3134
2024-10-31 01:27:28: [2024-10-31 01:27:28] iter = 12830, loss = 20.9230
2024-10-31 01:27:31: [2024-10-31 01:27:31] iter = 12840, loss = 38.8715
2024-10-31 01:27:35: [2024-10-31 01:27:35] iter = 12850, loss = 50.7107
2024-10-31 01:27:39: [2024-10-31 01:27:39] iter = 12860, loss = 10.4439
2024-10-31 01:27:43: [2024-10-31 01:27:43] iter = 12870, loss = 47.5602
2024-10-31 01:27:46: [2024-10-31 01:27:46] iter = 12880, loss = 34.1338
2024-10-31 01:27:49: [2024-10-31 01:27:49] iter = 12890, loss = 18.3409
2024-10-31 01:27:53: [2024-10-31 01:27:53] iter = 12900, loss = 5.5132
2024-10-31 01:27:57: [2024-10-31 01:27:57] iter = 12910, loss = 4.0034
2024-10-31 01:28:00: [2024-10-31 01:28:00] iter = 12920, loss = 20.0382
2024-10-31 01:28:03: [2024-10-31 01:28:03] iter = 12930, loss = 12.8093
2024-10-31 01:28:07: [2024-10-31 01:28:07] iter = 12940, loss = 19.9960
2024-10-31 01:28:10: [2024-10-31 01:28:10] iter = 12950, loss = 5.2074
2024-10-31 01:28:13: [2024-10-31 01:28:13] iter = 12960, loss = 38.6735
2024-10-31 01:28:17: [2024-10-31 01:28:17] iter = 12970, loss = 25.6252
2024-10-31 01:28:20: [2024-10-31 01:28:20] iter = 12980, loss = 19.5415
2024-10-31 01:28:23: [2024-10-31 01:28:23] iter = 12990, loss = 6.0666
2024-10-31 01:28:27: [2024-10-31 01:28:27] iter = 13000, loss = 25.9105
2024-10-31 01:28:30: [2024-10-31 01:28:30] iter = 13010, loss = 44.4706
2024-10-31 01:28:34: [2024-10-31 01:28:34] iter = 13020, loss = 6.7782
2024-10-31 01:28:38: [2024-10-31 01:28:38] iter = 13030, loss = 6.5640
2024-10-31 01:28:41: [2024-10-31 01:28:41] iter = 13040, loss = 5.7822
2024-10-31 01:28:44: [2024-10-31 01:28:44] iter = 13050, loss = 5.6724
2024-10-31 01:28:48: [2024-10-31 01:28:48] iter = 13060, loss = 11.5020
2024-10-31 01:28:51: [2024-10-31 01:28:51] iter = 13070, loss = 10.5278
2024-10-31 01:28:54: [2024-10-31 01:28:54] iter = 13080, loss = 16.2397
2024-10-31 01:28:57: [2024-10-31 01:28:57] iter = 13090, loss = 6.0963
2024-10-31 01:29:01: [2024-10-31 01:29:01] iter = 13100, loss = 5.6662
2024-10-31 01:29:04: [2024-10-31 01:29:04] iter = 13110, loss = 4.2444
2024-10-31 01:29:08: [2024-10-31 01:29:08] iter = 13120, loss = 20.2560
2024-10-31 01:29:12: [2024-10-31 01:29:12] iter = 13130, loss = 24.4420
2024-10-31 01:29:16: [2024-10-31 01:29:16] iter = 13140, loss = 40.1021
2024-10-31 01:29:20: [2024-10-31 01:29:20] iter = 13150, loss = 83.1513
2024-10-31 01:29:23: [2024-10-31 01:29:23] iter = 13160, loss = 6.4370
2024-10-31 01:29:27: [2024-10-31 01:29:27] iter = 13170, loss = 70.3828
2024-10-31 01:29:30: [2024-10-31 01:29:30] iter = 13180, loss = 14.3365
2024-10-31 01:29:33: [2024-10-31 01:29:33] iter = 13190, loss = 8.3891
2024-10-31 01:29:36: [2024-10-31 01:29:36] iter = 13200, loss = 4.0184
2024-10-31 01:29:39: [2024-10-31 01:29:39] iter = 13210, loss = 4.8835
2024-10-31 01:29:42: [2024-10-31 01:29:42] iter = 13220, loss = 27.2500
2024-10-31 01:29:45: [2024-10-31 01:29:45] iter = 13230, loss = 20.5598
2024-10-31 01:29:47: [2024-10-31 01:29:47] iter = 13240, loss = 23.3125
2024-10-31 01:29:50: [2024-10-31 01:29:50] iter = 13250, loss = 12.5201
2024-10-31 01:29:53: [2024-10-31 01:29:53] iter = 13260, loss = 52.9635
2024-10-31 01:29:55: [2024-10-31 01:29:55] iter = 13270, loss = 71.5931
2024-10-31 01:29:58: [2024-10-31 01:29:58] iter = 13280, loss = 24.4658
2024-10-31 01:30:01: [2024-10-31 01:30:01] iter = 13290, loss = 5.5263
2024-10-31 01:30:04: [2024-10-31 01:30:04] iter = 13300, loss = 24.1770
2024-10-31 01:30:07: [2024-10-31 01:30:07] iter = 13310, loss = 36.4049
2024-10-31 01:30:10: [2024-10-31 01:30:10] iter = 13320, loss = 12.3754
2024-10-31 01:30:13: [2024-10-31 01:30:13] iter = 13330, loss = 9.7555
2024-10-31 01:30:16: [2024-10-31 01:30:16] iter = 13340, loss = 16.9854
2024-10-31 01:30:19: [2024-10-31 01:30:19] iter = 13350, loss = 68.8514
2024-10-31 01:30:21: [2024-10-31 01:30:21] iter = 13360, loss = 11.2900
2024-10-31 01:30:24: [2024-10-31 01:30:24] iter = 13370, loss = 10.9009
2024-10-31 01:30:28: [2024-10-31 01:30:28] iter = 13380, loss = 29.0663
2024-10-31 01:30:31: [2024-10-31 01:30:31] iter = 13390, loss = 73.0841
2024-10-31 01:30:34: [2024-10-31 01:30:34] iter = 13400, loss = 12.7378
2024-10-31 01:30:38: [2024-10-31 01:30:38] iter = 13410, loss = 12.4498
2024-10-31 01:30:41: [2024-10-31 01:30:41] iter = 13420, loss = 12.3819
2024-10-31 01:30:44: [2024-10-31 01:30:44] iter = 13430, loss = 9.6990
2024-10-31 01:30:47: [2024-10-31 01:30:47] iter = 13440, loss = 42.3642
2024-10-31 01:30:51: [2024-10-31 01:30:51] iter = 13450, loss = 9.5255
2024-10-31 01:30:54: [2024-10-31 01:30:54] iter = 13460, loss = 10.6401
2024-10-31 01:30:57: [2024-10-31 01:30:57] iter = 13470, loss = 38.9078
2024-10-31 01:31:01: [2024-10-31 01:31:01] iter = 13480, loss = 4.2472
2024-10-31 01:31:02: [2024-10-31 01:31:02] iter = 13490, loss = 6.1298
2024-10-31 01:31:06: [2024-10-31 01:31:06] iter = 13500, loss = 23.9094
2024-10-31 01:31:08: [2024-10-31 01:31:08] iter = 13510, loss = 3.9964
2024-10-31 01:31:12: [2024-10-31 01:31:12] iter = 13520, loss = 7.1945
2024-10-31 01:31:15: [2024-10-31 01:31:15] iter = 13530, loss = 5.5753
2024-10-31 01:31:19: [2024-10-31 01:31:19] iter = 13540, loss = 16.1694
2024-10-31 01:31:21: [2024-10-31 01:31:21] iter = 13550, loss = 8.6105
2024-10-31 01:31:24: [2024-10-31 01:31:24] iter = 13560, loss = 10.3319
2024-10-31 01:31:28: [2024-10-31 01:31:28] iter = 13570, loss = 5.2742
2024-10-31 01:31:30: [2024-10-31 01:31:30] iter = 13580, loss = 16.0325
2024-10-31 01:31:33: [2024-10-31 01:31:33] iter = 13590, loss = 12.0010
2024-10-31 01:31:37: [2024-10-31 01:31:37] iter = 13600, loss = 22.9116
2024-10-31 01:31:40: [2024-10-31 01:31:40] iter = 13610, loss = 61.0632
2024-10-31 01:31:43: [2024-10-31 01:31:43] iter = 13620, loss = 7.7550
2024-10-31 01:31:45: [2024-10-31 01:31:45] iter = 13630, loss = 33.4843
2024-10-31 01:31:47: [2024-10-31 01:31:47] iter = 13640, loss = 41.7856
2024-10-31 01:31:51: [2024-10-31 01:31:51] iter = 13650, loss = 4.0997
2024-10-31 01:31:54: [2024-10-31 01:31:54] iter = 13660, loss = 42.4962
2024-10-31 01:31:58: [2024-10-31 01:31:58] iter = 13670, loss = 14.7962
2024-10-31 01:32:01: [2024-10-31 01:32:01] iter = 13680, loss = 15.4102
2024-10-31 01:32:04: [2024-10-31 01:32:04] iter = 13690, loss = 23.6240
2024-10-31 01:32:07: [2024-10-31 01:32:07] iter = 13700, loss = 7.8804
2024-10-31 01:32:09: [2024-10-31 01:32:09] iter = 13710, loss = 8.3972
2024-10-31 01:32:12: [2024-10-31 01:32:12] iter = 13720, loss = 4.2047
2024-10-31 01:32:15: [2024-10-31 01:32:15] iter = 13730, loss = 24.7656
2024-10-31 01:32:19: [2024-10-31 01:32:19] iter = 13740, loss = 14.9666
2024-10-31 01:32:22: [2024-10-31 01:32:22] iter = 13750, loss = 19.6350
2024-10-31 01:32:24: [2024-10-31 01:32:24] iter = 13760, loss = 4.4569
2024-10-31 01:32:28: [2024-10-31 01:32:28] iter = 13770, loss = 33.7725
2024-10-31 01:32:31: [2024-10-31 01:32:31] iter = 13780, loss = 13.1568
2024-10-31 01:32:34: [2024-10-31 01:32:34] iter = 13790, loss = 5.5328
2024-10-31 01:32:38: [2024-10-31 01:32:38] iter = 13800, loss = 4.7566
2024-10-31 01:32:41: [2024-10-31 01:32:41] iter = 13810, loss = 12.5216
2024-10-31 01:32:44: [2024-10-31 01:32:44] iter = 13820, loss = 8.7569
2024-10-31 01:32:47: [2024-10-31 01:32:47] iter = 13830, loss = 7.4350
2024-10-31 01:32:50: [2024-10-31 01:32:50] iter = 13840, loss = 38.4666
2024-10-31 01:32:53: [2024-10-31 01:32:53] iter = 13850, loss = 3.7980
2024-10-31 01:32:56: [2024-10-31 01:32:56] iter = 13860, loss = 4.0347
2024-10-31 01:32:58: [2024-10-31 01:32:58] iter = 13870, loss = 11.4609
2024-10-31 01:33:01: [2024-10-31 01:33:01] iter = 13880, loss = 3.5450
2024-10-31 01:33:04: [2024-10-31 01:33:04] iter = 13890, loss = 15.5472
2024-10-31 01:33:07: [2024-10-31 01:33:07] iter = 13900, loss = 3.8310
2024-10-31 01:33:11: [2024-10-31 01:33:11] iter = 13910, loss = 4.4621
2024-10-31 01:33:15: [2024-10-31 01:33:15] iter = 13920, loss = 3.8308
2024-10-31 01:33:17: [2024-10-31 01:33:17] iter = 13930, loss = 10.3026
2024-10-31 01:33:21: [2024-10-31 01:33:21] iter = 13940, loss = 22.6180
2024-10-31 01:33:25: [2024-10-31 01:33:25] iter = 13950, loss = 8.7252
2024-10-31 01:33:28: [2024-10-31 01:33:28] iter = 13960, loss = 11.0929
2024-10-31 01:33:31: [2024-10-31 01:33:31] iter = 13970, loss = 17.1846
2024-10-31 01:33:35: [2024-10-31 01:33:35] iter = 13980, loss = 22.8095
2024-10-31 01:33:38: [2024-10-31 01:33:38] iter = 13990, loss = 25.2282
2024-10-31 01:33:41: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 14000
2024-10-31 01:33:41: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:33:41: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 21406}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:35:38: Evaluate 5 random ConvNet, ACCmean = 0.2996 ACCstd = 0.0181
-------------------------
2024-10-31 01:35:38: Evaluate 5 random ConvNet, SENmean = 0.2903 SENstd = 0.0074
-------------------------
2024-10-31 01:35:38: Evaluate 5 random ConvNet, SPEmean = 0.9009 SPEstd = 0.0021
-------------------------
2024-10-31 01:35:38: Evaluate 5 random ConvNet, F!mean = 0.2547 F!std = 0.0119
-------------------------
2024-10-31 01:35:38: Evaluate 5 random ConvNet, mean = 0.2996 std = 0.0181
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:35:38: [2024-10-31 01:35:38] iter = 14000, loss = 28.1929
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:35:42: [2024-10-31 01:35:42] iter = 14010, loss = 15.1283
2024-10-31 01:35:45: [2024-10-31 01:35:45] iter = 14020, loss = 5.0008
2024-10-31 01:35:49: [2024-10-31 01:35:49] iter = 14030, loss = 4.5164
2024-10-31 01:35:52: [2024-10-31 01:35:52] iter = 14040, loss = 24.1420
2024-10-31 01:35:55: [2024-10-31 01:35:55] iter = 14050, loss = 8.7866
2024-10-31 01:35:58: [2024-10-31 01:35:58] iter = 14060, loss = 23.0622
2024-10-31 01:36:00: [2024-10-31 01:36:00] iter = 14070, loss = 4.2917
2024-10-31 01:36:04: [2024-10-31 01:36:04] iter = 14080, loss = 10.8021
2024-10-31 01:36:07: [2024-10-31 01:36:07] iter = 14090, loss = 19.9594
2024-10-31 01:36:10: [2024-10-31 01:36:10] iter = 14100, loss = 12.6404
2024-10-31 01:36:13: [2024-10-31 01:36:13] iter = 14110, loss = 8.9817
2024-10-31 01:36:17: [2024-10-31 01:36:17] iter = 14120, loss = 18.6227
2024-10-31 01:36:20: [2024-10-31 01:36:20] iter = 14130, loss = 9.5828
2024-10-31 01:36:23: [2024-10-31 01:36:23] iter = 14140, loss = 20.2518
2024-10-31 01:36:27: [2024-10-31 01:36:27] iter = 14150, loss = 4.5911
2024-10-31 01:36:30: [2024-10-31 01:36:30] iter = 14160, loss = 5.4134
2024-10-31 01:36:32: [2024-10-31 01:36:32] iter = 14170, loss = 8.7540
2024-10-31 01:36:34: [2024-10-31 01:36:34] iter = 14180, loss = 21.3172
2024-10-31 01:36:37: [2024-10-31 01:36:37] iter = 14190, loss = 18.1493
2024-10-31 01:36:41: [2024-10-31 01:36:41] iter = 14200, loss = 3.4411
2024-10-31 01:36:45: [2024-10-31 01:36:45] iter = 14210, loss = 17.3415
2024-10-31 01:36:48: [2024-10-31 01:36:48] iter = 14220, loss = 34.9120
2024-10-31 01:36:51: [2024-10-31 01:36:51] iter = 14230, loss = 4.5254
2024-10-31 01:36:55: [2024-10-31 01:36:55] iter = 14240, loss = 3.7161
2024-10-31 01:36:58: [2024-10-31 01:36:58] iter = 14250, loss = 4.0317
2024-10-31 01:37:01: [2024-10-31 01:37:01] iter = 14260, loss = 11.0843
2024-10-31 01:37:04: [2024-10-31 01:37:04] iter = 14270, loss = 20.6722
2024-10-31 01:37:07: [2024-10-31 01:37:07] iter = 14280, loss = 23.0101
2024-10-31 01:37:11: [2024-10-31 01:37:11] iter = 14290, loss = 18.5603
2024-10-31 01:37:14: [2024-10-31 01:37:14] iter = 14300, loss = 43.3516
2024-10-31 01:37:18: [2024-10-31 01:37:18] iter = 14310, loss = 31.4096
2024-10-31 01:37:20: [2024-10-31 01:37:20] iter = 14320, loss = 12.8955
2024-10-31 01:37:23: [2024-10-31 01:37:23] iter = 14330, loss = 19.3099
2024-10-31 01:37:27: [2024-10-31 01:37:27] iter = 14340, loss = 9.7987
2024-10-31 01:37:30: [2024-10-31 01:37:30] iter = 14350, loss = 4.2441
2024-10-31 01:37:33: [2024-10-31 01:37:33] iter = 14360, loss = 12.8517
2024-10-31 01:37:37: [2024-10-31 01:37:37] iter = 14370, loss = 44.4074
2024-10-31 01:37:39: [2024-10-31 01:37:39] iter = 14380, loss = 23.4904
2024-10-31 01:37:42: [2024-10-31 01:37:42] iter = 14390, loss = 26.6086
2024-10-31 01:37:47: [2024-10-31 01:37:47] iter = 14400, loss = 4.5670
2024-10-31 01:37:51: [2024-10-31 01:37:51] iter = 14410, loss = 4.2246
2024-10-31 01:37:54: [2024-10-31 01:37:54] iter = 14420, loss = 4.8491
2024-10-31 01:37:57: [2024-10-31 01:37:57] iter = 14430, loss = 5.0935
2024-10-31 01:38:00: [2024-10-31 01:38:00] iter = 14440, loss = 8.9215
2024-10-31 01:38:03: [2024-10-31 01:38:03] iter = 14450, loss = 35.8978
2024-10-31 01:38:06: [2024-10-31 01:38:06] iter = 14460, loss = 33.9380
2024-10-31 01:38:09: [2024-10-31 01:38:09] iter = 14470, loss = 19.6106
2024-10-31 01:38:12: [2024-10-31 01:38:12] iter = 14480, loss = 10.6354
2024-10-31 01:38:16: [2024-10-31 01:38:16] iter = 14490, loss = 32.6310
2024-10-31 01:38:19: [2024-10-31 01:38:19] iter = 14500, loss = 20.4263
2024-10-31 01:38:22: [2024-10-31 01:38:22] iter = 14510, loss = 10.4821
2024-10-31 01:38:25: [2024-10-31 01:38:25] iter = 14520, loss = 12.4447
2024-10-31 01:38:29: [2024-10-31 01:38:29] iter = 14530, loss = 46.5242
2024-10-31 01:38:32: [2024-10-31 01:38:32] iter = 14540, loss = 92.2085
2024-10-31 01:38:36: [2024-10-31 01:38:36] iter = 14550, loss = 25.1870
2024-10-31 01:38:39: [2024-10-31 01:38:39] iter = 14560, loss = 6.0339
2024-10-31 01:38:43: [2024-10-31 01:38:43] iter = 14570, loss = 8.3949
2024-10-31 01:38:46: [2024-10-31 01:38:46] iter = 14580, loss = 25.9127
2024-10-31 01:38:49: [2024-10-31 01:38:49] iter = 14590, loss = 138.1807
2024-10-31 01:38:53: [2024-10-31 01:38:53] iter = 14600, loss = 7.9752
2024-10-31 01:38:56: [2024-10-31 01:38:56] iter = 14610, loss = 4.9300
2024-10-31 01:39:00: [2024-10-31 01:39:00] iter = 14620, loss = 13.9341
2024-10-31 01:39:03: [2024-10-31 01:39:03] iter = 14630, loss = 12.3956
2024-10-31 01:39:07: [2024-10-31 01:39:07] iter = 14640, loss = 11.7653
2024-10-31 01:39:09: [2024-10-31 01:39:09] iter = 14650, loss = 23.5742
2024-10-31 01:39:11: [2024-10-31 01:39:11] iter = 14660, loss = 3.2038
2024-10-31 01:39:14: [2024-10-31 01:39:14] iter = 14670, loss = 30.6888
2024-10-31 01:39:17: [2024-10-31 01:39:17] iter = 14680, loss = 4.7590
2024-10-31 01:39:21: [2024-10-31 01:39:21] iter = 14690, loss = 20.4775
2024-10-31 01:39:25: [2024-10-31 01:39:25] iter = 14700, loss = 6.5639
2024-10-31 01:39:28: [2024-10-31 01:39:28] iter = 14710, loss = 6.1115
2024-10-31 01:39:31: [2024-10-31 01:39:31] iter = 14720, loss = 10.2178
2024-10-31 01:39:35: [2024-10-31 01:39:35] iter = 14730, loss = 20.6377
2024-10-31 01:39:39: [2024-10-31 01:39:39] iter = 14740, loss = 8.4229
2024-10-31 01:39:42: [2024-10-31 01:39:42] iter = 14750, loss = 3.6799
2024-10-31 01:39:45: [2024-10-31 01:39:45] iter = 14760, loss = 5.0308
2024-10-31 01:39:49: [2024-10-31 01:39:49] iter = 14770, loss = 103.3356
2024-10-31 01:39:53: [2024-10-31 01:39:53] iter = 14780, loss = 23.3146
2024-10-31 01:39:56: [2024-10-31 01:39:56] iter = 14790, loss = 80.5557
2024-10-31 01:39:59: [2024-10-31 01:39:59] iter = 14800, loss = 31.1696
2024-10-31 01:40:03: [2024-10-31 01:40:03] iter = 14810, loss = 23.1531
2024-10-31 01:40:06: [2024-10-31 01:40:06] iter = 14820, loss = 11.8640
2024-10-31 01:40:09: [2024-10-31 01:40:09] iter = 14830, loss = 5.6136
2024-10-31 01:40:12: [2024-10-31 01:40:12] iter = 14840, loss = 8.0154
2024-10-31 01:40:16: [2024-10-31 01:40:16] iter = 14850, loss = 24.2802
2024-10-31 01:40:20: [2024-10-31 01:40:20] iter = 14860, loss = 18.7773
2024-10-31 01:40:22: [2024-10-31 01:40:22] iter = 14870, loss = 17.5134
2024-10-31 01:40:26: [2024-10-31 01:40:26] iter = 14880, loss = 36.6166
2024-10-31 01:40:29: [2024-10-31 01:40:29] iter = 14890, loss = 37.3269
2024-10-31 01:40:33: [2024-10-31 01:40:33] iter = 14900, loss = 56.2963
2024-10-31 01:40:36: [2024-10-31 01:40:36] iter = 14910, loss = 6.4191
2024-10-31 01:40:39: [2024-10-31 01:40:39] iter = 14920, loss = 4.0815
2024-10-31 01:40:42: [2024-10-31 01:40:42] iter = 14930, loss = 25.5029
2024-10-31 01:40:45: [2024-10-31 01:40:45] iter = 14940, loss = 15.0732
2024-10-31 01:40:48: [2024-10-31 01:40:48] iter = 14950, loss = 42.1964
2024-10-31 01:40:52: [2024-10-31 01:40:52] iter = 14960, loss = 9.4312
2024-10-31 01:40:55: [2024-10-31 01:40:55] iter = 14970, loss = 24.7500
2024-10-31 01:40:59: [2024-10-31 01:40:59] iter = 14980, loss = 7.1468
2024-10-31 01:41:04: [2024-10-31 01:41:04] iter = 14990, loss = 35.7308
2024-10-31 01:41:07: [2024-10-31 01:41:07] iter = 15000, loss = 9.9019
2024-10-31 01:41:10: [2024-10-31 01:41:10] iter = 15010, loss = 7.3679
2024-10-31 01:41:14: [2024-10-31 01:41:14] iter = 15020, loss = 7.5678
2024-10-31 01:41:18: [2024-10-31 01:41:18] iter = 15030, loss = 20.7812
2024-10-31 01:41:21: [2024-10-31 01:41:21] iter = 15040, loss = 15.2731
2024-10-31 01:41:25: [2024-10-31 01:41:25] iter = 15050, loss = 32.7769
2024-10-31 01:41:28: [2024-10-31 01:41:28] iter = 15060, loss = 40.0843
2024-10-31 01:41:32: [2024-10-31 01:41:32] iter = 15070, loss = 33.9896
2024-10-31 01:41:35: [2024-10-31 01:41:35] iter = 15080, loss = 25.5467
2024-10-31 01:41:38: [2024-10-31 01:41:38] iter = 15090, loss = 4.8385
2024-10-31 01:41:43: [2024-10-31 01:41:43] iter = 15100, loss = 38.6821
2024-10-31 01:41:46: [2024-10-31 01:41:46] iter = 15110, loss = 6.9406
2024-10-31 01:41:49: [2024-10-31 01:41:49] iter = 15120, loss = 5.8347
2024-10-31 01:41:51: [2024-10-31 01:41:51] iter = 15130, loss = 25.9270
2024-10-31 01:41:54: [2024-10-31 01:41:54] iter = 15140, loss = 4.4930
2024-10-31 01:41:58: [2024-10-31 01:41:58] iter = 15150, loss = 55.6962
2024-10-31 01:42:01: [2024-10-31 01:42:01] iter = 15160, loss = 16.8861
2024-10-31 01:42:04: [2024-10-31 01:42:04] iter = 15170, loss = 18.6477
2024-10-31 01:42:08: [2024-10-31 01:42:08] iter = 15180, loss = 5.2506
2024-10-31 01:42:12: [2024-10-31 01:42:12] iter = 15190, loss = 20.8654
2024-10-31 01:42:15: [2024-10-31 01:42:15] iter = 15200, loss = 26.1351
2024-10-31 01:42:17: [2024-10-31 01:42:17] iter = 15210, loss = 9.4319
2024-10-31 01:42:21: [2024-10-31 01:42:21] iter = 15220, loss = 41.7515
2024-10-31 01:42:24: [2024-10-31 01:42:24] iter = 15230, loss = 10.0117
2024-10-31 01:42:26: [2024-10-31 01:42:26] iter = 15240, loss = 19.6558
2024-10-31 01:42:29: [2024-10-31 01:42:29] iter = 15250, loss = 17.5107
2024-10-31 01:42:34: [2024-10-31 01:42:34] iter = 15260, loss = 6.3042
2024-10-31 01:42:37: [2024-10-31 01:42:37] iter = 15270, loss = 12.9350
2024-10-31 01:42:40: [2024-10-31 01:42:40] iter = 15280, loss = 20.2876
2024-10-31 01:42:43: [2024-10-31 01:42:43] iter = 15290, loss = 10.0160
2024-10-31 01:42:47: [2024-10-31 01:42:47] iter = 15300, loss = 32.4882
2024-10-31 01:42:50: [2024-10-31 01:42:50] iter = 15310, loss = 18.7244
2024-10-31 01:42:53: [2024-10-31 01:42:53] iter = 15320, loss = 5.7777
2024-10-31 01:42:55: [2024-10-31 01:42:55] iter = 15330, loss = 18.0730
2024-10-31 01:42:58: [2024-10-31 01:42:58] iter = 15340, loss = 3.8490
2024-10-31 01:43:00: [2024-10-31 01:43:00] iter = 15350, loss = 24.5649
2024-10-31 01:43:04: [2024-10-31 01:43:04] iter = 15360, loss = 10.8684
2024-10-31 01:43:08: [2024-10-31 01:43:08] iter = 15370, loss = 26.8695
2024-10-31 01:43:11: [2024-10-31 01:43:11] iter = 15380, loss = 8.8114
2024-10-31 01:43:13: [2024-10-31 01:43:13] iter = 15390, loss = 61.5561
2024-10-31 01:43:16: [2024-10-31 01:43:16] iter = 15400, loss = 10.1278
2024-10-31 01:43:19: [2024-10-31 01:43:19] iter = 15410, loss = 12.1881
2024-10-31 01:43:22: [2024-10-31 01:43:22] iter = 15420, loss = 5.0287
2024-10-31 01:43:24: [2024-10-31 01:43:24] iter = 15430, loss = 13.0904
2024-10-31 01:43:28: [2024-10-31 01:43:28] iter = 15440, loss = 3.2924
2024-10-31 01:43:31: [2024-10-31 01:43:31] iter = 15450, loss = 13.6208
2024-10-31 01:43:34: [2024-10-31 01:43:34] iter = 15460, loss = 12.7404
2024-10-31 01:43:38: [2024-10-31 01:43:38] iter = 15470, loss = 40.7347
2024-10-31 01:43:42: [2024-10-31 01:43:42] iter = 15480, loss = 17.9718
2024-10-31 01:43:45: [2024-10-31 01:43:45] iter = 15490, loss = 14.7714
2024-10-31 01:43:48: [2024-10-31 01:43:48] iter = 15500, loss = 8.7691
2024-10-31 01:43:50: [2024-10-31 01:43:50] iter = 15510, loss = 20.6435
2024-10-31 01:43:53: [2024-10-31 01:43:53] iter = 15520, loss = 26.8037
2024-10-31 01:43:56: [2024-10-31 01:43:56] iter = 15530, loss = 5.5538
2024-10-31 01:43:58: [2024-10-31 01:43:58] iter = 15540, loss = 9.5491
2024-10-31 01:43:59: [2024-10-31 01:43:59] iter = 15550, loss = 19.3501
2024-10-31 01:44:02: [2024-10-31 01:44:02] iter = 15560, loss = 17.8836
2024-10-31 01:44:05: [2024-10-31 01:44:05] iter = 15570, loss = 6.3644
2024-10-31 01:44:08: [2024-10-31 01:44:08] iter = 15580, loss = 47.1405
2024-10-31 01:44:10: [2024-10-31 01:44:10] iter = 15590, loss = 10.9411
2024-10-31 01:44:14: [2024-10-31 01:44:14] iter = 15600, loss = 4.4161
2024-10-31 01:44:16: [2024-10-31 01:44:16] iter = 15610, loss = 3.2950
2024-10-31 01:44:19: [2024-10-31 01:44:19] iter = 15620, loss = 28.7562
2024-10-31 01:44:23: [2024-10-31 01:44:23] iter = 15630, loss = 13.9862
2024-10-31 01:44:26: [2024-10-31 01:44:26] iter = 15640, loss = 15.0707
2024-10-31 01:44:29: [2024-10-31 01:44:29] iter = 15650, loss = 21.1149
2024-10-31 01:44:33: [2024-10-31 01:44:33] iter = 15660, loss = 28.0841
2024-10-31 01:44:36: [2024-10-31 01:44:36] iter = 15670, loss = 44.1118
2024-10-31 01:44:38: [2024-10-31 01:44:38] iter = 15680, loss = 13.6045
2024-10-31 01:44:40: [2024-10-31 01:44:40] iter = 15690, loss = 12.1731
2024-10-31 01:44:43: [2024-10-31 01:44:43] iter = 15700, loss = 57.9693
2024-10-31 01:44:46: [2024-10-31 01:44:46] iter = 15710, loss = 16.4336
2024-10-31 01:44:49: [2024-10-31 01:44:49] iter = 15720, loss = 49.2483
2024-10-31 01:44:52: [2024-10-31 01:44:52] iter = 15730, loss = 23.9691
2024-10-31 01:44:55: [2024-10-31 01:44:55] iter = 15740, loss = 6.2987
2024-10-31 01:44:58: [2024-10-31 01:44:58] iter = 15750, loss = 5.3028
2024-10-31 01:45:02: [2024-10-31 01:45:02] iter = 15760, loss = 35.0254
2024-10-31 01:45:05: [2024-10-31 01:45:05] iter = 15770, loss = 67.1170
2024-10-31 01:45:08: [2024-10-31 01:45:08] iter = 15780, loss = 72.3499
2024-10-31 01:45:12: [2024-10-31 01:45:12] iter = 15790, loss = 21.5038
2024-10-31 01:45:16: [2024-10-31 01:45:16] iter = 15800, loss = 42.3587
2024-10-31 01:45:19: [2024-10-31 01:45:19] iter = 15810, loss = 11.3591
2024-10-31 01:45:22: [2024-10-31 01:45:22] iter = 15820, loss = 21.0392
2024-10-31 01:45:25: [2024-10-31 01:45:25] iter = 15830, loss = 6.9414
2024-10-31 01:45:28: [2024-10-31 01:45:28] iter = 15840, loss = 58.3113
2024-10-31 01:45:31: [2024-10-31 01:45:31] iter = 15850, loss = 37.1244
2024-10-31 01:45:35: [2024-10-31 01:45:35] iter = 15860, loss = 29.9696
2024-10-31 01:45:38: [2024-10-31 01:45:38] iter = 15870, loss = 19.0428
2024-10-31 01:45:42: [2024-10-31 01:45:42] iter = 15880, loss = 15.4382
2024-10-31 01:45:45: [2024-10-31 01:45:45] iter = 15890, loss = 3.3760
2024-10-31 01:45:48: [2024-10-31 01:45:48] iter = 15900, loss = 13.0363
2024-10-31 01:45:51: [2024-10-31 01:45:51] iter = 15910, loss = 13.6563
2024-10-31 01:45:55: [2024-10-31 01:45:55] iter = 15920, loss = 9.7772
2024-10-31 01:45:57: [2024-10-31 01:45:57] iter = 15930, loss = 46.3221
2024-10-31 01:46:01: [2024-10-31 01:46:01] iter = 15940, loss = 5.6693
2024-10-31 01:46:04: [2024-10-31 01:46:04] iter = 15950, loss = 3.7544
2024-10-31 01:46:07: [2024-10-31 01:46:07] iter = 15960, loss = 11.3686
2024-10-31 01:46:11: [2024-10-31 01:46:11] iter = 15970, loss = 12.4824
2024-10-31 01:46:14: [2024-10-31 01:46:14] iter = 15980, loss = 25.8643
2024-10-31 01:46:17: [2024-10-31 01:46:17] iter = 15990, loss = 5.8642
2024-10-31 01:46:19: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 16000
2024-10-31 01:46:19: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:46:19: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 79287}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:47:59: Evaluate 5 random ConvNet, ACCmean = 0.2453 ACCstd = 0.0061
-------------------------
2024-10-31 01:47:59: Evaluate 5 random ConvNet, SENmean = 0.2812 SENstd = 0.0035
-------------------------
2024-10-31 01:47:59: Evaluate 5 random ConvNet, SPEmean = 0.8950 SPEstd = 0.0007
-------------------------
2024-10-31 01:47:59: Evaluate 5 random ConvNet, F!mean = 0.2138 F!std = 0.0057
-------------------------
2024-10-31 01:47:59: Evaluate 5 random ConvNet, mean = 0.2453 std = 0.0061
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:47:59: [2024-10-31 01:47:59] iter = 16000, loss = 26.8667
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 01:48:02: [2024-10-31 01:48:02] iter = 16010, loss = 28.6214
2024-10-31 01:48:04: [2024-10-31 01:48:04] iter = 16020, loss = 7.7102
2024-10-31 01:48:07: [2024-10-31 01:48:07] iter = 16030, loss = 24.3073
2024-10-31 01:48:10: [2024-10-31 01:48:10] iter = 16040, loss = 29.3547
2024-10-31 01:48:13: [2024-10-31 01:48:13] iter = 16050, loss = 4.7943
2024-10-31 01:48:16: [2024-10-31 01:48:16] iter = 16060, loss = 14.6705
2024-10-31 01:48:18: [2024-10-31 01:48:18] iter = 16070, loss = 12.1715
2024-10-31 01:48:21: [2024-10-31 01:48:21] iter = 16080, loss = 23.8265
2024-10-31 01:48:25: [2024-10-31 01:48:25] iter = 16090, loss = 41.2827
2024-10-31 01:48:27: [2024-10-31 01:48:27] iter = 16100, loss = 26.0114
2024-10-31 01:48:30: [2024-10-31 01:48:30] iter = 16110, loss = 8.4570
2024-10-31 01:48:33: [2024-10-31 01:48:33] iter = 16120, loss = 11.4936
2024-10-31 01:48:36: [2024-10-31 01:48:36] iter = 16130, loss = 18.8663
2024-10-31 01:48:38: [2024-10-31 01:48:38] iter = 16140, loss = 40.2143
2024-10-31 01:48:41: [2024-10-31 01:48:41] iter = 16150, loss = 72.8886
2024-10-31 01:48:43: [2024-10-31 01:48:43] iter = 16160, loss = 9.8391
2024-10-31 01:48:46: [2024-10-31 01:48:46] iter = 16170, loss = 7.9049
2024-10-31 01:48:49: [2024-10-31 01:48:49] iter = 16180, loss = 18.7972
2024-10-31 01:48:53: [2024-10-31 01:48:53] iter = 16190, loss = 24.7128
2024-10-31 01:48:55: [2024-10-31 01:48:55] iter = 16200, loss = 35.7407
2024-10-31 01:48:58: [2024-10-31 01:48:58] iter = 16210, loss = 13.1222
2024-10-31 01:49:01: [2024-10-31 01:49:01] iter = 16220, loss = 9.0951
2024-10-31 01:49:05: [2024-10-31 01:49:05] iter = 16230, loss = 19.6513
2024-10-31 01:49:09: [2024-10-31 01:49:09] iter = 16240, loss = 6.8845
2024-10-31 01:49:12: [2024-10-31 01:49:12] iter = 16250, loss = 12.2751
2024-10-31 01:49:15: [2024-10-31 01:49:15] iter = 16260, loss = 58.7796
2024-10-31 01:49:19: [2024-10-31 01:49:19] iter = 16270, loss = 63.1478
2024-10-31 01:49:22: [2024-10-31 01:49:22] iter = 16280, loss = 9.3914
2024-10-31 01:49:26: [2024-10-31 01:49:26] iter = 16290, loss = 5.4074
2024-10-31 01:49:29: [2024-10-31 01:49:29] iter = 16300, loss = 27.5680
2024-10-31 01:49:33: [2024-10-31 01:49:33] iter = 16310, loss = 79.3830
2024-10-31 01:49:35: [2024-10-31 01:49:35] iter = 16320, loss = 20.5360
2024-10-31 01:49:39: [2024-10-31 01:49:39] iter = 16330, loss = 4.4691
2024-10-31 01:49:42: [2024-10-31 01:49:42] iter = 16340, loss = 10.8348
2024-10-31 01:49:45: [2024-10-31 01:49:45] iter = 16350, loss = 32.9182
2024-10-31 01:49:48: [2024-10-31 01:49:48] iter = 16360, loss = 27.2164
2024-10-31 01:49:52: [2024-10-31 01:49:52] iter = 16370, loss = 28.8194
2024-10-31 01:49:55: [2024-10-31 01:49:55] iter = 16380, loss = 11.5645
2024-10-31 01:49:58: [2024-10-31 01:49:58] iter = 16390, loss = 22.2756
2024-10-31 01:50:01: [2024-10-31 01:50:01] iter = 16400, loss = 23.3496
2024-10-31 01:50:05: [2024-10-31 01:50:05] iter = 16410, loss = 7.6418
2024-10-31 01:50:08: [2024-10-31 01:50:08] iter = 16420, loss = 17.9589
2024-10-31 01:50:11: [2024-10-31 01:50:11] iter = 16430, loss = 50.0551
2024-10-31 01:50:14: [2024-10-31 01:50:14] iter = 16440, loss = 4.1595
2024-10-31 01:50:17: [2024-10-31 01:50:17] iter = 16450, loss = 24.9450
2024-10-31 01:50:20: [2024-10-31 01:50:20] iter = 16460, loss = 29.0738
2024-10-31 01:50:23: [2024-10-31 01:50:23] iter = 16470, loss = 4.6735
2024-10-31 01:50:25: [2024-10-31 01:50:25] iter = 16480, loss = 16.1590
2024-10-31 01:50:28: [2024-10-31 01:50:28] iter = 16490, loss = 21.0235
2024-10-31 01:50:31: [2024-10-31 01:50:31] iter = 16500, loss = 41.8432
2024-10-31 01:50:34: [2024-10-31 01:50:34] iter = 16510, loss = 69.1760
2024-10-31 01:50:38: [2024-10-31 01:50:38] iter = 16520, loss = 33.3445
2024-10-31 01:50:40: [2024-10-31 01:50:40] iter = 16530, loss = 92.0973
2024-10-31 01:50:44: [2024-10-31 01:50:44] iter = 16540, loss = 42.7553
2024-10-31 01:50:47: [2024-10-31 01:50:47] iter = 16550, loss = 8.9631
2024-10-31 01:50:50: [2024-10-31 01:50:50] iter = 16560, loss = 18.6983
2024-10-31 01:50:53: [2024-10-31 01:50:53] iter = 16570, loss = 9.4235
2024-10-31 01:50:56: [2024-10-31 01:50:56] iter = 16580, loss = 42.4597
2024-10-31 01:50:59: [2024-10-31 01:50:59] iter = 16590, loss = 4.1216
2024-10-31 01:51:02: [2024-10-31 01:51:02] iter = 16600, loss = 39.0789
2024-10-31 01:51:05: [2024-10-31 01:51:05] iter = 16610, loss = 24.5554
2024-10-31 01:51:09: [2024-10-31 01:51:09] iter = 16620, loss = 8.4909
2024-10-31 01:51:12: [2024-10-31 01:51:12] iter = 16630, loss = 74.0052
2024-10-31 01:51:15: [2024-10-31 01:51:15] iter = 16640, loss = 25.9422
2024-10-31 01:51:18: [2024-10-31 01:51:18] iter = 16650, loss = 13.3414
2024-10-31 01:51:21: [2024-10-31 01:51:21] iter = 16660, loss = 5.2554
2024-10-31 01:51:24: [2024-10-31 01:51:24] iter = 16670, loss = 38.6243
2024-10-31 01:51:27: [2024-10-31 01:51:27] iter = 16680, loss = 40.9702
2024-10-31 01:51:31: [2024-10-31 01:51:31] iter = 16690, loss = 25.5971
2024-10-31 01:51:35: [2024-10-31 01:51:35] iter = 16700, loss = 19.0359
2024-10-31 01:51:37: [2024-10-31 01:51:37] iter = 16710, loss = 4.3508
2024-10-31 01:51:41: [2024-10-31 01:51:41] iter = 16720, loss = 8.7089
2024-10-31 01:51:44: [2024-10-31 01:51:44] iter = 16730, loss = 12.8910
2024-10-31 01:51:47: [2024-10-31 01:51:47] iter = 16740, loss = 49.7591
2024-10-31 01:51:50: [2024-10-31 01:51:50] iter = 16750, loss = 52.1608
2024-10-31 01:51:53: [2024-10-31 01:51:53] iter = 16760, loss = 17.2159
2024-10-31 01:51:57: [2024-10-31 01:51:57] iter = 16770, loss = 20.6729
2024-10-31 01:52:00: [2024-10-31 01:52:00] iter = 16780, loss = 5.3631
2024-10-31 01:52:04: [2024-10-31 01:52:04] iter = 16790, loss = 8.1135
2024-10-31 01:52:07: [2024-10-31 01:52:07] iter = 16800, loss = 6.3606
2024-10-31 01:52:10: [2024-10-31 01:52:10] iter = 16810, loss = 12.6401
2024-10-31 01:52:13: [2024-10-31 01:52:13] iter = 16820, loss = 18.7290
2024-10-31 01:52:16: [2024-10-31 01:52:16] iter = 16830, loss = 8.1239
2024-10-31 01:52:20: [2024-10-31 01:52:20] iter = 16840, loss = 15.1178
2024-10-31 01:52:23: [2024-10-31 01:52:23] iter = 16850, loss = 13.5218
2024-10-31 01:52:26: [2024-10-31 01:52:26] iter = 16860, loss = 4.6917
2024-10-31 01:52:29: [2024-10-31 01:52:29] iter = 16870, loss = 49.7704
2024-10-31 01:52:32: [2024-10-31 01:52:32] iter = 16880, loss = 3.1704
2024-10-31 01:52:36: [2024-10-31 01:52:36] iter = 16890, loss = 22.1417
2024-10-31 01:52:40: [2024-10-31 01:52:40] iter = 16900, loss = 12.0832
2024-10-31 01:52:43: [2024-10-31 01:52:43] iter = 16910, loss = 21.3895
2024-10-31 01:52:47: [2024-10-31 01:52:47] iter = 16920, loss = 15.5408
2024-10-31 01:52:50: [2024-10-31 01:52:50] iter = 16930, loss = 5.5510
2024-10-31 01:52:53: [2024-10-31 01:52:53] iter = 16940, loss = 3.7879
2024-10-31 01:52:57: [2024-10-31 01:52:57] iter = 16950, loss = 5.5109
2024-10-31 01:53:00: [2024-10-31 01:53:00] iter = 16960, loss = 16.5119
2024-10-31 01:53:03: [2024-10-31 01:53:03] iter = 16970, loss = 9.1593
2024-10-31 01:53:06: [2024-10-31 01:53:06] iter = 16980, loss = 8.0413
2024-10-31 01:53:09: [2024-10-31 01:53:09] iter = 16990, loss = 64.1856
2024-10-31 01:53:12: [2024-10-31 01:53:12] iter = 17000, loss = 22.9093
2024-10-31 01:53:15: [2024-10-31 01:53:15] iter = 17010, loss = 3.3242
2024-10-31 01:53:18: [2024-10-31 01:53:18] iter = 17020, loss = 9.1644
2024-10-31 01:53:21: [2024-10-31 01:53:21] iter = 17030, loss = 44.4395
2024-10-31 01:53:25: [2024-10-31 01:53:25] iter = 17040, loss = 15.4273
2024-10-31 01:53:29: [2024-10-31 01:53:29] iter = 17050, loss = 15.2333
2024-10-31 01:53:31: [2024-10-31 01:53:31] iter = 17060, loss = 37.3950
2024-10-31 01:53:35: [2024-10-31 01:53:35] iter = 17070, loss = 34.0699
2024-10-31 01:53:37: [2024-10-31 01:53:37] iter = 17080, loss = 6.3358
2024-10-31 01:53:39: [2024-10-31 01:53:39] iter = 17090, loss = 23.1243
2024-10-31 01:53:42: [2024-10-31 01:53:42] iter = 17100, loss = 33.5524
2024-10-31 01:53:45: [2024-10-31 01:53:45] iter = 17110, loss = 17.1479
2024-10-31 01:53:47: [2024-10-31 01:53:47] iter = 17120, loss = 10.0315
2024-10-31 01:53:50: [2024-10-31 01:53:50] iter = 17130, loss = 5.7177
2024-10-31 01:53:53: [2024-10-31 01:53:53] iter = 17140, loss = 9.9986
2024-10-31 01:53:56: [2024-10-31 01:53:56] iter = 17150, loss = 17.6313
2024-10-31 01:54:00: [2024-10-31 01:54:00] iter = 17160, loss = 40.9681
2024-10-31 01:54:04: [2024-10-31 01:54:04] iter = 17170, loss = 16.7749
2024-10-31 01:54:07: [2024-10-31 01:54:07] iter = 17180, loss = 26.7492
2024-10-31 01:54:11: [2024-10-31 01:54:10] iter = 17190, loss = 15.3505
2024-10-31 01:54:14: [2024-10-31 01:54:14] iter = 17200, loss = 11.4288
2024-10-31 01:54:17: [2024-10-31 01:54:17] iter = 17210, loss = 34.3067
2024-10-31 01:54:20: [2024-10-31 01:54:20] iter = 17220, loss = 19.7123
2024-10-31 01:54:24: [2024-10-31 01:54:24] iter = 17230, loss = 56.7857
2024-10-31 01:54:27: [2024-10-31 01:54:27] iter = 17240, loss = 9.1972
2024-10-31 01:54:30: [2024-10-31 01:54:30] iter = 17250, loss = 5.5011
2024-10-31 01:54:34: [2024-10-31 01:54:34] iter = 17260, loss = 6.0483
2024-10-31 01:54:39: [2024-10-31 01:54:39] iter = 17270, loss = 28.6600
2024-10-31 01:54:42: [2024-10-31 01:54:42] iter = 17280, loss = 49.9808
2024-10-31 01:54:46: [2024-10-31 01:54:46] iter = 17290, loss = 67.8070
2024-10-31 01:54:48: [2024-10-31 01:54:48] iter = 17300, loss = 5.8261
2024-10-31 01:54:52: [2024-10-31 01:54:52] iter = 17310, loss = 45.1397
2024-10-31 01:54:55: [2024-10-31 01:54:55] iter = 17320, loss = 5.1057
2024-10-31 01:54:58: [2024-10-31 01:54:58] iter = 17330, loss = 3.3223
2024-10-31 01:55:02: [2024-10-31 01:55:02] iter = 17340, loss = 16.3505
2024-10-31 01:55:04: [2024-10-31 01:55:04] iter = 17350, loss = 50.0556
2024-10-31 01:55:07: [2024-10-31 01:55:07] iter = 17360, loss = 37.2535
2024-10-31 01:55:11: [2024-10-31 01:55:11] iter = 17370, loss = 37.0087
2024-10-31 01:55:14: [2024-10-31 01:55:14] iter = 17380, loss = 28.5183
2024-10-31 01:55:17: [2024-10-31 01:55:17] iter = 17390, loss = 4.6915
2024-10-31 01:55:21: [2024-10-31 01:55:21] iter = 17400, loss = 31.6702
2024-10-31 01:55:24: [2024-10-31 01:55:24] iter = 17410, loss = 15.6099
2024-10-31 01:55:26: [2024-10-31 01:55:26] iter = 17420, loss = 20.0357
2024-10-31 01:55:30: [2024-10-31 01:55:30] iter = 17430, loss = 31.1360
2024-10-31 01:55:33: [2024-10-31 01:55:33] iter = 17440, loss = 6.0812
2024-10-31 01:55:37: [2024-10-31 01:55:37] iter = 17450, loss = 25.9255
2024-10-31 01:55:41: [2024-10-31 01:55:41] iter = 17460, loss = 35.4753
2024-10-31 01:55:45: [2024-10-31 01:55:45] iter = 17470, loss = 24.8384
2024-10-31 01:55:47: [2024-10-31 01:55:47] iter = 17480, loss = 3.9155
2024-10-31 01:55:50: [2024-10-31 01:55:50] iter = 17490, loss = 7.3632
2024-10-31 01:55:54: [2024-10-31 01:55:54] iter = 17500, loss = 16.9224
2024-10-31 01:55:57: [2024-10-31 01:55:57] iter = 17510, loss = 63.2173
2024-10-31 01:56:00: [2024-10-31 01:56:00] iter = 17520, loss = 46.3538
2024-10-31 01:56:04: [2024-10-31 01:56:04] iter = 17530, loss = 8.0488
2024-10-31 01:56:06: [2024-10-31 01:56:06] iter = 17540, loss = 14.7690
2024-10-31 01:56:10: [2024-10-31 01:56:10] iter = 17550, loss = 58.8676
2024-10-31 01:56:13: [2024-10-31 01:56:13] iter = 17560, loss = 18.1936
2024-10-31 01:56:16: [2024-10-31 01:56:16] iter = 17570, loss = 10.3499
2024-10-31 01:56:19: [2024-10-31 01:56:19] iter = 17580, loss = 18.0690
2024-10-31 01:56:22: [2024-10-31 01:56:22] iter = 17590, loss = 10.1871
2024-10-31 01:56:25: [2024-10-31 01:56:25] iter = 17600, loss = 87.7112
2024-10-31 01:56:28: [2024-10-31 01:56:28] iter = 17610, loss = 12.0833
2024-10-31 01:56:31: [2024-10-31 01:56:31] iter = 17620, loss = 4.6418
2024-10-31 01:56:34: [2024-10-31 01:56:34] iter = 17630, loss = 8.4027
2024-10-31 01:56:38: [2024-10-31 01:56:38] iter = 17640, loss = 12.1467
2024-10-31 01:56:41: [2024-10-31 01:56:41] iter = 17650, loss = 41.6473
2024-10-31 01:56:44: [2024-10-31 01:56:44] iter = 17660, loss = 42.0768
2024-10-31 01:56:47: [2024-10-31 01:56:47] iter = 17670, loss = 11.5097
2024-10-31 01:56:50: [2024-10-31 01:56:50] iter = 17680, loss = 27.5268
2024-10-31 01:56:53: [2024-10-31 01:56:53] iter = 17690, loss = 25.2705
2024-10-31 01:56:56: [2024-10-31 01:56:56] iter = 17700, loss = 3.7168
2024-10-31 01:56:59: [2024-10-31 01:56:59] iter = 17710, loss = 47.5515
2024-10-31 01:57:02: [2024-10-31 01:57:02] iter = 17720, loss = 60.1526
2024-10-31 01:57:05: [2024-10-31 01:57:05] iter = 17730, loss = 4.2487
2024-10-31 01:57:08: [2024-10-31 01:57:08] iter = 17740, loss = 21.5817
2024-10-31 01:57:11: [2024-10-31 01:57:11] iter = 17750, loss = 5.1994
2024-10-31 01:57:15: [2024-10-31 01:57:15] iter = 17760, loss = 11.6446
2024-10-31 01:57:18: [2024-10-31 01:57:18] iter = 17770, loss = 3.5869
2024-10-31 01:57:22: [2024-10-31 01:57:22] iter = 17780, loss = 53.0259
2024-10-31 01:57:25: [2024-10-31 01:57:25] iter = 17790, loss = 3.9710
2024-10-31 01:57:28: [2024-10-31 01:57:28] iter = 17800, loss = 32.9707
2024-10-31 01:57:30: [2024-10-31 01:57:30] iter = 17810, loss = 14.7011
2024-10-31 01:57:34: [2024-10-31 01:57:34] iter = 17820, loss = 6.3929
2024-10-31 01:57:37: [2024-10-31 01:57:37] iter = 17830, loss = 29.7782
2024-10-31 01:57:40: [2024-10-31 01:57:40] iter = 17840, loss = 10.5786
2024-10-31 01:57:43: [2024-10-31 01:57:43] iter = 17850, loss = 20.4339
2024-10-31 01:57:47: [2024-10-31 01:57:46] iter = 17860, loss = 4.7171
2024-10-31 01:57:50: [2024-10-31 01:57:50] iter = 17870, loss = 3.8479
2024-10-31 01:57:52: [2024-10-31 01:57:52] iter = 17880, loss = 29.2184
2024-10-31 01:57:55: [2024-10-31 01:57:55] iter = 17890, loss = 59.8239
2024-10-31 01:57:59: [2024-10-31 01:57:59] iter = 17900, loss = 14.4287
2024-10-31 01:58:02: [2024-10-31 01:58:02] iter = 17910, loss = 19.1700
2024-10-31 01:58:04: [2024-10-31 01:58:04] iter = 17920, loss = 16.2978
2024-10-31 01:58:07: [2024-10-31 01:58:07] iter = 17930, loss = 6.2045
2024-10-31 01:58:10: [2024-10-31 01:58:10] iter = 17940, loss = 53.3450
2024-10-31 01:58:12: [2024-10-31 01:58:12] iter = 17950, loss = 81.5053
2024-10-31 01:58:15: [2024-10-31 01:58:15] iter = 17960, loss = 64.4091
2024-10-31 01:58:18: [2024-10-31 01:58:18] iter = 17970, loss = 19.1054
2024-10-31 01:58:21: [2024-10-31 01:58:21] iter = 17980, loss = 24.3279
2024-10-31 01:58:24: [2024-10-31 01:58:24] iter = 17990, loss = 8.0714
2024-10-31 01:58:27: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 18000
2024-10-31 01:58:27: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 01:58:27: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 7028}
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:00:18: Evaluate 5 random ConvNet, ACCmean = 0.3922 ACCstd = 0.0093
-------------------------
2024-10-31 02:00:18: Evaluate 5 random ConvNet, SENmean = 0.3122 SENstd = 0.0019
-------------------------
2024-10-31 02:00:18: Evaluate 5 random ConvNet, SPEmean = 0.9105 SPEstd = 0.0008
-------------------------
2024-10-31 02:00:18: Evaluate 5 random ConvNet, F!mean = 0.2862 F!std = 0.0040
-------------------------
2024-10-31 02:00:18: Evaluate 5 random ConvNet, mean = 0.3922 std = 0.0093
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:00:18: [2024-10-31 02:00:18] iter = 18000, loss = 21.6310
2024-10-31 02:00:21: [2024-10-31 02:00:21] iter = 18010, loss = 8.0607
2024-10-31 02:00:24: [2024-10-31 02:00:24] iter = 18020, loss = 62.6831
2024-10-31 02:00:27: [2024-10-31 02:00:27] iter = 18030, loss = 6.9961
2024-10-31 02:00:30: [2024-10-31 02:00:30] iter = 18040, loss = 5.9550
2024-10-31 02:00:33: [2024-10-31 02:00:33] iter = 18050, loss = 26.5232
2024-10-31 02:00:36: [2024-10-31 02:00:36] iter = 18060, loss = 19.9407
2024-10-31 02:00:39: [2024-10-31 02:00:39] iter = 18070, loss = 116.3716
2024-10-31 02:00:42: [2024-10-31 02:00:42] iter = 18080, loss = 28.1536
2024-10-31 02:00:45: [2024-10-31 02:00:45] iter = 18090, loss = 43.8573
2024-10-31 02:00:48: [2024-10-31 02:00:48] iter = 18100, loss = 12.6897
2024-10-31 02:00:52: [2024-10-31 02:00:52] iter = 18110, loss = 21.5979
2024-10-31 02:00:55: [2024-10-31 02:00:55] iter = 18120, loss = 62.4041
2024-10-31 02:00:58: [2024-10-31 02:00:58] iter = 18130, loss = 50.7878
2024-10-31 02:01:01: [2024-10-31 02:01:01] iter = 18140, loss = 40.5221
2024-10-31 02:01:04: [2024-10-31 02:01:04] iter = 18150, loss = 3.8531
2024-10-31 02:01:07: [2024-10-31 02:01:07] iter = 18160, loss = 33.2746
2024-10-31 02:01:10: [2024-10-31 02:01:10] iter = 18170, loss = 10.8242
2024-10-31 02:01:13: [2024-10-31 02:01:13] iter = 18180, loss = 12.4222
2024-10-31 02:01:16: [2024-10-31 02:01:16] iter = 18190, loss = 4.8799
2024-10-31 02:01:20: [2024-10-31 02:01:20] iter = 18200, loss = 20.7585
2024-10-31 02:01:23: [2024-10-31 02:01:23] iter = 18210, loss = 44.6471
2024-10-31 02:01:26: [2024-10-31 02:01:26] iter = 18220, loss = 39.1888
2024-10-31 02:01:29: [2024-10-31 02:01:29] iter = 18230, loss = 9.8152
2024-10-31 02:01:32: [2024-10-31 02:01:32] iter = 18240, loss = 17.3599
2024-10-31 02:01:35: [2024-10-31 02:01:35] iter = 18250, loss = 10.3364
2024-10-31 02:01:38: [2024-10-31 02:01:38] iter = 18260, loss = 16.0094
2024-10-31 02:01:41: [2024-10-31 02:01:41] iter = 18270, loss = 32.3627
2024-10-31 02:01:45: [2024-10-31 02:01:45] iter = 18280, loss = 29.1537
2024-10-31 02:01:48: [2024-10-31 02:01:48] iter = 18290, loss = 3.7679
2024-10-31 02:01:52: [2024-10-31 02:01:52] iter = 18300, loss = 10.8956
2024-10-31 02:01:56: [2024-10-31 02:01:56] iter = 18310, loss = 6.1968
2024-10-31 02:01:59: [2024-10-31 02:01:59] iter = 18320, loss = 14.1466
2024-10-31 02:02:02: [2024-10-31 02:02:02] iter = 18330, loss = 3.7186
2024-10-31 02:02:05: [2024-10-31 02:02:05] iter = 18340, loss = 10.0973
2024-10-31 02:02:09: [2024-10-31 02:02:09] iter = 18350, loss = 6.8251
2024-10-31 02:02:11: [2024-10-31 02:02:11] iter = 18360, loss = 4.6834
2024-10-31 02:02:15: [2024-10-31 02:02:15] iter = 18370, loss = 59.2931
2024-10-31 02:02:18: [2024-10-31 02:02:18] iter = 18380, loss = 9.1018
2024-10-31 02:02:22: [2024-10-31 02:02:22] iter = 18390, loss = 33.3008
2024-10-31 02:02:25: [2024-10-31 02:02:25] iter = 18400, loss = 4.8307
2024-10-31 02:02:28: [2024-10-31 02:02:28] iter = 18410, loss = 15.4599
2024-10-31 02:02:31: [2024-10-31 02:02:31] iter = 18420, loss = 4.7025
2024-10-31 02:02:34: [2024-10-31 02:02:34] iter = 18430, loss = 14.8490
2024-10-31 02:02:37: [2024-10-31 02:02:37] iter = 18440, loss = 49.2095
2024-10-31 02:02:41: [2024-10-31 02:02:40] iter = 18450, loss = 10.9114
2024-10-31 02:02:44: [2024-10-31 02:02:44] iter = 18460, loss = 25.2550
2024-10-31 02:02:48: [2024-10-31 02:02:48] iter = 18470, loss = 54.7481
2024-10-31 02:02:51: [2024-10-31 02:02:51] iter = 18480, loss = 12.7972
2024-10-31 02:02:54: [2024-10-31 02:02:54] iter = 18490, loss = 18.0178
2024-10-31 02:02:58: [2024-10-31 02:02:58] iter = 18500, loss = 59.7077
2024-10-31 02:03:01: [2024-10-31 02:03:01] iter = 18510, loss = 8.3199
2024-10-31 02:03:04: [2024-10-31 02:03:04] iter = 18520, loss = 6.7169
2024-10-31 02:03:08: [2024-10-31 02:03:08] iter = 18530, loss = 9.2958
2024-10-31 02:03:11: [2024-10-31 02:03:11] iter = 18540, loss = 13.3504
2024-10-31 02:03:14: [2024-10-31 02:03:14] iter = 18550, loss = 10.3872
2024-10-31 02:03:18: [2024-10-31 02:03:18] iter = 18560, loss = 32.5047
2024-10-31 02:03:22: [2024-10-31 02:03:22] iter = 18570, loss = 45.6901
2024-10-31 02:03:25: [2024-10-31 02:03:25] iter = 18580, loss = 67.8987
2024-10-31 02:03:29: [2024-10-31 02:03:29] iter = 18590, loss = 10.3781
2024-10-31 02:03:32: [2024-10-31 02:03:32] iter = 18600, loss = 4.7901
2024-10-31 02:03:35: [2024-10-31 02:03:35] iter = 18610, loss = 3.8658
2024-10-31 02:03:39: [2024-10-31 02:03:39] iter = 18620, loss = 9.4987
2024-10-31 02:03:42: [2024-10-31 02:03:42] iter = 18630, loss = 27.6437
2024-10-31 02:03:46: [2024-10-31 02:03:46] iter = 18640, loss = 33.4244
2024-10-31 02:03:49: [2024-10-31 02:03:49] iter = 18650, loss = 4.0222
2024-10-31 02:03:53: [2024-10-31 02:03:53] iter = 18660, loss = 16.4255
2024-10-31 02:03:57: [2024-10-31 02:03:57] iter = 18670, loss = 6.5850
2024-10-31 02:04:00: [2024-10-31 02:04:00] iter = 18680, loss = 33.9609
2024-10-31 02:04:04: [2024-10-31 02:04:04] iter = 18690, loss = 50.7066
2024-10-31 02:04:07: [2024-10-31 02:04:07] iter = 18700, loss = 22.6227
2024-10-31 02:04:11: [2024-10-31 02:04:11] iter = 18710, loss = 4.6422
2024-10-31 02:04:14: [2024-10-31 02:04:14] iter = 18720, loss = 52.8568
2024-10-31 02:04:17: [2024-10-31 02:04:17] iter = 18730, loss = 29.4065
2024-10-31 02:04:19: [2024-10-31 02:04:19] iter = 18740, loss = 63.5733
2024-10-31 02:04:23: [2024-10-31 02:04:23] iter = 18750, loss = 6.5046
2024-10-31 02:04:26: [2024-10-31 02:04:26] iter = 18760, loss = 9.9004
2024-10-31 02:04:29: [2024-10-31 02:04:29] iter = 18770, loss = 5.5340
2024-10-31 02:04:32: [2024-10-31 02:04:32] iter = 18780, loss = 3.9930
2024-10-31 02:04:34: [2024-10-31 02:04:34] iter = 18790, loss = 3.7225
2024-10-31 02:04:37: [2024-10-31 02:04:37] iter = 18800, loss = 38.8100
2024-10-31 02:04:41: [2024-10-31 02:04:41] iter = 18810, loss = 48.4732
2024-10-31 02:04:45: [2024-10-31 02:04:45] iter = 18820, loss = 7.8819
2024-10-31 02:04:47: [2024-10-31 02:04:47] iter = 18830, loss = 12.6704
2024-10-31 02:04:51: [2024-10-31 02:04:51] iter = 18840, loss = 18.8627
2024-10-31 02:04:54: [2024-10-31 02:04:54] iter = 18850, loss = 11.0973
2024-10-31 02:04:58: [2024-10-31 02:04:58] iter = 18860, loss = 30.2484
2024-10-31 02:05:01: [2024-10-31 02:05:01] iter = 18870, loss = 20.2158
2024-10-31 02:05:04: [2024-10-31 02:05:04] iter = 18880, loss = 28.4701
2024-10-31 02:05:08: [2024-10-31 02:05:08] iter = 18890, loss = 4.1480
2024-10-31 02:05:11: [2024-10-31 02:05:11] iter = 18900, loss = 12.0635
2024-10-31 02:05:15: [2024-10-31 02:05:15] iter = 18910, loss = 7.5453
2024-10-31 02:05:18: [2024-10-31 02:05:18] iter = 18920, loss = 6.4649
2024-10-31 02:05:21: [2024-10-31 02:05:21] iter = 18930, loss = 8.8420
2024-10-31 02:05:25: [2024-10-31 02:05:25] iter = 18940, loss = 15.6676
2024-10-31 02:05:27: [2024-10-31 02:05:27] iter = 18950, loss = 33.5261
2024-10-31 02:05:31: [2024-10-31 02:05:31] iter = 18960, loss = 7.1812
2024-10-31 02:05:34: [2024-10-31 02:05:34] iter = 18970, loss = 8.5439
2024-10-31 02:05:37: [2024-10-31 02:05:37] iter = 18980, loss = 12.8705
2024-10-31 02:05:40: [2024-10-31 02:05:40] iter = 18990, loss = 20.1828
2024-10-31 02:05:43: [2024-10-31 02:05:43] iter = 19000, loss = 14.4555
2024-10-31 02:05:45: [2024-10-31 02:05:45] iter = 19010, loss = 5.4223
2024-10-31 02:05:48: [2024-10-31 02:05:48] iter = 19020, loss = 23.4141
2024-10-31 02:05:51: [2024-10-31 02:05:51] iter = 19030, loss = 38.7557
2024-10-31 02:05:54: [2024-10-31 02:05:54] iter = 19040, loss = 3.9482
2024-10-31 02:05:57: [2024-10-31 02:05:57] iter = 19050, loss = 3.9338
2024-10-31 02:06:00: [2024-10-31 02:06:00] iter = 19060, loss = 50.2916
2024-10-31 02:06:03: [2024-10-31 02:06:03] iter = 19070, loss = 14.1356
2024-10-31 02:06:07: [2024-10-31 02:06:07] iter = 19080, loss = 8.0273
2024-10-31 02:06:09: [2024-10-31 02:06:09] iter = 19090, loss = 15.8696
2024-10-31 02:06:13: [2024-10-31 02:06:13] iter = 19100, loss = 28.2286
2024-10-31 02:06:15: [2024-10-31 02:06:15] iter = 19110, loss = 10.7144
2024-10-31 02:06:18: [2024-10-31 02:06:18] iter = 19120, loss = 21.2423
2024-10-31 02:06:20: [2024-10-31 02:06:20] iter = 19130, loss = 6.8362
2024-10-31 02:06:24: [2024-10-31 02:06:24] iter = 19140, loss = 11.3280
2024-10-31 02:06:27: [2024-10-31 02:06:27] iter = 19150, loss = 90.2044
2024-10-31 02:06:30: [2024-10-31 02:06:30] iter = 19160, loss = 12.5791
2024-10-31 02:06:33: [2024-10-31 02:06:33] iter = 19170, loss = 47.7128
2024-10-31 02:06:36: [2024-10-31 02:06:36] iter = 19180, loss = 63.7809
2024-10-31 02:06:40: [2024-10-31 02:06:40] iter = 19190, loss = 4.5708
2024-10-31 02:06:43: [2024-10-31 02:06:43] iter = 19200, loss = 12.7685
2024-10-31 02:06:46: [2024-10-31 02:06:46] iter = 19210, loss = 29.4718
2024-10-31 02:06:48: [2024-10-31 02:06:48] iter = 19220, loss = 25.0672
2024-10-31 02:06:52: [2024-10-31 02:06:52] iter = 19230, loss = 6.4093
2024-10-31 02:06:54: [2024-10-31 02:06:54] iter = 19240, loss = 5.0277
2024-10-31 02:06:58: [2024-10-31 02:06:58] iter = 19250, loss = 3.3714
2024-10-31 02:07:01: [2024-10-31 02:07:01] iter = 19260, loss = 22.8792
2024-10-31 02:07:05: [2024-10-31 02:07:05] iter = 19270, loss = 10.9763
2024-10-31 02:07:09: [2024-10-31 02:07:09] iter = 19280, loss = 28.6601
2024-10-31 02:07:12: [2024-10-31 02:07:12] iter = 19290, loss = 4.6470
2024-10-31 02:07:15: [2024-10-31 02:07:15] iter = 19300, loss = 3.4716
2024-10-31 02:07:18: [2024-10-31 02:07:18] iter = 19310, loss = 38.5080
2024-10-31 02:07:22: [2024-10-31 02:07:22] iter = 19320, loss = 6.7138
2024-10-31 02:07:25: [2024-10-31 02:07:25] iter = 19330, loss = 12.1130
2024-10-31 02:07:28: [2024-10-31 02:07:28] iter = 19340, loss = 3.6352
2024-10-31 02:07:32: [2024-10-31 02:07:32] iter = 19350, loss = 23.4686
2024-10-31 02:07:35: [2024-10-31 02:07:35] iter = 19360, loss = 17.8463
2024-10-31 02:07:38: [2024-10-31 02:07:38] iter = 19370, loss = 4.9742
2024-10-31 02:07:41: [2024-10-31 02:07:41] iter = 19380, loss = 3.7241
2024-10-31 02:07:43: [2024-10-31 02:07:43] iter = 19390, loss = 19.8399
2024-10-31 02:07:45: [2024-10-31 02:07:45] iter = 19400, loss = 20.2960
2024-10-31 02:07:49: [2024-10-31 02:07:49] iter = 19410, loss = 23.5626
2024-10-31 02:07:52: [2024-10-31 02:07:52] iter = 19420, loss = 24.0410
2024-10-31 02:07:55: [2024-10-31 02:07:55] iter = 19430, loss = 16.6135
2024-10-31 02:07:58: [2024-10-31 02:07:58] iter = 19440, loss = 3.7560
2024-10-31 02:08:02: [2024-10-31 02:08:02] iter = 19450, loss = 3.7897
2024-10-31 02:08:06: [2024-10-31 02:08:06] iter = 19460, loss = 5.7609
2024-10-31 02:08:09: [2024-10-31 02:08:09] iter = 19470, loss = 5.2609
2024-10-31 02:08:13: [2024-10-31 02:08:13] iter = 19480, loss = 13.0324
2024-10-31 02:08:15: [2024-10-31 02:08:15] iter = 19490, loss = 10.5008
2024-10-31 02:08:18: [2024-10-31 02:08:18] iter = 19500, loss = 7.8175
2024-10-31 02:08:22: [2024-10-31 02:08:22] iter = 19510, loss = 18.8583
2024-10-31 02:08:26: [2024-10-31 02:08:26] iter = 19520, loss = 5.9817
2024-10-31 02:08:28: [2024-10-31 02:08:28] iter = 19530, loss = 61.2601
2024-10-31 02:08:31: [2024-10-31 02:08:31] iter = 19540, loss = 13.3733
2024-10-31 02:08:34: [2024-10-31 02:08:34] iter = 19550, loss = 6.2448
2024-10-31 02:08:37: [2024-10-31 02:08:37] iter = 19560, loss = 6.3795
2024-10-31 02:08:40: [2024-10-31 02:08:40] iter = 19570, loss = 27.1307
2024-10-31 02:08:43: [2024-10-31 02:08:43] iter = 19580, loss = 38.3721
2024-10-31 02:08:47: [2024-10-31 02:08:47] iter = 19590, loss = 12.3535
2024-10-31 02:08:49: [2024-10-31 02:08:49] iter = 19600, loss = 9.8423
2024-10-31 02:08:53: [2024-10-31 02:08:53] iter = 19610, loss = 47.4422
2024-10-31 02:08:56: [2024-10-31 02:08:56] iter = 19620, loss = 18.0704
2024-10-31 02:09:00: [2024-10-31 02:09:00] iter = 19630, loss = 11.0302
2024-10-31 02:09:03: [2024-10-31 02:09:03] iter = 19640, loss = 10.0814
2024-10-31 02:09:07: [2024-10-31 02:09:07] iter = 19650, loss = 12.6745
2024-10-31 02:09:10: [2024-10-31 02:09:10] iter = 19660, loss = 47.1355
2024-10-31 02:09:14: [2024-10-31 02:09:14] iter = 19670, loss = 7.8448
2024-10-31 02:09:16: [2024-10-31 02:09:16] iter = 19680, loss = 9.4932
2024-10-31 02:09:19: [2024-10-31 02:09:19] iter = 19690, loss = 7.6585
2024-10-31 02:09:22: [2024-10-31 02:09:22] iter = 19700, loss = 45.0828
2024-10-31 02:09:25: [2024-10-31 02:09:25] iter = 19710, loss = 7.6955
2024-10-31 02:09:29: [2024-10-31 02:09:29] iter = 19720, loss = 32.6693
2024-10-31 02:09:32: [2024-10-31 02:09:32] iter = 19730, loss = 8.6199
2024-10-31 02:09:36: [2024-10-31 02:09:36] iter = 19740, loss = 35.1589
2024-10-31 02:09:39: [2024-10-31 02:09:39] iter = 19750, loss = 3.7236
2024-10-31 02:09:42: [2024-10-31 02:09:42] iter = 19760, loss = 5.2165
2024-10-31 02:09:45: [2024-10-31 02:09:45] iter = 19770, loss = 9.3760
2024-10-31 02:09:48: [2024-10-31 02:09:48] iter = 19780, loss = 7.9739
2024-10-31 02:09:52: [2024-10-31 02:09:52] iter = 19790, loss = 13.7355
2024-10-31 02:09:55: [2024-10-31 02:09:55] iter = 19800, loss = 4.6578
2024-10-31 02:09:58: [2024-10-31 02:09:58] iter = 19810, loss = 16.4685
2024-10-31 02:10:01: [2024-10-31 02:10:01] iter = 19820, loss = 4.2888
2024-10-31 02:10:04: [2024-10-31 02:10:04] iter = 19830, loss = 12.9126
2024-10-31 02:10:07: [2024-10-31 02:10:07] iter = 19840, loss = 8.1548
2024-10-31 02:10:11: [2024-10-31 02:10:11] iter = 19850, loss = 7.4227
2024-10-31 02:10:14: [2024-10-31 02:10:14] iter = 19860, loss = 4.6981
2024-10-31 02:10:17: [2024-10-31 02:10:17] iter = 19870, loss = 13.6449
2024-10-31 02:10:21: [2024-10-31 02:10:21] iter = 19880, loss = 10.5370
2024-10-31 02:10:24: [2024-10-31 02:10:24] iter = 19890, loss = 62.1521
2024-10-31 02:10:27: [2024-10-31 02:10:27] iter = 19900, loss = 3.9271
2024-10-31 02:10:30: [2024-10-31 02:10:30] iter = 19910, loss = 8.6486
2024-10-31 02:10:33: [2024-10-31 02:10:33] iter = 19920, loss = 4.7209
2024-10-31 02:10:36: [2024-10-31 02:10:36] iter = 19930, loss = 39.2772
2024-10-31 02:10:38: [2024-10-31 02:10:38] iter = 19940, loss = 5.0344
2024-10-31 02:10:41: [2024-10-31 02:10:41] iter = 19950, loss = 11.7370
2024-10-31 02:10:44: [2024-10-31 02:10:44] iter = 19960, loss = 12.8215
2024-10-31 02:10:47: [2024-10-31 02:10:47] iter = 19970, loss = 5.2813
2024-10-31 02:10:50: [2024-10-31 02:10:50] iter = 19980, loss = 11.4100
2024-10-31 02:10:51: [2024-10-31 02:10:51] iter = 19990, loss = 7.0158
2024-10-31 02:10:53: -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 20000
2024-10-31 02:10:53: DSA augmentation strategy: 
color_crop_cutout_flip_scale_rotate
2024-10-31 02:10:53: DSA augmentation parameters: 
{'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 53480}

[2024-10-31 00:16:27] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.025782 train acc = 1.0000, test acc = 0.3558, test_sen =0.3012, test_spe =0.9073, test_f1 =0.2672
[2024-10-31 00:28:03] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.008370 train acc = 1.0000, test acc = 0.2834, test_sen =0.2763, test_spe =0.8991, test_f1 =0.2431
[2024-10-31 00:28:28] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.002856 train acc = 1.0000, test acc = 0.2995, test_sen =0.2854, test_spe =0.9014, test_f1 =0.2535
[2024-10-31 00:28:56] Evaluate_02: epoch = 1000 train time = 22 s train loss = 0.063225 train acc = 1.0000, test acc = 0.3092, test_sen =0.2906, test_spe =0.9022, test_f1 =0.2602
[2024-10-31 00:29:19] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.016568 train acc = 1.0000, test acc = 0.2967, test_sen =0.2902, test_spe =0.9010, test_f1 =0.2564
[2024-10-31 00:29:44] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.006922 train acc = 1.0000, test acc = 0.2849, test_sen =0.2794, test_spe =0.8998, test_f1 =0.2455
[2024-10-31 00:41:27] Evaluate_00: epoch = 1000 train time = 21 s train loss = 0.002573 train acc = 1.0000, test acc = 0.3381, test_sen =0.2900, test_spe =0.9052, test_f1 =0.2548
[2024-10-31 00:41:50] Evaluate_01: epoch = 1000 train time = 18 s train loss = 0.010069 train acc = 1.0000, test acc = 0.3546, test_sen =0.2929, test_spe =0.9069, test_f1 =0.2632
[2024-10-31 00:42:15] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.025425 train acc = 1.0000, test acc = 0.3515, test_sen =0.2905, test_spe =0.9066, test_f1 =0.2556
[2024-10-31 00:42:40] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.010199 train acc = 1.0000, test acc = 0.3416, test_sen =0.2927, test_spe =0.9058, test_f1 =0.2572
[2024-10-31 00:43:02] Evaluate_04: epoch = 1000 train time = 18 s train loss = 0.002357 train acc = 1.0000, test acc = 0.3618, test_sen =0.2961, test_spe =0.9073, test_f1 =0.2637
[2024-10-31 00:54:25] Evaluate_00: epoch = 1000 train time = 24 s train loss = 0.009633 train acc = 1.0000, test acc = 0.3110, test_sen =0.2937, test_spe =0.9032, test_f1 =0.2546
[2024-10-31 00:54:52] Evaluate_01: epoch = 1000 train time = 22 s train loss = 0.002052 train acc = 1.0000, test acc = 0.3027, test_sen =0.2911, test_spe =0.9023, test_f1 =0.2538
[2024-10-31 00:55:16] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.004992 train acc = 1.0000, test acc = 0.2981, test_sen =0.2899, test_spe =0.9019, test_f1 =0.2498
[2024-10-31 00:55:40] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.003675 train acc = 1.0000, test acc = 0.3063, test_sen =0.2890, test_spe =0.9025, test_f1 =0.2504
[2024-10-31 00:56:04] Evaluate_04: epoch = 1000 train time = 19 s train loss = 0.001497 train acc = 1.0000, test acc = 0.2859, test_sen =0.2860, test_spe =0.9006, test_f1 =0.2413
[2024-10-31 01:07:34] Evaluate_00: epoch = 1000 train time = 20 s train loss = 0.013241 train acc = 1.0000, test acc = 0.3988, test_sen =0.3172, test_spe =0.9114, test_f1 =0.3062
[2024-10-31 01:08:00] Evaluate_01: epoch = 1000 train time = 21 s train loss = 0.009742 train acc = 1.0000, test acc = 0.3992, test_sen =0.3156, test_spe =0.9114, test_f1 =0.3015
[2024-10-31 01:08:26] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.017006 train acc = 1.0000, test acc = 0.3960, test_sen =0.3102, test_spe =0.9106, test_f1 =0.2994
[2024-10-31 01:08:50] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.014091 train acc = 1.0000, test acc = 0.4036, test_sen =0.3203, test_spe =0.9120, test_f1 =0.3046
[2024-10-31 01:09:17] Evaluate_04: epoch = 1000 train time = 22 s train loss = 0.046053 train acc = 0.9875, test acc = 0.3964, test_sen =0.3198, test_spe =0.9112, test_f1 =0.3053
[2024-10-31 01:21:01] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.001759 train acc = 1.0000, test acc = 0.4255, test_sen =0.3033, test_spe =0.9123, test_f1 =0.2846
[2024-10-31 01:21:26] Evaluate_01: epoch = 1000 train time = 20 s train loss = 0.004539 train acc = 1.0000, test acc = 0.4086, test_sen =0.3111, test_spe =0.9120, test_f1 =0.2865
[2024-10-31 01:21:51] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.001862 train acc = 1.0000, test acc = 0.4215, test_sen =0.3104, test_spe =0.9124, test_f1 =0.2909
[2024-10-31 01:22:16] Evaluate_03: epoch = 1000 train time = 20 s train loss = 0.025442 train acc = 1.0000, test acc = 0.4220, test_sen =0.3095, test_spe =0.9122, test_f1 =0.2919
[2024-10-31 01:22:40] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.033214 train acc = 1.0000, test acc = 0.4226, test_sen =0.3035, test_spe =0.9121, test_f1 =0.2827
[2024-10-31 01:34:02] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.026175 train acc = 1.0000, test acc = 0.2695, test_sen =0.2779, test_spe =0.8972, test_f1 =0.2332
[2024-10-31 01:34:25] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.003201 train acc = 1.0000, test acc = 0.2946, test_sen =0.2937, test_spe =0.9007, test_f1 =0.2562
[2024-10-31 01:34:50] Evaluate_02: epoch = 1000 train time = 20 s train loss = 0.008977 train acc = 1.0000, test acc = 0.3186, test_sen =0.2999, test_spe =0.9034, test_f1 =0.2697
[2024-10-31 01:35:13] Evaluate_03: epoch = 1000 train time = 19 s train loss = 0.002200 train acc = 1.0000, test acc = 0.2969, test_sen =0.2928, test_spe =0.9007, test_f1 =0.2558
[2024-10-31 01:35:38] Evaluate_04: epoch = 1000 train time = 20 s train loss = 0.022023 train acc = 1.0000, test acc = 0.3183, test_sen =0.2874, test_spe =0.9025, test_f1 =0.2585
[2024-10-31 01:46:39] Evaluate_00: epoch = 1000 train time = 16 s train loss = 0.029484 train acc = 1.0000, test acc = 0.2384, test_sen =0.2747, test_spe =0.8940, test_f1 =0.2069
[2024-10-31 01:46:59] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.002584 train acc = 1.0000, test acc = 0.2411, test_sen =0.2830, test_spe =0.8946, test_f1 =0.2083
[2024-10-31 01:47:18] Evaluate_02: epoch = 1000 train time = 15 s train loss = 0.008508 train acc = 1.0000, test acc = 0.2534, test_sen =0.2853, test_spe =0.8958, test_f1 =0.2198
[2024-10-31 01:47:38] Evaluate_03: epoch = 1000 train time = 16 s train loss = 0.010160 train acc = 1.0000, test acc = 0.2519, test_sen =0.2811, test_spe =0.8958, test_f1 =0.2208
[2024-10-31 01:47:59] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.006974 train acc = 1.0000, test acc = 0.2417, test_sen =0.2821, test_spe =0.8948, test_f1 =0.2132
[2024-10-31 01:58:50] Evaluate_00: epoch = 1000 train time = 19 s train loss = 0.003616 train acc = 1.0000, test acc = 0.4035, test_sen =0.3125, test_spe =0.9114, test_f1 =0.2888
[2024-10-31 01:59:11] Evaluate_01: epoch = 1000 train time = 16 s train loss = 0.003894 train acc = 1.0000, test acc = 0.3989, test_sen =0.3152, test_spe =0.9111, test_f1 =0.2903
[2024-10-31 01:59:34] Evaluate_02: epoch = 1000 train time = 19 s train loss = 0.050393 train acc = 0.9875, test acc = 0.3945, test_sen =0.3128, test_spe =0.9107, test_f1 =0.2868
[2024-10-31 01:59:56] Evaluate_03: epoch = 1000 train time = 17 s train loss = 0.002960 train acc = 1.0000, test acc = 0.3869, test_sen =0.3096, test_spe =0.9098, test_f1 =0.2864
[2024-10-31 02:00:18] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.003962 train acc = 1.0000, test acc = 0.3772, test_sen =0.3110, test_spe =0.9093, test_f1 =0.2788
[2024-10-31 02:11:15] Evaluate_00: epoch = 1000 train time = 17 s train loss = 0.067176 train acc = 1.0000, test acc = 0.3249, test_sen =0.3026, test_spe =0.9048, test_f1 =0.2577
[2024-10-31 02:11:36] Evaluate_01: epoch = 1000 train time = 17 s train loss = 0.007308 train acc = 1.0000, test acc = 0.3218, test_sen =0.3066, test_spe =0.9044, test_f1 =0.2574
[2024-10-31 02:11:56] Evaluate_02: epoch = 1000 train time = 15 s train loss = 0.004629 train acc = 1.0000, test acc = 0.3079, test_sen =0.2977, test_spe =0.9028, test_f1 =0.2478
[2024-10-31 02:12:18] Evaluate_03: epoch = 1000 train time = 18 s train loss = 0.024255 train acc = 1.0000, test acc = 0.3247, test_sen =0.3028, test_spe =0.9044, test_f1 =0.2579
[2024-10-31 02:12:40] Evaluate_04: epoch = 1000 train time = 17 s train loss = 0.004541 train acc = 1.0000, test acc = 0.3170, test_sen =0.2987, test_spe =0.9038, test_f1 =0.2486/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:12:40: Evaluate 5 random ConvNet, ACCmean = 0.3193 ACCstd = 0.0064
-------------------------
2024-10-31 02:12:40: Evaluate 5 random ConvNet, SENmean = 0.3017 SENstd = 0.0032
-------------------------
2024-10-31 02:12:40: Evaluate 5 random ConvNet, SPEmean = 0.9040 SPEstd = 0.0007
-------------------------
2024-10-31 02:12:40: Evaluate 5 random ConvNet, F!mean = 0.2539 F!std = 0.0047
-------------------------
2024-10-31 02:12:40: Evaluate 5 random ConvNet, mean = 0.3193 std = 0.0064
-------------------------
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/data/users/xiongyuxuan/anaconda3/envs/DD/lib/python3.8/site-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
2024-10-31 02:12:41: [2024-10-31 02:12:41] iter = 20000, loss = 33.0719
2024-10-31 02:12:41: 
==================== Final Results ====================

2024-10-31 02:12:41: Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 34.80%  std = 2.59%

