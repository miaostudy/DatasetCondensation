import subprocess
import re
import os
import time
import pandas as pd
from datetime import datetime
from collections import deque
import sys

# ================= é…ç½®åŒºåŸŸ =================
# 1. æ•°æ®é›† (12ä¸ª)
DATASETS = [
    'PathMNIST', 'OCTMNIST', 'ChestMNIST', 'BreastMNIST',
    'TissueMNIST', 'BloodMNIST', 'PneumoniaMNIST',
    'OrganAMNIST', 'OrganCMNIST', 'OrganSMNIST',
    'RetinaMNIST', 'DermaMNIST'
]

# 2. IPC è®¾ç½® (3ä¸ª) -> æ€»ä»»åŠ¡æ•° = 12 * 3 = 36
IPCS = [1, 10, 50]

# 3. æ ¸å¿ƒä¿®æ”¹ï¼šèµ„æºæ± é…ç½®

REAL_GPU_IDS = ['0', '1']
MAX_WORKERS_PER_GPU = 4  # æ¯å¼ å¡è·‘ 4 ä¸ªä»»åŠ¡

# æ„é€ è™šæ‹Ÿ GPU èµ„æºæ± : ['0', '1', '0', '1', '0', '1', '0', '1']
AVAILABLE_RESOURCES = deque(REAL_GPU_IDS * MAX_WORKERS_PER_GPU)

# é€šç”¨å‚æ•°
MODEL = 'ConvNet'
PROXY_MODEL = 'ResNet18'
CAM_TYPE = 'GradCAM'
PROJECT_NAME = 'Benchmark_0905'


# ===========================================

def parse_output_from_file(log_path):
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­è¯»å–å¹¶è§£æ Accuracy å’Œ F1 Score"""
    try:
        if not os.path.exists(log_path):
            return "No Log", "No Log"

        with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        acc_pattern = re.search(r'Final Accuracy - Mean = ([\d\.]+)%,', content)
        f1_patterns = re.findall(r'F1mean = ([\d\.]+) ', content)

        acc = acc_pattern.group(1) if acc_pattern else "N/A"
        f1 = f1_patterns[-1] if f1_patterns else "N/A"

        return acc, f1
    except Exception as e:
        return f"Err: {str(e)}", "Err"


def run_parallel_experiments():
    # åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—
    task_queue = deque([(ds, ipc) for ipc in IPCS for ds in DATASETS])

    # æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡: {process_object: (gpu_id, dataset, ipc, log_file)}
    running_procs = {}

    results = []

    # å‡†å¤‡ç›®å½•
    log_dir = f"./{PROJECT_NAME}/logs"
    res_dir = f"./{PROJECT_NAME}/result"
    for d in [log_dir, res_dir]:
        if not os.path.exists(d):
            os.makedirs(d)

    total_tasks = len(task_queue)
    finished_tasks = 0

    print(f"ğŸš€ å¼€å§‹å¹¶è¡Œè¯„æµ‹ (8è¿›ç¨‹/2GPU)")
    print(f"ğŸ“Œ æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"ğŸ’» ç‰©ç† GPU: {REAL_GPU_IDS}")
    print(f"âš¡ å¹¶å‘ç­–ç•¥: æ¯å¼ å¡ {MAX_WORKERS_PER_GPU} ä¸ªä»»åŠ¡ (æ€»å¹¶å‘ {len(AVAILABLE_RESOURCES)})")
    print("-" * 60)

    # ä¸»å¾ªç¯
    while task_queue or running_procs:

        # --- A. æ£€æŸ¥å®Œæˆçš„ä»»åŠ¡ ---
        for proc in list(running_procs.keys()):
            if proc.poll() is not None:
                gpu_id, dataset, ipc, log_file = running_procs[proc]

                # 1. å›æ”¶èµ„æº (æŠŠ GPU ID æ”¾å›æ± å­)
                AVAILABLE_RESOURCES.append(gpu_id)
                # 2. ç§»é™¤è®°å½•
                del running_procs[proc]

                finished_tasks += 1

                # 3. è§£æç»“æœ
                acc, f1 = parse_output_from_file(log_file)
                status = "âœ…" if proc.returncode == 0 else "âŒ"

                # æ‰“å°ç®€æ´è¿›åº¦
                print(
                    f"[{finished_tasks}/{total_tasks}] {status} å®Œæˆ: {dataset} (IPC={ipc}) | GPU: {gpu_id} | Acc: {acc}%")

                results.append({
                    "Dataset": dataset,
                    "IPC": ipc,
                    "Accuracy": acc,
                    "F1 Score": f1
                })

        # --- B. åˆ†å‘æ–°ä»»åŠ¡ ---
        while task_queue and AVAILABLE_RESOURCES:
            # æ‹¿åˆ°ä¸€ä¸ªâ€œè™šæ‹Ÿå·¥ä½â€ (æ¯”å¦‚ '0' å·å¡çš„ä¸€ä¸ªåé¢)
            gpu_id = AVAILABLE_RESOURCES.popleft()
            dataset, ipc = task_queue.popleft()

            log_filename = f"{dataset}_IPC{ipc}.log"
            log_path = os.path.join(log_dir, log_filename)

            cmd = [
                "python", "-u", "mWCAMDM.py",
                "--dataset", dataset,
                "--model", MODEL,
                "--ipc", str(ipc),
                "--proxy_model", PROXY_MODEL,
                "--cam_type", CAM_TYPE,
                "--eval_mode", "SS",
                "--save_path", res_dir,
                "--log_dir", log_dir
            ]

            # å…³é”®ï¼šæŒ‡å®šè¯¥è¿›ç¨‹åªèƒ½çœ‹åˆ°åˆ†é…ç»™å®ƒçš„é‚£å¼ å¡
            env = os.environ.copy()
            env["CUDA_VISIBLE_DEVICES"] = gpu_id

            print(f"ğŸš€ å¯åŠ¨: {dataset} (IPC={ipc}) -> GPU {gpu_id} (é˜Ÿåˆ—å‰©ä½™: {len(task_queue)})")

            with open(log_path, 'w') as f:
                proc = subprocess.Popen(cmd, env=env, stdout=f, stderr=subprocess.STDOUT, text=True)

            running_procs[proc] = (gpu_id, dataset, ipc, log_path)

        # ç¨å¾®ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å… CPU ç©ºè½¬
        time.sleep(2)

    # ================= æ±‡æ€»è¾“å‡º =================
    print("\n" + "=" * 50)
    print("ğŸ“Š æœ€ç»ˆè¯„æµ‹ç»“æœæ±‡æ€»")
    print("=" * 50)

    df = pd.DataFrame(results)
    if not df.empty:
        # æŒ‰ Dataset æ’åºæ–¹ä¾¿æŸ¥çœ‹
        df = df.sort_values(by=['Dataset', 'IPC'])
        print(df.to_markdown(index=False))

        csv_path = f"./{PROJECT_NAME}_summary.csv"
        df.to_csv(csv_path, index=False)
        print(f"\nç»“æœå·²ä¿å­˜è‡³: {csv_path}")


if __name__ == "__main__":
    run_parallel_experiments()