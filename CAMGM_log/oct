/data/users/xiongyuxuan/anaconda3/envs/DD/bin/python /data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py --dataset oct --model ConvNet --ipc 10 --dsa_strategy color_crop_cutout_flip_scale_rotate --init real --lr_img 1 --num_exp 5 --num_eval 5
eval_it_pool:  [0, 500, 1000]
No checkpoint found at ./CAM_CKPT/ResNet18_GradCAM.pth, training model...
Finished Training
Model trained and saved to ./CAM_CKPT/ResNet18_GradCAM.pth!

================== Exp 0 ==================

Hyper-parameters:
 {'method': 'DC', 'dataset': 'oct', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'proxy_model': 'ResNet18', 'epoch_proxy': 1, 'save_model_path': './Model_Saved_new', 'validation_step': 1, 'temperature': 0.5, 'mode': 'CAMDM', 'cam_path': './CAM_dir', 'cam_type': 'GradCAM', 'checkpoint_path': './CAM_CKPT/ResNet18_GradCAM.pth', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f6c1035b2b0>, 'dsa': False}
Evaluation model pool:  ['ConvNet']
class c = 0: 5743 real images
class c = 1: 2591 real images
class c = 2: 1453 real images
class c = 3: 3057 real images
class c = 4: 1952 real images
real images channel 0, mean = -0.3062, std = 0.8858
real images channel 1, mean = -0.3062, std = 0.8858
real images channel 2, mean = -0.3062, std = 0.8858
initialize synthetic data from random real images
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/torch/csrc/utils/tensor_new.cpp:230.)
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
[2024-12-13 10:08:26] training begins
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 10:08:41] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.000318 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8900, test_f1 =0.5323
[2024-12-13 10:08:47] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.001553 train acc = 1.0000, test acc = 0.5680, test_sen =0.5680, test_spe =0.8920, test_f1 =0.5428
[2024-12-13 10:08:53] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.001456 train acc = 1.0000, test acc = 0.5040, test_sen =0.5040, test_spe =0.8760, test_f1 =0.4600
[2024-12-13 10:08:59] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.000588 train acc = 1.0000, test acc = 0.5640, test_sen =0.5640, test_spe =0.8910, test_f1 =0.5318
[2024-12-13 10:09:05] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.001570 train acc = 1.0000, test acc = 0.5160, test_sen =0.5160, test_spe =0.8790, test_f1 =0.4744
Evaluate 5 random ConvNet, ACCmean = 0.5424 ACCstd = 0.0268
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5424 SENstd = 0.0268
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8856 SPEstd = 0.0067
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5083 F1std = 0.0341
-------------------------
[2024-12-13 10:09:13] iter = 0000, loss = 81.0261
[2024-12-13 10:10:27] iter = 0010, loss = 99.5479
[2024-12-13 10:11:41] iter = 0020, loss = 82.0928
[2024-12-13 10:12:56] iter = 0030, loss = 70.8052
[2024-12-13 10:14:10] iter = 0040, loss = 73.5682
[2024-12-13 10:15:25] iter = 0050, loss = 85.7759
[2024-12-13 10:16:39] iter = 0060, loss = 78.5581
[2024-12-13 10:17:54] iter = 0070, loss = 77.6339
[2024-12-13 10:19:08] iter = 0080, loss = 70.2270
[2024-12-13 10:20:22] iter = 0090, loss = 70.9546
[2024-12-13 10:21:35] iter = 0100, loss = 80.6915
[2024-12-13 10:22:50] iter = 0110, loss = 65.8169
[2024-12-13 10:24:03] iter = 0120, loss = 70.6498
[2024-12-13 10:25:18] iter = 0130, loss = 69.8610
[2024-12-13 10:26:31] iter = 0140, loss = 60.1783
[2024-12-13 10:27:46] iter = 0150, loss = 62.7269
[2024-12-13 10:29:00] iter = 0160, loss = 72.6162
[2024-12-13 10:30:13] iter = 0170, loss = 70.7828
[2024-12-13 10:31:27] iter = 0180, loss = 66.9071
[2024-12-13 10:32:41] iter = 0190, loss = 66.7417
[2024-12-13 10:33:55] iter = 0200, loss = 58.4908
[2024-12-13 10:35:09] iter = 0210, loss = 63.8398
[2024-12-13 10:36:23] iter = 0220, loss = 69.5152
[2024-12-13 10:37:37] iter = 0230, loss = 53.2696
[2024-12-13 10:38:51] iter = 0240, loss = 61.3778
[2024-12-13 10:40:05] iter = 0250, loss = 68.0002
[2024-12-13 10:41:20] iter = 0260, loss = 68.0104
[2024-12-13 10:42:34] iter = 0270, loss = 68.0575
[2024-12-13 10:43:49] iter = 0280, loss = 64.3969
[2024-12-13 10:45:03] iter = 0290, loss = 59.9230
[2024-12-13 10:46:18] iter = 0300, loss = 54.6853
[2024-12-13 10:47:32] iter = 0310, loss = 54.8995
[2024-12-13 10:48:46] iter = 0320, loss = 55.5004
[2024-12-13 10:50:00] iter = 0330, loss = 52.6394
[2024-12-13 10:51:15] iter = 0340, loss = 74.0807
[2024-12-13 10:52:29] iter = 0350, loss = 60.9191
[2024-12-13 10:53:44] iter = 0360, loss = 59.5733
[2024-12-13 10:54:59] iter = 0370, loss = 57.3810
[2024-12-13 10:56:13] iter = 0380, loss = 55.3622
[2024-12-13 10:57:27] iter = 0390, loss = 52.8469
[2024-12-13 10:58:41] iter = 0400, loss = 55.3306
[2024-12-13 10:59:56] iter = 0410, loss = 58.2648
[2024-12-13 11:01:11] iter = 0420, loss = 60.3210
[2024-12-13 11:02:26] iter = 0430, loss = 65.2916
[2024-12-13 11:03:41] iter = 0440, loss = 56.5001
[2024-12-13 11:04:55] iter = 0450, loss = 55.6370
[2024-12-13 11:06:09] iter = 0460, loss = 56.2159
[2024-12-13 11:07:23] iter = 0470, loss = 56.8288
[2024-12-13 11:08:37] iter = 0480, loss = 54.7914
[2024-12-13 11:09:52] iter = 0490, loss = 54.0653
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 11:11:05] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.051818 train acc = 1.0000, test acc = 0.5160, test_sen =0.5160, test_spe =0.8790, test_f1 =0.4854
[2024-12-13 11:11:11] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.045213 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5149
[2024-12-13 11:11:17] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.035878 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5062
[2024-12-13 11:11:23] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.030294 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5194
[2024-12-13 11:11:30] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.037434 train acc = 1.0000, test acc = 0.5360, test_sen =0.5360, test_spe =0.8840, test_f1 =0.5141
Evaluate 5 random ConvNet, ACCmean = 0.5376 ACCstd = 0.0118
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5376 SENstd = 0.0118
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8844 SPEstd = 0.0029
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5080 F1std = 0.0121
-------------------------
[2024-12-13 11:11:37] iter = 0500, loss = 54.1345
[2024-12-13 11:12:51] iter = 0510, loss = 52.8709
[2024-12-13 11:14:05] iter = 0520, loss = 58.4852
[2024-12-13 11:15:19] iter = 0530, loss = 54.2364
[2024-12-13 11:16:33] iter = 0540, loss = 52.5177
[2024-12-13 11:17:47] iter = 0550, loss = 51.2893
[2024-12-13 11:19:01] iter = 0560, loss = 52.4071
[2024-12-13 11:20:16] iter = 0570, loss = 50.8702
[2024-12-13 11:21:31] iter = 0580, loss = 52.7101
[2024-12-13 11:22:45] iter = 0590, loss = 54.6347
[2024-12-13 11:24:00] iter = 0600, loss = 52.9463
[2024-12-13 11:25:14] iter = 0610, loss = 54.5778
[2024-12-13 11:26:28] iter = 0620, loss = 50.1895
[2024-12-13 11:27:43] iter = 0630, loss = 54.6631
[2024-12-13 11:28:57] iter = 0640, loss = 54.5414
[2024-12-13 11:30:11] iter = 0650, loss = 49.5481
[2024-12-13 11:31:26] iter = 0660, loss = 48.0765
[2024-12-13 11:32:40] iter = 0670, loss = 45.2171
[2024-12-13 11:33:55] iter = 0680, loss = 60.2742
[2024-12-13 11:35:09] iter = 0690, loss = 47.8304
[2024-12-13 11:36:23] iter = 0700, loss = 49.1411
[2024-12-13 11:37:37] iter = 0710, loss = 45.9101
[2024-12-13 11:38:51] iter = 0720, loss = 49.3148
[2024-12-13 11:40:06] iter = 0730, loss = 57.2543
[2024-12-13 11:41:20] iter = 0740, loss = 45.2617
[2024-12-13 11:42:35] iter = 0750, loss = 48.8719
[2024-12-13 11:43:49] iter = 0760, loss = 57.9774
[2024-12-13 11:45:03] iter = 0770, loss = 53.2880
[2024-12-13 11:46:18] iter = 0780, loss = 52.9515
[2024-12-13 11:47:32] iter = 0790, loss = 50.1051
[2024-12-13 11:48:46] iter = 0800, loss = 44.6787
[2024-12-13 11:50:01] iter = 0810, loss = 46.7320
[2024-12-13 11:51:14] iter = 0820, loss = 51.0207
[2024-12-13 11:52:28] iter = 0830, loss = 41.4450
[2024-12-13 11:53:43] iter = 0840, loss = 55.9607
[2024-12-13 11:54:57] iter = 0850, loss = 46.9600
[2024-12-13 11:56:11] iter = 0860, loss = 52.9335
[2024-12-13 11:57:25] iter = 0870, loss = 48.7018
[2024-12-13 11:58:39] iter = 0880, loss = 53.7311
[2024-12-13 11:59:54] iter = 0890, loss = 47.1773
[2024-12-13 12:01:09] iter = 0900, loss = 48.8035
[2024-12-13 12:02:25] iter = 0910, loss = 49.5992
[2024-12-13 12:03:39] iter = 0920, loss = 50.6034
[2024-12-13 12:04:54] iter = 0930, loss = 46.8074
[2024-12-13 12:06:12] iter = 0940, loss = 42.0958
[2024-12-13 12:07:28] iter = 0950, loss = 52.4383
[2024-12-13 12:08:43] iter = 0960, loss = 48.3480
[2024-12-13 12:09:57] iter = 0970, loss = 47.9114
[2024-12-13 12:11:12] iter = 0980, loss = 48.7900
[2024-12-13 12:12:27] iter = 0990, loss = 51.2636
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 12:13:41] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.070258 train acc = 1.0000, test acc = 0.5520, test_sen =0.5520, test_spe =0.8880, test_f1 =0.5325
[2024-12-13 12:13:47] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.063362 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5135
[2024-12-13 12:13:53] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.067703 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5376
[2024-12-13 12:14:00] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.062947 train acc = 1.0000, test acc = 0.5880, test_sen =0.5880, test_spe =0.8970, test_f1 =0.5574
[2024-12-13 12:14:06] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.084377 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8900, test_f1 =0.5225
Evaluate 5 random ConvNet, ACCmean = 0.5576 ACCstd = 0.0165
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5576 SENstd = 0.0165
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8894 SPEstd = 0.0041
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5327 F1std = 0.0149
-------------------------
[2024-12-13 12:14:13] iter = 1000, loss = 47.0162

================== Exp 1 ==================

Hyper-parameters:
 {'method': 'DC', 'dataset': 'oct', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'proxy_model': 'ResNet18', 'epoch_proxy': 1, 'save_model_path': './Model_Saved_new', 'validation_step': 1, 'temperature': 0.5, 'mode': 'CAMDM', 'cam_path': './CAM_dir', 'cam_type': 'GradCAM', 'checkpoint_path': './CAM_CKPT/ResNet18_GradCAM.pth', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f6c1035b2b0>, 'dsa': False, 'dc_aug_param': None}
Evaluation model pool:  ['ConvNet']
class c = 0: 5743 real images
class c = 1: 2591 real images
class c = 2: 1453 real images
class c = 3: 3057 real images
class c = 4: 1952 real images
real images channel 0, mean = -0.3062, std = 0.8858
real images channel 1, mean = -0.3062, std = 0.8858
real images channel 2, mean = -0.3062, std = 0.8858
initialize synthetic data from random real images
[2024-12-13 12:20:46] training begins
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
[2024-12-13 12:20:52] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.000515 train acc = 1.0000, test acc = 0.4600, test_sen =0.4600, test_spe =0.8650, test_f1 =0.4200
[2024-12-13 12:20:58] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.001268 train acc = 1.0000, test acc = 0.4360, test_sen =0.4360, test_spe =0.8590, test_f1 =0.3933
[2024-12-13 12:21:04] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.001392 train acc = 1.0000, test acc = 0.4720, test_sen =0.4720, test_spe =0.8680, test_f1 =0.4508
[2024-12-13 12:21:10] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.000758 train acc = 1.0000, test acc = 0.4240, test_sen =0.4240, test_spe =0.8560, test_f1 =0.3924
[2024-12-13 12:21:16] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.000299 train acc = 1.0000, test acc = 0.4320, test_sen =0.4320, test_spe =0.8580, test_f1 =0.3921
Evaluate 5 random ConvNet, ACCmean = 0.4448 ACCstd = 0.0181
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.4448 SENstd = 0.0181
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8612 SPEstd = 0.0045
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.4097 F1std = 0.0231
-------------------------
[2024-12-13 12:21:24] iter = 0000, loss = 60.0310
[2024-12-13 12:22:37] iter = 0010, loss = 91.9884
[2024-12-13 12:23:51] iter = 0020, loss = 85.2477
[2024-12-13 12:25:05] iter = 0030, loss = 88.9364
[2024-12-13 12:26:19] iter = 0040, loss = 73.4797
[2024-12-13 12:27:33] iter = 0050, loss = 62.9179
[2024-12-13 12:28:47] iter = 0060, loss = 70.3884
[2024-12-13 12:30:01] iter = 0070, loss = 60.5443
[2024-12-13 12:31:15] iter = 0080, loss = 65.8701
[2024-12-13 12:32:29] iter = 0090, loss = 67.8457
[2024-12-13 12:33:43] iter = 0100, loss = 63.9156
[2024-12-13 12:34:57] iter = 0110, loss = 70.8461
[2024-12-13 12:36:11] iter = 0120, loss = 56.6642
[2024-12-13 12:37:25] iter = 0130, loss = 66.6141
[2024-12-13 12:38:39] iter = 0140, loss = 60.0634
[2024-12-13 12:39:53] iter = 0150, loss = 79.4215
[2024-12-13 12:41:07] iter = 0160, loss = 64.7360
[2024-12-13 12:42:20] iter = 0170, loss = 70.6415
[2024-12-13 12:43:34] iter = 0180, loss = 65.2483
[2024-12-13 12:44:48] iter = 0190, loss = 54.4078
[2024-12-13 12:46:02] iter = 0200, loss = 60.5979
[2024-12-13 12:47:17] iter = 0210, loss = 66.2180
[2024-12-13 12:48:31] iter = 0220, loss = 60.6119
[2024-12-13 12:49:45] iter = 0230, loss = 61.9467
[2024-12-13 12:50:59] iter = 0240, loss = 63.0783
[2024-12-13 12:52:13] iter = 0250, loss = 57.7161
[2024-12-13 12:53:27] iter = 0260, loss = 54.8258
[2024-12-13 12:54:41] iter = 0270, loss = 57.5906
[2024-12-13 12:55:55] iter = 0280, loss = 55.9010
[2024-12-13 12:57:09] iter = 0290, loss = 58.5691
[2024-12-13 12:58:23] iter = 0300, loss = 59.8778
[2024-12-13 12:59:37] iter = 0310, loss = 63.3911
[2024-12-13 13:00:51] iter = 0320, loss = 64.7179
[2024-12-13 13:02:04] iter = 0330, loss = 66.1478
[2024-12-13 13:03:18] iter = 0340, loss = 59.1047
[2024-12-13 13:04:32] iter = 0350, loss = 55.6659
[2024-12-13 13:05:46] iter = 0360, loss = 71.8242
[2024-12-13 13:07:00] iter = 0370, loss = 61.9992
[2024-12-13 13:08:14] iter = 0380, loss = 56.1434
[2024-12-13 13:09:28] iter = 0390, loss = 54.6730
[2024-12-13 13:10:43] iter = 0400, loss = 53.8891
[2024-12-13 13:11:57] iter = 0410, loss = 58.1948
[2024-12-13 13:13:10] iter = 0420, loss = 53.6987
[2024-12-13 13:14:24] iter = 0430, loss = 53.9170
[2024-12-13 13:15:38] iter = 0440, loss = 55.0643
[2024-12-13 13:16:52] iter = 0450, loss = 57.8919
[2024-12-13 13:18:06] iter = 0460, loss = 58.7842
[2024-12-13 13:19:20] iter = 0470, loss = 51.9183
[2024-12-13 13:20:35] iter = 0480, loss = 53.4001
[2024-12-13 13:21:49] iter = 0490, loss = 59.3380
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 13:23:01] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.044181 train acc = 1.0000, test acc = 0.4960, test_sen =0.4960, test_spe =0.8740, test_f1 =0.4588
[2024-12-13 13:23:07] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.029873 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5014
[2024-12-13 13:23:13] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.058626 train acc = 1.0000, test acc = 0.6120, test_sen =0.6120, test_spe =0.9030, test_f1 =0.5920
[2024-12-13 13:23:19] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.061813 train acc = 1.0000, test acc = 0.5520, test_sen =0.5520, test_spe =0.8880, test_f1 =0.5227
[2024-12-13 13:23:25] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.048675 train acc = 1.0000, test acc = 0.5560, test_sen =0.5560, test_spe =0.8890, test_f1 =0.5183
Evaluate 5 random ConvNet, ACCmean = 0.5528 ACCstd = 0.0368
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5528 SENstd = 0.0368
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8882 SPEstd = 0.0092
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5186 F1std = 0.0431
-------------------------
[2024-12-13 13:23:33] iter = 0500, loss = 53.3864
[2024-12-13 13:24:47] iter = 0510, loss = 54.3099
[2024-12-13 13:26:01] iter = 0520, loss = 52.0848
[2024-12-13 13:27:15] iter = 0530, loss = 49.4995
[2024-12-13 13:28:29] iter = 0540, loss = 48.5398
[2024-12-13 13:29:44] iter = 0550, loss = 50.1493
[2024-12-13 13:30:58] iter = 0560, loss = 54.8895
[2024-12-13 13:32:12] iter = 0570, loss = 61.1270
[2024-12-13 13:33:26] iter = 0580, loss = 52.3220
[2024-12-13 13:34:41] iter = 0590, loss = 54.8663
[2024-12-13 13:35:55] iter = 0600, loss = 55.3025
[2024-12-13 13:37:09] iter = 0610, loss = 48.1443
[2024-12-13 13:38:24] iter = 0620, loss = 53.0854
[2024-12-13 13:39:38] iter = 0630, loss = 54.1667
[2024-12-13 13:40:52] iter = 0640, loss = 62.6700
[2024-12-13 13:42:07] iter = 0650, loss = 51.6213
[2024-12-13 13:43:21] iter = 0660, loss = 51.5837
[2024-12-13 13:44:35] iter = 0670, loss = 51.9345
[2024-12-13 13:45:49] iter = 0680, loss = 54.8980
[2024-12-13 13:47:04] iter = 0690, loss = 42.5441
[2024-12-13 13:48:18] iter = 0700, loss = 52.1591
[2024-12-13 13:49:32] iter = 0710, loss = 49.2350
[2024-12-13 13:50:46] iter = 0720, loss = 44.9177
[2024-12-13 13:52:01] iter = 0730, loss = 49.1077
[2024-12-13 13:53:15] iter = 0740, loss = 49.3770
[2024-12-13 13:54:29] iter = 0750, loss = 48.1387
[2024-12-13 13:55:44] iter = 0760, loss = 46.2032
[2024-12-13 13:56:58] iter = 0770, loss = 48.0798
[2024-12-13 13:58:12] iter = 0780, loss = 46.3573
[2024-12-13 13:59:27] iter = 0790, loss = 53.2676
[2024-12-13 14:00:41] iter = 0800, loss = 59.6801
[2024-12-13 14:01:56] iter = 0810, loss = 48.3552
[2024-12-13 14:03:10] iter = 0820, loss = 49.7506
[2024-12-13 14:04:24] iter = 0830, loss = 55.1629
[2024-12-13 14:05:39] iter = 0840, loss = 47.8659
[2024-12-13 14:06:53] iter = 0850, loss = 48.7259
[2024-12-13 14:08:08] iter = 0860, loss = 55.1935
[2024-12-13 14:09:22] iter = 0870, loss = 53.6240
[2024-12-13 14:10:36] iter = 0880, loss = 47.0054
[2024-12-13 14:11:51] iter = 0890, loss = 47.5072
[2024-12-13 14:13:05] iter = 0900, loss = 45.5526
[2024-12-13 14:14:19] iter = 0910, loss = 50.1652
[2024-12-13 14:15:34] iter = 0920, loss = 53.2886
[2024-12-13 14:16:48] iter = 0930, loss = 48.4874
[2024-12-13 14:18:03] iter = 0940, loss = 53.3128
[2024-12-13 14:19:17] iter = 0950, loss = 42.9762
[2024-12-13 14:20:32] iter = 0960, loss = 49.6664
[2024-12-13 14:21:46] iter = 0970, loss = 47.7746
[2024-12-13 14:23:01] iter = 0980, loss = 53.2441
[2024-12-13 14:24:15] iter = 0990, loss = 49.1300
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 14:25:28] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.059265 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5182
[2024-12-13 14:25:34] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.039525 train acc = 1.0000, test acc = 0.6080, test_sen =0.6080, test_spe =0.9020, test_f1 =0.5967
[2024-12-13 14:25:41] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.040298 train acc = 1.0000, test acc = 0.5720, test_sen =0.5720, test_spe =0.8930, test_f1 =0.5491
[2024-12-13 14:25:47] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.079382 train acc = 1.0000, test acc = 0.5640, test_sen =0.5640, test_spe =0.8910, test_f1 =0.5373
[2024-12-13 14:25:53] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.060014 train acc = 1.0000, test acc = 0.5520, test_sen =0.5520, test_spe =0.8880, test_f1 =0.5247
Evaluate 5 random ConvNet, ACCmean = 0.5688 ACCstd = 0.0214
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5688 SENstd = 0.0214
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8922 SPEstd = 0.0053
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5452 F1std = 0.0279
-------------------------
[2024-12-13 14:26:00] iter = 1000, loss = 48.5242

================== Exp 2 ==================

Hyper-parameters:
 {'method': 'DC', 'dataset': 'oct', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'proxy_model': 'ResNet18', 'epoch_proxy': 1, 'save_model_path': './Model_Saved_new', 'validation_step': 1, 'temperature': 0.5, 'mode': 'CAMDM', 'cam_path': './CAM_dir', 'cam_type': 'GradCAM', 'checkpoint_path': './CAM_CKPT/ResNet18_GradCAM.pth', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f6c1035b2b0>, 'dsa': False, 'dc_aug_param': None}
Evaluation model pool:  ['ConvNet']
class c = 0: 5743 real images
class c = 1: 2591 real images
class c = 2: 1453 real images
class c = 3: 3057 real images
class c = 4: 1952 real images
real images channel 0, mean = -0.3062, std = 0.8858
real images channel 1, mean = -0.3062, std = 0.8858
real images channel 2, mean = -0.3062, std = 0.8858
initialize synthetic data from random real images
[2024-12-13 14:32:38] training begins
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
[2024-12-13 14:32:44] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.001890 train acc = 1.0000, test acc = 0.4840, test_sen =0.4840, test_spe =0.8710, test_f1 =0.4879
[2024-12-13 14:32:50] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.004543 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5407
[2024-12-13 14:32:56] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.007093 train acc = 1.0000, test acc = 0.4560, test_sen =0.4560, test_spe =0.8640, test_f1 =0.4608
[2024-12-13 14:33:02] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.002012 train acc = 1.0000, test acc = 0.5160, test_sen =0.5160, test_spe =0.8790, test_f1 =0.5170
[2024-12-13 14:33:08] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.001988 train acc = 1.0000, test acc = 0.5000, test_sen =0.5000, test_spe =0.8750, test_f1 =0.5081
Evaluate 5 random ConvNet, ACCmean = 0.4992 ACCstd = 0.0284
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.4992 SENstd = 0.0284
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8748 SPEstd = 0.0071
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5029 F1std = 0.0270
-------------------------
[2024-12-13 14:33:16] iter = 0000, loss = 79.5341
[2024-12-13 14:34:29] iter = 0010, loss = 81.5426
[2024-12-13 14:35:44] iter = 0020, loss = 91.4135
[2024-12-13 14:36:58] iter = 0030, loss = 79.7831
[2024-12-13 14:38:12] iter = 0040, loss = 80.2770
[2024-12-13 14:39:27] iter = 0050, loss = 75.8232
[2024-12-13 14:40:41] iter = 0060, loss = 73.6443
[2024-12-13 14:41:56] iter = 0070, loss = 64.5640
[2024-12-13 14:43:10] iter = 0080, loss = 65.3007
[2024-12-13 14:44:25] iter = 0090, loss = 79.3078
[2024-12-13 14:45:40] iter = 0100, loss = 65.9504
[2024-12-13 14:46:55] iter = 0110, loss = 74.5160
[2024-12-13 14:48:10] iter = 0120, loss = 63.1985
[2024-12-13 14:49:24] iter = 0130, loss = 72.2982
[2024-12-13 14:50:38] iter = 0140, loss = 74.9227
[2024-12-13 14:51:52] iter = 0150, loss = 63.7733
[2024-12-13 14:53:06] iter = 0160, loss = 56.6167
[2024-12-13 14:54:20] iter = 0170, loss = 62.6102
[2024-12-13 14:55:34] iter = 0180, loss = 63.3542
[2024-12-13 14:56:48] iter = 0190, loss = 62.9319
[2024-12-13 14:58:02] iter = 0200, loss = 58.9520
[2024-12-13 14:59:16] iter = 0210, loss = 63.6532
[2024-12-13 15:00:30] iter = 0220, loss = 57.9204
[2024-12-13 15:01:44] iter = 0230, loss = 58.5338
[2024-12-13 15:02:58] iter = 0240, loss = 63.8326
[2024-12-13 15:04:12] iter = 0250, loss = 68.9943
[2024-12-13 15:05:26] iter = 0260, loss = 65.1810
[2024-12-13 15:06:40] iter = 0270, loss = 60.2868
[2024-12-13 15:07:54] iter = 0280, loss = 57.9289
[2024-12-13 15:09:09] iter = 0290, loss = 56.9117
[2024-12-13 15:10:23] iter = 0300, loss = 53.7328
[2024-12-13 15:11:37] iter = 0310, loss = 65.3565
[2024-12-13 15:12:51] iter = 0320, loss = 60.9684
[2024-12-13 15:14:05] iter = 0330, loss = 57.6947
[2024-12-13 15:15:19] iter = 0340, loss = 58.8770
[2024-12-13 15:16:33] iter = 0350, loss = 57.1434
[2024-12-13 15:17:46] iter = 0360, loss = 51.8603
[2024-12-13 15:19:01] iter = 0370, loss = 56.0134
[2024-12-13 15:20:15] iter = 0380, loss = 50.6648
[2024-12-13 15:21:29] iter = 0390, loss = 45.9094
[2024-12-13 15:22:43] iter = 0400, loss = 59.1079
[2024-12-13 15:23:57] iter = 0410, loss = 48.7854
[2024-12-13 15:25:11] iter = 0420, loss = 53.9950
[2024-12-13 15:26:25] iter = 0430, loss = 56.8960
[2024-12-13 15:27:39] iter = 0440, loss = 64.6731
[2024-12-13 15:28:53] iter = 0450, loss = 51.1381
[2024-12-13 15:30:07] iter = 0460, loss = 69.6125
[2024-12-13 15:31:21] iter = 0470, loss = 65.1794
[2024-12-13 15:32:35] iter = 0480, loss = 60.0424
[2024-12-13 15:33:49] iter = 0490, loss = 59.6485
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 15:35:02] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.056346 train acc = 1.0000, test acc = 0.5200, test_sen =0.5200, test_spe =0.8800, test_f1 =0.5137
[2024-12-13 15:35:08] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.066363 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5388
[2024-12-13 15:35:14] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.076876 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8810, test_f1 =0.5203
[2024-12-13 15:35:20] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.051046 train acc = 1.0000, test acc = 0.5720, test_sen =0.5720, test_spe =0.8930, test_f1 =0.5760
[2024-12-13 15:35:26] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.069605 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5389
Evaluate 5 random ConvNet, ACCmean = 0.5392 ACCstd = 0.0183
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5392 SENstd = 0.0183
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8848 SPEstd = 0.0046
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5375 F1std = 0.0217
-------------------------
[2024-12-13 15:35:33] iter = 0500, loss = 56.3129
[2024-12-13 15:36:47] iter = 0510, loss = 55.6899
[2024-12-13 15:38:01] iter = 0520, loss = 49.3203
[2024-12-13 15:39:15] iter = 0530, loss = 56.4547
[2024-12-13 15:40:30] iter = 0540, loss = 56.9746
[2024-12-13 15:41:44] iter = 0550, loss = 48.9863
[2024-12-13 15:42:58] iter = 0560, loss = 50.6057
[2024-12-13 15:44:12] iter = 0570, loss = 56.0685
[2024-12-13 15:45:26] iter = 0580, loss = 55.0588
[2024-12-13 15:46:40] iter = 0590, loss = 54.6788
[2024-12-13 15:47:54] iter = 0600, loss = 55.0395
[2024-12-13 15:49:08] iter = 0610, loss = 48.1179
[2024-12-13 15:50:22] iter = 0620, loss = 55.0109
[2024-12-13 15:51:36] iter = 0630, loss = 55.9039
[2024-12-13 15:52:50] iter = 0640, loss = 54.5668
[2024-12-13 15:54:04] iter = 0650, loss = 50.6225
[2024-12-13 15:55:19] iter = 0660, loss = 57.2667
[2024-12-13 15:56:33] iter = 0670, loss = 47.1586
[2024-12-13 15:57:47] iter = 0680, loss = 53.2566
[2024-12-13 15:59:01] iter = 0690, loss = 46.5094
[2024-12-13 16:00:15] iter = 0700, loss = 47.7527
[2024-12-13 16:01:29] iter = 0710, loss = 52.0788
[2024-12-13 16:02:44] iter = 0720, loss = 49.1586
[2024-12-13 16:03:57] iter = 0730, loss = 49.3605
[2024-12-13 16:05:11] iter = 0740, loss = 48.2268
[2024-12-13 16:06:26] iter = 0750, loss = 46.9550
[2024-12-13 16:07:40] iter = 0760, loss = 47.5095
[2024-12-13 16:08:54] iter = 0770, loss = 48.7694
[2024-12-13 16:10:08] iter = 0780, loss = 50.3022
[2024-12-13 16:11:23] iter = 0790, loss = 49.4938
[2024-12-13 16:12:37] iter = 0800, loss = 45.0838
[2024-12-13 16:13:51] iter = 0810, loss = 58.6276
[2024-12-13 16:15:06] iter = 0820, loss = 45.5516
[2024-12-13 16:16:20] iter = 0830, loss = 46.3606
[2024-12-13 16:17:34] iter = 0840, loss = 52.8106
[2024-12-13 16:18:48] iter = 0850, loss = 53.1349
[2024-12-13 16:20:02] iter = 0860, loss = 45.3433
[2024-12-13 16:21:17] iter = 0870, loss = 50.3963
[2024-12-13 16:22:30] iter = 0880, loss = 47.6942
[2024-12-13 16:23:44] iter = 0890, loss = 62.5913
[2024-12-13 16:24:58] iter = 0900, loss = 54.4817
[2024-12-13 16:26:13] iter = 0910, loss = 52.8870
[2024-12-13 16:27:27] iter = 0920, loss = 53.8339
[2024-12-13 16:28:40] iter = 0930, loss = 47.4437
[2024-12-13 16:29:54] iter = 0940, loss = 46.9158
[2024-12-13 16:31:08] iter = 0950, loss = 58.1667
[2024-12-13 16:32:23] iter = 0960, loss = 43.5387
[2024-12-13 16:33:36] iter = 0970, loss = 51.5783
[2024-12-13 16:34:51] iter = 0980, loss = 50.9425
[2024-12-13 16:36:05] iter = 0990, loss = 53.0467
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 16:37:18] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.050562 train acc = 1.0000, test acc = 0.6080, test_sen =0.6080, test_spe =0.9020, test_f1 =0.6042
[2024-12-13 16:37:24] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.112147 train acc = 1.0000, test acc = 0.5880, test_sen =0.5880, test_spe =0.8970, test_f1 =0.5841
[2024-12-13 16:37:30] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.105152 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8900, test_f1 =0.5577
[2024-12-13 16:37:36] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.094801 train acc = 1.0000, test acc = 0.5360, test_sen =0.5360, test_spe =0.8840, test_f1 =0.5326
[2024-12-13 16:37:42] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.063104 train acc = 1.0000, test acc = 0.5000, test_sen =0.5000, test_spe =0.8750, test_f1 =0.4945
Evaluate 5 random ConvNet, ACCmean = 0.5584 ACCstd = 0.0381
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5584 SENstd = 0.0381
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8896 SPEstd = 0.0095
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5546 F1std = 0.0386
-------------------------
[2024-12-13 16:37:49] iter = 1000, loss = 50.7239

================== Exp 3 ==================

Hyper-parameters:
 {'method': 'DC', 'dataset': 'oct', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'proxy_model': 'ResNet18', 'epoch_proxy': 1, 'save_model_path': './Model_Saved_new', 'validation_step': 1, 'temperature': 0.5, 'mode': 'CAMDM', 'cam_path': './CAM_dir', 'cam_type': 'GradCAM', 'checkpoint_path': './CAM_CKPT/ResNet18_GradCAM.pth', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f6c1035b2b0>, 'dsa': False, 'dc_aug_param': None}
Evaluation model pool:  ['ConvNet']
class c = 0: 5743 real images
class c = 1: 2591 real images
class c = 2: 1453 real images
class c = 3: 3057 real images
class c = 4: 1952 real images
real images channel 0, mean = -0.3062, std = 0.8858
real images channel 1, mean = -0.3062, std = 0.8858
real images channel 2, mean = -0.3062, std = 0.8858
initialize synthetic data from random real images
[2024-12-13 16:45:27] training begins
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
[2024-12-13 16:45:33] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.003558 train acc = 1.0000, test acc = 0.4320, test_sen =0.4320, test_spe =0.8580, test_f1 =0.4198
[2024-12-13 16:45:39] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.001790 train acc = 1.0000, test acc = 0.3920, test_sen =0.3920, test_spe =0.8480, test_f1 =0.3833
[2024-12-13 16:45:45] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.003512 train acc = 1.0000, test acc = 0.4080, test_sen =0.4080, test_spe =0.8520, test_f1 =0.3999
[2024-12-13 16:45:51] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.001980 train acc = 1.0000, test acc = 0.3960, test_sen =0.3960, test_spe =0.8490, test_f1 =0.3749
[2024-12-13 16:45:58] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.001159 train acc = 1.0000, test acc = 0.4000, test_sen =0.4000, test_spe =0.8500, test_f1 =0.3905
Evaluate 5 random ConvNet, ACCmean = 0.4056 ACCstd = 0.0142
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.4056 SENstd = 0.0142
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8514 SPEstd = 0.0036
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.3937 F1std = 0.0154
-------------------------
[2024-12-13 16:46:05] iter = 0000, loss = 74.0420
[2024-12-13 16:47:20] iter = 0010, loss = 83.1830
[2024-12-13 16:48:35] iter = 0020, loss = 82.1216
[2024-12-13 16:49:51] iter = 0030, loss = 76.1028
[2024-12-13 16:51:06] iter = 0040, loss = 74.8337
[2024-12-13 16:52:22] iter = 0050, loss = 69.8795
[2024-12-13 16:53:38] iter = 0060, loss = 70.0168
[2024-12-13 16:54:54] iter = 0070, loss = 70.5526
[2024-12-13 16:56:10] iter = 0080, loss = 69.1068
[2024-12-13 16:57:26] iter = 0090, loss = 77.0323
[2024-12-13 16:58:42] iter = 0100, loss = 76.4540
[2024-12-13 16:59:59] iter = 0110, loss = 73.2839
[2024-12-13 17:01:15] iter = 0120, loss = 72.6082
[2024-12-13 17:02:30] iter = 0130, loss = 63.1913
[2024-12-13 17:03:46] iter = 0140, loss = 63.5298
[2024-12-13 17:05:03] iter = 0150, loss = 58.5230
[2024-12-13 17:06:18] iter = 0160, loss = 67.6410
[2024-12-13 17:07:34] iter = 0170, loss = 62.9379
[2024-12-13 17:08:50] iter = 0180, loss = 62.5787
[2024-12-13 17:10:06] iter = 0190, loss = 67.1982
[2024-12-13 17:11:21] iter = 0200, loss = 56.0373
[2024-12-13 17:12:38] iter = 0210, loss = 64.5521
[2024-12-13 17:13:54] iter = 0220, loss = 59.6639
[2024-12-13 17:15:10] iter = 0230, loss = 64.0820
[2024-12-13 17:16:26] iter = 0240, loss = 59.4382
[2024-12-13 17:17:41] iter = 0250, loss = 63.8403
[2024-12-13 17:18:58] iter = 0260, loss = 57.9098
[2024-12-13 17:20:14] iter = 0270, loss = 56.1924
[2024-12-13 17:21:30] iter = 0280, loss = 53.5402
[2024-12-13 17:22:47] iter = 0290, loss = 56.5995
[2024-12-13 17:24:03] iter = 0300, loss = 65.1672
[2024-12-13 17:25:19] iter = 0310, loss = 61.4781
[2024-12-13 17:26:35] iter = 0320, loss = 66.7056
[2024-12-13 17:27:51] iter = 0330, loss = 64.6355
[2024-12-13 17:29:06] iter = 0340, loss = 55.2309
[2024-12-13 17:30:21] iter = 0350, loss = 55.9822
[2024-12-13 17:31:36] iter = 0360, loss = 56.8324
[2024-12-13 17:32:51] iter = 0370, loss = 67.6005
[2024-12-13 17:34:06] iter = 0380, loss = 66.0075
[2024-12-13 17:35:21] iter = 0390, loss = 55.7872
[2024-12-13 17:36:35] iter = 0400, loss = 54.7893
[2024-12-13 17:37:50] iter = 0410, loss = 59.0850
[2024-12-13 17:39:05] iter = 0420, loss = 48.2196
[2024-12-13 17:40:20] iter = 0430, loss = 61.2158
[2024-12-13 17:41:35] iter = 0440, loss = 60.8612
[2024-12-13 17:42:51] iter = 0450, loss = 57.8167
[2024-12-13 17:44:05] iter = 0460, loss = 60.4654
[2024-12-13 17:45:20] iter = 0470, loss = 58.1662
[2024-12-13 17:46:35] iter = 0480, loss = 50.3834
[2024-12-13 17:47:50] iter = 0490, loss = 46.5740
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 17:49:04] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.069614 train acc = 1.0000, test acc = 0.4560, test_sen =0.4560, test_spe =0.8640, test_f1 =0.4511
[2024-12-13 17:49:10] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.038503 train acc = 1.0000, test acc = 0.5280, test_sen =0.5280, test_spe =0.8820, test_f1 =0.5026
[2024-12-13 17:49:16] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.072584 train acc = 1.0000, test acc = 0.5120, test_sen =0.5120, test_spe =0.8780, test_f1 =0.4842
[2024-12-13 17:49:22] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.049370 train acc = 1.0000, test acc = 0.5520, test_sen =0.5520, test_spe =0.8880, test_f1 =0.5229
[2024-12-13 17:49:28] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.052548 train acc = 1.0000, test acc = 0.4520, test_sen =0.4520, test_spe =0.8630, test_f1 =0.4356
Evaluate 5 random ConvNet, ACCmean = 0.5000 ACCstd = 0.0397
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5000 SENstd = 0.0397
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8750 SPEstd = 0.0099
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.4793 F1std = 0.0322
-------------------------
[2024-12-13 17:49:36] iter = 0500, loss = 57.6989
[2024-12-13 17:50:51] iter = 0510, loss = 53.3349
[2024-12-13 17:52:07] iter = 0520, loss = 51.3995
[2024-12-13 17:53:22] iter = 0530, loss = 54.3975
[2024-12-13 17:54:37] iter = 0540, loss = 53.0806
[2024-12-13 17:55:52] iter = 0550, loss = 49.8374
[2024-12-13 17:57:08] iter = 0560, loss = 56.0717
[2024-12-13 17:58:22] iter = 0570, loss = 51.6989
[2024-12-13 17:59:37] iter = 0580, loss = 51.2061
[2024-12-13 18:00:51] iter = 0590, loss = 49.9183
[2024-12-13 18:02:06] iter = 0600, loss = 53.4695
[2024-12-13 18:03:21] iter = 0610, loss = 54.4313
[2024-12-13 18:04:36] iter = 0620, loss = 54.9132
[2024-12-13 18:05:50] iter = 0630, loss = 51.2698
[2024-12-13 18:07:05] iter = 0640, loss = 50.7770
[2024-12-13 18:08:20] iter = 0650, loss = 52.5331
[2024-12-13 18:09:35] iter = 0660, loss = 52.7471
[2024-12-13 18:10:51] iter = 0670, loss = 52.9337
[2024-12-13 18:12:05] iter = 0680, loss = 57.4914
[2024-12-13 18:13:20] iter = 0690, loss = 53.7124
[2024-12-13 18:14:35] iter = 0700, loss = 52.8048
[2024-12-13 18:15:50] iter = 0710, loss = 54.9621
[2024-12-13 18:17:05] iter = 0720, loss = 55.5249
[2024-12-13 18:18:20] iter = 0730, loss = 51.8590
[2024-12-13 18:19:36] iter = 0740, loss = 54.1180
[2024-12-13 18:20:50] iter = 0750, loss = 49.5506
[2024-12-13 18:22:05] iter = 0760, loss = 42.6381
[2024-12-13 18:23:21] iter = 0770, loss = 48.1770
[2024-12-13 18:24:36] iter = 0780, loss = 51.5721
[2024-12-13 18:25:50] iter = 0790, loss = 49.4005
[2024-12-13 18:27:05] iter = 0800, loss = 55.4087
[2024-12-13 18:28:20] iter = 0810, loss = 52.2875
[2024-12-13 18:29:34] iter = 0820, loss = 54.0049
[2024-12-13 18:30:50] iter = 0830, loss = 54.5382
[2024-12-13 18:32:04] iter = 0840, loss = 53.0027
[2024-12-13 18:33:19] iter = 0850, loss = 58.1828
[2024-12-13 18:34:34] iter = 0860, loss = 50.3586
[2024-12-13 18:35:49] iter = 0870, loss = 52.7627
[2024-12-13 18:37:05] iter = 0880, loss = 51.4688
[2024-12-13 18:38:21] iter = 0890, loss = 50.4382
[2024-12-13 18:39:38] iter = 0900, loss = 49.3063
[2024-12-13 18:40:54] iter = 0910, loss = 59.6866
[2024-12-13 18:42:10] iter = 0920, loss = 52.8648
[2024-12-13 18:43:26] iter = 0930, loss = 55.5053
[2024-12-13 18:44:41] iter = 0940, loss = 43.8065
[2024-12-13 18:45:56] iter = 0950, loss = 46.2708
[2024-12-13 18:47:11] iter = 0960, loss = 46.6170
[2024-12-13 18:48:26] iter = 0970, loss = 50.1587
[2024-12-13 18:49:41] iter = 0980, loss = 46.0127
[2024-12-13 18:50:56] iter = 0990, loss = 45.6876
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 18:52:09] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.109453 train acc = 1.0000, test acc = 0.5200, test_sen =0.5200, test_spe =0.8800, test_f1 =0.5046
[2024-12-13 18:52:15] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.079233 train acc = 1.0000, test acc = 0.5040, test_sen =0.5040, test_spe =0.8760, test_f1 =0.4900
[2024-12-13 18:52:22] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.067056 train acc = 1.0000, test acc = 0.5720, test_sen =0.5720, test_spe =0.8930, test_f1 =0.5580
[2024-12-13 18:52:28] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.048009 train acc = 1.0000, test acc = 0.5400, test_sen =0.5400, test_spe =0.8850, test_f1 =0.5256
[2024-12-13 18:52:34] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.067927 train acc = 1.0000, test acc = 0.5240, test_sen =0.5240, test_spe =0.8810, test_f1 =0.5035
Evaluate 5 random ConvNet, ACCmean = 0.5320 ACCstd = 0.0230
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5320 SENstd = 0.0230
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8830 SPEstd = 0.0058
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5163 F1std = 0.0238
-------------------------
[2024-12-13 18:52:42] iter = 1000, loss = 52.2294

================== Exp 4 ==================

Hyper-parameters:
 {'method': 'DC', 'dataset': 'oct', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 300, 'Iteration': 1000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'proxy_model': 'ResNet18', 'epoch_proxy': 1, 'save_model_path': './Model_Saved_new', 'validation_step': 1, 'temperature': 0.5, 'mode': 'CAMDM', 'cam_path': './CAM_dir', 'cam_type': 'GradCAM', 'checkpoint_path': './CAM_CKPT/ResNet18_GradCAM.pth', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f6c1035b2b0>, 'dsa': False, 'dc_aug_param': None}
Evaluation model pool:  ['ConvNet']
class c = 0: 5743 real images
class c = 1: 2591 real images
class c = 2: 1453 real images
class c = 3: 3057 real images
class c = 4: 1952 real images
real images channel 0, mean = -0.3062, std = 0.8858
real images channel 1, mean = -0.3062, std = 0.8858
real images channel 2, mean = -0.3062, std = 0.8858
initialize synthetic data from random real images
[2024-12-13 19:00:11] training begins
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
/data/users/xiongyuxuan/DD/CAMDM/DatasetCondensation-master/main_CAMGM.py:119: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
[2024-12-13 19:00:18] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.001410 train acc = 1.0000, test acc = 0.4200, test_sen =0.4200, test_spe =0.8550, test_f1 =0.3832
[2024-12-13 19:00:24] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.000645 train acc = 1.0000, test acc = 0.4440, test_sen =0.4440, test_spe =0.8610, test_f1 =0.4056
[2024-12-13 19:00:30] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.001230 train acc = 1.0000, test acc = 0.4160, test_sen =0.4160, test_spe =0.8540, test_f1 =0.3828
[2024-12-13 19:00:36] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.001396 train acc = 1.0000, test acc = 0.4200, test_sen =0.4200, test_spe =0.8550, test_f1 =0.3930
[2024-12-13 19:00:42] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.001341 train acc = 1.0000, test acc = 0.4320, test_sen =0.4320, test_spe =0.8580, test_f1 =0.4236
Evaluate 5 random ConvNet, ACCmean = 0.4264 ACCstd = 0.0103
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.4264 SENstd = 0.0103
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8566 SPEstd = 0.0026
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.3976 F1std = 0.0154
-------------------------
[2024-12-13 19:00:50] iter = 0000, loss = 60.9974
[2024-12-13 19:02:05] iter = 0010, loss = 90.1529
[2024-12-13 19:03:20] iter = 0020, loss = 84.4960
[2024-12-13 19:04:35] iter = 0030, loss = 74.4289
[2024-12-13 19:05:50] iter = 0040, loss = 75.2262
[2024-12-13 19:07:05] iter = 0050, loss = 76.0962
[2024-12-13 19:08:21] iter = 0060, loss = 74.0550
[2024-12-13 19:09:36] iter = 0070, loss = 68.2527
[2024-12-13 19:10:51] iter = 0080, loss = 76.6923
[2024-12-13 19:12:06] iter = 0090, loss = 76.1359
[2024-12-13 19:13:21] iter = 0100, loss = 66.7311
[2024-12-13 19:14:36] iter = 0110, loss = 70.0462
[2024-12-13 19:15:51] iter = 0120, loss = 67.5837
[2024-12-13 19:17:06] iter = 0130, loss = 62.5541
[2024-12-13 19:18:21] iter = 0140, loss = 74.3921
[2024-12-13 19:19:36] iter = 0150, loss = 61.1946
[2024-12-13 19:20:51] iter = 0160, loss = 74.5032
[2024-12-13 19:22:06] iter = 0170, loss = 66.4280
[2024-12-13 19:23:21] iter = 0180, loss = 57.9191
[2024-12-13 19:24:36] iter = 0190, loss = 65.2321
[2024-12-13 19:25:51] iter = 0200, loss = 67.1719
[2024-12-13 19:27:07] iter = 0210, loss = 58.4363
[2024-12-13 19:28:22] iter = 0220, loss = 68.9282
[2024-12-13 19:29:36] iter = 0230, loss = 52.6678
[2024-12-13 19:30:51] iter = 0240, loss = 60.0169
[2024-12-13 19:32:06] iter = 0250, loss = 57.1734
[2024-12-13 19:33:21] iter = 0260, loss = 66.8581
[2024-12-13 19:34:36] iter = 0270, loss = 59.1611
[2024-12-13 19:35:52] iter = 0280, loss = 63.9046
[2024-12-13 19:37:07] iter = 0290, loss = 56.8363
[2024-12-13 19:38:23] iter = 0300, loss = 65.5038
[2024-12-13 19:39:38] iter = 0310, loss = 61.6786
[2024-12-13 19:40:53] iter = 0320, loss = 56.4405
[2024-12-13 19:42:07] iter = 0330, loss = 60.8422
[2024-12-13 19:43:22] iter = 0340, loss = 53.3071
[2024-12-13 19:44:38] iter = 0350, loss = 53.4519
[2024-12-13 19:45:53] iter = 0360, loss = 52.5743
[2024-12-13 19:47:08] iter = 0370, loss = 57.2086
[2024-12-13 19:48:24] iter = 0380, loss = 61.3221
[2024-12-13 19:49:39] iter = 0390, loss = 64.7075
[2024-12-13 19:50:55] iter = 0400, loss = 56.2161
[2024-12-13 19:52:10] iter = 0410, loss = 58.3045
[2024-12-13 19:53:24] iter = 0420, loss = 56.3096
[2024-12-13 19:54:40] iter = 0430, loss = 52.9352
[2024-12-13 19:55:55] iter = 0440, loss = 50.2385
[2024-12-13 19:57:10] iter = 0450, loss = 56.1268
[2024-12-13 19:58:26] iter = 0460, loss = 52.8213
[2024-12-13 19:59:41] iter = 0470, loss = 52.9437
[2024-12-13 20:00:57] iter = 0480, loss = 53.2414
[2024-12-13 20:02:12] iter = 0490, loss = 58.6393
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 500
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 20:03:27] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.102945 train acc = 1.0000, test acc = 0.6080, test_sen =0.6080, test_spe =0.9020, test_f1 =0.5775
[2024-12-13 20:03:33] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.050418 train acc = 1.0000, test acc = 0.5760, test_sen =0.5760, test_spe =0.8940, test_f1 =0.5292
[2024-12-13 20:03:39] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.047147 train acc = 1.0000, test acc = 0.5560, test_sen =0.5560, test_spe =0.8890, test_f1 =0.5352
[2024-12-13 20:03:45] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.040281 train acc = 1.0000, test acc = 0.5600, test_sen =0.5600, test_spe =0.8900, test_f1 =0.5306
[2024-12-13 20:03:51] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.076847 train acc = 1.0000, test acc = 0.5120, test_sen =0.5120, test_spe =0.8780, test_f1 =0.4937
Evaluate 5 random ConvNet, ACCmean = 0.5624 ACCstd = 0.0311
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5624 SENstd = 0.0311
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8906 SPEstd = 0.0078
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.5332 F1std = 0.0266
-------------------------
[2024-12-13 20:03:59] iter = 0500, loss = 52.7480
[2024-12-13 20:05:14] iter = 0510, loss = 54.0268
[2024-12-13 20:06:29] iter = 0520, loss = 48.7258
[2024-12-13 20:07:45] iter = 0530, loss = 55.1396
[2024-12-13 20:09:00] iter = 0540, loss = 54.2836
[2024-12-13 20:10:16] iter = 0550, loss = 46.5230
[2024-12-13 20:11:31] iter = 0560, loss = 58.0862
[2024-12-13 20:12:47] iter = 0570, loss = 54.9889
[2024-12-13 20:14:02] iter = 0580, loss = 50.2604
[2024-12-13 20:15:18] iter = 0590, loss = 46.5822
[2024-12-13 20:16:34] iter = 0600, loss = 55.9988
[2024-12-13 20:17:49] iter = 0610, loss = 46.5408
[2024-12-13 20:19:04] iter = 0620, loss = 52.1712
[2024-12-13 20:20:19] iter = 0630, loss = 53.3611
[2024-12-13 20:21:35] iter = 0640, loss = 60.6265
[2024-12-13 20:22:50] iter = 0650, loss = 53.9562
[2024-12-13 20:24:05] iter = 0660, loss = 51.0475
[2024-12-13 20:25:20] iter = 0670, loss = 50.5552
[2024-12-13 20:26:35] iter = 0680, loss = 58.5596
[2024-12-13 20:27:50] iter = 0690, loss = 56.7191
[2024-12-13 20:29:06] iter = 0700, loss = 49.3861
[2024-12-13 20:30:21] iter = 0710, loss = 50.8266
[2024-12-13 20:31:36] iter = 0720, loss = 46.6753
[2024-12-13 20:32:52] iter = 0730, loss = 44.8408
[2024-12-13 20:34:07] iter = 0740, loss = 52.0305
[2024-12-13 20:35:23] iter = 0750, loss = 60.1981
[2024-12-13 20:36:38] iter = 0760, loss = 50.3363
[2024-12-13 20:37:53] iter = 0770, loss = 48.7133
[2024-12-13 20:39:09] iter = 0780, loss = 48.1752
[2024-12-13 20:40:24] iter = 0790, loss = 50.3528
[2024-12-13 20:41:40] iter = 0800, loss = 48.3207
[2024-12-13 20:42:55] iter = 0810, loss = 43.9272
[2024-12-13 20:44:09] iter = 0820, loss = 49.6827
[2024-12-13 20:45:24] iter = 0830, loss = 45.8905
[2024-12-13 20:46:39] iter = 0840, loss = 45.5755
[2024-12-13 20:47:54] iter = 0850, loss = 46.7088
[2024-12-13 20:49:08] iter = 0860, loss = 56.6839
[2024-12-13 20:50:23] iter = 0870, loss = 47.7719
[2024-12-13 20:51:37] iter = 0880, loss = 48.1141
[2024-12-13 20:52:52] iter = 0890, loss = 66.7374
[2024-12-13 20:54:08] iter = 0900, loss = 55.5609
[2024-12-13 20:55:24] iter = 0910, loss = 50.6958
[2024-12-13 20:56:40] iter = 0920, loss = 48.7941
[2024-12-13 20:57:55] iter = 0930, loss = 53.9265
[2024-12-13 20:59:10] iter = 0940, loss = 48.0540
[2024-12-13 21:00:25] iter = 0950, loss = 49.8196
[2024-12-13 21:01:40] iter = 0960, loss = 48.5581
[2024-12-13 21:02:55] iter = 0970, loss = 47.1752
[2024-12-13 21:04:10] iter = 0980, loss = 44.9342
[2024-12-13 21:05:24] iter = 0990, loss = 50.3759
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 1000
DC augmentation parameters:
 {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'none'}
[2024-12-13 21:06:37] Evaluate_00: epoch = 0300 train time = 2 s train loss = 0.073538 train acc = 1.0000, test acc = 0.5040, test_sen =0.5040, test_spe =0.8760, test_f1 =0.4811
[2024-12-13 21:06:44] Evaluate_01: epoch = 0300 train time = 2 s train loss = 0.103904 train acc = 1.0000, test acc = 0.5480, test_sen =0.5480, test_spe =0.8870, test_f1 =0.5045
[2024-12-13 21:06:50] Evaluate_02: epoch = 0300 train time = 2 s train loss = 0.124974 train acc = 1.0000, test acc = 0.5000, test_sen =0.5000, test_spe =0.8750, test_f1 =0.4782
[2024-12-13 21:06:56] Evaluate_03: epoch = 0300 train time = 2 s train loss = 0.053384 train acc = 1.0000, test acc = 0.4920, test_sen =0.4920, test_spe =0.8730, test_f1 =0.4399
[2024-12-13 21:07:02] Evaluate_04: epoch = 0300 train time = 2 s train loss = 0.080674 train acc = 1.0000, test acc = 0.4800, test_sen =0.4800, test_spe =0.8700, test_f1 =0.4379
Evaluate 5 random ConvNet, ACCmean = 0.5048 ACCstd = 0.0231
-------------------------
Evaluate 5 random ConvNet, SENmean = 0.5048 SENstd = 0.0231
-------------------------
Evaluate 5 random ConvNet, SPEmean = 0.8762 SPEstd = 0.0058
-------------------------
Evaluate 5 random ConvNet, F1mean = 0.4683 F1std = 0.0257
-------------------------
[2024-12-13 21:07:10] iter = 1000, loss = 46.3925

==================== Final Results ====================

Run 5 experiments, train on ConvNet, evaluate 25 random ConvNet, mean  = 54.43%  std = 3.44%

Process finished with exit code 0